diff --git a/src/mpid/ch4/netmod/ofi/libfabric/.appveyor.yml b/src/mpid/ch4/netmod/ofi/libfabric/.appveyor.yml
index 6f462c6b6..4a69c2ae3 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/.appveyor.yml
+++ b/src/mpid/ch4/netmod/ofi/libfabric/.appveyor.yml
@@ -23,14 +23,12 @@ before_build:
 
 after_build:
   - set PATH=%CD%\x64\%CONFIGURATION%;%PATH%
-  - cd ..
 
 before_test:
-  - git clone https://github.com/ofiwg/fabtests
   - cd fabtests
-  - git checkout -b v1.6.x origin/v1.6.x
   - msbuild fabtests.sln
 
 test_script:
   - set PATH=%CD%\x64\%CONFIGURATION%;%PATH%
+  - set FI_PROVIDER=sockets
   - scripts\runfabtests.cmd
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/.gitattributes b/src/mpid/ch4/netmod/ofi/libfabric/.gitattributes
new file mode 100644
index 000000000..cf1c38625
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/.gitattributes
@@ -0,0 +1 @@
+*.cmd eol=crlf
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/.gitignore b/src/mpid/ch4/netmod/ofi/libfabric/.gitignore
index c478d96ef..f8c16e564 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/.gitignore
+++ b/src/mpid/ch4/netmod/ofi/libfabric/.gitignore
@@ -31,6 +31,7 @@ Makefile
 Makefile.in
 aclocal.m4
 autom4te.cache
+config/*
 config.h
 config.h.in
 config.h.in~
@@ -63,3 +64,12 @@ util/fi_pingpong
 prov/*/*.spec
 
 .vs
+fabtests.spec
+
+fabtests/ubertest/fabtest
+fabtests/ubertest/fi_ubertest
+
+fabtests/benchmarks/fi_*
+fabtests/functional/fi_*
+fabtests/unit/fi_*
+pingpong/fi_*
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/.travis.yml b/src/mpid/ch4/netmod/ofi/libfabric/.travis.yml
index 307fb1fa3..4542a996a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/.travis.yml
+++ b/src/mpid/ch4/netmod/ofi/libfabric/.travis.yml
@@ -1,5 +1,4 @@
 dist: trusty
-sudo: false
 language: c
 compiler:
     - clang
@@ -11,13 +10,31 @@ addons:
     apt:
         packages:
             - rpm
-            - libibverbs-dev
-            - librdmacm-dev
             - libnl-3-200
             - libnl-3-dev
             - libnl-route-3-200
             - libnl-route-3-dev
             - libnuma-dev
+# required for rdma-core
+            - build-essential
+            - debhelper
+            - dh-systemd
+            - fakeroot
+            - gcc
+            - git
+            - libudev-dev
+            - make
+            - ninja-build
+            - pandoc
+            - pkg-config
+            - python
+            - valgrind
+            - sparse
+            - wget
+            - abi-compliance-checker
+            - abi-dumper
+# 32 bit support packages
+            - gcc-multilib
     ssh_known_hosts:
         - www.openfabrics.org
         - git.kernel.org
@@ -39,10 +56,15 @@ before_install:
 
 install:
     - ./autogen.sh
+    # Build rdma-core because ubuntu trusty doesn't have a sufficiently new version of ibverbs/rdma-core
     # Build verbs only in linux as OS X doesn't have verbs support
-    - if [[ "$TRAVIS_OS_NAME" == "linux" ]]; then
-        LIBRARY_CONFIGURE_ARGS="$LIBFABRIC_CONFIGURE_ARGS --enable-usnic
-        --enable-verbs --enable-mlx=$HOME/mlx";
+    - if [[ "$TRAVIS_OS_NAME" == "linux" ]] ; then
+        RDMA_CORE_BRANCH=v13 ;
+        git clone --depth 1 -b $RDMA_CORE_BRANCH https://github.com/linux-rdma/rdma-core.git && cd rdma-core && bash build.sh && cd - ;
+        RDMA_CORE_PATH=$PWD/rdma-core/build ;
+        export LD_LIBRARY_PATH="$RDMA_CORE_PATH/lib:$LD_LIBRARY_PATH" ;
+        LIBFABRIC_CONFIGURE_ARGS="$LIBFABRIC_CONFIGURE_ARGS --enable-usnic
+        --enable-verbs=$RDMA_CORE_PATH --enable-mlx=$HOME/mlx";
         UCX_BRANCH=v1.2.x;
         git clone --depth 1 -b $UCX_BRANCH https://github.com/openucx/ucx.git && cd ucx && ./autogen.sh && ./configure --prefix=$HOME/mlx CFLAGS="-w" && make -j2 install && cd -;
       fi
@@ -69,11 +91,16 @@ install:
     - make test
     - make distcheck
     - if [[ "$TRAVIS_OS_NAME" == "linux" ]]; then make rpm; fi
+    # Prepare build for fabtests
+    - ./configure $LIBFABRIC_CONFIGURE_ARGS
+    - make -j2
+    - make install
+    - make test
+    - make distcheck
+    - if [[ "$TRAVIS_OS_NAME" == "linux" ]]; then make rpm; fi
 
 script:
-    - git clone https://github.com/ofiwg/fabtests.git
     - cd fabtests
-    - git checkout -b v1.6.x origin/v1.6.x
     - ./autogen.sh
     - ./configure --prefix=$PREFIX --with-libfabric=$PREFIX
     - make -j2
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/AUTHORS b/src/mpid/ch4/netmod/ofi/libfabric/AUTHORS
index 559b95ea6..348227f51 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/AUTHORS
+++ b/src/mpid/ch4/netmod/ofi/libfabric/AUTHORS
@@ -1,12 +1,15 @@
+aikatz <aik49@cornell.edu>
 aingerson <aingerson@gmail.com>
 aingerson <alexia.ingerson@intel.com>
 Ajay Kulkarni <ajaykulk@cisco.com>
+aleksandra.justa <ajusta@gklab-125-155.igk.intel.com>
 Amith Abraham <aabraham@cray.com>
 Ana Guerrero López <ana@ekaia.org>
 Anatoliy Rozanov <anatoliy.rozanov@intel.com>
 Andrew Friedley <andrew.friedley@intel.com>
 Arun C Ilango <arun.ilango@intel.com>
 arun ilango <a-ilango@users.noreply.github.com>
+Arun Ilango <arun.ilango@intel.com>
 Ashley Pittman <ampittma@ampittma-mac02.pittman.co.uk.20.20.172.in-addr.arpa>
 Ashley Pittman <ashley.m.pittman@intel.com>
 Automated bot for the OFIWG organization <ofiwg-bot@users.noreply.github.com>
@@ -15,8 +18,10 @@ Ben Turrubiates <bturrubiates@lanl.gov>
 Ben Turrubiates <bturrubi@cisco.com>
 Brian Li <brian14708@gmail.com>
 Chang Hyun Park <heartinpiece@gmail.com>
+Charles J Archer <charles.j.archer@intel.com>
 Chen Zhao <soniczhao@gmail.com>
 Chuck Fossen <chuckf@cray.com>
+Dardo D Kleiner <dkleiner@cmf.nrl.navy.mil>
 Dave Goodell <dgoodell@cisco.com>
 David Noel <david.noel19@gmail.com>
 Dmitry Durnov <dmitry.durnov@intel.com>
@@ -28,11 +33,15 @@ Evan Harvey <eharvey@lanl.gov>
 Evgeny Leksikov <evgeny.leksikov@intel.com>
 Ezra Kissel <ezkissel@indiana.edu>
 Frank Zago <fzago@cray.com>
+germanafro <andreasberger86@hotmail.de>
 Gilles Gouaillardet <gilles.gouaillardet@iferc.org>
 Gilles Gouaillardet <gilles@rist.or.jp>
 Hefty <sean.hefty@intel.com>
 Holger Hoffstätte <holger@applied-asynchrony.com>
 Howard Pritchard <howardp@lanl.gov>
+Ignacio Hernandez <ignacio.hernandez@intel.com>
+Ira Weiny <ira.weiny@intel.com>
+Jaime Arteaga <jaime.a.arteaga.molina@intel.com>
 James Dinan <james.dinan@intel.com>
 James Shimek <jshimek@cray.com>
 James Swaro <james.swaro@gmail.com>
@@ -43,20 +52,32 @@ Jay Sternberg <jay.e.sternberg@intel.com>
 Jeff Hammond <jeff.r.hammond@intel.com>
 Jeff Hammond <jeff.science@gmail.com>
 Jeff Squyres <jsquyres@cisco.com>
+Jerome Berryhill <Jerome.Berryhill@Intel.com>
+Jerome Boyd Berryhill <JeromeBerryhill@Intel.com>
+Jerome Soumagne <jsoumagne@hdfgroup.org>
 Jianxin Xiong <jianxin.xiong@intel.com>
 Jim Snow <jim.m.snow@intel.com>
 Jithin Jose <jithin.jose@intel.com>
 Joe Doyle <joseph.doyle@intel.com>
+Johannes Ziegenbalg <Johannes.Ziegenbalg@gmail.com>
+John Biddiscombe <biddisco@cscs.ch>
+John Byrne <john.l.byrne@hpe.com>
 Jonathan Behrens <fintelia@gmail.com>
+jose <jose@cst-fs.(none)>
+jose <jose@cstnh-8.(none)>
+JoZie <JoZie@users.noreply.github.com>
 Ken Raffenetti <raffenet@mcs.anl.gov>
 kseager <kayla.seager@intel.com>
 Latchesar Ionkov <lionkov@lanl.gov>
 Lisanna Dettwyler <levi.e.dettwyler@intel.com>
 Lisanna Dettwyler <lisanna.dettwyler@intel.com>
+Marcin Salnik <marcin.salnik@intel.com>
 Martin Kontsek <mkontsek@cisco.com>
 Miao Luo <miao.luo@intel.com>
 Michael Blocksome <michael.blocksome@intel.com>
 Michael Chuvelev <michael.chuvelev@intel.com>
+Mohan Gandhi <mohgan@amazon.com>
+Neil Spruit <neil.r.spruit@intel.com>
 Oblomov, Sergey <hoopoepg@gmail.com>
 Oblomov, Sergey <sergey.oblomov@intel.com>
 OFIWG Bot <ofiwg@lists.openfabrics.org>
@@ -66,8 +87,10 @@ Patrick McCormick <patrick.m.mccormick@intel.com>
 Paul Coffman <pcoffman@anl.gov>
 Pierre Roux <piroux@cisco.com>
 Prankur Gupta <prankgup@cisco.com>
+Raghu Raja <craghun@amazon.com>
 Reese Faucette <rfaucett@cisco.com>
 Richard Halkyard <rhalkyard@cray.com>
+Robert Wespetal <wesper@amazon.com>
 Sannikov, Alexander <alexander.sannikov@intel.com>
 Sayantan Sur <sayantan.sur@intel.com>
 Sean Hefty <sean.hefty@intel.com>
@@ -79,6 +102,7 @@ Spruit, Neil R <neil.r.spruit@intel.com>
 Srdjan Milakovic <srdjan@rice.edu>
 Stan Smith <stan.smith@intel.com>
 Steven Vormwald <sdvormwa@cray.com>
+Steve Welch <swelch@systemfabricworks.com>
 Sung-Eun Choi <sungeunchoi@users.noreply.github.com>
 Sung-Eun Choi <sungeun@cray.com>
 Sylvain Didelot <didelot.sylvain@gmail.com>
@@ -86,6 +110,8 @@ Sylvain Didelot <sdidelot@ddn.com>
 Thananon Patinyasakdikul <apatinya@cisco.com>
 Thomas Smith <thomasm2@cisco.com>
 Tony Zinger <ajz@cray.com>
+tonyzinger <ajz@cray.com>
+Venkata Krishna Nimmagadda <nvkrishna85@gmail.com>
 Venkata Krishna Nimmagadda <venkata.krishna.nimmagadda@intel.com>
 Wesley Bland <wesley.bland@intel.com>
 Xuyang Wang <xuywang@cisco.com>
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/COPYING b/src/mpid/ch4/netmod/ofi/libfabric/COPYING
index 767dc0971..31bc30a75 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/COPYING
+++ b/src/mpid/ch4/netmod/ofi/libfabric/COPYING
@@ -3,8 +3,8 @@ licenses.  You may choose to be licensed under the terms of the the
 BSD license or the GNU General Public License (GPL) Version
 2, both included below.
 
-Copyright (c) 2015-2018 Intel Corporation.  All rights reserved.
-Copyright (c) 2015-2018 Cisco Systems, Inc.  All rights reserved.
+Copyright (c) 2015-2019 Intel Corporation.  All rights reserved.
+Copyright (c) 2015-2019 Cisco Systems, Inc.  All rights reserved.
 
 ==================================================================
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/Libfabric.Build.Default.props b/src/mpid/ch4/netmod/ofi/libfabric/Libfabric.Build.Default.props
new file mode 100644
index 000000000..285dce7b3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/Libfabric.Build.Default.props
@@ -0,0 +1,49 @@
+<?xml version="1.0" encoding="utf-8"?>
+<Project DefaultTargets="Build" ToolsVersion="12.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
+  <PropertyGroup Condition="'$(WindowsTargetPlatformVersion)'==''">
+    <!-- Default the installed latest Win10.0 SDK -->
+    <WindowsSdkInstallFolder_10_0 Condition="'$(WindowsSdkInstallFolder_10_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v10.0@InstallationFolder)</WindowsSdkInstallFolder_10_0>
+    <WindowsSdkInstallFolder_10_0 Condition="'$(WindowsSdkInstallFolder_10_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v10.0@InstallationFolder)</WindowsSdkInstallFolder_10_0>
+    <WindowsTargetPlatformVersion_10_0 Condition="'$(WindowsTargetPlatformVersion_10_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v10.0@ProductVersion)</WindowsTargetPlatformVersion_10_0>
+    <WindowsTargetPlatformVersion_10_0 Condition="'$(WindowsTargetPlatformVersion_10_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v10.0@ProductVersion)</WindowsTargetPlatformVersion_10_0>
+    <!-- Sometimes the version in the registry has to .0 suffix, and sometimes it doesn't. Check and add it -->
+    <WindowsTargetPlatformVersion_10_0 Condition="'$(WindowsTargetPlatformVersion_10_0)' != '' and !$(WindowsTargetPlatformVersion_10_0.EndsWith('.0'))">$(WindowsTargetPlatformVersion_10_0).0</WindowsTargetPlatformVersion_10_0>
+    <WindowsTargetPlatformVersion>$(WindowsTargetPlatformVersion_10_0)</WindowsTargetPlatformVersion>
+
+    <!-- Default the installed latest Win8.1 SDK -->
+    <WindowsSdkInstallFolder_8_1 Condition="'$(WindowsSdkInstallFolder_8_1)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v8.1@InstallationFolder)</WindowsSdkInstallFolder_8_1>
+    <WindowsSdkInstallFolder_8_1 Condition="'$(WindowsSdkInstallFolder_8_1)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v8.1@InstallationFolder)</WindowsSdkInstallFolder_8_1>
+    <WindowsTargetPlatformVersion_8_1 Condition="'$(WindowsTargetPlatformVersion_8_1)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v8.1@ProductVersion)</WindowsTargetPlatformVersion_8_1>
+    <WindowsTargetPlatformVersion_8_1 Condition="'$(WindowsTargetPlatformVersion_8_1)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v8.1@ProductVersion)</WindowsTargetPlatformVersion_8_1>
+    <!-- Sometimes the version in the registry has to .0 suffix, and sometimes it doesn't. Check and add it -->
+    <WindowsTargetPlatformVersion_8_1 Condition="'$(WindowsTargetPlatformVersion_8_1)' != '' and !$(WindowsTargetPlatformVersion_8_1.EndsWith('.0'))">$(WindowsTargetPlatformVersion_8_1).0</WindowsTargetPlatformVersion_8_1>
+    <WindowsTargetPlatformVersion Condition="'$(WindowsTargetPlatformVersion)' == ''">$(WindowsTargetPlatformVersion_8_1)</WindowsTargetPlatformVersion>
+
+    <!-- Default the installed latest Win8.0 SDK -->
+    <WindowsSdkInstallFolder_8_0 Condition="'$(WindowsSdkInstallFolder_8_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v8.0@InstallationFolder)</WindowsSdkInstallFolder_8_0>
+    <WindowsSdkInstallFolder_8_0 Condition="'$(WindowsSdkInstallFolder_8_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v8.0@InstallationFolder)</WindowsSdkInstallFolder_8_0>
+    <WindowsTargetPlatformVersion_8_0 Condition="'$(WindowsTargetPlatformVersion_8_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v8.0@ProductVersion)</WindowsTargetPlatformVersion_8_0>
+    <WindowsTargetPlatformVersion_8_0 Condition="'$(WindowsTargetPlatformVersion_8_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v8.0@ProductVersion)</WindowsTargetPlatformVersion_8_0>
+    <!-- Sometimes the version in the registry has to .0 suffix, and sometimes it doesn't. Check and add it -->
+    <WindowsTargetPlatformVersion_8_0 Condition="'$(WindowsTargetPlatformVersion_8_0)' != '' and !$(WindowsTargetPlatformVersion_8_0.EndsWith('.0'))">$(WindowsTargetPlatformVersion_8_0).0</WindowsTargetPlatformVersion_8_0>
+    <WindowsTargetPlatformVersion Condition="'$(WindowsTargetPlatformVersion)' == ''">$(WindowsTargetPlatformVersion_8_0)</WindowsTargetPlatformVersion>
+
+    <!-- Default the installed latest Win7.1 SDK -->
+    <WindowsSdkInstallFolder_7_1 Condition="'$(WindowsSdkInstallFolder_7_1)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v7.1@InstallationFolder)</WindowsSdkInstallFolder_7_1>
+    <WindowsSdkInstallFolder_7_1 Condition="'$(WindowsSdkInstallFolder_7_1)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v7.1@InstallationFolder)</WindowsSdkInstallFolder_7_1>
+    <WindowsTargetPlatformVersion_7_1 Condition="'$(WindowsTargetPlatformVersion_7_1)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v7.1@ProductVersion)</WindowsTargetPlatformVersion_7_1>
+    <WindowsTargetPlatformVersion_7_1 Condition="'$(WindowsTargetPlatformVersion_7_1)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v7.1@ProductVersion)</WindowsTargetPlatformVersion_7_1>
+    <!-- Sometimes the version in the registry has to .0 suffix, and sometimes it doesn't. Check and add it -->
+    <WindowsTargetPlatformVersion_7_1 Condition="'$(WindowsTargetPlatformVersion_7_1)' != '' and !$(WindowsTargetPlatformVersion_7_1.EndsWith('.0'))">$(WindowsTargetPlatformVersion_7_1).0</WindowsTargetPlatformVersion_7_1>
+    <WindowsTargetPlatformVersion Condition="'$(WindowsTargetPlatformVersion)' == ''">$(WindowsTargetPlatformVersion_7_1)</WindowsTargetPlatformVersion>
+
+    <!-- Default the installed latest Win7.1 SDK -->
+    <WindowsSdkInstallFolder_7_0 Condition="'$(WindowsSdkInstallFolder_7_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v7.0@InstallationFolder)</WindowsSdkInstallFolder_7_0>
+    <WindowsSdkInstallFolder_7_0 Condition="'$(WindowsSdkInstallFolder_7_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v7.0@InstallationFolder)</WindowsSdkInstallFolder_7_0>
+    <WindowsTargetPlatformVersion_7_0 Condition="'$(WindowsTargetPlatformVersion_7_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SDKs\Windows\v7.0@ProductVersion)</WindowsTargetPlatformVersion_7_0>
+    <WindowsTargetPlatformVersion_7_0 Condition="'$(WindowsTargetPlatformVersion_7_0)' == ''">$(Registry:HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\Microsoft SDKs\Windows\v7.0@ProductVersion)</WindowsTargetPlatformVersion_7_0>
+    <!-- Sometimes the version in the registry has to .0 suffix, and sometimes it doesn't. Check and add it -->
+    <WindowsTargetPlatformVersion_7_0 Condition="'$(WindowsTargetPlatformVersion_7_0)' != '' and !$(WindowsTargetPlatformVersion_7_0.EndsWith('.0'))">$(WindowsTargetPlatformVersion_7_0).0</WindowsTargetPlatformVersion_7_0>
+    <WindowsTargetPlatformVersion Condition="'$(WindowsTargetPlatformVersion)' == ''">$(WindowsTargetPlatformVersion_7_0)</WindowsTargetPlatformVersion>
+  </PropertyGroup>
+</Project>
\ No newline at end of file
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/Makefile.am b/src/mpid/ch4/netmod/ofi/libfabric/Makefile.am
index 6224aa60a..afa52a7a7 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/Makefile.am
+++ b/src/mpid/ch4/netmod/ofi/libfabric/Makefile.am
@@ -1,6 +1,7 @@
 #
 # Copyright (c) 2016 Cisco Systems, Inc.  All rights reserved.
-# Copyright (c) 2017 Intel Corporation, Inc. All right reserved.
+# Copyright (c) 2017-2018 Intel Corporation, Inc. All right reserved.
+# Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
 #
 # Makefile.am for libfabric
 
@@ -41,10 +42,12 @@ common_srcs =				\
 	src/common.c			\
 	src/enosys.c			\
 	src/rbtree.c			\
+	src/tree.c			\
 	src/fasthash.c			\
 	src/indexer.c			\
 	src/mem.c			\
 	src/iov.c			\
+	src/shared/ofi_str.c		\
 	prov/util/src/util_atomic.c	\
 	prov/util/src/util_attr.c	\
 	prov/util/src/util_av.c		\
@@ -63,17 +66,7 @@ common_srcs =				\
 	prov/util/src/util_ns.c		\
 	prov/util/src/util_shm.c	\
 	prov/util/src/util_mem_monitor.c\
-	prov/util/src/util_mr_cache.c	\
-	prov/hook/src/hook.c		\
-	prov/hook/src/hook_av.c		\
-	prov/hook/src/hook_cm.c		\
-	prov/hook/src/hook_cntr.c	\
-	prov/hook/src/hook_cq.c		\
-	prov/hook/src/hook_domain.c	\
-	prov/hook/src/hook_ep.c		\
-	prov/hook/src/hook_eq.c		\
-	prov/hook/src/hook_wait.c	\
-	prov/hook/src/hook_xfer.c
+	prov/util/src/util_mr_cache.c
 
 
 if MACOS
@@ -90,6 +83,7 @@ endif
 
 if LINUX
 common_srcs += src/unix/osd.c
+common_srcs += src/linux/osd.c
 if HAVE_LINUX_PERF_RDPMC
 common_srcs += src/linux/rdpmc.c
 endif
@@ -127,16 +121,21 @@ src_libfabric_la_SOURCES =			\
 	include/ofi_atom.h			\
 	include/ofi_enosys.h			\
 	include/ofi_file.h			\
+	include/ofi_hook.h			\
 	include/ofi_indexer.h			\
 	include/ofi_iov.h			\
 	include/ofi_list.h			\
+	include/shared/ofi_str.h		\
 	include/ofi_lock.h			\
 	include/ofi_mem.h			\
 	include/ofi_osd.h			\
 	include/ofi_proto.h			\
+	include/ofi_recvwin.h			\
 	include/ofi_rbuf.h			\
 	include/ofi_shm.h			\
 	include/ofi_signal.h			\
+	include/ofi_epoll.h			\
+	include/ofi_tree.h			\
 	include/ofi_util.h			\
 	include/ofi_atomic.h			\
 	include/ofi_mr.h			\
@@ -146,7 +145,6 @@ src_libfabric_la_SOURCES =			\
 	include/rbtree.h			\
 	include/uthash.h			\
 	include/ofi_prov.h			\
-	prov/hook/src/hook.h			\
 	include/rdma/providers/fi_log.h		\
 	include/rdma/providers/fi_prov.h	\
 	src/fabric.c				\
@@ -155,6 +153,16 @@ src_libfabric_la_SOURCES =			\
 	src/log.c				\
 	src/var.c				\
 	src/abi_1_0.c				\
+	prov/hook/src/hook.c			\
+	prov/hook/src/hook_av.c			\
+	prov/hook/src/hook_cm.c			\
+	prov/hook/src/hook_cntr.c		\
+	prov/hook/src/hook_cq.c			\
+	prov/hook/src/hook_domain.c		\
+	prov/hook/src/hook_ep.c			\
+	prov/hook/src/hook_eq.c			\
+	prov/hook/src/hook_wait.c		\
+	prov/hook/src/hook_xfer.c		\
 	$(common_srcs)
 
 src_libfabric_la_CPPFLAGS = $(AM_CPPFLAGS)
@@ -163,7 +171,7 @@ src_libfabric_la_LIBADD =
 src_libfabric_la_DEPENDENCIES = libfabric.map
 
 if !EMBEDDED
-src_libfabric_la_LDFLAGS += -version-info 10:15:9
+src_libfabric_la_LDFLAGS += -version-info 11:0:10
 endif
 src_libfabric_la_LDFLAGS += -export-dynamic \
 			   $(libfabric_version_script)
@@ -214,12 +222,14 @@ real_man_pages = \
         man/man3/fi_getinfo.3 \
         man/man3/fi_mr.3 \
         man/man3/fi_msg.3 \
+	man/man3/fi_nic.3 \
         man/man3/fi_poll.3 \
         man/man3/fi_rma.3 \
         man/man3/fi_tagged.3 \
         man/man3/fi_trigger.3 \
         man/man3/fi_version.3 \
         man/man7/fabric.7 \
+	man/man7/fi_hook.7 \
         man/man7/fi_provider.7 \
         man/man7/fi_direct.7
 
@@ -369,11 +379,15 @@ include prov/psm/Makefile.include
 include prov/psm2/Makefile.include
 include prov/gni/Makefile.include
 include prov/rxm/Makefile.include
+include prov/mrail/Makefile.include
 include prov/rxd/Makefile.include
 include prov/bgq/Makefile.include
 include prov/mlx/Makefile.include
 include prov/shm/Makefile.include
 include prov/tcp/Makefile.include
+include prov/rstream/Makefile.include
+include prov/hook/Makefile.include
+include prov/hook/perf/Makefile.include
 
 man_MANS = $(real_man_pages) $(prov_install_man_pages) $(dummy_man_pages)
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/NEWS.md b/src/mpid/ch4/netmod/ofi/libfabric/NEWS.md
index eada67bff..457303543 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/NEWS.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/NEWS.md
@@ -5,6 +5,173 @@ This file contains the main features as well as overviews of specific
 bug fixes (and other actions) for each version of Libfabric since
 version 1.0.
 
+v1.7.0, Mon Jan 7, 2018
+=======================
+
+The 1.7 release provides a few enhancements to the libfabric API.
+Notably, it extends the fi_info structure in order to report NIC
+attributes for domains that have a direct association with network
+hardware.  The NIC attributes include details about the device, the
+system bus it's attached to, and link state.  NIC attributes are
+automatically reported by the fi_info utility application.  See the
+fi_nic.3 man page for additional details.
+
+An experimental capability bit is added to optimize receive side
+processing.  This is known as variable messages, and targets applications
+that do now know what size message a peer with send prior to the
+message arriving.  Variable messages can be used to avoid receive
+side data copies and eliminate the need for applications to implement
+their own rendezvous protocol.  See the fi_msg.3 man page for details on
+variable messages and it's sister, buffered messages.
+
+Specific details on changes since the 1.6.2 release are outlined below.
+
+## Core
+
+- Add ability to report NIC details with fi_info data
+- Improve MR cache notification mechanisms
+- Set sockaddr address format correctly
+- Avoid possible null dereference in eq_read
+- Handle FI_PEEK in CQ/EQ readerr
+- Add debug messages to name server
+- Feature and performance enhancements added to internal buffer pool
+- Add support for huge pages
+- Decrease memory use for idle buffer pools
+- Refactor utility AV functionality
+- Generic counter support enhancements
+- Optimize EP and CQ locking based on application threading level
+- Enhance common support for EQ error handling
+- Add free/alloc memory notification hooks for MR cache support
+- Fix memory monitor unsubscribe handling
+- Add CQ fd wait support
+- Add CQ overflow protection
+- Enhance IPv6 addressing support for AVs
+- Enhancements to support for AV address lookup
+- Fixes for emulated epoll support
+- Allow layering of multiple utility providers
+- Minor bug fixes and optimization
+
+## Hook
+
+- Improved hooking infrastructure
+- Add support for installing multiple hooks
+- Support hooks provided by external libraries.
+
+## GNI
+
+- Fix CQ readfrom overwriting src_addr in case of multiple events
+- Signal wait set if error entry is added to CQ
+- Fix state data issue with SMSG buffers
+- Enhance and fix possible misuse of default authorization key
+- Add cancel support for SEP
+- Rework SEP setup
+- Suppress huge page counting for ARM
+- Fix incorrect check of FI_SYNC_ERR flag
+
+## MRAIL
+
+- Initial release of mrail provider. The current status is experimental: not all
+  features are supported and performance is not guaranteed.
+- Enables increased bandwidth for an underlying provider by utilizing multiple
+  network ports (rails).
+
+## NetDir
+
+- Fix crash in initialization code
+- Update references to NetworkDirect header packaged
+
+## PSM2
+
+- Requires PSM2 library version 10.2.260 or later
+- Clean up connection state in fi_av_remove
+- Use psm2_info_query to read HFI device info
+- Clean up CQ/counter poll list when endpoint is closed
+- Support shared address vector
+- Optimize CQ event conversion with psm2_mq_ipeek_dequeue_multi
+- Lock optimization for FI_THREAD_DOMAIN
+- Use new PSM2 fast path isend/irecv functions for large size RMA
+- Support building with latest PSM2 source code (version 11.2.68)
+- Support fabric direct
+
+## RxD
+
+- Initial release of RxD provider
+- Provides reliable datagram semantics over unreliable datagram EPs
+- Target is to improve scalability for very large clusters relative to RxM
+
+## RxM
+
+- Decrease memory use needed to maintain large number of connections
+- Set correct op_context and flags on CQ error completions
+- Fix file descriptor memory leaks
+- Introduce new protocol optimized for medium message transfers
+- Improve Rx software performance path
+- Use shared receive contexts if required by underlying provider
+- Handle addresses inserted multiple times into AV (for AV map)
+- Performance optimizations for single-thread applications
+- Rework deferred transmit processing
+- Separate and optimize eager and rendezvous protocol processing.
+- Fix passing incorrect addresses for AV insert/remove
+- Fix CM address handling
+- Fix race condition accessing connection handles
+- Simplify small RMA code path
+- Increment correct counter when processing FI_READ events
+- Dynamically grow the number of connections that can be supported
+- Fix padding in wire protocol structures
+- Report correct fi_addr when FI_SOURCE is requested
+- Fix truncating rendezvous messages
+- Fix use after free error in Rx buffer processing
+- Add support for manual progress
+- Make Tx/Rx queue sizes independent of MSG EP sizes
+- Decrease time needed to repost buffers to the MSG EP Rx queue.
+- Miscellaneous bug fixes
+
+## Sockets
+
+- Enable MSG EPs when user calls fi_accept
+- Fix fabric names to be underlying IP address
+- Add connection timeout environment variable.
+- Use size of addresses, not structures
+- Add debug messages to display selected addresses
+- Use loopback address in place of localhost
+- Simplify listen paths
+- Add support for IPv6
+- Code restructuring
+- Avoid unneeded address to string to address translations
+- Check length of iovec entries prior to access buffers
+- Fix segfault
+- Avoid acquiring nested spinlocks resulting in hangs
+- Fix use after free error in triggered op handling
+- New connection manager for MSG EPs to reduce number of threads
+- Avoid retrying recv operations if connection has been broken
+- Fixes for Windows socket support
+
+## TCP
+
+- Initial release of optimized socket based tcp provider
+- Supports MSG EPs, to be used in conjunction with RxM provider
+- Targets eventual replacement of sockets provider
+
+## Verbs
+
+- Remove RDM EP support.  Use RxM and RxD for RDM EPs.
+- Improve address handling and report in fi_getinfo
+- Handle FI_PEER when calling CQ/EQ readerr functions
+- Add support for XRC QPs.
+- Ignore destination address when allocating a PEP
+- Add workaround for i40iw incorrect return values when posting sends
+- Fix completion handling for FI_SELECTIVE_COMPLETION EP setting
+- Change format of fabric name to use hex instead of decimal values
+- Fix handling of err_data with EQ readerr
+- Report correct size of max_err_data
+- Fast path performance improvements
+- Improve progress under high system load
+- Optimize completion processing when handling hidden completions
+- Optimize RMA and MSG transfers by pre-formatting work requests
+- Remove locks based on application threading model
+- Add overflow support for CQ error events
+- Minor cleanups and bug fixes
+
 v1.6.2, Fri Sep 28, 2018
 ========================
 
@@ -13,6 +180,7 @@ v1.6.2, Fri Sep 28, 2018
 - Cleanup of debug messages
 
 ## GNI
+
 - Fix problems with Scalable Endpoint creation
 - Fix interoperability problem with HPC toolkit
 - Improve configuration check for kdreg
@@ -102,6 +270,7 @@ v1.6.1, Wed May 8, 2018
 
 - Fix use after free error handling triggered ops.
 
+
 v1.6.0, Wed Mar 14, 2018
 ========================
 
@@ -115,9 +284,9 @@ v1.6.0, Wed Mar 14, 2018
 - Add const to fi_getinfo() hints parameter
 - Improve use of epoll for better scalability
 - Fixes to generic name service
-- Implemented support of MR caching without merging of regions
 
 ## GNI
+
 - Fix a problem with the GNI waitset implementation
 - Enable use of XPMEM for intra node data transfers
 - Fix a problem with usage of Crays UDREG registration cache
@@ -211,7 +380,7 @@ v1.6.0, Wed Mar 14, 2018
 
 - Scalability enhancements
 - Fix issue associating a connection with an AV entry that could result in
-  application hangs
+   application hangs
 - Add support for new persistent memory capabilities
 - Fix fi_cq_signal to unblock threads waiting on cq sread calls
 - Fix epoll_wait loop handling to avoid out of memory errors
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/README.md b/src/mpid/ch4/netmod/ofi/libfabric/README.md
index fc4d53d4e..b6c640101 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/README.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/README.md
@@ -197,6 +197,19 @@ supports all Libfabric provider requirements and interfaces.
 
 See the `fi_sockets(7)` man page for more details.
 
+### tcp
+
+***
+
+The tcp provider is an optimized socket based provider that supports
+reliable connected endpoints.  It is intended to be used directly by
+apps that need MSG endpoint support, or in conjunction with the rxm
+provider for apps that need RDM endpoints.  The tcp provider targets
+replacing the sockets provider for applications using standard
+networking hardware.
+
+See the `fi_tcp(7)` man page for more details.
+
 
 ### udp
 
@@ -309,9 +322,6 @@ Windows OS to expose the capabilities of the networking devices if the hardware
 vendors of the devices implemented the Network Direct service provider interface
 (SPI) for their hardware.
 
-The Network Direct is an experimental provider. The full support of the Network
-Direct provider will be added to 1.6 release version of libfabric.
-
 See the `fi_netdir(7)` man page for more details.
 
 #### Dependencies
@@ -356,4 +366,38 @@ See the `fi_shm(7)` man page for more details.
 
 - The shared memory provider only works on Linux platforms and makes use of
   kernel support for 'cross-memory attach' (CMA) data copies for large
-  transfers.
\ No newline at end of file
+  transfers.
+
+## WINDOWS Instructions
+
+Even though windows isn't fully supported yet it is possible to compile and link your library.
+
+- 1. first you need the NetDirect provider:
+  Network Direct SDK/DDK may be obtained as a nuget package (preferred) from:
+
+  https://www.nuget.org/packages/NetworkDirect
+
+  or downloaded from:
+
+  https://www.microsoft.com/en-us/download/details.aspx?id=36043
+  on page press Download button and select NetworkDirect_DDK.zip.
+
+  Extract header files from downloaded
+  NetworkDirect_DDK.zip:`\NetDirect\include\` file into `<libfabricroot>\prov\netdir\NetDirect\`,
+  or add path to NetDirect headers into VS include paths
+
+- 2. compiling:
+  libfabric has 6 Visual Studio solution configurations:
+
+      1-2: Debug/Release ICC (restricted support for Intel Compiler XE 15.0 only)
+      3-4: Debug/Release v140 (VS 2015 tool set)
+      5-6: Debug/Release v141 (VS 2017 tool set)
+
+  make sure you choose the correct target fitting your compiler.
+  By default the library will be compiled to `<libfabricroot>\x64\<yourconfigchoice>`
+
+- 3. linking your library
+  - right click your project and select properties.
+  - choose C/C++ > General and add `<libfabricroot>\include` to "Additional include Directories"
+  - choose Linker > Input and add `<libfabricroot>\x64\<yourconfigchoice>\libfabric.lib` to "Additional Dependencies"
+  - depending on what you are building you may also need to copy `libfabric.dll` into the targetfolder of your own project.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/config/cron-make-nightly-tarball.pl b/src/mpid/ch4/netmod/ofi/libfabric/config/cron-make-nightly-tarball.pl
index b030a0534..2db6d2414 100755
--- a/src/mpid/ch4/netmod/ofi/libfabric/config/cron-make-nightly-tarball.pl
+++ b/src/mpid/ch4/netmod/ofi/libfabric/config/cron-make-nightly-tarball.pl
@@ -35,7 +35,6 @@ use File::Basename;
 use Getopt::Long;
 
 my $libfabric_dir_arg;
-my $fabtests_dir_arg;
 my $download_dir_arg;
 my $libfabric_coverity_token_arg;
 my $fabtests_coverity_token_arg;
@@ -45,7 +44,6 @@ my $verbose_arg;
 my $debug_arg;
 
 my $ok = Getopt::Long::GetOptions("libfabric-source-dir=s" => \$libfabric_dir_arg,
-                                  "fabtests-source-dir=s" => \$fabtests_dir_arg,
                                   "download-dir=s" => \$download_dir_arg,
                                   "libfabric-coverity-token=s" => \$libfabric_coverity_token_arg,
                                   "fabtests-coverity-token=s" => \$fabtests_coverity_token_arg,
@@ -56,14 +54,13 @@ my $ok = Getopt::Long::GetOptions("libfabric-source-dir=s" => \$libfabric_dir_ar
                                   );
 
 if ($help_arg || !$ok) {
-    print "$0 --libfabric-source-dir libfabric_git_tree --fabtests-source-dir fabtests_git_tree --download-dir download_tree\n";
+    print "$0 --libfabric-source-dir libfabric_git_tree --download-dir download_tree\n";
     exit($ok);
 }
 
 # Sanity checks
-die "Must specify --libfabric-source-dir, --fabtests-source-dir, --download-dir, and --logfile-dir"
+die "Must specify --libfabric-source-dir, --download-dir, and --logfile-dir"
     if (!defined($libfabric_dir_arg) || $libfabric_dir_arg eq "" ||
-        !defined($fabtests_dir_arg) || $fabtests_dir_arg eq "" ||
         !defined($download_dir_arg) || $download_dir_arg eq "" ||
         !defined($logfile_dir_arg) || $logfile_dir_arg eq "");
 die "$libfabric_dir_arg is not a valid directory"
@@ -140,7 +137,6 @@ sub get_git_version {
 
 sub make_tarball {
     my $base_name = shift;
-    my $source_dir = shift;
     my $version = shift;
     my $installdir = shift;
 
@@ -251,14 +247,13 @@ verbose("*** Building libfabric...\n");
 chdir($libfabric_dir_arg);
 git_cleanup();
 my $libfabric_version = get_git_version();
-my $rebuilt_libfabric = make_tarball("libfabric", $libfabric_dir_arg,
-    $libfabric_version, $installdir);
+my $rebuilt_libfabric = make_tarball("libfabric",
+				     $libfabric_version, $installdir);
 
 verbose("\n\n*** Building fabtests...\n");
-chdir($fabtests_dir_arg);
-git_cleanup();
+chdir('fabtests');
 my $fabtests_version = get_git_version();
-my $rebuilt_fabtests = make_tarball("fabtests", $fabtests_dir_arg,
+my $rebuilt_fabtests = make_tarball("fabtests",
                                     $fabtests_version, $installdir);
 
 if ($rebuilt_libfabric || $rebuilt_fabtests) {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/config/cron-run-all-md2nroff.pl b/src/mpid/ch4/netmod/ofi/libfabric/config/cron-run-all-md2nroff.pl
index b55b4317e..f1f0c7837 100755
--- a/src/mpid/ch4/netmod/ofi/libfabric/config/cron-run-all-md2nroff.pl
+++ b/src/mpid/ch4/netmod/ofi/libfabric/config/cron-run-all-md2nroff.pl
@@ -147,26 +147,43 @@ if (defined($pages_branch_arg)) {
     doit(0, "git clone --single-branch --branch $pages_branch_arg $repo_arg pages", "git-clone-pages");
 }
 
+#####################################################################
+# Look for all markdown man pages
 #####################################################################
 
-# Find all the *.\d.md files in the source repo
-verbose("*** Finding markdown man pages...\n");
+# Find all libfabric *.\d.md files
+verbose("*** Finding libfabric markdown man pages...\n");
 opendir(DIR, "source/man");
-my @markdown_files = grep { /\.\d\.md$/ && -f "source/man/$_" } readdir(DIR);
+my @libfabric_markdown_files =
+    map { "source/man/" . $_ }
+    grep { /\.\d\.md$/ && -f "source/man/$_" } readdir(DIR);
+closedir(DIR);
+verbose("Found: @libfabric_markdown_files\n");
+
+# Find all fabtests *.\d.md files
+verbose("*** Finding fabtests markdown man pages...\n");
+opendir(DIR, "source/fabtests/man");
+my @fabtests_markdown_files =
+    map { "source/fabtests/man/" . $_ }
+    grep { /\.\d\.md$/ && -f "source/fabtests/man/$_" } readdir(DIR);
 closedir(DIR);
-verbose("Found: @markdown_files\n");
+verbose("Found: @fabtests_markdown_files\n");
 
+#####################################################################
+# Publish any changes to man pages to the gh-pages branch
+# (only libfabric -- not fabtests)
 #####################################################################
 
 # Copy each of the markdown files to the pages branch checkout
 if (defined($pages_branch_arg)) {
     chdir("pages/master");
-    foreach my $file (@markdown_files) {
-        doit(0, "cp ../../source/man/$file man/$file", "loop-cp");
+    foreach my $file (@libfabric_markdown_files) {
+        my $base = basename($file);
+        doit(0, "cp $tmpdir/$file man/$base", "loop-cp");
 
         # Is there a new man page?  If so, we need to "git add" it.
-        my $out = `git status --porcelain man/$file`;
-        doit(0, "git add man/$file", "loop-git-add")
+        my $out = `git status --porcelain man/$base`;
+        doit(0, "git add man/$base", "loop-git-add")
             if ($out =~ /^\?\?/);
     }
 
@@ -190,11 +207,12 @@ if (defined($pages_branch_arg)) {
     push(@headings, { section=>3, title=>"API documentation" });
     foreach my $h (@headings) {
         print OUT "\n* $h->{title}\n";
-        foreach my $file (sort(@markdown_files)) {
-            if ($file =~ /\.$h->{section}\.md$/) {
-                $file =~ m/^(.+)\.$h->{section}\.md$/;
-                my $base = $1;
-                print OUT "  * [$base($h->{section})]($base.$h->{section}.html)\n";
+        foreach my $file (sort(@libfabric_markdown_files)) {
+            my $base = basename($file);
+            if ($base =~ /\.$h->{section}\.md$/) {
+                $base =~ m/^(.+)\.$h->{section}\.md$/;
+                my $shortname = $1;
+                print OUT "  * [$shortname($h->{section})]($shortname.$h->{section}.html)\n";
             }
         }
     }
@@ -210,28 +228,21 @@ if (defined($pages_branch_arg)) {
 }
 
 #####################################################################
+# Look for changes to .md files and generate nroff files on master
+#####################################################################
+
+my @markdown_files = (@libfabric_markdown_files,
+                      @fabtests_markdown_files);
 
 # Now process each of the Markdown files in the source repo and
 # generate new nroff man pages.
-chdir("$tmpdir/source/man");
+chdir("$tmpdir");
 foreach my $file (@markdown_files) {
-    doit(0, "../config/md2nroff.pl --source $file", "loop2-md2nroff");
-
-    # Did we generate a new man page?  If so, we need to "git add" it.
-    my $man_file = basename($file);
-
-    $man_file =~ m/\.(\d)\.md$/;
-    my $section = $1;
-
-    $man_file =~ s/\.md$//;
-
-    my $full_filename = "man$section/$man_file";
-
-    my $out = `git status --porcelain $full_filename`;
-    doit(0, "git add $full_filename", "loop2-git-add")
-        if ($out =~ /^\?\?/);
+    doit(0, "$tmpdir/source/config/md2nroff.pl --source $file", "loop2-md2nroff");
 }
 
+#####################################################################
+
 # Similar to above: commit the newly-generated nroff pages and push
 # them back upstream.  If nothing changed, these will be no-ops.  Note
 # that there are mandatory CI checks on master, which means we can't
@@ -241,6 +252,7 @@ foreach my $file (@markdown_files) {
 
 # Try to delete the old pr branch first (it's ok to fail -- i.e., if
 # it wasn't there).
+chdir("$tmpdir/source");
 my $pr_branch_name = "pr/update-nroff-generated-man-pages";
 doit(1, "git branch -D $pr_branch_name");
 doit(0, "git checkout -b $pr_branch_name");
@@ -271,7 +283,7 @@ if ($old_head ne $new_head) {
     close(GIT);
 
     # Create a new pull request
-    my $cmd_base = "curl ";
+    my $cmd_base = "curl --silent ";
     $cmd_base .= "-H 'Content-Type: application/json' ";
     $cmd_base .= "-H 'Authorization: token $pat' ";
     $cmd_base .= "-H 'User-Agent: OFIWG-bot' ";
@@ -311,18 +323,19 @@ if ($old_head ne $new_head) {
     my $pr_num = $json->{'number'};
     verbose("Created PR #$pr_num\n");
 
-    # Wait for the required DCO CI to complete on the git hash for the
-    # latest commit.
+    # Wait for the required DCO check to complete on the git hash for
+    # the latest commit.
     $outfile = "github-ci-status-check.json";
 
     $cmd = $cmd_base;
     $cmd .= "-o $outfile ";
-    $cmd .= "https://api.github.com/repos/$gh_org/$gh_repo/commits/$new_head/statuses";
+    $cmd .= "-H 'Accept: application/vnd.github.antiope-preview+json' ";
+    $cmd .= "https://api.github.com/repos/$gh_org/$gh_repo/commits/$new_head/check-runs";
 
     my $count = 0;
     my $max_count = 30;
     my $happy = 0;
-    verbose("Waiting for DCO CI to complete\n");
+    verbose("Waiting for DCO check to complete\n");
 
     # Only wait for $max_count iterations
     while (!$happy && $count < $max_count) {
@@ -330,20 +343,26 @@ if ($old_head ne $new_head) {
         sleep(1);
 
         unlink($outfile);
-        doit(0, $cmd, "github-check-ci-status");
+        doit(0, $cmd, "github-check-run-status");
         my $json = read_json_file($outfile, 1);
 
-        if ($json and $#{$json} >= 0) {
+        if ($json and $#{$json->{"check_runs"}} >= 0) {
             # If we got any statuses back, check them to see if we can
             # find a successful DCO signoff.  That would indicate that
-            # the required CI test run.
-            foreach my $j (@$json) {
-                if ($j->{"context"} eq "DCO") {
+            # the required check test ran.
+            foreach my $j (@{$json->{"check_runs"}}) {
+                if ($j->{"name"} eq "DCO") {
                     verbose("Found DCO status on SHA $new_head\n");
-                    if ($j->{"state"} eq "success") {
-                        verbose("DCO is happy!\n");
-                        $happy = 1;
-                        last;
+                    if ($j->{"status"} eq "completed") {
+                        if ($j->{"conclusion"} eq "success") {
+                            verbose("DCO is happy!\n");
+                            $happy = 1;
+                            last;
+                        } else {
+                            verbose("DCO is not happy -- how did that happen?\n");
+                            $happy = 0;
+                            last;
+                        }
                     }
                 }
             }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/config/cron-submit-coverity.pl b/src/mpid/ch4/netmod/ofi/libfabric/config/cron-submit-coverity.pl
index 799057456..2e2b87d32 100755
--- a/src/mpid/ch4/netmod/ofi/libfabric/config/cron-submit-coverity.pl
+++ b/src/mpid/ch4/netmod/ofi/libfabric/config/cron-submit-coverity.pl
@@ -18,7 +18,7 @@ my $verbose_arg = 0;
 my $debug_arg = 0;
 my $logfile_dir_arg;
 my $configure_args = "";
-my $make_args = "-j 32";
+my $make_args = "-j8";
 my $help_arg = 0;
 
 &Getopt::Long::Configure("bundling");
@@ -37,6 +37,8 @@ $ok = 0
     if (!defined($filename_arg));
 $ok = 0
     if (!defined($coverity_token_arg));
+$ok = 0
+    if (($debug_arg || $verbose_arg) && !defined($logfile_dir_arg));
 if (!$ok || $help_arg) {
     print "Usage: $0 --filename=FILENAME --coverity-token=TOKEN [--dry-run] [--verbose] [--help]\n";
     exit($ok);
@@ -94,9 +96,20 @@ verbose "*** Working in $dir\n";
 
 # Get the coverity tool, put it in our path
 
+my $new_tool = "$ENV{HOME}/coverity-tool-new.tgz";
+my $old_tool = "$ENV{HOME}/coverity-tool.tgz";
+
 verbose "*** Downloading coverity tool\n";
-doit(0, "wget $coverity_tool_url --post-data \"token=$coverity_token_arg\&project=$project_arg\" -O coverity_tool.tgz");
-doit(0, "tar xf coverity_tool.tgz");
+doit(1, "curl --silent $coverity_tool_url --request POST --data \"token=$coverity_token_arg\&project=$project_arg\" -o $new_tool -z $old_tool");
+# With the -z option, curl will download the coverity tool only if it
+# is newer than what we already have.  If there's no newer file to
+# download, it'll just exit(0) (which is a LOT faster, because the
+# coverity tool is giant and it takes a long time to download).
+doit(1, "mv $new_tool $old_tool")
+    if (-f $new_tool);
+
+verbose "*** Extracting coverity tool\n";
+doit(0, "tar xf $old_tool");
 opendir(my $dh, ".") ||
     die "Can't opendir .";
 my @files = grep { /^cov/ && -d "./$_" } readdir($dh);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/config/fi_provider.m4 b/src/mpid/ch4/netmod/ofi/libfabric/config/fi_provider.m4
index 901de770b..704e0eaaa 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/config/fi_provider.m4
+++ b/src/mpid/ch4/netmod/ofi/libfabric/config/fi_provider.m4
@@ -92,7 +92,11 @@ dnl
 	)
 
 	# Call the provider's CONFIGURE and CONDITIONALS macros
-	m4_include([prov/]$1[/configure.m4])
+	m4_ifnblank(m4_esyscmd(ls [prov/]$1[/configure.m4] 2> /dev/null),
+		[m4_include([prov/]$1[/configure.m4])])
+	m4_ifnblank(m4_esyscmd(ls [prov/hook/]$1[/configure.m4] 2> /dev/null),
+		[m4_include([prov/hook/]$1[/configure.m4])])
+
 	_FI_PROVIDER_INVOKE($1, [CONFIGURE], [yes], [yes])
 	_FI_PROVIDER_INVOKE($1, [CONDITIONALS], [no], [no])
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/configure.ac b/src/mpid/ch4/netmod/ofi/libfabric/configure.ac
index 05b8d1316..060e1d85e 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/configure.ac
+++ b/src/mpid/ch4/netmod/ofi/libfabric/configure.ac
@@ -4,7 +4,7 @@ dnl
 dnl Process this file with autoconf to produce a configure script.
 
 AC_PREREQ([2.60])
-AC_INIT([libfabric], [1.6.2], [ofiwg@lists.openfabrics.org])
+AC_INIT([libfabric], [1.7.0], [ofiwg@lists.openfabrics.org])
 AC_CONFIG_SRCDIR([src/fabric.c])
 AC_CONFIG_AUX_DIR(config)
 AC_CONFIG_MACRO_DIR(config)
@@ -50,9 +50,9 @@ AS_IF([test x"$with_build_id" = x"no"], [with_build_id=""])
 AC_DEFINE_UNQUOTED([BUILD_ID],["$with_build_id"],
                    [adds build_id to version if it was defined])
 
-# Fix autoconf's habit of setting CFLAGS="-g -O2" by default while still
+# Override autoconf default CFLAG settings (e.g. "-g -O2") while still
 # allowing the user to explicitly set CFLAGS=""
-: ${CFLAGS="-fvisibility=hidden -O2 -DNDEBUG ${base_c_warn_flags}"}
+: ${CFLAGS="-fvisibility=hidden ${base_c_warn_flags}"}
 
 # AM_PROG_AS would set CFLAGS="-g -O2" by default if not set already so it
 # should not be called earlier
@@ -95,30 +95,22 @@ AC_ARG_ENABLE([debug],
 
 AS_IF([test x"$enable_debug" != x"no"],
       [dbg=1
-       CFLAGS_save=
-       # Remove -DNDEBUG flag if set
-       for flag in $CFLAGS; do
-           if test "$flag" != "-DNDEBUG"; then
-               CFLAGS_save="$CFLAGS_save $flag"
-           fi
-       done
        # See if all the flags in $debug_c_other_flags work
        good_flags=
        for flag in $debug_c_other_flags; do
            AC_MSG_CHECKING([to see if compiler supports $flag])
-           CFLAGS="$flag $CFLAGS_save"
+           CFLAGS="$flag $CFLAGS"
            AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[]], [[int i = 3;]])],
 	                     [AC_MSG_RESULT([yes])
 			      good_flags="$flag $good_flags"],
 			     [AC_MSG_RESULT([no])])
        done
        debug_c_other_flags=$good_flags
-       CFLAGS=$CFLAGS_save
        unset good_flags
-       unset CFLAGS_save
 
        CFLAGS="-g -O0 ${base_c_warn_flags} ${debug_c_warn_flags} ${debug_c_other_flags} $CFLAGS"],
-      [dbg=0])
+      [dbg=0
+       CFLAGS="-O2 -DNDEBUG $CFLAGS"])
 
 AC_DEFINE_UNQUOTED([ENABLE_DEBUG],[$dbg],
                    [defined to 1 if libfabric was configured with --enable-debug, 0 otherwise])
@@ -246,6 +238,31 @@ AC_TRY_LINK([#include <stdint.h>],
     ],
     [AC_MSG_RESULT(no)])
 
+dnl Check for gcc memory model aware built-in atomics
+dnl If supported check to see if not internal to compiler
+AC_MSG_CHECKING(compiler support for built-in memory model aware atomics)
+AC_TRY_LINK([#include <stdint.h>],
+    [uint64_t d;
+     uint64_t s;
+     uint64_t c;
+     uint64_t r;
+      r = __atomic_fetch_add(&d, s, __ATOMIC_SEQ_CST);
+      __atomic_load(&d, &r, __ATOMIC_SEQ_CST);
+      __atomic_exchange(&d, &s, &r, __ATOMIC_SEQ_CST);
+      __atomic_compare_exchange(&d,&c,&s,0, __ATOMIC_SEQ_CST, __ATOMIC_SEQ_CST);
+     #if defined(__PPC__) && !defined(__PPC64__)
+       #error compiler built-in memory model aware atomics are not supported on PowerPC 32-bit
+     #else
+       return 0;
+     #endif
+    ],
+    [
+        AC_MSG_RESULT(yes)
+        AC_SEARCH_LIBS([__atomic_load_8], [atomic])
+        AC_DEFINE(HAVE_BUILTIN_MM_ATOMICS, 1, [Set to 1 to use built-in intrinsics memory model aware atomics])
+    ],
+    [AC_MSG_RESULT(no)])
+
 dnl Check for gcc cpuid intrinsics
 AC_MSG_CHECKING(compiler support for cpuid)
 AC_TRY_LINK([
@@ -368,9 +385,12 @@ FI_PROVIDER_SETUP([gni])
 FI_PROVIDER_SETUP([udp])
 FI_PROVIDER_SETUP([tcp])
 FI_PROVIDER_SETUP([rxm])
+FI_PROVIDER_SETUP([mrail])
 FI_PROVIDER_SETUP([rxd])
 FI_PROVIDER_SETUP([bgq])
 FI_PROVIDER_SETUP([shm])
+FI_PROVIDER_SETUP([rstream])
+FI_PROVIDER_SETUP([perf])
 FI_PROVIDER_FINI
 dnl Configure the .pc file
 FI_PROVIDER_SETUP_PC
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/Jenkinsfile.verbs b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/Jenkinsfile.verbs
new file mode 100644
index 000000000..3d87eb988
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/Jenkinsfile.verbs
@@ -0,0 +1,446 @@
+// Copyright (c) 2018. Cray Inc. All rights reserved.
+// Libfabric Verbs provider Jenkins Pipeline file
+
+@Library(['CrayNetworkCI@master', 'dst-shared@master']) _
+
+pipeline {
+    options {
+        // Generic build options
+        timeout (time: 30, unit: 'MINUTES')
+        buildDiscarder(logRotator(numToKeepStr: '15'))
+
+        // Build options
+        disableConcurrentBuilds()
+        timestamps()
+        skipStagesAfterUnstable()
+    }
+    agent {
+        node {
+            label 'wham'
+        }
+    }
+    stages {
+        stage('Prologue') {
+            steps {
+                // creating git short hash
+                script {
+                    GIT_SHORT_COMMIT = sh(returnStdout: true, script: "git log -n 1 --pretty=format:'%h'").trim()
+                    LIBFABRIC_INSTALL = pwd tmp: true
+                }
+
+                dir ('contrib/cray/bin') {
+                    // verify requirements
+                    sh './verify_requirements.sh'
+
+                    // install python environment if necessary
+                    sh './setup.sh'
+                }
+            }
+        }
+        stage('Build') {
+            options {
+                timeout (time: 5, unit: 'MINUTES')
+            }
+            steps {
+                sh './autogen.sh'
+                sh "./configure --prefix=$LIBFABRIC_INSTALL"
+                sh "make -j 12"
+                sh "make install"
+                dir ("fabtests") {
+                    sh './autogen.sh'
+                    sh "./configure --with-libfabric=$LIBFABRIC_INSTALL --prefix=$FABTEST_PATH"
+                    sh "make -j12"
+                    sh "make -j12 install"
+                }
+            }
+        }
+        stage('Test') {
+            environment {
+                LD_LIBRARY_PATH = "$LIBFABRIC_INSTALL/lib:$LD_LIBRARY_PATH"
+                MPIR_CVAR_OFI_USE_PROVIDER = 'verbs;ofi_rxm'
+                LIBFABRIC_INSTALL_PATH = "$LIBFABRIC_INSTALL"
+                SFT_BIN = "${SFT_INSTALL_PATH + '/bin'}"
+                SFT_MAX_JOB_TIME = '3'
+                SFT_NUM_JOBS = '4'
+                SFT_PROVIDER = 'verbs;ofi_rxm'
+                SFT_BASELINE_DIR = "contrib/cray"
+                SFT_BASELINE_RESULTS_FILE = 'sft_test_results_baseline.txt'
+                SFT_PREVIOUS_BASELINE_RESULTS = 'sft_test_results_baseline.txt'
+                SFT_TEST_CMDS = 'sft_test_commands'
+                SFT_TEST_RESULTS = '_test_results.xml'
+                SFT_TEST_RESULTS_EXPECTED = 'expected_'
+                SFT_TEST_RESULTS_PREFIX = 'BUILD_'
+                SFT_TEST_RESULTS_CI = 'sft_ci_results.yaml'
+            }
+            options {
+                timeout (time: 22, unit: 'MINUTES')
+            }
+            parallel {
+                stage('Unit tests') {
+                    steps {
+                        echo 'placeholder'
+                    }
+                }
+                stage('Smoke tests') {
+                    steps {
+                        tee ('smoketests.tap') {
+                            sh '${BATS_INSTALL_PATH}/bats -t contrib/cray/bats/smoketests.bats'
+                        }
+                    }
+                    post {
+                        always {
+                            sh """contrib/cray/bin/parse_logfiles.sh \\
+                                    -r smoketests.tap \\
+                                    -w smoketests.xml \\
+                                    tap simple.smoketests simple"""
+                        }
+                    }
+                }
+                stage('Functional Tests: RC') {
+                    steps {
+                        tee ('fabtests-rc.log') {
+                            sh 'srun -n 2 --ntasks-per-node=1 contrib/cray/bin/fabtest_wrapper.sh -p ${FABTEST_PATH}/bin -v -T 60'
+                        }
+                        tee ('ubertests-rc.log') {
+                            sh 'srun -n 2 --ntasks-per-node=1 contrib/cray/bin/fabtest_wrapper.sh -p ${FABTEST_PATH}/bin -vvv -T 60 -t complex -u all'
+                        }
+                    }
+                    post {
+                        always {
+                            sh """contrib/cray/bin/parse_logfiles.sh \\
+                                    -r fabtests-rc.log \\
+                                    -w fabtests-rc.xml \\
+                                    fabtests \\
+                                    functional.fabtests.rc.quick \\
+                                    functional"""
+
+                            sh """contrib/cray/bin/parse_logfiles.sh \\
+                                    -r ubertests-rc.log \\
+                                    -w ubertests-rc.xml \\
+                                    fabtests \\
+                                    functional.fabtests.rc.uber \\
+                                    functional"""
+                        }
+                    }
+		}
+                stage('Functional Tests: XRC') {
+                    steps {
+                        tee ('fabtests-xrc.log') {
+                            sh 'srun -n 2 --ntasks-per-node=1 contrib/cray/bin/fabtest_wrapper.sh -p ${FABTEST_PATH}/bin -v -T 60 -e FI_VERBS_PREFER_XRC=1 -e FI_OFI_RXM_USE_SRX=1'
+                        }
+                        tee ('ubertests-xrc.log') {
+                            sh 'srun -n 2 --ntasks-per-node=1 contrib/cray/bin/fabtest_wrapper.sh -p ${FABTEST_PATH}/bin -vvv -T 60 -t complex -u all -e FI_VERBS_PREFER_XRC=1 -e FI_OFI_RXM_USE_SRX=1'
+                        }
+                    }
+                    post {
+                        always {
+                            sh """contrib/cray/bin/parse_logfiles.sh \\
+                                    -r fabtests-xrc.log \\
+                                    -w fabtests-xrc.xml \\
+                                    fabtests \\
+                                    functional.fabtests.xrc.quick \\
+                                    functional"""
+
+                            sh """contrib/cray/bin/parse_logfiles.sh \\
+                                    -r ubertests-xrc.log \\
+                                    -w ubertests-xrc.xml \\
+                                    fabtests \\
+                                    functional.fabtests.xrc.uber \\
+                                    functional"""
+                        }
+                    }
+                }
+                stage('SFT tests: RC') {
+                    environment {
+                        SFT_ADD_ARGS = "--additional-args ' '"
+                        SFT_TEST_RESULTS_SUBDIR = "sft_test_results/RC"
+                        SFT_TEST_RESULTS_DIR = "${env.WORKSPACE}" + "/" + "${env.SFT_TEST_RESULTS_SUBDIR}"
+                    }
+                    steps {
+                        sh "mkdir -p ${SFT_TEST_RESULTS_DIR}"
+                        timeout (time: 20, unit: 'MINUTES') {
+                            // run the test
+                            script {
+                                try {
+                                    dir ("${SFT_BIN}") {
+                                        sh """
+                                            ./ci-all.sh \\
+                                                --provider '${SFT_PROVIDER}' \\
+                                                -L ${SFT_TEST_RESULTS_DIR} \\
+                                                --num-jobs ${SFT_NUM_JOBS} \\
+                                                --max-job-time ${SFT_MAX_JOB_TIME} \\
+                                                --output-cmds ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_CMDS} \\
+                                                --results-file ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS_CI} \\
+                                                ${SFT_ADD_ARGS}
+                                        """
+                                    }
+                                } catch (exc) {
+                                    echo 'failed test, ignore result for now'
+                                }
+                            }
+                        }
+                    }
+                    post {
+                        always {
+                            sh """
+                                cp  ./${SFT_BASELINE_DIR}/${SFT_BASELINE_RESULTS_FILE} ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE}
+                                ${SFT_BIN}/sft_parse_test_results.pm -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} -d ${SFT_TEST_RESULTS_DIR} -o sft_RMA${SFT_TEST_RESULTS} -p "TR_RMA"
+                                ${SFT_BIN}/sft_parse_test_results.pm -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} -d ${SFT_TEST_RESULTS_DIR} -o sft_TAGGED${SFT_TEST_RESULTS} -p "TR_TAGGED"
+                                ${SFT_BIN}/sft_parse_test_results.pm -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} -d ${SFT_TEST_RESULTS_DIR} -o sft_MESSAGE${SFT_TEST_RESULTS} -p "TR_MESSAGE"
+                                ${SFT_BIN}/sft_parse_test_results.pm -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} -d ${SFT_TEST_RESULTS_DIR} -o sft_AMO${SFT_TEST_RESULTS} -p "TR_AMO"
+                                gzip -r ${SFT_TEST_RESULTS_DIR}
+                                gunzip ${SFT_TEST_RESULTS_DIR}/sft_*${SFT_TEST_RESULTS}.gz
+                                gunzip ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE}
+                            """
+                            // archive the results
+                            archiveArtifacts artifacts: "${env.SFT_TEST_RESULTS_SUBDIR}/*"
+                        }
+                    }
+                }
+                stage('SFT tests: XRC') {
+                    environment {
+                        SFT_ADD_ARGS = "--additional-args '--use-xrc'"
+                        SFT_TEST_RESULTS_SUBDIR = "sft_test_results/XRC"
+                        SFT_TEST_RESULTS_DIR = "${env.WORKSPACE}" + "/" + "${env.SFT_TEST_RESULTS_SUBDIR}"
+                    }
+                    steps {
+                        sh "mkdir -p ${SFT_TEST_RESULTS_DIR}"
+                        timeout (time: 20, unit: 'MINUTES') {
+                            // run the test
+                            script {
+                                try {
+                                    dir ("${SFT_BIN}") {
+                                        sh """
+                                            ./ci-all.sh \\
+                                                --provider '${SFT_PROVIDER}' \\
+                                                -L ${SFT_TEST_RESULTS_DIR} \\
+                                                --num-jobs ${SFT_NUM_JOBS} \\
+                                                --max-job-time ${SFT_MAX_JOB_TIME} \\
+                                                --output-cmds ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_CMDS} \\
+                                                --results-file ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS_CI} \\
+                                                ${SFT_ADD_ARGS}
+                                        """
+                                    }
+                                } catch (exc) {
+                                    echo 'failed test, ignore result for now'
+                                }
+                            }
+                        }
+                    }
+                    post {
+                        always {
+                            sh """
+                                cp  ./${SFT_BASELINE_DIR}/${SFT_BASELINE_RESULTS_FILE} ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE}
+                                ${SFT_BIN}/sft_parse_test_results.pm -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} -d ${SFT_TEST_RESULTS_DIR} -o sft_RMA${SFT_TEST_RESULTS} -p "TR_RMA"
+                                ${SFT_BIN}/sft_parse_test_results.pm -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} -d ${SFT_TEST_RESULTS_DIR} -o sft_TAGGED${SFT_TEST_RESULTS}  -p "TR_TAGGED"
+                                ${SFT_BIN}/sft_parse_test_results.pm -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} -d ${SFT_TEST_RESULTS_DIR} -o sft_MESSAGE${SFT_TEST_RESULTS} -p "TR_MESSAGE"
+                                ${SFT_BIN}/sft_parse_test_results.pm -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} -d ${SFT_TEST_RESULTS_DIR} -o sft_AMO${SFT_TEST_RESULTS} -p "TR_AMO"
+                                gzip -r ${SFT_TEST_RESULTS_DIR}
+                                gunzip ${SFT_TEST_RESULTS_DIR}/sft_*${SFT_TEST_RESULTS}.gz
+                                gunzip ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE}
+                            """
+                            // archive the results
+                            archiveArtifacts artifacts: "${env.SFT_TEST_RESULTS_SUBDIR}/*"
+                        }
+                    }
+                }
+                stage("System tests") {
+                    steps {
+                        echo 'placeholder'
+                    }
+                }
+                stage("Applications") {
+                    steps {
+                        tee ('mpi.tap') {
+                            timeout(time: 10, unit: 'MINUTES') {
+                                sh '${BATS_INSTALL_PATH}/bats -t contrib/cray/bats/mpi.bats'
+                            }
+                        }
+                    }
+                    post {
+                        always {
+                            sh """contrib/cray/bin/parse_logfiles.sh \\
+                                    -r mpi.tap \\
+                                    -w mpi.xml \\
+                                    tap applications.mpi applications"""
+                        }
+                    }
+                }
+            }
+            post {
+                always {
+                    step ([$class: 'XUnitBuilder',
+                       thresholds: [
+                            [$class: 'FailedThreshold', unstableThreshold: '0']],
+                            tools: [[$class: 'JUnitType', pattern: "smoketests.xml"]]])
+                    step ([$class: 'XUnitBuilder',
+                       thresholds: [
+                            [$class: 'FailedThreshold', unstableThreshold: '0']],
+                            tools: [[$class: 'JUnitType', pattern: "*-rc.xml"]]])
+                    step ([$class: 'XUnitBuilder',
+                       thresholds: [
+                            [$class: 'FailedThreshold', unstableThreshold: '0']],
+                            tools: [[$class: 'JUnitType', pattern: "*-xrc.xml"]]])
+                    step ([$class: 'XUnitBuilder',
+                       thresholds: [
+                            [$class: 'FailedThreshold', unstableThreshold: '0']],
+                            tools: [[$class: 'JUnitType', pattern: "sft_test_results/RC/sft_*_test_results.xml"]]])
+                    step ([$class: 'XUnitBuilder',
+                       thresholds: [
+                            [$class: 'FailedThreshold', unstableThreshold: '0']],
+                            tools: [[$class: 'JUnitType', pattern: "sft_test_results/XRC/sft_*_test_results.xml"]]])
+                    step ([$class: 'XUnitBuilder',
+                       thresholds: [
+                            [$class: 'FailedThreshold', unstableThreshold: '0']],
+                            tools: [[$class: 'JUnitType', pattern: "mpi.xml"]]])
+                }
+            }
+        }
+        stage("Install Libfabric Build") {
+            when {
+                allOf {
+                    expression { currentBuild.result == 'SUCCESS' } ;
+                    anyOf {
+                        expression { env.BRANCH_NAME == 'master' } ;
+                        buildingTag() ;
+                    }
+                }
+            }
+            environment {
+                LIBFABRIC_INSTALL_PATH="${LIBFABRIC_BUILD_PATH + '/' + GIT_SHORT_COMMIT}"
+            }
+            steps {
+                sh './autogen.sh'
+                sh "./configure --prefix=$LIBFABRIC_INSTALL_PATH"
+                sh "make -j 12"
+                sh "make install"
+            }
+        }
+        stage("Deploy") {
+            when {
+                allOf {
+                    expression { currentBuild.result == 'SUCCESS' } ;
+                    anyOf {
+                        expression { env.BRANCH_NAME == 'master' } ;
+                        buildingTag()
+                    }
+                }
+            }
+            options {
+                timeout (time: 5, unit: 'MINUTES')
+            }
+            environment {
+                TAG_DIRECTORY = "${LIBFABRIC_BUILD_PATH + '/tags'}"
+            }
+            failFast true
+            parallel {
+                stage("Create nightly link") {
+                    when {
+                        expression { env.BRANCH_NAME == 'master' }
+                    }
+                    steps {
+                        dir (env.TAG_DIRECTORY) {
+                            sh "rm -f nightly || true"
+                            sh "ln -s ../$GIT_SHORT_COMMIT nightly"
+                        }
+                    }
+                }
+                stage("Create tagged link") {
+                    when {
+                        buildingTag()
+                    }
+                    steps {
+                        dir (env.TAG_DIRECTORY) {
+                            sh "rm -f $BRANCH_NAME || true"
+                            sh "ln -s ../$GIT_SHORT_COMMIT $BRANCH_NAME"
+                        }
+                    }
+                }
+                stage("Create RPMs") {
+                    steps {
+                        sh 'make dist-bzip2'
+                        sh '$WORKSPACE/contrib/buildrpm/buildrpmLibfabric.sh -i verbs -i sockets -osmv $(ls libfabric-*.tar.bz2)'
+                    }
+                    post {
+                        success {
+                            stash name: 'rpms', includes: 'rpmbuild/RPMS/**/*'
+                            stash name: 'sources',  includes: 'rpmbuild/SOURCES/*'
+                        }
+                    }
+                }
+            }
+        }
+        stage('Publish') {
+            when {
+                allOf {
+                    expression { currentBuild.result == 'SUCCESS' } ;
+                    expression { return isRelease("${env.GIT_BRANCH}") }
+                }
+            }
+            agent {
+                node {
+                    label 'utility_pod'
+                }
+            }
+            steps {
+                container('utility') {
+                    sh 'tar -cvzf /tmp/libfabric-source.tar.gz --exclude "*.log" .'
+
+                    // publishes the source RPM to DST's Artifactory instance
+                    transfer(artifactName: '/tmp/libfabric-source.tar.gz')
+
+                    // Sends event to message bus to notify other builds
+                    publishEvents(["os-networking-libfabric-verbs-publish"])
+                }
+            }
+        }
+    }
+    post {
+        success {
+            script {
+                try {
+                    unstash 'rpms'
+                    unstash 'sources'
+                    archiveArtifacts 'rpmbuild/SOURCES/*'
+                    archiveArtifacts 'rpmbuild/RPMS/**/*'
+                }
+                catch (Exception e) {
+                    echo 'No rpms to archive'
+                }
+            }
+        }
+        changed {
+            script {
+                // send email when the state of the pipeline changes
+                // only sends email to @cray.com
+
+                def emailBody = createEmail(build : currentBuild)
+                def providers = []
+                def defaultMailer = ''
+
+                if (env.BRANCH_NAME == 'master') {
+                    defaultMailer = mailingList()
+                } else {
+                    providers.add ( [$class: 'CulpritsRecipientProvider'] )
+                    providers.add ( [$class: 'RequesterRecipientProvider'] )
+                    providers.add ( [$class: 'DevelopersRecipientProvider'] )
+                }
+                emailext subject: '$DEFAULT_SUBJECT',
+                    body: emailBody,
+                    mimeType: 'text/html',
+                    recipientProviders: providers,
+                    replyTo: '$DEFAULT_REPLYTO',
+                    to: defaultMailer
+             }
+        }
+    }
+    environment {
+        ROOT_BUILD_PATH = "/scratch/jenkins/builds"
+        FABTEST_PATH = "${WORKSPACE + '/installs/fabtests'}"
+        LIBFABRIC_BUILD_PATH = "${ROOT_BUILD_PATH + '/libfabric'}"
+        OMB_BUILD_PATH = "${ROOT_BUILD_PATH + '/osu-micro-benchmarks/5.4.2/libexec/osu-micro-benchmarks/mpi'}"
+        MPICH_PATH = "${ROOT_BUILD_PATH + '/mpich/3.3b3'}"
+        SFT_INSTALL_PATH = "${ROOT_BUILD_PATH + '/libfabric-sft/stable'}"
+        BATS_INSTALL_PATH = "${ROOT_BUILD_PATH + '/bats/stable/bin'}"
+    }
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/mpi.bats b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/mpi.bats
new file mode 100644
index 000000000..48c96e143
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/mpi.bats
@@ -0,0 +1,401 @@
+#!/usr/bin/env bats
+
+load test_helper
+
+# RC
+@test "osu_latency 2 ranks, 1 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/pt2pt/osu_latency
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_bw 2 ranks, 1 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/pt2pt/osu_bw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_mbw_mr 8 ranks, 4 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 8 4) timeout 300 $OMB_BUILD_PATH/pt2pt/osu_mbw_mr
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_get_latency 2 ranks, 1 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_get_latency
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_get_bw 2 ranks, 1 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_get_bw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_put_latency 2 ranks, 1 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_put_latency
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_put_bw 2 ranks, 1 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_put_bw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_put_bibw 2 ranks, 1 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_put_bibw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_allreduce 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_allreduce
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_allgather 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_allgather
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_allgatherv 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_allgatherv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_alltoall 20 ranks, 5 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_alltoall
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_alltoallv 20 ranks, 5 ranks per node using RC verbs" {
+    skip "fails consistently at 128k message size"
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_alltoallv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_barrier 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_barrier
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_bcast 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_bcast
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_gather 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_gather
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_gatherv 40 ranks, 10 ranks per node using RC verbs" {
+    skip "fails intermittently"
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_gatherv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_iallgather 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_iallgather
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_iallgatherv 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_iallgatherv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ialltoall 20 ranks, 5 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_ialltoall
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ialltoallv 20 ranks, 5 ranks per node using RC verbs" {
+    skip "fails consistently at 128k message size"
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_ialltoallv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ialltoallw 20 ranks, 5 ranks per node using RC verbs" {
+    skip "fails consistently at 128k message size"
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_ialltoallw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ibarrier 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_ibarrier
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ibcast 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_ibcast
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_igather 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_igather
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_igatherv 40 ranks, 10 ranks per node using RC verbs" {
+    skip "fails intermittently"
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_igatherv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_iscatter 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_iscatter
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_iscatterv 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_iscatterv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_reduce 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_reduce
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_reduce_scatter 40 ranks, 10 ranks per node using RC verbs" {
+    skip "fails consistently at 512K message size"
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_reduce_scatter
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_scatter 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_scatter
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_scatterv 40 ranks, 10 ranks per node using RC verbs" {
+    run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_scatterv
+    [ "$status" -eq 0 ]
+}
+
+# XRC
+@test "osu_latency 2 ranks, 1 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/pt2pt/osu_latency
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_bw 2 ranks, 1 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/pt2pt/osu_bw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_mbw_mr 8 ranks, 4 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 8 4) timeout 300 $OMB_BUILD_PATH/pt2pt/osu_mbw_mr
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_get_latency 2 ranks, 1 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_get_latency
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_get_bw 2 ranks, 1 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_get_bw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_put_latency 2 ranks, 1 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_put_latency
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_put_bw 2 ranks, 1 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_put_bw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_put_bibw 2 ranks, 1 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 2 1) timeout 300 $OMB_BUILD_PATH/one-sided/osu_put_bibw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_allreduce 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_allreduce
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_allgather 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_allgather
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_allgatherv 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_allgatherv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_alltoall 20 ranks, 5 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_alltoall
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_alltoallv 20 ranks, 5 ranks per node using XRC verbs" {
+    skip "fails consistently at 128k message size"
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_alltoallv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_barrier 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_barrier
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_bcast 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_bcast
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_gather 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_gather
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_gatherv 40 ranks, 10 ranks per node using XRC verbs" {
+    skip "fails intermittently"
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_gatherv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_iallgather 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_iallgather
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_iallgatherv 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_iallgatherv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ialltoall 20 ranks, 5 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_ialltoall
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ialltoallv 20 ranks, 5 ranks per node using XRC verbs" {
+    skip "fails consistently at 128k message size"
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_ialltoallv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ialltoallw 20 ranks, 5 ranks per node using XRC verbs" {
+    skip "fails consistently at 128k message size"
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 20 5) timeout 300 $OMB_BUILD_PATH/collective/osu_ialltoallw
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ibarrier 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_ibarrier
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_ibcast 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_ibcast
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_igather 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_igather
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_igatherv 40 ranks, 10 ranks per node using XRC verbs" {
+    skip "fails intermittently"
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_igatherv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_iscatter 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_iscatter
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_iscatterv 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_iscatterv
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_reduce 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_reduce
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_reduce_scatter 40 ranks, 10 ranks per node using XRC verbs" {
+    skip "fails consistently at 512K message size"
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_reduce_scatter
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_scatter 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_scatter
+    [ "$status" -eq 0 ]
+}
+
+@test "osu_scatterv 40 ranks, 10 ranks per node using XRC verbs" {
+    FI_OFI_RXM_USE_SRX=1 FI_VERBS_PREFER_XRC=1 run $CONTRIB_BIN/logwrap -w ${BATS_TEST_LOGFILE} -- \
+        $(batch_launcher 40 10) timeout 300 $OMB_BUILD_PATH/collective/osu_scatterv
+    [ "$status" -eq 0 ]
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/smoketests.bats b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/smoketests.bats
new file mode 100644
index 000000000..40ca2a65c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/smoketests.bats
@@ -0,0 +1,27 @@
+#!/usr/bin/env bats
+
+load test_helper
+
+@test "fi_info" {
+    run ${CONTRIB_BIN}/logwrap -w ${BATS_TEST_LOGFILE} -- $(batch_launcher 1 1) ${LIBFABRIC_INSTALL_PATH}/bin/fi_info -p 'verbs;ofi_rxm'
+    [ $(grep 'provider: verbs;ofi_rxm' ${BATS_TEST_LOGFILE} | uniq | wc -l) -gt 0 ]
+    [ "$status" -eq 0 ]
+}
+
+@test "fi_info_xrc" {
+    FI_OFI_RXM_USE_SRX=1 run ${CONTRIB_BIN}/logwrap -w ${BATS_TEST_LOGFILE} -- $(batch_launcher 1 1) ${LIBFABRIC_INSTALL_PATH}/bin/fi_info -p 'verbs;ofi_rxm'
+    [ $(grep 'domain' ${BATS_TEST_LOGFILE} | grep '\-xrc' | wc -l) -gt 0 ]
+    [ "$status" -eq 0 ]
+}
+
+@test "prefer_rc" {
+    FI_OFI_RXM_USE_SRX=1 run ${CONTRIB_BIN}/logwrap -w ${BATS_TEST_LOGFILE} -- $(batch_launcher 1 1) ${LIBFABRIC_INSTALL_PATH}/bin/fi_info -p 'verbs;ofi_rxm'
+    [ $(grep 'domain' ${BATS_TEST_LOGFILE} | head -n1 | grep '\-xrc' | wc -l) -eq 0 ]
+    [ "$status" -eq 0 ]
+}
+
+@test "prefer_xrc" {
+    FI_VERBS_PREFER_XRC=1 FI_OFI_RXM_USE_SRX=1 run ${CONTRIB_BIN}/logwrap -w ${BATS_TEST_LOGFILE} -- $(batch_launcher 1 1) ${LIBFABRIC_INSTALL_PATH}/bin/fi_info -p 'verbs;ofi_rxm'
+    [ $(grep 'domain' ${BATS_TEST_LOGFILE} | head -n1 | grep '\-xrc' | wc -l) -gt 0 ]
+    [ "$status" -eq 0 ]
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/test_helper.bash b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/test_helper.bash
new file mode 100644
index 000000000..dd104dfb6
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bats/test_helper.bash
@@ -0,0 +1,44 @@
+#!/bin/bash
+
+SOURCE="${BASH_SOURCE[0]}"
+while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
+  DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null && pwd )"
+  SOURCE="$(readlink "$SOURCE")"
+  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
+done
+DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null && pwd )"
+
+if [[ -z "$BATS_LOG_DIRECTORY" ]] ; then
+    export BATS_LOG_DIRECTORY=$PWD
+fi
+
+if [[ ! -d $BATS_LOG_DIRECTORY ]] ; then
+    mkdir -p $BATS_LOG_DIRECTORY
+fi
+
+export CONTRIB_BIN=$DIR/../bin
+
+_cancel() {
+    echo caught sigint
+    kill -s SIGKILL
+}
+
+setup() {
+    export BATS_TEST_LOGFILE="${BATS_LOG_DIRECTORY}/${BATS_TEST_NAME}.log"
+}
+
+teardown() {
+    cat ${BATS_TEST_LOGFILE} || true
+}
+
+function batch_launcher {
+    if [[ $# -lt 2 ]] ; then
+        error "not enough arguments"
+    fi
+    NUM_RANKS=$1
+    NUM_RANKS_PER_NODE=$2
+    echo "srun -n ${NUM_RANKS} --ntasks-per-node ${NUM_RANKS_PER_NODE}"
+}
+
+# necessary to avoid deadlocks during termination/interrupt
+trap _cancel SIGINT
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/common.sh b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/common.sh
new file mode 100644
index 000000000..20f57783e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/common.sh
@@ -0,0 +1,8 @@
+#!/bin/bash
+
+# DIR is expected to be defined by files that include these common variables
+BUILD_VERSION=$(cat $DIR/../share/version)
+ROOT_INSTALL_PATH=$LIBFABRIC_BUILD_PATH/virtualenv/
+PREREQ_INSTALL_PATH=$ROOT_INSTALL_PATH/prerequisites
+VIRTUALENV_INSTALL_PATH=$ROOT_INSTALL_PATH/venv-${BUILD_VERSION}
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/fabtest_wrapper.sh b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/fabtest_wrapper.sh
new file mode 100755
index 000000000..078300bc7
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/fabtest_wrapper.sh
@@ -0,0 +1,27 @@
+#!/bin/bash
+
+export FABTESTS_PATH=/scratch/jenkins/builds/fabtests/stable
+export PATH=${FABTESTS_PATH}/bin:$PATH
+
+if [[ -z ${FABTEST_PROVIDER} ]] ; then
+    FABTEST_PROVIDER='verbs;ofi_rxm'
+fi
+
+if [[ -z ${SLURMD_NODENAME} ]] ; then
+    echo SLURM is the only supported WLM at this point for testing
+    exit 1
+fi
+
+SERVER=$(scontrol show hostname ${SLURM_NODELIST} | head -n1)
+CLIENT=$(scontrol show hostname ${SLURM_NODELIST} | tail -n1)
+
+SERVER_ADDR=$(getent hosts ${SERVER} | awk '{print $1}')
+CLIENT_ADDR=$(getent hosts ${CLIENT} | awk '{print $1}')
+
+if [[ "${SLURMD_NODENAME}" == "$SERVER" ]] ; then
+    runfabtests.sh \
+        $@ \
+        "${FABTEST_PROVIDER}" \
+        ${SERVER_ADDR} \
+        ${CLIENT_ADDR}
+fi
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/logwrap b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/logwrap
new file mode 100755
index 000000000..6d6b37c1a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/logwrap
@@ -0,0 +1,39 @@
+#!/bin/bash
+
+SOURCE="${BASH_SOURCE[0]}"
+while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
+  DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
+  SOURCE="$(readlink "$SOURCE")"
+  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
+done
+DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
+OUTFILE="log"
+OPTS=`getopt -o hw: --long help,outfile -n 'parse-options' -- "$@"`
+HELP=false
+
+if [ $? != 0 ] ; then echo "Failed parsing options." >&2 ; exit 1 ; fi
+
+eval set -- "$OPTS"
+
+while true; do
+  case "$1" in
+    -h | --help ) HELP=true; shift ;;
+    -w | --outfile ) OUTFILE="$2" ; shift ; shift ;;
+    * ) break ;;
+  esac
+done
+
+shift
+
+if $HELP ; then
+    echo "Usage: logwrap [-hw] command"
+    exit
+fi
+
+if [[ $# -eq 0 ]] ; then
+    echo failed to provide script to wrap
+    exit 1
+fi
+
+$@ 2>&1 | tee $OUTFILE
+exit ${PIPESTATUS[0]}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/parse_logfiles.sh b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/parse_logfiles.sh
new file mode 100755
index 000000000..09059822e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/parse_logfiles.sh
@@ -0,0 +1,16 @@
+#!/bin/bash
+
+set -e
+
+SOURCE="${BASH_SOURCE[0]}"
+while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
+  DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null && pwd )"
+  SOURCE="$(readlink "$SOURCE")"
+  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
+done
+DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null && pwd )"
+
+source $DIR/common.sh
+
+source $VIRTUALENV_INSTALL_PATH/bin/activate
+python $DIR/../python/parse_results.py $@
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/run_libfabric_pipeline b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/run_libfabric_pipeline
new file mode 100755
index 000000000..6383aea9c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/run_libfabric_pipeline
@@ -0,0 +1,315 @@
+#!/bin/bash
+
+SOURCE="${BASH_SOURCE[0]}"
+while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
+  DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null && pwd )"
+  SOURCE="$(readlink "$SOURCE")"
+  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
+done
+DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null && pwd )"
+
+# Variables
+HELP=false
+VERBOSE=false
+DEBUG=false
+CLEAN=false
+WORKSPACE=$(pwd)
+SECTIONS='all'
+LIBFABRIC=""
+
+BUILD=true
+TEST=true
+UNITTEST=true
+SMOKETEST=true
+FABTEST=true
+SFT=true
+MPI=true
+
+function usage {
+    echo \
+"
+Usage: $(basename $SOURCE) [-dhv]
+"
+
+}
+
+function set_sections_to_run {
+    BUILD=false
+    TEST=false
+    UNITTEST=false
+    SMOKETEST=false
+    FABTEST=false
+    SFT=false
+    MPI=false
+
+    sections=$(echo $@ | tr ',' ' ')
+    for section in $sections ; do
+        section_name=$(echo $section | awk '{print toupper($0)}')
+        case $section_name in
+            'UNITTEST'|'SMOKETEST'|'FABTEST'|'SFT'|'MPI')
+                TEST=true
+                eval ${section_name}=true
+                ;;
+            'ALL')
+                BUILD=true
+                TEST=true
+                UNITTEST=true
+                SMOKETEST=true
+                FABTEST=true
+                SFT=true
+                MPI=true
+                ;;
+            'TEST')
+                TEST=true
+                UNITTEST=true
+                SMOKETEST=true
+                FABTEST=true
+                SFT=true
+                MPI=true
+                ;;
+             'BUILD')
+                BUILD=true
+                ;;
+            *)
+                ;;
+        esac
+    done
+
+    for each in BUILD TEST UNITTEST SMOKETEST SFT MPI ; do
+        if $DEBUG ; then echo ${each} = $(eval echo \$$each) ; fi
+    done
+}
+
+OPTS=`getopt -o hdvcs:w:l: --long help,debug,verbose,clean,sections,workspace,libfabric -n 'parse-options' -- "$@"`
+
+if [ $? != 0 ] ; then echo "Failed parsing options." >&2 ; usage ; exit 1 ; fi
+
+eval set -- "$OPTS"
+set -e
+
+while true; do
+  case "$1" in
+    -h | --help ) HELP=true ; shift ;;
+    -v | --verbose ) VERBOSE=true ; shift ;;
+    -d | --debug ) DEBUG=true ; shift ;;
+    -c | --clean ) CLEAN=true ; shift ;;
+    -s | --sections ) SECTIONS="$2" ; shift ; shift ;;
+    -w | --workspace ) WORKSPACE="$2" ; shift ; shift ;;
+    -l | --libfabric ) LIBFABRIC="$2" ; shift ; shift ;;
+    * ) break ;;
+  esac
+done
+
+shift
+
+if $HELP ; then
+    usage
+    exit
+fi
+
+function verbose {
+    if $VERBOSE ; then
+        echo $@
+    fi
+}
+
+function debug {
+    if $DEBUG ; then
+        echo $0
+    fi
+}
+
+set_sections_to_run "$SECTIONS"
+verbose "HELP:      $HELP"
+verbose "VERBOSE:   $VERBOSE"
+verbose "DEBUG:     $DEBUG"
+verbose "CLEAN:     $CLEAN"
+verbose "SECTIONS:  $SECTIONS"
+verbose "WORKSPACE: $WORKSPACE"
+
+for each in BUILD TEST UNITTEST SMOKETEST FABTEST MPI SFT ; do
+    verbose "$each: $(eval echo \$$each)"
+done
+
+function section_start {
+    echo \
+"
+##############################################################################
+Start of \"$1\"
+##############################################################################
+"
+}
+
+function section_end {
+    echo \
+"
+##############################################################################
+End of \"$1\"
+##############################################################################
+"
+}
+if $CLEAN ; then
+    if [[ -d $WORKSPACE ]] ; then
+        rm -rf $WORKSPACE
+    fi
+fi
+
+if [[ ! -d $WORKSPACE ]] ; then
+    mkdir -p $WORKSPACE
+fi
+
+SOURCE_DIR=$DIR/../../..
+pushd $SOURCE_DIR
+
+# Start Pipeline variables
+export GIT_SHORT_COMMIT="$GIT_COMMIT"
+export LIBFABRIC_INSTALL_PATH=""
+export ROOT_BUILD_PATH="/scratch/jenkins/builds"
+export FABTEST_PATH="${WORKSPACE}/fabtests"
+export LIBFABRIC_BUILD_PATH="${ROOT_BUILD_PATH}/libfabric"
+export OMB_BUILD_PATH="${ROOT_BUILD_PATH}/osu-micro-benchmarks/5.4.2/libexec/osu-micro-benchmarks/mpi"
+export MPICH_PATH="${ROOT_BUILD_PATH}/mpich/3.3b3"
+export SFT_INSTALL_PATH="${ROOT_BUILD_PATH}/libfabric-sft/stable"
+export BATS_INSTALL_PATH="${ROOT_BUILD_PATH}/bats/stable/bin"
+export BATS_LOG_DIRECTORY="$WORKSPACE/logs"
+# End pipeline variables
+
+# Start Prologue
+GIT_SHORT_COMMIT=$(git log -n 1 --pretty=format:'%h')
+
+contrib/cray/bin/verify_requirements.sh
+contrib/cray/bin/setup.sh
+# End Prologue
+
+if [[ -z $LIBFABRIC ]] ; then
+    LIBFABRIC_INSTALL_PATH="${WORKSPACE}/builds/libfabric/${GIT_SHORT_COMMIT}"
+else
+    LIBFABRIC_INSTALL_PATH="$LIBFABRIC"
+fi
+echo using installed libfabric @ ${LIBFABRIC_INSTALL_PATH}
+
+if $BUILD ; then
+section_start 'build'
+# Start Build
+./autogen.sh
+./configure --prefix=$LIBFABRIC_INSTALL_PATH
+make -j12
+make install
+# End Build
+section_end 'build'
+fi
+
+LF_LIBRARY=${LIBFABRIC_INSTALL_PATH}/lib/libfabric.so
+if [[ ! -f ${LF_LIBRARY} ]] ; then
+    echo could not find libfabric library
+    echo expected file: ${LF_LIBRARY}
+    exit
+fi
+
+if $TEST ; then
+section_start 'test'
+# Start Test Phase
+export LD_LIBRARY_PATH=$LIBFABRIC_INSTALL_PATH/lib:$LD_LIBRARY_PATH
+export MPIR_CVAR_OFI_USE_PROVIDER='verbs;ofi_rxm'
+
+if $UNITTEST ; then
+section_start 'unit tests'
+## Start Unit Tests
+sleep 1
+## End Unit Tests
+section_end 'unit tests'
+fi
+
+if $SMOKETEST ; then
+section_start 'smoke tests'
+## Start Smoke Tests
+$BATS_INSTALL_PATH/bats $@ -t contrib/cray/bats/smoketests.bats | tee smoketests.tap
+## End Smoke Tests
+section_end 'smoke tests'
+fi
+
+if $FABTEST ; then
+section_start 'fabtests'
+## Start Fabtests
+if [[ ! -f $FABTEST_PATH/compile-target || "$(cat $FABTEST_PATH/compile-target)" != "$LIBFABRIC_INSTALL_PATH" ]] ; then
+    pushd $SOURCE_DIR/fabtests
+    ./autogen.sh
+    ./configure --with-libfabric=$LIBFABRIC_INSTALL_PATH --prefix=$FABTEST_PATH
+    make -j12
+    make -j12 install
+    echo $LIBFABRIC_INSTALL_PATH > $FABTEST_PATH/compile-target
+    popd
+fi
+
+if [[ ! -f $FABTEST_PATH/bin/runfabtests.sh ]] ; then
+    echo run the build step to install a version of fabtests for the current build
+else
+    srun -n 2 --ntasks-per-node=1 contrib/cray/bin/fabtest_wrapper.sh -p ${FABTEST_PATH}/bin -v -T 60 | tee fabtests.log
+fi
+## End Fabtests
+section_end 'fabtests'
+fi
+
+if $SFT ; then
+section_start 'sft'
+## Start SFT
+export SFT_BIN="${SFT_INSTALL_PATH}/bin"
+export SFT_ADD_ARGS="--additional-args ' '"
+export SFT_MAX_JOB_TIME='3'
+export SFT_NUM_JOBS='4'
+export SFT_PROVIDER='verbs;ofi_rxm'
+export SFT_BASELINE_DIR="contrib/cray"
+export SFT_BASELINE_RESULTS_FILE='sft_test_results_baseline.txt'
+export SFT_PREVIOUS_BASELINE_RESULTS='sft_test_results_baseline.txt'
+export SFT_TEST_CMDS='sft_test_commands'
+export SFT_TEST_RESULTS='sft_test_results.xml'
+export SFT_TEST_RESULTS_EXPECTED='expected_'
+export SFT_TEST_RESULTS_PREFIX='BUILD_'
+export SFT_TEST_RESULTS_CI='sft_ci_results.yaml'
+export SFT_TEST_RESULTS_BASE_DIR="${ROOT_BUILD_PATH}/sft_test_results/"
+export SFT_TEST_RESULTS_DIR=""
+
+export SFT_TEST_RESULTS_SUBDIR="${SFT_TEST_RESULTS_PREFIX}_${GIT_SHORT_COMMIT}_DATE_$(date +%Y_%m_%d_%H_%M_%S)"
+export SFT_TEST_RESULTS_DIR="${SFT_TEST_RESULTS_BASE_DIR}${SFT_TEST_RESULTS_SUBDIR}"
+
+rm -f ${SFT_BIN}/core*
+rm -rf ${SFT_TEST_RESULTS_DIR}
+mkdir -p ${SFT_TEST_RESULTS_DIR}
+
+pushd ${SFT_BIN}
+timeout 900 ./ci-all.sh \
+    --provider 'verbs;ofi_rxm' \
+    -L ${SFT_TEST_RESULTS_DIR} \
+    --num-jobs ${SFT_NUM_JOBS} \
+    --max-job-time ${SFT_MAX_JOB_TIME} \
+    --output-cmds ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_CMDS} \
+    --results-file ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS_CI}
+popd
+
+cp  ./${SFT_BASELINE_DIR}/${SFT_BASELINE_RESULTS_FILE} ${SFT_TEST_RESULTS_DIR}/ \
+    ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE}
+${SFT_BIN}/sft_parse_test_results.pm \
+    -b ${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE} \
+    -d ${SFT_TEST_RESULTS_DIR} \
+    -o ${SFT_TEST_RESULTS} \
+    -r ${SFT_BASELINE_RESULTS_FILE}
+gzip -r ${SFT_TEST_RESULTS_DIR}
+gunzip ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS}
+gunzip ${SFT_TEST_RESULTS_DIR}/${SFT_BASELINE_RESULTS_FILE}
+gunzip ${SFT_TEST_RESULTS_DIR}/${SFT_TEST_RESULTS_EXPECTED}${SFT_BASELINE_RESULTS_FILE}
+cp -r ${SFT_TEST_RESULTS_DIR} .
+
+rm -rf ${SFT_TEST_RESULTS_DIR} || true
+## End SFT
+section_end 'sft'
+fi
+
+if $MPI ; then
+section_start 'mpi'
+## Start MPI Tests
+$BATS_INSTALL_PATH/bats -t contrib/cray/bats/mpi.bats | tee mpi.tap
+## End MPI Tests
+section_end 'mpi'
+fi
+
+fi
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/setup.sh b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/setup.sh
new file mode 100755
index 000000000..e252a0caa
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/setup.sh
@@ -0,0 +1,43 @@
+#!/bin/bash
+
+set -e
+
+SOURCE="${BASH_SOURCE[0]}"
+while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
+  DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null && pwd )"
+  SOURCE="$(readlink "$SOURCE")"
+  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
+done
+DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null && pwd )"
+
+source $DIR/common.sh
+
+if [[ -z "$(which pip)" ]] ; then
+    echo failed to find pip
+    false
+fi
+
+if [[ -z "$(which python)" ]] ; then
+    echo failed to find python
+    false
+fi
+
+function cleanup {
+    echo failed to setup environment
+}
+
+trap cleanup ERR
+
+if [[ -z "$(which virtualenv)" ]] ; then
+    pip --isolated install --root $PREREQ_INSTALL_PATH virtualenv
+    export PYTHONPATH=$PREREQ_INSTALL_PATH/usr/lib/python2.7/site-packages:$PYTHONPATH
+    export PATH=$PREREQ_INSTALL_PATH/bin:$PATH
+fi
+
+if [[ ! -f $VIRTUALENV_INSTALL_PATH/bin/activate ]] ; then
+    virtualenv $VIRTUALENV_INSTALL_PATH
+fi
+
+source $VIRTUALENV_INSTALL_PATH/bin/activate
+pip install -r $DIR/../share/requirements.txt
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/verify_requirements.sh b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/verify_requirements.sh
new file mode 100755
index 000000000..c44e1339a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/bin/verify_requirements.sh
@@ -0,0 +1,59 @@
+#!/bin/bash
+
+set -e
+
+function check_executable {
+    if [[ ! -x $1 ]] ; then
+        echo could not find executable: $1
+        exit 1
+    fi
+}
+
+function check_directory {
+    if [[ ! -d $1 ]] ; then
+        echo could not find directory: $1
+        exit 1
+    fi
+}
+
+function check_environment {
+    var=$1
+    val=$(eval "echo \$$var")
+    if [[ -z "$val" ]] ; then
+        echo could not find environment variable: $var
+        exit 1
+    fi
+}
+
+function find_executable {
+    if [[ -z "$(which $1)" ]] ; then
+        echo could not find executable: $1
+        exit 1
+    fi
+}
+
+# check prerequisite environment variables
+check_environment ROOT_BUILD_PATH
+check_environment FABTEST_PATH
+check_environment LIBFABRIC_BUILD_PATH
+check_environment OMB_BUILD_PATH
+check_environment MPICH_PATH
+
+# check directories
+check_directory $ROOT_BUILD_PATH
+check_directory $OMB_BUILD_PATH
+check_directory $MPICH_PATH
+check_directory $SFT_INSTALL_PATH
+check_directory $BATS_INSTALL_PATH
+
+##### check prerequisite installed software packages
+# SLURM     https://slurm.schedmd.com/
+find_executable srun
+# OMB       http://mvapich.cse.ohio-state.edu/benchmarks/
+check_executable $OMB_BUILD_PATH/pt2pt/osu_bw
+# Cray Proprietary
+check_executable $SFT_INSTALL_PATH/bin/ci-all.sh
+# BATS      https://github.com/bats-core/bats-core
+check_executable $BATS_INSTALL_PATH/bats
+
+exit 0
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/python/parse_results.py b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/python/parse_results.py
new file mode 100755
index 000000000..f83a81208
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/python/parse_results.py
@@ -0,0 +1,200 @@
+#!/usr/bin/env python
+# encoding: utf-8
+
+"""
+parse_results -- script for parsing results from known
+    logfile types to junit xml format
+
+@author:     jswaro
+@copyright:  Copyright 2018 Cray Inc. All Rights Reserved.
+@deffield    updated: 2018-09-26
+"""
+
+from junit_xml import TestSuite, TestCase
+import sys
+import os
+from functools import wraps
+from argparse import ArgumentParser, RawDescriptionHelpFormatter
+
+__all__ = []
+__version__ = 1.0
+__date__ = '2018-09-26'
+__updated__ = '2018-09-26'
+
+VERSION = '1.0.0'
+DEBUG = False
+
+known_formats = dict()
+
+def generate_generic_test_case(name, classname, time, message, result):
+    default_pass_message = 'Test passed, check build log for additional details'
+    default_skip_message = 'Test skipped, check build log for additional details'
+    tc = TestCase(name, classname, time,
+                  default_pass_message if result == 'pass' else '')
+    if result == 'fail':
+        tc.add_failure_info(message=message)
+    if result == 'skip':
+        tc.add_skipped_info(message=default_skip_message)
+
+    return tc
+
+def tap_delimiter(line):
+    return line.startswith('ok') or line.startswith('not ok')
+
+def tap_parser(log, classname_prefix):
+    name = ""
+    testname = ""
+    classname = ""
+    result = ""
+    time = 0.0
+    message = ""
+    for line in log:
+        data = line.strip().split()
+        if tap_delimiter(line):
+            result = 'pass'
+            if data[0] == 'ok' and '# skip' in line:
+                result = 'skip'
+            elif data[0] == 'not':
+                result = 'fail'
+            name_index = 3 if result == 'fail' else 2
+            testname = " ".join(data[name_index:]) if result != 'skip' else " ".join(data[name_index:data.index('#')])
+            classname = classname_prefix
+        elif line.startswith('#'):
+            message += " ".join(data) + '\n'
+
+    tc = generate_generic_test_case(testname, classname, 1.00, message, result)
+    return tc
+
+def fabtests_test_delimiter(line):
+    return line.startswith('- name: ')
+
+def fabtests_testcase_parser(log, classname_prefix):
+    name = ""
+    testname = ""
+    classname = ""
+    result = ""
+    time = ""
+    message = ""
+    for line in log:
+        data = line.strip().split()
+        if fabtests_test_delimiter(line):
+            name = " ".join(data[2:])
+            testname = data[2]
+            classname = "{0}.{1}".format(classname_prefix, testname)
+        elif line.startswith('  result:'):
+            if data[1] == 'Pass':
+                result = 'pass'
+            elif data[1] == 'Notrun':
+                result = 'skip'
+            else:
+                result = 'fail'
+        elif line.startswith('  time:'):
+            time = float(data[1])
+        else: #recording stdout/stderr
+            message += " ".join(data) + '\n'
+
+    tc = generate_generic_test_case(name, classname, time, message, result)
+    return tc
+
+def parse(infile, outfile, format_type, classname, suitename):
+    testcases = list()
+    testcase_logs = list()
+    current = None
+    test_block_delimiter = known_formats[format_type]['tb_delimiter']
+
+    # separate log file into test blocks by test block delimiter
+    for line in infile:
+        if test_block_delimiter(line):
+            if current: # non-empty list
+                testcase_logs.append(current)
+            current = list()
+        if current is not None:
+            current.append(line)
+
+    # add last record if present
+    if current not in testcase_logs:
+        testcase_logs.append(current)
+
+    # create test cases from test blocks
+    for entry in testcase_logs:
+        testcases.append(known_formats[format_type]['test_parser'](entry, classname))
+
+    # generate test suite result using provided test cases
+    test_suite = TestSuite(suitename, testcases)
+
+    # get rid of unnecessary 'disabled' strings in formatted xml string
+    s = TestSuite.to_xml_string([test_suite])
+    s = s.replace(' disabled=\"0\"', '')
+
+    # write xml to outfile
+    outfile.write(s)
+
+def register_parser(label, func):
+    global known_formats
+    known_formats[label] = func
+
+
+def main(argv=None):  #IGNORE:C0111
+    if argv is None:
+        argv = sys.argv
+    else:
+        sys.argv.extend(argv)
+    register_parser('fabtests',
+                    {'tb_delimiter': fabtests_test_delimiter,
+                     'test_parser': fabtests_testcase_parser})
+    register_parser('tap',
+                    {'tb_delimiter': tap_delimiter,
+                     'test_parser': tap_parser})
+
+    program_name = os.path.basename(sys.argv[0])
+    program_version = "v%s" % (VERSION)
+    program_build_date = str(__updated__)
+    program_version_message = '%%(prog)s %s (%s)' % (program_version, program_build_date)
+    program_shortdesc = __import__('__main__').__doc__.split("\n")[1]
+    program_license = '''%s
+
+  Copyright 2018 Cray Inc. All rights reserved.
+
+  Distributed on an "AS IS" basis without warranties
+  or conditions of any kind, either express or implied.
+
+USAGE
+''' % program_shortdesc
+    # Setup argument parser
+    parser = ArgumentParser(description=program_license,
+                            formatter_class=RawDescriptionHelpFormatter)
+
+    parser.add_argument("-V", "--version", action="version", version=program_version_message)
+    parser.add_argument("-r", "--infile", action="store", default=None, dest='infile',
+                        help="file to read in, defaults to stdin")
+    parser.add_argument("-w", "--outfile", action="store", default=None, dest='outfile',
+                        help="junit xml file to write out, defaults to stdout")
+    parser.add_argument("format",
+                        help='test format to expect (available: {0})'.format(", ".join(known_formats.keys())))
+    parser.add_argument("classname",
+                        help='class name to associate with generated junit xml tests')
+    parser.add_argument("suitename",
+                        help='suite name to associate with generated junit xml tests')
+    # Process arguments
+    args = parser.parse_args()
+
+    infile = sys.stdin
+    outfile = sys.stdout
+    if args.infile is not None:
+        infile = open(args.infile, 'r')
+    if args.outfile is not None:
+        outfile = open(args.outfile, 'w')
+
+    parse(infile, outfile, args.format, args.classname, args.suitename)
+
+    if args.infile is not None:
+        infile.close()
+    if args.outfile is not None:
+        outfile.close()
+
+if __name__ == "__main__":
+    if DEBUG:
+        sys.argv.append("-h")
+        sys.argv.append("-v")
+
+    sys.exit(main())
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/sft_test_results_baseline.txt b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/sft_test_results_baseline.txt
new file mode 100644
index 000000000..8693e9463
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/sft_test_results_baseline.txt
@@ -0,0 +1,543 @@
+# Expected test values can be: 'PASS', 'FAIL', SKIP' or 'INTERMITTENT'
+#    PASS: means that the test should pass
+#          if the test result is PASS, then Jenkins will report this test as PASSED
+#          if the test result is FAIL, then Jenkins will report this test as FAILED
+#    FAIL: means that the test currently fails, probably due to incorrect behavior of a feature
+#          if the test result is PASS, then Jenkins will report this test as PASSED
+#          if the test result is FAIL, then Jenkins will report this test as SKIPPED
+#    SKIP: means that the test should be skipped, due to an unimplemented feature
+#          if the test result is PASS, then Jenkins will report this test as PASSED
+#          if the test result is FAIL, then Jenkins will report this test as SKIPPED
+#    INTERMITTENT: means that the test should pass but it fails infrequently
+#          if the test result is PASS, then Jenkins will report this test as PASSED
+#          if the test result is FAIL, then Jenkins will report this test as SKIPPED
+
+# The Test Case section contains the list of test cases and their expected results.
+
+# Test Case Results
+AMO_All-to-All_FI_ATOMIC_MIN=PASS
+AMO_All-to-All_FI_ATOMIC_MAX=PASS
+AMO_All-to-All_FI_ATOMIC_SUM=PASS
+AMO_All-to-All_FI_ATOMIC_PROD=PASS
+AMO_All-to-All_FI_ATOMIC_LOR=PASS
+AMO_All-to-All_FI_ATOMIC_LAND=PASS
+AMO_All-to-All_FI_ATOMIC_BOR=PASS
+AMO_All-to-All_FI_ATOMIC_BAND=PASS
+AMO_All-to-All_FI_ATOMIC_LXOR=PASS
+AMO_All-to-All_FI_ATOMIC_BXOR=PASS
+AMO_All-to-All_FI_ATOMIC_ATOMIC_WRITE=PASS
+AMO_All-to-All_FI_ATOMIC_ATOMIC_READ=PASS
+AMO_All-to-All_FI_ATOMICV_MIN=PASS
+AMO_All-to-All_FI_ATOMICV_MAX=PASS
+AMO_All-to-All_FI_ATOMICV_SUM=PASS
+AMO_All-to-All_FI_ATOMICV_PROD=PASS
+AMO_All-to-All_FI_ATOMICV_LOR=PASS
+AMO_All-to-All_FI_ATOMICV_LAND=PASS
+AMO_All-to-All_FI_ATOMICV_BOR=PASS
+AMO_All-to-All_FI_ATOMICV_BAND=PASS
+AMO_All-to-All_FI_ATOMICV_LXOR=PASS
+AMO_All-to-All_FI_ATOMICV_BXOR=PASS
+AMO_All-to-All_FI_ATOMICV_ATOMIC_WRITE=PASS
+AMO_All-to-All_FI_ATOMICV_ATOMIC_READ=PASS
+AMO_All-to-All_FI_ATOMICMSG_MIN=PASS
+AMO_All-to-All_FI_ATOMICMSG_MAX=PASS
+AMO_All-to-All_FI_ATOMICMSG_SUM=PASS
+AMO_All-to-All_FI_ATOMICMSG_PROD=PASS
+AMO_All-to-All_FI_ATOMICMSG_LOR=PASS
+AMO_All-to-All_FI_ATOMICMSG_LAND=PASS
+AMO_All-to-All_FI_ATOMICMSG_BOR=PASS
+AMO_All-to-All_FI_ATOMICMSG_BAND=PASS
+AMO_All-to-All_FI_ATOMICMSG_LXOR=PASS
+AMO_All-to-All_FI_ATOMICMSG_BXOR=PASS
+AMO_All-to-All_FI_ATOMICMSG_ATOMIC_WRITE=PASS
+AMO_All-to-All_FI_ATOMICMSG_ATOMIC_READ=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_MIN=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_MAX=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_SUM=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_PROD=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_LOR=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_LAND=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_BOR=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_BAND=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_LXOR=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_BXOR=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_ATOMIC_WRITE=PASS
+AMO_All-to-All_FI_INJECT_ATOMIC_ATOMIC_READ=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_MIN=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_MAX=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_SUM=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_PROD=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_LOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_LAND=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_BOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_BAND=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_LXOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_BXOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_ATOMIC_WRITE=PASS
+AMO_All-to-All_FI_FETCH_ATOMIC_ATOMIC_READ=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_MIN=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_MAX=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_SUM=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_PROD=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_LOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_LAND=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_BOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_BAND=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_LXOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_BXOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_ATOMIC_WRITE=PASS
+AMO_All-to-All_FI_FETCH_ATOMICV_ATOMIC_READ=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_MIN=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_MAX=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_SUM=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_PROD=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_LOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_LAND=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_BOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_BAND=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_LXOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_BXOR=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_ATOMIC_WRITE=PASS
+AMO_All-to-All_FI_FETCH_ATOMICMSG_ATOMIC_READ=PASS
+AMO_All-to-All_FI_COMPARE_ATOMIC_CSWAP=PASS
+AMO_All-to-All_FI_COMPARE_ATOMIC_CSWAP_NE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMIC_CSWAP_LE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMIC_CSWAP_LT=PASS
+AMO_All-to-All_FI_COMPARE_ATOMIC_CSWAP_GE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMIC_CSWAP_GT=PASS
+AMO_All-to-All_FI_COMPARE_ATOMIC_MSWAP=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICV_CSWAP=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICV_CSWAP_NE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICV_CSWAP_LE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICV_CSWAP_LT=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICV_CSWAP_GE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICV_CSWAP_GT=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICV_MSWAP=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICMSG_CSWAP=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICMSG_CSWAP_NE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICMSG_CSWAP_LE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICMSG_CSWAP_LT=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICMSG_CSWAP_GE=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICMSG_CSWAP_GT=PASS
+AMO_All-to-All_FI_COMPARE_ATOMICMSG_MSWAP=PASS
+AMO_All-to-One_FI_ATOMIC_MIN=PASS
+AMO_All-to-One_FI_ATOMIC_MAX=PASS
+AMO_All-to-One_FI_ATOMIC_SUM=PASS
+AMO_All-to-One_FI_ATOMIC_PROD=PASS
+AMO_All-to-One_FI_ATOMIC_LOR=PASS
+AMO_All-to-One_FI_ATOMIC_LAND=PASS
+AMO_All-to-One_FI_ATOMIC_BOR=PASS
+AMO_All-to-One_FI_ATOMIC_BAND=PASS
+AMO_All-to-One_FI_ATOMIC_LXOR=PASS
+AMO_All-to-One_FI_ATOMIC_BXOR=PASS
+AMO_All-to-One_FI_ATOMIC_ATOMIC_WRITE=PASS
+AMO_All-to-One_FI_ATOMIC_ATOMIC_READ=PASS
+AMO_All-to-One_FI_ATOMICV_MIN=PASS
+AMO_All-to-One_FI_ATOMICV_MAX=PASS
+AMO_All-to-One_FI_ATOMICV_SUM=PASS
+AMO_All-to-One_FI_ATOMICV_PROD=PASS
+AMO_All-to-One_FI_ATOMICV_LOR=PASS
+AMO_All-to-One_FI_ATOMICV_LAND=PASS
+AMO_All-to-One_FI_ATOMICV_BOR=PASS
+AMO_All-to-One_FI_ATOMICV_BAND=PASS
+AMO_All-to-One_FI_ATOMICV_LXOR=PASS
+AMO_All-to-One_FI_ATOMICV_BXOR=PASS
+AMO_All-to-One_FI_ATOMICV_ATOMIC_WRITE=PASS
+AMO_All-to-One_FI_ATOMICV_ATOMIC_READ=PASS
+AMO_All-to-One_FI_ATOMICMSG_MIN=PASS
+AMO_All-to-One_FI_ATOMICMSG_MAX=PASS
+AMO_All-to-One_FI_ATOMICMSG_SUM=PASS
+AMO_All-to-One_FI_ATOMICMSG_PROD=PASS
+AMO_All-to-One_FI_ATOMICMSG_LOR=PASS
+AMO_All-to-One_FI_ATOMICMSG_LAND=PASS
+AMO_All-to-One_FI_ATOMICMSG_BOR=PASS
+AMO_All-to-One_FI_ATOMICMSG_BAND=PASS
+AMO_All-to-One_FI_ATOMICMSG_LXOR=PASS
+AMO_All-to-One_FI_ATOMICMSG_BXOR=PASS
+AMO_All-to-One_FI_ATOMICMSG_ATOMIC_WRITE=PASS
+AMO_All-to-One_FI_ATOMICMSG_ATOMIC_READ=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_MIN=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_MAX=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_SUM=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_PROD=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_LOR=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_LAND=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_BOR=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_BAND=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_LXOR=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_BXOR=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_ATOMIC_WRITE=PASS
+AMO_All-to-One_FI_INJECT_ATOMIC_ATOMIC_READ=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_MIN=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_MAX=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_SUM=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_PROD=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_LOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_LAND=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_BOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_BAND=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_LXOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_BXOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_ATOMIC_WRITE=PASS
+AMO_All-to-One_FI_FETCH_ATOMIC_ATOMIC_READ=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_MIN=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_MAX=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_SUM=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_PROD=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_LOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_LAND=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_BOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_BAND=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_LXOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_BXOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_ATOMIC_WRITE=PASS
+AMO_All-to-One_FI_FETCH_ATOMICV_ATOMIC_READ=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_MIN=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_MAX=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_SUM=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_PROD=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_LOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_LAND=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_BOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_BAND=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_LXOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_BXOR=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_ATOMIC_WRITE=PASS
+AMO_All-to-One_FI_FETCH_ATOMICMSG_ATOMIC_READ=PASS
+AMO_All-to-One_FI_COMPARE_ATOMIC_CSWAP=PASS
+AMO_All-to-One_FI_COMPARE_ATOMIC_CSWAP_NE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMIC_CSWAP_LE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMIC_CSWAP_LT=PASS
+AMO_All-to-One_FI_COMPARE_ATOMIC_CSWAP_GE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMIC_CSWAP_GT=PASS
+AMO_All-to-One_FI_COMPARE_ATOMIC_MSWAP=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICV_CSWAP=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICV_CSWAP_NE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICV_CSWAP_LE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICV_CSWAP_LT=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICV_CSWAP_GE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICV_CSWAP_GT=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICV_MSWAP=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICMSG_CSWAP=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICMSG_CSWAP_NE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICMSG_CSWAP_LE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICMSG_CSWAP_LT=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICMSG_CSWAP_GE=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICMSG_CSWAP_GT=PASS
+AMO_All-to-One_FI_COMPARE_ATOMICMSG_MSWAP=PASS
+AMO_One-to-All_FI_ATOMIC_MIN=PASS
+AMO_One-to-All_FI_ATOMIC_MAX=PASS
+AMO_One-to-All_FI_ATOMIC_SUM=PASS
+AMO_One-to-All_FI_ATOMIC_PROD=PASS
+AMO_One-to-All_FI_ATOMIC_LOR=PASS
+AMO_One-to-All_FI_ATOMIC_LAND=PASS
+AMO_One-to-All_FI_ATOMIC_BOR=PASS
+AMO_One-to-All_FI_ATOMIC_BAND=PASS
+AMO_One-to-All_FI_ATOMIC_LXOR=PASS
+AMO_One-to-All_FI_ATOMIC_BXOR=PASS
+AMO_One-to-All_FI_ATOMIC_ATOMIC_WRITE=PASS
+AMO_One-to-All_FI_ATOMIC_ATOMIC_READ=PASS
+AMO_One-to-All_FI_ATOMICV_MIN=PASS
+AMO_One-to-All_FI_ATOMICV_MAX=PASS
+AMO_One-to-All_FI_ATOMICV_SUM=PASS
+AMO_One-to-All_FI_ATOMICV_PROD=PASS
+AMO_One-to-All_FI_ATOMICV_LOR=PASS
+AMO_One-to-All_FI_ATOMICV_LAND=PASS
+AMO_One-to-All_FI_ATOMICV_BOR=PASS
+AMO_One-to-All_FI_ATOMICV_BAND=PASS
+AMO_One-to-All_FI_ATOMICV_LXOR=PASS
+AMO_One-to-All_FI_ATOMICV_BXOR=PASS
+AMO_One-to-All_FI_ATOMICV_ATOMIC_WRITE=PASS
+AMO_One-to-All_FI_ATOMICV_ATOMIC_READ=PASS
+AMO_One-to-All_FI_ATOMICMSG_MIN=PASS
+AMO_One-to-All_FI_ATOMICMSG_MAX=PASS
+AMO_One-to-All_FI_ATOMICMSG_SUM=PASS
+AMO_One-to-All_FI_ATOMICMSG_PROD=PASS
+AMO_One-to-All_FI_ATOMICMSG_LOR=PASS
+AMO_One-to-All_FI_ATOMICMSG_LAND=PASS
+AMO_One-to-All_FI_ATOMICMSG_BOR=PASS
+AMO_One-to-All_FI_ATOMICMSG_BAND=PASS
+AMO_One-to-All_FI_ATOMICMSG_LXOR=PASS
+AMO_One-to-All_FI_ATOMICMSG_BXOR=PASS
+AMO_One-to-All_FI_ATOMICMSG_ATOMIC_WRITE=PASS
+AMO_One-to-All_FI_ATOMICMSG_ATOMIC_READ=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_MIN=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_MAX=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_SUM=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_PROD=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_LOR=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_LAND=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_BOR=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_BAND=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_LXOR=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_BXOR=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_ATOMIC_WRITE=PASS
+AMO_One-to-All_FI_INJECT_ATOMIC_ATOMIC_READ=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_MIN=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_MAX=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_SUM=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_PROD=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_LOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_LAND=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_BOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_BAND=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_LXOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_BXOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_ATOMIC_WRITE=PASS
+AMO_One-to-All_FI_FETCH_ATOMIC_ATOMIC_READ=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_MIN=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_MAX=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_SUM=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_PROD=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_LOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_LAND=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_BOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_BAND=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_LXOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_BXOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_ATOMIC_WRITE=PASS
+AMO_One-to-All_FI_FETCH_ATOMICV_ATOMIC_READ=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_MIN=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_MAX=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_SUM=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_PROD=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_LOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_LAND=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_BOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_BAND=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_LXOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_BXOR=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_ATOMIC_WRITE=PASS
+AMO_One-to-All_FI_FETCH_ATOMICMSG_ATOMIC_READ=PASS
+AMO_One-to-All_FI_COMPARE_ATOMIC_CSWAP=PASS
+AMO_One-to-All_FI_COMPARE_ATOMIC_CSWAP_NE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMIC_CSWAP_LE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMIC_CSWAP_LT=PASS
+AMO_One-to-All_FI_COMPARE_ATOMIC_CSWAP_GE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMIC_CSWAP_GT=PASS
+AMO_One-to-All_FI_COMPARE_ATOMIC_MSWAP=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICV_CSWAP=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICV_CSWAP_NE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICV_CSWAP_LE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICV_CSWAP_LT=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICV_CSWAP_GE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICV_CSWAP_GT=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICV_MSWAP=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICMSG_CSWAP=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICMSG_CSWAP_NE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICMSG_CSWAP_LE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICMSG_CSWAP_LT=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICMSG_CSWAP_GE=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICMSG_CSWAP_GT=PASS
+AMO_One-to-All_FI_COMPARE_ATOMICMSG_MSWAP=PASS
+AMO_Round-Robin_FI_ATOMIC_MIN=PASS
+AMO_Round-Robin_FI_ATOMIC_MAX=PASS
+AMO_Round-Robin_FI_ATOMIC_SUM=PASS
+AMO_Round-Robin_FI_ATOMIC_PROD=PASS
+AMO_Round-Robin_FI_ATOMIC_LOR=PASS
+AMO_Round-Robin_FI_ATOMIC_LAND=PASS
+AMO_Round-Robin_FI_ATOMIC_BOR=PASS
+AMO_Round-Robin_FI_ATOMIC_BAND=PASS
+AMO_Round-Robin_FI_ATOMIC_LXOR=PASS
+AMO_Round-Robin_FI_ATOMIC_BXOR=PASS
+AMO_Round-Robin_FI_ATOMIC_ATOMIC_WRITE=PASS
+AMO_Round-Robin_FI_ATOMIC_ATOMIC_READ=PASS
+AMO_Round-Robin_FI_ATOMICV_MIN=PASS
+AMO_Round-Robin_FI_ATOMICV_MAX=PASS
+AMO_Round-Robin_FI_ATOMICV_SUM=PASS
+AMO_Round-Robin_FI_ATOMICV_PROD=PASS
+AMO_Round-Robin_FI_ATOMICV_LOR=PASS
+AMO_Round-Robin_FI_ATOMICV_LAND=PASS
+AMO_Round-Robin_FI_ATOMICV_BOR=PASS
+AMO_Round-Robin_FI_ATOMICV_BAND=PASS
+AMO_Round-Robin_FI_ATOMICV_LXOR=PASS
+AMO_Round-Robin_FI_ATOMICV_BXOR=PASS
+AMO_Round-Robin_FI_ATOMICV_ATOMIC_WRITE=PASS
+AMO_Round-Robin_FI_ATOMICV_ATOMIC_READ=PASS
+AMO_Round-Robin_FI_ATOMICMSG_MIN=PASS
+AMO_Round-Robin_FI_ATOMICMSG_MAX=PASS
+AMO_Round-Robin_FI_ATOMICMSG_SUM=PASS
+AMO_Round-Robin_FI_ATOMICMSG_PROD=PASS
+AMO_Round-Robin_FI_ATOMICMSG_LOR=PASS
+AMO_Round-Robin_FI_ATOMICMSG_LAND=PASS
+AMO_Round-Robin_FI_ATOMICMSG_BOR=PASS
+AMO_Round-Robin_FI_ATOMICMSG_BAND=PASS
+AMO_Round-Robin_FI_ATOMICMSG_LXOR=PASS
+AMO_Round-Robin_FI_ATOMICMSG_BXOR=PASS
+AMO_Round-Robin_FI_ATOMICMSG_ATOMIC_WRITE=PASS
+AMO_Round-Robin_FI_ATOMICMSG_ATOMIC_READ=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_MIN=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_MAX=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_SUM=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_PROD=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_LOR=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_LAND=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_BOR=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_BAND=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_LXOR=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_BXOR=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_ATOMIC_WRITE=PASS
+AMO_Round-Robin_FI_INJECT_ATOMIC_ATOMIC_READ=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_MIN=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_MAX=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_SUM=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_PROD=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_LOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_LAND=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_BOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_BAND=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_LXOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_BXOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_ATOMIC_WRITE=PASS
+AMO_Round-Robin_FI_FETCH_ATOMIC_ATOMIC_READ=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_MIN=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_MAX=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_SUM=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_PROD=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_LOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_LAND=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_BOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_BAND=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_LXOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_BXOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_ATOMIC_WRITE=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICV_ATOMIC_READ=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_MIN=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_MAX=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_SUM=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_PROD=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_LOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_LAND=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_BOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_BAND=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_LXOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_BXOR=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_ATOMIC_WRITE=PASS
+AMO_Round-Robin_FI_FETCH_ATOMICMSG_ATOMIC_READ=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMIC_CSWAP=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMIC_CSWAP_NE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMIC_CSWAP_LE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMIC_CSWAP_LT=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMIC_CSWAP_GE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMIC_CSWAP_GT=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMIC_MSWAP=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICV_CSWAP=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICV_CSWAP_NE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICV_CSWAP_LE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICV_CSWAP_LT=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICV_CSWAP_GE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICV_CSWAP_GT=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICV_MSWAP=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICMSG_CSWAP=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICMSG_CSWAP_NE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICMSG_CSWAP_LE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICMSG_CSWAP_LT=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICMSG_CSWAP_GE=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICMSG_CSWAP_GT=PASS
+AMO_Round-Robin_FI_COMPARE_ATOMICMSG_MSWAP=PASS
+MESSAGE_All-to-All_FI_INJECT=PASS
+MESSAGE_All-to-All_FI_INJECTDATA=PASS
+MESSAGE_All-to-All_FI_SEND=PASS
+MESSAGE_All-to-All_FI_SENDDATA=PASS
+MESSAGE_All-to-All_FI_SENDMSG=PASS
+MESSAGE_All-to-All_FI_SENDV=PASS
+MESSAGE_All-to-One_FI_INJECT=PASS
+MESSAGE_All-to-One_FI_INJECTDATA=PASS
+MESSAGE_All-to-One_FI_SEND=PASS
+MESSAGE_All-to-One_FI_SENDDATA=PASS
+MESSAGE_All-to-One_FI_SENDMSG=PASS
+MESSAGE_All-to-One_FI_SENDV=PASS
+MESSAGE_One-to-All_FI_INJECT=PASS
+MESSAGE_One-to-All_FI_INJECTDATA=PASS
+MESSAGE_One-to-All_FI_SEND=PASS
+MESSAGE_One-to-All_FI_SENDDATA=PASS
+MESSAGE_One-to-All_FI_SENDMSG=PASS
+MESSAGE_One-to-All_FI_SENDV=PASS
+MESSAGE_Round-Robin_FI_INJECT=PASS
+MESSAGE_Round-Robin_FI_INJECTDATA=PASS
+MESSAGE_Round-Robin_FI_SEND=PASS
+MESSAGE_Round-Robin_FI_SENDDATA=PASS
+MESSAGE_Round-Robin_FI_SENDDATA_TRIGGER=SKIP
+MESSAGE_Round-Robin_FI_SENDMSG=PASS
+MESSAGE_Round-Robin_FI_SENDMSG_TRIGGER=SKIP
+MESSAGE_Round-Robin_FI_SENDV=PASS
+MESSAGE_Round-Robin_FI_SENDV_TRIGGER=SKIP
+MESSAGE_Round-Robin_FI_SEND_TRIGGER=SKIP
+RMA_All-to-All_FI_INJECT_WRITE=PASS
+RMA_All-to-All_FI_INJECT_WRITEDATA=PASS
+RMA_All-to-All_FI_READ=PASS
+RMA_All-to-All_FI_READMSG=PASS
+RMA_All-to-All_FI_READV=PASS
+RMA_All-to-All_FI_WRITE=PASS
+RMA_All-to-All_FI_WRITEDATA=PASS
+RMA_All-to-All_FI_WRITEMSG=PASS
+RMA_All-to-All_FI_WRITEV=PASS
+RMA_All-to-One_FI_INJECT_WRITE=PASS
+RMA_All-to-One_FI_INJECT_WRITEDATA=PASS
+RMA_All-to-One_FI_READ=PASS
+RMA_All-to-One_FI_READMSG=PASS
+RMA_All-to-One_FI_READV=PASS
+RMA_All-to-One_FI_WRITE=PASS
+RMA_All-to-One_FI_WRITEDATA=PASS
+RMA_All-to-One_FI_WRITEMSG=PASS
+RMA_All-to-One_FI_WRITEV=PASS
+RMA_One-to-All_FI_INJECT_WRITE=PASS
+RMA_One-to-All_FI_INJECT_WRITEDATA=PASS
+RMA_One-to-All_FI_READ=PASS
+RMA_One-to-All_FI_READMSG=PASS
+RMA_One-to-All_FI_READV=PASS
+RMA_One-to-All_FI_WRITE=PASS
+RMA_One-to-All_FI_WRITEDATA=PASS
+RMA_One-to-All_FI_WRITEMSG=PASS
+RMA_One-to-All_FI_WRITEV=PASS
+RMA_Round-Robin_FI_INJECT_WRITE=PASS
+RMA_Round-Robin_FI_INJECT_WRITEDATA=PASS
+RMA_Round-Robin_FI_READ=PASS
+RMA_Round-Robin_FI_READMSG=PASS
+RMA_Round-Robin_FI_READMSG_TRIGGER=SKIP
+RMA_Round-Robin_FI_READV=PASS
+RMA_Round-Robin_FI_READV_TRIGGER=SKIP
+RMA_Round-Robin_FI_READ_TRIGGER=SKIP
+RMA_Round-Robin_FI_WRITE=PASS
+RMA_Round-Robin_FI_WRITEDATA=PASS
+RMA_Round-Robin_FI_WRITEDATA_TRIGGER=SKIP
+RMA_Round-Robin_FI_WRITEMSG=PASS
+RMA_Round-Robin_FI_WRITEMSG_TRIGGER=SKIP
+RMA_Round-Robin_FI_WRITEV=PASS
+RMA_Round-Robin_FI_WRITEV_TRIGGER=SKIP
+RMA_Round-Robin_FI_WRITE_TRIGGER=SKIP
+TAGGED_All-to-All_FI_TINJECT=PASS
+TAGGED_All-to-All_FI_TINJECTDATA=PASS
+TAGGED_All-to-All_FI_TSEND=PASS
+TAGGED_All-to-All_FI_TSENDDATA=PASS
+TAGGED_All-to-All_FI_TSENDMSG=PASS
+TAGGED_All-to-All_FI_TSENDV=PASS
+TAGGED_All-to-One_FI_TINJECT=PASS
+TAGGED_All-to-One_FI_TINJECTDATA=PASS
+TAGGED_All-to-One_FI_TSEND=PASS
+TAGGED_All-to-One_FI_TSENDDATA=PASS
+TAGGED_All-to-One_FI_TSENDMSG=PASS
+TAGGED_All-to-One_FI_TSENDV=PASS
+TAGGED_One-to-All_FI_TINJECT=PASS
+TAGGED_One-to-All_FI_TINJECTDATA=PASS
+TAGGED_One-to-All_FI_TSEND=PASS
+TAGGED_One-to-All_FI_TSENDDATA=PASS
+TAGGED_One-to-All_FI_TSENDMSG=PASS
+TAGGED_One-to-All_FI_TSENDV=PASS
+TAGGED_Round-Robin_FI_TINJECT=PASS
+TAGGED_Round-Robin_FI_TINJECTDATA=PASS
+TAGGED_Round-Robin_FI_TSEND=PASS
+TAGGED_Round-Robin_FI_TSENDDATA=PASS
+TAGGED_Round-Robin_FI_TSENDDATA_TRIGGER=SKIP
+TAGGED_Round-Robin_FI_TSENDMSG=PASS
+TAGGED_Round-Robin_FI_TSENDMSG_TRIGGER=SKIP
+TAGGED_Round-Robin_FI_TSENDV=PASS
+TAGGED_Round-Robin_FI_TSENDV_TRIGGER=SKIP
+TAGGED_Round-Robin_FI_TSEND_TRIGGER=SKIP
+
+# The Error Messages section will contain error message that could happen intermittently.
+# However, a test should not encounter errors during libfabric initialization
+# because the test could not execute.
+# If a test encounters one of these error messages, then Jenkins will report this test as SKIPPED
+
+# Intermittent Error Messages
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/share/requirements.txt b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/share/requirements.txt
new file mode 100644
index 000000000..ac04d3fa9
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/share/requirements.txt
@@ -0,0 +1 @@
+junit-xml
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/share/version b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/share/version
new file mode 100644
index 000000000..3eefcb9dd
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/contrib/cray/share/version
@@ -0,0 +1 @@
+1.0.0
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/AUTHORS b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/AUTHORS
new file mode 100644
index 000000000..62652be6c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/AUTHORS
@@ -0,0 +1,41 @@
+aingerson <aingerson@gmail.com>
+aingerson <alexia.ingerson@intel.com>
+Arun C Ilango <arun.ilango@intel.com>
+arun ilango <a-ilango@users.noreply.github.com>
+Arun Ilango <arun.ilango@intel.com>
+Ben Turrubiates <bturrubiates@lanl.gov>
+Ben Turrubiates <bturrubi@cisco.com>
+Charles J Archer <charles.j.archer@intel.com>
+Chen Zhao <soniczhao@gmail.com>
+Chuck Fossen <chuckf@cray.com>
+Dardo D Kleiner <dkleiner@cmf.nrl.navy.mil>
+Dave Goodell <dgoodell@cisco.com>
+Dmitry Gladkov <dmitry.gladkov@intel.com>
+Erik Paulson <erik.r.paulson@intel.com>
+Evgeny Leksikov <evgeny.leksikov@intel.com>
+Howard Pritchard <howardp@lanl.gov>
+James Shimek <jshimek@cray.com>
+Jeff Squyres <jsquyres@cisco.com>
+Jerome Berryhill <Jerome.Berryhill@Intel.com>
+Jerome Boyd Berryhill <JeromeBerryhill@Intel.com>
+Jithin Jose <jithin.jose@intel.com>
+John Byrne <john.l.byrne@hpe.com>
+jose <jose@cst-fs.(none)>
+jose <jose@cstnh-8.(none)>
+Ken Raffenetti <raffenet@mcs.anl.gov>
+Miao Luo <miao.luo@intel.com>
+Neil Spruit <neil.r.spruit@intel.com>
+Oblomov, Sergey <sergey.oblomov@intel.com>
+Paolo Inaudi <p91paul@gmail.com>
+Patrick MacArthur <pmacarth@iol.unh.edu>
+Patrick McCormick <patrick.m.mccormick@intel.com>
+Prankur Gupta <prankgup@cisco.com>
+Reese Faucette <rfaucett@cisco.com>
+Sayantan Sur <sayantan.sur@intel.com>
+Sean Hefty <sean.hefty@intel.com>
+Shantonu Hossain <shantonu.hossain@intel.com>
+Solovyev, Dmitriy <dmitriy.solovyev@intel.com>
+Spruit, Neil R <neil.r.spruit@intel.com>
+Stan Smith <stan.smith@intel.com>
+Sung-Eun Choi <sungeunchoi@users.noreply.github.com>
+Xuyang Wang <xuywang@cisco.com>
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/COPYING b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/COPYING
new file mode 100644
index 000000000..c8cfa7428
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/COPYING
@@ -0,0 +1,409 @@
+This software is available to you under a choice of one of two
+licenses.  You may choose to be licensed under the terms of the the
+BSD license or the GNU General Public License (GPL) Version
+2, both included below.
+
+Some parts of the source are 3rd party code which uses MIT license.
+The description and requirements of the license are available in
+later part of this file.
+
+Copyright (c) 2015-2018 Intel Corporation.  All rights reserved.
+Copyright (c) 2016-2018 Cisco Systems, Inc.  All rights reserved.
+
+==================================================================
+
+		       BSD license
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions
+are met:
+
+  * Redistributions of source code must retain the above copyright
+    notice, this list of conditions and the following disclaimer.
+
+  * Redistributions in binary form must reproduce the above
+    copyright notice, this list of conditions and the following
+    disclaimer in the documentation and/or other materials provided
+    with the distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
+COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
+INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
+ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGE.
+
+==================================================================
+
+                    GNU GENERAL PUBLIC LICENSE
+                       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.
+                       59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+                            Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Library General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+                    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+                            NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+                     END OF TERMS AND CONDITIONS
+
+            How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program; if not, write to the Free Software
+    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Library General
+Public License instead of this License.
+
+==================================================================
+
+				MIT LICENSE
+
+Applies to: include/jsmn.h, common/jsmn.c
+
+Copyright (c) 2010 Serge A. Zaitsev
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in
+all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+THE SOFTWARE.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/Makefile.am b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/Makefile.am
new file mode 100644
index 000000000..5d3f8034a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/Makefile.am
@@ -0,0 +1,386 @@
+configdir = $(datarootdir)/${PACKAGE_NAME}
+AM_CFLAGS = -g -Wall -D_GNU_SOURCE -D 'CONFIG_PATH="${configdir}"' -I$(srcdir)/include
+ACLOCAL_AMFLAGS = -I config
+
+if MACOS
+os_excludes = -f ./test_configs/osx.exclude
+endif
+
+bin_PROGRAMS = \
+	functional/fi_av_xfer \
+	functional/fi_msg \
+	functional/fi_msg_sockets \
+	functional/fi_rdm \
+	functional/fi_rdm_rma_simple \
+	functional/fi_rdm_rma_trigger \
+	functional/fi_rdm_deferred_wq \
+	functional/fi_dgram \
+	functional/fi_mcast \
+	functional/fi_dgram_waitset \
+	functional/fi_rdm_tagged_peek \
+	functional/fi_cq_data \
+	functional/fi_poll \
+	functional/fi_scalable_ep \
+	functional/fi_shared_ctx \
+	functional/fi_msg_epoll \
+	functional/fi_rdm_shared_av \
+	functional/fi_cm_data \
+	functional/fi_multi_mr \
+	functional/fi_rdm_multi_domain \
+	functional/fi_multi_ep \
+	functional/fi_recv_cancel \
+	functional/fi_unexpected_msg \
+	functional/fi_inj_complete \
+	functional/fi_resmgmt_test \
+	functional/fi_rdm_atomic \
+	functional/fi_rdm_multi_recv \
+	benchmarks/fi_msg_pingpong \
+	benchmarks/fi_msg_bw \
+	benchmarks/fi_rma_bw \
+	benchmarks/fi_rdm_cntr_pingpong \
+	benchmarks/fi_dgram_pingpong \
+	benchmarks/fi_rdm_pingpong \
+	benchmarks/fi_rdm_tagged_pingpong \
+	benchmarks/fi_rdm_tagged_bw \
+	unit/fi_eq_test \
+	unit/fi_cq_test \
+	unit/fi_mr_test \
+	unit/fi_cntr_test \
+	unit/fi_av_test \
+	unit/fi_dom_test \
+	unit/fi_getinfo_test \
+	unit/fi_resource_freeing \
+	ubertest/fi_ubertest
+
+dist_bin_SCRIPTS = \
+	scripts/runfabtests.sh \
+	scripts/rft_yaml_to_junit_xml
+
+dist_noinst_SCRIPTS = \
+	scripts/parseyaml.py
+
+nobase_dist_config_DATA = \
+	test_configs/osx.exclude \
+        test_configs/eq_cq.test \
+        test_configs/lat_bw.test \
+        test_configs/sockets/all.test \
+        test_configs/sockets/quick.test \
+	test_configs/sockets/complete.test \
+	test_configs/sockets/verify.test \
+        test_configs/udp/all.test \
+        test_configs/udp/lat_bw.test \
+        test_configs/udp/quick.test \
+        test_configs/udp/functional.test \
+        test_configs/udp/udp.exclude \
+        test_configs/tcp/tcp.exclude \
+        test_configs/verbs/all.test \
+        test_configs/verbs/quick.test \
+	test_configs/verbs/exclude \
+	test_configs/usnic/all.test \
+	test_configs/usnic/quick.test \
+	test_configs/psm/all.test \
+	test_configs/psm2/all.test \
+	test_configs/psm2/verify.test \
+	test_configs/psm2/psm2.exclude \
+	test_configs/ofi_rxm/verbs/all.test \
+	test_configs/ofi_rxm/verbs/exclude \
+	test_configs/ofi_rxd/ofi_rxd.exclude \
+	test_configs/ofi_rxd/udp.test \
+	test_configs/shm/all.test \
+	test_configs/shm/verify.test
+
+noinst_LTLIBRARIES = libfabtests.la
+libfabtests_la_SOURCES = \
+	common/shared.c \
+	common/jsmn.c \
+	include/shared.h \
+	include/jsmn.h \
+	include/unix/osd.h \
+	include/ft_osd.h
+
+benchmarks_srcs = \
+	benchmarks/benchmark_shared.h \
+	benchmarks/benchmark_shared.c
+
+unit_srcs = \
+	include/unit_common.h \
+	unit/common.c
+
+if MACOS
+if !HAVE_CLOCK_GETTIME
+libfabtests_la_SOURCES += common/osx/osd.c
+endif
+endif
+
+functional_fi_av_xfer_SOURCES = \
+	functional/av_xfer.c
+functional_fi_av_xfer_LDADD = libfabtests.la
+
+functional_fi_msg_sockets_SOURCES = \
+	functional/msg_sockets.c
+functional_fi_msg_sockets_LDADD = libfabtests.la
+
+functional_fi_msg_epoll_SOURCES = \
+	functional/msg_epoll.c
+functional_fi_msg_epoll_LDADD = libfabtests.la
+
+functional_fi_msg_SOURCES = \
+	functional/msg.c
+functional_fi_msg_LDADD = libfabtests.la
+
+functional_fi_rdm_SOURCES = \
+	functional/rdm.c
+functional_fi_rdm_LDADD = libfabtests.la
+
+functional_fi_rdm_shared_av_SOURCES = \
+	functional/rdm_shared_av.c
+functional_fi_rdm_shared_av_LDADD = libfabtests.la
+
+functional_fi_rdm_rma_simple_SOURCES = \
+	functional/rdm_rma_simple.c
+functional_fi_rdm_rma_simple_LDADD = libfabtests.la
+
+functional_fi_rdm_rma_trigger_SOURCES = \
+	functional/rdm_rma_trigger.c
+functional_fi_rdm_rma_trigger_LDADD = libfabtests.la
+
+functional_fi_rdm_deferred_wq_SOURCES = \
+	functional/rdm_deferred_wq.c
+functional_fi_rdm_deferred_wq_LDADD = libfabtests.la
+
+functional_fi_dgram_SOURCES = \
+	functional/dgram.c
+functional_fi_dgram_LDADD = libfabtests.la
+
+functional_fi_mcast_SOURCES = \
+	functional/mcast.c
+functional_fi_mcast_LDADD = libfabtests.la
+
+functional_fi_dgram_waitset_SOURCES = \
+	functional/dgram_waitset.c
+functional_fi_dgram_waitset_LDADD = libfabtests.la
+
+functional_fi_rdm_tagged_peek_SOURCES = \
+	functional/rdm_tagged_peek.c
+functional_fi_rdm_tagged_peek_LDADD = libfabtests.la
+
+functional_fi_cq_data_SOURCES = \
+	functional/cq_data.c
+functional_fi_cq_data_LDADD = libfabtests.la
+
+functional_fi_cm_data_SOURCES = \
+	functional/cm_data.c
+functional_fi_cm_data_LDADD = libfabtests.la
+
+functional_fi_scalable_ep_SOURCES = \
+	functional/scalable_ep.c
+functional_fi_scalable_ep_LDADD = libfabtests.la
+
+functional_fi_shared_ctx_SOURCES = \
+	functional/shared_ctx.c
+functional_fi_shared_ctx_LDADD = libfabtests.la
+
+functional_fi_poll_SOURCES = \
+	functional/poll.c
+functional_fi_poll_LDADD = libfabtests.la
+
+functional_fi_multi_ep_SOURCES = \
+	functional/multi_ep.c
+functional_fi_multi_ep_LDADD = libfabtests.la
+
+functional_fi_multi_mr_SOURCES = \
+	functional/multi_mr.c
+functional_fi_multi_mr_LDADD = libfabtests.la
+
+functional_fi_unexpected_msg_SOURCES = \
+	functional/unexpected_msg.c
+functional_fi_unexpected_msg_LDADD = libfabtests.la
+
+functional_fi_rdm_multi_domain_SOURCES = \
+	functional/rdm_multi_domain.c
+functional_fi_rdm_multi_domain_LDADD = libfabtests.la
+
+functional_fi_recv_cancel_SOURCES = \
+	functional/recv_cancel.c
+functional_fi_recv_cancel_LDADD = libfabtests.la
+
+functional_fi_inj_complete_SOURCES = \
+	functional/inj_complete.c
+functional_fi_inj_complete_LDADD = libfabtests.la
+
+functional_fi_resmgmt_test_SOURCES = \
+	functional/resmgmt_test.c
+functional_fi_resmgmt_test_LDADD = libfabtests.la
+
+functional_fi_rdm_atomic_SOURCES = \
+	functional/rdm_atomic.c
+functional_fi_rdm_atomic_LDADD = libfabtests.la
+
+functional_fi_rdm_multi_recv_SOURCES = \
+	functional/rdm_multi_recv.c
+functional_fi_rdm_multi_recv_LDADD = libfabtests.la
+
+benchmarks_fi_msg_pingpong_SOURCES = \
+	benchmarks/msg_pingpong.c \
+	$(benchmarks_srcs)
+benchmarks_fi_msg_pingpong_LDADD = libfabtests.la
+
+benchmarks_fi_msg_bw_SOURCES = \
+	benchmarks/msg_bw.c \
+	$(benchmarks_srcs)
+benchmarks_fi_msg_bw_LDADD = libfabtests.la
+
+benchmarks_fi_rma_bw_SOURCES = \
+	benchmarks/rma_bw.c \
+	$(benchmarks_srcs)
+benchmarks_fi_rma_bw_LDADD = libfabtests.la
+
+benchmarks_fi_dgram_pingpong_SOURCES = \
+	benchmarks/dgram_pingpong.c \
+	$(benchmarks_srcs)
+benchmarks_fi_dgram_pingpong_LDADD = libfabtests.la
+
+benchmarks_fi_rdm_cntr_pingpong_SOURCES = \
+	benchmarks/rdm_cntr_pingpong.c \
+	$(benchmarks_srcs)
+benchmarks_fi_rdm_cntr_pingpong_LDADD = libfabtests.la
+
+benchmarks_fi_rdm_pingpong_SOURCES = \
+	benchmarks/rdm_pingpong.c \
+	$(benchmarks_srcs)
+benchmarks_fi_rdm_pingpong_LDADD = libfabtests.la
+
+benchmarks_fi_rdm_tagged_pingpong_SOURCES = \
+	benchmarks/rdm_tagged_pingpong.c \
+	$(benchmarks_srcs)
+benchmarks_fi_rdm_tagged_pingpong_LDADD = libfabtests.la
+
+benchmarks_fi_rdm_tagged_bw_SOURCES = \
+	benchmarks/rdm_tagged_bw.c \
+	$(benchmarks_srcs)
+benchmarks_fi_rdm_tagged_bw_LDADD = libfabtests.la
+
+
+unit_fi_eq_test_SOURCES = \
+	unit/eq_test.c \
+	$(unit_srcs)
+unit_fi_eq_test_LDADD = libfabtests.la
+
+unit_fi_cq_test_SOURCES = \
+	unit/cq_test.c \
+	$(unit_srcs)
+unit_fi_cq_test_LDADD = libfabtests.la
+
+unit_fi_mr_test_SOURCES = \
+	unit/mr_test.c \
+	$(unit_srcs)
+unit_fi_mr_test_LDADD = libfabtests.la
+
+unit_fi_cntr_test_SOURCES = \
+	unit/cntr_test.c \
+	$(unit_srcs)
+unit_fi_cntr_test_LDADD = libfabtests.la
+
+unit_fi_av_test_SOURCES = \
+	unit/av_test.c \
+	$(unit_srcs)
+unit_fi_av_test_LDADD = libfabtests.la
+
+unit_fi_dom_test_SOURCES = \
+	unit/dom_test.c \
+	$(unit_srcs)
+unit_fi_dom_test_LDADD = libfabtests.la
+
+unit_fi_getinfo_test_SOURCES = \
+	unit/getinfo_test.c \
+	$(unit_srcs)
+unit_fi_getinfo_test_LDADD = libfabtests.la
+
+unit_fi_resource_freeing_SOURCES = \
+	unit/resource_freeing.c
+unit_fi_resource_freeing_LDADD = libfabtests.la
+
+ubertest_fi_ubertest_SOURCES = \
+	ubertest/fabtest.h \
+	ubertest/ofi_atomic.h \
+	ubertest/ofi_atomic.c \
+	ubertest/uber.c \
+	ubertest/connect.c \
+	ubertest/cq.c \
+	ubertest/config.c \
+	ubertest/domain.c \
+	ubertest/ep.c \
+	ubertest/xfer.c \
+	ubertest/verify.c \
+	ubertest/test_ctrl.c
+ubertest_fi_ubertest_LDADD = libfabtests.la
+
+real_man_pages = \
+	 man/man7/fabtests.7
+
+dummy_man_pages = \
+	man/man1/fi_av_xfer.1 \
+	man/man1/fi_cm_data.1 \
+	man/man1/fi_cq_data.1 \
+	man/man1/fi_dgram.1 \
+	man/man1/fi_dgram_waitset.1 \
+	man/man1/fi_inj_complete.1 \
+	man/man1/fi_mcast.1 \
+	man/man1/fi_msg.1 \
+	man/man1/fi_msg_epoll.1 \
+	man/man1/fi_msg_sockets.1 \
+	man/man1/fi_multi_ep.1 \
+	man/man1/fi_multi_mr.1 \
+	man/man1/fi_poll.1 \
+	man/man1/fi_rdm.1 \
+	man/man1/fi_rdm_atomic.1 \
+	man/man1/fi_rdm_deferred_wq.1 \
+	man/man1/fi_rdm_multi_domain.1 \
+	man/man1/fi_rdm_multi_recv.1 \
+	man/man1/fi_rdm_rma_simple.1 \
+	man/man1/fi_rdm_rma_trigger.1 \
+	man/man1/fi_rdm_shared_av.1 \
+	man/man1/fi_rdm_tagged_peek.1 \
+	man/man1/fi_recv_cancel.1 \
+	man/man1/fi_resmgmt_test.1 \
+	man/man1/fi_scalable_ep.1 \
+	man/man1/fi_shared_ctx.1 \
+	man/man1/fi_unexpected_msg.1 \
+	man/man1/fi_dgram_pingpong.1 \
+	man/man1/fi_msg_bw.1 \
+	man/man1/fi_msg_pingpong.1 \
+	man/man1/fi_rdm_cntr_pingpong.1 \
+	man/man1/fi_rdm_pingpong.1 \
+	man/man1/fi_rdm_tagged_bw.1 \
+	man/man1/fi_rdm_tagged_pingpong.1 \
+	man/man1/fi_rma_bw.1 \
+	man/man1/fi_av_test.1 \
+	man/man1/fi_cntr_test.1 \
+	man/man1/fi_cq_test.1 \
+	man/man1/fi_dom_test.1 \
+	man/man1/fi_eq_test.1 \
+	man/man1/fi_getinfo_test.1 \
+	man/man1/fi_mr_test.1 \
+	man/man1/fi_resource_freeing.1 \
+	man/man1/fi_ubertest.1
+
+nroff:
+	@for file in $(real_man_pages); do \
+            source=`echo $$file | sed -e 's@/man[0-9]@@'`; \
+            perl $(top_srcdir)/config/md2nroff.pl --source=$(top_srcdir)/$$source.md; \
+        done
+
+
+man_MANS = $(real_man_pages) $(dummy_man_pages)
+
+EXTRA_DIST = \
+	fabtests.spec.in $(real_man_pages) $(dummy_man_pages)
+
+dist-hook: fabtests.spec
+	cp fabtests.spec $(distdir)
+
+test:
+	./scripts/runfabtests.sh -vvv -S $(os_excludes)
+	./scripts/runfabtests.sh -vvv -S $(os_excludes) -R -f ./test_configs/udp/udp.exclude udp
+	./scripts/runfabtests.sh -vvv -S $(os_excludes) -R -f ./test_configs/tcp/tcp.exclude tcp
+	./scripts/runfabtests.sh -vvv -S $(os_excludes) -R -f ./test_configs/ofi_rxd/ofi_rxd.exclude "UDP;ofi_rxd"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/Makefile.win b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/Makefile.win
new file mode 100644
index 000000000..1e59d3c56
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/Makefile.win
@@ -0,0 +1,120 @@
+
+
+!if "$(arch)" == ""
+arch = x64
+!endif
+
+!if "$(config)" == ""
+config = Debug-v140
+!endif
+
+output_root = .\\
+
+!if "$(config)" == "Debug-v140"
+outdir = $(output_root)$(arch)\debug-v140
+CFLAGS = $(CFLAGS) /Zi /Od /MTd
+!endif
+!if "$(config)" == "Debug-v141"
+outdir = $(output_root)$(arch)\debug-v141
+CFLAGS = $(CFLAGS) /Zi /Od /MTd
+!endif
+!if "$(config)" == "Release-v140"
+outdir = $(output_root)$(arch)\release-v140
+CFLAGS = $(CFLAGS) /O2 /MT
+!endif
+!if "$(config)" == "Release-v141"
+outdir = $(output_root)$(arch)\release-v141
+CFLAGS = $(CFLAGS) /O2 /MT
+!endif
+
+basedeps = common\shared.c common\jsmn.c common\windows\getopt.c \
+	common\windows\osd.c
+
+includes = /Iinclude /Iinclude\windows /I..\include /FIft_osd.h \
+	/Iinclude\windows\getopt
+defines = /DGETOPT_STATIC
+libs = ..\$(arch)\$(config)\libfabric.lib Ws2_32.lib
+
+CFLAGS = $(CFLAGS) $(includes) $(defines)
+
+#all: complex functional
+
+all: benchmarks functional unit
+
+{benchmarks}.c{$(outdir)}.exe:
+	if not exist $(@D) mkdir $(@D)
+	$(CC) /Fe$@ $** $(baseincludes) $(CFLAGS) $(libs)
+
+{functional}.c{$(outdir)}.exe:
+	if not exist $(@D) mkdir $(@D)
+	$(CC) /Fe$@ $** $(baseincludes) $(CFLAGS) $(libs)
+
+{unit}.c{$(outdir)}.exe:
+	if not exist $(@D) mkdir $(@D)
+	$(CC) /Fe$@ $** $(baseincludes) $(CFLAGS) $(libs)
+
+
+benchmarks: $(outdir)\msg_pingpong.exe $(outdir)\rdm_cntr_pingpong.exe \
+	$(outdir)\rdm_pingpong.exe $(outdir)\rdm_tagged_pingpong.exe
+
+functional: $(outdir)\cq_data.exe $(outdir)\dgram.exe $(outdir)\dgram_waitset.exe $(outdir)\msg.exe \
+	$(outdir)\msg_epoll.exe $(outdir)\msg_sockets.exe \
+	$(outdir)\poll.exe $(outdir)\rdm.exe $(outdir)\rdm_rma_simple.exe $(outdir)\rdm_rma_trigger.exe \
+	$(outdir)\rdm_tagged_peek.exe $(outdir)\scalable_ep.exe $(outdir)\inj_complete.exe
+
+unit: $(outdir)\av_test.exe $(outdir)\dom_test.exe $(outdir)\eq_test.exe
+
+complex: $(outdir)\complex.exe
+
+clean:
+	if exist $(outdir) rmdir /s /q $(outdir)
+	del *.obj
+
+$(outdir)\msg_pingpong.exe: {benchmarks}msg_pingpong.c $(basedeps) {benchmarks}benchmark_shared.c
+
+$(outdir)\rdm_cntr_pingpong.exe: {benchmarks}rdm_cntr_pingpong.c $(basedeps) {benchmarks}benchmark_shared.c
+
+$(outdir)\rdm_pingpong.exe: {benchmarks}rdm_pingpong.c $(basedeps) {benchmarks}benchmark_shared.c
+
+$(outdir)\rdm_tagged_pingpong.exe: {benchmarks}rdm_tagged_pingpong.c $(basedeps) {benchmarks}benchmark_shared.c
+
+
+$(outdir)\cq_data.exe: {functional}cq_data.c $(basedeps)
+
+$(outdir)\dgram.exe: {functional}dgram.c $(basedeps)
+
+$(outdir)\dgram_waitset.exe: {functional}dgram_waitset.c $(basedeps)
+
+$(outdir)\msg.exe: {functional}msg.c $(basedeps)
+
+$(outdir)\msg_epoll.exe: {functional}msg_epoll.c $(basedeps)
+
+$(outdir)\msg_sockets.exe: {functional}msg_sockets.c $(basedeps)
+
+$(outdir)\poll.exe: {functional}poll.c $(basedeps)
+
+$(outdir)\rdm.exe: {functional}rdm.c $(basedeps)
+
+$(outdir)\rdm_rma_simple.exe: {functional}rdm_rma_simple.c $(basedeps)
+
+$(outdir)\rdm_rma_trigger.exe: {functional}rdm_rma_trigger.c $(basedeps)
+
+$(outdir)\rdm_tagged_peek.exe: {functional}rdm_tagged_peek.c $(basedeps)
+
+$(outdir)\scalable_ep.exe: {functional}scalable_ep.c $(basedeps)
+
+$(outdir)\inj_complete.exe: {functional}inj_complete.c $(basedeps)
+
+$(outdir)\av_test.exe: {unit}av_test.c $(basedeps) {unit}common.c
+
+$(outdir)\dom_test.exe: {unit}dom_test.c $(basedeps) {unit}common.c
+
+$(outdir)\eq_test.exe: {unit}eq_test.c $(basedeps) {unit}common.c
+
+$(outdir)\complex.exe: {complex}ft_comm.c {complex}ft_comp.c {complex}ft_config.c {complex}ft_domain.c {complex}ft_endpoint.c {complex}ft_main.c {complex}ft_msg.c {complex}ft_test.c $(basedeps)
+	if not exist $(@D) mkdir $(@D)
+	$(CC) /Fe$@ $** $(baseincludes) $(CFLAGS) $(libs)
+
+
+
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/README b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/README
new file mode 100644
index 000000000..f90f7d047
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/README
@@ -0,0 +1,31 @@
+Introduction
+============
+Fabtests provides a set of examples that uses libfabric - a high-performance
+fabric software library.
+
+Support
+=======
+Fabtests will run on any operating system supported by Libfabric.
+
+Bugs or issues may be submitted directly to the Github issues list:
+
+https://github.com/ofiwg/fabtests/issues
+
+Additionally, users may post questions, comments, bugs, etc. to the Libfabric
+users mailing list.
+
+libfabric-users@lists.openfabrics.org
+
+Building
+========
+
+To install from a fabtests source package run the following commands:
+
+./configure && make && make install
+
+If building directly from the libfabric git tree, run './autogen.sh' before the
+configure step.
+
+For more detailed build information see the projects home page on Github:
+
+https://github.com/ofiwg/fabtests
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/README.md b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/README.md
new file mode 100644
index 000000000..8448191b0
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/README.md
@@ -0,0 +1,93 @@
+[![Build Status](https://travis-ci.org/ofiwg/fabtests.svg?branch=master)](https://travis-ci.org/ofiwg/fabtests)
+[![fabtests Coverity scan suild status](https://scan.coverity.com/projects/ofiwg-fabtests/badge.svg)](https://scan.coverity.com/projects/ofiwg-fabtests)
+[![fabtests release version](https://img.shields.io/github/release/ofiwg/fabtests.svg)](https://github.com/ofiwg/fabtests/releases/latest)
+
+# fabtests
+
+Fabtests provides a set of examples that uses
+[libfabric](http://libfabric.org) -- a high-performance fabric
+software library.
+
+## Notes
+
+Note that the fabtests suite is released paired with a specific
+version of libfabric.  For example, libfabric v1.4 and fabtests v1.4
+were released together.
+
+Using these paired versions is the best way to test a given version of
+libfabric.  Using version-mismatched libfabric/fabtests pairs may
+produce unexpected results.
+
+## Building fabtests
+
+Distribution tarballs are available from the Github
+[releases](https://github.com/ofiwg/fabtests/releases) tab.
+
+If you are building Fabtests from a developer Git clone, you must
+first run the `autogen.sh` script. This will invoke the GNU Autotools
+to bootstrap Fabtests' configuration and build mechanisms. If you are
+building Fabtests from an official distribution tarball, there is no
+need to run `autogen.sh`; Fabtests distribution tarballs are already
+bootstrapped for you.
+
+Fabtests relies on being able to find an installed version of
+Libfabric. In some cases, Libfabric may be in default compiler /
+linker search paths, and you don't need to tell Fabtests where to find
+it. In other cases, you may need to tell Fabtests where to find the
+installed Libfabric's header and library files using the
+`--with-libfabric=<directory>` option, described below.
+
+### Configure options
+
+The `configure` script has many built in options (see `./configure
+--help`). Some useful options are:
+
+```
+--prefix=<directory>
+```
+
+By default `make install` will place the files in the `/usr` tree.
+The `--prefix` option specifies that the Fabtests files should be
+installed into the tree specified by named `<directory>`. The
+executables will be located at `<directory>/bin`.
+
+```
+--with-libfabric=<directory>
+```
+
+Specify the directory where the Libfabric library and header files are
+located.  This is necessary if Libfabric was installed in a location
+where the compiler and linker will not search by default.  The
+Libfabric library will be searched for in `<directory>/lib`, and
+headers will be searched for in `<directory>/include`.
+
+```
+--with-valgrind=<directory>
+```
+
+Directory where valgrind is installed.  If valgrind is found, then
+valgrind annotations are enabled. This may incur a performance
+penalty.
+
+### Examples
+
+Consider the following example:
+
+```
+$ ./configure --with-libfabric=/opt/libfabric --prefix=/opt/fabtests && make -j 32 && sudo make install
+```
+
+This will tell the Fabtests to look for Libfabric libraries in the
+`/opt/libfabric` tree, and to install the Fabtests in the
+`/opt/fabtests` tree.
+
+Alternatively:
+
+```
+$ ./configure --prefix=/opt/fabtests && make -j 32 && sudo make install
+```
+
+Tells the Fabtests that it should be able to find the Libfabric header
+files and libraries in default compiler / linker search paths
+(configure will abort if it is not able to find them), and to install
+Fabtests in `/opt/fabtests`.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/autogen.sh b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/autogen.sh
new file mode 100755
index 000000000..b71795912
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/autogen.sh
@@ -0,0 +1,14 @@
+#! /bin/sh
+
+if test ! -d .git && test ! -f common/shared.c; then
+    echo You really need to run this script in the top-level fabtests directory
+    exit 1
+fi
+
+set -x
+
+if test ! -d config; then
+    mkdir config
+fi
+
+autoreconf -ivf
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/benchmark_shared.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/benchmark_shared.c
new file mode 100644
index 000000000..ba98bc6a3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/benchmark_shared.c
@@ -0,0 +1,320 @@
+/*
+ * Copyright (c) 2015-2017 Cisco Systems, Inc.  All rights reserved.
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+
+#include <rdma/fi_errno.h>
+
+#include "shared.h"
+#include "benchmark_shared.h"
+
+void ft_parse_benchmark_opts(int op, char *optarg)
+{
+	switch (op) {
+	case 'v':
+		opts.options |= FT_OPT_VERIFY_DATA;
+		break;
+	case 'k':
+		ft_force_prefix(hints, &opts);
+		break;
+	case 'j':
+		hints->tx_attr->inject_size = atoi(optarg);
+		break;
+	case 'W':
+		opts.window_size = atoi(optarg);
+		break;
+	default:
+		break;
+	}
+}
+
+void ft_benchmark_usage(void)
+{
+	FT_PRINT_OPTS_USAGE("-v", "enables data_integrity checks");
+	FT_PRINT_OPTS_USAGE("-k", "force prefix mode");
+	FT_PRINT_OPTS_USAGE("-j", "maximum inject message size");
+	FT_PRINT_OPTS_USAGE("-W", "window size* (for bandwidth tests)\n\n"
+			"* The following condition is required to have at least "
+			"one window\nsize # of messsages to be sent: "
+			"# of iterations > window size");
+}
+
+int ft_bw_init(void)
+{
+	if (opts.window_size > 0) {
+		tx_ctx_arr = calloc(opts.window_size, sizeof(struct fi_context));
+		if (!tx_ctx_arr)
+			return -FI_ENOMEM;
+	}
+	return 0;
+}
+
+int pingpong(void)
+{
+	int ret, i;
+
+	ret = ft_sync();
+	if (ret)
+		return ret;
+
+	if (opts.dst_addr) {
+		for (i = 0; i < opts.iterations + opts.warmup_iterations; i++) {
+			if (i == opts.warmup_iterations)
+				ft_start();
+
+			if (opts.transfer_size < fi->tx_attr->inject_size)
+				ret = ft_inject(ep, remote_fi_addr, opts.transfer_size);
+			else
+				ret = ft_tx(ep, remote_fi_addr, opts.transfer_size, &tx_ctx);
+			if (ret)
+				return ret;
+
+			ret = ft_rx(ep, opts.transfer_size);
+			if (ret)
+				return ret;
+		}
+	} else {
+		for (i = 0; i < opts.iterations + opts.warmup_iterations; i++) {
+			if (i == opts.warmup_iterations)
+				ft_start();
+
+			ret = ft_rx(ep, opts.transfer_size);
+			if (ret)
+				return ret;
+
+			if (opts.transfer_size < fi->tx_attr->inject_size)
+				ret = ft_inject(ep, remote_fi_addr, opts.transfer_size);
+			else
+				ret = ft_tx(ep, remote_fi_addr, opts.transfer_size, &tx_ctx);
+			if (ret)
+				return ret;
+		}
+	}
+	ft_stop();
+
+	if (opts.machr)
+		show_perf_mr(opts.transfer_size, opts.iterations, &start, &end, 2,
+				opts.argc, opts.argv);
+	else
+		show_perf(NULL, opts.transfer_size, opts.iterations, &start, &end, 2);
+
+	return 0;
+}
+
+static int bw_tx_comp()
+{
+	int ret;
+
+	ret = ft_get_tx_comp(tx_seq);
+	if (ret)
+		return ret;
+	return ft_rx(ep, 4);
+}
+
+static int bw_rx_comp()
+{
+	int ret;
+
+	/* rx_seq is always one ahead */
+	ret = ft_get_rx_comp(rx_seq - 1);
+	if (ret)
+		return ret;
+	return ft_tx(ep, remote_fi_addr, 4, &tx_ctx);
+}
+
+int bandwidth(void)
+{
+	int ret, i, j;
+
+	ret = ft_sync();
+	if (ret)
+		return ret;
+
+	/* The loop structured allows for the possibility that the sender
+	 * immediately overruns the receiving side on the first transfer (or
+	 * the entire window). This could result in exercising parts of the
+	 * provider's implementation of FI_RM_ENABLED. For better or worse,
+	 * some MPI-level benchmarks tend to use this type of loop for measuring
+	 * bandwidth.  */
+
+	if (opts.dst_addr) {
+		for (i = j = 0; i < opts.iterations + opts.warmup_iterations; i++) {
+			if (i == opts.warmup_iterations)
+				ft_start();
+
+			if (opts.transfer_size < fi->tx_attr->inject_size)
+				ret = ft_inject(ep, remote_fi_addr, opts.transfer_size);
+			else
+				ret = ft_post_tx(ep, remote_fi_addr, opts.transfer_size,
+						 NO_CQ_DATA, &tx_ctx_arr[j]);
+			if (ret)
+				return ret;
+
+			if (++j == opts.window_size) {
+				ret = bw_tx_comp();
+				if (ret)
+					return ret;
+				j = 0;
+			}
+		}
+		ret = bw_tx_comp();
+		if (ret)
+			return ret;
+	} else {
+		for (i = j = 0; i < opts.iterations + opts.warmup_iterations; i++) {
+			if (i == opts.warmup_iterations)
+				ft_start();
+
+			ret = ft_post_rx(ep, opts.transfer_size, &tx_ctx_arr[j]);
+			if (ret)
+				return ret;
+
+			if (++j == opts.window_size) {
+				ret = bw_rx_comp();
+				if (ret)
+					return ret;
+				j = 0;
+			}
+		}
+		ret = bw_rx_comp();
+		if (ret)
+			return ret;
+	}
+	ft_stop();
+
+	if (opts.machr)
+		show_perf_mr(opts.transfer_size, opts.iterations, &start, &end, 1,
+				opts.argc, opts.argv);
+	else
+		show_perf(NULL, opts.transfer_size, opts.iterations, &start, &end, 1);
+
+	return 0;
+}
+
+static int bw_rma_comp(enum ft_rma_opcodes rma_op)
+{
+	int ret;
+
+	if (rma_op == FT_RMA_WRITEDATA) {
+		if (opts.dst_addr) {
+			ret = bw_tx_comp();
+		} else {
+			ret = bw_rx_comp();
+		}
+	} else {
+		ret = ft_get_tx_comp(tx_seq);
+	}
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int bandwidth_rma(enum ft_rma_opcodes rma_op, struct fi_rma_iov *remote)
+{
+	int ret, i, j;
+
+	ret = ft_sync();
+	if (ret)
+		return ret;
+
+	for (i = j = 0; i < opts.iterations + opts.warmup_iterations; i++) {
+		if (i == opts.warmup_iterations)
+			ft_start();
+
+		switch (rma_op) {
+		case FT_RMA_WRITE:
+			if (opts.transfer_size < fi->tx_attr->inject_size) {
+				ret = ft_post_rma_inject(FT_RMA_WRITE, ep,
+						opts.transfer_size, remote);
+			} else {
+				ret = ft_post_rma(rma_op, ep, opts.transfer_size,
+						remote,	&tx_ctx_arr[j]);
+			}
+			break;
+		case FT_RMA_WRITEDATA:
+			if (!opts.dst_addr) {
+				if (fi->rx_attr->mode & FI_RX_CQ_DATA)
+					ret = ft_post_rx(ep, 0, &tx_ctx_arr[j]);
+				else
+					/* Just increment the seq # instead of
+					 * posting recv so that we wait for
+					 * remote write completion on the next
+					 * iteration */
+					rx_seq++;
+
+			} else {
+				if (opts.transfer_size < fi->tx_attr->inject_size) {
+					ret = ft_post_rma_inject(FT_RMA_WRITEDATA,
+							ep,
+							opts.transfer_size,
+							remote);
+				} else {
+					ret = ft_post_rma(FT_RMA_WRITEDATA,
+							ep,
+							opts.transfer_size,
+							remote,	&tx_ctx_arr[j]);
+				}
+			}
+			break;
+		case FT_RMA_READ:
+			ret = ft_post_rma(FT_RMA_READ, ep, opts.transfer_size,
+					remote,	&tx_ctx_arr[j]);
+			break;
+		default:
+			FT_ERR("Unknown RMA op type\n");
+			return EXIT_FAILURE;
+		}
+		if (ret)
+			return ret;
+
+		if (++j == opts.window_size) {
+			ret = bw_rma_comp(rma_op);
+			if (ret)
+				return ret;
+			j = 0;
+		}
+	}
+	ret = bw_rma_comp(rma_op);
+	if (ret)
+		return ret;
+	ft_stop();
+
+	if (opts.machr)
+		show_perf_mr(opts.transfer_size, opts.iterations, &start, &end,	1,
+				opts.argc, opts.argv);
+	else
+		show_perf(NULL, opts.transfer_size, opts.iterations, &start, &end, 1);
+	return 0;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_cntr.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/benchmark_shared.h
similarity index 63%
rename from prov/verbs/src/ep_dgram/verbs_dgram_cntr.c
rename to fabtests/benchmarks/benchmark_shared.h
index 5ec0efc34..9bc31201f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_cntr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/benchmark_shared.h
@@ -1,5 +1,6 @@
 /*
- * Copyright (c) 2017 Intel Corporation, Inc.  All rights reserved.
+ * Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -30,39 +31,27 @@
  * SOFTWARE.
  */
 
-#include "verbs_dgram.h"
+#ifndef _BENCHMARK_SHARED_H_
+#define _BENCHMARK_SHARED_H_
 
-int fi_ibv_dgram_cntr_open(struct fid_domain *domain_fid,
-			   struct fi_cntr_attr *attr,
-			   struct fid_cntr **cntr_fid,
-			   void *context)
-{
-	int ret;
-	struct fi_ibv_dgram_cntr *cntr;
-	struct fi_ibv_domain *domain;
+#ifdef __cplusplus
+extern "C" {
+#endif
 
-	cntr = calloc(1, sizeof(*cntr));
-	if (!cntr)
-		return -FI_ENOMEM;
+#include <rdma/fi_rma.h>
 
-	domain = container_of(domain_fid, struct fi_ibv_domain,
-			      util_domain.domain_fid);
-	if (!domain) {
-		ret = -FI_EINVAL;
- 		goto free;
-	}
+#define BENCHMARK_OPTS "vkj:W:"
+#define FT_BENCHMARK_MAX_MSG_SIZE (test_size[TEST_CNT - 1].size)
 
-	assert(domain->ep_type == FI_EP_DGRAM);
+void ft_parse_benchmark_opts(int op, char *optarg);
+void ft_benchmark_usage(void);
+int ft_bw_init(void);
+int pingpong(void);
+int bandwidth(void);
+int bandwidth_rma(enum ft_rma_opcodes op, struct fi_rma_iov *remote);
 
-	ret = ofi_cntr_init(&fi_ibv_prov, domain_fid, attr, &cntr->util_cntr,
-			    &ofi_cntr_progress, context);
-	if (ret)
-		goto free;
-
-	*cntr_fid = &cntr->util_cntr.cntr_fid;
-	return FI_SUCCESS;
-
-free:
-	free(cntr);
-	return ret;
+#ifdef __cplusplus
 }
+#endif
+
+#endif /* _BENCHMARK_SHARED_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/dgram_pingpong.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/dgram_pingpong.c
new file mode 100644
index 000000000..b109cb26b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/dgram_pingpong.c
@@ -0,0 +1,130 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2017 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+
+#include "shared.h"
+#include "benchmark_shared.h"
+
+static int run(void)
+{
+	int i, ret;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	/* Post an extra receive to avoid lacking a posted receive in the
+	 * finalize.
+	 */
+	ret = fi_recv(ep, rx_buf, rx_size + ft_rx_prefix_size(), mr_desc,
+			0, &rx_ctx);
+
+	if (!(opts.options & FT_OPT_SIZE)) {
+		for (i = 0; i < TEST_CNT; i++) {
+			if (!ft_use_size(i, opts.sizes_enabled))
+				continue;
+
+			opts.transfer_size = test_size[i].size;
+			if (opts.transfer_size > fi->ep_attr->max_msg_size)
+				continue;
+
+			init_test(&opts, test_name, sizeof(test_name));
+			ret = pingpong();
+			if (ret)
+				return ret;
+		}
+	} else {
+		init_test(&opts, test_name, sizeof(test_name));
+		ret = pingpong();
+		if (ret)
+			return ret;
+	}
+
+	return ft_finalize();
+}
+
+int main(int argc, char **argv)
+{
+	int ret, op;
+
+	opts = INIT_OPTS;
+
+	timeout = 5;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "hT:" CS_OPTS INFO_OPTS BENCHMARK_OPTS)) !=
+			-1) {
+		switch (op) {
+		case 'T':
+			timeout = atoi(optarg);
+			break;
+		default:
+			ft_parse_benchmark_opts(op, optarg);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Ping pong client and server using UD.");
+			ft_benchmark_usage();
+			FT_PRINT_OPTS_USAGE("-T <timeout>",
+					"seconds before timeout on receive");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_DGRAM;
+	if (opts.options & FT_OPT_SIZE)
+		hints->ep_attr->max_msg_size = opts.transfer_size;
+	hints->caps = FI_MSG;
+	hints->mode |= FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->domain_attr->threading = FI_THREAD_DOMAIN;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/msg_bw.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/msg_bw.c
new file mode 100644
index 000000000..c641acc57
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/msg_bw.c
@@ -0,0 +1,119 @@
+/*
+ * Copyright (c) 2013-2016 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+
+#include <shared.h>
+#include "benchmark_shared.h"
+
+static int run(void)
+{
+	int i, ret;
+
+	if (!opts.dst_addr) {
+		ret = ft_start_server();
+		if (ret)
+			return ret;
+	}
+
+	ret = opts.dst_addr ? ft_client_connect() : ft_server_connect();
+	if (ret) {
+		return ret;
+	}
+
+	ret = ft_bw_init();
+	if (ret)
+		return ret;
+
+	if (!(opts.options & FT_OPT_SIZE)) {
+		for (i = 0; i < TEST_CNT; i++) {
+			if (!ft_use_size(i, opts.sizes_enabled))
+				continue;
+			opts.transfer_size = test_size[i].size;
+			init_test(&opts, test_name, sizeof(test_name));
+			ret = bandwidth();
+			if (ret)
+				goto out;
+		}
+	} else {
+		init_test(&opts, test_name, sizeof(test_name));
+		ret = bandwidth();
+		if (ret)
+			goto out;
+	}
+
+	ft_finalize();
+out:
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_BW;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" CS_OPTS INFO_OPTS BENCHMARK_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_benchmark_opts(op, optarg);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Bandwidth test for MSG endpoints.");
+			ft_benchmark_usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_MSG;
+	hints->caps = FI_MSG;
+	hints->domain_attr->resource_mgmt = FI_RM_ENABLED;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->domain_attr->threading = FI_THREAD_DOMAIN;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/msg_pingpong.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/msg_pingpong.c
new file mode 100644
index 000000000..0c98014a4
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/msg_pingpong.c
@@ -0,0 +1,115 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_cm.h>
+
+#include "shared.h"
+#include "benchmark_shared.h"
+
+static int run(void)
+{
+	int i, ret;
+
+	if (!opts.dst_addr) {
+		ret = ft_start_server();
+		if (ret)
+			return ret;
+	}
+
+	ret = opts.dst_addr ? ft_client_connect() : ft_server_connect();
+	if (ret) {
+		return ret;
+	}
+
+	if (!(opts.options & FT_OPT_SIZE)) {
+		for (i = 0; i < TEST_CNT; i++) {
+			if (!ft_use_size(i, opts.sizes_enabled))
+				continue;
+			opts.transfer_size = test_size[i].size;
+			init_test(&opts, test_name, sizeof(test_name));
+			ret = pingpong();
+			if (ret)
+				goto out;
+		}
+	} else {
+		init_test(&opts, test_name, sizeof(test_name));
+		ret = pingpong();
+		if (ret)
+			goto out;
+	}
+
+	ret = ft_finalize();
+out:
+	fi_shutdown(ep, 0);
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" CS_OPTS INFO_OPTS BENCHMARK_OPTS)) !=
+			-1) {
+		switch (op) {
+		default:
+			ft_parse_benchmark_opts(op, optarg);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Ping pong client and server using message endpoints.");
+			ft_benchmark_usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_MSG;
+	hints->caps = FI_MSG;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->domain_attr->threading = FI_THREAD_DOMAIN;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_cntr_pingpong.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_cntr_pingpong.c
new file mode 100644
index 000000000..f2f04255a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_cntr_pingpong.c
@@ -0,0 +1,108 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+
+#include <shared.h>
+#include "benchmark_shared.h"
+
+static int run(void)
+{
+	int i, ret = 0;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	if (!(opts.options & FT_OPT_SIZE)) {
+		for (i = 0; i < TEST_CNT; i++) {
+			if (!ft_use_size(i, opts.sizes_enabled))
+				continue;
+			opts.transfer_size = test_size[i].size;
+			init_test(&opts, test_name, sizeof(test_name));
+			ret = pingpong();
+			if (ret)
+				goto out;
+		}
+	} else {
+		init_test(&opts, test_name, sizeof(test_name));
+		ret = pingpong();
+		if (ret)
+			goto out;
+	}
+
+	ft_finalize();
+out:
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options = FT_OPT_RX_CNTR | FT_OPT_TX_CNTR;
+	opts.comp_method = FT_COMP_SREAD;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" CS_OPTS INFO_OPTS BENCHMARK_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_benchmark_opts(op, optarg);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Ping pong client and server using counters.");
+			ft_benchmark_usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->domain_attr->threading = FI_THREAD_DOMAIN;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_pingpong.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_pingpong.c
new file mode 100644
index 000000000..836a263b1
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_pingpong.c
@@ -0,0 +1,106 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+
+#include "shared.h"
+#include "benchmark_shared.h"
+
+static int run(void)
+{
+	int i, ret = 0;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	if (!(opts.options & FT_OPT_SIZE)) {
+		for (i = 0; i < TEST_CNT; i++) {
+			if (!ft_use_size(i, opts.sizes_enabled))
+				continue;
+			opts.transfer_size = test_size[i].size;
+			init_test(&opts, test_name, sizeof(test_name));
+			ret = pingpong();
+			if (ret)
+				return ret;
+		}
+	} else {
+		init_test(&opts, test_name, sizeof(test_name));
+		ret = pingpong();
+		if (ret)
+			return ret;
+	}
+
+	return ft_finalize();
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" CS_OPTS INFO_OPTS BENCHMARK_OPTS)) !=
+			-1) {
+		switch (op) {
+		default:
+			ft_parse_benchmark_opts(op, optarg);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Ping pong client and server using RDM.");
+			ft_benchmark_usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->domain_attr->threading = FI_THREAD_DOMAIN;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_tagged_bw.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_tagged_bw.c
new file mode 100644
index 000000000..9815a0df1
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_tagged_bw.c
@@ -0,0 +1,113 @@
+/*
+ * Copyright (c) 2013-2016 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+
+#include <shared.h>
+#include "benchmark_shared.h"
+
+static int run(void)
+{
+	int i, ret = 0;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	ret = ft_bw_init();
+	if (ret)
+		return ret;
+
+	if (!(opts.options & FT_OPT_SIZE)) {
+		for (i = 0; i < TEST_CNT; i++) {
+			if (!ft_use_size(i, opts.sizes_enabled))
+				continue;
+			opts.transfer_size = test_size[i].size;
+			init_test(&opts, test_name, sizeof(test_name));
+			ret = bandwidth();
+			if (ret)
+				goto out;
+		}
+	} else {
+		init_test(&opts, test_name, sizeof(test_name));
+		ret = bandwidth();
+		if (ret)
+			goto out;
+	}
+
+	ft_finalize();
+out:
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_BW;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" CS_OPTS INFO_OPTS BENCHMARK_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_benchmark_opts(op, optarg);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Bandwidth test for RDM endpoints using tagged messages.");
+			ft_benchmark_usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->domain_attr->resource_mgmt = FI_RM_ENABLED;
+	hints->caps = FI_TAGGED;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->domain_attr->threading = FI_THREAD_DOMAIN;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_tagged_pingpong.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_tagged_pingpong.c
new file mode 100644
index 000000000..56ca4e854
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rdm_tagged_pingpong.c
@@ -0,0 +1,107 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+
+#include <shared.h>
+#include "benchmark_shared.h"
+
+static int run(void)
+{
+	int i, ret = 0;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	if (!(opts.options & FT_OPT_SIZE)) {
+		for (i = 0; i < TEST_CNT; i++) {
+			if (!ft_use_size(i, opts.sizes_enabled))
+				continue;
+			opts.transfer_size = test_size[i].size;
+			init_test(&opts, test_name, sizeof(test_name));
+			ret = pingpong();
+			if (ret)
+				goto out;
+		}
+	} else {
+		init_test(&opts, test_name, sizeof(test_name));
+		ret = pingpong();
+		if (ret)
+			goto out;
+	}
+
+	ft_finalize();
+out:
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" CS_OPTS INFO_OPTS BENCHMARK_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_benchmark_opts(op, optarg);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Ping pong client and server using tagged messages.");
+			ft_benchmark_usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_TAGGED;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->domain_attr->threading = FI_THREAD_DOMAIN;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rma_bw.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rma_bw.c
new file mode 100644
index 000000000..cf073d507
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/benchmarks/rma_bw.c
@@ -0,0 +1,134 @@
+/*
+ * Copyright (c) 2013-2016 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+
+#include <shared.h>
+#include "benchmark_shared.h"
+
+static int run(void)
+{
+	int i, ret;
+
+	if (hints->ep_attr->type == FI_EP_MSG) {
+		if (!opts.dst_addr) {
+			ret = ft_start_server();
+			if (ret)
+				return ret;
+		}
+
+		ret = opts.dst_addr ? ft_client_connect() : ft_server_connect();
+	} else {
+		ret = ft_init_fabric();
+	}
+	if (ret)
+		return ret;
+
+	ret = ft_bw_init();
+	if (ret)
+		return ret;
+
+	ret = ft_exchange_keys(&remote);
+	if (ret)
+		return ret;
+
+	if (!(opts.options & FT_OPT_SIZE)) {
+		for (i = 0; i < TEST_CNT; i++) {
+			if (!ft_use_size(i, opts.sizes_enabled))
+				continue;
+			opts.transfer_size = test_size[i].size;
+			init_test(&opts, test_name, sizeof(test_name));
+			ret = bandwidth_rma(opts.rma_op, &remote);
+			if (ret)
+				goto out;
+		}
+	} else {
+		init_test(&opts, test_name, sizeof(test_name));
+		ret = bandwidth_rma(opts.rma_op, &remote);
+		if (ret)
+			goto out;
+	}
+
+	ft_finalize();
+out:
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_BW;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	hints->caps = FI_MSG | FI_RMA;
+	hints->domain_attr->resource_mgmt = FI_RM_ENABLED;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->domain_attr->threading = FI_THREAD_DOMAIN;
+
+	while ((op = getopt(argc, argv, "ho:" CS_OPTS INFO_OPTS BENCHMARK_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_benchmark_opts(op, optarg);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			ret = ft_parse_rma_opts(op, optarg, hints, &opts);
+			if (ret)
+				return ret;
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Bandwidth test using RMA operations.");
+			ft_benchmark_usage();
+			FT_PRINT_OPTS_USAGE("-o <op>", "rma op type: read|write|"
+					"writedata (default: write)\n");
+			fprintf(stderr, "Note: read/write bw tests are bidirectional.\n"
+					"      writedata bw test is unidirectional"
+					" from the client side.\n");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	ret = run();
+
+	ft_free_res();
+	return -ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/jsmn.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/jsmn.c
new file mode 100644
index 000000000..9fe0fb4d4
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/jsmn.c
@@ -0,0 +1,333 @@
+/*
+ * Copyright (c) 2010 Serge A. Zaitsev
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#include <stdlib.h>
+
+#include "jsmn.h"
+
+/**
+ * Allocates a fresh unused token from the token pull.
+ */
+static jsmntok_t *jsmn_alloc_token(jsmn_parser *parser,
+		jsmntok_t *tokens, size_t num_tokens) {
+	jsmntok_t *tok;
+	if (parser->toknext >= num_tokens) {
+		return NULL;
+	}
+	tok = &tokens[parser->toknext++];
+	tok->start = tok->end = -1;
+	tok->size = 0;
+#ifdef JSMN_PARENT_LINKS
+	tok->parent = -1;
+#endif
+	return tok;
+}
+
+/**
+ * Fills token type and boundaries.
+ */
+static void jsmn_fill_token(jsmntok_t *token, jsmntype_t type,
+                            int start, int end) {
+	token->type = type;
+	token->start = start;
+	token->end = end;
+	token->size = 0;
+}
+
+/**
+ * Fills next available token with JSON primitive.
+ */
+static jsmnerr_t jsmn_parse_primitive(jsmn_parser *parser, const char *js,
+		size_t len, jsmntok_t *tokens, size_t num_tokens) {
+	jsmntok_t *token;
+	int start;
+
+	start = parser->pos;
+
+	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
+		switch (js[parser->pos]) {
+#ifndef JSMN_STRICT
+			/* In strict mode primitive must be followed by "," or "}" or "]" */
+			case ':':
+#endif
+			case '\t' : case '\r' : case '\n' : case ' ' :
+			case ','  : case ']'  : case '}' :
+				goto found;
+		}
+		if (js[parser->pos] < 32 || js[parser->pos] >= 127) {
+			parser->pos = start;
+			return JSMN_ERROR_INVAL;
+		}
+	}
+#ifdef JSMN_STRICT
+	/* In strict mode primitive must be followed by a comma/object/array */
+	parser->pos = start;
+	return JSMN_ERROR_PART;
+#endif
+
+found:
+	if (tokens == NULL) {
+		parser->pos--;
+		return 0;
+	}
+	token = jsmn_alloc_token(parser, tokens, num_tokens);
+	if (token == NULL) {
+		parser->pos = start;
+		return JSMN_ERROR_NOMEM;
+	}
+	jsmn_fill_token(token, JSMN_PRIMITIVE, start, parser->pos);
+#ifdef JSMN_PARENT_LINKS
+	token->parent = parser->toksuper;
+#endif
+	parser->pos--;
+	return 0;
+}
+
+/**
+ * Filsl next token with JSON string.
+ */
+static jsmnerr_t jsmn_parse_string(jsmn_parser *parser, const char *js,
+		size_t len, jsmntok_t *tokens, size_t num_tokens) {
+	jsmntok_t *token;
+
+	int start = parser->pos;
+
+	parser->pos++;
+
+	/* Skip starting quote */
+	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
+		char c = js[parser->pos];
+
+		/* Quote: end of string */
+		if (c == '\"') {
+			if (tokens == NULL) {
+				return 0;
+			}
+			token = jsmn_alloc_token(parser, tokens, num_tokens);
+			if (token == NULL) {
+				parser->pos = start;
+				return JSMN_ERROR_NOMEM;
+			}
+			jsmn_fill_token(token, JSMN_STRING, start+1, parser->pos);
+#ifdef JSMN_PARENT_LINKS
+			token->parent = parser->toksuper;
+#endif
+			return 0;
+		}
+
+		/* Backslash: Quoted symbol expected */
+		if (c == '\\' && parser->pos + 1 < len) {
+			int i;
+			parser->pos++;
+			switch (js[parser->pos]) {
+				/* Allowed escaped symbols */
+				case '\"': case '/' : case '\\' : case 'b' :
+				case 'f' : case 'r' : case 'n'  : case 't' :
+					break;
+				/* Allows escaped symbol \uXXXX */
+				case 'u':
+					parser->pos++;
+					for(i = 0; i < 4 && parser->pos < len && js[parser->pos] != '\0'; i++) {
+						/* If it isn't a hex character we have an error */
+						if(!((js[parser->pos] >= 48 && js[parser->pos] <= 57) || /* 0-9 */
+									(js[parser->pos] >= 65 && js[parser->pos] <= 70) || /* A-F */
+									(js[parser->pos] >= 97 && js[parser->pos] <= 102))) { /* a-f */
+							parser->pos = start;
+							return JSMN_ERROR_INVAL;
+						}
+						parser->pos++;
+					}
+					parser->pos--;
+					break;
+				/* Unexpected symbol */
+				default:
+					parser->pos = start;
+					return JSMN_ERROR_INVAL;
+			}
+		}
+	}
+	parser->pos = start;
+	return JSMN_ERROR_PART;
+}
+
+/**
+ * Parse JSON string and fill tokens.
+ */
+jsmnerr_t jsmn_parse(jsmn_parser *parser, const char *js, size_t len,
+		jsmntok_t *tokens, unsigned int num_tokens) {
+	jsmnerr_t r;
+	int i;
+	jsmntok_t *token;
+	int count = 0;
+
+	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
+		char c;
+		jsmntype_t type;
+
+		c = js[parser->pos];
+		switch (c) {
+			case '{': case '[':
+				count++;
+				if (tokens == NULL) {
+					break;
+				}
+				token = jsmn_alloc_token(parser, tokens, num_tokens);
+				if (token == NULL)
+					return JSMN_ERROR_NOMEM;
+				if (parser->toksuper != -1) {
+					tokens[parser->toksuper].size++;
+#ifdef JSMN_PARENT_LINKS
+					token->parent = parser->toksuper;
+#endif
+				}
+				token->type = (c == '{' ? JSMN_OBJECT : JSMN_ARRAY);
+				token->start = parser->pos;
+				parser->toksuper = parser->toknext - 1;
+				break;
+			case '}': case ']':
+				if (tokens == NULL)
+					break;
+				type = (c == '}' ? JSMN_OBJECT : JSMN_ARRAY);
+#ifdef JSMN_PARENT_LINKS
+				if (parser->toknext < 1) {
+					return JSMN_ERROR_INVAL;
+				}
+				token = &tokens[parser->toknext - 1];
+				for (;;) {
+					if (token->start != -1 && token->end == -1) {
+						if (token->type != type) {
+							return JSMN_ERROR_INVAL;
+						}
+						token->end = parser->pos + 1;
+						parser->toksuper = token->parent;
+						break;
+					}
+					if (token->parent == -1) {
+						break;
+					}
+					token = &tokens[token->parent];
+				}
+#else
+				for (i = parser->toknext - 1; i >= 0; i--) {
+					token = &tokens[i];
+					if (token->start != -1 && token->end == -1) {
+						if (token->type != type) {
+							return JSMN_ERROR_INVAL;
+						}
+						parser->toksuper = -1;
+						token->end = parser->pos + 1;
+						break;
+					}
+				}
+				/* Error if unmatched closing bracket */
+				if (i == -1) return JSMN_ERROR_INVAL;
+				for (; i >= 0; i--) {
+					token = &tokens[i];
+					if (token->start != -1 && token->end == -1) {
+						parser->toksuper = i;
+						break;
+					}
+				}
+#endif
+				break;
+			case '\"':
+				r = jsmn_parse_string(parser, js, len, tokens, num_tokens);
+				if (r < 0) return r;
+				count++;
+				if (parser->toksuper != -1 && tokens != NULL)
+					tokens[parser->toksuper].size++;
+				break;
+			case '\t' : case '\r' : case '\n' : case ' ':
+				break;
+			case ':':
+				parser->toksuper = parser->toknext - 1;
+				break;
+			case ',':
+				if (tokens != NULL &&
+						tokens[parser->toksuper].type != JSMN_ARRAY &&
+						tokens[parser->toksuper].type != JSMN_OBJECT) {
+#ifdef JSMN_PARENT_LINKS
+					parser->toksuper = tokens[parser->toksuper].parent;
+#else
+					for (i = parser->toknext - 1; i >= 0; i--) {
+						if (tokens[i].type == JSMN_ARRAY || tokens[i].type == JSMN_OBJECT) {
+							if (tokens[i].start != -1 && tokens[i].end == -1) {
+								parser->toksuper = i;
+								break;
+							}
+						}
+					}
+#endif
+				}
+				break;
+#ifdef JSMN_STRICT
+			/* In strict mode primitives are: numbers and booleans */
+			case '-': case '0': case '1' : case '2': case '3' : case '4':
+			case '5': case '6': case '7' : case '8': case '9':
+			case 't': case 'f': case 'n' :
+				/* And they must not be keys of the object */
+				if (tokens != NULL) {
+					jsmntok_t *t = &tokens[parser->toksuper];
+					if (t->type == JSMN_OBJECT ||
+							(t->type == JSMN_STRING && t->size != 0)) {
+						return JSMN_ERROR_INVAL;
+					}
+				}
+#else
+			/* In non-strict mode every unquoted value is a primitive */
+			default:
+#endif
+				r = jsmn_parse_primitive(parser, js, len, tokens, num_tokens);
+				if (r < 0) return r;
+				count++;
+				if (parser->toksuper != -1 && tokens != NULL)
+					tokens[parser->toksuper].size++;
+				break;
+
+#ifdef JSMN_STRICT
+			/* Unexpected char in strict mode */
+			default:
+				return JSMN_ERROR_INVAL;
+#endif
+		}
+	}
+
+	for (i = parser->toknext - 1; i >= 0; i--) {
+		/* Unmatched opened object or array */
+		if (tokens && tokens[i].start != -1 && tokens[i].end == -1) {
+			return JSMN_ERROR_PART;
+		}
+	}
+
+	return count;
+}
+
+/**
+ * Creates a new parser based over a given  buffer with an array of tokens
+ * available.
+ */
+void jsmn_init(jsmn_parser *parser) {
+	parser->pos = 0;
+	parser->toknext = 0;
+	parser->toksuper = -1;
+}
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/osx/osd.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/osx/osd.c
new file mode 100644
index 000000000..e9f70f0a9
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/osx/osd.c
@@ -0,0 +1,55 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016, Cisco Systems, Inc. All rights reserved.
+ * Copyright (c) 2015 Los Alamos Nat. Security, LLC. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "osx/osd.h"
+#include "config.h"
+
+/* clock_gettime() does not exist on OS X before the mac OS Sierra release. If
+ * the symbol is not already defined, then define a workaround using
+ * gettimeofday. Ignore the clk_id that is passed in and always return the
+ * system clock time.
+ */
+#if !HAVE_CLOCK_GETTIME
+int clock_gettime(clockid_t clk_id, struct timespec *tp) {
+	int retval;
+	struct timeval tv;
+
+	retval = gettimeofday(&tv, NULL);
+
+	tp->tv_sec = tv.tv_sec;
+	tp->tv_nsec = tv.tv_usec * 1000;
+
+	return retval;
+}
+#endif
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/shared.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/shared.c
new file mode 100644
index 000000000..9dc580466
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/shared.c
@@ -0,0 +1,3191 @@
+/*
+ * Copyright (c) 2013-2018 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016 Cray Inc.  All rights reserved.
+ * Copyright (c) 2014-2017, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <assert.h>
+#include <netdb.h>
+#include <poll.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <unistd.h>
+#include <sys/wait.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+
+#include <rdma/fi_cm.h>
+#include <rdma/fi_domain.h>
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_tagged.h>
+#include <rdma/fi_atomic.h>
+
+#include <shared.h>
+
+struct fi_info *fi_pep, *fi, *hints;
+struct fid_fabric *fabric;
+struct fid_wait *waitset;
+struct fid_domain *domain;
+struct fid_poll *pollset;
+struct fid_pep *pep;
+struct fid_ep *ep, *alias_ep;
+struct fid_cq *txcq, *rxcq;
+struct fid_cntr *txcntr, *rxcntr;
+struct fid_mr *mr;
+void *mr_desc = NULL;
+struct fid_av *av;
+struct fid_eq *eq;
+struct fid_mc *mc;
+
+struct fid_mr no_mr;
+struct fi_context tx_ctx, rx_ctx;
+struct fi_context *tx_ctx_arr = NULL, *rx_ctx_arr = NULL;
+uint64_t remote_cq_data = 0;
+
+uint64_t tx_seq, rx_seq, tx_cq_cntr, rx_cq_cntr;
+int (*ft_mr_alloc_func)(void);
+uint64_t ft_tag = 0;
+int ft_parent_proc = 0;
+pid_t ft_child_pid = 0;
+int ft_socket_pair[2];
+
+fi_addr_t remote_fi_addr = FI_ADDR_UNSPEC;
+char *buf, *tx_buf, *rx_buf;
+size_t buf_size, tx_size, rx_size;
+int rx_fd = -1, tx_fd = -1;
+char default_port[8] = "9228";
+static char default_oob_port[8] = "3000";
+const char *greeting = "Hello from Client!";
+
+
+char test_name[50] = "custom";
+int timeout = -1;
+struct timespec start, end;
+
+int listen_sock = -1;
+int sock = -1;
+int oob_sock = -1;
+
+struct fi_av_attr av_attr = {
+	.type = FI_AV_MAP,
+	.count = 1
+};
+struct fi_eq_attr eq_attr = {
+	.wait_obj = FI_WAIT_UNSPEC
+};
+struct fi_cq_attr cq_attr = {
+	.wait_obj = FI_WAIT_NONE
+};
+struct fi_cntr_attr cntr_attr = {
+	.events = FI_CNTR_EVENTS_COMP,
+	.wait_obj = FI_WAIT_NONE
+};
+
+struct fi_rma_iov remote;
+
+struct ft_opts opts;
+
+struct test_size_param test_size[] = {
+	{ 1 <<  0, 0 },
+	{ 1 <<  1, 0 }, { (1 <<  1) + (1 <<  0), 0 },
+	{ 1 <<  2, 0 }, { (1 <<  2) + (1 <<  1), 0 },
+	{ 1 <<  3, 0 }, { (1 <<  3) + (1 <<  2), 0 },
+	{ 1 <<  4, 0 }, { (1 <<  4) + (1 <<  3), 0 },
+	{ 1 <<  5, 0 }, { (1 <<  5) + (1 <<  4), 0 },
+	{ 1 <<  6, FT_DEFAULT_SIZE }, { (1 <<  6) + (1 <<  5), 0 },
+	{ 1 <<  7, 0 }, { (1 <<  7) + (1 <<  6), 0 },
+	{ 1 <<  8, FT_DEFAULT_SIZE }, { (1 <<  8) + (1 <<  7), 0 },
+	{ 1 <<  9, 0 }, { (1 <<  9) + (1 <<  8), 0 },
+	{ 1 << 10, FT_DEFAULT_SIZE }, { (1 << 10) + (1 <<  9), 0 },
+	{ 1 << 11, 0 }, { (1 << 11) + (1 << 10), 0 },
+	{ 1 << 12, FT_DEFAULT_SIZE }, { (1 << 12) + (1 << 11), 0 },
+	{ 1 << 13, 0 }, { (1 << 13) + (1 << 12), 0 },
+	{ 1 << 14, 0 }, { (1 << 14) + (1 << 13), 0 },
+	{ 1 << 15, 0 }, { (1 << 15) + (1 << 14), 0 },
+	{ 1 << 16, FT_DEFAULT_SIZE }, { (1 << 16) + (1 << 15), 0 },
+	{ 1 << 17, 0 }, { (1 << 17) + (1 << 16), 0 },
+	{ 1 << 18, 0 }, { (1 << 18) + (1 << 17), 0 },
+	{ 1 << 19, 0 }, { (1 << 19) + (1 << 18), 0 },
+	{ 1 << 20, FT_DEFAULT_SIZE }, { (1 << 20) + (1 << 19), 0 },
+	{ 1 << 21, 0 }, { (1 << 21) + (1 << 20), 0 },
+	{ 1 << 22, 0 }, { (1 << 22) + (1 << 21), 0 },
+	{ 1 << 23, 0 },
+};
+
+const unsigned int test_cnt = (sizeof test_size / sizeof test_size[0]);
+
+#define INTEG_SEED 7
+static const char integ_alphabet[] = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";
+static const int integ_alphabet_length = (sizeof(integ_alphabet)/sizeof(*integ_alphabet)) - 1;
+
+
+static int ft_poll_fd(int fd, int timeout)
+{
+	struct pollfd fds;
+	int ret;
+
+	fds.fd = fd;
+	fds.events = POLLIN;
+	ret = poll(&fds, 1, timeout);
+	if (ret == -1) {
+		FT_PRINTERR("poll", -errno);
+		ret = -errno;
+	} else if (!ret) {
+		ret = -FI_EAGAIN;
+	} else {
+		ret = 0;
+	}
+	return ret;
+}
+
+size_t ft_tx_prefix_size(void)
+{
+	return (fi->tx_attr->mode & FI_MSG_PREFIX) ?
+		fi->ep_attr->msg_prefix_size : 0;
+}
+
+size_t ft_rx_prefix_size(void)
+{
+	return (fi->rx_attr->mode & FI_MSG_PREFIX) ?
+		fi->ep_attr->msg_prefix_size : 0;
+}
+
+int ft_check_opts(uint64_t flags)
+{
+	return (opts.options & flags) == flags;
+}
+
+static void ft_cq_set_wait_attr(void)
+{
+	switch (opts.comp_method) {
+	case FT_COMP_SREAD:
+		cq_attr.wait_obj = FI_WAIT_UNSPEC;
+		cq_attr.wait_cond = FI_CQ_COND_NONE;
+		break;
+	case FT_COMP_WAITSET:
+		assert(waitset);
+		cq_attr.wait_obj = FI_WAIT_SET;
+		cq_attr.wait_cond = FI_CQ_COND_NONE;
+		cq_attr.wait_set = waitset;
+		break;
+	case FT_COMP_WAIT_FD:
+		cq_attr.wait_obj = FI_WAIT_FD;
+		cq_attr.wait_cond = FI_CQ_COND_NONE;
+		break;
+	default:
+		cq_attr.wait_obj = FI_WAIT_NONE;
+		break;
+	}
+}
+
+static void ft_cntr_set_wait_attr(void)
+{
+	switch (opts.comp_method) {
+	case FT_COMP_SREAD:
+		cntr_attr.wait_obj = FI_WAIT_UNSPEC;
+		break;
+	case FT_COMP_WAITSET:
+		assert(waitset);
+		cntr_attr.wait_obj = FI_WAIT_SET;
+		break;
+	case FT_COMP_WAIT_FD:
+		cntr_attr.wait_obj = FI_WAIT_FD;
+		break;
+	default:
+		cntr_attr.wait_obj = FI_WAIT_NONE;
+		break;
+	}
+}
+
+int ft_cntr_open(struct fid_cntr **cntr)
+{
+	ft_cntr_set_wait_attr();
+	return fi_cntr_open(domain, &cntr_attr, cntr, cntr);
+}
+
+static inline int ft_rma_read_target_allowed(uint64_t caps)
+{
+	if (caps & (FI_RMA | FI_ATOMIC)) {
+		if (caps & FI_REMOTE_READ)
+			return 1;
+		return !(caps & (FI_READ | FI_WRITE | FI_REMOTE_WRITE));
+	}
+	return 0;
+}
+
+static inline int ft_rma_write_target_allowed(uint64_t caps)
+{
+	if (caps & (FI_RMA | FI_ATOMIC)) {
+		if (caps & FI_REMOTE_WRITE)
+			return 1;
+		return !(caps & (FI_READ | FI_WRITE | FI_REMOTE_WRITE));
+	}
+	return 0;
+}
+
+static inline int ft_check_mr_local_flag(struct fi_info *info)
+{
+	return ((info->mode & FI_LOCAL_MR) ||
+		(info->domain_attr->mr_mode & FI_MR_LOCAL));
+}
+
+uint64_t ft_info_to_mr_access(struct fi_info *info)
+{
+	uint64_t mr_access = 0;
+	if (ft_check_mr_local_flag(info)) {
+		if (info->caps & (FI_MSG | FI_TAGGED)) {
+			if (info->caps & FT_MSG_MR_ACCESS) {
+				mr_access |= info->caps & FT_MSG_MR_ACCESS;
+			} else {
+				mr_access |= FT_MSG_MR_ACCESS;
+			}
+		}
+
+		if (info->caps & (FI_RMA | FI_ATOMIC)) {
+			if (info->caps & FT_RMA_MR_ACCESS) {
+				mr_access |= info->caps & FT_RMA_MR_ACCESS;
+			} else	{
+				mr_access |= FT_RMA_MR_ACCESS;
+			}
+		}
+	} else {
+		if (info->caps & (FI_RMA | FI_ATOMIC)) {
+			if (ft_rma_read_target_allowed(info->caps)) {
+				mr_access |= FI_REMOTE_READ;
+			}
+			if (ft_rma_write_target_allowed(info->caps)) {
+				mr_access |= FI_REMOTE_WRITE;
+			}
+		}
+	}
+	return mr_access;
+}
+
+#define bit_isset(x, i) (x >> i & 1)
+#define for_each_bit(x, i) for (i = 0; i < (8 * sizeof(x)); i++)
+
+static inline int bit_set_count(uint64_t val)
+{
+	int cnt = 0;
+	while (val) {
+		cnt++;
+		val &= val - 1;
+	}
+	return cnt;
+}
+
+int ft_alloc_bit_combo(uint64_t fixed, uint64_t opt,
+		       uint64_t **combos, int *len)
+{
+	uint64_t *flags;
+	int i, num_flags;
+	uint64_t index;
+	int ret;
+
+	num_flags = bit_set_count(opt) + 1;
+	flags = calloc(num_flags, sizeof(fixed));
+	if (!flags) {
+		perror("calloc");
+		return -FI_ENOMEM;
+	}
+
+	*len = 1 << (num_flags - 1);
+	*combos = calloc(*len, sizeof(fixed));
+	if (!(*combos)) {
+		perror("calloc");
+		ret = -FI_ENOMEM;
+		goto clean;
+	}
+
+	num_flags = 0;
+	for_each_bit(opt, i) {
+		if (bit_isset(opt, i))
+			flags[num_flags++] = 1ULL << i;
+	}
+
+	for (index = 0; index < (*len); index++) {
+		(*combos)[index] = fixed;
+		for_each_bit(index, i) {
+			if (bit_isset(index, i))
+				(*combos)[index] |= flags[i];
+		}
+	}
+	ret = FI_SUCCESS;
+
+clean:
+	free(flags);
+	return ret;
+}
+
+void ft_free_bit_combo(uint64_t *combo)
+{
+	free(combo);
+}
+
+/*
+ * Include FI_MSG_PREFIX space in the allocated buffer, and ensure that the
+ * buffer is large enough for a control message used to exchange addressing
+ * data.
+ */
+static int ft_alloc_msgs(void)
+{
+	int ret;
+	long alignment = 1;
+
+	if (ft_check_opts(FT_OPT_SKIP_MSG_ALLOC))
+		return 0;
+
+	tx_size = opts.options & FT_OPT_SIZE ?
+		  opts.transfer_size : test_size[TEST_CNT - 1].size;
+	if (tx_size > fi->ep_attr->max_msg_size)
+		tx_size = fi->ep_attr->max_msg_size;
+	rx_size = tx_size + ft_rx_prefix_size();
+	tx_size += ft_tx_prefix_size();
+	buf_size = MAX(tx_size, FT_MAX_CTRL_MSG) + MAX(rx_size, FT_MAX_CTRL_MSG);
+
+	if (opts.options & FT_OPT_ALIGN) {
+		alignment = sysconf(_SC_PAGESIZE);
+		if (alignment < 0)
+			return -errno;
+		buf_size += alignment;
+
+		ret = posix_memalign((void **) &buf, (size_t) alignment,
+				buf_size);
+		if (ret) {
+			FT_PRINTERR("posix_memalign", ret);
+			return ret;
+		}
+	} else {
+		buf = malloc(buf_size);
+		if (!buf) {
+			perror("malloc");
+			return -FI_ENOMEM;
+		}
+	}
+	memset(buf, 0, buf_size);
+	rx_buf = buf;
+	tx_buf = (char *) buf + MAX(rx_size, FT_MAX_CTRL_MSG);
+	tx_buf = (void *) (((uintptr_t) tx_buf + alignment - 1) &
+			   ~(alignment - 1));
+
+	remote_cq_data = ft_init_cq_data(fi);
+
+	if (!ft_mr_alloc_func && !ft_check_opts(FT_OPT_SKIP_REG_MR) &&
+	    ((fi->domain_attr->mr_mode & FI_MR_LOCAL) ||
+	     (fi->caps & (FI_RMA | FI_ATOMIC)))) {
+		ret = fi_mr_reg(domain, buf, buf_size, ft_info_to_mr_access(fi),
+				0, FT_MR_KEY, 0, &mr, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_mr_reg", ret);
+			return ret;
+		}
+		mr_desc = ft_check_mr_local_flag(fi) ? fi_mr_desc(mr) : NULL;
+	} else {
+		if (ft_mr_alloc_func) {
+			assert(!ft_check_opts(FT_OPT_SKIP_REG_MR));
+			ret = ft_mr_alloc_func();
+			if (ret)
+				return ret;
+		}
+		mr = &no_mr;
+	}
+
+	return 0;
+}
+
+int ft_open_fabric_res(void)
+{
+	int ret;
+
+	ret = fi_fabric(fi->fabric_attr, &fabric, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_fabric", ret);
+		return ret;
+	}
+
+	ret = fi_eq_open(fabric, &eq_attr, &eq, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_eq_open", ret);
+		return ret;
+	}
+
+	ret = fi_domain(fabric, fi, &domain, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_domain", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+int ft_alloc_ep_res(struct fi_info *fi)
+{
+	int ret;
+
+	ret = ft_alloc_msgs();
+	if (ret)
+		return ret;
+
+	if (cq_attr.format == FI_CQ_FORMAT_UNSPEC) {
+		if (fi->caps & FI_TAGGED)
+			cq_attr.format = FI_CQ_FORMAT_TAGGED;
+		else
+			cq_attr.format = FI_CQ_FORMAT_CONTEXT;
+	}
+
+	if (opts.options & FT_OPT_CQ_SHARED) {
+		ft_cq_set_wait_attr();
+		cq_attr.size = 0;
+
+		if (opts.tx_cq_size)
+			cq_attr.size += opts.tx_cq_size;
+		else
+			cq_attr.size += fi->tx_attr->size;
+
+		if (opts.rx_cq_size)
+			cq_attr.size += opts.rx_cq_size;
+		else
+			cq_attr.size += fi->rx_attr->size;
+
+		ret = fi_cq_open(domain, &cq_attr, &txcq, &txcq);
+		if (ret) {
+			FT_PRINTERR("fi_cq_open", ret);
+			return ret;
+		}
+		rxcq = txcq;
+	}
+
+	if (!(opts.options & FT_OPT_CQ_SHARED)) {
+		ft_cq_set_wait_attr();
+		if (opts.tx_cq_size)
+			cq_attr.size = opts.tx_cq_size;
+		else
+			cq_attr.size = fi->tx_attr->size;
+
+		ret = fi_cq_open(domain, &cq_attr, &txcq, &txcq);
+		if (ret) {
+			FT_PRINTERR("fi_cq_open", ret);
+			return ret;
+		}
+	}
+
+	if (opts.options & FT_OPT_TX_CNTR) {
+		ret = ft_cntr_open(&txcntr);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_open", ret);
+			return ret;
+		}
+	}
+
+	if (!(opts.options & FT_OPT_CQ_SHARED)) {
+		ft_cq_set_wait_attr();
+		if (opts.rx_cq_size)
+			cq_attr.size = opts.rx_cq_size;
+		else
+			cq_attr.size = fi->rx_attr->size;
+
+		ret = fi_cq_open(domain, &cq_attr, &rxcq, &rxcq);
+		if (ret) {
+			FT_PRINTERR("fi_cq_open", ret);
+			return ret;
+		}
+	}
+
+	if (opts.options & FT_OPT_RX_CNTR) {
+		ret = ft_cntr_open(&rxcntr);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_open", ret);
+			return ret;
+		}
+	}
+
+	if (fi->ep_attr->type == FI_EP_RDM || fi->ep_attr->type == FI_EP_DGRAM) {
+		if (fi->domain_attr->av_type != FI_AV_UNSPEC)
+			av_attr.type = fi->domain_attr->av_type;
+
+		if (opts.av_name) {
+			av_attr.name = opts.av_name;
+		}
+		av_attr.count = opts.av_size;
+		ret = fi_av_open(domain, &av_attr, &av, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_av_open", ret);
+			return ret;
+		}
+	}
+	return 0;
+}
+
+int ft_alloc_active_res(struct fi_info *fi)
+{
+	int ret;
+	ret = ft_alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	ret = fi_endpoint(domain, fi, &ep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static void ft_init(void)
+{
+	tx_seq = 0;
+	rx_seq = 0;
+	tx_cq_cntr = 0;
+	rx_cq_cntr = 0;
+}
+
+static int ft_init_oob(void)
+{
+	int ret, op, err;
+	struct addrinfo *ai = NULL;
+
+	if (!(opts.options & FT_OPT_OOB_SYNC) || oob_sock != -1)
+		return 0;
+
+	if (!opts.oob_port)
+		opts.oob_port = default_oob_port;
+
+	if (!opts.dst_addr) {
+		ret = ft_sock_listen(opts.src_addr, opts.oob_port);
+		if (ret)
+			return ret;
+
+		oob_sock = accept(listen_sock, NULL, 0);
+		if (oob_sock < 0) {
+			perror("accept");
+			ret = oob_sock;
+			return ret;
+		}
+
+		close(listen_sock);
+	} else {
+
+		ret = getaddrinfo(opts.dst_addr, opts.oob_port, NULL, &ai);
+		if (ret) {
+			perror("getaddrinfo");
+			return ret;
+		}
+
+		oob_sock = socket(ai->ai_family, SOCK_STREAM, 0);
+		if (oob_sock < 0) {
+			perror("socket");
+			ret = oob_sock;
+			goto free;
+		}
+
+		ret = connect(oob_sock, ai->ai_addr, ai->ai_addrlen);
+		if (ret) {
+			perror("connect");
+			close(oob_sock);
+			goto free;
+		}
+		sleep(1);
+	}
+
+	op = 1;
+	err = setsockopt(oob_sock, IPPROTO_TCP, TCP_NODELAY,
+			 (void *) &op, sizeof(op));
+	if (err)
+		perror("setsockopt"); /* non-fatal error */
+
+free:
+	if (ai)
+		freeaddrinfo(ai);
+	return ret;
+}
+
+int ft_getinfo(struct fi_info *hints, struct fi_info **info)
+{
+	char *node, *service;
+	uint64_t flags = 0;
+	int ret;
+
+	ret = ft_read_addr_opts(&node, &service, hints, &flags, &opts);
+	if (ret)
+		return ret;
+
+	if (!hints->ep_attr->type)
+		hints->ep_attr->type = FI_EP_RDM;
+
+	ret = fi_getinfo(FT_FIVERSION, node, service, flags, hints, info);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		return ret;
+	}
+
+	if (!ft_check_prefix_forced(*info, &opts)) {
+		FT_ERR("Provider disabled requested prefix mode.");
+		return -FI_ENODATA;
+	}
+
+	return 0;
+}
+
+int ft_init_fabric_cm(void)
+{
+	int ret;
+	if (!opts.dst_addr) {
+		ret = ft_start_server();
+		if (ret)
+			return ret;
+	}
+
+	ret = opts.dst_addr ? ft_client_connect() : ft_server_connect();
+
+	return ret;
+}
+
+int ft_start_server(void)
+{
+	int ret;
+
+	ft_init();
+	ret = ft_init_oob();
+	if (ret)
+		return ret;
+
+	ret = ft_getinfo(hints, &fi_pep);
+	if (ret)
+		return ret;
+
+	ret = fi_fabric(fi_pep->fabric_attr, &fabric, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_fabric", ret);
+		return ret;
+	}
+
+	ret = fi_eq_open(fabric, &eq_attr, &eq, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_eq_open", ret);
+		return ret;
+	}
+
+	ret = fi_passive_ep(fabric, fi_pep, &pep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_passive_ep", ret);
+		return ret;
+	}
+
+	ret = fi_pep_bind(pep, &eq->fid, 0);
+	if (ret) {
+		FT_PRINTERR("fi_pep_bind", ret);
+		return ret;
+	}
+
+	ret = fi_listen(pep);
+	if (ret) {
+		FT_PRINTERR("fi_listen", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+int ft_complete_connect(struct fid_ep *ep, struct fid_eq *eq)
+{
+	struct fi_eq_cm_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int ret;
+
+	rd = fi_eq_sread(eq, &event, &entry, sizeof(entry), -1, 0);
+	if (rd != sizeof(entry)) {
+		FT_PROCESS_EQ_ERR(rd, eq, "fi_eq_sread", "accept");
+		ret = (int) rd;
+		return ret;
+	}
+
+	if (event != FI_CONNECTED || entry.fid != &ep->fid) {
+		fprintf(stderr, "Unexpected CM event %d fid %p (ep %p)\n",
+			event, entry.fid, ep);
+		ret = -FI_EOTHER;
+		return ret;
+	}
+
+	return 0;
+}
+
+int ft_retrieve_conn_req(struct fid_eq *eq, struct fi_info **fi)
+{
+	struct fi_eq_cm_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int ret;
+
+	rd = fi_eq_sread(eq, &event, &entry, sizeof(entry), -1, 0);
+	if (rd != sizeof entry) {
+		FT_PROCESS_EQ_ERR(rd, eq, "fi_eq_sread", "listen");
+		return (int) rd;
+	}
+
+	*fi = entry.info;
+	if (event != FI_CONNREQ) {
+		fprintf(stderr, "Unexpected CM event %d\n", event);
+		ret = -FI_EOTHER;
+		return ret;
+	}
+
+	return 0;
+}
+
+int ft_accept_connection(struct fid_ep *ep, struct fid_eq *eq)
+{
+	int ret;
+
+	ret = fi_accept(ep, NULL, 0);
+	if (ret) {
+		FT_PRINTERR("fi_accept", ret);
+		return ret;
+	}
+
+	ret = ft_complete_connect(ep, eq);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int ft_server_connect(void)
+{
+	int ret;
+
+	ret = ft_retrieve_conn_req(eq, &fi);
+	if (ret)
+		goto err;
+
+	ret = fi_domain(fabric, fi, &domain, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_domain", ret);
+		goto err;
+	}
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		goto err;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		goto err;
+
+	ret = ft_accept_connection(ep, eq);
+	if (ret)
+		goto err;
+
+	return 0;
+
+err:
+	fi_reject(pep, fi->handle, NULL, 0);
+	return ret;
+}
+
+int ft_connect_ep(struct fid_ep *ep,
+		struct fid_eq *eq, fi_addr_t *remote_addr)
+{
+	int ret;
+
+	ret = fi_connect(ep, remote_addr, NULL, 0);
+	if (ret) {
+		FT_PRINTERR("fi_connect", ret);
+		return ret;
+	}
+
+	ret = ft_complete_connect(ep, eq);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int ft_client_connect(void)
+{
+	int ret;
+
+	ft_init();
+	ret = ft_init_oob();
+	if (ret)
+		return ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	ret = ft_connect_ep(ep, eq, fi->dest_addr);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int ft_init_fabric(void)
+{
+	int ret;
+
+	ft_init();
+	ret = ft_init_oob();
+	if (ret)
+		return ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	ret = ft_init_av();
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int ft_get_cq_fd(struct fid_cq *cq, int *fd)
+{
+	int ret = FI_SUCCESS;
+
+	if (cq && opts.comp_method == FT_COMP_WAIT_FD) {
+		ret = fi_control(&cq->fid, FI_GETWAIT, fd);
+		if (ret)
+			FT_PRINTERR("fi_control(FI_GETWAIT)", ret);
+	}
+
+	return ret;
+}
+
+int ft_init_alias_ep(uint64_t flags)
+{
+	int ret;
+	ret = fi_ep_alias(ep, &alias_ep, flags);
+	if (ret) {
+		FT_PRINTERR("fi_ep_alias", ret);
+		return ret;
+	}
+	return 0;
+}
+
+int ft_enable_ep(struct fid_ep *ep, struct fid_eq *eq, struct fid_av *av,
+		 struct fid_cq *txcq, struct fid_cq *rxcq,
+		 struct fid_cntr *txcntr, struct fid_cntr *rxcntr)
+{
+	uint64_t flags;
+	int ret;
+
+	if (fi->ep_attr->type == FI_EP_MSG || fi->caps & FI_MULTICAST)
+		FT_EP_BIND(ep, eq, 0);
+
+	FT_EP_BIND(ep, av, 0);
+
+	flags = FI_TRANSMIT;
+	if (!(opts.options & FT_OPT_TX_CQ))
+		flags |= FI_SELECTIVE_COMPLETION;
+	FT_EP_BIND(ep, txcq, flags);
+
+	flags = FI_RECV;
+	if (!(opts.options & FT_OPT_RX_CQ))
+		flags |= FI_SELECTIVE_COMPLETION;
+	FT_EP_BIND(ep, rxcq, flags);
+
+	ret = ft_get_cq_fd(txcq, &tx_fd);
+	if (ret)
+		return ret;
+
+	ret = ft_get_cq_fd(rxcq, &rx_fd);
+	if (ret)
+		return ret;
+
+	/* TODO: use control structure to select counter bindings explicitly */
+	if (opts.options & FT_OPT_TX_CQ)
+		flags = 0;
+	else
+		flags = FI_SEND;
+	if (hints->caps & (FI_WRITE | FI_READ))
+		flags |= hints->caps & (FI_WRITE | FI_READ);
+	else if (hints->caps & FI_RMA)
+		flags |= FI_WRITE | FI_READ;
+	FT_EP_BIND(ep, txcntr, flags);
+
+	if (opts.options & FT_OPT_RX_CQ)
+		flags = 0;
+	else
+		flags = FI_RECV;
+	if (hints->caps & (FI_REMOTE_WRITE | FI_REMOTE_READ))
+		flags |= hints->caps & (FI_REMOTE_WRITE | FI_REMOTE_READ);
+	else if (hints->caps & FI_RMA)
+		flags |= FI_REMOTE_WRITE | FI_REMOTE_READ;
+	FT_EP_BIND(ep, rxcntr, flags);
+
+	ret = fi_enable(ep);
+	if (ret) {
+		FT_PRINTERR("fi_enable", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+int ft_enable_ep_recv(void)
+{
+	int ret;
+
+	ret = ft_enable_ep(ep, eq, av, txcq, rxcq, txcntr, rxcntr);
+	if (ret)
+		return ret;
+
+	if (!ft_check_opts(FT_OPT_SKIP_MSG_ALLOC) &&
+	    (fi->caps & (FI_MSG | FI_TAGGED))) {
+		/* Initial receive will get remote address for unconnected EPs */
+		ret = ft_post_rx(ep, MAX(rx_size, FT_MAX_CTRL_MSG), &rx_ctx);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+int ft_join_mc(void)
+{
+	struct fi_eq_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int ret;
+
+	ret = fi_join(ep, fi->dest_addr, 0, &mc, ep->fid.context);
+	if (ret) {
+		FT_PRINTERR("fi_join", ret);
+		return ret;
+	}
+
+	rd = fi_eq_sread(eq, &event, &entry, sizeof entry, -1, 0);
+	if (rd != sizeof entry) {
+		FT_PROCESS_EQ_ERR(rd, eq, "fi_eq_sread", "join");
+		ret = (int) rd;
+		return ret;
+	}
+
+	if (event != FI_JOIN_COMPLETE || entry.fid != &mc->fid) {
+		fprintf(stderr, "Unexpected join event %d fid %p (mc %p)\n",
+			event, entry.fid, ep);
+		ret = -FI_EOTHER;
+		return ret;
+	}
+
+	return 0;
+}
+
+int ft_av_insert(struct fid_av *av, void *addr, size_t count, fi_addr_t *fi_addr,
+		uint64_t flags, void *context)
+{
+	int ret;
+
+	ret = fi_av_insert(av, addr, count, fi_addr, flags, context);
+	if (ret < 0) {
+		FT_PRINTERR("fi_av_insert", ret);
+		return ret;
+	} else if (ret != count) {
+		FT_ERR("fi_av_insert: number of addresses inserted = %d;"
+			       " number of addresses given = %zd\n", ret, count);
+		return -EXIT_FAILURE;
+	}
+
+	return 0;
+}
+
+int ft_init_av(void)
+{
+	return ft_init_av_dst_addr(av, ep, &remote_fi_addr);
+}
+
+int ft_exchange_addresses_oob(struct fid_av *av_ptr, struct fid_ep *ep_ptr,
+		fi_addr_t *remote_addr)
+{
+	char buf[FT_MAX_CTRL_MSG];
+	int ret;
+	size_t addrlen = FT_MAX_CTRL_MSG;
+
+	ret = fi_getname(&ep_ptr->fid, buf, &addrlen);
+	if (ret) {
+		FT_PRINTERR("fi_getname", ret);
+		return ret;
+	}
+
+	ret = ft_sock_send(oob_sock, buf, FT_MAX_CTRL_MSG);
+	if (ret)
+		return ret;
+
+	ret = ft_sock_recv(oob_sock, buf, FT_MAX_CTRL_MSG);
+	if (ret)
+		return ret;
+
+	ret = ft_av_insert(av_ptr, buf, 1, remote_addr, 0, NULL);
+	if (ret)
+		return ret;	
+
+	return 0;
+}
+
+/* TODO: retry send for unreliable endpoints */
+int ft_init_av_dst_addr(struct fid_av *av_ptr, struct fid_ep *ep_ptr,
+		fi_addr_t *remote_addr)
+{
+	size_t addrlen;
+	int ret;
+
+	if (opts.oob_port) {
+		ret = ft_exchange_addresses_oob(av_ptr, ep_ptr, remote_addr);
+		if (ret)
+			return ret;
+		else
+			goto set_rx_seq_close;
+	}
+
+	if (opts.dst_addr) {
+		ret = ft_av_insert(av_ptr, fi->dest_addr, 1, remote_addr, 0, NULL);
+		if (ret)
+			return ret;
+
+		addrlen = FT_MAX_CTRL_MSG;
+		ret = fi_getname(&ep_ptr->fid, (char *) tx_buf + ft_tx_prefix_size(),
+				&addrlen);
+		if (ret) {
+			FT_PRINTERR("fi_getname", ret);
+			return ret;
+		}
+
+		ret = (int) ft_tx(ep, *remote_addr, addrlen, &tx_ctx);
+		if (ret)
+			return ret;
+
+		ret = ft_rx(ep, 1);
+		if (ret)
+			return ret;
+	} else {
+		ret = (int) ft_rx(ep, FT_MAX_CTRL_MSG);
+		if (ret)
+			return ret;
+
+		/* Test passing NULL fi_addr on one of the sides (server) if
+		 * AV type is FI_AV_TABLE */
+		ret = ft_av_insert(av_ptr, (char *) rx_buf + ft_rx_prefix_size(),
+				   1, ((fi->domain_attr->av_type == FI_AV_TABLE) ?
+				       NULL : remote_addr), 0, NULL);
+		if (ret)
+			return ret;
+
+		if (fi->domain_attr->av_type == FI_AV_TABLE)
+			*remote_addr = 0;
+
+		ret = (int) ft_tx(ep, *remote_addr, 1, &tx_ctx);
+		if (ret)
+			return ret;
+	}
+
+set_rx_seq_close:
+	/*
+	* For a test which does not have MSG or TAGGED
+	* capabilities, but has RMA/Atomics and uses the OOB sync.
+	* If no recv is going to be posted,
+	* then the rx_seq needs to be incremented to wait on the first RMA/Atomic
+	* completion.
+	*/
+	if (!(fi->caps & FI_MSG) && !(fi->caps & FI_TAGGED) && opts.oob_port)
+		rx_seq++;
+
+	return 0;
+}
+
+/* TODO: retry send for unreliable endpoints */
+int ft_init_av_addr(struct fid_av *av_ptr, struct fid_ep *ep_ptr,
+		fi_addr_t *remote_addr)
+{
+	size_t addrlen;
+	int ret;
+
+	if (opts.oob_port)
+		return ft_exchange_addresses_oob(av_ptr, ep_ptr, remote_addr);
+
+	if (opts.dst_addr) {
+		addrlen = FT_MAX_CTRL_MSG;
+		ret = fi_getname(&ep_ptr->fid, (char *) tx_buf + ft_tx_prefix_size(),
+				 &addrlen);
+		if (ret) {
+			FT_PRINTERR("fi_getname", ret);
+			return ret;
+		}
+
+		ret = (int) ft_tx(ep, remote_fi_addr, addrlen, &tx_ctx);
+		if (ret)
+			return ret;
+
+		ret = (int) ft_rx(ep, FT_MAX_CTRL_MSG);
+		if (ret)
+			return ret;
+
+		ret = ft_av_insert(av_ptr, (char *) rx_buf + ft_rx_prefix_size(),
+				1, remote_addr, 0, NULL);
+		if (ret)
+			return ret;
+	} else {
+		ret = (int) ft_rx(ep, FT_MAX_CTRL_MSG);
+		if (ret)
+			return ret;
+
+		ret = ft_av_insert(av_ptr, (char *) rx_buf + ft_rx_prefix_size(),
+				   1, remote_addr, 0, NULL);
+		if (ret)
+			return ret;
+
+		addrlen = FT_MAX_CTRL_MSG;
+		ret = fi_getname(&ep_ptr->fid,
+				(char *) tx_buf + ft_tx_prefix_size(),
+				&addrlen);
+		if (ret) {
+			FT_PRINTERR("fi_getname", ret);
+			return ret;
+		}
+
+		ret = (int) ft_tx(ep, remote_fi_addr, addrlen, &tx_ctx);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+int ft_exchange_raw_keys(struct fi_rma_iov *peer_iov)
+{
+	struct fi_rma_iov *rma_iov;
+	size_t key_size;
+	size_t len;
+	uint64_t addr;
+	int ret;
+
+	/* Get key size */
+	key_size = 0;
+	ret = fi_mr_raw_attr(mr, &addr, NULL, &key_size, 0);
+	if (ret != -FI_ETOOSMALL) {
+		return ret;
+	}
+
+	len = sizeof(*rma_iov) + key_size - sizeof(rma_iov->key);
+	/* TODO: make sure this fits in tx_buf and rx_buf */
+
+	if (opts.dst_addr) {
+		rma_iov = (struct fi_rma_iov *) (tx_buf + ft_tx_prefix_size());
+		if ((fi->domain_attr->mr_mode == FI_MR_BASIC) ||
+		    (fi->domain_attr->mr_mode & FI_MR_VIRT_ADDR)) {
+			rma_iov->addr = (uintptr_t) rx_buf + ft_rx_prefix_size();
+		} else {
+			rma_iov->addr = 0;
+		}
+
+		/* Get raw attributes */
+		ret = fi_mr_raw_attr(mr, &addr, (uint8_t *) &rma_iov->key,
+				&key_size, 0);
+		if (ret)
+			return ret;
+
+               ret = ft_tx(ep, remote_fi_addr, len, &tx_ctx);
+		if (ret)
+			return ret;
+
+		ret = ft_get_rx_comp(rx_seq);
+		if (ret)
+			return ret;
+
+		rma_iov = (struct fi_rma_iov *) (rx_buf + ft_rx_prefix_size());
+		peer_iov->addr 	= rma_iov->addr;
+		peer_iov->len 	= rma_iov->len;
+		/* Map remote mr raw locally */
+		ret = fi_mr_map_raw(domain, rma_iov->addr,
+				(uint8_t *) &rma_iov->key, key_size,
+				&peer_iov->key, 0);
+		if (ret)
+			return ret;
+
+		ret = ft_post_rx(ep, rx_size, &rx_ctx);
+	} else {
+		ret = ft_get_rx_comp(rx_seq);
+		if (ret)
+			return ret;
+
+		rma_iov = (struct fi_rma_iov *) (rx_buf + ft_rx_prefix_size());
+		peer_iov->addr 	= rma_iov->addr;
+		peer_iov->len 	= rma_iov->len;
+		/* Map remote mr raw locally */
+		ret = fi_mr_map_raw(domain, rma_iov->addr,
+				(uint8_t *) &rma_iov->key, key_size,
+				&peer_iov->key, 0);
+		if (ret)
+			return ret;
+
+		ret = ft_post_rx(ep, rx_size, &rx_ctx);
+		if (ret)
+			return ret;
+
+		rma_iov = (struct fi_rma_iov *) (tx_buf + ft_tx_prefix_size());
+		if ((fi->domain_attr->mr_mode == FI_MR_BASIC) ||
+		    (fi->domain_attr->mr_mode & FI_MR_VIRT_ADDR)) {
+			rma_iov->addr = (uintptr_t) rx_buf + ft_rx_prefix_size();
+		} else {
+			rma_iov->addr = 0;
+		}
+
+		/* Get raw attributes */
+		ret = fi_mr_raw_attr(mr, &addr, (uint8_t *) &rma_iov->key,
+				&key_size, 0);
+		if (ret)
+			return ret;
+
+		ret = ft_tx(ep, remote_fi_addr, len, &tx_ctx);
+	}
+
+	return ret;
+}
+
+int ft_exchange_keys(struct fi_rma_iov *peer_iov)
+{
+	struct fi_rma_iov *rma_iov;
+	int ret;
+
+	if (fi->domain_attr->mr_mode & FI_MR_RAW)
+		return ft_exchange_raw_keys(peer_iov);
+
+	if (opts.dst_addr) {
+		rma_iov = (struct fi_rma_iov *) (tx_buf + ft_tx_prefix_size());
+		if ((fi->domain_attr->mr_mode == FI_MR_BASIC) ||
+		    (fi->domain_attr->mr_mode & FI_MR_VIRT_ADDR)) {
+			rma_iov->addr = (uintptr_t) rx_buf + ft_rx_prefix_size();
+		} else {
+			rma_iov->addr = 0;
+		}
+		rma_iov->key = fi_mr_key(mr);
+		ret = ft_tx(ep, remote_fi_addr, sizeof *rma_iov, &tx_ctx);
+		if (ret)
+			return ret;
+
+		ret = ft_get_rx_comp(rx_seq);
+		if (ret)
+			return ret;
+
+		rma_iov = (struct fi_rma_iov *) (rx_buf + ft_rx_prefix_size());
+		*peer_iov = *rma_iov;
+		ret = ft_post_rx(ep, rx_size, &rx_ctx);
+	} else {
+		ret = ft_get_rx_comp(rx_seq);
+		if (ret)
+			return ret;
+
+		rma_iov = (struct fi_rma_iov *) (rx_buf + ft_rx_prefix_size());
+		*peer_iov = *rma_iov;
+		ret = ft_post_rx(ep, rx_size, &rx_ctx);
+		if (ret)
+			return ret;
+
+		rma_iov = (struct fi_rma_iov *) (tx_buf + ft_tx_prefix_size());
+		if ((fi->domain_attr->mr_mode == FI_MR_BASIC) ||
+		    (fi->domain_attr->mr_mode & FI_MR_VIRT_ADDR)) {
+			rma_iov->addr = (uintptr_t) rx_buf + ft_rx_prefix_size();
+		} else {
+			rma_iov->addr = 0;
+		}
+		rma_iov->key = fi_mr_key(mr);
+		ret = ft_tx(ep, remote_fi_addr, sizeof *rma_iov, &tx_ctx);
+	}
+
+	return ret;
+}
+
+static void ft_close_fids(void)
+{
+	if (mr != &no_mr)
+		FT_CLOSE_FID(mr);
+	FT_CLOSE_FID(mc);
+	FT_CLOSE_FID(alias_ep);
+	FT_CLOSE_FID(ep);
+	FT_CLOSE_FID(pep);
+	FT_CLOSE_FID(pollset);
+	if (opts.options & FT_OPT_CQ_SHARED) {
+		FT_CLOSE_FID(txcq);
+	} else {
+		FT_CLOSE_FID(rxcq);
+		FT_CLOSE_FID(txcq);
+	}
+	FT_CLOSE_FID(rxcntr);
+	FT_CLOSE_FID(txcntr);
+	FT_CLOSE_FID(av);
+	FT_CLOSE_FID(eq);
+	FT_CLOSE_FID(domain);
+	FT_CLOSE_FID(waitset);
+	FT_CLOSE_FID(fabric);
+}
+
+void ft_free_res(void)
+{
+	ft_close_fids();
+
+	free(tx_ctx_arr);
+	free(rx_ctx_arr);
+	tx_ctx_arr = NULL;
+	rx_ctx_arr = NULL;
+
+	if (buf) {
+		free(buf);
+		buf = rx_buf = tx_buf = NULL;
+		buf_size = rx_size = tx_size = 0;
+	}
+	if (fi_pep) {
+		fi_freeinfo(fi_pep);
+		fi_pep = NULL;
+	}
+	if (fi) {
+		fi_freeinfo(fi);
+		fi = NULL;
+	}
+	if (hints) {
+		fi_freeinfo(hints);
+		hints = NULL;
+	}
+}
+
+static int dupaddr(void **dst_addr, size_t *dst_addrlen,
+		void *src_addr, size_t src_addrlen)
+{
+	*dst_addr = malloc(src_addrlen);
+	if (!*dst_addr) {
+		FT_ERR("address allocation failed");
+		return EAI_MEMORY;
+	}
+	*dst_addrlen = src_addrlen;
+	memcpy(*dst_addr, src_addr, src_addrlen);
+	return 0;
+}
+
+static int getaddr(char *node, char *service,
+			struct fi_info *hints, uint64_t flags)
+{
+	int ret;
+	struct fi_info *fi;
+
+	if (!node && !service) {
+		if (flags & FI_SOURCE) {
+			hints->src_addr = NULL;
+			hints->src_addrlen = 0;
+		} else {
+			hints->dest_addr = NULL;
+			hints->dest_addrlen = 0;
+		}
+		return 0;
+	}
+
+	ret = fi_getinfo(FT_FIVERSION, node, service, flags, hints, &fi);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		return ret;
+	}
+	hints->addr_format = fi->addr_format;
+
+	if (flags & FI_SOURCE) {
+		ret = dupaddr(&hints->src_addr, &hints->src_addrlen,
+				fi->src_addr, fi->src_addrlen);
+	} else {
+		ret = dupaddr(&hints->dest_addr, &hints->dest_addrlen,
+				fi->dest_addr, fi->dest_addrlen);
+	}
+
+	fi_freeinfo(fi);
+	return ret;
+}
+
+int ft_getsrcaddr(char *node, char *service, struct fi_info *hints)
+{
+	return getaddr(node, service, hints, FI_SOURCE);
+}
+
+int ft_read_addr_opts(char **node, char **service, struct fi_info *hints,
+		uint64_t *flags, struct ft_opts *opts)
+{
+	int ret;
+
+	if (opts->dst_addr) {
+		if (!opts->dst_port)
+			opts->dst_port = default_port;
+
+		ret = ft_getsrcaddr(opts->src_addr, opts->src_port, hints);
+		if (ret)
+			return ret;
+		*node = opts->dst_addr;
+		*service = opts->dst_port;
+	} else {
+		if (!opts->src_port)
+			opts->src_port = default_port;
+
+		*node = opts->src_addr;
+		*service = opts->src_port;
+		*flags = FI_SOURCE;
+	}
+
+	return 0;
+}
+
+char *size_str(char str[FT_STR_LEN], long long size)
+{
+	long long base, fraction = 0;
+	char mag;
+
+	memset(str, '\0', FT_STR_LEN);
+
+	if (size >= (1 << 30)) {
+		base = 1 << 30;
+		mag = 'g';
+	} else if (size >= (1 << 20)) {
+		base = 1 << 20;
+		mag = 'm';
+	} else if (size >= (1 << 10)) {
+		base = 1 << 10;
+		mag = 'k';
+	} else {
+		base = 1;
+		mag = '\0';
+	}
+
+	if (size / base < 10)
+		fraction = (size % base) * 10 / base;
+
+	if (fraction)
+		snprintf(str, FT_STR_LEN, "%lld.%lld%c", size / base, fraction, mag);
+	else
+		snprintf(str, FT_STR_LEN, "%lld%c", size / base, mag);
+
+	return str;
+}
+
+char *cnt_str(char str[FT_STR_LEN], long long cnt)
+{
+	if (cnt >= 1000000000)
+		snprintf(str, FT_STR_LEN, "%lldb", cnt / 1000000000);
+	else if (cnt >= 1000000)
+		snprintf(str, FT_STR_LEN, "%lldm", cnt / 1000000);
+	else if (cnt >= 1000)
+		snprintf(str, FT_STR_LEN, "%lldk", cnt / 1000);
+	else
+		snprintf(str, FT_STR_LEN, "%lld", cnt);
+
+	return str;
+}
+
+int size_to_count(int size)
+{
+	if (size >= (1 << 20))
+		return (opts.options & FT_OPT_BW) ? 200 : 100;
+	else if (size >= (1 << 16))
+		return (opts.options & FT_OPT_BW) ? 2000 : 1000;
+	else
+		return (opts.options & FT_OPT_BW) ? 20000: 10000;
+}
+
+static const size_t datatype_size_table[] = {
+	[FI_INT8]   = sizeof(int8_t),
+	[FI_UINT8]  = sizeof(uint8_t),
+	[FI_INT16]  = sizeof(int16_t),
+	[FI_UINT16] = sizeof(uint16_t),
+	[FI_INT32]  = sizeof(int32_t),
+	[FI_UINT32] = sizeof(uint32_t),
+	[FI_INT64]  = sizeof(int64_t),
+	[FI_UINT64] = sizeof(uint64_t),
+	[FI_FLOAT]  = sizeof(float),
+	[FI_DOUBLE] = sizeof(double),
+	[FI_FLOAT_COMPLEX]  = sizeof(OFI_COMPLEX(float)),
+	[FI_DOUBLE_COMPLEX] = sizeof(OFI_COMPLEX(double)),
+	[FI_LONG_DOUBLE]    = sizeof(long double),
+	[FI_LONG_DOUBLE_COMPLEX] = sizeof(OFI_COMPLEX(long_double)),
+};
+
+size_t datatype_to_size(enum fi_datatype datatype)
+{
+	if (datatype >= FI_DATATYPE_LAST)
+		return 0;
+
+	return datatype_size_table[datatype];
+}
+
+void init_test(struct ft_opts *opts, char *test_name, size_t test_name_len)
+{
+	char sstr[FT_STR_LEN];
+
+	size_str(sstr, opts->transfer_size);
+	if (!strcmp(test_name, "custom"))
+		snprintf(test_name, test_name_len, "%s_lat", sstr);
+	if (!(opts->options & FT_OPT_ITER))
+		opts->iterations = size_to_count(opts->transfer_size);
+}
+
+static int ft_progress(struct fid_cq *cq, uint64_t total, uint64_t *cq_cntr)
+{
+	struct fi_cq_err_entry comp;
+	int ret;
+
+	ret = fi_cq_read(cq, &comp, 1);
+	if (ret > 0)
+		(*cq_cntr)++;
+
+	if (ret >= 0 || ret == -FI_EAGAIN)
+		return 0;
+
+	if (ret == -FI_EAVAIL) {
+		ret = ft_cq_readerr(cq);
+		(*cq_cntr)++;
+	} else {
+		FT_PRINTERR("fi_cq_read/sread", ret);
+	}
+	return ret;
+}
+
+#define FT_POST(post_fn, progress_fn, cq, seq, cq_cntr, op_str, ...)		\
+	do {									\
+		int timeout_save;						\
+		int ret, rc;							\
+										\
+		while (1) {							\
+			ret = post_fn(__VA_ARGS__);				\
+			if (!ret)						\
+				break;						\
+										\
+			if (ret != -FI_EAGAIN) {				\
+				FT_PRINTERR(op_str, ret);			\
+				return ret;					\
+			}							\
+										\
+			timeout_save = timeout;					\
+			timeout = 0;						\
+			rc = progress_fn(cq, seq, cq_cntr);			\
+			if (rc && rc != -FI_EAGAIN) {				\
+				FT_ERR("Failed to get " op_str " completion");	\
+				return rc;					\
+			}							\
+			timeout = timeout_save;					\
+		}								\
+		seq++;								\
+	} while (0)
+
+ssize_t ft_post_tx_buf(struct fid_ep *ep, fi_addr_t fi_addr, size_t size,
+		       uint64_t data, struct fi_context* ctx,
+		       void *op_buf, void *op_mr_desc, uint64_t op_tag)
+{
+	size += ft_tx_prefix_size();
+	if (hints->caps & FI_TAGGED) {
+		op_tag = op_tag ? op_tag : tx_seq;
+		if (data != NO_CQ_DATA) {
+			FT_POST(fi_tsenddata, ft_progress, txcq, tx_seq,
+				&tx_cq_cntr, "transmit", ep, op_buf, size,
+				op_mr_desc, data, fi_addr, op_tag, ctx);
+		} else {
+			FT_POST(fi_tsend, ft_progress, txcq, tx_seq,
+				&tx_cq_cntr, "transmit", ep, op_buf, size,
+				op_mr_desc, fi_addr, op_tag, ctx);
+		}
+	} else {
+		if (data != NO_CQ_DATA) {
+			FT_POST(fi_senddata, ft_progress, txcq, tx_seq,
+				&tx_cq_cntr, "transmit", ep, op_buf, size,
+				op_mr_desc, data, fi_addr, ctx);
+
+		} else {
+			FT_POST(fi_send, ft_progress, txcq, tx_seq,
+				&tx_cq_cntr, "transmit", ep, op_buf, size,
+				op_mr_desc, fi_addr, ctx);
+		}
+	}
+	return 0;
+}
+
+ssize_t ft_post_tx(struct fid_ep *ep, fi_addr_t fi_addr, size_t size,
+		   uint64_t data, struct fi_context* ctx)
+{
+	return ft_post_tx_buf(ep, fi_addr, size, data,
+			      ctx, tx_buf, mr_desc, ft_tag);
+}
+
+ssize_t ft_tx(struct fid_ep *ep, fi_addr_t fi_addr, size_t size, struct fi_context *ctx)
+{
+	ssize_t ret;
+
+	if (ft_check_opts(FT_OPT_VERIFY_DATA | FT_OPT_ACTIVE))
+		ft_fill_buf((char *) tx_buf + ft_tx_prefix_size(), size);
+
+	ret = ft_post_tx(ep, fi_addr, size, NO_CQ_DATA, ctx);
+	if (ret)
+		return ret;
+
+	ret = ft_get_tx_comp(tx_seq);
+	return ret;
+}
+
+ssize_t ft_post_inject(struct fid_ep *ep, fi_addr_t fi_addr, size_t size)
+{
+	if (hints->caps & FI_TAGGED) {
+		FT_POST(fi_tinject, ft_progress, txcq, tx_seq, &tx_cq_cntr,
+			"inject", ep, tx_buf, size + ft_tx_prefix_size(),
+			fi_addr, tx_seq);
+	} else {
+		FT_POST(fi_inject, ft_progress, txcq, tx_seq, &tx_cq_cntr,
+			"inject", ep, tx_buf, size + ft_tx_prefix_size(),
+			fi_addr);
+	}
+
+	tx_cq_cntr++;
+	return 0;
+}
+
+ssize_t ft_inject(struct fid_ep *ep, fi_addr_t fi_addr, size_t size)
+{
+	ssize_t ret;
+
+	if (ft_check_opts(FT_OPT_VERIFY_DATA | FT_OPT_ACTIVE))
+		ft_fill_buf((char *) tx_buf + ft_tx_prefix_size(), size);
+
+	ret = ft_post_inject(ep, fi_addr, size);
+	if (ret)
+		return ret;
+
+	return ret;
+}
+
+ssize_t ft_post_rma(enum ft_rma_opcodes op, struct fid_ep *ep, size_t size,
+		struct fi_rma_iov *remote, void *context)
+{
+	switch (op) {
+	case FT_RMA_WRITE:
+		FT_POST(fi_write, ft_progress, txcq, tx_seq, &tx_cq_cntr,
+			"fi_write", ep, tx_buf, opts.transfer_size, mr_desc,
+			remote_fi_addr, remote->addr, remote->key, context);
+		break;
+	case FT_RMA_WRITEDATA:
+		FT_POST(fi_writedata, ft_progress, txcq, tx_seq, &tx_cq_cntr,
+			"fi_writedata", ep, tx_buf, opts.transfer_size, mr_desc,
+			remote_cq_data, remote_fi_addr,	remote->addr,
+			remote->key, context);
+		break;
+	case FT_RMA_READ:
+		FT_POST(fi_read, ft_progress, txcq, tx_seq, &tx_cq_cntr,
+			"fi_read", ep, rx_buf, opts.transfer_size, mr_desc,
+			remote_fi_addr, remote->addr,remote->key, context);
+		break;
+	default:
+		FT_ERR("Unknown RMA op type\n");
+		return EXIT_FAILURE;
+	}
+
+	return 0;
+}
+
+ssize_t ft_rma(enum ft_rma_opcodes op, struct fid_ep *ep, size_t size,
+		struct fi_rma_iov *remote, void *context)
+{
+	int ret;
+
+	ret = ft_post_rma(op, ep, size, remote, context);
+	if (ret)
+		return ret;
+
+	if (op == FT_RMA_WRITEDATA) {
+		if (fi->rx_attr->mode & FI_RX_CQ_DATA) {
+			ret = ft_rx(ep, 0);
+		} else {
+			ret = ft_get_rx_comp(rx_seq);
+			/* Just increment the seq # instead of posting recv so
+			 * that we wait for remote write completion on the next
+			 * iteration. */
+			rx_seq++;
+		}
+		if (ret)
+			return ret;
+	}
+
+	ret = ft_get_tx_comp(tx_seq);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+ssize_t ft_post_rma_inject(enum ft_rma_opcodes op, struct fid_ep *ep, size_t size,
+		struct fi_rma_iov *remote)
+{
+	switch (op) {
+	case FT_RMA_WRITE:
+		FT_POST(fi_inject_write, ft_progress, txcq, tx_seq, &tx_cq_cntr,
+			"fi_inject_write", ep, tx_buf, opts.transfer_size, 
+			remote_fi_addr, remote->addr, remote->key);
+		break;
+	case FT_RMA_WRITEDATA:
+		FT_POST(fi_inject_writedata, ft_progress, txcq, tx_seq,
+			&tx_cq_cntr, "fi_inject_writedata", ep, tx_buf,
+			opts.transfer_size, remote_cq_data, remote_fi_addr,
+			remote->addr, remote->key);
+		break;
+	default:
+		FT_ERR("Unknown RMA inject op type\n");
+		return EXIT_FAILURE;
+	}
+
+	tx_cq_cntr++;
+	return 0;
+}
+
+ssize_t ft_post_atomic(enum ft_atomic_opcodes opcode, struct fid_ep *ep,
+		       void *compare, void *compare_desc, void *result,
+		       void *result_desc, struct fi_rma_iov *remote,
+		       enum fi_datatype datatype, enum fi_op atomic_op,
+		       void *context)
+{
+	size_t size, count;
+
+	size = datatype_to_size(datatype);
+	if (!size) {
+		FT_ERR("Unknown datatype\n");
+		return EXIT_FAILURE;
+	}
+	count = opts.transfer_size / size;
+
+	switch (opcode) {
+	case FT_ATOMIC_BASE:
+		FT_POST(fi_atomic, ft_progress, txcq, tx_seq, &tx_cq_cntr,
+			"fi_atomic", ep, buf, count, mr_desc, remote_fi_addr,
+			remote->addr, remote->key, datatype, atomic_op, context);
+		break;
+	case FT_ATOMIC_FETCH:
+		FT_POST(fi_fetch_atomic, ft_progress, txcq, tx_seq, &tx_cq_cntr,
+			"fi_fetch_atomic", ep, buf, count, mr_desc, result,
+			result_desc, remote_fi_addr, remote->addr, remote->key,
+			datatype, atomic_op, context);
+		break;
+	case FT_ATOMIC_COMPARE:
+		FT_POST(fi_compare_atomic, ft_progress, txcq, tx_seq,
+			&tx_cq_cntr, "fi_compare_atomic", ep, buf, count,
+			mr_desc, compare, compare_desc, result, result_desc,
+			remote_fi_addr, remote->addr, remote->key, datatype,
+			atomic_op, context);
+		break;
+	default:
+		FT_ERR("Unknown atomic opcode\n");
+		return EXIT_FAILURE;
+	}
+
+	return 0;
+}
+
+static int check_atomic_attr(enum fi_op op, enum fi_datatype datatype,
+			     uint64_t flags)
+{
+	struct fi_atomic_attr attr;
+	int ret;
+
+	ret = fi_query_atomic(domain, datatype, op, &attr, flags);
+	if (ret) {
+		FT_PRINTERR("fi_query_atomic", ret);
+		return ret;
+	}
+
+	if (attr.size != datatype_to_size(datatype)) {
+		fprintf(stderr, "Provider atomic size mismatch\n");
+		return -FI_ENOSYS;
+	}
+
+	return 0;
+}
+
+int check_base_atomic_op(struct fid_ep *endpoint, enum fi_op op,
+			 enum fi_datatype datatype, size_t *count)
+{
+	int ret;
+
+	ret = fi_atomicvalid(endpoint, datatype, op, count);
+	if (ret)
+		return ret;
+
+	return check_atomic_attr(op, datatype, 0);
+}
+
+int check_fetch_atomic_op(struct fid_ep *endpoint, enum fi_op op,
+			  enum fi_datatype datatype, size_t *count)
+{
+	int ret;
+
+	ret = fi_fetch_atomicvalid(endpoint, datatype, op, count);
+	if (ret)
+		return ret;
+
+	return check_atomic_attr(op, datatype, FI_FETCH_ATOMIC);
+}
+
+int check_compare_atomic_op(struct fid_ep *endpoint, enum fi_op op,
+			    enum fi_datatype datatype, size_t *count)
+{
+	int ret;
+
+	ret = fi_compare_atomicvalid(endpoint, datatype, op, count);
+	if (ret)
+		return ret;
+
+	return check_atomic_attr(op, datatype, FI_COMPARE_ATOMIC);
+}
+
+ssize_t ft_post_rx_buf(struct fid_ep *ep, size_t size, struct fi_context* ctx,
+		       void *op_buf, void *op_mr_desc, uint64_t op_tag)
+{
+	size = MAX(size, FT_MAX_CTRL_MSG) + ft_rx_prefix_size();
+	if (hints->caps & FI_TAGGED) {
+		op_tag = op_tag ? op_tag : rx_seq;
+		FT_POST(fi_trecv, ft_progress, rxcq, rx_seq, &rx_cq_cntr,
+			"receive", ep, op_buf, size, op_mr_desc, 0, op_tag,
+			0, ctx);
+	} else {
+		FT_POST(fi_recv, ft_progress, rxcq, rx_seq, &rx_cq_cntr,
+			"receive", ep, op_buf, size, op_mr_desc, 0, ctx);
+	}
+	return 0;
+}
+
+ssize_t ft_post_rx(struct fid_ep *ep, size_t size, struct fi_context* ctx)
+{
+	return ft_post_rx_buf(ep, size, ctx, rx_buf, mr_desc, ft_tag);
+}
+
+ssize_t ft_rx(struct fid_ep *ep, size_t size)
+{
+	ssize_t ret;
+
+	ret = ft_get_rx_comp(rx_seq);
+	if (ret)
+		return ret;
+
+	if (ft_check_opts(FT_OPT_VERIFY_DATA | FT_OPT_ACTIVE)) {
+		ret = ft_check_buf((char *) rx_buf + ft_rx_prefix_size(), size);
+		if (ret)
+			return ret;
+	}
+	/* TODO: verify CQ data, if available */
+
+	/* Ignore the size arg. Post a buffer large enough to handle all message
+	 * sizes. ft_sync() makes use of ft_rx() and gets called in tests just before
+	 * message size is updated. The recvs posted are always for the next incoming
+	 * message */
+	ret = ft_post_rx(ep, rx_size, &rx_ctx);
+	return ret;
+}
+
+/*
+ * Received messages match tagged buffers in order, but the completions can be
+ * reported out of order.  A tag is valid if it's within the current window.
+ */
+static inline int
+ft_tag_is_valid(struct fid_cq * cq, struct fi_cq_err_entry *comp, uint64_t tag)
+{
+	int valid = 1;
+
+	if ((hints->caps & FI_TAGGED) && (cq == rxcq)) {
+		if (opts.options & FT_OPT_BW) {
+			/* valid: (tag - window) < comp->tag < (tag + window) */
+			valid = (tag < comp->tag + opts.window_size) &&
+				(comp->tag < tag + opts.window_size);
+		} else {
+			valid = (comp->tag == tag);
+		}
+
+		if (!valid) {
+			FT_ERR("Tag mismatch!. Expected: %"PRIu64", actual: %"
+				PRIu64, tag, comp->tag);
+		}
+	}
+
+	return valid;
+}
+/*
+ * fi_cq_err_entry can be cast to any CQ entry format.
+ */
+static int ft_spin_for_comp(struct fid_cq *cq, uint64_t *cur,
+			    uint64_t total, int timeout)
+{
+	struct fi_cq_err_entry comp;
+	struct timespec a, b;
+	int ret;
+
+	if (timeout >= 0)
+		clock_gettime(CLOCK_MONOTONIC, &a);
+
+	do {
+		ret = fi_cq_read(cq, &comp, 1);
+		if (ret > 0) {
+			if (timeout >= 0)
+				clock_gettime(CLOCK_MONOTONIC, &a);
+			if (!ft_tag_is_valid(cq, &comp, ft_tag ? ft_tag : rx_cq_cntr))
+				return -FI_EOTHER;
+			(*cur)++;
+		} else if (ret < 0 && ret != -FI_EAGAIN) {
+			return ret;
+		} else if (timeout >= 0) {
+			clock_gettime(CLOCK_MONOTONIC, &b);
+			if ((b.tv_sec - a.tv_sec) > timeout) {
+				fprintf(stderr, "%ds timeout expired\n", timeout);
+				return -FI_ENODATA;
+			}
+		}
+	} while (total - *cur > 0);
+
+	return 0;
+}
+
+/*
+ * fi_cq_err_entry can be cast to any CQ entry format.
+ */
+static int ft_wait_for_comp(struct fid_cq *cq, uint64_t *cur,
+			    uint64_t total, int timeout)
+{
+	struct fi_cq_err_entry comp;
+	int ret;
+
+	while (total - *cur > 0) {
+		ret = fi_cq_sread(cq, &comp, 1, NULL, timeout);
+		if (ret > 0) {
+			if (!ft_tag_is_valid(cq, &comp, ft_tag ? ft_tag : rx_cq_cntr))
+				return -FI_EOTHER;
+			(*cur)++;
+		} else if (ret < 0 && ret != -FI_EAGAIN) {
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * fi_cq_err_entry can be cast to any CQ entry format.
+ */
+static int ft_fdwait_for_comp(struct fid_cq *cq, uint64_t *cur,
+			    uint64_t total, int timeout)
+{
+	struct fi_cq_err_entry comp;
+	struct fid *fids[1];
+	int fd, ret;
+
+	fd = cq == txcq ? tx_fd : rx_fd;
+	fids[0] = &cq->fid;
+
+	while (total - *cur > 0) {
+		ret = fi_trywait(fabric, fids, 1);
+		if (ret == FI_SUCCESS) {
+			ret = ft_poll_fd(fd, timeout);
+			if (ret && ret != -FI_EAGAIN)
+				return ret;
+		}
+
+		ret = fi_cq_read(cq, &comp, 1);
+		if (ret > 0) {
+			if (!ft_tag_is_valid(cq, &comp, ft_tag ? ft_tag : rx_cq_cntr))
+				return -FI_EOTHER;
+			(*cur)++;
+		} else if (ret < 0 && ret != -FI_EAGAIN) {
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int ft_get_cq_comp(struct fid_cq *cq, uint64_t *cur,
+			  uint64_t total, int timeout)
+{
+	int ret;
+
+	switch (opts.comp_method) {
+	case FT_COMP_SREAD:
+		ret = ft_wait_for_comp(cq, cur, total, timeout);
+		break;
+	case FT_COMP_WAIT_FD:
+		ret = ft_fdwait_for_comp(cq, cur, total, timeout);
+		break;
+	default:
+		ret = ft_spin_for_comp(cq, cur, total, timeout);
+		break;
+	}
+
+	if (ret) {
+		if (ret == -FI_EAVAIL) {
+			ret = ft_cq_readerr(cq);
+			(*cur)++;
+		} else {
+			FT_PRINTERR("ft_get_cq_comp", ret);
+		}
+	}
+	return ret;
+}
+
+static int ft_spin_for_cntr(struct fid_cntr *cntr, uint64_t total, int timeout)
+{
+	struct timespec a, b;
+	uint64_t cur;
+
+	if (timeout >= 0)
+		clock_gettime(CLOCK_MONOTONIC, &a);
+
+	for (;;) {
+		cur = fi_cntr_read(cntr);
+		if (cur >= total)
+			return 0;
+
+		if (timeout >= 0) {
+			clock_gettime(CLOCK_MONOTONIC, &b);
+			if ((b.tv_sec - a.tv_sec) > timeout)
+				break;
+		}
+	}
+
+	fprintf(stderr, "%ds timeout expired\n", timeout);
+	return -FI_ENODATA;
+}
+
+static int ft_wait_for_cntr(struct fid_cntr *cntr, uint64_t total, int timeout)
+{
+	int ret;
+
+	while (fi_cntr_read(cntr) < total) {
+		ret = fi_cntr_wait(cntr, total, timeout);
+		if (ret)
+			FT_PRINTERR("fi_cntr_wait", ret);
+		else
+			break;
+	}
+	return 0;
+}
+
+static int ft_get_cntr_comp(struct fid_cntr *cntr, uint64_t total, int timeout)
+{
+	int ret = 0;
+
+	switch (opts.comp_method) {
+	case FT_COMP_SREAD:
+	case FT_COMP_WAITSET:
+	case FT_COMP_WAIT_FD:
+		ret = ft_wait_for_cntr(cntr, total, timeout);
+		break;
+	default:
+		ret = ft_spin_for_cntr(cntr, total, timeout);
+		break;
+	}
+
+	if (ret)
+		FT_PRINTERR("fs_get_cntr_comp", ret);
+
+	return ret;
+}
+
+int ft_get_rx_comp(uint64_t total)
+{
+	int ret = FI_SUCCESS;
+
+	if (opts.options & FT_OPT_RX_CQ) {
+		ret = ft_get_cq_comp(rxcq, &rx_cq_cntr, total, timeout);
+	} else if (rxcntr) {
+		ret = ft_get_cntr_comp(rxcntr, total, timeout);
+	} else {
+		FT_ERR("Trying to get a RX completion when no RX CQ or counter were opened");
+		ret = -FI_EOTHER;
+	}
+	return ret;
+}
+
+int ft_get_tx_comp(uint64_t total)
+{
+	int ret;
+
+	if (opts.options & FT_OPT_TX_CQ) {
+		ret = ft_get_cq_comp(txcq, &tx_cq_cntr, total, -1);
+	} else if (txcntr) {
+		ret = ft_get_cntr_comp(txcntr, total, -1);
+	} else {
+		FT_ERR("Trying to get a TX completion when no TX CQ or counter were opened");
+		ret = -FI_EOTHER;
+	}
+	return ret;
+}
+
+int ft_sendmsg(struct fid_ep *ep, fi_addr_t fi_addr,
+		size_t size, struct fi_context *ctx, int flags)
+{
+	int ret;
+	struct fi_msg msg;
+	struct fi_msg_tagged tagged_msg;
+	struct iovec msg_iov;
+
+	msg_iov.iov_base = tx_buf;
+	msg_iov.iov_len = size;
+
+	if (hints->caps & FI_TAGGED) {
+		tagged_msg.msg_iov = &msg_iov;
+		tagged_msg.desc = &mr_desc;
+		tagged_msg.iov_count = 1;
+		tagged_msg.addr = fi_addr;
+		tagged_msg.data = NO_CQ_DATA;
+		tagged_msg.context = ctx;
+		tagged_msg.tag = ft_tag ? ft_tag : tx_seq;
+		tagged_msg.ignore = 0;
+
+		ret = fi_tsendmsg(ep, &tagged_msg, flags);
+		if (ret) {
+			FT_PRINTERR("fi_tsendmsg", ret);
+			return ret;
+		}
+	} else {
+		msg.msg_iov = &msg_iov;
+		msg.desc = &mr_desc;
+		msg.iov_count = 1;
+		msg.addr = fi_addr;
+		msg.data = NO_CQ_DATA;
+		msg.context = ctx;
+
+		ret = fi_sendmsg(ep, &msg, flags);
+		if (ret) {
+			FT_PRINTERR("fi_sendmsg", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int ft_recvmsg(struct fid_ep *ep, fi_addr_t fi_addr,
+	       size_t size, struct fi_context *ctx, int flags)
+{
+	int ret;
+	struct fi_msg msg;
+	struct fi_msg_tagged tagged_msg;
+	struct iovec msg_iov;
+
+	msg_iov.iov_base = rx_buf;
+	msg_iov.iov_len = size;
+
+	if (hints->caps & FI_TAGGED) {
+		tagged_msg.msg_iov = &msg_iov;
+		tagged_msg.desc = &mr_desc;
+		tagged_msg.iov_count = 1;
+		tagged_msg.addr = fi_addr;
+		tagged_msg.data = NO_CQ_DATA;
+		tagged_msg.context = ctx;
+		tagged_msg.tag = ft_tag ? ft_tag : tx_seq;
+		tagged_msg.ignore = 0;
+
+		ret = fi_trecvmsg(ep, &tagged_msg, flags);
+		if (ret) {
+			FT_PRINTERR("fi_trecvmsg", ret);
+			return ret;
+		}
+	} else {
+		msg.msg_iov = &msg_iov;
+		msg.desc = &mr_desc;
+		msg.iov_count = 1;
+		msg.addr = fi_addr;
+		msg.data = NO_CQ_DATA;
+		msg.context = ctx;
+
+		ret = fi_recvmsg(ep, &msg, flags);
+		if (ret) {
+			FT_PRINTERR("fi_recvmsg", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int ft_cq_read_verify(struct fid_cq *cq, void *op_context)
+{
+	int ret;
+	struct fi_cq_err_entry completion;
+
+	do {
+		/* read events from the completion queue */
+		ret = fi_cq_read(cq, (void *)&completion, 1);
+
+		if (ret > 0) {
+			if (op_context != completion.op_context) {
+				fprintf(stderr, "ERROR: op ctx=%p cq_ctx=%p\n",
+					op_context, completion.op_context);
+				return -FI_EOTHER;
+			}
+			if (!ft_tag_is_valid(cq, &completion,
+					     ft_tag ? ft_tag : rx_cq_cntr))
+				return -FI_EOTHER;
+		} else if ((ret <= 0) && (ret != -FI_EAGAIN)) {
+			FT_PRINTERR("POLL: Error\n", ret);
+			if (ret == -FI_EAVAIL)
+				FT_PRINTERR("POLL: error available\n", ret);
+			return -FI_EOTHER;
+		}
+	} while (ret == -FI_EAGAIN);
+
+	return 0;
+}
+
+int ft_cq_readerr(struct fid_cq *cq)
+{
+	struct fi_cq_err_entry cq_err;
+	int ret;
+
+	memset(&cq_err, 0, sizeof(cq_err));
+	ret = fi_cq_readerr(cq, &cq_err, 0);
+	if (ret < 0) {
+		FT_PRINTERR("fi_cq_readerr", ret);
+	} else {
+		FT_CQ_ERR(cq, cq_err, NULL, 0);
+		ret = -cq_err.err;
+	}
+	return ret;
+}
+
+void eq_readerr(struct fid_eq *eq, const char *eq_str)
+{
+	struct fi_eq_err_entry eq_err;
+	int rd;
+
+	memset(&eq_err, 0, sizeof(eq_err));
+	rd = fi_eq_readerr(eq, &eq_err, 0);
+	if (rd != sizeof(eq_err)) {
+		FT_PRINTERR("fi_eq_readerr", rd);
+	} else {
+		FT_EQ_ERR(eq, eq_err, NULL, 0);
+	}
+}
+
+int ft_sync()
+{
+	char buf;
+	int ret;
+
+	if (opts.dst_addr) {
+		if (!opts.oob_port) {
+			ret = ft_tx(ep, remote_fi_addr, 1, &tx_ctx);
+			if (ret)
+				return ret;
+
+			ret = ft_rx(ep, 1);
+		} else {
+			ret = ft_sock_send(oob_sock, &buf, 1);
+			if (ret)
+				return ret;
+
+			ret = ft_sock_recv(oob_sock, &buf, 1);
+			if (ret)
+				return ret;
+		}
+	} else {
+		if (!opts.oob_port) {
+			ret = ft_rx(ep, 1);
+			if (ret)
+				return ret;
+
+			ret = ft_tx(ep, remote_fi_addr, 1, &tx_ctx);
+		} else {
+			ret = ft_sock_recv(oob_sock, &buf, 1);
+			if (ret)
+				return ret;
+
+			ret = ft_sock_send(oob_sock, &buf, 1);
+			if (ret)
+				return ret;
+		}
+	}
+
+	return ret;
+}
+
+int ft_sync_pair(int status)
+{
+	int ret;
+	int pair_status;
+
+	if (ft_parent_proc) {
+		ret = write(ft_socket_pair[1], &status, sizeof(int));
+		if (ret < 0) {
+			FT_PRINTERR("write", errno);
+			return ret;
+		}
+		ret = read(ft_socket_pair[1], &pair_status, sizeof(int));
+		if (ret < 0) {
+			FT_PRINTERR("read", errno);
+			return ret;
+		}
+	} else {
+		ret = read(ft_socket_pair[0], &pair_status, sizeof(int));
+		if (ret < 0) {
+			FT_PRINTERR("read", errno);
+			return ret;
+		}
+		ret = write(ft_socket_pair[0], &status, sizeof(int));
+		if (ret < 0) {
+			FT_PRINTERR("write", errno);
+			return ret;
+		}
+	}
+
+	/* check status reported the other guy */
+	if (pair_status != FI_SUCCESS)
+		return pair_status;
+
+	return 0;
+}
+
+int ft_fork_and_pair(void)
+{
+	int ret;
+
+	ret = socketpair(AF_LOCAL, SOCK_STREAM, 0, ft_socket_pair);
+	if (ret) {
+		FT_PRINTERR("socketpair", errno);
+		return -errno;
+	}
+
+	ft_child_pid = fork();
+	if (ft_child_pid < 0) {
+		FT_PRINTERR("fork", ft_child_pid);
+		return -errno;
+	}
+	if (ft_child_pid)
+		ft_parent_proc = 1;
+
+	return 0;
+}
+
+int ft_wait_child(void)
+{
+	int ret;
+
+	ret = close(ft_socket_pair[0]);
+	if (ret) {
+		FT_PRINTERR("close", errno);
+		return ret;
+	}
+	ret = close(ft_socket_pair[1]);
+	if (ret) {
+		FT_PRINTERR("close", errno);
+		return ret;
+	}
+	if (ft_parent_proc) {
+		ret = waitpid(ft_child_pid, NULL, WCONTINUED);
+		if (ret < 0) {
+			FT_PRINTERR("waitpid", errno);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int ft_finalize_ep(struct fid_ep *ep)
+{
+	struct iovec iov;
+	int ret;
+	struct fi_context ctx;
+
+	strcpy(tx_buf + ft_tx_prefix_size(), "fin");
+	iov.iov_base = tx_buf;
+	iov.iov_len = 4 + ft_tx_prefix_size();
+
+	if (hints->caps & FI_TAGGED) {
+		struct fi_msg_tagged tmsg;
+
+		memset(&tmsg, 0, sizeof tmsg);
+		tmsg.msg_iov = &iov;
+		tmsg.desc = &mr_desc;
+		tmsg.iov_count = 1;
+		tmsg.addr = remote_fi_addr;
+		tmsg.tag = tx_seq;
+		tmsg.ignore = 0;
+		tmsg.context = &ctx;
+
+		ret = fi_tsendmsg(ep, &tmsg, FI_INJECT | FI_TRANSMIT_COMPLETE);
+	} else {
+		struct fi_msg msg;
+
+		memset(&msg, 0, sizeof msg);
+		msg.msg_iov = &iov;
+		msg.desc = &mr_desc;
+		msg.iov_count = 1;
+		msg.addr = remote_fi_addr;
+		msg.context = &ctx;
+
+		ret = fi_sendmsg(ep, &msg, FI_INJECT | FI_TRANSMIT_COMPLETE);
+	}
+	if (ret) {
+		FT_PRINTERR("transmit", ret);
+		return ret;
+	}
+
+
+	ret = ft_get_tx_comp(++tx_seq);
+	if (ret)
+		return ret;
+
+	ret = ft_get_rx_comp(rx_seq);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int ft_finalize(void)
+{
+	int ret;
+
+	if (fi->domain_attr->mr_mode & FI_MR_RAW) {
+		ret = fi_mr_unmap_key(domain, remote.key);
+		if (ret)
+			return ret;
+	}
+
+	return ft_finalize_ep(ep);
+}
+
+int64_t get_elapsed(const struct timespec *b, const struct timespec *a,
+		    enum precision p)
+{
+	int64_t elapsed;
+
+	elapsed = difftime(a->tv_sec, b->tv_sec) * 1000 * 1000 * 1000;
+	elapsed += a->tv_nsec - b->tv_nsec;
+	return elapsed / p;
+}
+
+void show_perf(char *name, int tsize, int iters, struct timespec *start,
+		struct timespec *end, int xfers_per_iter)
+{
+	static int header = 1;
+	char str[FT_STR_LEN];
+	int64_t elapsed = get_elapsed(start, end, MICRO);
+	long long bytes = (long long) iters * tsize * xfers_per_iter;
+	float usec_per_xfer;
+
+	if (name) {
+		if (header) {
+			printf("%-50s%-8s%-8s%-8s%8s %10s%13s%13s\n",
+					"name", "bytes", "iters",
+					"total", "time", "MB/sec",
+					"usec/xfer", "Mxfers/sec");
+			header = 0;
+		}
+
+		printf("%-50s", name);
+	} else {
+		if (header) {
+			printf("%-8s%-8s%-8s%8s %10s%13s%13s\n",
+					"bytes", "iters", "total",
+					"time", "MB/sec", "usec/xfer",
+					"Mxfers/sec");
+			header = 0;
+		}
+	}
+
+	printf("%-8s", size_str(str, tsize));
+
+	printf("%-8s", cnt_str(str, iters));
+
+	printf("%-8s", size_str(str, bytes));
+
+	usec_per_xfer = ((float)elapsed / iters / xfers_per_iter);
+	printf("%8.2fs%10.2f%11.2f%11.2f\n",
+		elapsed / 1000000.0, bytes / (1.0 * elapsed),
+		usec_per_xfer, 1.0/usec_per_xfer);
+}
+
+void show_perf_mr(int tsize, int iters, struct timespec *start,
+		  struct timespec *end, int xfers_per_iter, int argc, char *argv[])
+{
+	static int header = 1;
+	int64_t elapsed = get_elapsed(start, end, MICRO);
+	long long total = (long long) iters * tsize * xfers_per_iter;
+	int i;
+	float usec_per_xfer;
+
+	if (header) {
+		printf("---\n");
+
+		for (i = 0; i < argc; ++i)
+			printf("%s ", argv[i]);
+
+		printf(":\n");
+		header = 0;
+	}
+
+	usec_per_xfer = ((float)elapsed / iters / xfers_per_iter);
+
+	printf("- { ");
+	printf("xfer_size: %d, ", tsize);
+	printf("iterations: %d, ", iters);
+	printf("total: %lld, ", total);
+	printf("time: %f, ", elapsed / 1000000.0);
+	printf("MB/sec: %f, ", (total) / (1.0 * elapsed));
+	printf("usec/xfer: %f, ", usec_per_xfer);
+	printf("Mxfers/sec: %f", 1.0/usec_per_xfer);
+	printf(" }\n");
+}
+
+void ft_addr_usage()
+{
+	FT_PRINT_OPTS_USAGE("-B <src_port>", "non default source port number");
+	FT_PRINT_OPTS_USAGE("-P <dst_port>", "non default destination port number");
+	FT_PRINT_OPTS_USAGE("-s <address>", "source address");
+	FT_PRINT_OPTS_USAGE("-b[=<oob_port>]", "enable out-of-band address exchange and "
+			"synchronization over the, optional, port");
+}
+
+void ft_usage(char *name, char *desc)
+{
+	fprintf(stderr, "Usage:\n");
+	fprintf(stderr, "  %s [OPTIONS]\t\tstart server\n", name);
+	fprintf(stderr, "  %s [OPTIONS] <host>\tconnect to server\n", name);
+
+	if (desc)
+		fprintf(stderr, "\n%s\n", desc);
+
+	fprintf(stderr, "\nOptions:\n");
+	ft_addr_usage();
+	FT_PRINT_OPTS_USAGE("-f <fabric>", "fabric name");
+	FT_PRINT_OPTS_USAGE("-d <domain>", "domain name");
+	FT_PRINT_OPTS_USAGE("-p <provider>", "specific provider name eg sockets, verbs");
+	FT_PRINT_OPTS_USAGE("-e <ep_type>", "Endpoint type: msg|rdm|dgram (default:rdm)");
+	FT_PRINT_OPTS_USAGE("", "Only the following tests support this option for now:");
+	FT_PRINT_OPTS_USAGE("", "fi_rma_bw");
+	FT_PRINT_OPTS_USAGE("", "fi_shared_ctx");
+	FT_PRINT_OPTS_USAGE("", "fi_multi_mr");
+	FT_PRINT_OPTS_USAGE("", "fi_multi_ep");
+	FT_PRINT_OPTS_USAGE("", "fi_recv_cancel");
+	FT_PRINT_OPTS_USAGE("", "fi_unexpected_msg");
+	FT_PRINT_OPTS_USAGE("", "fi_resmgmt_test");
+	FT_PRINT_OPTS_USAGE("", "fi_inj_complete");
+	FT_PRINT_OPTS_USAGE("-a <address vector name>", "name of address vector");
+	FT_PRINT_OPTS_USAGE("-h", "display this help output");
+
+	return;
+}
+
+void ft_mcusage(char *name, char *desc)
+{
+	fprintf(stderr, "Usage:\n");
+	fprintf(stderr, "  %s [OPTIONS] -M <mcast_addr>\tstart listener\n", name);
+	fprintf(stderr, "  %s [OPTIONS] <mcast_addr>\tsend to group\n", name);
+
+	if (desc)
+		fprintf(stderr, "\n%s\n", desc);
+
+	fprintf(stderr, "\nOptions:\n");
+	ft_addr_usage();
+	FT_PRINT_OPTS_USAGE("-f <fabric>", "fabric name");
+	FT_PRINT_OPTS_USAGE("-d <domain>", "domain name");
+	FT_PRINT_OPTS_USAGE("-p <provider>", "specific provider name eg sockets, verbs");
+	FT_PRINT_OPTS_USAGE("-d <domain>", "domain name");
+	FT_PRINT_OPTS_USAGE("-p <provider>", "specific provider name eg sockets, verbs");
+	FT_PRINT_OPTS_USAGE("-h", "display this help output");
+
+	return;
+}
+
+void ft_csusage(char *name, char *desc)
+{
+	ft_usage(name, desc);
+	FT_PRINT_OPTS_USAGE("-I <number>", "number of iterations");
+	FT_PRINT_OPTS_USAGE("-w <number>", "number of warmup iterations");
+	FT_PRINT_OPTS_USAGE("-S <size>", "specific transfer size or 'all'");
+	FT_PRINT_OPTS_USAGE("-l", "align transmit and receive buffers to page size");
+	FT_PRINT_OPTS_USAGE("-m", "machine readable output");
+	FT_PRINT_OPTS_USAGE("-t <type>", "completion type [queue, counter]");
+	FT_PRINT_OPTS_USAGE("-c <method>", "completion method [spin, sread, fd]");
+	FT_PRINT_OPTS_USAGE("-h", "display this help output");
+
+	return;
+}
+
+void ft_parseinfo(int op, char *optarg, struct fi_info *hints)
+{
+	switch (op) {
+	case 'f':
+		if (!hints->fabric_attr) {
+			hints->fabric_attr = malloc(sizeof *(hints->fabric_attr));
+			if (!hints->fabric_attr) {
+				perror("malloc");
+				exit(EXIT_FAILURE);
+			}
+		}
+		hints->fabric_attr->name = strdup(optarg);
+		break;
+	case 'd':
+		if (!hints->domain_attr) {
+			hints->domain_attr = malloc(sizeof *(hints->domain_attr));
+			if (!hints->domain_attr) {
+				perror("malloc");
+				exit(EXIT_FAILURE);
+			}
+		}
+		hints->domain_attr->name = strdup(optarg);
+		break;
+	case 'p':
+		if (!hints->fabric_attr) {
+			hints->fabric_attr = malloc(sizeof *(hints->fabric_attr));
+			if (!hints->fabric_attr) {
+				perror("malloc");
+				exit(EXIT_FAILURE);
+			}
+		}
+		hints->fabric_attr->prov_name = strdup(optarg);
+		break;
+	case 'e':
+		if (!strncasecmp("msg", optarg, 3))
+			hints->ep_attr->type = FI_EP_MSG;
+		if (!strncasecmp("rdm", optarg, 3))
+			hints->ep_attr->type = FI_EP_RDM;
+		if (!strncasecmp("dgram", optarg, 5))
+			hints->ep_attr->type = FI_EP_DGRAM;
+		break;
+	default:
+		/* let getopt handle unknown opts*/
+		break;
+
+	}
+}
+
+void ft_parse_addr_opts(int op, char *optarg, struct ft_opts *opts)
+{
+	switch (op) {
+	case 's':
+		opts->src_addr = optarg;
+		break;
+	case 'B':
+		opts->src_port = optarg;
+		break;
+	case 'P':
+		opts->dst_port = optarg;
+		break;
+	case 'b':
+		opts->options |= FT_OPT_OOB_SYNC;
+		if (optarg && strlen(optarg) > 1)
+			opts->oob_port = optarg + 1;
+		else
+			opts->oob_port = default_oob_port;
+		break;
+	default:
+		/* let getopt handle unknown opts*/
+		break;
+	}
+}
+
+void ft_parsecsopts(int op, char *optarg, struct ft_opts *opts)
+{
+	ft_parse_addr_opts(op, optarg, opts);
+
+	switch (op) {
+	case 'I':
+		opts->options |= FT_OPT_ITER;
+		opts->iterations = atoi(optarg);
+		break;
+	case 'S':
+		if (!strncasecmp("all", optarg, 3)) {
+			opts->sizes_enabled = FT_ENABLE_ALL;
+		} else {
+			opts->options |= FT_OPT_SIZE;
+			opts->transfer_size = atoi(optarg);
+		}
+		break;
+	case 'm':
+		opts->machr = 1;
+		break;
+	case 'c':
+		if (!strncasecmp("sread", optarg, 5))
+			opts->comp_method = FT_COMP_SREAD;
+		else if (!strncasecmp("fd", optarg, 2))
+			opts->comp_method = FT_COMP_WAIT_FD;
+		break;
+	case 't':
+		if (!strncasecmp("counter", optarg, 7)) {
+			opts->options |= FT_OPT_RX_CNTR | FT_OPT_TX_CNTR;
+			opts->options &= ~(FT_OPT_RX_CQ | FT_OPT_TX_CQ);
+		}
+		break;
+	case 'a':
+		opts->av_name = optarg;
+		break;
+	case 'w':
+		opts->warmup_iterations = atoi(optarg);
+		break;
+	case 'l':
+		opts->options |= FT_OPT_ALIGN;
+		break;
+	default:
+		/* let getopt handle unknown opts*/
+		break;
+	}
+}
+
+int ft_parse_rma_opts(int op, char *optarg, struct fi_info *hints,
+		      struct ft_opts *opts)
+{
+	switch (op) {
+	case 'o':
+		if (!strcmp(optarg, "read")) {
+			hints->caps |= FI_READ | FI_REMOTE_READ;
+			opts->rma_op = FT_RMA_READ;
+		} else if (!strcmp(optarg, "writedata")) {
+			hints->caps |= FI_WRITE | FI_REMOTE_WRITE;
+			hints->mode |= FI_RX_CQ_DATA;
+			hints->domain_attr->cq_data_size = 4;
+			opts->rma_op = FT_RMA_WRITEDATA;
+			cq_attr.format = FI_CQ_FORMAT_DATA;
+		} else if (!strcmp(optarg, "write")) {
+			hints->caps |= FI_WRITE | FI_REMOTE_WRITE;
+			opts->rma_op = FT_RMA_WRITE;
+		} else {
+			fprintf(stderr, "Invalid operation type: \"%s\". Usage:\n"
+					"-o <op>\trma op type: read|write|writedata "
+				       "(default:write)\n", optarg);
+			return EXIT_FAILURE;
+		}
+		break;
+	default:
+		/* let getopt handle unknown opts*/
+		break;
+	}
+	return 0;
+}
+
+void ft_fill_buf(void *buf, int size)
+{
+	char *msg_buf;
+	int msg_index;
+	static unsigned int iter = 0;
+	int i;
+
+	msg_index = ((iter++)*INTEG_SEED) % integ_alphabet_length;
+	msg_buf = (char *)buf;
+	for (i = 0; i < size; i++) {
+		msg_buf[i] = integ_alphabet[msg_index++];
+		if (msg_index >= integ_alphabet_length)
+			msg_index = 0;
+	}
+}
+
+int ft_check_buf(void *buf, int size)
+{
+	char *recv_data;
+	char c;
+	static unsigned int iter = 0;
+	int msg_index;
+	int i;
+
+	msg_index = ((iter++)*INTEG_SEED) % integ_alphabet_length;
+	recv_data = (char *)buf;
+
+	for (i = 0; i < size; i++) {
+		c = integ_alphabet[msg_index++];
+		if (msg_index >= integ_alphabet_length)
+			msg_index = 0;
+		if (c != recv_data[i])
+			break;
+	}
+	if (i != size) {
+		printf("Error at iteration=%d size=%d byte=%d\n",
+			iter, size, i);
+		return 1;
+	}
+
+	return 0;
+}
+
+uint64_t ft_init_cq_data(struct fi_info *info)
+{
+	if (info->domain_attr->cq_data_size >= sizeof(uint64_t)) {
+		return 0x0123456789abcdefULL;
+	} else {
+		return 0x0123456789abcdef &
+			((0x1ULL << (info->domain_attr->cq_data_size * 8)) - 1);
+	}
+}
+
+int check_recv_msg(const char *message)
+{
+	size_t recv_len;
+	size_t message_len = strlen(message) + 1;
+	/* Account for null terminated byte. */
+	recv_len = strlen(rx_buf) + 1;
+
+	if (recv_len != message_len) {
+		fprintf(stderr, "Received length does not match expected length.\n");
+		return -1;
+	}
+
+	if (strncmp(rx_buf, message, message_len)) {
+		fprintf(stderr, "Received message does not match expected message.\n");
+		return -1;
+	}
+	fprintf(stdout, "Data check OK\n");
+	return 0;
+}
+
+int ft_send_greeting(struct fid_ep *ep)
+{
+	size_t message_len = strlen(greeting) + 1;
+	int ret;
+
+	fprintf(stdout, "Sending message...\n");
+	if (snprintf(tx_buf, tx_size, "%s", greeting) >= tx_size) {
+		fprintf(stderr, "Transmit buffer too small.\n");
+		return -FI_ETOOSMALL;
+	}
+
+	ret = ft_tx(ep, remote_fi_addr, message_len, &tx_ctx);
+	if (ret)
+		return ret;
+
+	fprintf(stdout, "Send completion received\n");
+	return 0;
+}
+
+int ft_recv_greeting(struct fid_ep *ep)
+{
+	int ret;
+
+	fprintf(stdout, "Waiting for message from client...\n");
+	ret = ft_get_rx_comp(rx_seq);
+	if (ret)
+		return ret;
+
+	ret = check_recv_msg(greeting);
+	if (ret)
+		return ret;
+
+	fprintf(stdout, "Received data from client: %s\n", (char *) rx_buf);
+	return 0;
+}
+
+int ft_send_recv_greeting(struct fid_ep *ep)
+{
+	return opts.dst_addr ? ft_send_greeting(ep) : ft_recv_greeting(ep);
+}
+
+int ft_sock_listen(char *node, char *service)
+{
+	struct addrinfo *ai, hints;
+	int val, ret;
+
+	memset(&hints, 0, sizeof hints);
+	hints.ai_flags = AI_PASSIVE;
+
+	ret = getaddrinfo(node, service, &hints, &ai);
+	if (ret) {
+		fprintf(stderr, "getaddrinfo() %s\n", gai_strerror(ret));
+		return ret;
+	}
+
+	listen_sock = socket(ai->ai_family, SOCK_STREAM, 0);
+	if (listen_sock < 0) {
+		perror("socket");
+		ret = listen_sock;
+		goto out;
+	}
+
+	val = 1;
+	ret = setsockopt(listen_sock, SOL_SOCKET, SO_REUSEADDR,
+			 (void *) &val, sizeof val);
+	if (ret) {
+		perror("setsockopt SO_REUSEADDR");
+		goto out;
+	}
+
+	ret = bind(listen_sock, ai->ai_addr, ai->ai_addrlen);
+	if (ret) {
+		perror("bind");
+		goto out;
+	}
+
+	ret = listen(listen_sock, 0);
+	if (ret)
+		perror("listen");
+
+out:
+	if (ret && listen_sock >= 0)
+		close(listen_sock);
+	freeaddrinfo(ai);
+	return ret;
+}
+
+int ft_sock_connect(char *node, char *service)
+{
+	struct addrinfo *ai;
+	int ret;
+
+	ret = getaddrinfo(node, service, NULL, &ai);
+	if (ret) {
+		perror("getaddrinfo");
+		return ret;
+	}
+
+	sock = socket(ai->ai_family, SOCK_STREAM, 0);
+	if (sock < 0) {
+		perror("socket");
+		ret = sock;
+		goto free;
+	}
+
+	ret = 1;
+	ret = setsockopt(sock, IPPROTO_TCP, TCP_NODELAY, (void *) &ret, sizeof(ret));
+	if (ret)
+		perror("setsockopt");
+
+	ret = connect(sock, ai->ai_addr, ai->ai_addrlen);
+	if (ret) {
+		perror("connect");
+		close(sock);
+	}
+
+free:
+	freeaddrinfo(ai);
+	return ret;
+}
+
+int ft_sock_accept()
+{
+	int ret, op;
+
+	sock = accept(listen_sock, NULL, 0);
+        if (sock < 0) {
+		ret = sock;
+		perror("accept");
+		return ret;
+	}
+
+	op = 1;
+	ret = setsockopt(sock, IPPROTO_TCP, TCP_NODELAY,
+			  (void *) &op, sizeof(op));
+	if (ret)
+		perror("setsockopt");
+
+	return 0;
+}
+
+int ft_sock_send(int fd, void *msg, size_t len)
+{
+	int ret;
+
+	ret = send(fd, msg, len, 0);
+	if (ret == len) {
+		return 0;
+	} else if (ret < 0) {
+		perror("send");
+		return -errno;
+	} else {
+		perror("send aborted");
+		return -FI_ECONNABORTED;
+	}
+}
+
+int ft_sock_recv(int fd, void *msg, size_t len)
+{
+	int ret;
+
+	ret = recv(fd, msg, len, MSG_WAITALL);
+	if (ret == len) {
+		return 0;
+	} else if (ret == 0) {
+		return -FI_ENOTCONN;
+	} else if (ret < 0) {
+		FT_PRINTERR("ft_fw_recv", ret);
+		perror("recv");
+		return -errno;
+	} else {
+		perror("recv aborted");
+		return -FI_ECONNABORTED;
+	}
+}
+
+int ft_sock_sync(int value)
+{
+	int result = -FI_EOTHER;
+
+	if (listen_sock < 0) {
+		ft_sock_send(sock, &value,  sizeof value);
+		ft_sock_recv(sock, &result, sizeof result);
+	} else {
+		ft_sock_recv(sock, &result, sizeof result);
+		ft_sock_send(sock, &value,  sizeof value);
+	}
+
+	return result;
+}
+
+void ft_sock_shutdown(int fd)
+{
+	shutdown(fd, SHUT_RDWR);
+	close(fd);
+}
+
+static int ft_has_util_prefix(const char *str)
+{
+	return !strncasecmp(str, OFI_UTIL_PREFIX, strlen(OFI_UTIL_PREFIX));
+}
+
+const char *ft_util_name(const char *str, size_t *len)
+{
+	char *delim;
+
+	delim = strchr(str, OFI_NAME_DELIM);
+	if (delim) {
+		if (ft_has_util_prefix(delim + 1)) {
+			*len = strlen(delim + 1);
+			return delim + 1;
+		} else if (ft_has_util_prefix(str)) {
+			*len = delim - str;
+			return str;
+		}
+	} else if (ft_has_util_prefix(str)) {
+		*len = strlen(str);
+		return str;
+	}
+	*len = 0;
+	return NULL;
+}
+
+const char *ft_core_name(const char *str, size_t *len)
+{
+	char *delim;
+
+	delim = strchr(str, OFI_NAME_DELIM);
+	if (delim) {
+		if (!ft_has_util_prefix(delim + 1)) {
+			*len = strlen(delim + 1);
+			return delim + 1;
+		} else if (!ft_has_util_prefix(str)) {
+			*len = delim - str;
+			return str;
+		}
+	} else if (!ft_has_util_prefix(str)) {
+		*len = strlen(str);
+		return str;
+	}
+	*len = 0;
+	return NULL;
+}
+
+/* Split the given string "s" using the specified delimiter(s) in the string
+ * "delim" and return an array of strings. The array is terminated with a NULL
+ * pointer. Returned array should be freed with ft_free_string_array().
+ *
+ * Returns NULL on failure.
+ */
+
+char **ft_split_and_alloc(const char *s, const char *delim, size_t *count)
+{
+	int i, n;
+	char *tmp;
+	char *dup = NULL;
+	char **arr = NULL;
+
+	if (!s || !delim)
+		return NULL;
+
+	dup = strdup(s);
+	if (!dup)
+		return NULL;
+
+	/* compute the array size */
+	n = 1;
+	for (tmp = dup; *tmp != '\0'; ++tmp) {
+		for (i = 0; delim[i] != '\0'; ++i) {
+			if (*tmp == delim[i]) {
+				++n;
+				break;
+			}
+		}
+	}
+
+	/* +1 to leave space for NULL terminating pointer */
+	arr = calloc(n + 1, sizeof(*arr));
+	if (!arr)
+		goto cleanup;
+
+	/* set array elts to point inside the dup'ed string */
+	for (tmp = dup, i = 0; tmp != NULL; ++i) {
+		arr[i] = strsep(&tmp, delim);
+	}
+	assert(i == n);
+
+	if (count)
+		*count = n;
+	return arr;
+
+cleanup:
+	free(dup);
+	free(arr);
+	return NULL;
+}
+
+/* see ft_split_and_alloc() */
+void ft_free_string_array(char **s)
+{
+	/* all strings are allocated from the same strdup'ed slab, so just free
+	 * the first element */
+	if (s != NULL)
+		free(s[0]);
+
+	/* and then the actual array of pointers */
+	free(s);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/windows/getopt.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/windows/getopt.c
new file mode 100644
index 000000000..3eb62d12d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/windows/getopt.c
@@ -0,0 +1,727 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <assert.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdio.h>
+
+#include "getopt.h"
+
+#ifndef min
+# define min(x,y) (x)<(y) ? (x) : (y)
+#endif // min
+
+char *optarg = 0;
+int optind = 1;
+int opterr = 1;
+int optopt = '?';
+static int nextchar = 0;
+
+typedef struct _getopt_param
+{
+	const char* optstring;	/* effective option string, without prefixes */
+	int posix;		/* POSIX compatible mode (stop at first not detected parameter) */
+	int process_all;	/* process all elements */
+	int no_report;		/* don't report about errors... */
+	char missing_arg;	/* character for return for missing option argument
+				 * by default - '?', but may be ':' */
+} getopt_param;
+
+
+/* this function detects for parameters of processing */
+static getopt_param scan_param(const char* optstring)
+{
+	assert(optstring);
+	getopt_param param = {optstring, 0, 0, 0, '?'};
+	size_t len = strlen(optstring);
+
+	if (!opterr)
+		param.no_report = 1;
+
+	for (size_t i = 0; i < len; i++) { 
+	/* if option string begins with symbols '-+:' then this is special symbols... */
+		switch (optstring[i]) {
+		case '-':
+			param.process_all = 1;
+			break;
+		case '+':
+			param.posix = 1;
+			break;
+		case ':':
+			param.missing_arg = ':';
+			param.no_report = 1; /* i don't know why, but if optstrings starts with */
+			break; /* ':' - original Linux function doesn't report about errors... */
+		default: /* ok, no more special symbols... save efective format string & return */
+			param.optstring = optstring + i;
+			return param;
+		}
+	}
+	assert(0); /* no more symbols? not good :( */
+	return param;
+}
+
+/* this function detects different between 2 strings:
+ * return values:
+ * -1 - strings differ
+ *  0  - strings same
+ * >0 - str is substring of opt */
+static int string_diff(const char* opt, const char* str, int len)
+{
+	assert(opt);
+	assert(str);
+	assert(len);
+	assert(len <= (int)strlen(str));
+
+	int olen = strlen(opt);
+
+	if(olen < len)
+		return -1;
+
+	for (int i = 0;; i++) {
+		if (!opt[i] && i == len)
+			return 0; /* option == str */
+		else if (opt[i] && i >= len)
+			return olen - i; /* str is part of option */
+		else if (opt[i] != str[i])
+			return -1; /* option is shorter str...
+				    * in str specified option name longer that option */
+	}
+}
+
+typedef enum _opt_type
+{
+	opt_not_found		= 0,
+	opt_err_no_arg		= 1,
+	opt_err_ambiguous	= 2,
+	opt_single		= 3,
+	opt_inplace_arg		= 4,
+	opt_has_arg		= 5
+} opt_type;
+
+
+/* check for short option... should be like "-opt_name" */
+static int is_short_option(const char* str)
+{
+	return (str[0] == '-' && str[1] && str[1] != '-');
+}
+
+/* check for long option... should be like "--opt_name" */
+static int is_long_option(const char* str)
+{
+	return (str[0] == '-' && str[1] == '-' && str[2]);
+}
+
+static int is_option(const char* str)
+{
+	return (is_short_option(str) || is_long_option(str));
+}
+
+static int is_finish(const char* str)
+{ /* if string == "--" - then this is terminator (no more process) */
+	return (str[0] == '-' && str[1] == '-' && !str[2]);
+}
+
+static int short_option_begin(const char* str)
+{ /* currently this is fake because supported only '-' as attribute of short option */
+	(void) str;
+	return 1;
+}
+
+static int long_option_begin(const char* str)
+{ /* currently this is fake because supported only '--' as attribute of long option */
+	(void) str;
+	return 2;
+}
+
+static int option_begin(const char* str)
+{
+	if (is_short_option(str))
+		return short_option_begin(str);
+	else if (is_long_option(str))
+		return long_option_begin(str);
+	assert(0);
+	return 0;
+}
+
+/* looking for nearest option or terminate sequence ('--')
+ * in argv from optind index if no option found - return -1,
+ * else - index of found option */
+static int look_for_option(int argc, char* const argv[], int optind)
+{
+	assert(argv);
+	for (int i = optind; i < argc; i++)
+		if(is_option(argv[i]) || is_finish(argv[i]))
+			return i;
+	return -1;
+}
+
+/* this function tries to detect short option entry in string */
+static opt_type check_for_short_option(const char* optstring, const char* str)
+{
+	assert(optstring);
+	assert(str);
+
+	size_t olen = strlen(optstring);
+	size_t slen = strlen(str);
+
+	if (!olen || !slen)
+		return opt_not_found;
+
+	char sym = str[0];
+	/* loop for all options in optstring */
+	for (size_t i = 0; i < olen; i++ ) {
+		/* ok, we found option... */
+		if (optstring[i] != ':' && optstring[i] == sym) {
+			/* let's check is it valid? */
+			if (optstring[i + 1] != ':') {
+				/* single option... just return... */
+				return opt_single;
+			}
+			else if (optstring[i+1] == ':' && optstring[i+2] != ':') { 
+				/* mandatory argument */
+				if (str[1]) /* value of arg is in same argv */
+					return opt_inplace_arg;
+				else /* else next arg is value of option */
+					return opt_has_arg;
+			}
+			else { /* optional argument */
+				if (str[1]) /* value of arg is in same argv */
+					return opt_inplace_arg;
+				else /* else optional argument is absent */
+					return opt_single;
+			}
+		}
+	}
+
+	return opt_not_found;
+}
+
+/* this function tries to detect long option entry in string */
+static opt_type check_for_long_option(const struct option *longopts, int *longindex,
+				      const char* str, const char** arg)
+{
+	assert(longindex);
+	assert(str);
+
+	*arg = 0;
+
+	if (!longopts)
+		return opt_not_found;
+
+	/* looking for '=' in string... */
+	int i;
+	for (i = 0; str[i] && str[i] != '='; i++);
+	assert(str[i] == '=' || !str[i]);
+
+	int len = i; /* len used for detecting length of option name in string */
+
+	if (str[i] == '=' && str[i+1]) /* ok, symbol '=' detected... */
+		*arg = str + i + 1; /* set potential option name substring length */
+
+	/* detecting the nearest option name to string */
+	int index = 1;
+	const char* opt = longopts->name;
+
+	if (!opt)
+		return opt_not_found;
+
+	int diff = string_diff(opt, str, len);
+	int selected = diff >= 0 ? 0 : -1;
+	int ambiguous = 0;
+
+	while (longopts[index].name) {
+		opt = longopts[index].name;
+
+		int _diff = string_diff(opt, str, len);
+		if (!_diff) {
+			diff = 0;
+			selected = index;
+			break;
+		}
+
+		if (_diff > 0 && diff > 0) {
+			ambiguous = 1; /* detected 2 or more options which are confirms string */
+		}
+		else if (_diff > 0 && (_diff < diff || diff < 0)) {
+			diff = _diff;
+			selected = index;
+		}
+		index++;
+	}
+
+	if (ambiguous && diff > 0) /* if detected multiple confirms and no exact match - return error */
+		return opt_err_ambiguous;
+
+	if (selected >= 0) {
+		if (longopts[selected].has_arg == no_argument && *arg) {
+			return opt_err_no_arg; /* argument is not required but specified */
+		}
+		else if (longopts[selected].has_arg == no_argument /*&& !arg*/) {
+			*longindex = index;
+			return opt_single; // option without argument
+		}
+		else if (longopts[selected].has_arg == required_argument && *arg) {
+			*longindex = index;
+			return opt_inplace_arg;
+		}
+		else if (longopts[selected].has_arg == required_argument /*&& !arg*/) {
+			*longindex = index;
+			return opt_has_arg;
+		}
+		else if (longopts[selected].has_arg == optional_argument && *arg) {
+			*longindex = index;
+			return opt_inplace_arg;
+		}
+		else if (longopts[selected].has_arg == optional_argument /*&& !arg*/) {
+			*longindex = index;
+			return opt_single; // option without argument
+		}
+	}
+	return opt_not_found;
+}
+
+/* here stored all numbers of elements which should be placed at end of argv list */
+static int* swap_list = 0;
+static int  swap_num = 0;
+
+static void clear_swap()
+{
+	if (swap_list)
+		free( swap_list );
+	swap_list = 0;
+	swap_num = 0;
+}
+
+/* adding index to list */
+static void add_to_swap(int idx, int num)
+{
+	assert(!swap_list && !swap_num || swap_list && swap_num);
+	assert(num);
+
+	if (!swap_num)
+		swap_list = (int*)malloc(sizeof(*swap_list) * num);
+	else
+		swap_list = (int*)realloc(swap_list,
+					  sizeof(*swap_list) * (swap_num + num));
+	assert(swap_list);
+
+	for(int i = 0; i < num; i++)
+		swap_list[swap_num + i] = idx + i;
+	swap_num += num;
+}
+
+/* swap values in array
+ * this function moves elements enumrated in swap_list to end of
+ * argv vector...
+ * arguments:
+ *	argc   - size of argv vector (used mostly for control of length,
+ *		 to be sure that we are inside of vector)
+ *	argv   - vector to process
+ *	optind - bound of process... argv vector is processed in range 0..optind */
+static void swap_values(int argc, char** argv, int _optind)
+{
+	assert(_optind >= swap_num);
+	assert(_optind <= argc);
+
+	int i; /* index for original array */
+	int j; /* index for temp array */
+	int k; /* index for swap array */
+
+	int vals = min(argc, _optind);
+
+	char** tmp = (char**)malloc(vals * sizeof(*tmp));
+	assert(tmp);
+
+	for (i = j = k = 0; i < vals && j < vals; i++)
+	{
+		/* copying all elements which NOT enumerated in swap_list array to temp array */
+		if (k >= swap_num || i != swap_list[k])
+			tmp[j++] = argv[i];
+		else {
+			/* if index of element is in swap_list array - then just skip this element
+			 * NOTE: swap_list array is SORTED, that is why we can to not run
+			 * throgh whole swap_list array in every iteration */
+			assert(k < swap_num);
+			k++;
+		}
+	}
+
+	/* ok, now copy rest of array (skipped elements) to temp array */
+	for (k = 0; j < vals && k < swap_num; k++, j++) {
+		assert(swap_list[k] < _optind);
+		assert(swap_list[k] < argc);
+		tmp[j] = argv[swap_list[k]];
+	}
+
+	/* and now save tmp array to argv */
+	for (i = 0; i < vals; i++)
+		argv[i] = tmp[i];
+
+	free(tmp);
+
+	optind -= swap_num;
+
+	clear_swap();
+}
+
+/* this function is called when we need to detect next option entry in argv
+ * return value:
+ *   1  - next option entry found, retval not used
+ *   0 - no more options, retval - reason (-1 no more options, 1 - argument
+ *	 processed as default option with code 1) */
+static int detect_next_option(int argc, char* const argv[],
+			      const getopt_param* param, int* retval)
+{
+    if (!is_option(argv[optind])) {
+	    /* if optind points to non-option - then check it... */
+		if (is_finish(argv[optind])) { 
+			/* is it terminate sequence ('--')? */
+			optind++;
+			if (!param->posix && !param->process_all)
+				swap_values(argc, (char**)argv, optind);
+			*retval = -1;
+			return 0;
+		}
+		else if (param->process_all) {
+			/* processing all elements */
+			optarg = (char*)argv[optind];
+			optind++;
+			*retval = 1;
+			return 0;
+		}
+		else if (param->posix) {
+			*retval = -1;
+			return 0;
+		}
+		else {
+			int next_ind = look_for_option(argc, argv, optind);
+			assert(next_ind != optind); /* should not be same */
+			if (next_ind > 0) {
+				/* marking elements for swap */
+				add_to_swap(optind, next_ind - optind); 
+				/* NOTE: in swap_list stored indexes of elements which are not
+				 * detected as options and not detected as arguments
+				 * (if argv[x] is detected as option - stsrts with '-',
+				 * it doesn't added to this list). later, when no more
+				 * element may be detected, these stored elements are moved
+				 * to end of argv vector */
+				optind = next_ind;
+			}
+			else {
+				/* no more options found */
+				swap_values(argc, (char**)argv, optind);
+				*retval = -1;
+				return 0;
+			}
+		}
+
+		if (is_finish(argv[optind])) {
+			optind++;
+			if (!param->posix && !param->process_all)
+				swap_values(argc, (char**)argv, optind);
+			*retval = -1;
+			return 0;
+		}
+	}
+	return 1;
+}
+
+/* this function is called when we are sure that option is short... */
+static int get_short_option(int argc, char* const argv[], const getopt_param* param)
+{
+	assert(argc);
+	assert(argv);
+	assert(nextchar);
+	assert(optind < argc);
+
+	const char* str = argv[optind] + nextchar;
+
+	switch (check_for_short_option(param->optstring, str)) {
+	case opt_not_found:
+		optopt = str[0];
+		nextchar++;
+		if (!argv[optind][nextchar]) {
+			nextchar = 0;
+			optind++;
+		}
+		if (!param->no_report)
+			printf("%s: invalid option -- %c\n", argv[0], optopt);
+		return '?';
+	case opt_err_no_arg:
+	/* somethibg wrong... check_for_short_option can't
+	 * detect absent external parameter... */
+	assert(0);
+	break;
+	case opt_single:
+	{
+		nextchar++;
+		if (!argv[optind][nextchar]) {
+			nextchar = 0;
+			optind++;
+		}
+		return str[0];
+	}
+	case opt_inplace_arg:
+		optarg = (char*)str + 1;
+		optind++;
+		nextchar = 0;
+		return str[0];
+	case opt_has_arg:
+		if (optind + 1 >= argc) { 
+			/* error: option hasn't argument */
+			optopt = str[0];
+			optind++;
+			nextchar = 0;
+			if (!param->no_report)
+				printf("%s: option requires an "
+				       "argument -- %c\n", argv[0],
+				       optopt);
+				return param->missing_arg;
+		}
+		else {
+			optarg = (char*)argv[optind + 1];
+			optind += 2;
+			nextchar = 0;
+			return str[0];
+		}
+	}
+
+	/* should not go here... */
+	assert(0);
+	return -1;
+}
+
+static int get_long_option(int argc, char* const argv[], const getopt_param* param,
+			   const struct option* longopts, int* longindex)
+{
+	assert(argc);
+	assert(argv);
+	assert(!nextchar);
+	assert(optind < argc);
+
+	optopt = 0;
+	*longindex = 0;
+
+	/* saving current argument for error message */
+	const char* element = argv[optind];
+
+	switch (check_for_long_option(longopts, longindex,
+		argv[optind] + option_begin(argv[optind]),
+		&optarg)) {
+	case opt_not_found:
+		if (!param->no_report)
+			printf("%s: unrecognized option `%s'\n",
+			       argv[0], element);
+			optind++;
+			return '?';
+	case opt_err_no_arg:
+		if (!param->no_report)
+			printf("%s: option `%s' doesn't allow an argument\n",
+			       argv[0], element);
+		optind++;
+		return '?';
+	case opt_has_arg:
+		if (optind + 1 >= argc) {
+			optind++;
+			if (!param->no_report)
+				printf("%s: option `%s' requires an argument\n",
+				       argv[0], element);
+			*longindex = 0;
+			return param->missing_arg;
+		}
+		optarg = (char*)(argv[optind + 1]);
+		optind++;
+		/* here should NOT be break because here is same return method */
+	case opt_single:
+	case opt_inplace_arg:
+		optind++;
+		if(longopts[*longindex].flag) {
+			*longopts[*longindex].flag = longopts[*longindex].val;
+			return 0;
+		}
+		else {
+			return longopts[*longindex].val;
+		}
+	case opt_err_ambiguous:
+		optind++;
+		if (!param->no_report)
+			printf("%s: option `%s' is ambiguous\n",
+			       argv[0], element);
+		return '?';
+	}
+
+	assert(0); /* should not be here... */
+	return -1;
+}
+
+static int get_long_short_option(int argc, char* const argv[], const getopt_param* param,
+				 const struct option* longopts, int* longindex)
+{
+	assert(argc);
+	assert(argv);
+	assert(!nextchar);
+	assert(optind < argc);
+
+	optopt = 0;
+	*longindex = 0;
+
+	const char* element = argv[optind]; /* saving current argument for error message */
+
+	opt_type ltype = check_for_long_option(longopts, longindex,
+					       argv[optind] + option_begin(argv[optind]),
+									   &optarg);
+	opt_type stype = check_for_short_option(param->optstring,
+						argv[optind] + option_begin(argv[optind]));
+
+	if (ltype == opt_not_found && stype == opt_not_found) {
+		if (!param->no_report)
+			printf("%s: unrecognized option `%s'\n",
+			       argv[0], element);
+		optind++;
+		return '?';
+	}
+	else if (ltype != opt_not_found)
+		return get_long_option(argc, argv, param, longopts, longindex);
+	else {
+		nextchar = short_option_begin(argv[optind]);
+		return get_short_option(argc, argv, param);
+	}
+}
+
+int getopt(int argc, char* const argv[], const char *optstring)
+{
+	if(!argc || !argv || !optstring )
+		return -1;
+
+	getopt_param param = scan_param(optstring ? optstring : "");
+
+	if (optind >= argc) {
+		if (!param.posix && !param.process_all)
+			swap_values(argc, (char**)argv, optind);
+		return -1;
+	}
+
+	optarg = 0;
+    
+	if (!nextchar) {
+		/* we are in begin of argument...
+		 * no previous iterations on this arg */
+		int retval;
+		if (!detect_next_option(argc, argv, &param, &retval))
+			return retval;
+		nextchar = short_option_begin(argv[optind]);
+	}
+
+	return get_short_option(argc, argv, &param);
+}
+
+int getopt_long(int argc, char * const argv[],
+		const char *optstring,
+		const struct option *longopts, int *longindex)
+{
+	if(!argc || !argv)
+		return -1;
+
+	getopt_param param = scan_param(optstring ? optstring : "");
+
+	if(optind >= argc) {
+		 if(!param.posix && !param.process_all)
+			swap_values(argc, (char**)argv, optind);
+		return -1;
+	}
+
+	optarg = 0;
+
+	if (!nextchar) {
+		/* we are in begin of argument...
+		 * no previous iterations on this arg */
+		int retval;
+		if (!detect_next_option(argc, argv, &param, &retval))
+			return retval;
+
+		const char* str = argv[optind];
+		if (is_long_option(str)) {
+			int _longindex;
+			/* if no longindex specified - create own temp... */
+			if (!longindex)
+				longindex = &_longindex;
+			return get_long_option(argc, argv, &param,
+					       longopts, longindex);
+		}
+		else if (is_short_option(str)) {
+			nextchar = short_option_begin(str);
+		}
+	}
+
+	return get_short_option(argc, argv, &param);
+}
+
+int getopt_long_only(int argc, char * const argv[],
+		     const char *optstring,
+		     const struct option *longopts, int *longindex)
+{
+	if (!argc || !argv)
+		return -1;
+
+	getopt_param param = scan_param(optstring ? optstring : "");
+
+	if (optind >= argc) {
+		if (!param.posix && !param.process_all)
+			swap_values(argc, (char**)argv, optind);
+		return -1;
+	}
+
+	optarg = 0;
+
+	if (!nextchar) {
+		int retval;
+		if (!detect_next_option(argc, argv, &param, &retval))
+			return retval;
+
+		const char* str = argv[optind];
+		if (is_long_option(str)) {
+			int _longindex;
+			/* if no longindex specified - create own temp... */
+			if (!longindex)
+				longindex = &_longindex;
+			return get_long_option(argc, argv, &param,
+					       longopts, longindex);
+		}
+		else if (is_short_option(str)) {
+			return get_long_short_option(argc, argv, &param, 
+						     longopts, longindex);
+		}
+	}
+
+	return get_short_option(argc, argv, &param);
+}
+
+
+
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/windows/osd.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/windows/osd.c
new file mode 100644
index 000000000..0e54de8bf
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/common/windows/osd.c
@@ -0,0 +1,87 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "ft_osd.h"
+
+int socketpair(int af, int type, int protocol, int socks[2])
+{
+	protocol; /* suppress warning */
+	struct sockaddr_in in_addr;
+	int lsock;
+	int len = sizeof(in_addr);
+
+	if (!socks) {
+		WSASetLastError(WSAEINVAL);
+		return SOCKET_ERROR;
+	}
+
+	socks[0] = socks[1] = (int)INVALID_SOCKET;
+	if ((lsock = socket(af == AF_UNIX ? AF_INET : af, 
+			    type, 0)) == INVALID_SOCKET) {
+		return SOCKET_ERROR;
+	}
+
+	memset(&in_addr, 0, sizeof(in_addr));
+	in_addr.sin_family = AF_INET;
+	in_addr.sin_addr.s_addr = htonl(0x7f000001);
+
+	if (bind(lsock, (struct sockaddr*)&in_addr, sizeof(in_addr))) {
+		int err = WSAGetLastError();
+		closesocket(lsock);
+		WSASetLastError(err);
+		return SOCKET_ERROR;
+	}
+	if (getsockname(lsock, (struct sockaddr*) &in_addr, &len)) {
+		int err = WSAGetLastError();
+		closesocket(lsock);
+		WSASetLastError(err);
+		return SOCKET_ERROR;
+	}
+
+	if (listen(lsock, 1))
+		goto err;
+	if ((socks[0] = WSASocket(af == AF_UNIX ? AF_INET : af, 
+				  type, 0, NULL, 0, 0)) == INVALID_SOCKET)
+		goto err;
+	if (connect(socks[0], (const struct sockaddr*) &in_addr, sizeof(in_addr)))
+		goto err;
+	if ((socks[1] = accept(lsock, NULL, NULL)) == INVALID_SOCKET)
+		goto err;
+
+	closesocket(lsock);
+	return 0;
+
+	int err;
+err:
+	err = WSAGetLastError();
+	closesocket(lsock);
+	closesocket(socks[0]);
+	closesocket(socks[1]);
+	WSASetLastError(err);
+	return SOCKET_ERROR;
+}
\ No newline at end of file
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/configure.ac b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/configure.ac
new file mode 100644
index 000000000..392375724
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/configure.ac
@@ -0,0 +1,125 @@
+dnl
+dnl Copyright (c) 2016-2017 Cisco Systems, Inc.  All rights reserved.
+dnl Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+dnl
+dnl Process this file with autoconf to produce a configure script.
+
+AC_PREREQ(2.57)
+AC_INIT([fabtests], [1.7.0], [ofiwg@lists.openfabrics.org])
+AC_CONFIG_AUX_DIR(config)
+AC_CONFIG_MACRO_DIR(config)
+AC_CONFIG_HEADERS(config.h)
+AM_INIT_AUTOMAKE([1.11 dist-bzip2 foreign -Wall -Werror subdir-objects])
+m4_ifdef([AM_SILENT_RULES], [AM_SILENT_RULES([yes])])
+
+AC_CANONICAL_HOST
+
+macos=0
+linux=0
+freebsd=0
+
+case $host_os in
+*darwin*)
+	macos=1
+	;;
+*linux*)
+	linux=1
+	;;
+*freebsd*)
+	freebsd=1
+	;;
+*)
+	AC_MSG_ERROR([libfabric only builds on Linux & OS X])
+	;;
+esac
+
+AM_CONDITIONAL([MACOS], [test $macos -eq 1])
+AM_CONDITIONAL([LINUX], [test $linux -eq 1])
+AM_CONDITIONAL([FREEBSD], [test $freebsd -eq 1])
+
+base_c_warn_flags="-Wall -Wundef -Wpointer-arith"
+debug_c_warn_flags="-Wextra -Wno-unused-parameter -Wno-sign-compare -Wno-missing-field-initializers"
+debug_c_other_flags="-fstack-protector-strong"
+
+AC_ARG_ENABLE([debug],
+	[AS_HELP_STRING([--enable-debug],
+			[Enable debugging - default NO])],
+	[CFLAGS="-g -O0 ${base_c_warn_flags} ${debug_c_warn_flags} ${debug_c_other_flags} $CFLAGS"
+	 dbg=1],
+	[dbg=0])
+
+AC_DEFINE_UNQUOTED([ENABLE_DEBUG], [$dbg],
+	[defined to 1 if configured with --enable-debug])
+
+dnl Fix autoconf's habit of adding -g -O2 by default
+AS_IF([test -z "$CFLAGS"],
+      [CFLAGS="-O2 -DNDEBUG ${base_c_warn_flags}"])
+
+# AM PROG_AR did not exist pre AM 1.11.x (where x is somewhere >0 and
+# <3), but it is necessary in AM 1.12.x.
+m4_ifdef([AM_PROG_AR], [AM_PROG_AR])
+
+AM_PROG_LIBTOOL
+
+AC_ARG_WITH([valgrind],
+    AC_HELP_STRING([--with-valgrind],
+		   [Enable valgrind annotations - default NO]))
+
+if test "$with_valgrind" != "" && test "$with_valgrind" != "no"; then
+	AC_DEFINE([INCLUDE_VALGRIND], 1,
+		  [Define to 1 to enable valgrind annotations])
+	if test -d $with_valgrind; then
+		CPPFLAGS="$CPPLFAGS -I$with_valgrind/include"
+	fi
+fi
+
+dnl Checks for programs
+AC_PROG_CC
+AM_PROG_CC_C_O
+
+LT_INIT
+
+have_clock_gettime=0
+
+AC_SEARCH_LIBS([clock_gettime],[rt],
+	       [have_clock_gettime=1],
+	       [])
+
+AC_DEFINE_UNQUOTED(HAVE_CLOCK_GETTIME, [$have_clock_gettime],
+		   [Define to 1 if clock_gettime is available.])
+AM_CONDITIONAL(HAVE_CLOCK_GETTIME, [test $have_clock_gettime -eq 1])
+
+AC_ARG_WITH([libfabric],
+            AC_HELP_STRING([--with-libfabric], [Use non-default libfabric location - default NO]),
+            [AS_IF([test -d $withval/lib64], [fab_libdir="lib64"], [fab_libdir="lib"])
+             CPPFLAGS="-I $withval/include $CPPFLAGS"
+             LDFLAGS="-L$withval/$fab_libdir $LDFLAGS"],
+            [])
+
+dnl Checks for libraries
+AC_CHECK_LIB([fabric], fi_getinfo, [],
+    AC_MSG_ERROR([fi_getinfo() not found.  fabtests requires libfabric.]))
+
+dnl Checks for header files.
+AC_HEADER_STDC
+AC_CHECK_HEADER([rdma/fabric.h], [],
+    [AC_MSG_ERROR([<rdma/fabric.h> not found.  fabtests requires libfabric.])])
+
+AC_MSG_CHECKING([for fi_trywait support])
+AC_LINK_IFELSE([AC_LANG_PROGRAM([[#include <rdma/fi_eq.h>]],
+	       [[fi_trywait(NULL, NULL, 0);]])],
+	       [AC_MSG_RESULT([yes])],
+	       [AC_MSG_RESULT([no])
+	        AC_MSG_ERROR([fabtests requires fi_trywait support. Cannot continue])])
+
+if test "$with_valgrind" != "" && test "$with_valgrind" != "no"; then
+AC_CHECK_HEADER(valgrind/memcheck.h, [],
+    AC_MSG_ERROR([valgrind requested but <valgrind/memcheck.h> not found.]))
+fi
+
+AC_CHECK_FUNC([epoll_create1], [have_epoll=1], [have_epoll=0])
+AC_DEFINE_UNQUOTED([HAVE_EPOLL], [$have_epoll],
+		   [Defined to 1 if Linux epoll is available])
+
+AC_CONFIG_FILES([Makefile fabtests.spec])
+AC_OUTPUT
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.sln b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.sln
new file mode 100644
index 000000000..2e460cb02
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.sln
@@ -0,0 +1,28 @@
+﻿
+Microsoft Visual Studio Solution File, Format Version 12.00
+# Visual Studio 14
+VisualStudioVersion = 14.0.25420.1
+MinimumVisualStudioVersion = 10.0.40219.1
+Project("{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}") = "fabtests", "fabtests.vcxproj", "{076F757A-8827-4D3C-A87F-6E49623C16E1}"
+EndProject
+Global
+	GlobalSection(SolutionConfigurationPlatforms) = preSolution
+		Debug-v140|x64 = Debug-v140|x64
+		Debug-v141|x64 = Debug-v141|x64
+		Release-v140|x64 = Release-v140|x64
+		Release-v141|x64 = Release-v141|x64
+	EndGlobalSection
+	GlobalSection(ProjectConfigurationPlatforms) = postSolution
+		{076F757A-8827-4D3C-A87F-6E49623C16E1}.Debug-v140|x64.ActiveCfg = Debug-v140|x64
+		{076F757A-8827-4D3C-A87F-6E49623C16E1}.Debug-v140|x64.Build.0 = Debug-v140|x64
+		{076F757A-8827-4D3C-A87F-6E49623C16E1}.Debug-v141|x64.ActiveCfg = Debug-v141|x64
+		{076F757A-8827-4D3C-A87F-6E49623C16E1}.Debug-v141|x64.Build.0 = Debug-v141|x64
+		{076F757A-8827-4D3C-A87F-6E49623C16E1}.Release-v140|x64.ActiveCfg = Release-v140|x64
+		{076F757A-8827-4D3C-A87F-6E49623C16E1}.Release-v140|x64.Build.0 = Release-v140|x64
+		{076F757A-8827-4D3C-A87F-6E49623C16E1}.Release-v141|x64.ActiveCfg = Release-v141|x64
+		{076F757A-8827-4D3C-A87F-6E49623C16E1}.Release-v141|x64.Build.0 = Release-v141|x64
+	EndGlobalSection
+	GlobalSection(SolutionProperties) = preSolution
+		HideSolutionNode = FALSE
+	EndGlobalSection
+EndGlobal
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.spec.in b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.spec.in
new file mode 100644
index 000000000..d15c0fb2a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.spec.in
@@ -0,0 +1,41 @@
+Name: fabtests
+Version: @VERSION@
+Release: 1%{?dist}
+Summary: Test suite for libfabric API
+Group: System Environment/Libraries
+License: GPLv2 or BSD
+Url: http://www.github.com/ofiwg/fabtests
+Source: http://www.github.org/ofiwg/%{name}/releases/download/v{%version}/%{name}-%{version}.tar.bz2
+Requires: libfabric
+BuildRoot: %{_tmppath}/%{name}-%{version}-%{release}-root-%(%{__id_u} -n)
+
+%description
+Fabtests provides a set of examples that uses libfabric - a high-performance fabric software library.
+
+%prep
+%setup -q -n %{name}-%{version}
+
+%build
+%configure %{?_with_libfabric}
+make %{?_smp_mflags}
+
+%install
+rm -rf %{buildroot}
+%makeinstall installdirs
+# remove unpackaged files from the buildroot
+rm -f %{buildroot}%{_libdir}/*.la
+
+%clean
+rm -rf %{buildroot}
+
+%files
+%defattr(-,root,root,-)
+%{_bindir}/*
+%{_mandir}/man7/*
+%{_mandir}/man1/*
+%{_datadir}/%{name}/test_configs/*
+%doc AUTHORS COPYING README
+
+%changelog
+* Sun May 3 2015 Open Fabrics Interfaces Working Group <ofiwg@lists.openfabrics.org> 1.0.0
+- Release 1.0.0
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.vcxproj b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.vcxproj
new file mode 100644
index 000000000..96374f465
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.vcxproj
@@ -0,0 +1,175 @@
+﻿<?xml version="1.0" encoding="utf-8"?>
+<Project DefaultTargets="Build" ToolsVersion="14.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
+  <ItemGroup Label="ProjectConfigurations">
+    <ProjectConfiguration Include="Debug-v140|x64">
+      <Configuration>Debug-v140</Configuration>
+      <Platform>x64</Platform>
+    </ProjectConfiguration>
+    <ProjectConfiguration Include="Debug-v141|x64">
+      <Configuration>Debug-v141</Configuration>
+      <Platform>x64</Platform>
+    </ProjectConfiguration>
+    <ProjectConfiguration Include="Release-v140|x64">
+      <Configuration>Release-v140</Configuration>
+      <Platform>x64</Platform>
+    </ProjectConfiguration>
+    <ProjectConfiguration Include="Release-v141|x64">
+      <Configuration>Release-v141</Configuration>
+      <Platform>x64</Platform>
+    </ProjectConfiguration>
+  </ItemGroup>
+  <PropertyGroup Label="Globals">
+    <ProjectGuid>{076F757A-8827-4D3C-A87F-6E49623C16E1}</ProjectGuid>
+    <Keyword>MakeFileProj</Keyword>
+  </PropertyGroup>
+  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
+  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'" Label="Configuration">
+    <ConfigurationType>Makefile</ConfigurationType>
+    <UseDebugLibraries>true</UseDebugLibraries>
+    <PlatformToolset>v140</PlatformToolset>
+    <WholeProgramOptimization>true</WholeProgramOptimization>
+    <CharacterSet>MultiByte</CharacterSet>
+  </PropertyGroup>
+  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v141|x64'" Label="Configuration">
+    <ConfigurationType>Makefile</ConfigurationType>
+    <UseDebugLibraries>true</UseDebugLibraries>
+    <PlatformToolset>v141</PlatformToolset>
+    <WholeProgramOptimization>true</WholeProgramOptimization>
+    <CharacterSet>MultiByte</CharacterSet>
+  </PropertyGroup>
+  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release-v140|x64'" Label="Configuration">
+    <ConfigurationType>Makefile</ConfigurationType>
+    <UseDebugLibraries>false</UseDebugLibraries>
+    <PlatformToolset>v140</PlatformToolset>
+    <WholeProgramOptimization>true</WholeProgramOptimization>
+    <CharacterSet>MultiByte</CharacterSet>
+  </PropertyGroup>
+  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release-v141|x64'" Label="Configuration">
+    <ConfigurationType>Makefile</ConfigurationType>
+    <UseDebugLibraries>false</UseDebugLibraries>
+    <PlatformToolset>v141</PlatformToolset>
+    <WholeProgramOptimization>true</WholeProgramOptimization>
+    <CharacterSet>MultiByte</CharacterSet>
+  </PropertyGroup>
+  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
+  <ImportGroup Label="ExtensionSettings">
+  </ImportGroup>
+  <ImportGroup Label="Shared">
+  </ImportGroup>
+  <ImportGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'" Label="PropertySheets">
+    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
+  </ImportGroup>
+  <ImportGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v141|x64'" Label="PropertySheets">
+    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
+  </ImportGroup>
+  <ImportGroup Condition="'$(Configuration)|$(Platform)'=='Release-v140|x64'" Label="PropertySheets">
+    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
+  </ImportGroup>
+  <ImportGroup Condition="'$(Configuration)|$(Platform)'=='Release-v141|x64'" Label="PropertySheets">
+    <Import Project="$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props" Condition="exists('$(UserRootDir)\Microsoft.Cpp.$(Platform).user.props')" Label="LocalAppDataPlatform" />
+  </ImportGroup>
+  <PropertyGroup Label="UserMacros" />
+  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'">
+    <NMakePreprocessorDefinitions>WIN32;_DEBUG;$(NMakePreprocessorDefinitions)</NMakePreprocessorDefinitions>
+    <ExecutablePath>$(ProjectDir)Include;$(ExecutablePath)</ExecutablePath>
+    <NMakeBuildCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) all</NMakeBuildCommandLine>
+    <NMakeReBuildCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) clean all</NMakeReBuildCommandLine>
+    <NMakeCleanCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) clean</NMakeCleanCommandLine>
+  </PropertyGroup>
+  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v141|x64'">
+    <NMakePreprocessorDefinitions>WIN32;_DEBUG;$(NMakePreprocessorDefinitions)</NMakePreprocessorDefinitions>
+    <ExecutablePath>$(ProjectDir)Include;$(ExecutablePath)</ExecutablePath>
+    <NMakeBuildCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) all</NMakeBuildCommandLine>
+    <NMakeReBuildCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) clean all</NMakeReBuildCommandLine>
+    <NMakeCleanCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) clean</NMakeCleanCommandLine>
+  </PropertyGroup>
+  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release-v140|x64'">
+    <NMakePreprocessorDefinitions>WIN32;NDEBUG;$(NMakePreprocessorDefinitions)</NMakePreprocessorDefinitions>
+    <ExecutablePath>$(ProjectDir)Include;$(ExecutablePath)</ExecutablePath>
+    <NMakeBuildCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) all</NMakeBuildCommandLine>
+    <NMakeReBuildCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) clean all</NMakeReBuildCommandLine>
+    <NMakeCleanCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) clean</NMakeCleanCommandLine>
+  </PropertyGroup>
+  <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release-v141|x64'">
+    <NMakePreprocessorDefinitions>WIN32;NDEBUG;$(NMakePreprocessorDefinitions)</NMakePreprocessorDefinitions>
+    <ExecutablePath>$(ProjectDir)Include;$(ExecutablePath)</ExecutablePath>
+    <NMakeBuildCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) all</NMakeBuildCommandLine>
+    <NMakeReBuildCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) clean all</NMakeReBuildCommandLine>
+    <NMakeCleanCommandLine>nmake /F Makefile.win config=$(Configuration) arch=x$(PlatformArchitecture) clean</NMakeCleanCommandLine>
+  </PropertyGroup>
+  <ItemGroup>
+    <ClCompile Include="benchmarks\benchmark_shared.c" />
+    <ClCompile Include="benchmarks\dgram_pingpong.c" />
+    <ClCompile Include="benchmarks\msg_bw.c" />
+    <ClCompile Include="benchmarks\msg_pingpong.c" />
+    <ClCompile Include="benchmarks\rdm_cntr_pingpong.c" />
+    <ClCompile Include="benchmarks\rdm_pingpong.c" />
+    <ClCompile Include="benchmarks\rdm_tagged_bw.c" />
+    <ClCompile Include="benchmarks\rdm_tagged_pingpong.c" />
+    <ClCompile Include="benchmarks\rma_bw.c" />
+    <ClCompile Include="common\jsmn.c" />
+    <ClCompile Include="common\shared.c" />
+    <ClCompile Include="common\windows\getopt.c" />
+    <ClCompile Include="common\windows\osd.c" />
+    <ClCompile Include="ubertest\connect.c" />
+    <ClCompile Include="ubertest\cq.c" />
+    <ClCompile Include="ubertest\config.c" />
+    <ClCompile Include="ubertest\domain.c" />
+    <ClCompile Include="ubertest\ep.c" />
+    <ClCompile Include="ubertest\uber.c" />
+    <ClCompile Include="ubertest\xfer.c" />
+    <ClCompile Include="ubertest\test_ctrl.c" />
+    <ClCompile Include="functional\cq_data.c" />
+    <ClCompile Include="functional\dgram.c" />
+    <ClCompile Include="functional\dgram_waitset.c" />
+    <ClCompile Include="functional\msg.c" />
+    <ClCompile Include="functional\msg_epoll.c" />
+    <ClCompile Include="functional\msg_netdir.c" />
+    <ClCompile Include="functional\msg_sockets.c" />
+    <ClCompile Include="functional\poll.c" />
+    <ClCompile Include="functional\rdm.c" />
+    <ClCompile Include="functional\rdm_rma_simple.c" />
+    <ClCompile Include="functional\rdm_rma_trigger.c" />
+    <ClCompile Include="functional\rdm_shared_ctx.c" />
+    <ClCompile Include="functional\rdm_tagged_peek.c" />
+    <ClCompile Include="functional\rdm_netdir.c" />
+    <ClCompile Include="functional\scalable_ep.c" />
+    <ClCompile Include="functional\inj_complete.c" />
+    <ClCompile Include="unit\av_test.c" />
+    <ClCompile Include="unit\cntr_test.c" />
+    <ClCompile Include="unit\common.c" />
+    <ClCompile Include="unit\cq_test.c" />
+    <ClCompile Include="unit\dom_test.c" />
+    <ClCompile Include="unit\eq_test.c" />
+    <ClCompile Include="unit\getinfo_test.c" />
+    <ClCompile Include="unit\mr_test.c" />
+  </ItemGroup>
+  <ItemGroup>
+    <ClInclude Include="benchmarks\benchmark_shared.h" />
+    <ClInclude Include="ubertest\fabtest.h" />
+    <ClInclude Include="include\ft_osd.h" />
+    <ClInclude Include="include\jsmn.h" />
+    <ClInclude Include="include\shared.h" />
+    <ClInclude Include="include\unit_common.h" />
+    <ClInclude Include="include\windows\getopt\getopt.h" />
+    <ClInclude Include="include\windows\netdb.h" />
+    <ClInclude Include="include\windows\netinet\in.h" />
+    <ClInclude Include="include\windows\netinet\tcp.h" />
+    <ClInclude Include="include\windows\osd.h" />
+    <ClInclude Include="include\windows\poll.h" />
+    <ClInclude Include="include\windows\sys\socket.h" />
+    <ClInclude Include="include\windows\sys\uio.h" />
+    <ClInclude Include="include\windows\sys\wait.h" />
+    <ClInclude Include="include\windows\unistd.h" />
+  </ItemGroup>
+  <ItemGroup>
+    <None Include="test_configs\eq_cq.json" />
+    <None Include="test_configs\lat_bw.json" />
+    <None Include="test_configs\sockets.json" />
+    <None Include="test_configs\verbs.json" />
+    <None Include="Makefile.win" />
+  </ItemGroup>
+  <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
+  <ImportGroup Label="ExtensionTargets">
+  </ImportGroup>
+</Project>
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.vcxproj.filters b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.vcxproj.filters
new file mode 100644
index 000000000..2370a8e23
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/fabtests.vcxproj.filters
@@ -0,0 +1,249 @@
+﻿<?xml version="1.0" encoding="utf-8"?>
+<Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
+  <ItemGroup>
+    <Filter Include="Source Files">
+      <UniqueIdentifier>{4FC737F1-C7A5-4376-A066-2A32D752A2FF}</UniqueIdentifier>
+      <Extensions>cpp;c;cc;cxx;def;odl;idl;hpj;bat;asm;asmx</Extensions>
+    </Filter>
+    <Filter Include="Header Files">
+      <UniqueIdentifier>{93995380-89BD-4b04-88EB-625FBE52EBFB}</UniqueIdentifier>
+      <Extensions>h;hh;hpp;hxx;hm;inl;inc;xsd</Extensions>
+    </Filter>
+    <Filter Include="Resource Files">
+      <UniqueIdentifier>{67DA6AB6-F800-4c08-8B7A-83BB121AAD01}</UniqueIdentifier>
+      <Extensions>rc;ico;cur;bmp;dlg;rc2;rct;bin;rgs;gif;jpg;jpeg;jpe;resx;tiff;tif;png;wav;mfcribbon-ms</Extensions>
+    </Filter>
+    <Filter Include="Source Files\common">
+      <UniqueIdentifier>{506aaadf-53cc-4344-941b-011008029037}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Source Files\functional">
+      <UniqueIdentifier>{660dbead-4d8e-4589-8eb4-43dfab9566bd}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Source Files\ubertest">
+      <UniqueIdentifier>{401b54c2-4a43-40a2-b707-50b5f6ebb556}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Source Files\test_configs">
+      <UniqueIdentifier>{b3a8fe06-b4cf-48f9-b123-60cb55a123a7}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Source Files\unit">
+      <UniqueIdentifier>{02aa369d-fd9a-47f4-8fd3-583dcb953179}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Header Files\osd">
+      <UniqueIdentifier>{fba45a64-c3ed-4d15-827b-ab11ee5e9439}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Header Files\osd\netinet">
+      <UniqueIdentifier>{49185c64-a450-46e4-a685-870b48b52533}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Header Files\osd\sys">
+      <UniqueIdentifier>{6860bc78-04ef-4ab3-8e81-5c6a0ef80954}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Header Files\osd\getopt">
+      <UniqueIdentifier>{41b0d676-ab4e-4ba1-aeae-ee73272ae273}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Source Files\benchmarks">
+      <UniqueIdentifier>{f1716194-5311-4a40-a1f3-d4e96c93639f}</UniqueIdentifier>
+    </Filter>
+  </ItemGroup>
+  <ItemGroup>
+    <ClCompile Include="common\jsmn.c">
+      <Filter>Source Files\common</Filter>
+    </ClCompile>
+    <ClCompile Include="common\shared.c">
+      <Filter>Source Files\common</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\cq_data.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\dgram.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\dgram_waitset.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\msg.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\msg_epoll.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\msg_sockets.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\poll.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\rdm.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\rdm_rma_simple.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\rdm_rma_trigger.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\rdm_shared_ctx.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\rdm_tagged_peek.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\scalable_ep.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\inj_complete.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="ubertest\connect.c">
+      <Filter>Source Files\ubertest</Filter>
+    </ClCompile>
+    <ClCompile Include="ubertest\cq.c">
+      <Filter>Source Files\ubertest</Filter>
+    </ClCompile>
+    <ClCompile Include="ubertest\config.c">
+      <Filter>Source Files\ubertest</Filter>
+    </ClCompile>
+    <ClCompile Include="ubertest\domain.c">
+      <Filter>Source Files\ubertest</Filter>
+    </ClCompile>
+    <ClCompile Include="ubertest\ep.c">
+      <Filter>Source Files\ubertest</Filter>
+    </ClCompile>
+    <ClCompile Include="ubertest\uber.c">
+      <Filter>Source Files\ubertest</Filter>
+    </ClCompile>
+    <ClCompile Include="ubertest\xfer.c">
+      <Filter>Source Files\ubertest</Filter>
+    </ClCompile>
+    <ClCompile Include="ubertest\test_ctrl.c">
+      <Filter>Source Files\ubertest</Filter>
+    </ClCompile>
+    <ClCompile Include="unit\av_test.c">
+      <Filter>Source Files\unit</Filter>
+    </ClCompile>
+    <ClCompile Include="unit\common.c">
+      <Filter>Source Files\unit</Filter>
+    </ClCompile>
+    <ClCompile Include="unit\dom_test.c">
+      <Filter>Source Files\unit</Filter>
+    </ClCompile>
+    <ClCompile Include="unit\eq_test.c">
+      <Filter>Source Files\unit</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\msg_netdir.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="common\windows\getopt.c">
+      <Filter>Source Files\common</Filter>
+    </ClCompile>
+    <ClCompile Include="common\windows\osd.c">
+      <Filter>Source Files\common</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\benchmark_shared.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\dgram_pingpong.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\msg_bw.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\msg_pingpong.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\rdm_cntr_pingpong.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\rdm_pingpong.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\rdm_tagged_bw.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\rdm_tagged_pingpong.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="benchmarks\rma_bw.c">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClCompile>
+    <ClCompile Include="functional\rdm_netdir.c">
+      <Filter>Source Files\functional</Filter>
+    </ClCompile>
+    <ClCompile Include="unit\cq_test.c">
+      <Filter>Source Files\unit</Filter>
+    </ClCompile>
+    <ClCompile Include="unit\getinfo_test.c">
+      <Filter>Source Files\unit</Filter>
+    </ClCompile>
+    <ClCompile Include="unit\mr_test.c">
+      <Filter>Source Files\unit</Filter>
+    </ClCompile>
+    <ClCompile Include="unit\cntr_test.c">
+      <Filter>Source Files\unit</Filter>
+    </ClCompile>
+  </ItemGroup>
+  <ItemGroup>
+    <ClInclude Include="include\jsmn.h">
+      <Filter>Header Files</Filter>
+    </ClInclude>
+    <ClInclude Include="include\shared.h">
+      <Filter>Header Files</Filter>
+    </ClInclude>
+    <ClInclude Include="include\unit_common.h">
+      <Filter>Header Files</Filter>
+    </ClInclude>
+    <ClInclude Include="ubertest\fabtest.h">
+      <Filter>Source Files\ubertest</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\netdb.h">
+      <Filter>Header Files\osd</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\osd.h">
+      <Filter>Header Files\osd</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\poll.h">
+      <Filter>Header Files\osd</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\unistd.h">
+      <Filter>Header Files\osd</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\sys\socket.h">
+      <Filter>Header Files\osd\sys</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\sys\uio.h">
+      <Filter>Header Files\osd\sys</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\sys\wait.h">
+      <Filter>Header Files\osd\sys</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\netinet\tcp.h">
+      <Filter>Header Files\osd\netinet</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\netinet\in.h">
+      <Filter>Header Files\osd\netinet</Filter>
+    </ClInclude>
+    <ClInclude Include="include\windows\getopt\getopt.h">
+      <Filter>Header Files\osd\getopt</Filter>
+    </ClInclude>
+    <ClInclude Include="benchmarks\benchmark_shared.h">
+      <Filter>Source Files\benchmarks</Filter>
+    </ClInclude>
+    <ClInclude Include="include\ft_osd.h">
+      <Filter>Header Files</Filter>
+    </ClInclude>
+  </ItemGroup>
+  <ItemGroup>
+    <None Include="Makefile.win" />
+    <None Include="test_configs\eq_cq.json">
+      <Filter>Source Files\test_configs</Filter>
+    </None>
+    <None Include="test_configs\lat_bw.json">
+      <Filter>Source Files\test_configs</Filter>
+    </None>
+    <None Include="test_configs\sockets.json">
+      <Filter>Source Files\test_configs</Filter>
+    </None>
+    <None Include="test_configs\verbs.json">
+      <Filter>Source Files\test_configs</Filter>
+    </None>
+  </ItemGroup>
+</Project>
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/av_xfer.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/av_xfer.c
new file mode 100644
index 000000000..812bad317
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/av_xfer.c
@@ -0,0 +1,242 @@
+/*
+ * Copyright (c) 2018 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <unistd.h>
+
+#include <shared.h>
+
+
+static struct fi_info *base_hints;
+
+
+static int av_removal_test(void)
+{
+	int ret;
+
+	fprintf(stdout, "AV address removal: ");
+	hints = fi_dupinfo(base_hints);
+	if (!hints)
+		return -FI_ENOMEM;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	if (opts.dst_addr) {
+		ret = ft_tx(ep, remote_fi_addr, opts.transfer_size, &tx_ctx);
+		if (ret) {
+			FT_PRINTERR("ft_tx", -ret);
+			goto out;
+		}
+
+		ret = fi_av_remove(av, &remote_fi_addr, 1, 0);
+		if (ret) {
+			FT_PRINTERR("fi_av_remove", ret);
+			goto out;
+		}
+
+		ret = ft_sync();
+		if (ret)
+			goto out;
+
+		ret = ft_init_av();
+		if (ret) {
+			FT_PRINTERR("ft_init_av", -ret);
+			goto out;
+		}
+
+		ret = ft_rx(ep, opts.transfer_size);
+		if (ret) {
+			FT_PRINTERR("ft_rx", -ret);
+			goto out;
+		}
+	} else {
+		ret = ft_rx(ep, opts.transfer_size);
+		if (ret) {
+			FT_PRINTERR("ft_rx", -ret);
+			goto out;
+		}
+
+		ret = fi_av_remove(av, &remote_fi_addr, 1, 0);
+		if (ret) {
+			FT_PRINTERR("fi_av_remove", ret);
+			goto out;
+		}
+
+		ret = ft_sync();
+		if (ret)
+			goto out;
+
+		ret = ft_init_av();
+		if (ret) {
+			FT_PRINTERR("ft_init_av", -ret);
+			goto out;
+		}
+
+		ret = ft_tx(ep, remote_fi_addr, opts.transfer_size, &tx_ctx);
+		if (ret) {
+			FT_PRINTERR("ft_tx", -ret);
+			goto out;
+		}
+	}
+
+	fprintf(stdout, "PASS\n");
+	(void) ft_sync();
+out:
+	ft_free_res();
+	return ret;
+}
+
+static int av_reinsert_test(void)
+{
+	int ret;
+
+	fprintf(stdout, "AV re-insertion address: ");
+	hints = fi_dupinfo(base_hints);
+	if (!hints)
+		return -FI_ENOMEM;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	if (opts.dst_addr) {
+		ret = ft_tx(ep, remote_fi_addr, opts.transfer_size, &tx_ctx);
+		if (ret) {
+			FT_PRINTERR("ft_tx", -ret);
+			goto out;
+		}
+	} else {
+		ret = ft_rx(ep, opts.transfer_size);
+		if (ret) {
+			FT_PRINTERR("ft_rx", -ret);
+			goto out;
+		}
+	}
+
+	ret = fi_av_remove(av, &remote_fi_addr, 1, 0);
+	if (ret) {
+		FT_PRINTERR("fi_av_remove", ret);
+		goto out;
+	}
+
+	ret = ft_sync();
+	if (ret)
+		goto out;
+
+	ret = ft_init_av();
+	if (ret)
+		goto out;
+
+	if (opts.dst_addr) {
+		ret = ft_tx(ep, remote_fi_addr, opts.transfer_size, &tx_ctx);
+		if (ret) {
+			FT_PRINTERR("ft_tx", -ret);
+			goto out;
+		}
+	} else {
+		ret = ft_rx(ep, opts.transfer_size);
+		if (ret) {
+			FT_PRINTERR("ft_rx", -ret);
+			goto out;
+		}
+	}
+
+	fprintf(stdout, "PASS\n");
+	(void) ft_sync();
+out:
+	ft_free_res();
+	return ret;
+}
+
+/*
+ Test flow proposal for directed receive
+ client (dst_addr):
+	recvfrom
+ 	remove addr
+ 	insert addr
+ 	OOB sync
+	recvfrom
+ server (else):
+ 	tsend
+ 	OOB sync
+ 	tsend
+ */
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE | FT_OPT_OOB_SYNC;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	hints->ep_attr->type = FI_EP_RDM;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "AV communication unit test.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->caps = hints->ep_attr->type == FI_EP_RDM ?
+		      FI_TAGGED : FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	base_hints = hints;
+
+	ret = av_removal_test();
+	if (ret && ret != -FI_ENODATA)
+		goto out;
+
+	if (opts.dst_addr)
+		sleep(1);
+	ret = av_reinsert_test();
+	if (ret && ret != -FI_ENODATA)
+		goto out;
+
+out:
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/cm_data.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/cm_data.c
new file mode 100644
index 000000000..ed7a62bb6
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/cm_data.c
@@ -0,0 +1,484 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <string.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_cm.h>
+
+#include "shared.h"
+
+static char *cm_data;
+static size_t cm_data_size;
+static struct fi_eq_cm_entry *entry;
+static struct fi_eq_err_entry err_entry;
+
+char *sock_service = "2710";
+
+static int read_shutdown_event()
+{
+	int ret;
+	uint32_t event;
+
+	memset(entry, 0, sizeof(*entry));
+	ret = fi_eq_sread(eq, &event, entry, sizeof(*entry), -1, 0);
+	if (ret < 0) {
+		FT_PROCESS_EQ_ERR(ret, eq, "fi_eq_sread", "shutdown");
+		return ret;
+	}
+	if (event != FI_SHUTDOWN || entry->fid != &ep->fid) {
+		FT_ERR("Unexpected CM event %d fid %p (ep %p)", event,
+			entry->fid, ep);
+		ret = -FI_EOTHER;
+		return ret;
+	}
+	return 0;
+}
+
+static int server_setup(void)
+{
+	size_t opt_size;
+	int ret;
+
+	ret = ft_start_server();
+	if (ret)
+		return ret;
+
+	/* Get the maximum cm_size supported in all domains */
+	opt_size = sizeof(cm_data_size);
+	return fi_getopt(&pep->fid, FI_OPT_ENDPOINT, FI_OPT_CM_DATA_SIZE,
+		&cm_data_size, &opt_size);
+}
+
+static int client_setup(void)
+{
+	size_t opt_size;
+	int ret;
+
+	/* Get fabric info */
+	ret = fi_getinfo(FT_FIVERSION, opts.dst_addr, opts.dst_port, 0, hints,
+			&fi);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		return ret;
+	}
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	/* Get the maximum cm_size for this domain + endpoint combination */
+	opt_size = sizeof(opt_size);
+	return fi_getopt(&ep->fid, FI_OPT_ENDPOINT, FI_OPT_CM_DATA_SIZE,
+		&cm_data_size, &opt_size);
+}
+
+static int server_listen(size_t paramlen)
+{
+	size_t expected;
+	uint32_t event;
+	int ret;
+
+	expected = paramlen + sizeof(*entry);
+	memset(entry, 0, expected);
+
+	ret = fi_eq_sread(eq, &event, entry, expected, -1, 0);
+	if (ret != expected) {
+		FT_PROCESS_EQ_ERR(ret, eq, "fi_eq_sread", "listen");
+		return ret;
+	}
+
+	if (event != FI_CONNREQ) {
+		FT_ERR("Unexpected CM event %d", event);
+		return -FI_EOTHER;
+	}
+
+	ret = ft_check_buf(entry->data, paramlen);
+	if (ret)
+		return ret;
+
+	fi = entry->info;
+
+	return 0;
+}
+
+static int server_reject(size_t paramlen)
+{
+	int ret;
+
+	ret = server_listen(paramlen);
+	if (ret)
+		return ret;
+
+	/* Data will appear in error event generated on remote end. */
+	ft_fill_buf(cm_data, paramlen);
+	ret = fi_reject(pep, fi->handle, cm_data, paramlen);
+	if (ret)
+		FT_PRINTERR("fi_reject", ret);
+
+	return ret;
+}
+
+static int server_accept(size_t paramlen)
+{
+	uint32_t event;
+	int ret;
+
+	ret = server_listen(paramlen);
+	if (ret)
+		return ret;
+
+	ret = fi_domain(fabric, fi, &domain, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_domain", ret);
+		goto err;
+	}
+
+	ret = ft_alloc_active_res(fi);
+	if (ret) {
+		FT_PRINTERR("alloc_active_res", ret);
+		goto err;
+	}
+
+	ret = ft_enable_ep_recv();
+	if (ret) {
+		FT_PRINTERR("init_ep", ret);
+		goto err;
+	}
+	/* Data will apppear on accept event on remote end. */
+	ft_fill_buf(cm_data, paramlen);
+
+	/* Accept the incoming connection. Also transitions endpoint to active
+	 * state.
+	 */
+	ret = fi_accept(ep, cm_data, paramlen);
+	if (ret) {
+		FT_PRINTERR("fi_accept", ret);
+		goto err;
+	}
+
+	/* Local FI_CONNECTED event does not have data associated. */
+	memset(entry, 0, sizeof(*entry));
+	ret = fi_eq_sread(eq, &event, entry, sizeof(*entry), -1, 0);
+	if (ret != sizeof(*entry)) {
+		FT_PROCESS_EQ_ERR(ret, eq, "fi_eq_sread", "accept");
+		goto err;
+	}
+
+	if (event != FI_CONNECTED || entry->fid != &ep->fid) {
+		FT_ERR("Unexpected CM event %d fid %p (ep %p)", event,
+				entry->fid, ep);
+		ret = -FI_EOTHER;
+		goto err;
+	}
+
+	fi_shutdown(ep, 0);
+	ret = read_shutdown_event();
+	if (ret)
+		goto err;
+
+	FT_CLOSE_FID(ep);
+	FT_CLOSE_FID(rxcq);
+	FT_CLOSE_FID(txcq);
+	FT_CLOSE_FID(rxcntr);
+	FT_CLOSE_FID(txcntr);
+	FT_CLOSE_FID(av);
+	FT_CLOSE_FID(domain);
+
+	return 0;
+
+err:
+	fi_reject(pep, fi->handle, NULL, 0);
+	return ret;
+}
+
+static int server(size_t paramlen)
+{
+	int ret;
+
+	ret = server_reject(paramlen);
+	if (ret)
+		return ret;
+
+	return server_accept(paramlen);
+}
+
+static int client_connect(size_t paramlen)
+{
+	ft_fill_buf(cm_data, paramlen);
+
+	/* Connect to server */
+	return fi_connect(ep, fi->dest_addr, cm_data, paramlen);
+}
+
+static int client_open_new_ep()
+{
+	size_t opt_size;
+	int ret;
+
+	FT_CLOSE_FID(ep);
+
+	ret = fi_endpoint(domain, fi, &ep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		return ret;
+	}
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	/* Get the maximum cm_size for this domain + endpoint combination */
+	opt_size = sizeof(opt_size);
+	return fi_getopt(&ep->fid, FI_OPT_ENDPOINT, FI_OPT_CM_DATA_SIZE,
+		&cm_data_size, &opt_size);
+}
+
+static int client_expect_reject(size_t paramlen)
+{
+	uint32_t event;
+	int ret;
+
+	ret = client_connect(paramlen);
+	if (ret) {
+		FT_PRINTERR("fi_connect", ret);
+		return ret;
+	}
+
+	ret = fi_eq_sread(eq, &event, entry, sizeof(*entry), -1, 0);
+	if (ret != -FI_EAVAIL) {
+		FT_PROCESS_EQ_ERR(ret, eq, "fi_eq_sread", "connect");
+		return ret;
+	}
+
+	memset(&err_entry, 0, sizeof(err_entry));
+	ret = fi_eq_readerr(eq, &err_entry, 0);
+	if (ret != sizeof(err_entry)) {
+		FT_EQ_ERR(eq, err_entry, NULL, 0);
+		return err_entry.err;
+	}
+
+	if (err_entry.err != FI_ECONNREFUSED)
+		return err_entry.err;
+
+	/* Check data on FI_ECONNREFUSED error event. */
+	return ft_check_buf(err_entry.err_data, err_entry.err_data_size);
+}
+
+static int client_expect_accept(size_t paramlen)
+{
+	size_t expected;
+	uint32_t event;
+	int ret;
+
+	expected = paramlen + sizeof(*entry);
+
+	ret = client_connect(paramlen);
+	if (ret) {
+		FT_PRINTERR("fi_connect", ret);
+		return ret;
+	}
+
+	ret = fi_eq_sread(eq, &event, entry, expected, -1, 0);
+	if (ret != expected) {
+		FT_PROCESS_EQ_ERR(ret, eq, "fi_eq_sread", "connect");
+		return ret;
+	}
+
+	if (event != FI_CONNECTED || entry->fid != &ep->fid) {
+		FT_ERR("Unexpected CM event %d fid %p (ep %p)", event,
+				entry->fid, ep);
+		return -FI_EOTHER;
+	}
+
+	/* Check data on FI_CONNECTED event. */
+	ret = ft_check_buf(entry->data, paramlen);
+	if (ret)
+		return ret;
+
+	fi_shutdown(ep, 0);
+	return read_shutdown_event();
+}
+
+/*
+ * After each reject and accept of a connection request we close the endpoint and
+ * open a new one since fi_connect can be called only once in a connected
+ * endpoint's lifetime.
+ */
+static int client(size_t paramlen)
+{
+	int ret;
+
+	ret = client_expect_reject(paramlen);
+	if (ret)
+		return ret;
+
+	ret = client_open_new_ep();
+	if (ret)
+		return ret;
+
+	ret = client_expect_accept(paramlen);
+	if (ret)
+		return ret;
+
+	return client_open_new_ep();
+}
+
+static int run(void)
+{
+	char *node, *service;
+	uint64_t flags;
+	int ret;
+	size_t i;
+
+	ret = ft_read_addr_opts(&node, &service, hints, &flags, &opts);
+	if (ret)
+		return ret;
+
+	ret = opts.dst_addr ? client_setup() : server_setup();
+	if (ret) {
+		fprintf(stderr, "error: %s\n", fi_strerror(-ret));
+		return ret;
+	}
+
+	/* Leave extra space for invalid size test */
+	cm_data = calloc(1, cm_data_size + 1);
+	if (!cm_data)
+		return -FI_ENOMEM;
+
+	entry = calloc(1, sizeof(*entry) + cm_data_size);
+	if (!entry)
+		return -FI_ENOMEM;
+
+	if (opts.dst_addr) {
+		ret = ft_sock_connect(opts.dst_addr, sock_service);
+		if (ret)
+			goto err2;
+	} else {
+		ret = ft_sock_listen(opts.src_addr, sock_service);
+		if (ret)
+			goto err2;
+		ret = ft_sock_accept();
+		if (ret)
+			goto err1;
+	}
+
+	for (i = 1; i <= cm_data_size; i <<= 1) {
+		printf("trying with data size: %zu\n", i);
+
+		if (opts.dst_addr)
+			ret = client(i);
+		else
+			ret = server(i);
+
+		if (ret)
+			goto err1;
+
+		ret = ft_sock_sync(0);
+		if (ret)
+			goto err1;
+	}
+
+	/* Despite server not being setup to handle this, the client should fail
+	 * with -FI_EINVAL since this exceeds its max data size.
+	 */
+	if (opts.dst_addr) {
+		printf("trying with data size exceeding maximum: %zu\n",
+				cm_data_size + 1);
+		/* Don't call client since it produces an error message. */
+		ret = client_connect(cm_data_size + 1);
+		if (ret != -FI_EINVAL) {
+			FT_ERR("expected -FI_EINVAL, got: [%d]:%s\n", ret,
+				fi_strerror(-ret));
+		} else {
+			ret = FI_SUCCESS;
+		}
+	}
+
+err1:
+	ft_sock_shutdown(sock);
+err2:
+	free(entry);
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE | FT_OPT_SKIP_REG_MR;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "q:h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		case 'q':
+			sock_service = optarg;
+			break;
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0],
+					"A MSG client-sever example that uses CM data.");
+			FT_PRINT_OPTS_USAGE("-q <service_port>", "management port");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type	= FI_EP_MSG;
+	hints->caps		= FI_MSG;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/cq_data.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/cq_data.c
new file mode 100644
index 000000000..7930a176e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/cq_data.c
@@ -0,0 +1,144 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_cm.h>
+
+#include <shared.h>
+
+static int run_test()
+{
+	int ret;
+	size_t size = 1000;
+	struct fi_cq_data_entry comp;
+
+	if (opts.dst_addr) {
+		fprintf(stdout,
+			"Posting send with CQ data: 0x%" PRIx64 "\n",
+			remote_cq_data);
+		ret = ft_post_tx(ep, remote_fi_addr, size, remote_cq_data, &tx_ctx);
+		if (ret)
+			return ret;
+
+		ret = ft_get_tx_comp(tx_seq);
+		fprintf(stdout, "Done\n");
+	} else {
+		fprintf(stdout, "Waiting for CQ data from client\n");
+		ret = fi_cq_sread(rxcq, &comp, 1, NULL, -1);
+		if (ret < 0) {
+			if (ret == -FI_EAVAIL) {
+				ret = ft_cq_readerr(rxcq);
+			} else {
+				FT_PRINTERR("fi_cq_sread", ret);
+			}
+			return ret;
+		}
+
+		if (comp.flags & FI_REMOTE_CQ_DATA) {
+			if (comp.data == remote_cq_data) {
+				fprintf(stdout, "remote_cq_data: success\n");
+				ret = 0;
+			} else {
+				fprintf(stdout, "error, Expected data:0x%" PRIx64
+					", Received data:0x%" PRIx64 "\n",
+					remote_cq_data, comp.data);
+				ret = -FI_EIO;
+			}
+		} else {
+			fprintf(stdout, "error, CQ data flag not set\n");
+			ret = -FI_EBADFLAGS;
+		}
+	}
+
+	return ret;
+}
+
+static int run(void)
+{
+	int ret;
+
+	if (hints->ep_attr->type == FI_EP_MSG)
+		ret = ft_init_fabric_cm();
+	else
+		ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	ret = run_test();
+
+	fi_shutdown(ep, 0);
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+	opts.comp_method = FT_COMP_SREAD;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A client-server example that transfers CQ data.\n");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->domain_attr->cq_data_size = 4;  /* required minimum */
+	hints->mode |= FI_CONTEXT | FI_RX_CQ_DATA;
+
+	hints->caps = FI_MSG;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	cq_attr.format = FI_CQ_FORMAT_DATA;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/dgram.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/dgram.c
new file mode 100644
index 000000000..68f892506
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/dgram.c
@@ -0,0 +1,84 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <shared.h>
+
+static int run(void)
+{
+	int ret;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	return ft_send_recv_greeting(ep);
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A simple DRAM client-sever example.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type		= FI_EP_DGRAM;
+	hints->caps			= FI_MSG;
+	hints->mode			= FI_CONTEXT;
+	hints->domain_attr->mr_mode 	= FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/dgram_waitset.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/dgram_waitset.c
new file mode 100644
index 000000000..e8f9dbd4a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/dgram_waitset.c
@@ -0,0 +1,191 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2015-2016 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+
+#include <shared.h>
+
+static int alloc_ep_res(struct fi_info *fi)
+{
+	struct fi_wait_attr wait_attr;
+	int ret;
+
+	memset(&wait_attr, 0, sizeof wait_attr);
+	wait_attr.wait_obj = FI_WAIT_UNSPEC;
+	ret = fi_wait_open(fabric, &wait_attr, &waitset);
+	if (ret) {
+		FT_PRINTERR("fi_wait_open", ret);
+		return ret;
+	}
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int init_fabric(void)
+{
+	int ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int send_recv()
+{
+	struct fi_cq_entry comp;
+	int ret;
+
+	ret = fi_recv(ep, rx_buf, rx_size + ft_rx_prefix_size(),
+		      mr_desc, 0, &rx_ctx);
+	if (ret)
+		return ret;
+
+	ft_sync();
+
+	fprintf(stdout, "Posting a send...\n");
+	ret = ft_post_tx(ep, remote_fi_addr, tx_size, NO_CQ_DATA, &tx_ctx);
+	if (ret)
+		return ret;
+
+	while ((tx_cq_cntr < tx_seq) || (rx_cq_cntr < rx_seq)) {
+		/* Wait for completion events on CQs */
+		ret = fi_wait(waitset, -1);
+		if (ret < 0) {
+			FT_PRINTERR("fi_wait", ret);
+			return ret;
+		}
+
+		/* Read the send completion entry */
+		ret = fi_cq_read(txcq, &comp, 1);
+		if (ret > 0) {
+			tx_cq_cntr++;
+			fprintf(stdout, "Received send completion event!\n");
+		} else if (ret < 0 && ret != -FI_EAGAIN) {
+			if (ret == -FI_EAVAIL) {
+				ret = ft_cq_readerr(txcq);
+			} else {
+				FT_PRINTERR("fi_cq_read", ret);
+			}
+			return ret;
+		}
+
+		/* Read the recv completion entry */
+		ret = fi_cq_read(rxcq, &comp, 1);
+		if (ret > 0) {
+			rx_cq_cntr++;
+			fprintf(stdout, "Received recv completion event!\n");
+		} else if (ret < 0 && ret != -FI_EAGAIN) {
+			if (ret == -FI_EAVAIL) {
+				ret = ft_cq_readerr(rxcq);
+			} else {
+				FT_PRINTERR("fi_cq_read", ret);
+			}
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int run(void)
+{
+	int ret;
+
+	ret = init_fabric();
+	if (ret)
+		return ret;
+
+	ret = ft_init_av();
+	if (ret)
+		return ret;
+
+	return send_recv();
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret = 0;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+	opts.comp_method = FT_COMP_WAITSET;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A DGRAM client-server example that uses waitset.\n");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_DGRAM;
+	hints->caps = FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/inj_complete.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/inj_complete.c
new file mode 100644
index 000000000..b7ac46948
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/inj_complete.c
@@ -0,0 +1,210 @@
+/*
+ * Copyright (c) 2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <unistd.h>
+#include <string.h>
+#include <getopt.h>
+#include <rdma/fi_tagged.h>
+#include "shared.h"
+
+int use_sendmsg, use_recvmsg, send_inj_count;
+
+static int send_msg(int sendmsg, size_t size)
+{
+	int ret;
+	ft_tag = 0xabcd;
+
+	if (ft_check_opts(FT_OPT_VERIFY_DATA))
+		ft_fill_buf(tx_buf, size);
+
+	if (sendmsg) {
+		ret = ft_sendmsg(ep, remote_fi_addr, size,
+				&tx_ctx, FI_INJECT_COMPLETE);
+		if (ret) {
+			FT_PRINTERR("ft_sendmsg", ret);
+			return ret;
+		}
+	} else {
+		ret = ft_post_tx(ep, remote_fi_addr, size, NO_CQ_DATA, &tx_ctx);
+		if (ret) {
+			FT_PRINTERR("ft_post_rx", ret);
+			return ret;
+		}
+	}
+	ret = ft_cq_read_verify(txcq, &tx_ctx);
+	if (ret) {
+		FT_PRINTERR("ft_cq_read_verify", ret);
+		return ret;
+	}
+	tx_cq_cntr++;
+	/*
+	Alter the tx buffer contents, if the inject event
+	was properly generated, then the changes to the TX buffer
+	will not be sent to the target.
+	*/
+	memset(tx_buf, 0xb, size);
+
+	return 0;
+}
+
+static int receive_msg(int recvmsg, size_t size)
+{
+	int ret;
+	struct fi_context inj_ctx;
+	ft_tag = 0xabcd;
+
+	if (recvmsg) {
+		ret = ft_recvmsg(ep, FI_ADDR_UNSPEC, size,
+				&inj_ctx, 0);
+		if (ret) {
+			FT_PRINTERR("ft_recvmsg", ret);
+			return ret;
+		}
+	} else {
+		ret = ft_post_rx(ep, size, &inj_ctx);
+		if (ret) {
+			FT_PRINTERR("ft_post_rx", ret);
+			return ret;
+		}
+	}
+
+	ret = ft_cq_read_verify(rxcq, &inj_ctx);
+	if (ret) {
+		FT_PRINTERR("ft_cq_read_verify", ret);
+		return ret;
+	}
+	rx_cq_cntr++;
+
+	if (ft_check_opts(FT_OPT_VERIFY_DATA)) {
+		ret = ft_check_buf(rx_buf, size);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+static int run_test(void)
+{
+	int ret = 0, i;
+
+	if (!use_sendmsg)
+		hints->tx_attr->op_flags |= FI_INJECT_COMPLETE;
+
+	if (hints->ep_attr->type == FI_EP_MSG) {
+		ret = ft_init_fabric_cm();
+		if (ret)
+			return ret;
+	} else {
+		ret = ft_init_fabric();
+		if (ret)
+			return ret;
+	}
+
+	fprintf(stdout, "Start testing FI_INJECT_COMPLETIONS\n");
+	for (i = 0; i < send_inj_count; i++) {
+		if (opts.dst_addr) {
+			ret = send_msg(use_sendmsg, opts.transfer_size);
+			if (ret)
+				return ret;
+		} else {
+			ret = receive_msg(use_recvmsg, opts.transfer_size);
+			if (ret)
+				return ret;
+		}
+	}
+	fprintf(stdout, "GOOD: Completed FI_INJECT_COMPLETIONS Testing\n");
+
+	return 0;
+}
+
+int main(int argc, char **argv)
+{
+	int op;
+	int ret = 0;
+
+	opts = INIT_OPTS;
+	use_sendmsg = 0;
+	use_recvmsg = 0;
+	send_inj_count = 1;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "m:OSRvh" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'O':
+			send_inj_count = 100;
+			break;
+		case 'm':
+			opts.transfer_size = strtoul(optarg, NULL, 0);
+			break;
+		case 'S':
+			use_sendmsg = 1;
+			break;
+		case 'R':
+			use_recvmsg = 1;
+			break;
+		case 'v':
+			opts.options |= FT_OPT_VERIFY_DATA;
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "FI_Inject_Completion Functional Test");
+			FT_PRINT_OPTS_USAGE("-m <size>", "size of Injection message");
+			FT_PRINT_OPTS_USAGE("-S", "enable testing with fi_sendmsg");
+			FT_PRINT_OPTS_USAGE("-R", "enable testing with fi_recvmsg");
+			FT_PRINT_OPTS_USAGE("-O", "enable testing injection overrun");
+			FT_PRINT_OPTS_USAGE("-v", "Enable DataCheck testing");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->mode = FI_CONTEXT;
+	hints->caps = FI_TAGGED;
+	hints->domain_attr->resource_mgmt = FI_RM_ENABLED;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run_test();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/mcast.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/mcast.c
new file mode 100644
index 000000000..650bbd25e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/mcast.c
@@ -0,0 +1,115 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <rdma/fi_cm.h>
+
+#include <shared.h>
+
+
+static int listener;
+
+
+static int run(void)
+{
+	int ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	if (!listener)
+		fi->tx_attr->op_flags = FI_MULTICAST;
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	ret = ft_join_mc();
+	if (ret)
+		return ret;
+
+	remote_fi_addr = fi_mc_addr(mc);
+	return listener ? ft_recv_greeting(ep) : ft_send_greeting(ep);
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "Mh" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'M':
+			listener = 1;
+			break;
+		case '?':
+		case 'h':
+			goto usage;
+		}
+	}
+
+	if (optind == argc)
+		goto usage;
+
+	opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type		= FI_EP_DGRAM;
+	hints->caps			= FI_MSG | FI_MULTICAST;
+	hints->mode			= FI_CONTEXT;
+	hints->domain_attr->mr_mode 	= FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+usage:
+	ft_mcusage(argv[0], "A simple multicast example.");
+	return EXIT_FAILURE;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg.c
new file mode 100644
index 000000000..33e8b1307
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg.c
@@ -0,0 +1,95 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_cm.h>
+
+#include "shared.h"
+
+static int run(void)
+{
+	int ret;
+
+	if (!opts.dst_addr) {
+		ret = ft_start_server();
+		if (ret)
+			return ret;
+	}
+
+	ret = opts.dst_addr ? ft_client_connect() : ft_server_connect();
+	if (ret) {
+		return ret;
+	}
+
+	ret = ft_send_recv_greeting(ep);
+
+	fi_shutdown(ep, 0);
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A simple MSG client-sever example.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type		= FI_EP_MSG;
+	hints->caps			= FI_MSG;
+	hints->domain_attr->mr_mode 	= FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg_epoll.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg_epoll.c
new file mode 100644
index 000000000..3ce6b0be2
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg_epoll.c
@@ -0,0 +1,239 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#if HAVE_CONFIG_H
+#  include <config.h>
+#endif /* HAVE_CONFIG_H */
+
+#include <shared.h>
+
+#if HAVE_EPOLL == 1
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include <unistd.h>
+#include <sys/epoll.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_cm.h>
+
+static int epfd;
+
+static int alloc_epoll_res(void)
+{
+	struct epoll_event event;
+	int ret, fd;
+
+	epfd = epoll_create1(0);
+	if (epfd < 0) {
+		ret = -errno;
+		FT_PRINTERR("epoll_create1", ret);
+		return ret;
+	}
+
+	memset((void *) &event, 0, sizeof event);
+	if (opts.dst_addr) {
+		fd = tx_fd;
+		event.data.ptr = (void *) &txcq->fid;
+	} else {
+		fd = rx_fd;
+		event.data.ptr = (void *) &rxcq->fid;
+	}
+
+	event.events = EPOLLIN;
+	ret = epoll_ctl(epfd, EPOLL_CTL_ADD, fd, &event);
+	if (ret) {
+		ret = -errno;
+		FT_PRINTERR("epoll_ctl", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int send_recv()
+{
+	struct fi_cq_entry comp;
+	struct epoll_event event;
+	struct fid *fids[1];
+	int ret;
+	const char *message = "Hello from Client!";
+	size_t message_len = strlen(message) + 1;
+
+	if (opts.dst_addr) {
+		fprintf(stdout, "Posting a send...\n");
+		if (snprintf(tx_buf, tx_size, "%s", message) >= tx_size) {
+			fprintf(stderr, "Transmit buffer too small.\n");
+			return -FI_ETOOSMALL;
+		}
+		ret = ft_post_tx(ep, remote_fi_addr, message_len, NO_CQ_DATA, &tx_ctx);
+		if (ret)
+			return ret;
+
+		memset(&event, 0, sizeof event);
+		fids[0] = &txcq->fid;
+		do {
+			if (fi_trywait(fabric, fids, 1) == FI_SUCCESS) {
+				ret = TEMP_FAILURE_RETRY(epoll_wait(epfd, &event, 1, -1));
+				if (ret < 0) {
+					ret = -errno;
+					FT_PRINTERR("epoll_wait", ret);
+					return ret;
+				}
+
+				if (event.data.ptr != &txcq->fid)
+					fprintf(stdout, "unexpected event!\n");
+			}
+
+			ret = fi_cq_read(txcq, &comp, 1);
+		} while (ret == -FI_EAGAIN);
+
+		if (ret < 0) {
+			if (ret == -FI_EAVAIL)
+				ret = ft_cq_readerr(txcq);
+			return ret;
+		}
+
+		fprintf(stdout, "Send completion received\n");
+	} else {
+		fprintf(stdout, "Waiting for client...\n");
+
+		memset(&event, 0, sizeof event);
+		fids[0] = &rxcq->fid;
+		do {
+			if (fi_trywait(fabric, fids, 1) == FI_SUCCESS) {
+				ret = TEMP_FAILURE_RETRY(epoll_wait(epfd, &event, 1, -1));
+				if (ret < 0) {
+					ret = -errno;
+					FT_PRINTERR("epoll_wait", ret);
+					return ret;
+				}
+
+				if (event.data.ptr != &rxcq->fid) {
+					fprintf(stdout, "unexpected event!\n");
+				}
+			}
+
+			ret = fi_cq_read(rxcq, &comp, 1);
+		} while (ret == -FI_EAGAIN);
+
+		if (ret < 0) {
+			if (ret == -FI_EAVAIL)
+				ret = ft_cq_readerr(rxcq);
+			return ret;
+		}
+
+		ret = check_recv_msg(message);
+		if (ret)
+			return ret;
+
+		fprintf(stdout, "Received data from client: %s\n", (char *) rx_buf);
+	}
+
+	return 0;
+}
+
+static int run(void)
+{
+	int ret;
+
+	if (!opts.dst_addr) {
+		ret = ft_start_server();
+		if (ret)
+			return ret;
+	}
+
+	ret = opts.dst_addr ? ft_client_connect() : ft_server_connect();
+	if (ret) {
+		return ret;
+	}
+
+	ret = alloc_epoll_res();
+	if (ret)
+		return ret;
+
+	ret = send_recv();
+
+	fi_shutdown(ep, 0);
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+	opts.comp_method = FT_COMP_WAIT_FD;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A simple MSG client-sever example that "
+				"demonstrates one possible usage of the underlying "
+				"cq wait objects.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type		= FI_EP_MSG;
+	hints->caps			= FI_MSG;
+	hints->domain_attr->mr_mode 	= FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	close(epfd);
+	return ft_exit_code(ret);
+}
+
+#else
+
+#include <rdma/fi_errno.h>
+
+int main(int argc, char **argv)
+{
+	return ft_exit_code(FI_ENODATA);
+}
+#endif
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg_sockets.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg_sockets.c
new file mode 100644
index 000000000..ede5e6c06
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/msg_sockets.c
@@ -0,0 +1,493 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <assert.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include <netdb.h>
+#include <netinet/in.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_cm.h>
+
+#include "shared.h"
+
+union sockaddr_any {
+	struct sockaddr		sa;
+	struct sockaddr_in	sin;
+	struct sockaddr_in6	sin6;
+	struct sockaddr_storage	ss;
+};
+
+static union sockaddr_any bound_addr;
+static size_t bound_addr_len = sizeof bound_addr;
+
+
+/* Wrapper for memcmp for sockaddr.  Note that the sockaddr structure may
+ * contain holes, so sockaddr's are expected to have been initialized to all
+ * zeroes prior to being filled with an address. */
+static int
+sockaddrcmp(const union sockaddr_any *actual, socklen_t actual_len,
+	    const union sockaddr_any *expected, socklen_t expected_len)
+{
+	if (actual->sa.sa_family != expected->sa.sa_family) {
+		return actual->sa.sa_family - expected->sa.sa_family;
+	} else if (actual_len != expected_len) {
+		return actual_len - expected_len;
+	}
+
+	/* Handle binds to wildcard addresses, for address types we know
+	 * about */
+	switch (expected->sa.sa_family) {
+	case AF_INET:
+		if (expected->sin.sin_addr.s_addr == INADDR_ANY) {
+			return 0;
+		}
+		break;
+	case AF_INET6:
+		if (!memcmp(&expected->sin6.sin6_addr,
+			    &in6addr_any, sizeof(struct in6_addr))) {
+			return 0;
+		}
+		break;
+	}
+	return memcmp(actual, expected, actual_len);
+}
+
+/* Returns a string for the given sockaddr using getnameinfo().  This returns a
+ * static buffer so it is not reentrant or thread-safe.  Returns the string on
+ * success and NULL on failure. */
+static const char *
+sockaddrstr(const union sockaddr_any *addr, socklen_t len, char *buf, size_t buflen)
+{
+	static char namebuf[BUFSIZ];
+	static char servbuf[BUFSIZ];
+	int errcode;
+
+	if ((errcode = getnameinfo(&addr->sa, len, namebuf, BUFSIZ,
+				servbuf, BUFSIZ,
+				NI_NUMERICHOST | NI_NUMERICSERV))) {
+		if (errcode != EAI_SYSTEM) {
+			fprintf(stderr, "getnameinfo: %s\n", gai_strerror(errcode));
+		} else {
+			fprintf(stderr, "getnameinfo: %s\n", strerror(errno));
+		}
+		return NULL;
+	}
+
+	snprintf(buf, buflen, "[%s]:%s", namebuf, servbuf);
+	return buf;
+}
+
+static int check_address(struct fid *fid, const char *message)
+{
+	char buf1[BUFSIZ], buf2[BUFSIZ];
+	union sockaddr_any tmp;
+	size_t tmplen;
+	const char *ep_addr, *addr_expected;
+	int ret;
+
+	memset(&tmp, 0, sizeof tmp);
+	tmplen = sizeof tmp;
+	ret = fi_getname(fid, &tmp, &tmplen);
+	if (ret) {
+		FT_PRINTERR("fi_getname", ret);
+	}
+
+	if (sockaddrcmp(&tmp, tmplen, &bound_addr, bound_addr_len)) {
+		ep_addr = sockaddrstr(&tmp, tmplen, buf1, BUFSIZ);
+		if (!ep_addr) {
+			FT_ERR("Unable to get ep_addr as string!");
+			return -FI_EINVAL;
+		}
+
+		addr_expected = sockaddrstr(&bound_addr, bound_addr_len, buf2, BUFSIZ);
+		if (!addr_expected) {
+			FT_ERR("Unable to get addr_expected as string!");
+			return -FI_EINVAL;
+		}
+
+		FT_ERR("address changed after %s: got %s expected %s",
+			message, ep_addr, addr_expected);
+		return -FI_EINVAL;
+	}
+
+	return 0;
+}
+
+static int server_listen(void)
+{
+	int ret;
+
+	ret = fi_pep_bind(pep, &eq->fid, 0);
+	if (ret) {
+		FT_PRINTERR("fi_pep_bind", ret);
+		return ret;
+	}
+
+	ret = fi_listen(pep);
+	if (ret) {
+		FT_PRINTERR("fi_listen", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int server_connect(void)
+{
+	struct fi_eq_cm_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int ret;
+
+	/* Wait for connection request from client */
+	rd = fi_eq_sread(eq, &event, &entry, sizeof entry, -1, 0);
+	if (rd != sizeof entry) {
+		FT_PRINTERR("fi_eq_sread", rd);
+		return (int) rd;
+	}
+
+	fi = entry.info;
+	if (event != FI_CONNREQ) {
+		FT_ERR("Unexpected CM event %d", event);
+		ret = -FI_EOTHER;
+		goto err;
+	}
+
+	ret = fi_domain(fabric, fi, &domain, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_domain", ret);
+		goto err;
+	}
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		 goto err;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		goto err;
+
+	/* Accept the incoming connection. Also transitions endpoint to active state */
+	ret = fi_accept(ep, NULL, 0);
+	if (ret) {
+		FT_PRINTERR("fi_accept", ret);
+		goto err;
+	}
+
+	/* Wait for the connection to be established */
+	rd = fi_eq_sread(eq, &event, &entry, sizeof entry, -1, 0);
+	if (rd != sizeof entry) {
+		FT_PRINTERR("fi_eq_sread", rd);
+		goto err;
+	}
+
+	if (event != FI_CONNECTED || entry.fid != &ep->fid) {
+		FT_ERR("Unexpected CM event %d fid %p (ep %p)", event, entry.fid, ep);
+		ret = -FI_EOTHER;
+		goto err;
+	}
+
+	ret = check_address(&ep->fid, "accept");
+	if (ret) {
+		goto err;
+	}
+
+	return 0;
+
+err:
+	fi_reject(pep, fi->handle, NULL, 0);
+	return ret;
+}
+
+static int client_connect(void)
+{
+	struct fi_eq_cm_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int ret;
+
+	ret = fi_getinfo(FT_FIVERSION, opts.dst_addr, opts.dst_port, 0, hints, &fi);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		return ret;
+	}
+
+	ret = fi_domain(fabric, fi, &domain, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_domain", ret);
+		return ret;
+	}
+
+	ret = check_address(&pep->fid, "fi_endpoint (pep)");
+	if (ret)
+		return ret;
+
+	assert(fi->handle == &pep->fid);
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	/* Close the passive endpoint that we "stole" the source address
+	 * from */
+	FT_CLOSE_FID(pep);
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	ret = check_address(&ep->fid, "fi_endpoint (ep)");
+	if (ret)
+		return ret;
+
+	/* Connect to server */
+	ret = fi_connect(ep, fi->dest_addr, NULL, 0);
+	if (ret) {
+		FT_PRINTERR("fi_connect", ret);
+		return ret;
+	}
+
+	/* Wait for the connection to be established */
+	rd = fi_eq_sread(eq, &event, &entry, sizeof entry, -1, 0);
+	if (rd != sizeof entry) {
+		FT_PROCESS_EQ_ERR(rd, eq, "fi_eq_sread", "listen");
+		return (int) rd;
+	}
+
+	if (event != FI_CONNECTED || entry.fid != &ep->fid) {
+		FT_ERR("Unexpected CM event %d fid %p (ep %p)", event, entry.fid, ep);
+		return -FI_EOTHER;
+	}
+
+	ret = check_address(&ep->fid, "connect");
+	if (ret) {
+		return ret;
+	}
+
+	return 0;
+}
+
+static int setup_handle(void)
+{
+	static char buf[BUFSIZ];
+	struct addrinfo *ai, aihints;
+	const char *bound_addr_str;
+	char *saved_addr;
+	size_t saved_addrlen;
+	int ret;
+
+	ret = ft_startup();
+	if (ret) {
+		FT_ERR("ft_startup: %d", ret);
+		return ret;
+	}
+
+	memset(&aihints, 0, sizeof aihints);
+	aihints.ai_flags = AI_PASSIVE;
+	ret = getaddrinfo(opts.src_addr, opts.src_port, &aihints, &ai);
+	if (ret == EAI_SYSTEM) {
+		FT_ERR("getaddrinfo for %s:%s: %s",
+			opts.src_addr, opts.src_port, strerror(errno));
+		return -ret;
+	} else if (ret) {
+		FT_ERR("getaddrinfo: %s", gai_strerror(ret));
+		return -FI_ENODATA;
+	}
+
+	switch (ai->ai_family) {
+	case AF_INET:
+		hints->addr_format = FI_SOCKADDR_IN;
+		break;
+	case AF_INET6:
+		hints->addr_format = FI_SOCKADDR_IN6;
+		break;
+	}
+
+	/* Get fabric info */
+	ret = fi_getinfo(FT_FIVERSION, opts.src_addr, NULL, FI_SOURCE, hints, &fi_pep);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		goto freeai;
+	}
+
+	/* Open passive endpoint without source address */
+	saved_addr = fi_pep->src_addr;
+	saved_addrlen = fi_pep->src_addrlen;
+	fi_pep->src_addr = NULL;
+	fi_pep->src_addrlen = 0;
+
+	ret = fi_fabric(fi_pep->fabric_attr, &fabric, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_fabric", ret);
+		goto out;
+	}
+
+	ret = fi_eq_open(fabric, &eq_attr, &eq, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_eq_open", ret);
+		goto out;
+	}
+
+	/* Open a passive endpoint */
+	ret = fi_passive_ep(fabric, fi_pep, &pep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_passive_ep", ret);
+		goto out;
+	}
+
+	ret = fi_setname(&pep->fid, ai->ai_addr, ai->ai_addrlen);
+	if (ret) {
+		FT_PRINTERR("fi_setname", ret);
+		goto out;
+	}
+
+	ret = fi_getname(&pep->fid, &bound_addr, &bound_addr_len);
+	if (ret) {
+		FT_PRINTERR("fi_getname", ret);
+		goto out;
+	}
+
+	/* Verify port number */
+	switch (ai->ai_family) {
+	case AF_INET:
+		if (bound_addr.sin.sin_port == 0) {
+			FT_ERR("port number is 0 after fi_setname()");
+			ret = -FI_EINVAL;
+			goto out;
+		}
+		break;
+	case AF_INET6:
+		if (bound_addr.sin6.sin6_port == 0) {
+			FT_ERR("port number is 0 after fi_setname()");
+			ret = -FI_EINVAL;
+			goto out;
+		}
+		break;
+	}
+
+	bound_addr_str = sockaddrstr(&bound_addr, bound_addr_len, buf, BUFSIZ);
+	if (!bound_addr_str) {
+		FT_ERR("Unable to get bound_addr as string!");
+		ret = -FI_EINVAL;
+		goto out;
+	}
+	printf("bound_addr: \"%s\"\n", bound_addr_str);
+
+	hints->handle = &pep->fid;
+out:
+	fi_pep->src_addr = saved_addr;
+	fi_pep->src_addrlen = saved_addrlen;
+freeai:
+	freeaddrinfo(ai);
+	return ret;
+}
+
+static int run(void)
+{
+	char *node, *service;
+	uint64_t flags;
+	int ret;
+
+	ret = ft_read_addr_opts(&node, &service, hints, &flags, &opts);
+	if (ret)
+		return ret;
+
+	if (!opts.src_port)
+		opts.src_port = "9229";
+
+	if (!opts.src_addr) {
+		fprintf(stderr, "Source address (-s) is required for this test\n");
+		return -EXIT_FAILURE;
+	}
+
+	ret = setup_handle();
+	if (ret)
+		return ret;
+
+	if (!opts.dst_addr) {
+		ret = server_listen();
+		if (ret)
+			return ret;
+	}
+
+	ret = opts.dst_addr ? client_connect() : server_connect();
+	if (ret) {
+		return ret;
+	}
+
+	ret = ft_send_recv_greeting(ep);
+
+	fi_shutdown(ep, 0);
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A simple MSG client-sever example.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type		= FI_EP_MSG;
+	hints->caps			= FI_MSG;
+	hints->domain_attr->mr_mode 	= FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	hints->addr_format		= FI_SOCKADDR;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/multi_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/multi_ep.c
new file mode 100644
index 000000000..fe1c8158b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/multi_ep.c
@@ -0,0 +1,319 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include <time.h>
+#include <netdb.h>
+#include <unistd.h>
+
+#include <rdma/fabric.h>
+#include <rdma/fi_errno.h>
+#include <rdma/fi_tagged.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_cm.h>
+
+#include "shared.h"
+
+static struct fid_ep **eps;
+static char *data_bufs;
+static char **send_bufs;
+static char **recv_bufs;
+static struct fi_context *recv_ctx;
+static struct fi_context *send_ctx;
+static fi_addr_t *remote_addr;
+int num_eps = 3;
+
+
+static int alloc_multi_ep_res()
+{
+	char *rx_buf_ptr;
+	int i;
+
+	eps = calloc(num_eps, sizeof(*eps));
+	remote_addr = calloc(num_eps, sizeof(*remote_addr));
+	send_bufs = calloc(num_eps, sizeof(*send_bufs));
+	recv_bufs = calloc(num_eps, sizeof(*recv_bufs));
+	send_ctx = calloc(num_eps, sizeof(*send_ctx));
+	recv_ctx = calloc(num_eps, sizeof(*recv_ctx));
+	data_bufs = calloc(num_eps * 2, opts.transfer_size);
+
+	if (!eps || !remote_addr || !send_bufs || !recv_bufs ||
+	    !send_ctx || !recv_ctx || !data_bufs)
+		return -FI_ENOMEM;
+
+	rx_buf_ptr = data_bufs + opts.transfer_size * num_eps;
+	for (i = 0; i < num_eps; i++) {
+		send_bufs[i] = data_bufs + opts.transfer_size * i;
+		recv_bufs[i] = rx_buf_ptr + opts.transfer_size * i;
+	}
+
+	return 0;
+}
+
+static void free_ep_res()
+{
+	int i;
+
+	for (i = 0; i < num_eps; i++)
+		FT_CLOSE_FID(eps[i]);
+
+	free(data_bufs);
+	free(send_bufs);
+	free(recv_bufs);
+	free(send_ctx);
+	free(recv_ctx);
+	free(remote_addr);
+	free(eps);
+}
+
+static int do_transfers(void)
+{
+	int i, ret;
+
+	for (i = 0; i < num_eps; i++) {
+		rx_buf = recv_bufs[i];
+		ret = ft_post_rx(eps[i], opts.transfer_size, &recv_ctx[i]);
+		if (ret)
+			return ret;
+	}
+
+	for (i = 0; i < num_eps; i++) {
+		if (ft_check_opts(FT_OPT_VERIFY_DATA))
+			ft_fill_buf(send_bufs[i], opts.transfer_size);
+
+		tx_buf = send_bufs[i];
+		ret = ft_post_tx(eps[i], remote_addr[i], opts.transfer_size, NO_CQ_DATA, &send_ctx[i]);
+		if (ret)
+			return ret;
+	}
+
+	ret = ft_get_tx_comp(num_eps);
+	if (ret < 0)
+		return ret;
+
+	ret = ft_get_rx_comp(num_eps);
+	if (ret < 0)
+		return ret;
+
+	if (ft_check_opts(FT_OPT_VERIFY_DATA)) {
+		for (i = 0; i < num_eps; i++) {
+			ret = ft_check_buf(recv_bufs[i], opts.transfer_size);
+			if (ret)
+				return ret;
+		}
+	}
+
+	for (i = 0; i < num_eps; i++)
+		ft_finalize_ep(eps[i]);
+
+	printf("PASSED multi ep\n");
+	return 0;
+}
+
+static int setup_client_ep(struct fid_ep **ep)
+{
+	int ret;
+
+	ret = fi_endpoint(domain, fi, ep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		return ret;
+	}
+
+	ret = ft_enable_ep(*ep, eq, av, txcq, rxcq, txcntr, rxcntr);
+	if (ret)
+		return ret;
+
+	ret = ft_connect_ep(*ep, eq, fi->dest_addr);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int setup_server_ep(struct fid_ep **ep)
+{
+	int ret;
+
+	ret = ft_retrieve_conn_req(eq, &fi);
+	if (ret)
+		goto failed_accept;
+
+	ret = fi_endpoint(domain, fi, ep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		goto failed_accept;
+	}
+
+	ret = ft_enable_ep(*ep, eq, av, txcq, rxcq, txcntr, rxcntr);
+	if (ret)
+		goto failed_accept;
+
+	ret = ft_accept_connection(*ep, eq);
+	if (ret)
+		goto failed_accept;
+
+	return 0;
+
+failed_accept:
+	fi_reject(pep, fi->handle, NULL, 0);
+	return ret;
+}
+
+static int setup_av_ep(struct fid_ep **ep, fi_addr_t *remote_addr)
+{
+	int ret;
+	hints->src_addr = NULL;
+
+	fi_freeinfo(fi);
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, NULL, 0, hints, &fi);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		return ret;
+	}
+
+	ret = fi_endpoint(domain, fi, ep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		return ret;
+	}
+
+	ret = ft_enable_ep(*ep, eq, av, txcq, rxcq, txcntr, rxcntr);
+	if (ret)
+		return ret;
+
+	ret = ft_init_av_addr(av, *ep, remote_addr);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int run_test(void)
+{
+	int i, ret;
+
+	ret = alloc_multi_ep_res();
+	if (ret)
+		return ret;
+
+	if (hints->ep_attr->type == FI_EP_MSG) {
+		ret = ft_init_fabric_cm();
+		if (ret)
+			return ret;
+	} else {
+		opts.av_size = num_eps + 1;
+		ret = ft_init_fabric();
+		if (ret)
+			return ret;
+	}
+
+	/* Create additional endpoints. */
+	for (i = 0; i < num_eps; i++) {
+		if (hints->ep_attr->type == FI_EP_MSG) {
+			if (opts.dst_addr) {
+				ret = setup_client_ep(&eps[i]);
+				if (ret)
+					return ret;
+			} else {
+				ret = setup_server_ep(&eps[i]);
+				if (ret)
+					return ret;
+			}
+		} else {
+			ret = setup_av_ep(&eps[i], &remote_addr[i]);
+			if (ret)
+				return ret;
+		}
+	}
+
+	tx_cq_cntr = rx_cq_cntr = 0;
+	tx_seq = rx_seq = 0;
+	ret = do_transfers();
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int main(int argc, char **argv)
+{
+	int op;
+	int ret = 0;
+
+	opts = INIT_OPTS;
+	opts.transfer_size = 256;
+	opts.options |= FT_OPT_SKIP_REG_MR;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "c:vh" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'c':
+			num_eps = atoi(optarg);
+			break;
+		case 'v':
+			opts.options |= FT_OPT_VERIFY_DATA;
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "Multi endpoint test");
+			FT_PRINT_OPTS_USAGE("-c <int>",
+				"number of endpoints to create and test (def 3)");
+			FT_PRINT_OPTS_USAGE("-v", "Enable DataCheck testing");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->caps = FI_MSG;
+	hints->mode = FI_CONTEXT;
+
+	ret = run_test();
+
+	free_ep_res();
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/multi_mr.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/multi_mr.c
new file mode 100644
index 000000000..de01d7b62
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/multi_mr.c
@@ -0,0 +1,325 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ * Copyright (c) 2017, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+
+#include <rdma/fabric.h>
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_cm.h>
+
+#include "shared.h"
+
+struct test_mr {
+	uint8_t *buf;
+	struct fid_cntr *rcntr;
+	uint64_t rcntr_next;
+	struct fid_mr *mr;
+	struct fi_rma_iov *remote;
+};
+
+struct test_mr *mr_res_array;
+uint8_t *mr_buf_array;
+struct fi_rma_iov *remote_array;
+uint64_t mr_count;
+int verbose;
+
+static int wait_cntr(struct fid_cntr *cntr, uint64_t *cntr_next)
+{
+	/* 30 second wait timeout */
+	int ret = fi_cntr_wait(cntr, *cntr_next, 30 * 1000);
+	if (ret < 0)
+		return ret;
+
+	*cntr_next += 1;
+
+	return 0;
+}
+
+static int free_mr_res()
+{
+	int i;
+
+	if (!mr_res_array)
+		return 0;
+
+	for (i = 0; i < mr_count; i++) {
+		FT_CLOSE_FID(mr_res_array[i].mr);
+		FT_CLOSE_FID(mr_res_array[i].rcntr);
+	}
+	free(mr_res_array);
+	free(remote_array);
+	free(mr_buf_array);
+
+	return 0;
+}
+
+static int alloc_multi_mr_res()
+{
+	int i = 0;
+
+	mr_res_array = calloc(mr_count, sizeof(*mr_res_array));
+	if (!mr_res_array)
+		return -FI_ENOMEM;
+
+	remote_array = calloc(mr_count, sizeof(*remote_array));
+	if (!remote_array)
+		return -FI_ENOMEM;
+
+	mr_buf_array = calloc(mr_count, opts.transfer_size);
+	if (!mr_buf_array)
+		return -FI_ENOMEM;
+
+	for (i = 0; i < mr_count; i++) {
+		mr_res_array[i].remote = &remote_array[i];
+		mr_res_array[i].buf = &mr_buf_array[i];
+	}
+
+	return 0;
+}
+
+static int init_multi_mr_res()
+{
+	int ret = 0, i;
+
+	if ((1ULL << fi->domain_attr->mr_key_size) < mr_count) {
+		fprintf(stderr, "ERROR: too many memory regions for unique mr keys");
+		return -FI_EINVAL;
+	}
+
+	ret = alloc_multi_mr_res();
+	if (ret)
+		return ret;
+
+	for (i = 0; i < mr_count; i++) {
+		ret = fi_cntr_open(domain,
+				&cntr_attr,
+				&mr_res_array[i].rcntr,
+				NULL);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_open", ret);
+			return ret;
+		}
+
+		mr_res_array[i].remote->len = opts.transfer_size;
+		mr_res_array[i].remote->addr = 0;
+
+		memset(mr_res_array[i].buf, 0, opts.transfer_size);
+
+		mr_res_array[i].rcntr_next = 1;
+
+		mr_res_array[i].remote->key = i + 1;
+
+		ret = fi_mr_reg(domain, mr_res_array[i].buf,
+				opts.transfer_size, FI_REMOTE_WRITE,
+				0, mr_res_array[i].remote->key,
+				0, &mr_res_array[i].mr, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_mr_reg", ret);
+			return ret;
+		}
+
+		if (verbose) {
+			printf("MR_REG:domain_ptr, buf_ptr, mr_size, mr_ptr, mr_key)\n");
+			printf("%p, %p, %d, %p, %lu)\n",
+					domain,
+					mr_res_array[i].buf,
+					opts.transfer_size,
+					&mr_res_array[i].mr,
+					(unsigned long)fi_mr_key(mr_res_array[i].mr));
+		}
+
+		ret = fi_mr_bind(mr_res_array[i].mr,
+				&mr_res_array[i].rcntr->fid,
+				FI_REMOTE_WRITE);
+		if (ret) {
+			FT_PRINTERR("fi_mr_bind", ret);
+			return ret;
+		}
+	}
+
+	return ret;
+}
+
+static int mr_key_test()
+{
+	int i, ret = 0;
+	struct fi_context rma_ctx;
+
+	for (i = 0; i < mr_count; i++) {
+		tx_buf = (char *)mr_res_array[i].buf;
+
+		if (opts.dst_addr) {
+			ft_fill_buf(mr_res_array[i].buf,
+					opts.transfer_size);
+
+			if (verbose)
+				printf("write to host's key %lx\n",
+						(unsigned long)fi_mr_key(mr_res_array[i].mr));
+
+			ft_post_rma(FT_RMA_WRITE, ep, opts.transfer_size,
+					mr_res_array[i].remote, &rma_ctx);
+
+			if (verbose)
+				printf("sent successfully\n");
+
+			ret = wait_cntr(mr_res_array[i].rcntr,
+					&mr_res_array[i].rcntr_next);
+			if (ret)
+				return ret;
+
+			if (ft_check_opts(FT_OPT_VERIFY_DATA)) {
+				if (verbose)
+					printf("checking result in buffer %p, key %lx\n",
+							mr_res_array[i].buf,
+							(unsigned long)fi_mr_key(mr_res_array[i].mr));
+
+				ret = ft_check_buf(mr_res_array[i].buf,
+						opts.transfer_size);
+				if (ret)
+					return ret;
+			}
+		} else {
+			ret = wait_cntr(mr_res_array[i].rcntr,
+					&mr_res_array[i].rcntr_next);
+			if (ret)
+				return ret;
+
+			if (ft_check_opts(FT_OPT_VERIFY_DATA)) {
+				if (verbose)
+					printf("checking result in buffer %p, key %lx\n",
+							mr_res_array[i].buf,
+							(unsigned long)fi_mr_key(mr_res_array[i].mr));
+
+				ret = ft_check_buf(mr_res_array[i].buf,
+						opts.transfer_size);
+				if (ret)
+					return ret;
+			}
+
+			ft_fill_buf(mr_res_array[i].buf,
+					opts.transfer_size);
+
+			if (verbose)
+				printf("write to client's key %lx\n",
+						(unsigned long)fi_mr_key(mr_res_array[i].mr));
+
+			ft_post_rma(FT_RMA_WRITE, ep, opts.transfer_size,
+					mr_res_array[i].remote, &rma_ctx);
+
+			if (verbose)
+					printf("sent successfully\n");
+		}
+	}
+	printf("GOOD, multi mr key test complete\n");
+
+	return ret;
+}
+
+static int run_test(void)
+{
+	int ret = 0;
+
+	ft_mr_alloc_func = init_multi_mr_res;
+
+	if (hints->ep_attr->type == FI_EP_MSG)
+		ret = ft_init_fabric_cm();
+	else
+		ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	ret = mr_key_test();
+
+	ft_sync();
+	ft_finalize();
+
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op;
+	int ret = 0;
+
+	opts = INIT_OPTS;
+	opts.transfer_size = 4096;
+	mr_count = 2;
+	verbose = 0;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "c:Vvh" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'c':
+			mr_count = strtoull(optarg, NULL, 10);
+			break;
+		case 'V':
+			verbose = 1;
+			break;
+		case 'v':
+			opts.options |= FT_OPT_VERIFY_DATA;
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "Ping-pong multi memory region test");
+			FT_PRINT_OPTS_USAGE("-c <int>", "number of memory regions to create and test");
+			FT_PRINT_OPTS_USAGE("-V", "Enable verbose printing");
+			FT_PRINT_OPTS_USAGE("-v", "Enable DataCheck testing");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->caps = FI_RMA | FI_RMA_EVENT | FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run_test();
+
+	free_mr_res();
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/poll.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/poll.c
new file mode 100644
index 000000000..5fd01c17d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/poll.c
@@ -0,0 +1,244 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include <unistd.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_cm.h>
+
+#include <shared.h>
+
+#define MAX_POLL_CNT 10
+
+static int alloc_ep_res(struct fi_info *fi)
+{
+	struct fi_poll_attr poll_attr;
+	int ret;
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	memset(&poll_attr, 0, sizeof poll_attr);
+	ret = fi_poll_open(domain, &poll_attr, &pollset);
+	if (ret) {
+		FT_PRINTERR("fi_poll_open", ret);
+		return ret;
+	}
+
+	if (txcq) {
+		ret = fi_poll_add(pollset, &txcq->fid, 0);
+		if (ret)
+			goto err;
+	}
+
+	if (rxcq) {
+		ret = fi_poll_add(pollset, &rxcq->fid, 0);
+		if (ret)
+			goto err;
+	}
+
+	if (txcntr) {
+		ret = fi_poll_add(pollset, &txcntr->fid, 0);
+		if (ret)
+			goto err;
+	}
+
+	if (rxcntr) {
+		ret = fi_poll_add(pollset, &rxcntr->fid, 0);
+		if (ret)
+			goto err;
+	}
+
+	return 0;
+err:
+	FT_PRINTERR("fi_poll_add", ret);
+	return ret;
+}
+
+static int init_fabric(void)
+{
+	int ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+	return 0;
+}
+
+static int send_recv()
+{
+	struct fid_cq *cq;
+	void *context[MAX_POLL_CNT];
+	struct fi_cq_entry comp;
+	int ret;
+	int ret_count = 0;
+	int i, tx_cntr_val = 0, rx_cntr_val = 0;
+
+	fprintf(stdout, "Posting a send...\n");
+	ret = ft_post_tx(ep, remote_fi_addr, tx_size, NO_CQ_DATA, &tx_ctx);
+	if (ret)
+		return ret;
+
+	while (((opts.options & FT_OPT_TX_CQ) && (tx_cq_cntr < tx_seq)) ||
+	       ((opts.options & FT_OPT_TX_CNTR) && (tx_cntr_val < tx_seq)) ||
+	       ((opts.options & FT_OPT_RX_CQ) && (rx_cq_cntr < rx_seq)) ||
+	       ((opts.options & FT_OPT_RX_CNTR) && (rx_cntr_val < rx_seq))) {
+
+		/* Poll send and recv CQs/Cntrs */
+		do {
+			ret_count = fi_poll(pollset, context, MAX_POLL_CNT);
+			if (ret_count < 0) {
+				FT_PRINTERR("fi_poll", ret_count);
+				return ret_count;
+			}
+		} while (!ret_count);
+
+		fprintf(stdout, "Retrieved %d event(s)\n", ret_count);
+
+		for (i = 0; i < ret_count; i++) {
+			if (context[i] == &txcq) {
+				printf("Send completion received\n");
+				cq = txcq;
+				tx_cq_cntr++;
+			} else if (context[i] == &rxcq) {
+				printf("Recv completion received\n");
+				cq = rxcq;
+				rx_cq_cntr++;
+			} else if (context[i] == &txcntr) {
+				printf("Send counter poll-event\n");
+				tx_cntr_val = fi_cntr_read(txcntr);
+				if (tx_cntr_val > tx_seq) {
+					FT_ERR("Invalid tx counter event\n");
+					FT_ERR("expected: %" PRIu64 ", found: "
+					       "%d\n", tx_seq, tx_cntr_val);
+					return -1;
+				}
+				continue;
+			} else if (context[i] == &rxcntr) {
+				printf("Recv counter poll-event\n");
+				rx_cntr_val = fi_cntr_read(rxcntr);
+				if (rx_cntr_val > rx_seq) {
+					FT_ERR("Invalid rx counter event\n");
+					FT_ERR("expected: %" PRIu64 ", found: "
+					       "%d\n", rx_seq, rx_cntr_val);
+					return -1;
+				}
+				continue;
+			} else {
+				FT_ERR("Unknown completion received\n");
+				return -1;
+			}
+
+			/* Read the completion entry */
+			ret = fi_cq_read(cq, &comp, 1);
+			if (ret < 0) {
+				if (ret == -FI_EAVAIL) {
+					ret = ft_cq_readerr(cq);
+				} else {
+					FT_PRINTERR("fi_cq_read", ret);
+				}
+				return ret;
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int run(void)
+{
+	int ret;
+
+	ret = init_fabric();
+	if (ret)
+		return ret;
+
+	ret = ft_init_av();
+	if (ret)
+		return ret;
+
+	return send_recv();
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret = 0;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" CS_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A client-server example that uses poll.\n");
+			FT_PRINT_OPTS_USAGE("-t <type>", "completion type [queue, counter]");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm.c
new file mode 100644
index 000000000..e9edf9b4c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm.c
@@ -0,0 +1,84 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2017, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <shared.h>
+
+static int run(void)
+{
+	int ret;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	return ft_send_recv_greeting(ep);
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A simple RDM client-sever example.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_atomic.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_atomic.c
new file mode 100644
index 000000000..3750f9a66
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_atomic.c
@@ -0,0 +1,544 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_atomic.h>
+
+#include "shared.h"
+
+static enum fi_op op_type = FI_MIN;
+static void *result;
+static void *compare;
+
+static struct fid_mr *mr_result;
+static struct fid_mr *mr_compare;
+static struct fi_context fi_ctx_atomic;
+
+static enum fi_datatype datatype;
+static size_t *count;
+static int run_all_ops = 1, run_all_datatypes = 1;
+
+static enum fi_op get_fi_op(char *op)
+{
+	if (!strcmp(op, "min"))
+		return FI_MIN;
+	else if (!strcmp(op, "max"))
+		return FI_MAX;
+	else if (!strcmp(op, "sum"))
+		return FI_SUM;
+	else if (!strcmp(op, "prod"))
+		return FI_PROD;
+	else if (!strcmp(op, "lor"))
+		return FI_LOR;
+	else if (!strcmp(op, "land"))
+		return FI_LAND;
+	else if (!strcmp(op, "bor"))
+		return FI_BOR;
+	else if (!strcmp(op, "band"))
+		return FI_BAND;
+	else if (!strcmp(op, "lxor"))
+		return FI_LXOR;
+	else if (!strcmp(op, "bxor"))
+		return FI_BXOR;
+	else if (!strcmp(op, "read"))
+		return FI_ATOMIC_READ;
+	else if (!strcmp(op, "write"))
+		return FI_ATOMIC_WRITE;
+	else if (!strcmp(op, "cswap"))
+		return FI_CSWAP;
+	else if (!strcmp(op, "cswap_ne"))
+		return FI_CSWAP_NE;
+	else if (!strcmp(op, "cswap_le"))
+		return FI_CSWAP_LE;
+	else if (!strcmp(op, "cswap_lt"))
+		return FI_CSWAP_LT;
+	else if (!strcmp(op, "cswap_ge"))
+		return FI_CSWAP_GE;
+	else if (!strcmp(op, "cswap_gt"))
+		return FI_CSWAP_GT;
+	else if (!strcmp(op, "mswap"))
+		return FI_MSWAP;
+	else {
+		fprintf(stderr, "Not a valid atomic operation\n");
+		return FI_ATOMIC_OP_LAST;
+	}
+}
+
+static enum fi_datatype get_fi_datatype(char *op)
+{
+	if (!strcmp(op, "int8"))
+		return FI_INT8;
+	else if (!strcmp(op, "uint8"))
+		return FI_UINT8;
+	else if (!strcmp(op, "int16"))
+		return FI_INT16;
+	else if (!strcmp(op, "uint16"))
+		return FI_UINT16;
+	else if (!strcmp(op, "int32"))
+		return FI_INT32;
+	else if (!strcmp(op, "uint32"))
+		return FI_UINT32;
+	else if (!strcmp(op, "int64"))
+		return FI_INT64;
+	else if (!strcmp(op, "uint64"))
+		return FI_UINT64;
+	else if (!strcmp(op, "float"))
+		return FI_FLOAT;
+	else if (!strcmp(op, "double"))
+		return FI_DOUBLE;
+	else if (!strcmp(op, "float_complex"))
+		return FI_FLOAT_COMPLEX;
+	else if (!strcmp(op, "double_complex"))
+		return FI_DOUBLE_COMPLEX;
+	else if (!strcmp(op, "long_double"))
+		return FI_LONG_DOUBLE;
+	else if (!strcmp(op, "long_double_complex"))
+		return FI_LONG_DOUBLE_COMPLEX;
+	else {
+		fprintf(stderr, "Not a valid atomic operation\n");
+		return FI_DATATYPE_LAST;
+	}
+}
+
+static void print_opts_usage(char *name)
+{
+	ft_csusage(name, NULL);
+	/* Atomic op type */
+	FT_PRINT_OPTS_USAGE("-o <op>", "atomic op type: all|min|max|sum|prod|lor|");
+	FT_PRINT_OPTS_USAGE("", "land|bor|band|lxor|bxor|read|write|cswap|cswap_ne|"
+				"cswap_le|cswap_lt|");
+	FT_PRINT_OPTS_USAGE("", "cswap_ge|cswap_gt|mswap (default: all)");
+	/* Atomic datatype */
+	FT_PRINT_OPTS_USAGE("-z <datatype>", "atomic datatype: int8|uint8|int16|uint16|");
+	FT_PRINT_OPTS_USAGE("", "int32|uint32|int64|uint64|float|double|"
+				"float_complex|double_complex|");
+	FT_PRINT_OPTS_USAGE("", "long_double|long_double_complex (default: all)");
+}
+
+#define create_atomic_op_executor(type)						\
+static inline int execute_atomic_ ## type ## _op(enum fi_op op_type,		\
+						 enum fi_datatype datatype)	\
+{										\
+	int ret = FI_SUCCESS, len, i;						\
+	len = snprintf((test_name), sizeof(test_name), "%s_",			\
+		       fi_tostr(&(datatype), FI_TYPE_ATOMIC_TYPE));		\
+	snprintf((test_name) + len, sizeof(test_name) - len, "%s_"#type"_lat",	\
+		 fi_tostr(&op_type, FI_TYPE_ATOMIC_OP));			\
+	opts.transfer_size = datatype_to_size(datatype);			\
+										\
+	ft_start();								\
+	for (i = 0; i < opts.iterations; i++) {					\
+		ret = execute_ ## type ## _atomic_op(op_type);			\
+		if (ret)							\
+			break;							\
+	}									\
+	ft_stop();								\
+	report_perf();								\
+										\
+	return ret;								\
+}
+
+#define create_atomic_op_handler(type)						\
+create_atomic_op_executor(type)							\
+static inline int handle_atomic_ ## type ## _op(int run_all_datatypes,		\
+						enum fi_op op_type,		\
+						size_t *count)			\
+{										\
+	int ret = FI_SUCCESS;							\
+										\
+	if (run_all_datatypes) {						\
+		for (datatype = 0; datatype < FI_DATATYPE_LAST; datatype++) {	\
+			ret = check_ ## type ## _atomic_op(ep, op_type,		\
+							   datatype, count);	\
+			if (ret == -FI_ENOSYS || ret == -FI_EOPNOTSUPP) {	\
+				fprintf(stderr,					\
+					"Provider doesn't support %s ",		\
+					fi_tostr(&op_type,			\
+						 FI_TYPE_ATOMIC_OP));		\
+				fprintf(stderr,					\
+					#type" atomic operation on %s\n",	\
+					fi_tostr(&datatype,			\
+						 FI_TYPE_ATOMIC_TYPE));		\
+				continue;					\
+			} else if (ret) {					\
+				goto fn;					\
+			}							\
+										\
+			ret = execute_atomic_ ##type ## _op(op_type, datatype);	\
+			if (ret)						\
+				goto fn;					\
+		}								\
+	} else {								\
+		ret = check_ ## type ## _atomic_op(ep, op_type,			\
+						   datatype, count);		\
+		if (ret == -FI_ENOSYS || ret == -FI_EOPNOTSUPP) {		\
+			fprintf(stderr,						\
+				"Provider doesn't support %s ",			\
+				fi_tostr(&op_type,				\
+					 FI_TYPE_ATOMIC_OP));			\
+			fprintf(stderr,						\
+				#type" atomic operation on %s\n",		\
+				fi_tostr(&datatype,				\
+					 FI_TYPE_ATOMIC_TYPE));			\
+			goto fn;						\
+		} else if (ret) {						\
+			goto fn;						\
+		}								\
+										\
+		ret = execute_atomic_ ## type ##_op(op_type, datatype);		\
+	}									\
+										\
+fn:										\
+	return ret;								\
+}
+
+
+static inline int execute_base_atomic_op(enum fi_op op)
+{
+	int ret;
+
+	ret = ft_post_atomic(FT_ATOMIC_BASE, ep, NULL, NULL, NULL, NULL,
+			     &remote, datatype, op, &fi_ctx_atomic);
+	if (ret)
+		return ret;
+
+	ret = ft_get_tx_comp(tx_seq);
+
+	return ret;
+}
+
+static inline int execute_fetch_atomic_op(enum fi_op op)
+{
+	int ret;
+
+	ret = ft_post_atomic(FT_ATOMIC_FETCH, ep, NULL, NULL, result,
+			     fi_mr_desc(mr_result), &remote, datatype,
+			     op, &fi_ctx_atomic);
+	if (ret)
+		return ret;
+
+	ret = ft_get_tx_comp(tx_seq);
+
+	return ret;
+}
+
+static inline int execute_compare_atomic_op(enum fi_op op)
+{
+	int ret;
+
+	ret = ft_post_atomic(FT_ATOMIC_COMPARE, ep, compare, fi_mr_desc(mr_compare),
+			     result, fi_mr_desc(mr_result), &remote, datatype,
+			     op, &fi_ctx_atomic);
+	if (ret)
+		return ret;
+
+	ret = ft_get_tx_comp(tx_seq);
+
+	return ret;
+}
+
+static void report_perf(void)
+{
+	if (opts.machr)
+		show_perf_mr(opts.transfer_size, opts.iterations, &start, &end, 1, opts.argc,
+			opts.argv);
+	else
+		show_perf(test_name, opts.transfer_size, opts.iterations, &start, &end, 1);
+}
+
+create_atomic_op_handler(base)
+create_atomic_op_handler(fetch)
+create_atomic_op_handler(compare)
+
+static int run_op(void)
+{
+	int ret = -FI_EINVAL;
+
+	count = (size_t *)malloc(sizeof(*count));
+	if (!count) {
+		ret = -FI_ENOMEM;
+		perror("malloc");
+		goto fn;
+	}
+	ft_sync();
+
+	switch (op_type) {
+	case FI_MIN:
+	case FI_MAX:
+	case FI_SUM:
+	case FI_PROD:
+	case FI_LOR:
+	case FI_LAND:
+	case FI_BOR:
+	case FI_BAND:
+	case FI_LXOR:
+	case FI_BXOR:
+	case FI_ATOMIC_WRITE:
+		ret = handle_atomic_base_op(run_all_datatypes,
+					    op_type, count);
+		break;
+	case FI_ATOMIC_READ:
+		ret = handle_atomic_fetch_op(run_all_datatypes,
+					     op_type, count);
+		break;
+	case FI_CSWAP:
+	case FI_CSWAP_NE:
+	case FI_CSWAP_LE:
+	case FI_CSWAP_LT:
+	case FI_CSWAP_GE:
+	case FI_CSWAP_GT:
+	case FI_MSWAP:
+		ret = handle_atomic_compare_op(run_all_datatypes,
+					       op_type, count);
+		break;
+	default:
+		FT_WARN("Invalid atomic operation type %d\n", op_type);
+		break;
+	}
+
+	free(count);
+fn:
+	return ret;
+}
+
+static int run_ops(void)
+{
+	int ret;
+
+	for (op_type = FI_MIN; op_type < FI_ATOMIC_OP_LAST; op_type++) {
+		ret = run_op();
+		if (ret && ret != -FI_ENOSYS && ret != -FI_EOPNOTSUPP) {
+			FT_PRINTERR("run_op", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int run_test(void)
+{
+	return run_all_ops ? run_ops() : run_op();
+}
+
+static void free_res(void)
+{
+	FT_CLOSE_FID(mr_result);
+	FT_CLOSE_FID(mr_compare);
+	if (result) {
+		free(result);
+		result = NULL;
+	}
+	if (compare) {
+		free(compare);
+		compare = NULL;
+	}
+}
+
+static uint64_t get_mr_key()
+{
+	static uint64_t user_key = FT_MR_KEY;
+
+	return ((fi->domain_attr->mr_mode == FI_MR_BASIC) ||
+		(fi->domain_attr->mr_mode & FI_MR_PROV_KEY)) ?
+		0 : user_key++;
+}
+
+static int alloc_ep_res(struct fi_info *fi)
+{
+	int ret;
+	int mr_local = !!(fi->domain_attr->mr_mode & FI_MR_LOCAL);
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	result = malloc(buf_size);
+	if (!result) {
+		perror("malloc");
+		return -1;
+	}
+
+	compare = malloc(buf_size);
+	if (!compare) {
+		perror("malloc");
+		return -1;
+	}
+
+	// registers local data buffer buff that used for send/recv
+	// and local/remote RMA.
+	ret = fi_mr_reg(domain, buf, buf_size,
+			((mr_local ?
+			  FI_SEND | FI_RECV | FI_READ | FI_WRITE : 0) |
+			 FI_REMOTE_READ | FI_REMOTE_WRITE), 0,
+			get_mr_key(), 0, &mr, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", ret);
+		return ret;
+	}
+	// Set global descriptor for FI_MR_LOCAL.
+	if (mr_local)
+		mr_desc = fi_mr_desc(mr);
+
+	// registers local data buffer that stores results
+	ret = fi_mr_reg(domain, result, buf_size,
+			(mr_local ? FI_READ : 0) | FI_REMOTE_WRITE, 0,
+			get_mr_key(), 0, &mr_result, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", -ret);
+		return ret;
+	}
+
+	// registers local data buffer that contains comparison data
+	ret = fi_mr_reg(domain, compare, buf_size,
+			(mr_local ? FI_WRITE : 0)  | FI_REMOTE_READ, 0,
+			get_mr_key(), 0, &mr_compare, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int init_fabric(void)
+{
+	int ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int run(void)
+{
+	int ret;
+
+	ret = init_fabric();
+	if (ret)
+		return ret;
+
+	ret = ft_init_av();
+	if (ret)
+		goto out;
+
+	ret = ft_exchange_keys(&remote);
+	if (ret)
+		goto out;
+
+	ret = run_test();
+	if (ret)
+		goto out;
+
+	ft_sync();
+	ft_finalize();
+out:
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SKIP_REG_MR;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "ho:z:" CS_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		case 'o':
+			if (!strncasecmp("all", optarg, 3)) {
+				run_all_ops = 1;
+			} else {
+				run_all_ops = 0;
+				op_type = get_fi_op(optarg);
+				if (op_type == FI_ATOMIC_OP_LAST) {
+					print_opts_usage(argv[0]);
+					return EXIT_FAILURE;
+				}
+			}
+			break;
+		case 'z':
+			if (!strncasecmp("all", optarg, 3)) {
+				run_all_datatypes = 1;
+			} else {
+				run_all_datatypes = 0;
+				datatype = get_fi_datatype(optarg);
+				if (datatype == FI_DATATYPE_LAST) {
+					print_opts_usage(argv[0]);
+					return EXIT_FAILURE;
+				}
+			}
+			break;
+		default:
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			print_opts_usage(argv[0]);
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG | FI_ATOMICS;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	free_res();
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_deferred_wq.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_deferred_wq.c
new file mode 100644
index 000000000..1077187d2
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_deferred_wq.c
@@ -0,0 +1,672 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2017, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_trigger.h>
+
+#include <shared.h>
+
+struct fi_context2 trig_ctx1, trig_ctx2;
+static char *welcome_text = "Hello from Client!";
+static char *write_text = "This is a successful trigger";
+struct fi_deferred_work work;
+struct fid_cntr *test_cntr;
+uint64_t n_trig, rx_exp;
+static char *result_buf, *compare_buf;
+static struct fid_mr *mr_result, *mr_compare;
+int use_alias = 0;
+struct fid_ep *trig_ep;
+enum fi_op_type tested_op;
+
+static void format_simple_msg(struct fi_msg *msg, struct iovec *iov, void *src,
+			      size_t size, void *ctx)
+{
+	msg->context = ctx;
+	msg->desc = mr_desc;
+	msg->iov_count = 1;
+	msg->addr = remote_fi_addr;
+	msg->data = 0;
+
+	iov->iov_base = src;
+	iov->iov_len = size;
+	msg->msg_iov = iov;
+}
+
+static void format_simple_msg_tagged(struct fi_msg_tagged *msg, struct iovec *iov,
+			      void *src, size_t size, void *ctx,
+			      uint64_t tag)
+{
+	msg->context = ctx;
+	msg->desc = mr_desc;
+	msg->iov_count = 1;
+	msg->addr = remote_fi_addr;
+	msg->data = 0;
+	msg->tag = tag;
+
+	iov->iov_base = src;
+	iov->iov_len = size;
+	msg->msg_iov = iov;
+}
+
+static void format_simple_msg_rma(struct fi_msg_rma *msg, struct iovec *iov,
+			   struct fi_rma_iov *rma_iov, void *src,
+			   size_t size, void *ctx)
+{
+	msg->context = ctx;
+	msg->desc = mr_desc;
+	msg->iov_count = 1;
+	msg->addr = remote_fi_addr;
+	msg->rma_iov_count = 1;
+
+	iov->iov_base = src;
+	iov->iov_len = size;
+	msg->msg_iov = iov;
+
+	rma_iov->addr = 0;
+	rma_iov->key = FT_MR_KEY;
+	rma_iov->len = size;
+	msg->rma_iov = rma_iov;
+}
+
+static void format_simple_msg_atomic(struct fi_msg_atomic *msg, struct fi_ioc *iov,
+			      struct fi_rma_ioc *rma_iov, void *src, size_t size,
+			      void *ctx, enum fi_datatype datatype,
+			      enum fi_op op)
+{
+	msg->context = ctx;
+	msg->desc = mr_desc;
+	msg->iov_count = 1;
+	msg->rma_iov_count = 1;
+	msg->addr = remote_fi_addr;
+	msg->data = 0;
+	msg->datatype = datatype;
+	msg->op = op;
+	msg->data = 0;
+
+	iov->addr = src;
+	iov->count = size;
+	msg->msg_iov = iov;
+
+	rma_iov->addr = 0;
+	rma_iov->count = size;
+	rma_iov->key = FT_MR_KEY;
+	msg->rma_iov = rma_iov;
+}
+
+static void format_simple_msg_fetch(struct fi_msg_fetch *msg, struct fi_ioc *iov,
+				    void *src, size_t size)
+{
+	msg->desc = fi_mr_desc(mr_result);
+
+	iov->addr = src;
+	iov->count = size;
+
+	msg->iov_count = 1;
+	msg->msg_iov = iov;
+}
+
+static void format_simple_msg_compare(struct fi_msg_compare *msg, struct fi_ioc *iov,
+				      void *src, size_t size)
+{
+	msg->desc = fi_mr_desc(mr_compare);
+
+	iov->addr = src;
+	iov->count = size;
+
+	msg->iov_count = 1;
+	msg->msg_iov = iov;
+}
+
+static int check_data()
+{
+	int ret, i;
+	char c = ~0;
+
+	switch (tested_op) {
+	case FI_OP_COMPARE_ATOMIC:
+	case FI_OP_FETCH_ATOMIC:
+		if (strncmp(result_buf, welcome_text, strlen(welcome_text))) {
+			printf("Data mismatch in fetch buffer...");
+			return 1;
+		}
+		/* fall through */
+	case FI_OP_ATOMIC:
+		for (i = 0; i < strlen(welcome_text); i++) {
+			if (rx_buf[i] != c) {
+				printf("Data mismatch found at byte %d...", i);
+				return 1;
+			}
+		}
+		break;
+	case FI_OP_CNTR_SET:
+	case FI_OP_CNTR_ADD:
+		ret  = fi_cntr_wait(test_cntr, 10, -1);
+		if (ret)
+			return ret;
+		break;
+	case FI_OP_READ:
+	case FI_OP_WRITE:
+		if (strncmp(result_buf, write_text, strlen(write_text))) {
+			printf("Data mismatch in read buffer...");
+			return 1;
+		}
+		/* fall through */
+	default:
+		if (strncmp(rx_buf, write_text, strlen(write_text))) {
+			printf("Data mismatch in rx_buf, found...");
+			return 1;
+		}
+	}
+	return 0;
+}
+
+static int send_wait_check()
+{
+	int ret;
+
+	if (opts.dst_addr) {
+		ret = fi_write(ep, tx_buf, strlen(welcome_text), mr_desc,
+				remote_fi_addr, 0, FT_MR_KEY, &tx_ctx);
+ 		if (ret) {
+ 			FT_PRINTERR("fi_write", ret);
+ 			return ret;
+		}
+	}
+
+	ret = fi_cntr_wait(test_cntr, n_trig, -1);
+	if (ret)
+		return ret;
+
+	ret = fi_cntr_wait(rxcntr, rx_exp, -1);
+	if (ret)
+		return ret;
+
+	return check_data();
+}
+
+static int cntr_trigger()
+{
+	int ret;
+	struct fi_op_cntr op_cntr;
+
+	op_cntr.cntr = test_cntr;
+	op_cntr.value = 5;
+	work.op_type = FI_OP_CNTR_SET;
+
+	work.op.cntr = &op_cntr;
+
+	ret = fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+	if (ret)
+		return ret;
+
+	work.op_type = FI_OP_CNTR_ADD;
+	return fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+}
+
+static int rma_trigger()
+{
+	int ret;
+	struct fi_msg_rma msg;
+	struct fi_rma_iov rma_iov;
+	struct iovec iov;
+	struct fi_op_rma rma;
+
+	format_simple_msg_rma(&msg, &iov, &rma_iov,
+			      tx_buf + strlen(welcome_text),
+			      strlen(write_text), &work.context);
+	rma.ep = trig_ep;
+	rma.msg = msg;
+	rma.flags = 0;
+
+	work.op.rma = &rma;
+	work.op_type = FI_OP_WRITE;
+	ret = fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+	if (ret)
+		return ret;
+
+	format_simple_msg_rma(&msg, &iov, &rma_iov,
+			      result_buf, strlen(write_text), &work.context);
+	work.op_type = FI_OP_READ;
+	work.triggering_cntr = test_cntr;
+	work.threshold = 1;
+	return fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+}
+
+static int atomic_trigger()
+{
+	int ret;
+	size_t count;
+	struct fi_op_atomic atomic;
+	struct fi_msg_atomic msg;
+	struct fi_ioc iov;
+	struct fi_rma_ioc rma_iov;
+
+	ret = check_base_atomic_op(ep, FI_BOR, FI_UINT8, &count);
+	if (ret)
+		return ret;
+
+	format_simple_msg_atomic(&msg, &iov, &rma_iov,
+				 tx_buf + strlen(welcome_text),
+				 strlen(welcome_text), &work.context, FI_UINT8, FI_BOR);
+	atomic.ep = trig_ep;
+	atomic.msg = msg;
+	atomic.flags = 0;
+	work.op_type = FI_OP_ATOMIC;
+
+	work.op.atomic = &atomic;
+	return fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+}
+
+static int fetch_atomic_trigger()
+{
+	int ret;
+	size_t count;
+	struct fi_op_fetch_atomic fetch_atomic;
+	struct fi_msg_atomic msg;
+	struct fi_msg_fetch fetch;
+	struct fi_ioc iov;
+	struct fi_ioc fetch_iov;
+	struct fi_rma_ioc rma_iov;
+
+	ret = check_fetch_atomic_op(ep, FI_BOR, FI_UINT8, &count);
+	if (ret)
+		return ret;
+
+	format_simple_msg_atomic(&msg, &iov, &rma_iov,
+				 tx_buf + strlen(welcome_text),
+				 strlen(welcome_text), &work.context, FI_UINT8, FI_BOR);
+	format_simple_msg_fetch(&fetch, &fetch_iov, result_buf, strlen(welcome_text));
+
+	fetch_atomic.ep = trig_ep;
+	fetch_atomic.msg = msg;
+	fetch_atomic.fetch = fetch;
+	fetch_atomic.flags = 0;
+	work.op_type = FI_OP_FETCH_ATOMIC;
+
+	work.op.fetch_atomic = &fetch_atomic;
+	return fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+}
+
+static int compare_atomic_trigger()
+{
+	int ret;
+	size_t count;
+	struct fi_op_compare_atomic compare_atomic;
+	struct fi_msg_atomic msg;
+	struct fi_msg_fetch fetch;
+	struct fi_msg_compare compare;
+	struct fi_ioc iov;
+	struct fi_ioc fetch_iov;
+	struct fi_ioc compare_iov;
+	struct fi_rma_ioc rma_iov;
+
+	ret = check_compare_atomic_op(ep, FI_CSWAP_LE, FI_UINT8, &count);
+	if (ret)
+		return ret;
+
+	format_simple_msg_atomic(&msg, &iov, &rma_iov,
+				 tx_buf + strlen(welcome_text),
+				 strlen(welcome_text), &work.context, FI_UINT8, FI_CSWAP_LE);
+	format_simple_msg_fetch(&fetch, &fetch_iov, result_buf, strlen(welcome_text));
+	format_simple_msg_compare(&compare, &compare_iov, compare_buf, strlen(welcome_text));
+
+	compare_atomic.ep = trig_ep;
+	compare_atomic.msg = msg;
+	compare_atomic.fetch = fetch;
+	compare_atomic.compare = compare;
+	compare_atomic.flags = 0;
+	work.op_type = FI_OP_COMPARE_ATOMIC;
+
+	work.op.compare_atomic = &compare_atomic;
+	return fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+}
+
+static int tsend_trigger()
+{
+	int ret;
+	struct fi_op_tagged tagged;
+	struct fi_msg_tagged msg;
+	struct iovec msg_iov;
+
+	format_simple_msg_tagged(&msg, &msg_iov, rx_buf,
+				 strlen(write_text), &work.context, 0xCAFE);
+	tagged.ep = trig_ep;
+	tagged.msg = msg;
+	tagged.flags = 0;
+	work.op.tagged = &tagged;
+
+	work.op_type = FI_OP_TRECV;
+	ret = fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+	if (ret)
+		return ret;
+
+	work.context = trig_ctx2;
+
+	format_simple_msg_tagged(&msg, &msg_iov, tx_buf + strlen(welcome_text),
+				 strlen(write_text), &work.context, 0xCAFE);
+	work.op_type = FI_OP_TSEND;
+	return fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+}
+
+static int send_trigger()
+{
+	int ret;
+	struct fi_op_msg op_msg;
+	struct fi_msg msg;
+	struct iovec msg_iov;
+
+	format_simple_msg(&msg, &msg_iov, rx_buf,
+			  strlen(write_text), &work.context);
+
+	op_msg.ep = trig_ep;
+	op_msg.msg = msg;
+	op_msg.flags = 0;
+	work.op.msg = &op_msg;
+
+	work.op_type = FI_OP_RECV;
+	ret = fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+	if (ret)
+		return ret;
+
+	work.context = trig_ctx2;
+
+	format_simple_msg(&msg, &msg_iov, tx_buf + strlen(welcome_text),
+			  strlen(write_text), &work.context);
+	work.op_type = FI_OP_SEND;
+	return fi_control(&domain->fid, FI_QUEUE_WORK, &work);
+}
+
+static int trigger()
+{
+	int ret;
+
+	//both sides start with both counters at 2, client will initiate triggering write
+	//which will trigger txcntr on client and rxcntr on server
+	//rx_exp = number of rx completions we should expect on that side
+	//n_trig = total number of triggers on work queue to expect completed
+	if (opts.dst_addr) {
+		work.triggering_cntr = txcntr;
+		rx_exp = 2;
+	} else {
+		work.triggering_cntr = rxcntr;
+		rx_exp = 3;
+	}
+	work.threshold = 3;
+
+	if (tested_op != FI_OP_CNTR_ADD && tested_op != FI_OP_CNTR_SET)
+		work.completion_cntr = test_cntr;
+
+	switch (tested_op) {
+	case FI_OP_RECV:
+	case FI_OP_SEND:
+		ret = send_trigger();
+		n_trig++;
+		break;
+	case FI_OP_TRECV:
+	case FI_OP_TSEND:
+		ret = tsend_trigger();
+		n_trig++;
+		break;
+	case FI_OP_READ:
+	case FI_OP_WRITE:
+		ret = rma_trigger();
+		n_trig++;
+		rx_exp += 2;
+		break;
+	case FI_OP_ATOMIC:
+		ret = atomic_trigger();
+		rx_exp++;
+		break;
+	case FI_OP_FETCH_ATOMIC:
+		ret = fetch_atomic_trigger();
+		rx_exp++;
+		break;
+	case FI_OP_COMPARE_ATOMIC:
+		ret = compare_atomic_trigger();
+		rx_exp++;
+		break;
+	default:
+		work.op_type = tested_op;
+		ret = cntr_trigger();
+		n_trig++;
+	}
+	n_trig++;
+
+	if (ret) {
+		if (ret == -FI_ENOSYS)
+			fprintf(stdout, "Operation not supported by provider\n");
+		else
+			FT_PRINTERR("fi_control", ret);
+		return ret;
+	}
+
+	ret = send_wait_check();
+
+	return ret;
+}
+
+static void init_buf_vals()
+{
+	switch (tested_op) {
+	case FI_OP_ATOMIC:
+	case FI_OP_FETCH_ATOMIC:
+	case FI_OP_COMPARE_ATOMIC:
+		memset(compare_buf, ~0, strlen(welcome_text) * 2);
+		sprintf(tx_buf, "%s", welcome_text);
+		memset(&tx_buf[strlen(welcome_text)], ~0, strlen(welcome_text));
+		if (opts.dst_addr)
+			sprintf(rx_buf, "%s", welcome_text);
+		break;
+	default:
+		sprintf(tx_buf, "%s%s", welcome_text, write_text);
+	}
+}
+
+static int run_test()
+{
+	int ret;
+
+	work.context = trig_ctx1;
+
+	printf("Testing triggered %s", fi_tostr(&tested_op, FI_TYPE_OP_TYPE));
+	if (tested_op != FI_OP_ATOMIC && tested_op != FI_OP_FETCH_ATOMIC &&
+	    tested_op != FI_OP_COMPARE_ATOMIC) {
+		tested_op++;
+		printf("/%s", fi_tostr(&tested_op, FI_TYPE_OP_TYPE));
+	}
+	printf(" with counters..."); 
+
+	init_buf_vals();
+
+	//eat up first receive to make sure the triggered op doesn't go there instead
+	ret = ft_tx(ep, remote_fi_addr, strlen(welcome_text), &tx_ctx);
+	if (ret)
+		return ret;
+	ret = ft_get_rx_comp(rx_seq);
+	if (ret)
+		return ret;
+
+	ret = trigger();
+	if (ret) {
+		if (ret != -FI_ENOSYS) {
+	       		printf("FAIL\n");
+       			if (ret != 1)
+       				FT_PRINTERR("cntr_trigger", ret);
+       		}
+	} else {
+		printf("PASS\n");
+	}
+
+	return ret;
+}
+
+static int alloc_mr_res()
+{
+	int ret;
+
+	result_buf = calloc(buf_size, sizeof(*result_buf));
+	compare_buf = calloc(buf_size, sizeof(*compare_buf));
+	if (!result_buf || !compare_buf) {
+		fprintf(stdout, "calloc\n");
+		return -FI_ENOMEM;
+	}
+
+	ret = fi_mr_reg(domain, buf, buf_size, FT_RMA_MR_ACCESS | FT_MSG_MR_ACCESS,
+			0, FT_MR_KEY, 0, &mr, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", ret);
+		return ret;
+	}
+
+	ret = fi_mr_reg(domain, result_buf, buf_size, FT_RMA_MR_ACCESS,
+			0, FT_MR_KEY + 1, 0, &mr_result, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", ret);
+		return ret;
+	}
+	ret = fi_mr_reg(domain, compare_buf, buf_size, FT_RMA_MR_ACCESS,
+			0, FT_MR_KEY + 2, 0, &mr_compare, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", ret);
+		return ret;
+	}
+	return 0;
+}
+
+static void free_mr_res()
+{
+	FT_CLOSE_FID(mr_result);
+	FT_CLOSE_FID(mr_compare);
+	free(result_buf);
+	free(compare_buf);
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options = FT_OPT_SIZE | FT_OPT_RX_CNTR | FT_OPT_TX_CNTR |
+		       FT_OPT_SKIP_REG_MR;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	tested_op = FI_OP_CNTR_SET;
+
+	while ((op = getopt(argc, argv, "aT:h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'a':
+			use_alias = 1;
+			break;
+		case 'T':
+			if (!strncasecmp("msg", optarg, 3))
+				tested_op = FI_OP_RECV;
+			else if (!strncasecmp("tagged", optarg, 6))
+				tested_op = FI_OP_TRECV;
+			else if (!strncasecmp("rma", optarg, 3))
+				tested_op = FI_OP_READ;
+			else if (!strncasecmp("atomic", optarg, 6))
+				tested_op = FI_OP_ATOMIC;
+			else if (!strncasecmp("f_atomic", optarg, 8))
+				tested_op = FI_OP_FETCH_ATOMIC;
+			else if (!strncasecmp("c_atomic", optarg, 8))
+				tested_op = FI_OP_COMPARE_ATOMIC;
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A simple RDM client-sever triggered RMA example with alias ep.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG | FI_RMA | FI_RMA_EVENT | FI_TRIGGER;
+
+	if (tested_op == FI_OP_TSEND)
+		hints->caps |= FI_TAGGED;
+	else if (tested_op == FI_OP_ATOMIC ||
+		 tested_op == FI_OP_FETCH_ATOMIC ||
+		 tested_op == FI_OP_COMPARE_ATOMIC)
+		hints->caps |= FI_ATOMIC;
+
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = (FI_MR_LOCAL | FI_MR_VIRT_ADDR |
+				       FI_MR_ALLOCATED);
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	if (use_alias) {
+		ret = ft_init_alias_ep(FI_TRANSMIT | FI_TRIGGER);
+		if (ret)
+			return ret;
+		trig_ep = alias_ep;
+	} else {
+		trig_ep = ep;
+	}
+
+	ret = ft_cntr_open(&test_cntr);
+	if (ret) {
+		FT_PRINTERR("fi_cntr_open", ret);
+		return ret;
+	}
+
+	ret = alloc_mr_res();
+	if (ret)
+		return ret;
+
+	ret = run_test();
+	if (ret)
+		return ret;
+
+	free_mr_res();
+
+	ret = fi_close(&test_cntr->fid);
+	if (ret)
+		FT_PRINTERR("fi_cntr_close", ret);
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_multi_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_multi_domain.c
new file mode 100644
index 000000000..f804bae7c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_multi_domain.c
@@ -0,0 +1,441 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ * Copyright (c) 2017, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include <unistd.h>
+
+#include <rdma/fabric.h>
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_cm.h>
+
+#include "shared.h"
+
+struct test_domain {
+	uint8_t *buf;
+	struct fid_domain *dom;
+	struct fid_ep *ep;
+	struct fid_cntr *rx_cntr;
+	uint64_t rma_op_cnt;
+	struct fid_cntr *tx_cntr;
+	struct fid_av *av;
+	struct fid_mr *mr;
+	struct fid_cq *tx_cq;
+	struct fi_context *rma_ctx;
+};
+
+struct test_domain *domain_res_array;
+uint8_t *mr_buf_array;
+fi_addr_t *peer_addrs;
+int domain_cnt;
+int verbose;
+
+static int alloc_domain_res()
+{
+	domain_res_array = calloc(domain_cnt, sizeof(*domain_res_array));
+	if (!domain_res_array)
+		return -FI_ENOMEM;
+
+	mr_buf_array = calloc(domain_cnt, opts.transfer_size);
+	if (!mr_buf_array)
+		return -FI_ENOMEM;
+
+	peer_addrs = calloc(domain_cnt, sizeof(*peer_addrs));
+	if (!peer_addrs)
+		return -FI_ENOMEM;
+
+	return 0;
+}
+
+static int open_domain_res(struct test_domain *domain)
+{
+	int ret;
+
+	av_attr.type = FI_AV_MAP;
+	av_attr.count = domain_cnt;
+	av_attr.name = NULL;
+
+	ret = fi_cntr_open(domain->dom,
+			&cntr_attr, &domain->rx_cntr, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_cntr_open", ret);
+		return ret;
+	}
+
+	ret = fi_cntr_open(domain->dom,
+			&cntr_attr, &domain->tx_cntr, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_cntr_open", ret);
+		return ret;
+	}
+
+	cq_attr.size = domain_cnt;
+	ret = fi_cq_open(domain->dom,
+			&cq_attr, &domain->tx_cq, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_cq_open", ret);
+		return ret;
+	}
+
+	ret = fi_av_open(domain->dom,
+			&av_attr, &domain->av, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_av_open", ret);
+		return ret;
+	}
+
+	domain->rma_ctx = calloc(domain_cnt, sizeof(*domain->rma_ctx));
+	if (!domain->rma_ctx)
+		return -FI_ENOMEM;
+
+	return 0;
+}
+
+static int init_ep_mr_res(struct test_domain *domain, struct fi_info *info)
+{
+	int ret;
+
+	domain->rma_op_cnt = 0;
+
+	ret = fi_endpoint(domain->dom, info, &domain->ep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		return ret;
+	}
+
+	ret = fi_ep_bind(domain->ep,
+			&domain->av->fid, 0);
+	if (ret) {
+		FT_PRINTERR("fi_ep_bind", ret);
+		return ret;
+	}
+
+	ret = fi_ep_bind(domain->ep,
+			&domain->tx_cntr->fid, FI_WRITE);
+	if (ret) {
+		FT_PRINTERR("fi_ep_bind", ret);
+		return ret;
+	}
+
+	ret = fi_ep_bind(domain->ep,
+			&domain->tx_cq->fid, FI_TRANSMIT);
+	if (ret) {
+		FT_PRINTERR("fi_ep_bind", ret);
+		return ret;
+	}
+
+	ret = fi_enable(domain->ep);
+	if (ret) {
+		FT_PRINTERR("fi_enable", ret);
+		return ret;
+	}
+
+	ret = fi_mr_reg(domain->dom, domain->buf,
+			opts.transfer_size, FI_REMOTE_WRITE,
+			0, FT_MR_KEY, 0, &domain->mr, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", ret);
+		return ret;
+	}
+
+	if (verbose) {
+		printf("fi_mr_reg(fi_domain = %p,buffer = %p,size = %d,",
+				domain->dom, domain->buf, opts.transfer_size);
+		printf("memory_region = %p,mr_key %ld)\n",
+				domain->mr, (unsigned long)fi_mr_key(domain->mr));
+	}
+
+	ret = fi_mr_bind(domain->mr,
+			&domain->rx_cntr->fid,
+			FI_REMOTE_WRITE);
+	if (ret) {
+		FT_PRINTERR("fi_mr_bind", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int init_peer_addresses()
+{
+	int dom_idx, ret;
+	int ep_idx;
+
+	/*
+	Initializes the Address Vectors for each domain
+	with the addresses of the remote hosts' endpoints.
+	The fi_addr_t array peer_addrs gets rewritten
+	in this loop with the same set of addresses for each domain
+	init, but the peer addresses to the remote domains
+	are the same so this is not an issue.
+	The address vectors for each domain must be init even if
+	the peer addresses returned is the same after the first loop.
+	*/
+	for (dom_idx = 0; dom_idx < domain_cnt; dom_idx++) {
+		for (ep_idx = 0; ep_idx < domain_cnt; ep_idx++) {
+			ret = ft_init_av_addr(domain_res_array[dom_idx].av,
+					domain_res_array[ep_idx].ep, &peer_addrs[ep_idx]);
+			if (ret)
+				return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int init_domain_res()
+{
+	int dom_idx, ret;
+
+	for (dom_idx = 0; dom_idx < domain_cnt; dom_idx++) {
+		struct fi_info *info;
+		hints->src_addr = NULL;
+		ret = fi_getinfo(FT_FIVERSION, NULL, NULL, 0, hints, &info);
+		if (ret) {
+			FT_PRINTERR("fi_getinfo", ret);
+			return ret;
+		}
+
+		info->domain_attr->mr_mode = FI_MR_SCALABLE;
+		ret = fi_domain(fabric, info,
+				&domain_res_array[dom_idx].dom,
+				NULL);
+		if (ret) {
+			FT_PRINTERR("fi_domain", ret);
+			return ret;
+		}
+
+		domain_res_array[dom_idx].buf = &mr_buf_array[dom_idx];
+
+		ret = open_domain_res(&domain_res_array[dom_idx]);
+		if (ret)
+			return ret;
+
+		ret = init_ep_mr_res(&domain_res_array[dom_idx], info);
+		if (ret)
+			return ret;
+
+		fi_freeinfo(info);
+	}
+
+	return 0;
+}
+
+static void free_domain_res()
+{
+	int dom_idx;
+
+	for (dom_idx = 0; dom_idx < domain_cnt; dom_idx++) {
+		FT_CLOSE_FID(domain_res_array[dom_idx].ep);
+		FT_CLOSE_FID(domain_res_array[dom_idx].av);
+		FT_CLOSE_FID(domain_res_array[dom_idx].mr);
+		FT_CLOSE_FID(domain_res_array[dom_idx].tx_cntr);
+		FT_CLOSE_FID(domain_res_array[dom_idx].rx_cntr);
+		FT_CLOSE_FID(domain_res_array[dom_idx].tx_cq);
+		FT_CLOSE_FID(domain_res_array[dom_idx].dom);
+		free(domain_res_array[dom_idx].rma_ctx);
+	}
+	free(peer_addrs);
+	free(mr_buf_array);
+	free(domain_res_array);
+}
+
+static int write_data(void *buffer, size_t size, int dom_idx,
+		int remote_dom_idx, struct fi_context *rma_ctx)
+{
+	int ret = -FI_EAGAIN;
+
+	while (ret == -FI_EAGAIN) {
+		ret = fi_write(domain_res_array[dom_idx].ep, buffer, size,
+				fi_mr_desc(domain_res_array[dom_idx].mr), peer_addrs[remote_dom_idx],
+				0, fi_mr_key(domain_res_array[remote_dom_idx].mr), rma_ctx);
+	}
+
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int wait_write_cq(struct fid_cq *cq, size_t rma_op_count)
+{
+	struct fi_cq_tagged_entry entry;
+	int ret;
+	int op_counter = 0;
+
+	do {
+		ret = fi_cq_read(cq, &entry, 1);
+		if (ret > 0)
+			op_counter++;
+	} while ((ret == -FI_EAGAIN) && (op_counter < rma_op_count));
+
+	if (ret < 0) {
+		if (ret == -FI_EAVAIL) {
+			ret = ft_cq_readerr(cq);
+		} else {
+			FT_PRINTERR("fi_cq_read", ret);
+		}
+	}
+
+	return ret;
+}
+
+static int multi_domain_test()
+{
+	int ret, remote_dom_idx, dom_idx;
+
+	ft_sync();
+
+	for (dom_idx = 0; dom_idx < domain_cnt; dom_idx++) {
+		for (remote_dom_idx = 0; remote_dom_idx < domain_cnt; remote_dom_idx++) {
+			if (verbose)
+				printf("write to host's domain idx %d, memory region\n", remote_dom_idx);
+
+			ret = write_data(tx_buf, opts.transfer_size, dom_idx,
+				remote_dom_idx, &domain_res_array[dom_idx].rma_ctx[remote_dom_idx]);
+			if (ret)
+				return ret;
+
+			domain_res_array[dom_idx].rma_op_cnt++;
+		}
+	}
+
+	for (dom_idx = 0; dom_idx < domain_cnt; dom_idx++) {
+		ret = fi_cntr_wait(domain_res_array[dom_idx].tx_cntr,
+				domain_res_array[dom_idx].rma_op_cnt, 30 * 1000);
+		if (ret < 0)
+			return ret;
+
+		ret = wait_write_cq(domain_res_array[dom_idx].tx_cq,
+				domain_res_array[dom_idx].rma_op_cnt);
+		if (ret < 1)
+			return ret;
+
+		if (verbose)
+			printf("writes from domain idx %d completed\n", dom_idx);
+	}
+
+	for (dom_idx = 0; dom_idx < domain_cnt; dom_idx++) {
+		if (verbose)
+			printf("check for writes to domain idx %d\n", dom_idx);
+
+		ret = fi_cntr_wait(domain_res_array[dom_idx].rx_cntr,
+				domain_res_array[dom_idx].rma_op_cnt, 30 * 1000);
+		if (ret < 0)
+			return ret;
+
+		if (verbose)
+			printf("got all writes to domain idx %d\n", dom_idx);
+	}
+	printf("GOOD, multi domain test complete\n");
+	return 0;
+}
+
+static int run_test(void)
+{
+	int ret;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	ret = alloc_domain_res();
+	if (ret)
+		return ret;
+	ret = init_domain_res();
+	if (ret)
+		return ret;
+
+	ret = init_peer_addresses();
+	if (ret)
+		return ret;
+
+	ret = multi_domain_test();
+
+	return 0;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	domain_cnt = 2;
+	opts = INIT_OPTS;
+	opts.transfer_size = 4096;
+	verbose = 0;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "c:Vh" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'c':
+			domain_cnt = strtoull(optarg, NULL, 10);
+			break;
+		case 'V':
+			verbose = 1;
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "Ping-pong multi-domain test");
+			FT_PRINT_OPTS_USAGE("-c <int>", "number of domains to create and test");
+			FT_PRINT_OPTS_USAGE("-V", "Enable verbose printing");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_RMA | FI_RMA_EVENT | FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run_test();
+
+	if (domain_res_array)
+		free_domain_res();
+	ft_free_res();
+
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_multi_recv.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_multi_recv.c
new file mode 100644
index 000000000..0869aac6f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_multi_recv.c
@@ -0,0 +1,366 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_cm.h>
+
+#include <shared.h>
+
+// MULTI_BUF_SIZE_FACTOR defines how large the multi recv buffer will be.
+// The minimum value of the factor is 2 which will set the multi recv buffer
+// size to be twice the size of the send buffer. In order to use FI_MULTI_RECV
+// feature efficiently, we need to have a large recv buffer so that we don't
+// to repost the buffer often to get the remaining data when the buffer is full
+#define MULTI_BUF_SIZE_FACTOR 4
+#define DEFAULT_MULTI_BUF_SIZE (1024 * 1024)
+
+static struct fid_mr *mr_multi_recv;
+struct fi_context ctx_multi_recv[2];
+static int use_recvmsg;
+
+static int repost_recv(int iteration) {
+	struct fi_msg msg;
+	struct iovec msg_iov;
+	int ret;
+
+	if (use_recvmsg) {
+		msg_iov.iov_base = rx_buf + (rx_size / 2) * iteration;
+		msg_iov.iov_len = rx_size / 2;
+		msg.msg_iov = &msg_iov;
+		msg.desc = fi_mr_desc(mr_multi_recv);
+		msg.iov_count = 1;
+		msg.addr = 0;
+		msg.data = NO_CQ_DATA;
+		msg.context = &ctx_multi_recv[iteration];
+		ret = fi_recvmsg(ep, &msg, FI_MULTI_RECV);
+		if (ret) {
+			FT_PRINTERR("fi_recvmsg", ret);
+			return ret;
+		}
+	} else {
+		ret = fi_recv(ep, rx_buf + (rx_size / 2) * iteration,
+				rx_size / 2, fi_mr_desc(mr_multi_recv),
+				0, &ctx_multi_recv[iteration]);
+		if (ret) {
+			FT_PRINTERR("fi_recv", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+
+int wait_for_recv_completion(int num_completions)
+{
+	int i, ret;
+	struct fi_cq_data_entry comp;
+
+	while (num_completions > 0) {
+		ret = fi_cq_read(rxcq, &comp, 1);
+		if (ret == -FI_EAGAIN)
+			continue;
+
+		if (ret < 0) {
+			FT_PRINTERR("fi_cq_read", ret);
+			return ret;
+		}
+
+		if (comp.len)
+			num_completions--;
+
+		if (comp.flags & FI_MULTI_RECV) {
+			i = (comp.op_context == &ctx_multi_recv[0]) ? 0 : 1;
+
+			ret = repost_recv(i);
+			if (ret)
+				return ret;
+		}
+	}
+	return 0;
+}
+
+static int sync_test(void)
+{
+	int ret;
+
+	ret = opts.dst_addr ? ft_tx(ep, remote_fi_addr, 1, &tx_ctx) : wait_for_recv_completion(1);
+	if (ret)
+		return ret;
+
+	ret = opts.dst_addr ? wait_for_recv_completion(1) : ft_tx(ep, remote_fi_addr, 1, &tx_ctx);
+	return ret;
+}
+
+/*
+ * Post buffer as two halves, so that we can repost one half
+ * when the other half is full.
+ */
+static int post_multi_recv_buffer()
+{
+	int ret, i;
+
+	for (i = 0; i < 2; i++) {
+		ret = repost_recv(i);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+static int run_test(void)
+{
+	int ret, i;
+
+	ret = sync_test();
+	if (ret) {
+		fprintf(stderr, "sync_test failed!\n");
+		goto out;
+	}
+
+	ft_start();
+	if (opts.dst_addr) {
+		for (i = 0; i < opts.iterations; i++) {
+			ret = ft_tx(ep, remote_fi_addr, opts.transfer_size, &tx_ctx);
+			if (ret)
+				goto out;
+		}
+	} else {
+		ret = wait_for_recv_completion(opts.iterations);
+		if (ret)
+			goto out;
+	}
+	ft_stop();
+
+	if (opts.machr)
+		show_perf_mr(opts.transfer_size, opts.iterations,
+			&start, &end, 1, opts.argc, opts.argv);
+	else
+		show_perf(test_name, opts.transfer_size, opts.iterations,
+			&start, &end, 1);
+
+out:
+	return ret;
+}
+
+static void free_res(void)
+{
+	FT_CLOSE_FID(mr_multi_recv);
+	if (tx_buf) {
+		free(tx_buf);
+		tx_buf = NULL;
+	}
+	if (rx_buf) {
+		free(rx_buf);
+		rx_buf = NULL;
+	}
+}
+
+static int alloc_ep_res(struct fi_info *fi)
+{
+	int ret;
+
+	tx_size = MAX(FT_MAX_CTRL_MSG, opts.transfer_size);
+	if (tx_size > fi->ep_attr->max_msg_size) {
+		fprintf(stderr, "transfer size is larger than the maximum size "
+				"of the data transfer supported by the provider\n");
+		return -1;
+	}
+
+	tx_buf = malloc(tx_size);
+	if (!tx_buf) {
+		fprintf(stderr, "Cannot allocate tx_buf\n");
+		return -1;
+	}
+
+	ret = fi_mr_reg(domain, tx_buf, tx_size, FI_SEND,
+			0, FT_MR_KEY, 0, &mr, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", ret);
+		return ret;
+	}
+
+	// set the multi buffer size to be allocated
+	rx_size = MAX(tx_size, DEFAULT_MULTI_BUF_SIZE) * MULTI_BUF_SIZE_FACTOR;
+	rx_buf = malloc(rx_size);
+	if (!rx_buf) {
+		fprintf(stderr, "Cannot allocate rx_buf\n");
+		return -1;
+	}
+
+	ret = fi_mr_reg(domain, rx_buf, rx_size, FI_RECV, 0, FT_MR_KEY + 1, 0,
+			&mr_multi_recv, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_mr_reg", ret);
+		return ret;
+	}
+
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int init_fabric(void)
+{
+	int ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	// set FI_MULTI_RECV flag for all recv operations
+	fi->rx_attr->op_flags = FI_MULTI_RECV;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep_recv();
+	if (ret)
+		return ret;
+
+	ret = fi_setopt(&ep->fid, FI_OPT_ENDPOINT, FI_OPT_MIN_MULTI_RECV,
+			&tx_size, sizeof(tx_size));
+	if (ret)
+		return ret;
+
+	ret = post_multi_recv_buffer();
+	return ret;
+}
+
+static int init_av(void)
+{
+	size_t addrlen;
+	int ret;
+
+	if (opts.dst_addr) {
+		ret = ft_av_insert(av, fi->dest_addr, 1, &remote_fi_addr, 0, NULL);
+		if (ret)
+			return ret;
+
+		addrlen = 64;
+		ret = fi_getname(&ep->fid, tx_buf, &addrlen);
+		if (ret) {
+			FT_PRINTERR("fi_getname", ret);
+			return ret;
+		}
+
+		ret = ft_tx(ep, remote_fi_addr, addrlen, &tx_ctx);
+		if (ret)
+			return ret;
+	} else {
+		ret = wait_for_recv_completion(1);
+		if (ret)
+			return ret;
+
+		ret = ft_av_insert(av, rx_buf, 1, &remote_fi_addr, 0, NULL);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+static int run(void)
+{
+	int ret = 0;
+
+	ret = init_fabric();
+	if (ret)
+		goto out;
+
+	ret = init_av();
+	if (ret)
+		goto out;
+
+	ret = run_test();
+
+	rx_seq++;
+	ft_finalize();
+out:
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE | FT_OPT_SKIP_MSG_ALLOC;
+	use_recvmsg = 0;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "Mh" CS_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case 'M':
+			use_recvmsg = 1;
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "Streaming RDM client-server using multi recv buffer.");
+			FT_PRINT_OPTS_USAGE("-M", "enable testing with fi_recvmsg");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG | FI_MULTI_RECV;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	cq_attr.format = FI_CQ_FORMAT_DATA;
+
+	ret = run();
+
+	free_res();
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_rma_simple.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_rma_simple.c
new file mode 100644
index 000000000..efee1ad3a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_rma_simple.c
@@ -0,0 +1,127 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+
+#include <shared.h>
+
+struct fi_rma_iov local;
+
+struct fi_context fi_ctx_write;
+struct fi_context fi_ctx_read;
+
+static int run_test(void)
+{
+	int ret = 0;
+	const char *message = "Hello from Client!";
+	size_t message_len = strlen(message) + 1;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	ret = ft_exchange_keys(&remote);
+	if (ret)
+		return ret;
+
+	if (opts.dst_addr) {
+		fprintf(stdout, "RMA write to server\n");
+		if (snprintf(tx_buf, tx_size, "%s", message) >= tx_size) {
+                        fprintf(stderr, "Transmit buffer too small.\n");
+                        return -FI_ETOOSMALL;
+                }
+		ret = fi_write(ep, tx_buf, message_len, mr_desc,
+			       remote_fi_addr, remote.addr, remote.key,
+			       &fi_ctx_write);
+		if (ret)
+			return ret;
+
+		ret = ft_get_tx_comp(++tx_seq);
+		if (ret)
+			return ret;
+
+		fprintf(stdout, "Received a completion event for RMA write\n");
+	} else {
+		ret = ft_get_rx_comp(rx_seq);
+		if (ret)
+			return ret;
+
+		ret = check_recv_msg(message);
+		if (ret)
+			return ret;
+
+		fprintf(stdout, "Received data from Client: %s\n", (char *) rx_buf);
+	}
+
+	/* TODO: need support for finalize operation to sync test */
+	return 0;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options = FT_OPT_SIZE | FT_OPT_RX_CNTR | FT_OPT_TX_CNTR;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A simple RDM client-server RMA example.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG | FI_RMA | FI_RMA_EVENT;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run_test();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_rma_trigger.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_rma_trigger.c
new file mode 100644
index 000000000..24411a2f0
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_rma_trigger.c
@@ -0,0 +1,160 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_trigger.h>
+
+#include <shared.h>
+
+struct fi_triggered_context triggered_ctx;
+
+static char *welcome_text1 = "Hello1 from Client!";
+static char *welcome_text2 = "Hello2 from Client!";
+
+static int rma_write_trigger(void *src, size_t size,
+			     struct fid_cntr *cntr, size_t threshold)
+{
+	int ret;
+	triggered_ctx.event_type = FI_TRIGGER_THRESHOLD;
+	triggered_ctx.trigger.threshold.cntr = cntr;
+	triggered_ctx.trigger.threshold.threshold = threshold;
+	ret = fi_write(alias_ep, src, size, mr_desc,
+		       remote_fi_addr, remote.addr, remote.key,
+		       &triggered_ctx);
+ 	if (ret){
+ 		FT_PRINTERR("fi_write", ret);
+ 		return ret;
+	}
+	return 0;
+}
+
+static int run_test(void)
+{
+	int ret = 0;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	ret = ft_init_alias_ep(FI_TRANSMIT | FI_TRIGGER);
+	if (ret)
+		return ret;
+
+	ret = ft_exchange_keys(&remote);
+	if (ret)
+		return ret;
+
+	if (opts.dst_addr) {
+		sprintf(tx_buf, "%s%s", welcome_text1, welcome_text2);
+
+		fprintf(stdout, "Triggered RMA write to server\n");
+		ret = rma_write_trigger((char *) tx_buf + strlen(welcome_text1),
+					strlen(welcome_text2), txcntr, 3);
+		if (ret)
+			goto out;
+
+		fprintf(stdout, "RMA write to server\n");
+		ret = fi_write(ep, tx_buf, strlen(welcome_text1), mr_desc,
+			       remote_fi_addr, remote.addr, remote.key,
+			       &tx_ctx);
+ 		if (ret){
+ 			FT_PRINTERR("fi_write", ret);
+ 			goto out;
+		}
+		/* The value of the counter is 4 including a transfer during
+		 * init_av and ft_exchange_keys() */
+		ret = fi_cntr_wait(txcntr, 4, -1);
+		if (ret < 0) {
+			FT_PRINTERR("fi_cntr_wait", ret);
+			goto out;
+		}
+
+		fprintf(stdout, "Received completion events for RMA write operations\n");
+	} else {
+		/* The value of the counter is 4 including a transfer during
+		 * init_av and ft_exchange_keys() */
+		ret = fi_cntr_wait(rxcntr, 4, -1);
+		if (ret < 0) {
+			FT_PRINTERR("fi_cntr_wait", ret);
+			goto out;
+		}
+
+		ret = check_recv_msg(welcome_text2);
+		if (ret)
+			return ret;
+		fprintf(stdout, "Received data from Client: %s\n", (char *) rx_buf);
+	}
+
+out:
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options = FT_OPT_SIZE | FT_OPT_RX_CNTR | FT_OPT_TX_CNTR;
+	opts.transfer_size = strlen(welcome_text1) + strlen(welcome_text2);
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A simple RDM client-server triggered RMA example with alias ep.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG | FI_RMA | FI_RMA_EVENT | FI_TRIGGER;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run_test();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_shared_av.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_shared_av.c
new file mode 100644
index 000000000..861f92a50
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_shared_av.c
@@ -0,0 +1,208 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <unistd.h>
+#include <string.h>
+
+#include <rdma/fi_errno.h>
+
+#include "shared.h"
+
+static int init_fabric(void)
+{
+	int ret;
+	int ret2;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	if (opts.dst_addr && !ft_parent_proc) {
+		/* child waits until parent is done creating AV */
+		ret2 = ft_sync_pair(FI_SUCCESS);
+		if (ret2)
+			return ret2;
+
+		/* child needs to open AV in read only mode */
+		av_attr.flags = FI_READ;
+	}
+
+	ret = ft_alloc_active_res(fi);
+	if (opts.dst_addr && ft_parent_proc) {
+		/* parent lets the child know its status */
+		ret2 = ft_sync_pair(ret);
+		if (ret2)
+			return ret2;
+	}
+
+	/* handle the failed alloc_active_res call */
+	if (ret)
+		return ret;
+
+	return ft_enable_ep_recv();
+}
+
+static int send_recv()
+{
+	int ret;
+	const char *message = "Hello from Child Client!";
+	size_t message_len = strlen(message) + 1;
+
+	if (opts.dst_addr) {
+		fprintf(stdout, "Sending message...\n");
+		if (snprintf(tx_buf, tx_size, "%s", message) >= tx_size) {
+			fprintf(stderr, "Transmit buffer too small.\n");
+			return -FI_ETOOSMALL;
+		}
+
+		ret = ft_tx(ep, remote_fi_addr, message_len, &tx_ctx);
+		if (ret)
+			return ret;
+
+		fprintf(stdout, "Send completion received\n");
+	} else {
+		fprintf(stdout, "Waiting for message from client...\n");
+
+		ret = ft_get_rx_comp(rx_seq);
+		if (ret)
+			return ret;
+
+		ret = check_recv_msg(message);
+		if (ret)
+			return ret;
+
+		fprintf(stdout, "Received data from client: %s\n", (char *) rx_buf);
+	}
+
+	return 0;
+}
+
+static int run(void)
+{
+	int ret;
+	int ret2;
+
+	ret = init_fabric();
+	if (ret)
+		return ret;
+
+	if (opts.dst_addr) {
+		if (ft_parent_proc) {
+			/* parent inits AV and lets child proceed,
+			 * and itself returns without sending a message */
+			ret = ft_init_av();
+			ret2 = ft_sync_pair(ret);
+			if (ret2)
+				return ret2;
+
+			/* parent doesn't run the send_recv loop,
+			 * it waits for the child until it is done
+			 * with send_recv */
+			return ret;
+		} else {
+			ret2 = ft_sync_pair(FI_SUCCESS);
+			if (ret2)
+				return ret2;
+
+			remote_fi_addr = ((fi_addr_t *)av_attr.map_addr)[0];
+		}
+	} else {
+		ret = ft_init_av();
+		if (ret)
+			return ret;
+	}
+
+	return send_recv();
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			ft_parsecsopts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "A shared AV client-server example.");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	if (opts.dst_addr) {
+		if (!opts.av_name)
+			opts.av_name = "client_av";
+
+		ret = ft_fork_and_pair();
+		if (ret)
+			return ret;
+	} else {
+		if (!opts.av_name)
+			opts.av_name = "server_av";
+	}
+
+	hints->ep_attr->type	= FI_EP_RDM;
+	hints->caps		= FI_MSG | FI_SHARED_AV;
+	hints->mode		= FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	if (opts.dst_addr) {
+		if (ft_wait_child()) {
+			FT_PRINTERR("ft_wait_child", errno);
+		}
+	}
+
+	ft_free_res();
+
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_tagged_peek.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_tagged_peek.c
new file mode 100644
index 000000000..4f4afbcfe
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/rdm_tagged_peek.c
@@ -0,0 +1,267 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include <unistd.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_tagged.h>
+
+#include <shared.h>
+
+static struct fi_context fi_context;
+
+static int wait_for_send_comp(int count)
+{
+	int ret, completions = 0;
+	struct fi_cq_tagged_entry comp;
+
+	do {
+		ret = fi_cq_sread(txcq, &comp, 1, NULL, -1);
+		if (ret != 1) {
+			FT_PRINTERR("fi_cq_sread", ret);
+			return ret;
+		}
+		completions++;
+	} while (completions < count);
+
+	return 0;
+}
+
+static int tag_queue_op(uint64_t tag, int recv, uint64_t flags)
+{
+	int ret;
+	struct fi_cq_tagged_entry comp;
+	struct fi_msg_tagged msg = {0};
+	struct fi_cq_err_entry cq_err;
+	struct iovec iov;
+	void *desc;
+
+	if (recv) {
+		iov.iov_base = buf;
+		iov.iov_len = rx_size;
+		msg.msg_iov = &iov;
+		desc = mr_desc;
+		msg.desc = &desc;
+		msg.iov_count = 1;
+		msg.addr = remote_fi_addr;
+	}
+	msg.tag = tag;
+	msg.context = &fi_context;
+
+	ret = fi_trecvmsg(ep, &msg, flags);
+	if (ret) {
+		FT_PRINTERR("fi_trecvmsg", ret);
+		return ret;
+	}
+
+	ret = fi_cq_sread(rxcq, &comp, 1, NULL, -1);
+	if (ret != 1) {
+		if (ret == -FI_EAVAIL) {
+			ret = fi_cq_readerr(rxcq, &cq_err, 0);
+			if (ret < 0)
+				FT_PRINTERR("fi_cq_readerr", ret);
+			else
+				ret = -cq_err.err;
+		} else {
+			FT_PRINTERR("fi_cq_sread", ret);
+		}
+	}
+	return ret;
+}
+
+static int run(void)
+{
+	int i, ret;
+
+	ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	if (!(tx_ctx_arr = calloc(5, sizeof *tx_ctx_arr)))
+		return -FI_ENOMEM;
+
+	if (opts.dst_addr) {
+		printf("Searching for a bad msg\n");
+		ret = tag_queue_op(0xbad, 0, FI_PEEK);
+		if (ret != -FI_ENOMSG) {
+			FT_PRINTERR("FI_PEEK", ret);
+			return ret;
+		}
+
+		printf("Searching for a bad msg with claim\n");
+		ret = tag_queue_op(0xbad, 0, FI_PEEK | FI_CLAIM);
+		if (ret != -FI_ENOMSG) {
+			FT_PRINTERR("FI_PEEK", ret);
+			return ret;
+		}
+
+		printf("Retrieving fifth message\n");
+		ret = tag_queue_op(0x900d+4, 1, 0);
+		if (ret != 1) {
+			FT_PRINTERR("Receive after peek", ret);
+			return ret;
+		}
+		printf("Messages 1-4 should be in unexpected queue\n");
+
+		printf("Searching for first msg\n");
+		ret = tag_queue_op(0x900d, 0, FI_PEEK);
+		if (ret != 1) {
+			FT_PRINTERR("FI_PEEK", ret);
+			return ret;
+		}
+
+		printf("Receiving first msg\n");
+		ret = tag_queue_op(0x900d, 1, 0);
+		if (ret != 1) {
+			FT_PRINTERR("Receive after peek", ret);
+			return ret;
+		}
+
+		printf("Searching for second msg to claim\n");
+		ret = tag_queue_op(0x900d+1, 0, FI_PEEK | FI_CLAIM);
+		if (ret != 1) {
+			FT_PRINTERR("FI_PEEK | FI_CLAIM", ret);
+			return ret;
+		}
+
+		printf("Receiving second msg\n");
+		ret = tag_queue_op(0x900d+1, 1, FI_CLAIM);
+		if (ret != 1) {
+			FT_PRINTERR("FI_CLAIM", ret);
+			return ret;
+		}
+
+		printf("Searching for third msg to peek and discard\n");
+		ret = tag_queue_op(0x900d+2, 0, FI_PEEK | FI_DISCARD);
+		if (ret != 1) {
+			FT_PRINTERR("FI_PEEK | FI_DISCARD", ret);
+			return ret;
+		}
+
+		printf("Checking to see if third msg was discarded\n");
+		ret = tag_queue_op(0x900d+2, 0, FI_PEEK);
+		if (ret != -FI_ENOMSG) {
+			FT_PRINTERR("FI_PEEK", ret);
+			return ret;
+		}
+
+		printf("Searching for fourth msg to claim and discard\n");
+		ret = tag_queue_op(0x900d+3, 0, FI_PEEK | FI_CLAIM);
+		if (ret != 1) {
+			FT_PRINTERR("FI_DISCARD", ret);
+			return ret;
+		}
+
+		printf("Discarding fourth msg\n");
+		ret = tag_queue_op(0x900d+3, 0, FI_CLAIM | FI_DISCARD);
+		if (ret != 1) {
+			FT_PRINTERR("FI_CLAIM", ret);
+			return ret;
+		}
+		/* sync with sender before ft_finalize, since we sent
+		 * and received messages outside of the sequence numbers
+		 * maintained by common code */
+		ret = fi_tsend(ep, tx_buf, 1, mr_desc,
+				remote_fi_addr, 0xabc,
+				&tx_ctx_arr[0]);
+		if (ret)
+			return ret;
+		ret = wait_for_send_comp(1);
+		if (ret)
+			return ret;
+	} else {
+		printf("Sending five tagged messages\n");
+		for(i = 0; i < 5; i++) {
+			ret = fi_tsend(ep, tx_buf, tx_size, mr_desc,
+				       remote_fi_addr, 0x900d+i,
+				       &tx_ctx_arr[i]);
+			if (ret)
+				return ret;
+		}
+		printf("Waiting for messages to complete\n");
+		ret = wait_for_send_comp(5);
+		if (ret)
+			return ret;
+		ret = tag_queue_op(0xabc, 1, 0);
+		if (ret != 1) {
+			FT_PRINTERR("Receive sync", ret);
+			return ret;
+		}
+	}
+
+	ft_finalize();
+	return 0;
+}
+
+int main(int argc, char **argv)
+{
+	int ret, op;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+	opts.comp_method = FT_COMP_SREAD;
+
+	hints = fi_allocinfo();
+	if (!hints) {
+		FT_PRINTERR("fi_allocinfo", -FI_ENOMEM);
+		return EXIT_FAILURE;
+	}
+
+	while ((op = getopt(argc, argv, "h" CS_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parsecsopts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_csusage(argv[0], "An RDM client-server example that uses tagged search.\n");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->domain_attr->resource_mgmt = FI_RM_ENABLED;
+	hints->tx_attr->msg_order = FI_ORDER_SAS;
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_TAGGED;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/recv_cancel.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/recv_cancel.c
new file mode 100644
index 000000000..b44de188e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/recv_cancel.c
@@ -0,0 +1,224 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <unistd.h>
+#include "shared.h"
+
+#define CANCEL_TAG 0xC
+#define STANDARD_TAG 0xA
+
+static int recv_cancel_client(void)
+{
+	int ret;
+
+	/* sync with server */
+	ret = ft_rx(ep, 1);
+	if (ret)
+		return ret;
+
+	ft_tag = CANCEL_TAG;
+	ret = ft_post_tx(ep, remote_fi_addr, opts.transfer_size, NO_CQ_DATA, &tx_ctx);
+	if (ret)
+		return ret;
+
+	if (opts.verbose)
+		fprintf(stdout, "CANCEL msg posted to server\n");
+
+	ft_tag = STANDARD_TAG;
+	ret = ft_post_tx(ep, remote_fi_addr, opts.transfer_size, NO_CQ_DATA, &tx_ctx);
+	if (ret)
+		return ret;
+
+	if (opts.verbose)
+		fprintf(stdout, "STANDARD msg posted to server\n");
+
+	ret = ft_get_tx_comp(tx_seq);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int recv_cancel_host(void)
+{
+	int ret = 0;
+	int retries = 0;
+	struct fi_cq_err_entry recv_completion, cancel_error_entry;
+	struct fi_context cancel_recv_ctx, standard_recv_ctx;
+
+	/* Pre-post two recvs, one of which will be cancelled */
+	ft_tag = CANCEL_TAG;
+	ret = ft_post_rx(ep, opts.transfer_size, &cancel_recv_ctx);
+	if (ret)
+		return ret;
+
+	ft_tag = STANDARD_TAG;
+	ret = ft_post_rx(ep, opts.transfer_size, &standard_recv_ctx);
+	if (ret)
+		return ret;
+
+	/* Cancel the first recv*/
+	ret = fi_cancel((struct fid *)ep, &cancel_recv_ctx);
+	if (ret) {
+		FT_PRINTERR("fi_cancel", ret);
+		return ret;
+	}
+
+	/* sync with client */
+	ft_tag = 0;
+	ret = ft_tx(ep, remote_fi_addr, 1, &tx_ctx);
+	if (ret)
+		return ret;
+
+	/* Wait for fi_cq_read to fail indicating an err entry */
+	do {
+		ret = fi_cq_read(rxcq, &recv_completion, 1);
+		if (ret == -FI_EAVAIL)
+			break;
+		else
+			retries++;
+		usleep(1000);
+	} while ((ret == -FI_EAGAIN) && (retries < 5000));
+	if (retries >= 5000) {
+		FT_PRINTERR("ERROR: failed to detect error CQ entry in cq_read", -FI_EOTHER);
+		return -FI_EOTHER;
+	} else {
+		if (opts.verbose)
+			fprintf(stdout, "GOOD: detected error cq entry in cq_read\n");
+	}
+
+	/* Verify the error CQ has been populated */
+	if (fi_cq_readerr(rxcq, &cancel_error_entry, 0) != 1) {
+		FT_PRINTERR("ERROR: No cancel CQ error entry was populated", -FI_EOTHER);
+		return -FI_EOTHER;
+	}
+
+	if (cancel_error_entry.err != FI_ECANCELED) {
+		FT_PRINTERR("ERROR: error code is incorrect", -FI_EOTHER);
+		return -FI_EOTHER;
+	}
+
+	if (!(cancel_error_entry.flags & FI_RECV)) {
+		FT_PRINTERR("ERROR: cancelled completion flags is incorrect", -FI_EOTHER);
+		return -FI_EOTHER;
+	}
+
+	if (opts.verbose)
+		fprintf(stdout, "GOOD: error entry has expected values\n");
+
+	/* Verify only one CQ err entry can be read */
+	if (fi_cq_readerr(rxcq, &cancel_error_entry, 0) != -FI_EAGAIN) {
+		FT_PRINTERR("ERROR: Another CQ error entry was populated", -FI_EOTHER);
+		return -FI_EOTHER;
+	}
+
+	if (opts.verbose)
+		fprintf(stdout, "GOOD: no additional error entries have been detected\n");
+
+	/* Check for second recv completion*/
+	do {
+		ret = fi_cq_read(rxcq, &recv_completion, 1);
+		if (ret > 0) {
+			if (recv_completion.op_context != &standard_recv_ctx) {
+				FT_PRINTERR("ERROR: op_context does not match recv ctx", -FI_EOTHER);
+				return -FI_EOTHER;
+			}
+		} else if ((ret <= 0) && (ret != -FI_EAGAIN)) {
+			FT_PRINTERR("fi_cq_read", ret);
+		}
+	} while (ret == -FI_EAGAIN);
+
+	if (opts.verbose)
+		fprintf(stdout, "GOOD: Completed uncancelled recv\n");
+
+	fprintf(stdout, "GOOD: Completed Recv Cancel Test\n");
+
+	return 0;
+}
+
+static int run_test(void)
+{
+	int ret;
+	if (hints->ep_attr->type == FI_EP_MSG)
+		ret = ft_init_fabric_cm();
+	else
+		ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	if (opts.dst_addr)
+		return recv_cancel_client();
+	else
+		return recv_cancel_host();
+}
+
+int main(int argc, char **argv)
+{
+	int op;
+	int ret = 0;
+
+	opts = INIT_OPTS;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "Vh" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'V':
+			opts.verbose = 1;
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "Recv Cancel Functional test");
+			FT_PRINT_OPTS_USAGE("-V", "Enable Verbose printing");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->caps = FI_TAGGED;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | FI_MR_ALLOCATED;
+
+	ret = run_test();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/resmgmt_test.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/resmgmt_test.c
new file mode 100644
index 000000000..26c32120b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/resmgmt_test.c
@@ -0,0 +1,272 @@
+/*
+ * Copyright (c) 2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <unistd.h>
+#include <rdma/fi_tagged.h>
+#include "shared.h"
+
+static uint16_t max_opts = 100;
+int delay, tagged;
+
+/*
+ * The general strategy here is that we call send_loop and do as many sends
+ * in a row as we can until we get FI_EAGAIN which prevents us from continuing and
+ * we have to drain the send_cq.  Then we do it again, until we've sent
+ * all the messages we were going to send.
+ */
+static int send_loop(size_t size) {
+	int q_opts = 0;
+	int ret;
+	struct fi_context send_ctx[max_opts];
+
+	while (q_opts < max_opts) {
+		do {
+			ft_tag = q_opts + 1;
+			if (tagged)
+				ret = fi_tsend(ep, tx_buf, size, NULL, remote_fi_addr,
+					ft_tag, (void *) &send_ctx[q_opts]);
+			else
+				ret = fi_send(ep, tx_buf, size, NULL, remote_fi_addr,
+					(void *) &send_ctx[q_opts]);
+
+			if (ret == FI_SUCCESS) {
+				tx_seq++;
+				q_opts++;
+			}
+		} while (!ret && (q_opts != max_opts));
+
+		if (ret < 0) {
+			if (ret == -FI_EAGAIN) {
+				ret = ft_get_tx_comp(tx_seq);
+				if (ret)
+					return ret;
+			} else {
+				FT_PRINTERR("Send OP", ret);
+				return ret;
+			}
+		}
+	}
+
+	ret = ft_get_tx_comp(tx_seq);
+	if (ret)
+		return ret;
+
+	if (opts.verbose)
+		printf("Success: Completed %d queued ops\n", q_opts);
+
+	return 0;
+}
+
+static int receive_loop(size_t size)
+{
+	int ret;
+	int q_opts = 0;
+	struct fi_context recv_ctx[max_opts];
+
+	while (q_opts < max_opts) {
+		do {
+			ft_tag = q_opts + 1;
+			if (tagged)
+				ret = fi_trecv(ep, rx_buf, size, NULL, remote_fi_addr,
+					ft_tag, 0x0, (void *) &recv_ctx[q_opts]);
+			else
+				ret = fi_recv(ep, rx_buf, size, NULL, remote_fi_addr,
+					(void *) &recv_ctx[q_opts]);
+
+			if (ret == FI_SUCCESS) {
+				rx_seq++;
+				q_opts++;
+			}
+		} while (!ret && (q_opts != max_opts));
+
+		if (ret < 0) {
+			if (ret == -FI_EAGAIN) {
+				if (delay > 0)
+					sleep(delay);
+
+				ret = ft_get_rx_comp(rx_seq);
+				if (ret)
+					return ret;
+			} else {
+				FT_PRINTERR("Recv OP", ret);
+				return ret;
+			}
+		}
+	}
+
+	if (delay > 0)
+		sleep(delay);
+
+	ret = ft_get_rx_comp(rx_seq);
+	if (ret)
+		return ret;
+
+	if (opts.verbose)
+		printf("Success: Completed %d queued ops\n", q_opts);
+
+	return 0;
+}
+
+static int overflow_test(void)
+{
+	int ret = 0;
+
+	if (opts.dst_addr) {
+		printf("Start testing for fi_send operations: %d\n", (int) max_opts);
+		ret = send_loop(opts.transfer_size);
+		if (ret)
+			printf("ERROR: calling send_master %d\n", ret);
+	} else {
+		printf("Start testing for fi_recv operations: %d\n", (int) max_opts);
+		ret = receive_loop(opts.transfer_size);
+		if (ret)
+			printf("ERROR: calling receive_loop %d\n", ret);
+	}
+	printf("GOOD, Completed Overflow Testing\n");
+
+	return 0;
+}
+
+static int run_test(void)
+{
+	int ret = 0;
+
+	if (hints->ep_attr->type == FI_EP_MSG)
+		ret = ft_init_fabric_cm();
+	else
+		ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	ret = overflow_test();
+
+	ft_sync();
+	ft_finalize();
+
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op;
+	int ret = 0;
+
+	opts = INIT_OPTS;
+	opts.tx_cq_size = max_opts;
+	opts.rx_cq_size = max_opts;
+	delay = 0;
+	tagged = 0;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "S:R:m:l:T:X:ActdjwvVh" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'S':
+			opts.tx_cq_size = strtoul(optarg, NULL, 0);
+			printf("send cq size: %d\n", (int) opts.tx_cq_size);
+			break;
+		case 'R':
+			opts.rx_cq_size = strtoul(optarg, NULL, 0);
+			printf("recv cq size: %d\n", (int) opts.rx_cq_size);
+			break;
+		case 'T':
+			hints->tx_attr->size = strtoul(optarg, NULL, 0);
+			printf("tx context size: %d\n", (int) hints->tx_attr->size);
+			break;
+		case 'X':
+			hints->rx_attr->size = strtoul(optarg, NULL, 0);
+			printf("rx context size: %d\n", (int) hints->rx_attr->size);
+			break;
+		case 'm':
+			max_opts = strtoul(optarg, NULL, 0);
+			printf("max_opts set to %d\n", max_opts);
+			break;
+		case 'j':
+			opts.options |= FT_OPT_CQ_SHARED;
+			printf("using single shared CQ\n");
+			break;
+		case 'l':
+			opts.transfer_size = strtoul(optarg, NULL, 0);
+			printf("Testing Message Size: %d\n", opts.transfer_size);
+			break;
+		case 't':
+			tagged = 1;
+			hints->caps |= FI_TAGGED;
+			printf("tagged messaging enabled\n");
+			break;
+		case 'd':
+			delay = 1;
+			break;
+		case 'A':
+			hints->domain_attr->av_type = FI_AV_TABLE;
+			printf("AV TABLE enabled\n");
+			break;
+		case 'V':
+			opts.verbose = 1;
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "Resource Management Functional Test");
+			FT_PRINT_OPTS_USAGE("-S <int>", "Size of send CQ");
+			FT_PRINT_OPTS_USAGE("-R <int>", "Size of recv CQ");
+			FT_PRINT_OPTS_USAGE("-T <int>", "Number of TX Contexts");
+			FT_PRINT_OPTS_USAGE("-X <int>", "Number of RX Contexts");
+			FT_PRINT_OPTS_USAGE("-m <int>", "number of operations to post");
+			FT_PRINT_OPTS_USAGE("-l <int>", "message length to test");
+			FT_PRINT_OPTS_USAGE("-j", "Enable shared cq");
+			FT_PRINT_OPTS_USAGE("-t", "Enable tagged message testing");
+			FT_PRINT_OPTS_USAGE("-d", "Enable setting a delay");
+			FT_PRINT_OPTS_USAGE("-A", "Enable av table testing (only RDM/DGRAM EP)");
+			FT_PRINT_OPTS_USAGE("-V", "Enable verbose printing");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->caps = FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->resource_mgmt = FI_RM_ENABLED;
+
+	ret = run_test();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/scalable_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/scalable_ep.c
new file mode 100644
index 000000000..147945c3e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/scalable_ep.c
@@ -0,0 +1,389 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_cm.h>
+
+#include <shared.h>
+
+
+static int ctx_cnt = 2;
+static int rx_ctx_bits = 0;
+static struct fid_ep *sep;
+static struct fid_ep **tx_ep, **rx_ep;
+static struct fid_cq **txcq_array;
+static struct fid_cq **rxcq_array;
+static fi_addr_t *remote_rx_addr;
+
+static void free_res(void)
+{
+	if (rx_ep) {
+		FT_CLOSEV_FID(rx_ep, ctx_cnt);
+		free(rx_ep);
+		rx_ep = NULL;
+	}
+	if (tx_ep) {
+		FT_CLOSEV_FID(tx_ep, ctx_cnt);
+		free(tx_ep);
+		tx_ep = NULL;
+	}
+	if (rxcq_array) {
+		FT_CLOSEV_FID(rxcq_array, ctx_cnt);
+		free(rxcq_array);
+		rxcq_array = NULL;
+	}
+	if (txcq_array) {
+		FT_CLOSEV_FID(txcq_array, ctx_cnt);
+		free(txcq_array);
+		txcq_array = NULL;
+	}
+}
+
+static int alloc_ep_res(struct fid_ep *sep)
+{
+	int i, ret;
+
+	/* Get number of bits needed to represent ctx_cnt */
+	while (ctx_cnt >> ++rx_ctx_bits);
+
+	av_attr.rx_ctx_bits = rx_ctx_bits;
+
+	ret = ft_alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	txcq_array = calloc(ctx_cnt, sizeof *txcq_array);
+	rxcq_array = calloc(ctx_cnt, sizeof *rxcq_array);
+	tx_ep = calloc(ctx_cnt, sizeof *tx_ep);
+	rx_ep = calloc(ctx_cnt, sizeof *rx_ep);
+	remote_rx_addr = calloc(ctx_cnt, sizeof *remote_rx_addr);
+
+	if (!buf || !txcq_array || !rxcq_array || !tx_ep || !rx_ep || !remote_rx_addr) {
+		perror("malloc");
+		return -1;
+	}
+
+	for (i = 0; i < ctx_cnt; i++) {
+		ret = fi_tx_context(sep, i, NULL, &tx_ep[i], NULL);
+		if (ret) {
+			FT_PRINTERR("fi_tx_context", ret);
+			return ret;
+		}
+
+		ret = fi_cq_open(domain, &cq_attr, &txcq_array[i], NULL);
+		if (ret) {
+			FT_PRINTERR("fi_cq_open", ret);
+			return ret;
+		}
+
+		ret = fi_rx_context(sep, i, NULL, &rx_ep[i], NULL);
+		if (ret) {
+			FT_PRINTERR("fi_rx_context", ret);
+			return ret;
+		}
+
+		ret = fi_cq_open(domain, &cq_attr, &rxcq_array[i], NULL);
+		if (ret) {
+			FT_PRINTERR("fi_cq_open", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int bind_ep_res(void)
+{
+	int i, ret;
+
+	ret = fi_scalable_ep_bind(sep, &av->fid, 0);
+	if (ret) {
+		FT_PRINTERR("fi_scalable_ep_bind", ret);
+		return ret;
+	}
+
+	for (i = 0; i < ctx_cnt; i++) {
+		ret = fi_ep_bind(tx_ep[i], &txcq_array[i]->fid, FI_SEND);
+		if (ret) {
+			FT_PRINTERR("fi_ep_bind", ret);
+			return ret;
+		}
+
+		ret = fi_enable(tx_ep[i]);
+		if (ret) {
+			FT_PRINTERR("fi_enable", ret);
+			return ret;
+		}
+	}
+
+	for (i = 0; i < ctx_cnt; i++) {
+		ret = fi_ep_bind(rx_ep[i], &rxcq_array[i]->fid, FI_RECV);
+		if (ret) {
+			FT_PRINTERR("fi_ep_bind", ret);
+			return ret;
+		}
+
+		ret = fi_enable(rx_ep[i]);
+		if (ret) {
+			FT_PRINTERR("fi_enable", ret);
+			return ret;
+		}
+
+		ret = fi_recv(rx_ep[i], rx_buf, MAX(rx_size, FT_MAX_CTRL_MSG),
+			      mr_desc, 0, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_recv", ret);
+			return ret;
+		}
+	}
+
+	ret = fi_enable(sep);
+	if (ret) {
+		FT_PRINTERR("fi_enable", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int wait_for_comp(struct fid_cq *cq)
+{
+	struct fi_cq_entry comp;
+	int ret;
+
+	do {
+		ret = fi_cq_read(cq, &comp, 1);
+	} while (ret < 0 && ret == -FI_EAGAIN);
+
+	if (ret != 1)
+		FT_PRINTERR("fi_cq_read", ret);
+	else
+		ret = 0;
+
+	return ret;
+}
+
+#define DATA 0x12345670
+
+static int run_test()
+{
+	int ret = 0, i;
+	uint32_t data;
+	uint32_t *tb = (uint32_t *)tx_buf;
+	uint32_t *rb = (uint32_t *)rx_buf;
+
+	if (opts.dst_addr) {
+		for (i = 0; i < ctx_cnt && !ret; i++) {
+			fprintf(stdout, "Posting send for ctx: %d\n", i);
+			tb[0] = DATA + i;
+			ret = fi_send(tx_ep[i], tx_buf, tx_size, mr_desc,
+				      remote_rx_addr[i], NULL);
+			if (ret) {
+				FT_PRINTERR("fi_send", ret);
+				return ret;
+			}
+
+			ret = wait_for_comp(txcq_array[i]);
+		}
+	} else {
+		for (i = 0; i < ctx_cnt && !ret; i++) {
+			fprintf(stdout, "wait for recv completion for ctx: %d\n", i);
+			ret = wait_for_comp(rxcq_array[i]);
+
+			data = DATA + i;
+			if (memcmp(&data, rx_buf, 4) != 0) {
+				fprintf(stdout, "failed compare expected 0x%x,"
+					" read 0x%x\n", data, rb[0]);
+			}
+		}
+	}
+
+	return ret;
+}
+
+static int init_fabric(void)
+{
+	int ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	/* Check the optimal number of TX and RX contexts supported by the provider */
+	ctx_cnt = MIN(ctx_cnt, fi->domain_attr->tx_ctx_cnt);
+	ctx_cnt = MIN(ctx_cnt, fi->domain_attr->rx_ctx_cnt);
+	if (!ctx_cnt) {
+		fprintf(stderr, "Provider doesn't support contexts\n");
+		return 1;
+	}
+
+	fi->ep_attr->tx_ctx_cnt = ctx_cnt;
+	fi->ep_attr->rx_ctx_cnt = ctx_cnt;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = fi_scalable_ep(domain, fi, &sep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_scalable_ep", ret);
+		return ret;
+	}
+
+	ret = alloc_ep_res(sep);
+	if (ret)
+		return ret;
+
+	ret = bind_ep_res();
+	return ret;
+}
+
+static int init_av(void)
+{
+	size_t addrlen;
+	int ret, i;
+
+	if (opts.dst_addr) {
+		ret = ft_av_insert(av, fi->dest_addr, 1, &remote_fi_addr, 0, NULL);
+		if (ret)
+			return ret;
+
+		addrlen = FT_MAX_CTRL_MSG;
+		ret = fi_getname(&sep->fid, tx_buf, &addrlen);
+		if (ret) {
+			FT_PRINTERR("fi_getname", ret);
+			return ret;
+		}
+
+		ret = fi_send(tx_ep[0], tx_buf, addrlen,
+			      mr_desc, remote_fi_addr, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_send", ret);
+			return ret;
+		}
+
+		ret = wait_for_comp(rxcq_array[0]);
+		if (ret)
+			return ret;
+	} else {
+		ret = wait_for_comp(rxcq_array[0]);
+		if (ret)
+			return ret;
+
+		ret = ft_av_insert(av, rx_buf, 1, &remote_fi_addr, 0, NULL);
+		if (ret)
+			return ret;
+
+		ret = fi_send(tx_ep[0], tx_buf, 1,
+			      mr_desc, remote_fi_addr, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_send", ret);
+			return ret;
+		}
+	}
+
+	for (i = 0; i < ctx_cnt; i++)
+		remote_rx_addr[i] = fi_rx_addr(remote_fi_addr, i, rx_ctx_bits);
+
+	ret = fi_recv(rx_ep[0], rx_buf, rx_size, mr_desc, 0, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_recv", ret);
+		return ret;
+	}
+
+	ret = wait_for_comp(txcq_array[0]);
+	return ret;
+}
+
+
+static int run(void)
+{
+	int ret = 0;
+
+	ret = init_fabric();
+	if (ret)
+		return ret;
+
+	ret = init_av();
+	if (ret)
+		return ret;
+
+	ret = run_test();
+
+	/*TODO: Add a local finalize applicable for scalable ep */
+	//ft_finalize(fi, tx_ep[0], txcq_array[0], rxcq_array[0], remote_rx_addr[0]);
+
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int ret, op;
+
+	opts = INIT_OPTS;
+	opts.options = FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "An RDM client-server example with scalable endpoints.\n");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->ep_attr->type = FI_EP_RDM;
+	hints->caps = FI_MSG | FI_NAMED_RX_CTX;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	ret = run();
+
+	free_res();
+	/* Closes the scalable ep that was allocated in the test */
+	FT_CLOSE_FID(sep);
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/shared_ctx.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/shared_ctx.c
new file mode 100644
index 000000000..bbee0c10c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/shared_ctx.c
@@ -0,0 +1,665 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under the BSD license
+ * below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_cm.h>
+
+#include <shared.h>
+
+enum {
+	FT_UNSPEC,
+	FT_EP_CNT,
+};
+
+enum ft_ep_state {
+	FT_EP_STATE_INIT,
+	FT_EP_CONNECT_RCVD,
+	FT_EP_CONNECTING,
+	FT_EP_CONNECTED,
+};
+
+struct ep_info {
+	struct fid_ep *ep;
+	struct fi_info *fi;
+	enum ft_ep_state state;
+};
+
+static struct fi_info *fi_dup;
+static int tx_shared_ctx = 1;
+static int rx_shared_ctx = 1;
+static int ep_cnt = 4;
+static struct fid_ep **ep_array, *srx_ctx;
+static struct fid_stx *stx_ctx;
+static size_t addrlen = 0;
+static fi_addr_t *addr_array;
+
+static int get_dupinfo(void)
+{
+	struct fi_info *hints_dup;
+	int ret;
+
+       /* Get a fi_info corresponding to a wild card port. The first endpoint
+	* should use default/given port since that is what is known to both
+	* client and server. For other endpoints we should use addresses with
+	* random ports to avoid collision. fi_getinfo should return a random
+	* port if we don't specify it in the service arg or the hints. This
+	* is used only for non-MSG endpoints. */
+
+	hints_dup = fi_dupinfo(hints);
+	if (!hints_dup)
+		return -FI_ENOMEM;
+
+	free(hints_dup->src_addr);
+	free(hints_dup->dest_addr);
+	hints_dup->src_addr = NULL;
+	hints_dup->dest_addr = NULL;
+	hints_dup->src_addrlen = 0;
+	hints_dup->dest_addrlen = 0;
+
+	if (opts.dst_addr) {
+		ret = fi_getinfo(FT_FIVERSION, opts.dst_addr, NULL, 0,
+				 hints_dup, &fi_dup);
+	} else {
+		ret = fi_getinfo(FT_FIVERSION, opts.src_addr, NULL, FI_SOURCE,
+				 hints_dup, &fi_dup);
+	}
+	if (ret)
+		FT_PRINTERR("fi_getinfo", ret);
+	fi_freeinfo(hints_dup);
+	return ret;
+}
+
+static int alloc_ep(void)
+{
+	int i, ret;
+
+	ep_array = calloc(ep_cnt, sizeof(*ep_array));
+	if (!ep_array)
+		return -FI_ENOMEM;
+
+	ret = fi_endpoint(domain, fi, &ep_array[0], NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		return ret;
+	}
+
+	for (i = 1; i < ep_cnt; i++) {
+		if (hints->ep_attr->type == FI_EP_MSG)
+			ret = fi_endpoint(domain, fi, &ep_array[i], NULL);
+		else
+			ret = fi_endpoint(domain, fi_dup, &ep_array[i], NULL);
+		if (ret) {
+			FT_PRINTERR("fi_endpoint", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int alloc_ep_res(struct fi_info *fi)
+{
+	int ret;
+
+	ret = ft_alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	if (tx_shared_ctx) {
+		ret = fi_stx_context(domain, fi->tx_attr, &stx_ctx, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_stx_context", ret);
+			return ret;
+		}
+	}
+
+	if (rx_shared_ctx) {
+		ret = fi_srx_context(domain, fi->rx_attr, &srx_ctx, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_srx_context", ret);
+			return ret;
+		}
+	}
+	return 0;
+}
+
+static int bind_ep_res(struct fid_ep *ep)
+{
+	int ret;
+
+	if (hints->ep_attr->type == FI_EP_MSG)
+		FT_EP_BIND(ep, eq, 0);
+
+	if (tx_shared_ctx)
+		FT_EP_BIND(ep, stx_ctx, 0);
+
+	if (rx_shared_ctx)
+		FT_EP_BIND(ep, srx_ctx, 0);
+
+	FT_EP_BIND(ep, txcq, FI_SEND);
+	FT_EP_BIND(ep, rxcq, FI_RECV);
+	FT_EP_BIND(ep, av, 0);
+
+	ret = fi_enable(ep);
+	if (ret) {
+		FT_PRINTERR("fi_enable", ret);
+		return ret;
+	}
+	return 0;
+}
+
+static int bind_ep_array_res(void)
+{
+	int i, ret;
+	for (i = 0; i < ep_cnt; i++) {
+		ret = bind_ep_res(ep_array[i]);
+		if (ret)
+			return ret;
+	}
+	return 0;
+}
+
+static int run_test()
+{
+	int ret, i;
+
+	if (!(tx_ctx_arr = calloc(ep_cnt, sizeof *tx_ctx_arr)))
+		return -FI_ENOMEM;
+
+	if (!(rx_ctx_arr = calloc(ep_cnt, sizeof *rx_ctx_arr)))
+		return -FI_ENOMEM;
+
+	/* Post recvs */
+	for (i = 0; i < ep_cnt; i++) {
+		if (rx_shared_ctx) {
+			fprintf(stdout, "Posting recv #%d for shared rx ctx\n", i);
+			ret = ft_post_rx(srx_ctx, rx_size, &rx_ctx_arr[i]);
+		 } else {
+			fprintf(stdout, "Posting recv for endpoint #%d\n", i);
+			ret = ft_post_rx(ep_array[i], rx_size, &rx_ctx_arr[i]);
+		 }
+		if (ret)
+			return ret;
+	}
+
+	if (opts.dst_addr) {
+		/* Post sends addressed to remote EPs */
+		for (i = 0; i < ep_cnt; i++) {
+			if (tx_shared_ctx)
+				fprintf(stdout, "Posting send #%d to shared tx ctx\n", i);
+			else
+				fprintf(stdout, "Posting send to endpoint #%d\n", i);
+			ret = ft_tx(ep_array[i], addr_array[i], tx_size, &tx_ctx_arr[i]);
+			if (ret)
+				return ret;
+		}
+	}
+
+	/* Wait for recv completions */
+	ret = ft_get_rx_comp(rx_seq - 1);
+	if (ret)
+		return ret;
+
+	if (!opts.dst_addr) {
+		/* Post sends addressed to remote EPs */
+		for (i = 0; i < ep_cnt; i++) {
+			if (tx_shared_ctx)
+				fprintf(stdout, "Posting send #%d to shared tx ctx\n", i);
+			else
+				fprintf(stdout, "Posting send to endpoint #%d\n", i);
+			ret = ft_tx(ep_array[i], addr_array[i], tx_size, &tx_ctx_arr[i]);
+			if (ret)
+				return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int init_av(void)
+{
+	int ret;
+	int i;
+
+	if (opts.dst_addr) {
+		ret = ft_av_insert(av, fi->dest_addr, 1, &addr_array[0], 0, NULL);
+		if (ret)
+			return ret;
+	}
+
+	for (i = 0; i < ep_cnt; i++) {
+		addrlen = tx_size;
+		ret = fi_getname(&ep_array[i]->fid, tx_buf + ft_tx_prefix_size(),
+				 &addrlen);
+		if (ret) {
+			FT_PRINTERR("fi_getname", ret);
+			return ret;
+		}
+
+		if (opts.dst_addr) {
+			ret = ft_tx(ep_array[0], addr_array[0], addrlen, &tx_ctx);
+			if (ret)
+				return ret;
+
+			if (rx_shared_ctx)
+				ret = ft_rx(srx_ctx, rx_size);
+			else
+				ret = ft_rx(ep_array[0], rx_size);
+			if (ret)
+				return ret;
+
+			/* Skip the first address since we already have it in AV */
+			if (i) {
+				ret = ft_av_insert(av, rx_buf + ft_rx_prefix_size(), 1,
+						   &addr_array[i], 0, NULL);
+				if (ret)
+					return ret;
+			}
+		} else {
+			if (rx_shared_ctx)
+				ret = ft_rx(srx_ctx, rx_size);
+			else
+				ret = ft_rx(ep_array[0], rx_size);
+			if (ret)
+				return ret;
+
+			ret = ft_av_insert(av, rx_buf + ft_rx_prefix_size(), 1,
+					   &addr_array[i], 0, NULL);
+			if (ret)
+				return ret;
+
+			ret = ft_tx(ep_array[0], addr_array[0], addrlen, &tx_ctx);
+			if (ret)
+				return ret;
+
+		}
+	}
+
+	/* ACK */
+	if (opts.dst_addr) {
+		ret = ft_tx(ep_array[0], addr_array[0], 1, &tx_ctx);
+	} else {
+		if (rx_shared_ctx)
+			ret = ft_rx(srx_ctx, rx_size);
+		else
+			ret = ft_rx(ep_array[0], rx_size);
+	}
+
+	return ret;
+}
+
+static int init_fabric(void)
+{
+	int ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = get_dupinfo();
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	av_attr.count = ep_cnt;
+
+	ret = alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	ret = alloc_ep();
+	if (ret)
+		return ret;
+
+	ret = bind_ep_array_res();
+	if (ret)
+		return ret;
+
+	/* Post recv */
+	if (rx_shared_ctx)
+		ret = ft_post_rx(srx_ctx, MAX(rx_size, FT_MAX_CTRL_MSG), &rx_ctx);
+	else
+		ret = ft_post_rx(ep_array[0], MAX(rx_size, FT_MAX_CTRL_MSG), &rx_ctx);
+	if (ret)
+		return ret;
+
+	ret = init_av();
+	return ret;
+}
+
+static int client_connect(void)
+{
+	struct fi_eq_cm_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int i, ret;
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = get_dupinfo();
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	ret = alloc_ep_res(fi);
+	if (ret)
+		return ret;
+
+	ret = alloc_ep();
+	if (ret)
+		return ret;
+
+	ret = bind_ep_array_res();
+	if (ret)
+		return ret;
+
+	for (i = 0; i < ep_cnt; i++) {
+		ret = fi_connect(ep_array[i], fi->dest_addr, NULL, 0);
+		if (ret) {
+			FT_PRINTERR("fi_connect", ret);
+			return ret;
+		}
+
+		rd = fi_eq_sread(eq, &event, &entry, sizeof entry, -1, 0);
+		if (rd != sizeof entry) {
+			FT_PROCESS_EQ_ERR(rd, eq, "fi_eq_sread", "connect");
+			ret = (int) rd;
+			return ret;
+		}
+
+		if (event != FI_CONNECTED || entry.fid != &ep_array[i]->fid) {
+			fprintf(stderr, "Unexpected CM event %d fid %p (ep %p)\n",
+				event, entry.fid, ep);
+			ret = -FI_EOTHER;
+			return ret;
+		}
+	}
+
+	/* Post recv */
+	if (rx_shared_ctx)
+		ret = ft_post_rx(srx_ctx, MAX(rx_size, FT_MAX_CTRL_MSG), &rx_ctx);
+	else
+		ret = ft_post_rx(ep_array[0], MAX(rx_size, FT_MAX_CTRL_MSG), &rx_ctx);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int server_connect(void)
+{
+	struct fi_eq_cm_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int ret, k;
+	int num_conn_reqs = 0, num_connected = 0;
+	struct ep_info *ep_state_array = NULL;
+
+	ep_array = calloc(ep_cnt, sizeof(*ep_array));
+	if (!ep_array)
+		return -FI_ENOMEM;
+
+	ep_state_array = calloc(ep_cnt, sizeof(*ep_state_array));
+	if (!ep_state_array)
+		return -FI_ENOMEM;
+
+	while (num_connected != ep_cnt) {
+		rd = fi_eq_sread(eq, &event, &entry, sizeof entry, -1, 0);
+		if (rd != sizeof entry) {
+			FT_PROCESS_EQ_ERR(rd, eq, "fi_eq_sread", "cm-event");
+			ret = (int) rd;
+			goto err;
+		}
+
+		switch(event) {
+		case FI_CONNREQ:
+			if (num_conn_reqs == ep_cnt) {
+				fprintf(stderr, "Unexpected CM event %d\n", event);
+				ret = -FI_EOTHER;
+				goto err;
+			}
+			fi = ep_state_array[num_conn_reqs].fi = entry.info;
+			ep_state_array[num_conn_reqs].state = FT_EP_CONNECT_RCVD;
+
+			if (num_conn_reqs == 0) {
+				ret = fi_domain(fabric, fi, &domain, NULL);
+				if (ret) {
+					FT_PRINTERR("fi_domain", ret);
+					goto err;
+				}
+
+				ret = alloc_ep_res(fi);
+				if (ret)
+					goto err;
+			}
+
+			ret = fi_endpoint(domain, fi, &ep_array[num_conn_reqs], NULL);
+			if (ret) {
+				FT_PRINTERR("fi_endpoint", ret);
+				goto err;
+			}
+
+			ep_state_array[num_conn_reqs].ep = ep_array[num_conn_reqs];
+			ret = bind_ep_res(ep_array[num_conn_reqs]);
+			if (ret)
+				goto err;
+
+			ret = fi_accept(ep_array[num_conn_reqs], NULL, 0);
+			if (ret) {
+				FT_PRINTERR("fi_accept", ret);
+				goto err;
+			}
+
+			ep_state_array[num_conn_reqs].state = FT_EP_CONNECTING;
+			num_conn_reqs++;
+			break;
+
+		case FI_CONNECTED:
+			if (num_conn_reqs <= num_connected) {
+				ret = -FI_EOTHER;
+				goto err;
+			}
+
+			for (k = 0; k < num_conn_reqs; k++) {
+				if (ep_state_array[k].state != FT_EP_CONNECTING)
+					continue;
+				if (&ep_state_array[k].ep->fid == entry.fid) {
+					ep_state_array[k].state = FT_EP_CONNECTED;
+					num_connected++;
+					if (num_connected != ep_cnt)
+						fi_freeinfo(ep_state_array[k].fi);
+					break;
+				}
+			}
+
+			if (k == num_conn_reqs) {
+				fprintf(stderr, "Unexpected CM event %d fid %p (ep %p)\n",
+					event, entry.fid, ep);
+				ret = -FI_EOTHER;
+				goto err;
+			}
+			break;
+
+		default:
+			ret = -FI_EOTHER;
+			goto err;
+		}
+	}
+
+	/* Post recv */
+	if (rx_shared_ctx)
+		ret = ft_post_rx(srx_ctx, MAX(rx_size, FT_MAX_CTRL_MSG), &rx_ctx);
+	else
+		ret = ft_post_rx(ep_array[0], MAX(rx_size, FT_MAX_CTRL_MSG), &rx_ctx);
+	if (ret)
+		goto err;
+
+	free(ep_state_array);
+	return 0;
+err:
+	for (k = 0; k < ep_cnt; k++) {
+		switch(ep_state_array[k].state) {
+		case FT_EP_CONNECT_RCVD:
+			fi_reject(pep, ep_state_array[k].fi->handle, NULL, 0);
+			break;
+
+		case FT_EP_CONNECTING:
+		case FT_EP_CONNECTED:
+			fi_shutdown(ep_state_array[k].ep, 0);
+			break;
+
+		case FT_EP_STATE_INIT:
+		default:
+			break;
+		}
+	}
+
+	free(ep_state_array);
+	return ret;
+}
+
+static int run(void)
+{
+	int ret = 0;
+
+	addr_array = calloc(ep_cnt, sizeof(*addr_array));
+	if (!addr_array) {
+		perror("malloc");
+		return -FI_ENOMEM;
+	}
+
+	if (hints->ep_attr->type == FI_EP_MSG) {
+		if (!opts.dst_addr) {
+			ret = ft_start_server();
+			if (ret)
+				return ret;
+		}
+
+		ret = opts.dst_addr ? client_connect() : server_connect();
+	} else {
+		ret = init_fabric();
+	}
+	if (ret)
+		return ret;
+
+	ret = run_test();
+
+	/* TODO: Add a local finalize applicable to shared ctx */
+	//ft_finalize(fi, ep_array[0], txcq, rxcq, addr_array[0]);
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+	int option_index = 0;
+
+	struct option long_options[] = {
+		{"no-tx-shared-ctx", no_argument, &tx_shared_ctx, 0},
+		{"no-rx-shared-ctx", no_argument, &rx_shared_ctx, 0},
+		{"ep-count", required_argument, 0, FT_EP_CNT},
+		{0, 0, 0, 0},
+	};
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt_long(argc, argv, "h" ADDR_OPTS INFO_OPTS,
+					long_options, &option_index)) != -1) {
+		switch (op) {
+		case FT_EP_CNT:
+			ep_cnt = atoi(optarg);
+			if (ep_cnt <= 0) {
+				FT_ERR("ep_count needs to be greater than 0\n");
+				return EXIT_FAILURE;
+			}
+			hints->domain_attr->ep_cnt = ep_cnt;
+			break;
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "An RDM client-server example that uses"
+				       " shared context.\n");
+			FT_PRINT_OPTS_USAGE("--no-tx-shared-ctx",
+					"Disable shared context for TX");
+			FT_PRINT_OPTS_USAGE("--no-rx-shared-ctx",
+					"Disable shared context for RX");
+			FT_PRINT_OPTS_USAGE("--ep-count <count> (default: 4)",
+					"# of endpoints to be opened");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->caps = FI_MSG;
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+
+	if (tx_shared_ctx)
+		hints->ep_attr->tx_ctx_cnt = FI_SHARED_CONTEXT;
+	if (rx_shared_ctx)
+		hints->ep_attr->rx_ctx_cnt = FI_SHARED_CONTEXT;
+
+	ret = run();
+
+	FT_CLOSEV_FID(ep_array, ep_cnt);
+	if (rx_shared_ctx)
+		FT_CLOSE_FID(srx_ctx);
+	if (tx_shared_ctx)
+		FT_CLOSE_FID(stx_ctx);
+	ft_free_res();
+	free(addr_array);
+	free(ep_array);
+	fi_freeinfo(fi_dup);
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/unexpected_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/unexpected_msg.c
new file mode 100644
index 000000000..7d917b653
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/functional/unexpected_msg.c
@@ -0,0 +1,276 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include <time.h>
+#include <netdb.h>
+#include <unistd.h>
+#include <stdbool.h>
+
+#include <rdma/fabric.h>
+#include <rdma/fi_errno.h>
+#include <rdma/fi_tagged.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_cm.h>
+
+#include "shared.h"
+
+
+static size_t concurrent_msgs = 5;
+static size_t num_iters = 600;
+static bool send_data = false;
+
+
+/* Common code will free allocated buffers and MR */
+static int alloc_bufs(void)
+{
+	int ret;
+
+	tx_size = opts.transfer_size + ft_tx_prefix_size();
+	rx_size = opts.transfer_size + ft_rx_prefix_size();
+	buf_size = (tx_size + rx_size) * concurrent_msgs;
+
+	buf = malloc(buf_size);
+	tx_ctx_arr = calloc(concurrent_msgs, sizeof(*tx_ctx_arr));
+	rx_ctx_arr = calloc(concurrent_msgs, sizeof(*rx_ctx_arr));
+	if (!buf || !tx_ctx_arr || !rx_ctx_arr)
+		return -FI_ENOMEM;
+
+	rx_buf = buf;
+	tx_buf = (char *) buf + rx_size * concurrent_msgs;
+
+	if (fi->domain_attr->mr_mode & FI_MR_LOCAL) {
+		ret = fi_mr_reg(domain, buf, buf_size, FI_SEND | FI_RECV,
+				 0, FT_MR_KEY, 0, &mr, NULL);
+		if (ret)
+			return ret;
+
+		mr_desc = fi_mr_desc(mr);
+	}
+
+	return 0;
+}
+
+static char *get_tx_buf(int index)
+{
+	return tx_buf + tx_size * index;
+}
+
+static char *get_rx_buf(int index)
+{
+	return rx_buf + rx_size * index;
+}
+
+static int wait_recvs()
+{
+	struct fi_cq_tagged_entry entry;
+	int ret;
+
+	if (opts.comp_method == FT_COMP_SREAD) {
+		ret = fi_cq_sread(rxcq, &entry, 1, NULL, -1);
+	} else {
+		do {
+			ret = fi_cq_read(rxcq, &entry, 1);
+		} while (ret == -FI_EAGAIN);
+	}
+
+	if ((ret == 1) && send_data) {
+		if (entry.data != opts.transfer_size) {
+			printf("ERROR incorrect remote CQ data value. Got %lu, expected %d\n",
+					(unsigned long)entry.data, opts.transfer_size);
+			return -FI_EOTHER;
+		}
+	}
+
+	if (ret < 1)
+		printf("ERROR fi_cq_(s)read returned %d %s\n", ret, fi_strerror(-ret));
+	return ret;
+}
+
+static int run_test_loop(void)
+{
+	int ret = 0;
+	uint64_t op_data = send_data ? opts.transfer_size : NO_CQ_DATA;
+	uint64_t op_tag = 0x1234;
+	char *op_buf;
+	int i, j;
+
+	for (i = 0; i < num_iters; i++) {
+		for (j = 0; j < concurrent_msgs; j++) {
+			op_buf = get_tx_buf(j);
+			if (ft_check_opts(FT_OPT_VERIFY_DATA))
+				ft_fill_buf(op_buf + ft_tx_prefix_size(),
+					    opts.transfer_size);
+
+			ret = ft_post_tx_buf(ep, remote_fi_addr,
+					     opts.transfer_size,
+					     op_data, &tx_ctx_arr[j],
+					     op_buf, mr_desc, op_tag);
+			if (ret) {
+				printf("ERROR send_msg returned %d\n", ret);
+				return ret;
+			}
+		}
+
+		ret = ft_sync();
+		if (ret)
+			return ret;
+
+		for (j = 0; j < concurrent_msgs; j++) {
+			op_buf = get_rx_buf(j);
+			ret = ft_post_rx_buf(ep, opts.transfer_size,
+					     &rx_ctx_arr[j], op_buf,
+					     mr_desc, op_tag);
+			if (ret) {
+				printf("ERROR recv_msg returned %d\n", ret);
+				return ret;
+			}
+		}
+
+		for (j = 0; j < concurrent_msgs; j++) {
+			ret = wait_recvs();
+			if (ret < 1)
+				return ret;
+		}
+
+		if (ft_check_opts(FT_OPT_VERIFY_DATA)) {
+			for (j = 0; j < concurrent_msgs; j++) {
+				op_buf = get_rx_buf(j);
+				if (ft_check_buf(op_buf + ft_rx_prefix_size(),
+						 opts.transfer_size))
+					return -FI_EOTHER;
+			}
+		}
+
+		for (j = 0; j < concurrent_msgs; j++) {
+			ret = ft_get_tx_comp(tx_seq);
+			if (ret)
+				return ret;
+		}
+
+		if (i % 100 == 0)
+			printf("PID %d GOOD iter %d/%ld completed\n",
+				getpid(), i, num_iters);
+	}
+
+	(void) ft_sync();
+	printf("PID %d GOOD all done\n", getpid());
+	return ret;
+}
+
+static int run_test(void)
+{
+	int ret;
+
+	if (hints->ep_attr->type == FI_EP_MSG)
+		ret = ft_init_fabric_cm();
+	else
+		ret = ft_init_fabric();
+	if (ret)
+		return ret;
+
+	alloc_bufs();
+	ret = run_test_loop();
+
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	int op;
+	int ret;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_OOB_SYNC | FT_OPT_SKIP_MSG_ALLOC;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "m:i:c:vdSh" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'c':
+			concurrent_msgs = strtoul(optarg, NULL, 0);
+			break;
+		case 'i':
+			num_iters = strtoul(optarg, NULL, 0);
+			break;
+		case 'S':
+			opts.comp_method = FT_COMP_SREAD;
+			break;
+		case 'v':
+			opts.options |= FT_OPT_VERIFY_DATA;
+			break;
+		case 'm':
+			opts.transfer_size = strtoul(optarg, NULL, 0);
+			break;
+		case 'd':
+			send_data = true;
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "Unexpected message functional test");
+			FT_PRINT_OPTS_USAGE("-c <int>",
+				"Concurrent messages per iteration ");
+			FT_PRINT_OPTS_USAGE("-v", "Enable data verification");
+			FT_PRINT_OPTS_USAGE("-i <int>", "Number of iterations");
+			FT_PRINT_OPTS_USAGE("-S",
+				"Use fi_cq_sread instead of polling fi_cq_read");
+			FT_PRINT_OPTS_USAGE("-m <size>",
+				"Size of unexpected messages");
+			FT_PRINT_OPTS_USAGE("-d", "Send remote CQ data");
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+
+	hints->mode = FI_CONTEXT;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL | FI_MR_ALLOCATED;
+	hints->domain_attr->resource_mgmt = FI_RM_ENABLED;
+	hints->rx_attr->total_buffered_recv = 0;
+	hints->caps = FI_TAGGED;
+
+	ret = run_test();
+
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/freebsd/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/freebsd/osd.h
new file mode 100644
index 000000000..f4e7f0182
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/freebsd/osd.h
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2016 Intel Corp, Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _FABTESTS_FREEBSD_OSD_H_
+#define _FABTESTS_FREEBSD_OSD_H_
+
+#include <sys/endian.h>
+#include <pthread_np.h>
+#include <netinet/in.h>
+
+
+#define bswap_64 bswap64
+
+#define ENODATA ENOMSG
+#define HOST_NAME_MAX  128
+
+typedef cpuset_t cpu_set_t;
+
+#endif /* _FABTESTS_FREEBSD_OSD_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/ft_osd.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/ft_osd.h
new file mode 100644
index 000000000..a71c1c9d3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/ft_osd.h
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _FT_OSD_H_
+#define _FT_OSD_H_
+
+#ifdef __APPLE__
+#include <osx/osd.h>
+#include <unix/osd.h>
+#elif defined __FreeBSD__
+#include <freebsd/osd.h>
+#include <unix/osd.h>
+#elif defined _WIN32
+#include <windows/osd.h>
+#else
+#include <unix/osd.h>
+#endif
+
+#endif /* _FT_OSD_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/jsmn.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/jsmn.h
new file mode 100644
index 000000000..48a07c1d2
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/jsmn.h
@@ -0,0 +1,97 @@
+/*
+ * Copyright (c) 2010 Serge A. Zaitsev
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef __JSMN_H_
+#define __JSMN_H_
+
+#include <stddef.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/**
+ * JSON type identifier. Basic types are:
+ * 	o Object
+ * 	o Array
+ * 	o String
+ * 	o Other primitive: number, boolean (true/false) or null
+ */
+typedef enum {
+	JSMN_PRIMITIVE = 0,
+	JSMN_OBJECT = 1,
+	JSMN_ARRAY = 2,
+	JSMN_STRING = 3
+} jsmntype_t;
+
+typedef enum {
+	/* Not enough tokens were provided */
+	JSMN_ERROR_NOMEM = -1,
+	/* Invalid character inside JSON string */
+	JSMN_ERROR_INVAL = -2,
+	/* The string is not a full JSON packet, more bytes expected */
+	JSMN_ERROR_PART = -3
+} jsmnerr_t;
+
+/**
+ * JSON token description.
+ * @param		type	type (object, array, string etc.)
+ * @param		start	start position in JSON data string
+ * @param		end		end position in JSON data string
+ */
+typedef struct {
+	jsmntype_t type;
+	int start;
+	int end;
+	int size;
+#ifdef JSMN_PARENT_LINKS
+	int parent;
+#endif
+} jsmntok_t;
+
+/**
+ * JSON parser. Contains an array of token blocks available. Also stores
+ * the string being parsed now and current position in that string
+ */
+typedef struct {
+	unsigned int pos; /* offset in the JSON string */
+	unsigned int toknext; /* next token to allocate */
+	int toksuper; /* superior token node, e.g parent object or array */
+} jsmn_parser;
+
+/**
+ * Create JSON parser over an array of tokens
+ */
+void jsmn_init(jsmn_parser *parser);
+
+/**
+ * Run JSON parser. It parses a JSON data string into and array of tokens, each describing
+ * a single JSON object.
+ */
+jsmnerr_t jsmn_parse(jsmn_parser *parser, const char *js, size_t len,
+		jsmntok_t *tokens, unsigned int num_tokens);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __JSMN_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/osx/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/osx/osd.h
new file mode 100644
index 000000000..5c425d35c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/osx/osd.h
@@ -0,0 +1,59 @@
+/*
+ * Copyright (c) 2015 Los Alamos Nat. Security, LLC. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _FABTESTS_OSX_OSD_H_
+#define _FABTESTS_OSX_OSD_H_
+
+#include <config.h>
+
+#include <sys/time.h>
+#include <time.h>
+
+#if !HAVE_CLOCK_GETTIME
+#define CLOCK_REALTIME 0
+#define CLOCK_REALTIME_COARSE 0
+#define CLOCK_MONOTONIC 0
+
+typedef int clockid_t;
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+int clock_gettime(clockid_t clk_id, struct timespec *tp);
+
+#ifdef __cplusplus
+}
+#endif
+#endif // !HAVE_CLOCK_GETTIME
+
+#endif // FABTESTS_OSX_OSD_H
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/shared.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/shared.h
new file mode 100644
index 000000000..201fe5e6f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/shared.h
@@ -0,0 +1,504 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2017, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _SHARED_H_
+#define _SHARED_H_
+
+#if HAVE_CONFIG_H
+#  include <config.h>
+#endif /* HAVE_CONFIG_H */
+
+#include <stdlib.h>
+#include <inttypes.h>
+#include <netinet/tcp.h>
+#include <sys/uio.h>
+#include <stdbool.h>
+
+#include <rdma/fabric.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_domain.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#ifndef FT_FIVERSION
+#define FT_FIVERSION FI_VERSION(1,5)
+#endif
+
+#include "ft_osd.h"
+#define OFI_UTIL_PREFIX "ofi_"
+#define OFI_NAME_DELIM ';'
+
+#define OFI_MR_BASIC_MAP (FI_MR_ALLOCATED | FI_MR_PROV_KEY | FI_MR_VIRT_ADDR)
+
+/* exit codes must be 0-255 */
+static inline int ft_exit_code(int ret)
+{
+	int absret = ret < 0 ? -ret : ret;
+	return absret > 255 ? EXIT_FAILURE : absret;
+}
+
+#define ft_foreach_info(fi, info) \
+	for (fi = info; fi; fi = fi->next)
+
+#define ft_sa_family(addr) (((struct sockaddr *)(addr))->sa_family)
+
+struct test_size_param {
+	int size;
+	int enable_flags;
+};
+
+extern struct test_size_param test_size[];
+extern const unsigned int test_cnt;
+#define TEST_CNT test_cnt
+
+#define FT_ENABLE_ALL		(~0)
+#define FT_DEFAULT_SIZE		(1 << 0)
+
+static inline int ft_use_size(int index, int enable_flags)
+{
+	return (enable_flags == FT_ENABLE_ALL) ||
+		(enable_flags & test_size[index].enable_flags);
+}
+
+
+enum precision {
+	NANO = 1,
+	MICRO = 1000,
+	MILLI = 1000000,
+};
+
+enum ft_comp_method {
+	FT_COMP_SPIN = 0,
+	FT_COMP_SREAD,
+	FT_COMP_WAITSET,
+	FT_COMP_WAIT_FD
+};
+
+enum {
+	FT_OPT_ACTIVE		= 1 << 0,
+	FT_OPT_ITER		= 1 << 1,
+	FT_OPT_SIZE		= 1 << 2,
+	FT_OPT_RX_CQ		= 1 << 3,
+	FT_OPT_TX_CQ		= 1 << 4,
+	FT_OPT_RX_CNTR		= 1 << 5,
+	FT_OPT_TX_CNTR		= 1 << 6,
+	FT_OPT_VERIFY_DATA	= 1 << 7,
+	FT_OPT_ALIGN		= 1 << 8,
+	FT_OPT_BW		= 1 << 9,
+	FT_OPT_CQ_SHARED	= 1 << 10,
+	FT_OPT_OOB_SYNC		= 1 << 11,
+	FT_OPT_SKIP_MSG_ALLOC	= 1 << 12,
+	FT_OPT_SKIP_REG_MR	= 1 << 13,
+};
+
+/* for RMA tests --- we want to be able to select fi_writedata, but there is no
+ * constant in libfabric for this */
+enum ft_rma_opcodes {
+	FT_RMA_READ = 1,
+	FT_RMA_WRITE,
+	FT_RMA_WRITEDATA,
+};
+
+enum ft_atomic_opcodes {
+	FT_ATOMIC_BASE,
+	FT_ATOMIC_FETCH,
+	FT_ATOMIC_COMPARE,
+};
+
+struct ft_opts {
+	int iterations;
+	int warmup_iterations;
+	int transfer_size;
+	int window_size;
+	int av_size;
+	int verbose;
+	int tx_cq_size;
+	int rx_cq_size;
+	char *src_port;
+	char *dst_port;
+	char *src_addr;
+	char *dst_addr;
+	char *av_name;
+	int sizes_enabled;
+	int options;
+	enum ft_comp_method comp_method;
+	int machr;
+	enum ft_rma_opcodes rma_op;
+	char *oob_port;
+	int argc;
+
+	/* Fail if the selected provider does not support FI_MSG_PREFIX.  */
+	int force_prefix;
+	char **argv;
+};
+
+extern struct fi_info *fi_pep, *fi, *hints;
+extern struct fid_fabric *fabric;
+extern struct fid_wait *waitset;
+extern struct fid_domain *domain;
+extern struct fid_poll *pollset;
+extern struct fid_pep *pep;
+extern struct fid_ep *ep, *alias_ep;
+extern struct fid_cq *txcq, *rxcq;
+extern struct fid_cntr *txcntr, *rxcntr;
+extern struct fid_mr *mr, no_mr;
+extern void *mr_desc;
+extern struct fid_av *av;
+extern struct fid_eq *eq;
+extern struct fid_mc *mc;
+
+extern fi_addr_t remote_fi_addr;
+extern char *buf, *tx_buf, *rx_buf;
+extern size_t buf_size, tx_size, rx_size;
+extern int tx_fd, rx_fd;
+extern int timeout;
+
+extern struct fi_context tx_ctx, rx_ctx;
+extern struct fi_context *tx_ctx_arr, *rx_ctx_arr;
+extern uint64_t remote_cq_data;
+
+extern uint64_t tx_seq, rx_seq, tx_cq_cntr, rx_cq_cntr;
+extern struct fi_av_attr av_attr;
+extern struct fi_eq_attr eq_attr;
+extern struct fi_cq_attr cq_attr;
+extern struct fi_cntr_attr cntr_attr;
+
+extern struct fi_rma_iov remote;
+
+extern char test_name[50];
+extern struct timespec start, end;
+extern struct ft_opts opts;
+
+void ft_parseinfo(int op, char *optarg, struct fi_info *hints);
+void ft_parse_addr_opts(int op, char *optarg, struct ft_opts *opts);
+void ft_parsecsopts(int op, char *optarg, struct ft_opts *opts);
+int ft_parse_rma_opts(int op, char *optarg, struct fi_info *hints,
+		      struct ft_opts *opts);
+void ft_addr_usage();
+void ft_usage(char *name, char *desc);
+void ft_mcusage(char *name, char *desc);
+void ft_csusage(char *name, char *desc);
+
+void ft_fill_buf(void *buf, int size);
+int ft_check_buf(void *buf, int size);
+int ft_check_opts(uint64_t flags);
+uint64_t ft_init_cq_data(struct fi_info *info);
+int ft_sock_listen(char *node, char *service);
+int ft_sock_connect(char *node, char *service);
+int ft_sock_accept();
+int ft_sock_send(int fd, void *msg, size_t len);
+int ft_sock_recv(int fd, void *msg, size_t len);
+int ft_sock_sync(int value);
+void ft_sock_shutdown(int fd);
+extern int (*ft_mr_alloc_func)(void);
+extern uint64_t ft_tag;
+extern int ft_parent_proc;
+extern int ft_socket_pair[2];
+extern int sock;
+extern int listen_sock;
+#define ADDR_OPTS "B:P:s:a:b::"
+#define FAB_OPTS "f:d:p:"
+#define INFO_OPTS FAB_OPTS "e:"
+#define CS_OPTS ADDR_OPTS "I:S:mc:t:w:l"
+#define NO_CQ_DATA 0
+
+extern char default_port[8];
+
+#define INIT_OPTS (struct ft_opts) \
+	{	.options = FT_OPT_RX_CQ | FT_OPT_TX_CQ, \
+		.iterations = 1000, \
+		.warmup_iterations = 10, \
+		.transfer_size = 1024, \
+		.window_size = 64, \
+		.av_size = 1, \
+		.tx_cq_size = 0, \
+		.rx_cq_size = 0, \
+		.verbose = 0, \
+		.sizes_enabled = FT_DEFAULT_SIZE, \
+		.rma_op = FT_RMA_WRITE, \
+		.oob_port = NULL, \
+		.argc = argc, .argv = argv \
+	}
+
+#define FT_STR_LEN 32
+#define FT_MAX_CTRL_MSG 64
+#define FT_MR_KEY 0xC0DE
+#define FT_MSG_MR_ACCESS (FI_SEND | FI_RECV)
+#define FT_RMA_MR_ACCESS (FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE)
+
+int ft_getsrcaddr(char *node, char *service, struct fi_info *hints);
+int ft_read_addr_opts(char **node, char **service, struct fi_info *hints,
+		uint64_t *flags, struct ft_opts *opts);
+char *size_str(char str[FT_STR_LEN], long long size);
+char *cnt_str(char str[FT_STR_LEN], long long cnt);
+int size_to_count(int size);
+size_t datatype_to_size(enum fi_datatype datatype);
+
+#define FT_PRINTERR(call, retv) \
+	do { fprintf(stderr, call "(): %s:%d, ret=%d (%s)\n", __FILE__, __LINE__, \
+			(int) (retv), fi_strerror((int) -(retv))); } while (0)
+
+#define FT_LOG(level, fmt, ...) \
+	do { fprintf(stderr, "[%s] fabtests:%s:%d: " fmt "\n", level, __FILE__, \
+			__LINE__, ##__VA_ARGS__); } while (0)
+
+#define FT_ERR(fmt, ...) FT_LOG("error", fmt, ##__VA_ARGS__)
+#define FT_WARN(fmt, ...) FT_LOG("warn", fmt, ##__VA_ARGS__)
+
+#if ENABLE_DEBUG
+#define FT_DEBUG(fmt, ...) FT_LOG("debug", fmt, ##__VA_ARGS__)
+#else
+#define FT_DEBUG(fmt, ...)
+#endif
+
+#define FT_EQ_ERR(eq, entry, buf, len) \
+	FT_ERR("eq_readerr (Provider errno: %d) : %s",		 \
+		entry.prov_errno, fi_eq_strerror(eq, entry.err,	 \
+						 entry.err_data, \
+						 buf, len))	 \
+
+#define FT_CQ_ERR(cq, entry, buf, len) \
+	FT_ERR("cq_readerr (Provider errno: %d) : %s",		 \
+		entry.prov_errno, fi_cq_strerror(cq, entry.err,	 \
+						 entry.err_data, \
+						 buf, len))	 \
+
+#define FT_CLOSE_FID(fd)						\
+	do {								\
+		int ret;						\
+		if ((fd)) {						\
+			ret = fi_close(&(fd)->fid);			\
+			if (ret)					\
+				FT_ERR("fi_close: %s(%d) fid %d",	\
+					fi_strerror(-ret), 		\
+					ret,				\
+					(int) (fd)->fid.fclass);	\
+			fd = NULL;					\
+		}							\
+	} while (0)
+
+#define FT_CLOSEV_FID(fd, cnt)			\
+	do {					\
+		int i;				\
+		if (!(fd))			\
+			break;			\
+		for (i = 0; i < (cnt); i++) {	\
+			FT_CLOSE_FID((fd)[i]);	\
+		}				\
+	} while (0)
+
+#define FT_EP_BIND(ep, fd, flags)					\
+	do {								\
+		int ret;						\
+		if ((fd)) {						\
+			ret = fi_ep_bind((ep), &(fd)->fid, (flags));	\
+			if (ret) {					\
+				FT_PRINTERR("fi_ep_bind", ret);		\
+				return ret;				\
+			}						\
+		}							\
+	} while (0)
+
+int ft_alloc_bufs();
+int ft_open_fabric_res();
+int ft_getinfo(struct fi_info *hints, struct fi_info **info);
+int ft_init_fabric();
+int ft_start_server();
+int ft_server_connect();
+int ft_client_connect();
+int ft_init_fabric_cm(void);
+int ft_complete_connect(struct fid_ep *ep, struct fid_eq *eq);
+int ft_retrieve_conn_req(struct fid_eq *eq, struct fi_info **fi);
+int ft_accept_connection(struct fid_ep *ep, struct fid_eq *eq);
+int ft_connect_ep(struct fid_ep *ep,
+		struct fid_eq *eq, fi_addr_t *remote_addr);
+int ft_alloc_ep_res(struct fi_info *fi);
+int ft_alloc_active_res(struct fi_info *fi);
+int ft_enable_ep_recv(void);
+int ft_enable_ep(struct fid_ep *ep, struct fid_eq *eq, struct fid_av *av,
+		 struct fid_cq *txcq, struct fid_cq *rxcq,
+		 struct fid_cntr *txcntr, struct fid_cntr *rxcntr);
+int ft_init_alias_ep(uint64_t flags);
+int ft_av_insert(struct fid_av *av, void *addr, size_t count, fi_addr_t *fi_addr,
+		uint64_t flags, void *context);
+int ft_init_av(void);
+int ft_join_mc(void);
+int ft_init_av_dst_addr(struct fid_av *av_ptr, struct fid_ep *ep_ptr,
+		fi_addr_t *remote_addr);
+int ft_init_av_addr(struct fid_av *av, struct fid_ep *ep,
+		fi_addr_t *addr);
+int ft_exchange_keys(struct fi_rma_iov *peer_iov);
+void ft_free_res();
+void init_test(struct ft_opts *opts, char *test_name, size_t test_name_len);
+
+static inline void ft_start(void)
+{
+	opts.options |= FT_OPT_ACTIVE;
+	clock_gettime(CLOCK_MONOTONIC, &start);
+}
+static inline void ft_stop(void)
+{
+	clock_gettime(CLOCK_MONOTONIC, &end);
+	opts.options &= ~FT_OPT_ACTIVE;
+}
+
+/* Set the FI_MSG_PREFIX mode bit in the given fi_info structure and also set
+ * the option bit in the given opts structure. If using ft_getinfo, it will
+ * return -ENODATA if the provider clears the application requested mdoe bit.
+ */
+static inline void ft_force_prefix(struct fi_info *info, struct ft_opts *opts)
+{
+	info->mode |= FI_MSG_PREFIX;
+	opts->force_prefix = 1;
+}
+
+/* If force_prefix was not requested, just continue. If it was requested,
+ * return true if it was respected by the provider.
+ */
+static inline bool ft_check_prefix_forced(struct fi_info *info,
+					 struct ft_opts *opts)
+{
+	if (opts->force_prefix) {
+		return (info->tx_attr->mode & FI_MSG_PREFIX) &&
+		       (info->rx_attr->mode & FI_MSG_PREFIX);
+	}
+
+	/* Continue if forced prefix wasn't requested. */
+	return true;
+}
+
+int ft_sync(void);
+int ft_sync_pair(int status);
+int ft_fork_and_pair(void);
+int ft_wait_child(void);
+int ft_finalize(void);
+int ft_finalize_ep(struct fid_ep *ep);
+
+size_t ft_rx_prefix_size(void);
+size_t ft_tx_prefix_size(void);
+ssize_t ft_post_rx(struct fid_ep *ep, size_t size, struct fi_context* ctx);
+ssize_t ft_post_rx_buf(struct fid_ep *ep, size_t size, struct fi_context* ctx,
+		       void *op_buf, void *op_mr_desc, uint64_t op_tag);
+ssize_t ft_post_tx(struct fid_ep *ep, fi_addr_t fi_addr, size_t size,
+		uint64_t data, struct fi_context* ctx);
+ssize_t ft_post_tx_buf(struct fid_ep *ep, fi_addr_t fi_addr, size_t size,
+		       uint64_t data, struct fi_context* ctx,
+		       void *op_buf, void *op_mr_desc, uint64_t op_tag);
+ssize_t ft_rx(struct fid_ep *ep, size_t size);
+ssize_t ft_tx(struct fid_ep *ep, fi_addr_t fi_addr, size_t size, struct fi_context *ctx);
+ssize_t ft_inject(struct fid_ep *ep, fi_addr_t fi_addr, size_t size);
+ssize_t ft_post_rma(enum ft_rma_opcodes op, struct fid_ep *ep, size_t size,
+		struct fi_rma_iov *remote, void *context);
+ssize_t ft_rma(enum ft_rma_opcodes op, struct fid_ep *ep, size_t size,
+		struct fi_rma_iov *remote, void *context);
+ssize_t ft_post_rma_inject(enum ft_rma_opcodes op, struct fid_ep *ep, size_t size,
+		struct fi_rma_iov *remote);
+
+
+ssize_t ft_post_atomic(enum ft_atomic_opcodes opcode, struct fid_ep *ep,
+		       void *compare, void *compare_desc, void *result,
+		       void *result_desc, struct fi_rma_iov *remote,
+		       enum fi_datatype datatype, enum fi_op atomic_op,
+		       void *context);
+int check_base_atomic_op(struct fid_ep *endpoint, enum fi_op op,
+			 enum fi_datatype datatype, size_t *count);
+int check_fetch_atomic_op(struct fid_ep *endpoint, enum fi_op op,
+			  enum fi_datatype datatype, size_t *count);
+int check_compare_atomic_op(struct fid_ep *endpoint, enum fi_op op,
+			    enum fi_datatype datatype, size_t *count);
+
+int ft_cq_readerr(struct fid_cq *cq);
+int ft_get_rx_comp(uint64_t total);
+int ft_get_tx_comp(uint64_t total);
+int ft_recvmsg(struct fid_ep *ep, fi_addr_t fi_addr,
+		size_t size, struct fi_context *ctx, int flags);
+int ft_sendmsg(struct fid_ep *ep, fi_addr_t fi_addr,
+		size_t size, struct fi_context *ctx, int flags);
+int ft_cq_read_verify(struct fid_cq *cq, void *op_context);
+
+void eq_readerr(struct fid_eq *eq, const char *eq_str);
+
+int64_t get_elapsed(const struct timespec *b, const struct timespec *a,
+		enum precision p);
+void show_perf(char *name, int tsize, int iters, struct timespec *start,
+		struct timespec *end, int xfers_per_iter);
+void show_perf_mr(int tsize, int iters, struct timespec *start,
+		struct timespec *end, int xfers_per_iter, int argc, char *argv[]);
+
+int ft_send_recv_greeting(struct fid_ep *ep);
+int ft_send_greeting(struct fid_ep *ep);
+int ft_recv_greeting(struct fid_ep *ep);
+
+int check_recv_msg(const char *message);
+uint64_t ft_info_to_mr_access(struct fi_info *info);
+int ft_alloc_bit_combo(uint64_t fixed, uint64_t opt, uint64_t **combos, int *len);
+void ft_free_bit_combo(uint64_t *combo);
+int ft_cntr_open(struct fid_cntr **cntr);
+const char *ft_util_name(const char *str, size_t *len);
+const char *ft_core_name(const char *str, size_t *len);
+char **ft_split_and_alloc(const char *s, const char *delim, size_t *count);
+void ft_free_string_array(char **s);
+
+#define FT_PROCESS_QUEUE_ERR(readerr, rd, queue, fn, str)	\
+	do {							\
+		if (rd == -FI_EAVAIL) {				\
+			readerr(queue, fn " " str);		\
+		} else {					\
+			FT_PRINTERR(fn, rd);			\
+		}						\
+	} while (0)
+
+#define FT_PROCESS_EQ_ERR(rd, eq, fn, str) \
+	FT_PROCESS_QUEUE_ERR(eq_readerr, rd, eq, fn, str)
+
+#define FT_OPTS_USAGE_FORMAT "%-30s %s"
+#define FT_PRINT_OPTS_USAGE(opt, desc) fprintf(stderr, FT_OPTS_USAGE_FORMAT "\n", opt, desc)
+
+#define MIN(a,b) (((a)<(b))?(a):(b))
+#define MAX(a,b) (((a)>(b))?(a):(b))
+#define ARRAY_SIZE(A) (sizeof(A)/sizeof(*A))
+
+#define TEST_ENUM_SET_N_RETURN(str, len,  enum_val, type, data)	\
+	TEST_SET_N_RETURN(str, len, #enum_val, enum_val, type, data)
+
+#define TEST_SET_N_RETURN(str, len, val_str, val, type, data)	\
+	do {							\
+		if (!strncmp(str, val_str, len)) {	\
+			*(type *)(data) = val;			\
+			return 0;				\
+		}						\
+	} while (0)
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _SHARED_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/unit_common.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/unit_common.h
new file mode 100644
index 000000000..f3774bfcc
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/unit_common.h
@@ -0,0 +1,57 @@
+/*
+ * Copyright (c) 2013-2014 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _UNIT_COMMON_H_
+#define _UNIT_COMMON_H_
+
+#include <shared.h>
+
+enum { PASS, FAIL, NOTSUPP, SKIPPED };
+#define TEST_ENTRY(NAME, DESC) { NAME, #NAME, DESC}
+
+#define TEST_RET_VAL(_ret, _testret) \
+	(_ret == -FI_ENOSYS || _ret == -FI_ENODATA) ? SKIPPED : (_testret)
+
+#define FT_UNIT_STRERR(buf, str, ret) \
+	sprintf(buf, str ": ret=%d (%s)", (int)-ret, fi_strerror((int)-ret))
+
+struct test_entry {
+	int (*test)();
+	char *name;
+	char *desc;
+};
+
+void ft_unit_usage(char *name, char *desc);
+int run_tests(struct test_entry *test_array, char *err_buf);
+
+#endif /* _UNIT_COMMON_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/unix/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/unix/osd.h
new file mode 100644
index 000000000..3d7b415af
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/unix/osd.h
@@ -0,0 +1,78 @@
+/*
+ * Copyright (c) 2016 Intel Corp, Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _FABTESTS_UNIX_OSD_H_
+#define _FABTESTS_UNIX_OSD_H_
+
+#include <complex.h>
+
+static inline int ft_startup(void)
+{
+	return 0;
+}
+
+/* complex operations implementation */
+#define OFI_COMPLEX(name) ofi_##name##_complex
+#define OFI_COMPLEX_OP(name, op) ofi_complex_##name##_##op
+#define OFI_COMPLEX_TYPE_DECL(name, type) typedef type complex OFI_COMPLEX(name);
+
+OFI_COMPLEX_TYPE_DECL(float, float)
+OFI_COMPLEX_TYPE_DECL(double, double)
+OFI_COMPLEX_TYPE_DECL(long_double, long double)
+
+#define OFI_COMPLEX_OPS(name)									      \
+static inline OFI_COMPLEX(name) OFI_COMPLEX_OP(name, sum)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2) \
+{												      \
+	return v1 + v2;										      \
+}												      \
+static inline OFI_COMPLEX(name) OFI_COMPLEX_OP(name, mul)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2) \
+{												      \
+	return v1 * v2;										      \
+}												      \
+static inline int OFI_COMPLEX_OP(name, equ)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2)		      \
+{												      \
+	return v1 == v2;                                                                	      \
+}												      \
+static inline OFI_COMPLEX(name) OFI_COMPLEX_OP(name, land)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2)\
+{												      \
+	return v1 && v2;      									      \
+}												      \
+static inline OFI_COMPLEX(name) OFI_COMPLEX_OP(name, lor)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2) \
+{												      \
+	return v1 || v2;									      \
+}
+
+OFI_COMPLEX_OPS(float)
+OFI_COMPLEX_OPS(double)
+OFI_COMPLEX_OPS(long_double)
+
+#endif /* FABTESTS_UNIX_OSD_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/getopt/getopt.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/getopt/getopt.h
new file mode 100644
index 000000000..e364288d3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/getopt/getopt.h
@@ -0,0 +1,83 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _GETOPT_H_
+#define _GETOPT_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif __cplusplus
+
+#if defined WIN32 && !defined GETOPT_STATIC
+#ifdef GETOPT_DLL_EXPORTS
+#define GET_OPT_INTERFACE __declspec(dllexport)
+#else // GETOPT_DLL_EXPORTS
+#define GET_OPT_INTERFACE __declspec(dllimport)
+#endif // GETOPT_DLL_EXPORTS
+#else // WIN32 && not defined GETOPT_STATIC
+#define GET_OPT_INTERFACE
+#endif
+
+GET_OPT_INTERFACE extern char* optarg;
+extern int   optind, opterr, optopt;
+
+#ifndef no_argument
+# define no_argument		0
+#endif //no_argument
+
+#ifndef required_argument
+# define required_argument	1
+#endif //required_argument
+
+#ifndef optional_argument
+# define optional_argument	2
+#endif //optional_argument
+
+int getopt(int argc, char *const argv[], const char *optstring);
+
+struct option
+{
+	const char *name;
+	int has_arg;
+	int *flag;
+	int val;
+};
+
+int getopt_long(int argc, char *const argv[],
+		const char *optstring,
+		const struct option *longopts, int *longindex);
+
+int getopt_long_only(int argc, char *const argv[],
+		     const char *optstring,
+		     const struct option *longopts, int *longindex);
+
+#ifdef __cplusplus
+}
+#endif __cplusplus
+
+#endif //_GETOPT_H_
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/netdb.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/netdb.h
new file mode 100644
index 000000000..e42aa5870
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/netdb.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _FABTESTS_OSD_WINDOWS_NETDB_H_
+#define _FABTESTS_OSD_WINDOWS_NETDB_H_
+
+#include <ws2def.h>
+
+/* Error values for `getaddrinfo' function.  */
+# define EAI_MEMORY - 10   /* Memory allocation failure.  */
+
+#endif /* _FABTESTS_OSD_WINDOWS_NETDB_H_ */
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_attr.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/netinet/in.h
similarity index 54%
rename from prov/netdir/src/netdir_attr.c
rename to fabtests/include/windows/netinet/in.h
index 76823ae34..626c6c20c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_attr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/netinet/in.h
@@ -1,11 +1,7 @@
 /*
-* Copyright (c) 2015-2016 Intel Corporation, Inc.  All rights reserved.
+* Copyright (c) 2017 Intel Corporation.  All rights reserved.
 *
-* This software is available to you under a choice of one of two
-* licenses.  You may choose to be licensed under the terms of the GNU
-* General Public License (GPL) Version 2, available from the file
-* COPYING in the main directory of this source tree, or the
-* BSD license below:
+* This software is available to you under the BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
@@ -30,29 +26,10 @@
 * SOFTWARE.
 */
 
-#ifdef _WIN32
+#ifndef _FABTESTS_OSD_NETINET_IN_H_
+#define _FABTESTS_OSD_NETINET_IN_H_
 
-#include "ofi.h"
-#include "ofi_util.h"
-#include "rdma/fabric.h"
+#include <Ws2tcpip.h>
 
-#include "netdir.h"
+#endif /* _FABTESTS_OSD_NETINET_IN_H_ */
 
-const char ofi_nd_prov_name[] = "netdir";
-
-struct fi_provider ofi_nd_prov = {
-	.name = ofi_nd_prov_name,
-	.version = FI_VERSION(OFI_ND_MAJOR_VERSION, OFI_ND_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 6),
-	.getinfo = ofi_nd_getinfo,
-	.fabric = ofi_nd_fabric,
-	.cleanup = ofi_nd_fini
-};
-
-struct util_prov ofi_nd_util_prov = {
-	.prov = &ofi_nd_prov,
-	.info = 0,
-	.flags = UTIL_RX_SHARED_CTX,
-};
-
-#endif /* _WIN32 */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_err.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/netinet/tcp.h
similarity index 52%
rename from prov/netdir/src/netdir_err.h
rename to fabtests/include/windows/netinet/tcp.h
index 9695dd74e..dfeadf79b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_err.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/netinet/tcp.h
@@ -1,11 +1,7 @@
 /*
-* Copyright (c) 2015-2016 Intel Corporation, Inc.  All rights reserved.
+* Copyright (c) 2017 Intel Corporation.  All rights reserved.
 *
-* This software is available to you under a choice of one of two
-* licenses.  You may choose to be licensed under the terms of the GNU
-* General Public License (GPL) Version 2, available from the file
-* COPYING in the main directory of this source tree, or the
-* BSD license below:
+* This software is available to you under the BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
@@ -30,39 +26,9 @@
 * SOFTWARE.
 */
 
-#ifndef _FI_NETDIR_ERR_H_
-#define _FI_NETDIR_ERR_H_
+#ifndef _FABTESTS_OSD_WINDOWS_TCP_H_
+#define _FABTESTS_OSD_WINDOWS_TCP_H_
 
-#include <windows.h>
-
-#include "rdma/fabric.h"
-
-#ifdef __cplusplus
-extern "C" {
-#endif /* __cplusplus */
-
-#define H2F(x) ofi_nd_hresult_2_fierror(x)
-
-static inline int ofi_nd_hresult_2_fierror(HRESULT hr)
-{
-	switch (hr) {
-	case S_OK:
-	case ND_PENDING:
-		return FI_SUCCESS;
-	case ND_BUFFER_OVERFLOW:
-		return -EOVERFLOW; /* FI_EOVERFLOW */
-	case ND_CONNECTION_REFUSED:
-		return -FI_ECONNREFUSED;
-	case ND_TIMEOUT:
-		return -FI_ETIMEDOUT;
-	default:
-		return -FI_EOTHER;
-	}
-}
-
-#ifdef __cplusplus
-}
-#endif /* __cplusplus */
-
-#endif /* _FI_NETDIR_ERR_H_ */
+#include <ws2def.h>
 
+#endif /* _FABTESTS_OSD_WINDOWS_TCP_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/osd.h
new file mode 100644
index 000000000..bf7a11450
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/osd.h
@@ -0,0 +1,233 @@
+/*
+* Copyright (c) 2017 Intel Corporation.  All rights reserved.
+*
+* This software is available to you under the BSD license below:
+*
+*     Redistribution and use in source and binary forms, with or
+*     without modification, are permitted provided that the following
+*     conditions are met:
+*
+*      - Redistributions of source code must retain the above
+*        copyright notice, this list of conditions and the following
+*        disclaimer.
+*
+*      - Redistributions in binary form must reproduce the above
+*        copyright notice, this list of conditions and the following
+*        disclaimer in the documentation and/or other materials
+*        provided with the distribution.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+* EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+* NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+* BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+* ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+* CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+* SOFTWARE.
+*/
+
+#ifndef _WINDOWS_OSD_H_
+#define _WINDOWS_OSD_H_
+
+#include <winsock2.h>
+#include <ws2def.h>
+#include <windows.h>
+#include <assert.h>
+#include <inttypes.h>
+
+#include <time.h>
+
+struct iovec
+{
+	void *iov_base; /* Pointer to data.  */
+	size_t iov_len; /* Length of data.  */
+};
+
+#define strdup _strdup
+#define strncasecmp _strnicmp
+#define SHUT_RDWR SD_BOTH
+#define CLOCK_MONOTONIC	1
+
+#ifndef EAI_SYSTEM
+# define EAI_SYSTEM	-11
+#endif
+
+typedef int pid_t;
+
+/*
+ * The FILETIME structure records time in the form of
+ * 100-nanosecond intervals since January 1, 1601
+ */
+#define file2unix_time	10000000i64		/* 1E+7 */
+#define win2unix_epoch	116444736000000000i64	/* 1 Jan 1601 to 1 Jan 1970 */
+
+static inline
+int clock_gettime(int which_clock, struct timespec *spec)
+{
+	__int64 wintime;
+
+	GetSystemTimeAsFileTime((FILETIME*)&wintime);
+	wintime -= win2unix_epoch;
+
+	spec->tv_sec = wintime / file2unix_time;
+	spec->tv_nsec = wintime % file2unix_time * 100;
+
+	return 0;
+}
+
+static inline int ft_close_fd(int fd)
+{
+	return closesocket(fd);
+}
+
+static inline int poll(struct pollfd *fds, int nfds, int timeout)
+{
+	return WSAPoll(fds, nfds, timeout);
+}
+
+static inline char* strndup(const char* str, size_t n)
+{
+	char* res = strdup(str);
+	if (strlen(res) > n)
+		res[n] = '\0';
+	return res;
+}
+
+static inline char* strsep(char **stringp, const char *delim)
+{
+	char* ptr = *stringp;
+	char* p;
+
+	p = ptr ? strpbrk(ptr, delim) : NULL;
+
+	if(!p)
+		*stringp = NULL;
+	else
+	{
+		*p = 0;
+		*stringp = p + 1;
+	}
+
+	return ptr;
+}
+
+#define _SC_PAGESIZE	30
+
+static long int sysconf(int name)
+{
+	switch (name) {
+	case _SC_PAGESIZE:
+		SYSTEM_INFO info;
+		GetNativeSystemInfo(&info);
+		return (long int)info.dwPageSize;
+	default:
+		assert(0);
+	}
+	errno = EINVAL;
+	return -1;
+}
+
+#define AF_LOCAL AF_UNIX
+
+int socketpair(int af, int type, int protocol, int socks[2]);
+
+/* Bits in the fourth argument to `waitid'.  */
+#define WSTOPPED	2	/* Report stopped child (same as WUNTRACED). */
+#define WEXITED		4	/* Report dead child. */
+#define WCONTINUED	8	/* Report continued child. */
+#define WNOWAIT		0x01000000	/* Don't reap, just poll status. */
+
+static pid_t waitpid(pid_t pid, int *status, int options)
+{
+	assert(0);
+	return 0;
+}
+
+static const char* gai_strerror(int code)
+{
+	return "Unknown error";
+}
+
+static pid_t fork(void)
+{
+	assert(0);
+	return -1;
+}
+
+static int posix_memalign(void **memptr, size_t alignment, size_t size)
+{
+	*memptr = _aligned_malloc(size, alignment);
+	return (*memptr) ? 0 : ENOMEM;
+}
+
+static inline int ft_startup(void)
+{
+	int ret = 0;
+	WSADATA data;
+
+	ret = WSAStartup(MAKEWORD(2, 2), &data);
+	if (ret)
+		return HRESULT_FROM_WIN32(ret);
+	return ret;
+}
+
+
+/* complex operations implementation */
+#define OFI_COMPLEX(name) ofi_##name##_complex
+#define OFI_COMPLEX_BASE(name) OFI_COMPLEX(name)##_base
+#define OFI_COMPLEX_OP(name, op) ofi_complex_##name##_##op
+#define OFI_COMPLEX_TYPE_DECL(name, type)	\
+typedef type OFI_COMPLEX_BASE(name);		\
+typedef struct {				\
+	OFI_COMPLEX_BASE(name) re;		\
+	OFI_COMPLEX_BASE(name) im;		\
+} OFI_COMPLEX(name);
+
+OFI_COMPLEX_TYPE_DECL(float, float)
+OFI_COMPLEX_TYPE_DECL(double, double)
+OFI_COMPLEX_TYPE_DECL(long_double, long double)
+
+#define OFI_COMPLEX_OPS(name)								\
+static inline OFI_COMPLEX_BASE(name) OFI_COMPLEX_OP(name, real)(OFI_COMPLEX(name) v)	\
+{											\
+	return v.re;									\
+} 											\
+static inline OFI_COMPLEX_BASE(name) OFI_COMPLEX_OP(name, imag)(OFI_COMPLEX(name) v)	\
+{											\
+	return v.im;									\
+}											\
+static inline OFI_COMPLEX(name) OFI_COMPLEX_OP(name, sum)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2) \
+{											\
+	OFI_COMPLEX(name) ret = {.re = v1.re + v2.re, .im = v1.im + v2.im};		\
+	return ret;									\
+}											\
+static inline OFI_COMPLEX(name) OFI_COMPLEX_OP(name, mul)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2) \
+{											\
+	OFI_COMPLEX(name) ret = {.re = (v1.re * v2.re) - (v1.im * v2.im),		\
+			      .im = (v1.re * v2.im) + (v1.im * v2.re)};			\
+	return ret;									\
+}											\
+static inline int OFI_COMPLEX_OP(name, equ)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2)	\
+{											\
+	return v1.re == v2.re && v1.im == v2.im;					\
+}											\
+static inline OFI_COMPLEX(name) OFI_COMPLEX_OP(name, land)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2) \
+{											\
+	OFI_COMPLEX(name) zero = {.re = 0, .im = 0};					\
+	int equ = !OFI_COMPLEX_OP(name, equ)(v1, zero) && !OFI_COMPLEX_OP(name, equ)(v2, zero); \
+	OFI_COMPLEX(name) ret = {.re = equ ? 1.f : 0, .im = 0};				\
+	return ret;									\
+}											\
+static inline OFI_COMPLEX(name) OFI_COMPLEX_OP(name, lor)(OFI_COMPLEX(name) v1, OFI_COMPLEX(name) v2) \
+{											\
+	OFI_COMPLEX(name) zero = {.re = 0, .im = 0};					\
+	int equ = !OFI_COMPLEX_OP(name, equ)(v1, zero) || !OFI_COMPLEX_OP(name, equ)(v2, zero); \
+	OFI_COMPLEX(name) ret = {.re = equ ? 1.f : 0, .im = 0};				\
+	return ret;									\
+}
+
+OFI_COMPLEX_OPS(float)
+OFI_COMPLEX_OPS(double)
+OFI_COMPLEX_OPS(long_double)
+
+#endif /* _WINDOWS_OSD_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/poll.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/poll.h
new file mode 100644
index 000000000..b6393fb36
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/poll.h
@@ -0,0 +1,2 @@
+
+#pragma once
\ No newline at end of file
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/socket.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/socket.h
new file mode 100644
index 000000000..b6393fb36
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/socket.h
@@ -0,0 +1,2 @@
+
+#pragma once
\ No newline at end of file
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/uio.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/uio.h
new file mode 100644
index 000000000..b6393fb36
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/uio.h
@@ -0,0 +1,2 @@
+
+#pragma once
\ No newline at end of file
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/wait.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/wait.h
new file mode 100644
index 000000000..b6393fb36
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/sys/wait.h
@@ -0,0 +1,2 @@
+
+#pragma once
\ No newline at end of file
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/unistd.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/unistd.h
new file mode 100644
index 000000000..064012f4a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/include/windows/unistd.h
@@ -0,0 +1,3 @@
+#pragma once
+
+#define sleep(x) Sleep(x * 1000)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/fabtests.7.md b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/fabtests.7.md
new file mode 100644
index 000000000..ef3b94633
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/fabtests.7.md
@@ -0,0 +1,377 @@
+---
+layout: page
+title: fabtests(7)
+tagline: Fabtests Programmer's Manual
+---
+{% include JB/setup %}
+
+# NAME
+
+Fabtests
+
+# SYNOPSIS
+
+Fabtests is a set of examples for fabric providers that demonstrates
+various features of libfabric- high-performance fabric software library.
+
+# OVERVIEW
+
+Libfabric defines sets of interface that fabric providers can support.
+The purpose of Fabtests examples is to demonstrate some of the major features.
+The goal is to familiarize users with different functionalities libfabric
+offers and how to use them.  Although most tests report performance numbers,
+they are designed to test functionality and not performance.  The exception
+are the benchmarks and ubertest.
+
+The tests are divided into the following categories. Except the unit tests
+all of them are client-server tests.  Not all providers will support each test.
+
+The test names try to indicate the type of functionality each test is
+verifying.  Although some tests work with any endpoint type, many are
+restricted to verifying a single endpoint type.  These tests typically
+include the endpoint type as part of the test name, such as dgram, msg, or
+rdm.
+
+# Functional
+
+These tests are a mix of very basic functionality tests that show major
+features of libfabric.
+
+*fi_av_xfer*
+: Tests communication for unconnected endpoints, as addresses
+  are inserted and removed from the local address vector.
+
+*fi_cm_data*
+: Verifies exchanging CM data as part of connecting endpoints.
+
+*fi_cq_data*
+: Tranfers messages with CQ data.
+
+*fi_dgram*
+: A basic datagram endpoint example.
+
+*fi_dgram_waitset*
+: Transfers datagrams using waitsets for completion notifcation.
+
+*fi_inj_complete*
+: Sends messages using the FI_INJECT_COMPLETE operation flag.
+
+*fi_mcast*
+: A simple multicast test.
+
+*fi_msg*
+: A basic message endpoint example.
+
+*fi_msg_epoll*
+: Transfers messages with completion queues configured to use file
+  descriptors as wait objetcts.  The file descriptors are retrieved
+  by the program and used directly with the Linux epoll API.
+
+*fi_msg_sockets*
+: Verifies that the address assigned to a passive endpoint can be
+  transitioned to an active endpoint.  This is required applications
+  that need socket API semantics over RDMA implementations (e.g. rsockets).
+
+*fi_multi_ep*
+: Performs data transfers over multiple endpoints in parallel.
+
+*fi_multi_mr*
+: Issues RMA write operations to multiple memory regions, using
+  completion counters of inbound writes as the notification
+  mechanism.
+
+*fi_poll*
+: Exchanges data over RDM endpoints using poll sets to drive
+  completion notifications.
+
+*fi_rdm*
+: A basic RDM endpoint example.
+
+*fi_rdm_atomic*
+: Test and verifies atomic operations over an RDM endpoint.
+
+*fi_rdm_deferred_wq*
+: Test triggered operations and deferred work queue support.
+
+*fi_rdm_multi_domain*
+: Performs data transfers over multiple endpoints, with each
+  endpoint belonging to a different opened domain.
+
+*fi_rdm_multi_recv*
+: Transfers multiple messages over an RDM endpoint that are received
+  into a single buffer, posted using the FI_MULTI_RECV flag.
+
+*fi_rdm_rma_simple*
+: A simple RMA write example over an RDM endpoint.
+
+*fi_rdm_rma_trigger*
+: A basic example of queuing an RMA write operation that is initiated
+  upon the firing of a triggering completion. Works with RDM endpoints.
+
+*fi_rdm_shared_av*
+: Spawns child processes to verify basic functionality of using a shared
+  address vector with RDM endpoints.
+
+*fi_rdm_tagged_peek*
+: Basic test of using the FI_PEEK operation flag with tagged messages.
+  Works with RDM endpoints.
+
+*fi_recv_cancel*
+: Tests canceling posted receives for tagged messages.
+
+*fi_resmgmt_test*
+: Tests the resource management enabled feature.  This verifies that the
+  provider prevents applications from overruning local and remote command
+  queues and completion queues.  This corresponds to setting the domain
+  attribute resource_mgmt to FI_RM_ENABLED.
+
+*fi_scalable_ep*
+: Performs data transfers over scalable endpoints, endpoints associated
+  with multiple transmit and receive contexts.
+
+*fi_shared_ctx*
+: Performs data transfers between multiple endpoints, where the endpoints
+  share transmit and/or receive contexts.
+
+*fi_unexpected_msg*
+: Tests the send and receive handling of unexpected tagged messages.
+
+# Benchmarks
+
+The client and the server exchange messages in either a ping-pong manner,
+for pingpong named tests, or transfer messages one-way, for bw named tests.
+These tests can transfer various messages sizes, with controls over which
+features are used by the test, and report performance numbers.  The tests
+are structured based on the benchmarks provided by OSU MPI.  They are not
+guaranteed to provide the best latency or bandwidth performance numbers a
+given provider or system may achieve.
+
+*fi_dgram_pingpong*
+: Latency test for datagram endpoints
+
+*fi_msg_bw*
+: Message transfer bandwidth test for connected (MSG) endpoints.
+
+*fi_msg_pingpong*
+: Message transfer latency test for connected (MSG) endpoints.
+
+*fi_rdm_cntr_pingpong*
+: Message transfer latency test for reliable-datagram (RDM) endpoints
+  that uses counters as the completion mechanism.
+
+*fi_rdm_pingpong*
+: Message transfer latency test for reliable-datagram (RDM) endpoints.
+
+*fi_rdm_tagged_bw*
+: Tagged message bandwidth test for reliable-datagram (RDM) endpoints.
+
+*fi_rdm_tagged_pingpong*
+: Tagged message latency test for reliable-datagram (RDM) endpoints.
+
+*fi_rma_bw*
+: An RMA read and write bandwidth test for reliable (MSG and RDM) endpoints.
+
+# Unit
+
+These are simple one-sided unit tests that validate basic behavior of the API.
+Because these are single system tests that do not perform data transfers their
+testing scope is limited.
+
+*fi_av_test*
+: Verify address vector interfaces.
+
+*fi_cntr_test*
+: Tests counter creation and destruction.
+
+*fi_cq_test*
+: Tests completion queue creation and destruction.
+
+*fi_dom_test*
+: Tests domain creation and destruction.
+
+*fi_eq_test*
+: Tests event queue creation, destruction, and capabilities.
+
+*fi_getinfo_test*
+: Tests provider response to fi_getinfo calls with varying hints.
+
+*fi_mr_test*
+: Tests memory registration.
+
+*fi_resource_freeing*
+: Allocates and closes fabric resources to check for proper cleanup.
+
+# Ubertest
+
+This is a comprehensive latency, bandwidth, and functionality test that can
+handle a variety of test configurations.  The test is able to run a large
+number of tests by iterating over a large number of test variables.  As a
+result, a full ubertest run can take a significant amount of time.  Because
+ubertest iterates over input variables, it relies on a test configuration
+file for control, rather than extensive command line options that are used
+by other fabtests.  A configuration file must be constructured for each
+provider.  Example test configurations are at /test_configs.
+
+*fi_ubertest*
+: This test takes a configure file as input.  The file contains a list of
+  variables and their values to iterate over.  The test will run a set of
+  latency, bandwidth, and functionality tests over a given provider.  It
+  will perform one execution for every possible combination of all variables.
+  For example, if there are 8 test variables, with 6 having 2 possible
+  values and 2 having 3 possible values, ubertest will execute 576 total
+  iterations of each test.
+
+# HOW TO RUN TESTS
+
+(1) Fabtests requires that libfabric be installed on the system, and at least one provider be usable.
+
+(2) Install fabtests on the system. By default all the test executables are installed in /usr/bin directory unless specified otherwise.
+
+(3) All the client-server tests have the following usage model:
+
+	fi_<testname> [OPTIONS]		start server
+	fi_<testname> <host>		connect to server
+
+# COMMAND LINE OPTIONS
+
+Tests share command line options where appropriate.  The following
+command line options are available for one or more test.  To see which
+options apply for a given test, you can use the '-h' help option to see
+the list available for that test.
+
+*-h*
+: Displays help output for the test.
+
+*-f <fabric>*
+: Restrict test to the specified fabric name.
+
+*-d <domain>*
+: Restrict test to the specified domain name.
+
+*-p <provider>*
+: Restrict test to the specified provider name.
+
+*-e <ep_type>*
+: Use the specified endpoint type for the test.  Valid options are msg,
+  dgram, and rdm.  The default endpoint type is rdm.
+
+*-a <address vector name>*
+: The name of a shared address vector.  This option only applies to tests
+  that support shared address vectors.
+
+*-B <src_port>*
+: Specifies the port number of the local endpoint, overriding the default.
+
+*-P <dst_port>*
+: Specifies the port number of the peer endpoint, overriding the default.
+
+*-s <address>*
+: Specifies the address of the local endpoint.
+
+*-b[=oob_port]*
+: Enables out-of-band (via sockets) address exchange and test
+  synchronization.  A port for the out-of-band connection may be specified
+  as part of this option to override the default.
+
+*-I <number>*
+: Number of data transfer iterations.
+
+*-w <number>*
+: Number of warm-up data transfer iterations.
+
+*-S <size>*
+: Data transfer size or 'all' for a full range of sizes.  By default a
+  select number of sizes will be tested.
+
+*-l*
+: If specified, the starting address of transmit and receive buffers will
+  be aligned along a page boundary.
+
+*-m*
+: Use machine readable output.  This is useful for post-processing the test
+  output with scripts.
+
+*-t <comp_type>*
+: Specify the type of completion mechanism to use.  Valid values are queue
+  and counter.  The default is to use completion queues.
+
+*-c <comp_method>*
+: Indicate the type of processing to use checking for completed operations.
+  Valid values are spin, sread, and fd.  The default is to busy wait (spin)
+  until the desired operation has completed.  The sread option indicates that
+  the application will invoke a blocking read call in libfabric, such as
+  fi_cq_sread.  Fd indicates that the application will retrieve the native
+  operating system wait object (file descriptor) and use either poll() or
+  select() to block until the fd has been signaled, prior to checking for
+  completions.
+
+*-o <rma_op>*
+: For RMA based tests, specify the type of RMA operation to perform.  Valid
+  values are read, write, and writedata.  Write operations are the default.
+
+*-M <mcast_addr>*
+: For multicast tests, specifies the address of the multicast group to join.
+
+# USAGE EXAMPLES
+
+## A simple example
+
+	run server: <test_name> -p <provider_name> -s <source_addr>
+		e.g.	fi_msg_rma -p sockets -s 192.168.0.123
+	run client: <test_name> <server_addr> -p <provider_name>
+		e.g.	fi_msg_rma 192.168.0.123 -p sockets
+
+## An example with various options
+
+	run server: fi_rdm_atomic -p psm -s 192.168.0.123 -I 1000 -S 1024
+	run client: fi_rdm_atomic 192.168.0.123 -p psm -I 1000 -S 1024
+
+This will run "fi_rdm_atomic" for all atomic operations with
+
+	- PSM provider
+	- 1000 iterations
+	- 1024 bytes message size
+	- server node as 123.168.0.123
+
+## Run fi_ubertest
+
+	run server: fi_ubertest
+	run client: fi_ubertest -u /usr/share/fabtests/test_configs/sockets/quick.test 192.168.0.123
+
+This will run "fi_ubertest" with
+
+	- sockets provider
+	- configurations defined in /usr/share/fabtests/test_configs/sockets/quick.test
+	- server node as 192.168.0.123
+
+The config files are provided in /test_configs for sockets, verbs, udp,
+and usnic providers and distributed with fabtests installation.
+
+For more usage options: fi_ubertest -h
+
+## Run the whole fabtests suite
+
+A runscript scripts/runfabtests.sh is provided that runs all the tests
+in fabtests and reports the number of pass/fail/notrun.
+
+	Usage: runfabtests.sh [OPTIONS] [provider] [host] [client]
+
+By default if none of the options are provided, it runs all the tests using
+
+	- sockets provider
+	- 127.0.0.1 as both server and client address
+	- for small number of optiond and iterations
+
+Various options can be used to choose provider, subset tests to run,
+level of verbosity etc.
+
+	runfabtests.sh -vvv -t all psm 192.168.0.123 192.168.0.124
+
+This will run all fabtests using
+
+	- psm provider
+	- for different options and larger iterations
+	- server node as 192.168.0.123 and client node as 192.168.0.124
+	- print test output for all the tests
+
+For detailed usage options: runfabtests.sh -h
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_av_test.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_av_test.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_av_test.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_av_xfer.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_av_xfer.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_av_xfer.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cm_data.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cm_data.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cm_data.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cntr_test.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cntr_test.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cntr_test.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cq_data.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cq_data.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cq_data.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cq_test.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cq_test.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_cq_test.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram_pingpong.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram_pingpong.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram_pingpong.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram_waitset.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram_waitset.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dgram_waitset.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dom_test.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dom_test.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_dom_test.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_eq_test.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_eq_test.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_eq_test.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_getinfo_test.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_getinfo_test.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_getinfo_test.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_inj_complete.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_inj_complete.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_inj_complete.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_mcast.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_mcast.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_mcast.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_mr_test.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_mr_test.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_mr_test.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_bw.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_bw.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_bw.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_epoll.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_epoll.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_epoll.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_pingpong.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_pingpong.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_pingpong.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_sockets.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_sockets.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_msg_sockets.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_multi_ep.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_multi_ep.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_multi_ep.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_multi_mr.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_multi_mr.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_multi_mr.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_poll.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_poll.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_poll.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_atomic.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_atomic.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_atomic.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_cntr_pingpong.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_cntr_pingpong.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_cntr_pingpong.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_deferred_wq.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_deferred_wq.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_deferred_wq.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_multi_domain.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_multi_domain.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_multi_domain.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_multi_recv.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_multi_recv.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_multi_recv.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_pingpong.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_pingpong.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_pingpong.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_rma_simple.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_rma_simple.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_rma_simple.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_rma_trigger.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_rma_trigger.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_rma_trigger.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_shared_av.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_shared_av.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_shared_av.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_bw.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_bw.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_bw.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_peek.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_peek.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_peek.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_pingpong.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_pingpong.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rdm_tagged_pingpong.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_recv_cancel.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_recv_cancel.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_recv_cancel.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_resmgmt_test.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_resmgmt_test.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_resmgmt_test.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_resource_freeing.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_resource_freeing.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_resource_freeing.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rma_bw.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rma_bw.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_rma_bw.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_scalable_ep.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_scalable_ep.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_scalable_ep.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_shared_ctx.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_shared_ctx.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_shared_ctx.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_ubertest.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_ubertest.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_ubertest.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_unexpected_msg.1 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_unexpected_msg.1
new file mode 100644
index 000000000..3f6ccf96f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man1/fi_unexpected_msg.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man7/fabtests.7 b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man7/fabtests.7
new file mode 100644
index 000000000..64364cbbb
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/man/man7/fabtests.7
@@ -0,0 +1,550 @@
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fabtests" "7" "2018\-10\-06" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
+.SH NAME
+.PP
+Fabtests
+.SH SYNOPSIS
+.PP
+Fabtests is a set of examples for fabric providers that demonstrates
+various features of libfabric\- high\-performance fabric software
+library.
+.SH OVERVIEW
+.PP
+Libfabric defines sets of interface that fabric providers can support.
+The purpose of Fabtests examples is to demonstrate some of the major
+features.
+The goal is to familiarize users with different functionalities
+libfabric offers and how to use them.
+Although most tests report performance numbers, they are designed to
+test functionality and not performance.
+The exception are the benchmarks and ubertest.
+.PP
+The tests are divided into the following categories.
+Except the unit tests all of them are client\-server tests.
+Not all providers will support each test.
+.PP
+The test names try to indicate the type of functionality each test is
+verifying.
+Although some tests work with any endpoint type, many are restricted to
+verifying a single endpoint type.
+These tests typically include the endpoint type as part of the test
+name, such as dgram, msg, or rdm.
+.SH Functional
+.PP
+These tests are a mix of very basic functionality tests that show major
+features of libfabric.
+.TP
+.B \f[I]fi_av_xfer\f[]
+Tests communication for unconnected endpoints, as addresses are inserted
+and removed from the local address vector.
+.RS
+.RE
+.TP
+.B \f[I]fi_cm_data\f[]
+Verifies exchanging CM data as part of connecting endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_cq_data\f[]
+Tranfers messages with CQ data.
+.RS
+.RE
+.TP
+.B \f[I]fi_dgram\f[]
+A basic datagram endpoint example.
+.RS
+.RE
+.TP
+.B \f[I]fi_dgram_waitset\f[]
+Transfers datagrams using waitsets for completion notifcation.
+.RS
+.RE
+.TP
+.B \f[I]fi_inj_complete\f[]
+Sends messages using the FI_INJECT_COMPLETE operation flag.
+.RS
+.RE
+.TP
+.B \f[I]fi_mcast\f[]
+A simple multicast test.
+.RS
+.RE
+.TP
+.B \f[I]fi_msg\f[]
+A basic message endpoint example.
+.RS
+.RE
+.TP
+.B \f[I]fi_msg_epoll\f[]
+Transfers messages with completion queues configured to use file
+descriptors as wait objetcts.
+The file descriptors are retrieved by the program and used directly with
+the Linux epoll API.
+.RS
+.RE
+.TP
+.B \f[I]fi_msg_sockets\f[]
+Verifies that the address assigned to a passive endpoint can be
+transitioned to an active endpoint.
+This is required applications that need socket API semantics over RDMA
+implementations (e.g.
+rsockets).
+.RS
+.RE
+.TP
+.B \f[I]fi_multi_ep\f[]
+Performs data transfers over multiple endpoints in parallel.
+.RS
+.RE
+.TP
+.B \f[I]fi_multi_mr\f[]
+Issues RMA write operations to multiple memory regions, using completion
+counters of inbound writes as the notification mechanism.
+.RS
+.RE
+.TP
+.B \f[I]fi_poll\f[]
+Exchanges data over RDM endpoints using poll sets to drive completion
+notifications.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm\f[]
+A basic RDM endpoint example.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_atomic\f[]
+Test and verifies atomic operations over an RDM endpoint.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_deferred_wq\f[]
+Test triggered operations and deferred work queue support.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_multi_domain\f[]
+Performs data transfers over multiple endpoints, with each endpoint
+belonging to a different opened domain.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_multi_recv\f[]
+Transfers multiple messages over an RDM endpoint that are received into
+a single buffer, posted using the FI_MULTI_RECV flag.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_rma_simple\f[]
+A simple RMA write example over an RDM endpoint.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_rma_trigger\f[]
+A basic example of queuing an RMA write operation that is initiated upon
+the firing of a triggering completion.
+Works with RDM endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_shared_av\f[]
+Spawns child processes to verify basic functionality of using a shared
+address vector with RDM endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_tagged_peek\f[]
+Basic test of using the FI_PEEK operation flag with tagged messages.
+Works with RDM endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_recv_cancel\f[]
+Tests canceling posted receives for tagged messages.
+.RS
+.RE
+.TP
+.B \f[I]fi_resmgmt_test\f[]
+Tests the resource management enabled feature.
+This verifies that the provider prevents applications from overruning
+local and remote command queues and completion queues.
+This corresponds to setting the domain attribute resource_mgmt to
+FI_RM_ENABLED.
+.RS
+.RE
+.TP
+.B \f[I]fi_scalable_ep\f[]
+Performs data transfers over scalable endpoints, endpoints associated
+with multiple transmit and receive contexts.
+.RS
+.RE
+.TP
+.B \f[I]fi_shared_ctx\f[]
+Performs data transfers between multiple endpoints, where the endpoints
+share transmit and/or receive contexts.
+.RS
+.RE
+.TP
+.B \f[I]fi_unexpected_msg\f[]
+Tests the send and receive handling of unexpected tagged messages.
+.RS
+.RE
+.SH Benchmarks
+.PP
+The client and the server exchange messages in either a ping\-pong
+manner, for pingpong named tests, or transfer messages one\-way, for bw
+named tests.
+These tests can transfer various messages sizes, with controls over
+which features are used by the test, and report performance numbers.
+The tests are structured based on the benchmarks provided by OSU MPI.
+They are not guaranteed to provide the best latency or bandwidth
+performance numbers a given provider or system may achieve.
+.TP
+.B \f[I]fi_dgram_pingpong\f[]
+Latency test for datagram endpoints
+.RS
+.RE
+.TP
+.B \f[I]fi_msg_bw\f[]
+Message transfer bandwidth test for connected (MSG) endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_msg_pingpong\f[]
+Message transfer latency test for connected (MSG) endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_cntr_pingpong\f[]
+Message transfer latency test for reliable\-datagram (RDM) endpoints
+that uses counters as the completion mechanism.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_pingpong\f[]
+Message transfer latency test for reliable\-datagram (RDM) endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_tagged_bw\f[]
+Tagged message bandwidth test for reliable\-datagram (RDM) endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_rdm_tagged_pingpong\f[]
+Tagged message latency test for reliable\-datagram (RDM) endpoints.
+.RS
+.RE
+.TP
+.B \f[I]fi_rma_bw\f[]
+An RMA read and write bandwidth test for reliable (MSG and RDM)
+endpoints.
+.RS
+.RE
+.SH Unit
+.PP
+These are simple one\-sided unit tests that validate basic behavior of
+the API.
+Because these are single system tests that do not perform data transfers
+their testing scope is limited.
+.TP
+.B \f[I]fi_av_test\f[]
+Verify address vector interfaces.
+.RS
+.RE
+.TP
+.B \f[I]fi_cntr_test\f[]
+Tests counter creation and destruction.
+.RS
+.RE
+.TP
+.B \f[I]fi_cq_test\f[]
+Tests completion queue creation and destruction.
+.RS
+.RE
+.TP
+.B \f[I]fi_dom_test\f[]
+Tests domain creation and destruction.
+.RS
+.RE
+.TP
+.B \f[I]fi_eq_test\f[]
+Tests event queue creation, destruction, and capabilities.
+.RS
+.RE
+.TP
+.B \f[I]fi_getinfo_test\f[]
+Tests provider response to fi_getinfo calls with varying hints.
+.RS
+.RE
+.TP
+.B \f[I]fi_mr_test\f[]
+Tests memory registration.
+.RS
+.RE
+.TP
+.B \f[I]fi_resource_freeing\f[]
+Allocates and closes fabric resources to check for proper cleanup.
+.RS
+.RE
+.SH Ubertest
+.PP
+This is a comprehensive latency, bandwidth, and functionality test that
+can handle a variety of test configurations.
+The test is able to run a large number of tests by iterating over a
+large number of test variables.
+As a result, a full ubertest run can take a significant amount of time.
+Because ubertest iterates over input variables, it relies on a test
+configuration file for control, rather than extensive command line
+options that are used by other fabtests.
+A configuration file must be constructured for each provider.
+Example test configurations are at /test_configs.
+.TP
+.B \f[I]fi_ubertest\f[]
+This test takes a configure file as input.
+The file contains a list of variables and their values to iterate over.
+The test will run a set of latency, bandwidth, and functionality tests
+over a given provider.
+It will perform one execution for every possible combination of all
+variables.
+For example, if there are 8 test variables, with 6 having 2 possible
+values and 2 having 3 possible values, ubertest will execute 576 total
+iterations of each test.
+.RS
+.RE
+.SH HOW TO RUN TESTS
+.IP "(1)" 4
+Fabtests requires that libfabric be installed on the system, and at
+least one provider be usable.
+.IP "(2)" 4
+Install fabtests on the system.
+By default all the test executables are installed in /usr/bin directory
+unless specified otherwise.
+.IP "(3)" 4
+All the client\-server tests have the following usage model:
+.RS 4
+.PP
+fi_ [OPTIONS] start server fi_ connect to server
+.RE
+.SH COMMAND LINE OPTIONS
+.PP
+Tests share command line options where appropriate.
+The following command line options are available for one or more test.
+To see which options apply for a given test, you can use the
+\[aq]\-h\[aq] help option to see the list available for that test.
+.TP
+.B \f[I]\-h\f[]
+Displays help output for the test.
+.RS
+.RE
+.TP
+.B \f[I]\-f \f[]
+Restrict test to the specified fabric name.
+.RS
+.RE
+.TP
+.B \f[I]\-d \f[]
+Restrict test to the specified domain name.
+.RS
+.RE
+.TP
+.B \f[I]\-p \f[]
+Restrict test to the specified provider name.
+.RS
+.RE
+.TP
+.B \f[I]\-e \f[]
+Use the specified endpoint type for the test.
+Valid options are msg, dgram, and rdm.
+The default endpoint type is rdm.
+.RS
+.RE
+*\-a
+.IP \[bu] 2
+: The name of a shared address vector.
+This option only applies to tests that support shared address vectors.
+.TP
+.B \f[I]\-B \f[]
+Specifies the port number of the local endpoint, overriding the default.
+.RS
+.RE
+.TP
+.B \f[I]\-P \f[]
+Specifies the port number of the peer endpoint, overriding the default.
+.RS
+.RE
+*\-s
+.IP \[bu] 2
+: Specifies the address of the local endpoint.
+.TP
+.B \f[I]\-b[=oob_port]\f[]
+Enables out\-of\-band (via sockets) address exchange and test
+synchronization.
+A port for the out\-of\-band connection may be specified as part of this
+option to override the default.
+.RS
+.RE
+.TP
+.B \f[I]\-I \f[]
+Number of data transfer iterations.
+.RS
+.RE
+.TP
+.B \f[I]\-w \f[]
+Number of warm\-up data transfer iterations.
+.RS
+.RE
+.TP
+.B \f[I]\-S \f[]
+Data transfer size or \[aq]all\[aq] for a full range of sizes.
+By default a select number of sizes will be tested.
+.RS
+.RE
+.TP
+.B \f[I]\-l\f[]
+If specified, the starting address of transmit and receive buffers will
+be aligned along a page boundary.
+.RS
+.RE
+.TP
+.B \f[I]\-m\f[]
+Use machine readable output.
+This is useful for post\-processing the test output with scripts.
+.RS
+.RE
+.TP
+.B \f[I]\-t \f[]
+Specify the type of completion mechanism to use.
+Valid values are queue and counter.
+The default is to use completion queues.
+.RS
+.RE
+.TP
+.B \f[I]\-c \f[]
+Indicate the type of processing to use checking for completed
+operations.
+Valid values are spin, sread, and fd.
+The default is to busy wait (spin) until the desired operation has
+completed.
+The sread option indicates that the application will invoke a blocking
+read call in libfabric, such as fi_cq_sread.
+Fd indicates that the application will retrieve the native operating
+system wait object (file descriptor) and use either poll() or select()
+to block until the fd has been signaled, prior to checking for
+completions.
+.RS
+.RE
+.TP
+.B \f[I]\-o \f[]
+For RMA based tests, specify the type of RMA operation to perform.
+Valid values are read, write, and writedata.
+Write operations are the default.
+.RS
+.RE
+.TP
+.B \f[I]\-M \f[]
+For multicast tests, specifies the address of the multicast group to
+join.
+.RS
+.RE
+.SH USAGE EXAMPLES
+.SS A simple example
+.IP
+.nf
+\f[C]
+run\ server:\ <test_name>\ \-p\ <provider_name>\ \-s\ <source_addr>
+\ \ \ \ e.g.\ \ \ \ fi_msg_rma\ \-p\ sockets\ \-s\ 192.168.0.123
+run\ client:\ <test_name>\ <server_addr>\ \-p\ <provider_name>
+\ \ \ \ e.g.\ \ \ \ fi_msg_rma\ 192.168.0.123\ \-p\ sockets
+\f[]
+.fi
+.SS An example with various options
+.IP
+.nf
+\f[C]
+run\ server:\ fi_rdm_atomic\ \-p\ psm\ \-s\ 192.168.0.123\ \-I\ 1000\ \-S\ 1024
+run\ client:\ fi_rdm_atomic\ 192.168.0.123\ \-p\ psm\ \-I\ 1000\ \-S\ 1024
+\f[]
+.fi
+.PP
+This will run "fi_rdm_atomic" for all atomic operations with
+.IP
+.nf
+\f[C]
+\-\ PSM\ provider
+\-\ 1000\ iterations
+\-\ 1024\ bytes\ message\ size
+\-\ server\ node\ as\ 123.168.0.123
+\f[]
+.fi
+.SS Run fi_ubertest
+.IP
+.nf
+\f[C]
+run\ server:\ fi_ubertest
+run\ client:\ fi_ubertest\ \-u\ /usr/share/fabtests/test_configs/sockets/quick.test\ 192.168.0.123
+\f[]
+.fi
+.PP
+This will run "fi_ubertest" with
+.IP
+.nf
+\f[C]
+\-\ sockets\ provider
+\-\ configurations\ defined\ in\ /usr/share/fabtests/test_configs/sockets/quick.test
+\-\ server\ node\ as\ 192.168.0.123
+\f[]
+.fi
+.PP
+The config files are provided in /test_configs for sockets, verbs, udp,
+and usnic providers and distributed with fabtests installation.
+.PP
+For more usage options: fi_ubertest \-h
+.SS Run the whole fabtests suite
+.PP
+A runscript scripts/runfabtests.sh is provided that runs all the tests
+in fabtests and reports the number of pass/fail/notrun.
+.IP
+.nf
+\f[C]
+Usage:\ runfabtests.sh\ [OPTIONS]\ [provider]\ [host]\ [client]
+\f[]
+.fi
+.PP
+By default if none of the options are provided, it runs all the tests
+using
+.IP
+.nf
+\f[C]
+\-\ sockets\ provider
+\-\ 127.0.0.1\ as\ both\ server\ and\ client\ address
+\-\ for\ small\ number\ of\ optiond\ and\ iterations
+\f[]
+.fi
+.PP
+Various options can be used to choose provider, subset tests to run,
+level of verbosity etc.
+.IP
+.nf
+\f[C]
+runfabtests.sh\ \-vvv\ \-t\ all\ psm\ 192.168.0.123\ 192.168.0.124
+\f[]
+.fi
+.PP
+This will run all fabtests using
+.IP
+.nf
+\f[C]
+\-\ psm\ provider
+\-\ for\ different\ options\ and\ larger\ iterations
+\-\ server\ node\ as\ 192.168.0.123\ and\ client\ node\ as\ 192.168.0.124
+\-\ print\ test\ output\ for\ all\ the\ tests
+\f[]
+.fi
+.PP
+For detailed usage options: runfabtests.sh \-h
+.SH AUTHORS
+OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/parseyaml.py b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/parseyaml.py
new file mode 100755
index 000000000..9ece600fa
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/parseyaml.py
@@ -0,0 +1,95 @@
+#!/usr/bin/env python
+
+import sys
+import pprint
+import operator
+from optparse import OptionParser
+
+try:
+	import yaml
+except ImportError:
+	print ("PyYAML library missing, try: yum install PyYAML")
+	sys.exit(1)
+
+# diff two list-of dicts for perf numbers
+# this means just produce xfer_size, MB/sec, usec/xfer
+def _diff(a,b):
+	r = []
+
+	for v1, v2 in zip(a,b):
+		d = {}
+		for k in v2.keys():
+			if k == 'xfer_size':
+				d[k] = v2[k]
+			elif k == 'MB/sec' or k == 'usec/xfer':
+				d[k] = float((v2[k] - v1[k])) / float(v1[k]) * 100
+			else:
+				continue
+
+		r.append(d.copy())
+
+	return r
+
+def difference(ystream):
+	"""Subtract a from b and print the results"""
+
+	# reverse stream and split based on key
+	rev = reversed(list(ystream))
+	a, b = {}, {}
+	for i in rev:
+		if not set(i).issubset(set(b)):
+			b.update(i)
+		else:
+			a.update(i)
+
+	result = {}
+	for k in b.keys():
+		result[k] = _diff(a[k], b[k])
+
+	return result
+
+def pretty(stream):
+	"""Prety-print given yaml stream and exit"""
+	for i in stream: pprint.pprint(i)
+	return 0
+
+def perfprint(d):
+	for k,v in d.items():
+		print k, ":"
+		for i in v:
+			print 'xfer_size: ', i['xfer_size'],
+			print ', MB/sec: %.2f' % i['MB/sec'] + '%',
+			print ', usec/xfer: %.2f' % i['usec/xfer'] + '%'
+	
+
+def main(argv=None):
+
+	parser = OptionParser(description='fabtests yaml parsing utility')
+	parser.add_option('-d', action='store_true', default=False, help=difference.__doc__)
+	parser.add_option('-v', action='store_true', default=False, help=pretty.__doc__)
+	(options, args) = parser.parse_args()
+
+	if len(args) == 0:
+		fd = sys.stdin
+	elif len(args) > 1:
+		class fd:
+			@staticmethod
+			def read():
+				r1 = map(open, args)
+				r2 = map(lambda x: x.read(), r1) 
+				return reduce(operator.add, r2)
+	else:
+		fd = open(args[0], 'r')
+
+	yi = yaml.load_all(fd.read())
+
+	if options.d:
+		perfprint(difference(yi))
+
+	if options.v:
+		pretty(yi)
+
+	return 0
+
+if __name__ == "__main__":
+	sys.exit(main(sys.argv))
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/rft_yaml_to_junit_xml b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/rft_yaml_to_junit_xml
new file mode 100755
index 000000000..feb646366
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/rft_yaml_to_junit_xml
@@ -0,0 +1,97 @@
+#!/usr/bin/env ruby
+
+# Copyright (c) 2015 Cisco Systems, Inc.  All rights reserved.
+#
+# This software is available to you under a choice of one of two
+# licenses.  You may choose to be licensed under the terms of the GNU
+# General Public License (GPL) Version 2, available from the file
+# COPYING in the main directory of this source tree, or the
+# BSD license below:
+#
+#     Redistribution and use in source and binary forms, with or
+#     without modification, are permitted provided that the following
+#     conditions are met:
+#
+#      - Redistributions of source code must retain the above
+#        copyright notice, this list of conditions and the following
+#        disclaimer.
+#
+#      - Redistributions in binary form must reproduce the above
+#        copyright notice, this list of conditions and the following
+#        disclaimer in the documentation and/or other materials
+#        provided with the distribution.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AWV
+# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# Transform YAML-formatted runfabtests.sh output on STDIN into jUnit-formatted
+# XML on STDOUT.
+
+require 'yaml'
+
+results = YAML.load(ARGF);
+
+suite_duration = 0.0
+num_tests = 0
+failures = 0  # jUnit considers failures/errors to be different, we only use
+errors = 0    # failures for right now
+skipped = 0
+
+# make an initial pass so we can fill out the <testsuite> tag's attributes
+results.each do |tcase|
+  num_tests += 1
+
+  case tcase['result']
+  when 'Notrun'
+    skipped += 1
+  when 'Fail'
+    failures += 1
+  end
+
+  suite_duration += tcase['time']
+end
+
+printf %Q{<testsuite name="fabtests" tests="%d" failures="%d" errors="%d" skipped="%d" time="%.3f">\n},
+  num_tests, failures, errors, skipped, suite_duration
+
+# now emit each <testcase>
+results.each do |tcase|
+  if tcase.has_key?('client_stdout')
+    output = "SERVER OUTPUT:\n"
+    output += tcase['server_stdout']
+    output += "\n"
+    output += "CLIENT OUTPUT:\n"
+    output += tcase['client_stdout']
+  else
+    output = tcase['server_stdout']
+  end
+
+  puts <<-EOT
+  <testcase name="#{tcase['name']}" time="#{tcase['time']}">
+  EOT
+  case tcase['result']
+  when 'Notrun'
+    puts <<-EOT
+    <skipped />
+    EOT
+  when 'Fail'
+    puts <<-EOT
+    <failure message="Fail">"#{tcase['name']}" failed</failure>
+    EOT
+  end
+  puts <<-EOT
+    <system-out>
+<![CDATA[#{output}]]>
+    </system-out>
+  </testcase>
+
+  EOT
+end
+
+puts "</testsuite>"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/run_with_output.cmd b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/run_with_output.cmd
new file mode 100644
index 000000000..bc105cab8
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/run_with_output.cmd
@@ -0,0 +1,11 @@
+set cmdline=%1
+set out_file=%2
+set result_file=%3
+
+
+for /f "tokens=*" %%n in (%cmdline%) do set test_cmdline=%%n
+%test_cmdline% >%out_file% 2>&1
+echo %errorlevel% >%result_file%.tmp
+ren %result_file%.tmp %result_file%
+
+exit
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/runfabtests.cmd b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/runfabtests.cmd
new file mode 100644
index 000000000..8d31b7704
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/runfabtests.cmd
@@ -0,0 +1,265 @@
+@echo off
+setlocal EnableDelayedExpansion
+
+set PATH=%~dp0;%PATH%
+
+
+set S_INTERFACE=127.0.0.1
+set C_INTERFACE=127.0.0.1
+
+set TEST_FAIL_TIMEOUT=90
+
+set unit_tests=^
+	"av_test -g 192.168.10.1 -n 1 -s 127.0.0.1"^
+	"eq_test"
+rem Disabling this test since it fails on windows (appveyor). Re-enable after root cause is identified and fixed
+rem "dom_test -n 2"
+
+set functional_tests=^
+	"cq_data"^
+	"dgram -p sockets"^
+	"dgram_waitset -p sockets"^
+	"msg"^
+	"msg_sockets"^
+	"poll -t queue"^
+	"poll -t counter"^
+	"rdm"^
+	"rdm_rma_simple"^
+	"rdm_rma_trigger"^
+	"rdm_tagged_peek"^
+	"scalable_ep"
+rem	"msg_epoll"
+
+set short_tests=^
+	"msg_pingpong -I 5"^
+	"msg_pingpong -I 5 -v"^
+	"rdm_cntr_pingpong -I 5"^
+	"rdm_pingpong -I 5"^
+	"rdm_pingpong -I 5 -v"^
+	"rdm_tagged_pingpong -I 5"^
+	"rdm_tagged_pingpong -I 5 -v"
+rem	"msg_bw -I 5"^
+rem	"msg_bw -I 5 -v"^
+rem	"rma_bw -e msg -o write -I 5"^
+rem	"rma_bw -e msg -o read -I 5"^
+rem	"rma_bw -e msg -o writedata -I 5"^
+rem	"rma_bw -e rdm -o write -I 5"^
+rem	"rma_bw -e rdm -o read -I 5"^
+rem	"rma_bw -e rdm -o writedata -I 5"^
+rem	"msg_rma -o write -I 5"^
+rem	"msg_rma -o read -I 5"^
+rem	"msg_rma -o writedata -I 5"^
+rem	"msg_stream -I 5"^
+rem	"rdm_atomic -I 5 -o all"^
+rem	"rdm_multi_recv -I 5"^
+rem	"rdm_rma -o write -I 5"^
+rem	"rdm_rma -o read -I 5"^
+rem	"rdm_rma -o writedata -I 5"^
+rem	"rdm_tagged_bw -I 5"^
+rem	"rdm_tagged_bw -I 5 -v"^
+rem	"dgram_pingpong -I 5"^
+
+
+set standard_tests=^
+	"msg_pingpong"^
+	"msg_pingpong -v"^
+	"msg_pingpong -k"^
+	"msg_pingpong -k -v"^
+	"rdm_cntr_pingpong"^
+	"rdm_pingpong"^
+	"rdm_pingpong -v"^
+	"rdm_pingpong -k"^
+	"rdm_pingpong -k -v"^
+	"rdm_tagged_pingpong"^
+	"rdm_tagged_pingpong -v"
+rem	"msg_bw"^
+rem	"msg_bw -v"^
+rem	"rma_bw -e msg -o write"^
+rem	"rma_bw -e msg -o read"^
+rem	"rma_bw -e msg -o writedata"^
+rem	"rma_bw -e rdm -o write"^
+rem	"rma_bw -e rdm -o read"^
+rem	"rma_bw -e rdm -o writedata"^
+rem	"msg_rma -o write"^
+rem	"msg_rma -o read"^
+rem	"msg_rma -o writedata"^
+rem	"msg_stream"^
+rem	"rdm_atomic -o all -I 1000"^
+rem	"rdm_multi_recv"^
+rem	"rdm_rma -o write"^
+rem	"rdm_rma -o read"^
+rem	"rdm_rma -o writedata"^
+rem	"rdm_tagged_bw"^
+rem	"rdm_tagged_bw -v"^
+rem	"dgram_pingpong"^
+rem	"dgram_pingpong -k"^
+
+
+set test_types=unit functional short
+
+
+goto :main
+
+
+:single__clear_txt
+	del out.txt res.txt >nul 2>nul
+exit /b 0
+:single__start_job
+	start /b run_with_output.cmd "!test_cmdline!" out.txt res.txt >nul 2>nul
+exit /b 0
+:single__check_is_job_ended
+	if not exist res.txt exit /b 1
+exit /b 0
+:single__print_output
+	echo OUTPUT: & type out.txt & echo ----
+exit /b 0
+:single__print_and_check_err_code
+	setlocal
+	set err=0
+	set /p err_code= <res.txt || ( echo error getting error code >&2 & exit /b 2 )
+	set /a err_code=err_code
+	if not "!err_code!"=="0" ( set err=1 & echo error code = !err_code! )
+exit /b !err!
+
+
+:client_server__clear_txt
+	del out_sv.txt res_sv.txt out_cl.txt res_cl.txt >nul 2>nul
+exit /b 0
+:client_server__start_job
+	start /b run_with_output.cmd "!test_cmdline! -s !S_INTERFACE!" out_sv.txt res_sv.txt >nul 2>nul
+	start /b run_with_output.cmd "!test_cmdline! -s !C_INTERFACE! !S_INTERFACE!" out_cl.txt res_cl.txt >nul 2>nul
+exit /b 0
+:client_server__check_is_job_ended
+	if not exist res_sv.txt exit /b 1
+	if not exist res_cl.txt exit /b 1
+exit /b 0
+:client_server__print_output
+	echo SERVER OUTPUT: & type out_sv.txt & echo ----
+	echo CLIENT OUTPUT: & type out_cl.txt & echo ----
+exit /b 0
+:client_server__print_and_check_err_code
+	setlocal
+	set err=0
+	set /p sv_err_code= <res_sv.txt || ( echo error getting server error code >&2 & exit /b 2 )
+	set /p cl_err_code= <res_cl.txt || ( echo error getting client error code >&2 & exit /b 2 )
+	set /a sv_err_code=sv_err_code
+	set /a cl_err_code=cl_err_code
+	if not "!sv_err_code!"=="0" ( set err=1 & echo server error code = !sv_err_code! )
+	if not "!cl_err_code!"=="0" ( set err=1 & echo client error code = !cl_err_code! )
+exit /b !err!
+
+
+:results
+	setlocal
+	set err=%1
+	call :!test_type!__print_output
+	if "!err!"=="2" (
+		echo test failed due to timeout
+	) else (
+		if not "!err!"=="0" (
+			echo UNKNOWN ERROR
+			exit -1
+		) else (
+			call :!test_type!__print_and_check_err_code
+			set err=!errorlevel!
+			if not "!err!"=="0" echo test failed
+		)
+	)
+exit /b !err!
+
+
+
+
+:run
+	setlocal
+	for /f "tokens=1" %%n in ("!test_cmdline!") do set test_exename=%%n.exe
+
+	call :!test_type!__start_job
+	set /a secs=0
+	:run_client_server__WAIT
+		set /a secs=secs+1
+		timeout /t 1 >nul
+		if /I !secs! geq %TEST_FAIL_TIMEOUT% (
+			echo timeout, killing job
+			taskkill /f /im !test_exename! >nul
+			exit /b 2
+		)
+		call :!test_type!__check_is_job_ended || goto :run_client_server__WAIT
+	:run_client_server__WAIT_END
+exit /b 0
+
+
+
+
+
+:test
+	setlocal
+	set test_type=%1
+	for /f "tokens=*" %%n in (%2) do set test_cmdline=%%n
+	echo !test_cmdline!
+
+	call :!test_type!__clear_txt
+	call :run
+	call :results !errorlevel!
+	set err=!errorlevel!
+	call :!test_type!__clear_txt
+exit /b !err!
+
+
+
+
+:run_test__unit
+	call :test single %*
+exit /b
+
+
+:run_test__functional
+	call :test client_server %*
+exit /b
+
+
+:run_test__standard
+	call :test client_server %*
+exit /b
+
+
+:run_test__short
+	call :test client_server %*
+exit /b
+
+
+
+
+:main
+	set /a tests_count=0
+	set /a failed_tests_count=0
+	for %%a in (!test_types!) do (
+		for %%t in (!%%a_tests!) do (
+			set /a tests_count=tests_count+1
+		)
+	)
+
+	for %%a in (!test_types!) do (
+		echo %%a tests:
+		set run=run_test__%%a
+		for %%t in (!%%a_tests!) do (
+			call :!run! %%t || (
+				set failed=!failed! %%t
+				set /a failed_tests_count=failed_tests_count+1
+			)
+		)
+		echo.
+		echo ==============================
+	)
+
+
+	if not "!failed!"=="" (
+		echo !failed_tests_count! of !tests_count! tests failed:
+		for %%t in (!failed!) do (
+			echo %%t
+		)
+		exit /b !failed_tests_count!
+	)
+
+	echo all !tests_count! tests passed
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/runfabtests.sh b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/runfabtests.sh
new file mode 100755
index 000000000..813fa5346
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/runfabtests.sh
@@ -0,0 +1,668 @@
+#!/usr/bin/env bash
+
+#
+# Copyright (c) 2017-2018, Intel Corporation.  All rights reserved.
+# Copyright (c) 2016-2018, Cisco Systems, Inc. All rights reserved.
+# Copyright (c) 2016, Cray, Inc. All rights reserved.
+#
+# This software is available to you under a choice of one of two
+# licenses.  You may choose to be licensed under the terms of the GNU
+# General Public License (GPL) Version 2, available from the file
+# COPYING in the main directory of this source tree, or the
+# BSD license below:
+#
+#     Redistribution and use in source and binary forms, with or
+#     without modification, are permitted provided that the following
+#     conditions are met:
+#
+#      - Redistributions of source code must retain the above
+#        copyright notice, this list of conditions and the following
+#        disclaimer.
+#
+#      - Redistributions in binary form must reproduce the above
+#        copyright notice, this list of conditions and the following
+#        disclaimer in the documentation and/or other materials
+#        provided with the distribution.
+#
+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
+# COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
+# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
+# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+# POSSIBILITY OF SUCH DAMAGE.
+#
+
+trap cleanup_and_exit SIGINT
+
+#
+# Default behavior with no args will use sockets provider with loopback
+#
+declare BIN_PATH
+declare PROV="sockets"
+declare TEST_TYPE="quick"
+declare SERVER="127.0.0.1"
+declare CLIENT="127.0.0.1"
+declare EXCLUDE=""
+declare GOOD_ADDR=""
+declare -i VERBOSE=0
+declare -i SKIP_NEG=0
+declare COMPLEX_CFG
+declare TIMEOUT_VAL="120"
+declare STRICT_MODE=0
+declare REGEX=0
+declare FORK=0
+
+declare -r c_outp=$(mktemp fabtests.c_outp.XXXXXX)
+declare -r s_outp=$(mktemp fabtests.s_outp.XXXXXX)
+
+declare -i skip_count=0
+declare -i pass_count=0
+declare -i fail_count=0
+
+if [[ "$(uname)" == "FreeBSD" ]]; then
+    declare -ri FI_ENODATA=$(python -c 'import errno; print(errno.ENOMSG)')
+else
+    declare -ri FI_ENODATA=$(python -c 'import errno; print(errno.ENODATA)')
+fi
+declare -ri FI_ENOSYS=$(python -c 'import errno; print(errno.ENOSYS)')
+
+neg_unit_tests=(
+	"dgram g00n13s"
+	"rdm g00n13s"
+	"msg g00n13s"
+)
+
+functional_tests=(
+	"av_xfer -e rdm"
+	"av_xfer -e dgram"
+	"cm_data"
+	"cq_data -e msg"
+	"cq_data -e rdm"
+	"cq_data -e dgram"
+	"dgram"
+	"dgram_waitset"
+	"msg"
+	"msg_epoll"
+	"msg_sockets"
+	"poll -t queue"
+	"poll -t counter"
+	"rdm"
+	"rdm_rma_simple"
+	"rdm_rma_trigger"
+	"shared_ctx"
+	"shared_ctx --no-tx-shared-ctx"
+	"shared_ctx --no-rx-shared-ctx"
+	"shared_ctx -e msg"
+	"shared_ctx -e msg --no-tx-shared-ctx"
+	"shared_ctx -e msg --no-rx-shared-ctx"
+	"shared_ctx -e dgram"
+	"shared_ctx -e dgram --no-tx-shared-ctx"
+	"shared_ctx -e dgram --no-rx-shared-ctx"
+	"rdm_tagged_peek"
+	"scalable_ep"
+	"rdm_shared_av"
+	"multi_mr -e msg -V"
+	"multi_mr -e rdm -V"
+	"recv_cancel -e rdm -V"
+	"unexpected_msg -e msg -i 10"
+	"unexpected_msg -e rdm -i 10"
+	"unexpected_msg -e msg -S -i 10"
+	"unexpected_msg -e rdm -S -i 10"
+	"inj_complete -e msg"
+	"inj_complete -e rdm"
+	"inj_complete -e dgram"
+	"inj_complete -e msg -SR"
+	"inj_complete -e rdm -SR"
+	"inj_complete -e dgram -SR"
+)
+
+short_tests=(
+	"msg_pingpong -I 5"
+	"msg_pingpong -I 5 -v"
+	"msg_bw -I 5"
+	"msg_bw -I 5 -v"
+	"rma_bw -e msg -o write -I 5"
+	"rma_bw -e msg -o read -I 5"
+	"rma_bw -e msg -o writedata -I 5"
+	"rma_bw -e rdm -o write -I 5"
+	"rma_bw -e rdm -o read -I 5"
+	"rma_bw -e rdm -o writedata -I 5"
+	"rdm_atomic -I 5 -o all"
+	"rdm_cntr_pingpong -I 5"
+	"rdm_multi_recv -I 5"
+	"rdm_pingpong -I 5"
+	"rdm_pingpong -I 5 -v"
+	"rdm_tagged_pingpong -I 5"
+	"rdm_tagged_pingpong -I 5 -v"
+	"rdm_tagged_bw -I 5"
+	"rdm_tagged_bw -I 5 -v"
+	"dgram_pingpong -I 5"
+)
+
+standard_tests=(
+	"msg_pingpong"
+	"msg_pingpong -v"
+	"msg_pingpong -k"
+	"msg_pingpong -k -v"
+	"msg_bw"
+	"msg_bw -v"
+	"rma_bw -e msg -o write"
+	"rma_bw -e msg -o read"
+	"rma_bw -e msg -o writedata"
+	"rma_bw -e rdm -o write"
+	"rma_bw -e rdm -o read"
+	"rma_bw -e rdm -o writedata"
+	"rdm_atomic -o all -I 1000"
+	"rdm_cntr_pingpong"
+	"rdm_multi_recv"
+	"rdm_pingpong"
+	"rdm_pingpong -v"
+	"rdm_pingpong -k"
+	"rdm_pingpong -k -v"
+	"rdm_tagged_pingpong"
+	"rdm_tagged_pingpong -v"
+	"rdm_tagged_bw"
+	"rdm_tagged_bw -v"
+	"dgram_pingpong"
+	"dgram_pingpong -k"
+)
+
+unit_tests=(
+	"getinfo_test -s SERVER_ADDR GOOD_ADDR"
+	"av_test -g GOOD_ADDR -n 1 -s SERVER_ADDR"
+	"dom_test -n 2"
+	"eq_test"
+	"cq_test"
+	"mr_test"
+	"cntr_test"
+)
+
+complex_tests=(
+	"ubertest"
+)
+
+function errcho {
+	>&2 echo $*
+}
+
+function print_border {
+	printf "# "
+	printf "%.0s-" {1..78}
+	printf "\n"
+}
+
+function print_results {
+	local test_name=$1
+	local test_result=$2
+	local test_time=$3
+	local server_out_file=$4
+	local server_cmd=$5
+	local client_out_file=$6
+	local client_cmd=$7
+
+	if [ $VERBOSE -eq 0 ] ; then
+		# print a simple, single-line format that is still valid YAML
+		printf "%-70s%10s\n" "$test_exe:" "$test_result"
+	else
+		# Print a more detailed YAML format that is not a superset of
+		# the non-verbose output.  See ofiwg/fabtests#259 for a
+		# rationale.
+		emit_stdout=0
+		case $test_result in
+			Pass*)
+				[ $VERBOSE -ge 3 ] && emit_stdout=1
+				;;
+			Notrun|Excluded)
+				[ $VERBOSE -ge 2 ] && emit_stdout=1
+				;;
+			Fail*)
+				[ $VERBOSE -ge 1 ] && emit_stdout=1
+				;;
+		esac
+
+		printf -- "- name:   %s\n" "$test_exe"
+		printf -- "  result: %s\n" "$test_result"
+		printf -- "  time:   %s\n" "$test_time"
+		if [ $emit_stdout -eq 1 -a "$server_out_file" != "" ] ; then
+			if [ "$server_cmd" != "" ] ; then
+				printf -- "  server_cmd: %s\n" "$server_cmd"
+			fi
+			printf -- "  server_stdout: |\n"
+			sed -e 's/^/    /' < $server_out_file
+		fi
+		if [ $emit_stdout -eq 1 -a "$client_out_file" != "" ] ; then
+			if [ "$client_cmd" != "" ] ; then
+				printf -- "  client_cmd: %s\n" "$client_cmd"
+			fi
+			printf -- "  client_stdout: |\n"
+			sed -e 's/^/    /' < $client_out_file
+		fi
+	fi
+}
+
+function cleanup {
+	${CLIENT_CMD} "ps -eo comm,pid | grep '^fi_' | awk '{print \$2}' | xargs kill -9" >& /dev/null
+	${SERVER_CMD} "ps -eo comm,pid | grep '^fi_' | awk '{print \$2}' | xargs kill -9" >& /dev/null
+	rm -f $c_outp $s_outp
+}
+
+function cleanup_and_exit {
+	cleanup
+	exit 1
+}
+
+# compute the duration in seconds between two integer values
+# measured since the start of the UNIX epoch and print the result to stdout
+function compute_duration {
+	local -i s=$1
+	local -i e=$2
+	echo $(( $2 - $1))
+}
+
+function read_exclude_file {
+	exclude_file=$1
+
+	if [ ! -f $exclude_file ]; then
+		echo "Given exclusion file does not exist!"
+		exit 1
+	fi
+
+	while read -r pattern || [[ -n "$pattern" ]]; do
+		# Ignore patterns that are comments or just whitespaces
+		ignore_pattern="#.*|^[\t ]*$"
+		if [[ ! "$pattern" =~ $ignore_pattern ]]; then
+			if [ -z "$EXCLUDE" ]; then
+				EXCLUDE="$pattern"
+			else
+				EXCLUDE="${EXCLUDE},$pattern"
+			fi
+		fi
+	done < "$exclude_file"
+}
+
+function is_excluded {
+	test_name=$1
+
+	[[ -z "$EXCLUDE" ]] && return 1
+
+	IFS="," read -ra exclude_array <<< "$EXCLUDE"
+	for pattern in "${exclude_array[@]}"; do
+		if [[ $REGEX -eq 1 && "$test_name" =~ $pattern ]] ||
+		   [[ "$test_name" == "$pattern" ]]; then
+			print_results "$test_exe" "Excluded" "0" "" ""
+			skip_count+=1
+			return 0
+		fi
+	done
+	return 1
+}
+
+function unit_test {
+	local test=$1
+	local is_neg=$2
+	local ret1=0
+	local test_exe=$(echo "fi_${test} -p \"$PROV\"" | \
+	    sed -e "s/GOOD_ADDR/$GOOD_ADDR/g" -e "s/SERVER_ADDR/${S_INTERFACE}/g")
+	local start_time
+	local end_time
+	local test_time
+
+	is_excluded "$test" && return
+
+	start_time=$(date '+%s')
+
+	cmd="${BIN_PATH}${test_exe}"
+	${SERVER_CMD} "${EXPORT_ENV} $cmd" &> $s_outp &
+	p1=$!
+
+	wait $p1
+	ret=$?
+
+	end_time=$(date '+%s')
+	test_time=$(compute_duration "$start_time" "$end_time")
+
+	if [ $is_neg -eq 1 -a $ret -eq $FI_ENODATA ]; then
+		# negative test passed
+		ret=0
+	elif [ $is_neg -eq 1 ]; then
+		# negative test failed
+		ret=1
+	fi
+	if [[ $STRICT_MODE -eq 0 && $ret -eq $FI_ENODATA || $ret -eq $FI_ENOSYS ]]; then
+		print_results "$test_exe" "Notrun" "$test_time" "$s_outp" "$cmd"
+		skip_count+=1
+	elif [ $ret -ne 0 ]; then
+		print_results "$test_exe" "Fail" "$test_time" "$s_outp" "$cmd"
+		if [ $ret -eq 124 ]; then
+			cleanup
+		fi
+		fail_count+=1
+	else
+		print_results "$test_exe" "Pass" "$test_time" "$s_outp" "$cmd"
+		pass_count+=1
+	fi
+}
+
+function cs_test {
+	local test=$1
+	local s_ret=0
+	local c_ret=0
+	local test_exe="fi_${test} -p \"${PROV}\""
+	local start_time
+	local end_time
+	local test_time
+
+	is_excluded "$test" && return
+
+	start_time=$(date '+%s')
+
+	s_cmd="${BIN_PATH}${test_exe} -s $S_INTERFACE"
+	${SERVER_CMD} "${EXPORT_ENV} $s_cmd" &> $s_outp &
+	s_pid=$!
+	sleep 1
+
+	c_cmd="${BIN_PATH}${test_exe} -s $C_INTERFACE $S_INTERFACE"
+	${CLIENT_CMD} "${EXPORT_ENV} $c_cmd" &> $c_outp &
+	c_pid=$!
+
+	wait $c_pid
+	c_ret=$?
+
+	[[ c_ret -ne 0 ]] && kill -9 $s_pid 2> /dev/null
+
+	wait $s_pid
+	s_ret=$?
+
+	end_time=$(date '+%s')
+	test_time=$(compute_duration "$start_time" "$end_time")
+
+	if [[ $STRICT_MODE -eq 0 && $s_ret -eq $FI_ENODATA && $c_ret -eq $FI_ENODATA ]] ||
+	   [[ $STRICT_MODE -eq 0 && $s_ret -eq $FI_ENOSYS && $c_ret -eq $FI_ENOSYS ]]; then
+		print_results "$test_exe" "Notrun" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+		skip_count+=1
+	elif [ $s_ret -ne 0 -o $c_ret -ne 0 ]; then
+		print_results "$test_exe" "Fail" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+		if [ $s_ret -eq 124 -o $c_ret -eq 124 ]; then
+			cleanup
+		fi
+		fail_count+=1
+	else
+		print_results "$test_exe" "Pass" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+		pass_count+=1
+	fi
+}
+
+function complex_test {
+	local test=$1
+	local config=$2
+	local test_exe="fi_${test}"
+	local s_ret=0
+	local c_ret=0
+	local start_time
+	local end_time
+	local test_time
+
+	is_excluded "$test" && return
+
+	start_time=$(date '+%s')
+
+	if [[ $FORK -eq 1 ]]; then
+		opts="-f"
+	else
+		opts=""
+	fi
+
+	s_cmd="${BIN_PATH}${test_exe} -x $opts"
+	FI_LOG_LEVEL=error ${SERVER_CMD} "${EXPORT_ENV} $s_cmd" &> $s_outp &
+	s_pid=$!
+	sleep 1
+
+	c_cmd="${BIN_PATH}${test_exe} -p \"${PROV}\" -t $config $S_INTERFACE $opts"
+	FI_LOG_LEVEL=error ${CLIENT_CMD} "${EXPORT_ENV} $c_cmd" &> $c_outp &
+	c_pid=$!
+
+	wait $c_pid
+	c_ret=$?
+
+	[[ c_ret -ne 0 ]] && kill -9 $s_pid
+
+	wait $s_pid
+	s_ret=$?
+
+	end_time=$(date '+%s')
+	test_time=$(compute_duration "$start_time" "$end_time")
+
+	# case: config file doesn't exist or invalid option provided
+	if [ $s_ret -eq 1 -o $c_ret -eq 1 ]; then
+		print_results "$test_exe" "Notrun" "0" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+		cleanup
+		skip_count+=1
+		return
+	# case: test didn't run becasue some error occured
+	elif [ $s_ret -ne 0 -o $c_ret -ne 0 ]; then
+		printf "%-50s%s\n" "$test_exe:" "Server returns $s_ret, client returns $c_ret"
+		print_results "$test_exe" "Fail [$f_cnt/$total]" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+                cleanup
+                fail_count+=1
+	else
+		local f_cnt=$(cat $c_outp | awk -F': ' '/ENOSYS|ERROR/ {total += $2} END {print total}')
+		local s_cnt=$(cat $c_outp | awk -F': ' '/Success/ {total += $2} END {print total}')
+		local total=$(cat $c_outp | awk -F': ' '/Success|ENODATA|ENOSYS|ERROR/ {total += $2} END {print total}')
+		if [ $f_cnt -eq 0 ]; then
+			print_results "$test_exe" "Pass [$s_cnt/$total]" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+			pass_count+=1
+		else
+			print_results "$test_exe" "Fail [$f_cnt/$total]" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+			cleanup
+			fail_count+=1
+		fi
+	fi
+}
+
+function main {
+	local complex_cfg="quick"
+
+	if [[ $1 == "quick" ]]; then
+		local -r tests="unit functional short"
+	elif [[ $1 == "verify" ]]; then
+		local -r tests="complex"
+		complex_cfg=$1
+	else
+		local -r tests=$(echo $1 | sed 's/all/unit,functional,standard,complex/g' | tr ',' ' ')
+		if [[ $1 == "all" ]]; then
+			complex_cfg=$1
+		fi
+	fi
+
+	if [[ -n "$COMPLEX_CFG" ]]; then
+		complex_cfg="$COMPLEX_CFG"
+	fi
+
+	if [ $VERBOSE -eq 0 ] ; then
+		printf "# %-68s%10s\n" "Test" "Result"
+		print_border
+	fi
+
+	for ts in ${tests}; do
+	case ${ts} in
+		unit)
+			for test in "${unit_tests[@]}"; do
+				unit_test "$test" "0"
+			done
+
+			if [ $SKIP_NEG -eq 0 ] ; then
+				for test in "${neg_unit_tests[@]}"; do
+					unit_test "$test" "1"
+				done
+			fi
+		;;
+		functional)
+			for test in "${functional_tests[@]}"; do
+				cs_test "$test"
+			done
+		;;
+		short)
+			for test in "${short_tests[@]}"; do
+				cs_test "$test"
+			done
+		;;
+		standard)
+			for test in "${standard_tests[@]}"; do
+				cs_test "$test"
+			done
+		;;
+		complex)
+			for test in "${complex_tests[@]}"; do
+				complex_test $test $complex_cfg
+
+			done
+		;;
+		*)
+			errcho "Unknown test set: ${ts}"
+			exit 1
+		;;
+	esac
+	done
+
+	total=$(( $pass_count + $fail_count ))
+
+	print_border
+
+	printf "# %-50s%10d\n" "Total Pass" $pass_count
+	printf "# %-50s%10d\n" "Total Notrun/Excluded" $skip_count
+	printf "# %-50s%10d\n" "Total Fail" $fail_count
+
+	if [[ "$total" > "0" ]]; then
+		printf "# %-50s%10d\n" "Percentage of Pass" $(( $pass_count * 100 / $total ))
+	fi
+
+	print_border
+
+	cleanup
+	exit $fail_count
+}
+
+function usage {
+	errcho "Usage:"
+	errcho "  $0 [OPTIONS] [provider] [host] [client]"
+	errcho
+	errcho "Run fabtests using provider between host and client (default"
+	errcho "'sockets' provider in loopback-mode).  Report pass/fail/notrun status."
+	errcho
+	errcho "Options:"
+	errcho -e " -g\tgood IP address from <host>'s perspective (default $GOOD_ADDR)"
+	errcho -e " -v\tprint output of failing"
+	errcho -e " -vv\tprint output of failing/notrun"
+	errcho -e " -vvv\tprint output of failing/notrun/passing"
+	errcho -e " -t\ttest set(s): all,quick,unit,functional,standard,short,complex (default quick)"
+	errcho -e " -e\texclude tests: comma delimited list of test names /
+			 regex patterns (with -R) e.g. \"dgram,rma.*write\""
+	errcho -e " -E\texport provided variable name and value to ssh client and server processes.
+			 options must of of the form '-E var=value'"
+	errcho -e " -f\texclude tests file: File containing list of test names /
+			 regex patterns (with -R) to exclude (one per line)"
+	errcho -e " -R\tTreat test exclusions as regex patterns"
+	errcho -e "   \tNote: the test names / patterns for -e and -f options
+			would be matched with the list of test names defined
+			in this script. They don't have fi_ prefix"
+	errcho -e " -N\tskip negative unit tests"
+	errcho -e " -p\tpath to test bins (default PATH)"
+	errcho -e " -c\tclient interface"
+	errcho -e " -s\tserver/host interface"
+	errcho -e " -u\tconfigure option for complex tests"
+	errcho -e " -T\ttimeout value in seconds"
+	errcho -e " -S\tStrict mode: -FI_ENODATA, -FI_ENOSYS errors would be treated as failures instead of skipped/notrun"
+	exit 1
+}
+
+while getopts ":vt:p:g:e:f:c:s:u:T:NRSkE:" opt; do
+case ${opt} in
+	t) TEST_TYPE=$OPTARG
+	;;
+	v) VERBOSE+=1
+	;;
+	p) BIN_PATH="${OPTARG}/"
+	;;
+	g) GOOD_ADDR=${OPTARG}
+	;;
+	f) read_exclude_file ${OPTARG}
+	;;
+	e) [[ -z "$EXCLUDE" ]] && EXCLUDE=${OPTARG} || EXCLUDE="${EXCLUDE},${OPTARG}"
+	;;
+	c) C_INTERFACE=${OPTARG}
+	;;
+	s) S_INTERFACE=${OPTARG}
+	;;
+	u) COMPLEX_CFG=${OPTARG}
+	;;
+	T) TIMEOUT_VAL=${OPTARG}
+	;;
+	N) SKIP_NEG+=1
+	;;
+	R) REGEX=1
+	;;
+	S) STRICT_MODE=1
+	;;
+	k) FORK=1
+	;;
+	E)
+	delimiter="="
+	value=${OPTARG#*$delimiter}
+	var=${OPTARG:0:$(( ${#OPTARG} - ${#value} - ${#delimiter} ))}
+	EXPORT_STRING="export $var=\"$value\""
+	if [[ -z $EXPORT_ENV ]] ; then
+		EXPORT_ENV="$EXPORT_STRING ;"
+	else
+		EXPORT_ENV="$EXPORT_ENV $EXPORT_STRING ;"
+	fi
+	;;
+	:|\?) usage
+	;;
+esac
+
+done
+
+# base ssh command
+declare bssh="ssh -n -o StrictHostKeyChecking=no -o ConnectTimeout=2 -o BatchMode=yes"
+if [ -z "$(which timeout 2> /dev/null)" ]; then
+	# forego timeout
+	declare SERVER_CMD="eval"
+	declare CLIENT_CMD="eval"
+else
+	declare SERVER_CMD="eval timeout ${TIMEOUT_VAL}"
+	declare CLIENT_CMD="eval timeout ${TIMEOUT_VAL}"
+	bssh="timeout ${TIMEOUT_VAL} ${bssh}"
+fi
+
+# shift past options
+shift $((OPTIND-1))
+
+if [[ $# -ge 4 ]]; then
+	usage
+fi
+
+if [[ $# -ge 1 ]]; then
+	PROV=$1
+fi
+
+if [[ $# -ge 2 ]]; then
+	SERVER=$2
+	SERVER_CMD="${bssh} ${SERVER}"
+fi
+
+if [[ $# -ge 3 ]]; then
+	CLIENT=$3
+	CLIENT_CMD="${bssh} ${CLIENT}"
+fi
+
+[ -z $C_INTERFACE ] && C_INTERFACE=$CLIENT
+[ -z $S_INTERFACE ] && S_INTERFACE=$SERVER
+[ -z $GOOD_ADDR ] && GOOD_ADDR=$S_INTERFACE
+
+main ${TEST_TYPE}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/toCSV.py b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/toCSV.py
new file mode 100755
index 000000000..c3b095e35
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/scripts/toCSV.py
@@ -0,0 +1,37 @@
+#!/usr/bin/env python
+
+import sys
+import csv
+from optparse import OptionParser
+
+try:
+	import yaml
+except ImportError:
+	print ("PyYAML library missing, try: yum install pyyaml")
+	sys.exit(1)
+
+def main(argv=None):
+	"""Convert runfabtests.sh yaml output to CSV. If no argument is given
+	   stdin is read, otherwise read from file.
+	"""
+
+	parser = OptionParser(description=main.__doc__, usage="usage: %prog [file]")
+	(options, args) = parser.parse_args()
+
+	if len(args) == 0:
+		fd = sys.stdin
+	else:
+		fd = open(args[0], 'r')
+
+	yi = yaml.load(fd.read())
+
+	csv_fd = csv.writer(sys.stdout, delimiter=",", quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
+	csv_fd.writerow(["Test name", "Status"])
+	
+	for k,v in yi.iteritems():
+		csv_fd.writerow([k, v])
+
+	return 0
+
+if __name__ == "__main__":
+	sys.exit(main(sys.argv))
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/eq_cq.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/eq_cq.test
new file mode 100644
index 000000000..6113eb932
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/eq_cq.test
@@ -0,0 +1,132 @@
+#: "Tests different wait objects for EQ and CQ across sockets and verbs providers"
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/lat_bw.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/lat_bw.test
new file mode 100644
index 000000000..cc184a2dc
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/lat_bw.test
@@ -0,0 +1,79 @@
+#: "Latency and bandwidth tests for all providers"
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_DGRAM,
+		FI_EP_MSG,
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: udp,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxd/ofi_rxd.exclude b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxd/ofi_rxd.exclude
new file mode 100644
index 000000000..a1fa91b18
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxd/ofi_rxd.exclude
@@ -0,0 +1,25 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+^msg|-e msg
+^dgram|-e dgram
+
+# Exclude all prefix tests
+-k
+
+# Exclude tests that use sread/polling until issues are resolved
+-S
+rdm_cntr_pingpong
+poll
+cq_data
+
+# Exclude tests with unsupported capabilities
+rdm_tagged_peek
+cm_data
+trigger
+shared_ctx
+scalable_ep
+shared_av
+multi_mr
+
+# Exclude because it takes too long
+ubertest
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxd/udp.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxd/udp.test
new file mode 100644
index 000000000..51c11120b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxd/udp.test
@@ -0,0 +1,26 @@
+{
+	prov_name: UDP;ofi_rxd,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_SENDDATA,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/ofi_rxm.exclude b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/ofi_rxm.exclude
new file mode 100644
index 000000000..15a9a62af
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/ofi_rxm.exclude
@@ -0,0 +1,19 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+# Exclude all prefix tests
+-k
+
+^msg|-e msg
+^dgram|-e dgram
+
+cm_data
+rdm_rma_simple
+trigger
+shared_ctx
+scalable_ep
+shared_av
+multi_mr
+atomic
+
+# Remove this once ubertest supports setting MR modes
+ubertest
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/verbs/all.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/verbs/all.test
new file mode 100644
index 000000000..24a06be8e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/verbs/all.test
@@ -0,0 +1,110 @@
+#: "Suite of tests for the verbs provider"
+#: "
+# TODO
+#  - Debug WRITEDATA, WRITEMSG, READMSG for RxM before enabling
+#  - Test without FI_MR_LOCAL for RxM
+#  - disable quick test for some configs (takes long time on some fabric)
+#  - Adding more tests results in timeout in runfabtests.sh - fix the script"
+{
+	prov_name: verbs;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+},
+{
+	prov_name: verbs;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+},
+{
+	prov_name: verbs;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SENDMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+	msg_flags: FI_REMOTE_CQ_DATA,
+},
+{
+	prov_name: verbs;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+	test_flags: FT_FLAG_QUICKTEST,
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/verbs/exclude b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/verbs/exclude
new file mode 100644
index 000000000..f30e59359
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/ofi_rxm/verbs/exclude
@@ -0,0 +1,16 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+# Exclude all prefix tests
+-k
+
+^msg|-e msg
+^dgram|-e dgram
+
+cm_data
+rdm_rma_simple
+trigger
+shared_ctx
+scalable_ep
+shared_av
+multi_mr
+atomic
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/osx.exclude b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/osx.exclude
new file mode 100644
index 000000000..3178270c6
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/osx.exclude
@@ -0,0 +1,5 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+# Exclude msg_epoll test as OSX doesn't have epoll system call
+msg_epoll
+msg_sockets
\ No newline at end of file
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm/all.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm/all.test
new file mode 100644
index 000000000..a65a1607d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm/all.test
@@ -0,0 +1,62 @@
+{
+	prov_name: psm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/all.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/all.test
new file mode 100644
index 000000000..e573e602f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/all.test
@@ -0,0 +1,93 @@
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/psm2.exclude b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/psm2.exclude
new file mode 100644
index 000000000..1cee189c1
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/psm2.exclude
@@ -0,0 +1,15 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+# Exclude all prefix tests
+-k
+
+# av_test supports only FI_SOCKADDR
+av_test
+
+^msg|-e msg
+
+cm_data
+shared_ctx
+scalable_ep
+shared_av
+rdm_cntr_pingpong
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/verify.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/verify.test
new file mode 100644
index 000000000..0e2328c14
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/psm2/verify.test
@@ -0,0 +1,246 @@
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_ATOMIC,
+		FT_FUNC_ATOMICV,
+		FT_FUNC_ATOMICMSG,
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+		FT_FUNC_INJECT_ATOMIC,
+	],
+	op:[
+		FI_MIN,
+		FI_MAX,
+		FI_SUM,
+		FI_PROD,
+		FI_LOR,
+		FI_LAND,
+		FI_BOR,
+		FI_BAND,
+		FI_LXOR,
+		FI_BXOR,
+		FI_ATOMIC_WRITE,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+	],
+	op:[
+		FI_ATOMIC_READ,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_COMPARE_ATOMIC,
+		FT_FUNC_COMPARE_ATOMICV,
+		FT_FUNC_COMPARE_ATOMICMSG,
+	],
+	op:[
+		FI_CSWAP,
+		FI_CSWAP_NE,
+		FI_CSWAP_LE,
+		FI_CSWAP_LT,
+		FI_CSWAP_GE,
+		FI_CSWAP_GT,
+		FI_MSWAP,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/shm/all.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/shm/all.test
new file mode 100644
index 000000000..339e9e293
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/shm/all.test
@@ -0,0 +1,407 @@
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_INJECT_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_INJECT_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_ATOMIC,
+		FT_FUNC_ATOMICV,
+		FT_FUNC_ATOMICMSG,
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+		FT_FUNC_INJECT_ATOMIC,
+	],
+	op:[
+		FI_MIN,
+		FI_MAX,
+		FI_SUM,
+		FI_PROD,
+		FI_LOR,
+		FI_LAND,
+		FI_BOR,
+		FI_BAND,
+		FI_LXOR,
+		FI_BXOR,
+		FI_ATOMIC_WRITE,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+	],
+	op:[
+		FI_ATOMIC_READ,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_COMPARE_ATOMIC,
+		FT_FUNC_COMPARE_ATOMICV,
+		FT_FUNC_COMPARE_ATOMICMSG,
+	],
+	op:[
+		FI_CSWAP,
+		FI_CSWAP_NE,
+		FI_CSWAP_LE,
+		FI_CSWAP_LT,
+		FI_CSWAP_GE,
+		FI_CSWAP_GT,
+		FI_MSWAP,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_ATOMIC,
+		FT_FUNC_ATOMICV,
+		FT_FUNC_ATOMICMSG,
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+		FT_FUNC_INJECT_ATOMIC,
+	],
+	op:[
+		FI_MIN,
+		FI_MAX,
+		FI_SUM,
+		FI_PROD,
+		FI_LOR,
+		FI_LAND,
+		FI_BOR,
+		FI_BAND,
+		FI_LXOR,
+		FI_BXOR,
+		FI_ATOMIC_WRITE,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+	],
+	op:[
+		FI_ATOMIC_READ,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_COMPARE_ATOMIC,
+		FT_FUNC_COMPARE_ATOMICV,
+		FT_FUNC_COMPARE_ATOMICMSG,
+	],
+	op:[
+		FI_CSWAP,
+		FI_CSWAP_NE,
+		FI_CSWAP_LE,
+		FI_CSWAP_LT,
+		FI_CSWAP_GE,
+		FI_CSWAP_GT,
+		FI_MSWAP,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/shm/verify.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/shm/verify.test
new file mode 100644
index 000000000..156c4415c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/shm/verify.test
@@ -0,0 +1,401 @@
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_INJECT_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_INJECT_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_ATOMIC,
+		FT_FUNC_ATOMICV,
+		FT_FUNC_ATOMICMSG,
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+		FT_FUNC_INJECT_ATOMIC,
+	],
+	op:[
+		FI_MIN,
+		FI_MAX,
+		FI_SUM,
+		FI_PROD,
+		FI_LOR,
+		FI_LAND,
+		FI_BOR,
+		FI_BAND,
+		FI_LXOR,
+		FI_BXOR,
+		FI_ATOMIC_WRITE,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+	],
+	op:[
+		FI_ATOMIC_READ,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_COMPARE_ATOMIC,
+		FT_FUNC_COMPARE_ATOMICV,
+		FT_FUNC_COMPARE_ATOMICMSG,
+	],
+	op:[
+		FI_CSWAP,
+		FI_CSWAP_NE,
+		FI_CSWAP_LE,
+		FI_CSWAP_LT,
+		FI_CSWAP_GE,
+		FI_CSWAP_GT,
+		FI_MSWAP,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	mr_mode: [
+		FI_MR_VIRT_ADDR,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_ATOMIC,
+		FT_FUNC_ATOMICV,
+		FT_FUNC_ATOMICMSG,
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+		FT_FUNC_INJECT_ATOMIC,
+	],
+	op:[
+		FI_MIN,
+		FI_MAX,
+		FI_SUM,
+		FI_PROD,
+		FI_LOR,
+		FI_LAND,
+		FI_BOR,
+		FI_BAND,
+		FI_LXOR,
+		FI_BXOR,
+		FI_ATOMIC_WRITE,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+	],
+	op:[
+		FI_ATOMIC_READ,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: shm,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_COMPARE_ATOMIC,
+		FT_FUNC_COMPARE_ATOMICV,
+		FT_FUNC_COMPARE_ATOMICMSG,
+	],
+	op:[
+		FI_CSWAP,
+		FI_CSWAP_NE,
+		FI_CSWAP_LE,
+		FI_CSWAP_LT,
+		FI_CSWAP_GE,
+		FI_CSWAP_GT,
+		FI_MSWAP,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/all.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/all.test
new file mode 100644
index 000000000..31080aa8b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/all.test
@@ -0,0 +1,102 @@
+#: "Suite of tests for the sockets provider"
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_DGRAM,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/complete.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/complete.test
new file mode 100644
index 000000000..f4e7a6a9c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/complete.test
@@ -0,0 +1,495 @@
+#: "Suite of tests for the sockets provider"
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_DGRAM,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+		FT_MODE_NONE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	mode: [
+		FT_MODE_ALL,
+		FT_MODE_NONE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	mode: [
+		FT_MODE_ALL,
+		FT_MODE_NONE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_CNTR,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cntr_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	mode: [
+		FT_MODE_ALL,
+		FT_MODE_NONE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_INJECT_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+		FT_MODE_NONE,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_ATOMIC,
+		FT_FUNC_ATOMICV,
+		FT_FUNC_ATOMICMSG,
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+		FT_FUNC_INJECT_ATOMIC,
+	],
+	op:[
+		FI_MIN,
+		FI_MAX,
+		FI_SUM,
+		FI_PROD,
+		FI_LOR,
+		FI_LAND,
+		FI_BOR,
+		FI_BAND,
+		FI_LXOR,
+		FI_BXOR,
+		FI_ATOMIC_WRITE,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+		FT_MODE_NONE,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+	],
+	op:[
+		FI_ATOMIC_READ,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+		FT_MODE_NONE,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_COMPARE_ATOMIC,
+		FT_FUNC_COMPARE_ATOMICV,
+		FT_FUNC_COMPARE_ATOMICMSG,
+	],
+	op:[
+		FI_CSWAP,
+		FI_CSWAP_NE,
+		FI_CSWAP_LE,
+		FI_CSWAP_LT,
+		FI_CSWAP_GE,
+		FI_CSWAP_GT,
+		FI_MSWAP,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+		FT_MODE_NONE,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SENDMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	rx_cq_bind_flags: [
+		FI_SELECTIVE_COMPLETION,
+	],
+	rx_op_flags: [
+		FI_COMPLETION,
+	],
+	msg_flags: [
+		FI_COMPLETION,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SENDMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	rx_cq_bind_flags: [
+		FI_SELECTIVE_COMPLETION,
+	],
+	msg_flags: [
+		FI_COMPLETION,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	rx_cq_bind_flags: [
+		FI_SELECTIVE_COMPLETION,
+	],
+	rx_op_flags: [
+		FI_COMPLETION,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SENDMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+		FT_COMP_CNTR,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	tx_cq_bind_flags: [
+		FI_SELECTIVE_COMPLETION,
+	],
+	msg_flags: [
+		FI_COMPLETION,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/quick.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/quick.test
new file mode 100644
index 000000000..b91373239
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/quick.test
@@ -0,0 +1,251 @@
+#: "Suite of tests for the sockets provider"
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_DGRAM,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+		FI_WAIT_MUTEX_COND,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_INJECT_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_ATOMIC,
+		FT_FUNC_ATOMICV,
+		FT_FUNC_ATOMICMSG,
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+		FT_FUNC_INJECT_ATOMIC,
+	],
+	op:[
+		FI_SUM,
+		FI_PROD,
+	],
+	datatype:[
+		FI_INT8,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+	],
+	op:[
+		FI_ATOMIC_READ,
+	],
+	datatype:[
+		FI_INT8,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_COMPARE_ATOMIC,
+		FT_FUNC_COMPARE_ATOMICV,
+		FT_FUNC_COMPARE_ATOMICMSG,
+	],
+	op:[
+		FI_CSWAP,
+	],
+	datatype:[
+		FI_INT8,
+	],
+	ep_type: [
+		FI_EP_MSG,
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/verify.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/verify.test
new file mode 100644
index 000000000..79ad5084a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/sockets/verify.test
@@ -0,0 +1,279 @@
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_INJECT_WRITE,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_INJECT_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_ATOMIC,
+		FT_FUNC_ATOMICV,
+		FT_FUNC_ATOMICMSG,
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+		FT_FUNC_INJECT_ATOMIC,
+	],
+	op:[
+		FI_MIN,
+		FI_MAX,
+		FI_SUM,
+		FI_PROD,
+		FI_LOR,
+		FI_LAND,
+		FI_BOR,
+		FI_BAND,
+		FI_LXOR,
+		FI_BXOR,
+		FI_ATOMIC_WRITE,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_FETCH_ATOMIC,
+		FT_FUNC_FETCH_ATOMICV,
+		FT_FUNC_FETCH_ATOMICMSG,
+	],
+	op:[
+		FI_ATOMIC_READ,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_COMPARE_ATOMIC,
+		FT_FUNC_COMPARE_ATOMICV,
+		FT_FUNC_COMPARE_ATOMICMSG,
+	],
+	op:[
+		FI_CSWAP,
+		FI_CSWAP_NE,
+		FI_CSWAP_LE,
+		FI_CSWAP_LT,
+		FI_CSWAP_GE,
+		FI_CSWAP_GT,
+		FI_MSWAP,
+	],
+	datatype:[
+		FI_INT8,
+		FI_UINT8,
+		FI_INT16,
+		FI_UINT16,
+		FI_INT32,
+		FI_UINT32,
+		FI_INT64,
+		FI_UINT64,
+		FI_FLOAT,
+		FI_DOUBLE,
+		FI_LONG_DOUBLE,
+		FI_FLOAT_COMPLEX,
+		FI_DOUBLE_COMPLEX,
+		FI_LONG_DOUBLE_COMPLEX,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_ATOMIC,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_SENDMSG,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	msg_flags: FI_REMOTE_CQ_DATA,
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: sockets,
+	test_type: [
+		FT_TEST_UNIT,
+	],
+	class_function: [
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_INJECT_WRITEDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	av_type: [
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	msg_flags: FI_REMOTE_CQ_DATA,
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/tcp/tcp.exclude b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/tcp/tcp.exclude
new file mode 100644
index 000000000..d909078af
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/tcp/tcp.exclude
@@ -0,0 +1,19 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+^dgram| -e dgram
+
+rdm_rma_simple
+rdm_rma_trigger
+shared_ctx
+scalable_ep
+shared_av
+multi_mr
+atomic
+inj_complete -e msg
+unexpected_msg -e msg
+
+# TODO. Following fails with macOS. will fix them later
+cq_data -e rdm
+rdm_tagged_peek
+unexpected_msg -e rdm
+rdm_cntr_pingpong
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/all.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/all.test
new file mode 100644
index 000000000..bb1c20b27
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/all.test
@@ -0,0 +1,40 @@
+#: "Suite of tests for the udp provider"
+{
+	prov_name: udp,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+	],
+	ep_type: [
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/functional.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/functional.test
new file mode 100644
index 000000000..37d7af142
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/functional.test
@@ -0,0 +1,32 @@
+#: "Simple test for the udp provider"
+{
+	prov_name: udp,
+	test_type: [
+		FT_TEST_LATENCY,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/lat_bw.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/lat_bw.test
new file mode 100644
index 000000000..fca389de0
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/lat_bw.test
@@ -0,0 +1,27 @@
+#: "Latency and bandwidth tests for the udp provider"
+{
+	prov_name: udp,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/quick.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/quick.test
new file mode 100644
index 000000000..3a6ae2121
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/quick.test
@@ -0,0 +1,41 @@
+#: "Suite of tests for the udp provider"
+{
+	prov_name: udp,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+	],
+	ep_type: [
+		FI_EP_DGRAM,
+	],
+	av_type: [
+		FI_AV_TABLE,
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/udp.exclude b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/udp.exclude
new file mode 100644
index 000000000..3d545a9ef
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/udp/udp.exclude
@@ -0,0 +1,16 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+^msg
+-e msg
+rdm
+poll
+av_test.*
+eq_test
+mr_test
+cm_data
+cq_data
+cntr_test
+scalable_ep
+shared_ctx
+unexpected_msg
+inj_complete
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/usnic/all.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/usnic/all.test
new file mode 100644
index 000000000..958cc7e52
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/usnic/all.test
@@ -0,0 +1,40 @@
+#: "Suite of tests for the usnic provider"
+{
+	prov_name: usnic,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+	],
+	ep_type: [
+		FI_EP_DGRAM,
+		FI_EP_RDM,
+		FI_EP_MSG
+	],
+	av_type: [
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/usnic/quick.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/usnic/quick.test
new file mode 100644
index 000000000..9ca00afd8
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/usnic/quick.test
@@ -0,0 +1,41 @@
+#: "Suite of tests for the usnic provider"
+{
+	prov_name: usnic,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+	],
+	ep_type: [
+		FI_EP_DGRAM,
+		FI_EP_RDM,
+		FI_EP_MSG,
+	],
+	av_type: [
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+	],
+	mode: [
+		FT_MODE_ALL,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/all.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/all.test
new file mode 100644
index 000000000..d5ec27b76
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/all.test
@@ -0,0 +1,151 @@
+#: "Suite of tests for the verbs provider"
+#: "
+# TODO
+#  - Disable INJECT, INJECTDATA for verbs until the failure is debugged
+#    In pingpong test, we get a FLUSH error on recv CQ but no error on send
+#    queue when we don't read send completions for ibv_post_sends."
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SENDMSG,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	msg_flags: FI_REMOTE_CQ_DATA,
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEDATA,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITEMSG,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	msg_flags: FI_REMOTE_CQ_DATA,
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/exclude b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/exclude
new file mode 100644
index 000000000..04bf7d786
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/exclude
@@ -0,0 +1,18 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+# Exclude all prefix tests
+-k
+
+rdm
+dgram
+
+trigger
+
+# Verbs supports only shared receive context
+shared_ctx$|shared_ctx --no|shared_ctx -e msg$|shared_ctx -e msg --no-rx
+
+scalable_ep
+multi_mr
+recv_cancel
+unexpected_msg
+inj_complete
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/quick.test b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/quick.test
new file mode 100644
index 000000000..a8f0a230d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/test_configs/verbs/quick.test
@@ -0,0 +1,89 @@
+#: "Suite of tests for the verbs provider"
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE
+	],
+	mode: [
+		FT_MODE_ALL
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE
+	],
+	mode: [
+		FT_MODE_ALL
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: verbs,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	mode: [
+		FT_MODE_ALL
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/config.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/config.c
new file mode 100644
index 000000000..96adee308
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/config.c
@@ -0,0 +1,899 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <string.h>
+
+#include "fabtest.h"
+#include "jsmn.h"
+
+
+#define FT_CAP_MSG	FI_MSG | FI_SEND | FI_RECV
+#define FT_CAP_TAGGED	FI_TAGGED | FI_SEND | FI_RECV
+#define FT_CAP_RMA	FI_RMA | FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE
+#define FT_CAP_ATOMIC	FI_ATOMICS | FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE
+
+#define FT_MODE_ALL	FI_CONTEXT | FI_LOCAL_MR /*| FI_MSG_PREFIX*/
+#define FT_MODE_NONE	~0ULL
+
+struct key_t {
+	char *str;
+	size_t offset;
+	enum { VAL_STRING, VAL_NUM } val_type;
+	int val_size;
+};
+
+static struct ft_set test_sets_default[] = {
+	{
+		.prov_name = "sockets",
+		.test_type = {
+			FT_TEST_LATENCY,
+			FT_TEST_BANDWIDTH
+		},
+		.class_function = {
+			FT_FUNC_SEND,
+			FT_FUNC_SENDV,
+			FT_FUNC_SENDMSG
+		},
+		.ep_type = {
+			FI_EP_MSG,
+			FI_EP_DGRAM,
+			FI_EP_RDM
+		},
+		.av_type = {
+			FI_AV_TABLE,
+			FI_AV_MAP
+		},
+		.comp_type = {
+			FT_COMP_QUEUE
+		},
+		.mode = {
+			FT_MODE_ALL
+		},
+		.test_class = {
+			FT_CAP_MSG,
+			FT_CAP_TAGGED,
+//			FT_CAP_RMA,
+//			FT_CAP_ATOMIC
+		},
+		.test_flags = FT_FLAG_QUICKTEST
+	},
+	{
+		.prov_name = "verbs",
+		.test_type = {
+			FT_TEST_LATENCY,
+			FT_TEST_BANDWIDTH
+		},
+		.class_function = {
+			FT_FUNC_SEND,
+			FT_FUNC_SENDV,
+			FT_FUNC_SENDMSG
+		},
+		.ep_type = {
+			FI_EP_MSG,
+		},
+		.comp_type = {
+			FT_COMP_QUEUE
+		},
+		.mode = {
+			FT_MODE_ALL
+		},
+		.test_class = {
+			FT_CAP_MSG,
+		},
+		.test_flags = FT_FLAG_QUICKTEST
+	},
+};
+
+static struct ft_series test_series;
+
+size_t sm_size_array[] = {
+		1 << 0,
+		1 << 1,
+		1 << 2, (1 << 2) + (1 << 1),
+		1 << 3, (1 << 3) + (1 << 2),
+		1 << 4, (1 << 4) + (1 << 3),
+		1 << 5, (1 << 5) + (1 << 4),
+		1 << 6, (1 << 6) + (1 << 5),
+		1 << 7, (1 << 7) + (1 << 6),
+		1 << 8
+};
+const unsigned int sm_size_cnt = (sizeof sm_size_array / sizeof sm_size_array[0]);
+
+size_t med_size_array[] = {
+		1 <<  4,
+		1 <<  5,
+		1 <<  6,
+		1 <<  7, (1 <<  7) + (1 <<  6),
+		1 <<  8, (1 <<  8) + (1 <<  7),
+		1 <<  9, (1 <<  9) + (1 <<  8),
+		1 << 10, (1 << 10) + (1 <<  9),
+		1 << 11, (1 << 11) + (1 << 10),
+		1 << 12, (1 << 12) + (1 << 11),
+		1 << 13, (1 << 13) + (1 << 12),
+		1 << 14
+};
+const unsigned int med_size_cnt = (sizeof med_size_array / sizeof med_size_array[0]);
+
+size_t lg_size_array[] = {
+		1 <<  4,
+		1 <<  5,
+		1 <<  6,
+		1 <<  7, (1 <<  7) + (1 <<  6),
+		1 <<  8, (1 <<  8) + (1 <<  7),
+		1 <<  9, (1 <<  9) + (1 <<  8),
+		1 << 10, (1 << 10) + (1 <<  9),
+		1 << 11, (1 << 11) + (1 << 10),
+		1 << 12, (1 << 12) + (1 << 11),
+		1 << 13, (1 << 13) + (1 << 12),
+		1 << 14, (1 << 14) + (1 << 13),
+		1 << 15, (1 << 15) + (1 << 14),
+		1 << 16, (1 << 16) + (1 << 15),
+		1 << 17, (1 << 17) + (1 << 16),
+		1 << 18, (1 << 18) + (1 << 17),
+		1 << 19, (1 << 19) + (1 << 18),
+		1 << 20, (1 << 20) + (1 << 19),
+		1 << 21, (1 << 21) + (1 << 20),
+		1 << 22, (1 << 22) + (1 << 21),
+};
+const unsigned int lg_size_cnt = (sizeof lg_size_array / sizeof lg_size_array[0]);
+
+static struct key_t keys[] = {
+	{
+		.str = "node",
+		.offset = offsetof(struct ft_set, node),
+		.val_type = VAL_STRING,
+	},
+	{
+		.str = "service",
+		.offset = offsetof(struct ft_set, service),
+		.val_type = VAL_STRING,
+	},
+	{
+		.str = "prov_name",
+		.offset = offsetof(struct ft_set, prov_name),
+		.val_type = VAL_STRING,
+	},
+	{
+		.str = "test_type",
+		.offset = offsetof(struct ft_set, test_type),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->test_type) / FT_MAX_TEST,
+	},
+	{
+		.str = "class_function",
+		.offset = offsetof(struct ft_set, class_function),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->class_function) / FT_MAX_FUNCTIONS,
+	},
+	{
+		.str = "ep_type",
+		.offset = offsetof(struct ft_set, ep_type),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->ep_type) / FT_MAX_EP_TYPES,
+	},
+	{
+		.str = "av_type",
+		.offset = offsetof(struct ft_set, av_type),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->av_type) / FT_MAX_AV_TYPES,
+	},
+	{
+		.str = "comp_type",
+		.offset = offsetof(struct ft_set, comp_type),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->comp_type) / FT_MAX_COMP,
+	},
+	{
+		.str = "eq_wait_obj",
+		.offset = offsetof(struct ft_set, eq_wait_obj),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->eq_wait_obj) / FT_MAX_WAIT_OBJ,
+	},
+	{
+		.str = "cq_wait_obj",
+		.offset = offsetof(struct ft_set, cq_wait_obj),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->cq_wait_obj) / FT_MAX_WAIT_OBJ,
+	},
+	{
+		.str = "cntr_wait_obj",
+		.offset = offsetof(struct ft_set, cntr_wait_obj),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->cntr_wait_obj) / FT_MAX_WAIT_OBJ,
+	},
+	{
+		.str = "op",
+		.offset = offsetof(struct ft_set, op),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->op) / FI_ATOMIC_OP_LAST,
+	},
+	{
+		.str = "datatype",
+		.offset = offsetof(struct ft_set, datatype),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->datatype) / FI_DATATYPE_LAST,
+	},
+	{
+		.str = "mode",
+		.offset = offsetof(struct ft_set, mode),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->mode) / FT_MAX_PROV_MODES,
+	},
+	{
+		.str = "test_class",
+		.offset = offsetof(struct ft_set, test_class),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->test_class) / FT_MAX_CLASS,
+	},
+	{
+		.str = "constant_caps",
+		.offset = offsetof(struct ft_set, constant_caps),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->constant_caps) / FT_MAX_CAPS,
+	},
+	{
+		.str = "rx_cq_bind_flags",
+		.offset = offsetof(struct ft_set, rx_cq_bind_flags),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->rx_cq_bind_flags) / FT_MAX_FLAGS,
+	},
+	{
+		.str = "tx_cq_bind_flags",
+		.offset = offsetof(struct ft_set, tx_cq_bind_flags),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->tx_cq_bind_flags) / FT_MAX_FLAGS,
+	},
+	{
+		.str = "rx_op_flags",
+		.offset = offsetof(struct ft_set, rx_op_flags),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->rx_op_flags) / FT_MAX_FLAGS,
+	},
+	{
+		.str = "tx_op_flags",
+		.offset = offsetof(struct ft_set, tx_op_flags),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->tx_op_flags) / FT_MAX_FLAGS,
+	},
+	{
+		.str = "test_flags",
+		.offset = offsetof(struct ft_set, test_flags),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->test_flags),
+	},
+	{
+		.str = "msg_flags",
+		.offset = offsetof(struct ft_set, msg_flags),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->msg_flags),
+	},
+	{
+		.str = "mr_mode",
+		.offset = offsetof(struct ft_set, mr_mode),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->mr_mode) / FT_MAX_MR_MODES,
+	},
+	{
+		.str = "progress",
+		.offset = offsetof(struct ft_set, progress),
+		.val_type = VAL_NUM,
+		.val_size = sizeof(((struct ft_set *)0)->progress) / FT_MAX_PROGRESS,
+	}
+};
+
+static int ft_parse_num(char *str, int len, struct key_t *key, void *buf)
+{
+	if (!strncmp(key->str, "test_type", strlen("test_type"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FT_TEST_LATENCY, enum ft_test_type, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_TEST_BANDWIDTH, enum ft_test_type, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_TEST_UNIT, enum ft_test_type, buf);
+		FT_ERR("Unknown test_type");
+	} else if (!strncmp(key->str, "class_function", strlen("class_function"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_SEND, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_SENDV, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_SENDMSG, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_INJECT, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_INJECTDATA, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_SENDDATA, enum ft_class_function, buf);
+
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_WRITE, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_WRITEV, enum ft_class_function, buf);	
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_WRITEMSG, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_WRITEDATA, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_INJECT_WRITE, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_INJECT_WRITEDATA, enum ft_class_function, buf);
+		
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_READ, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_READV, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_READMSG, enum ft_class_function, buf);
+
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_ATOMIC, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_ATOMICV, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_ATOMICMSG, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_INJECT_ATOMIC, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_FETCH_ATOMIC, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_FETCH_ATOMICV, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_FETCH_ATOMICMSG, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_COMPARE_ATOMIC, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_COMPARE_ATOMICV, enum ft_class_function, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_FUNC_COMPARE_ATOMICMSG, enum ft_class_function, buf);
+
+		FT_ERR("Unknown class_function");
+	} else if (!strncmp(key->str, "ep_type", strlen("ep_type"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_EP_MSG, enum fi_ep_type, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_EP_DGRAM, enum fi_ep_type, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_EP_RDM, enum fi_ep_type, buf);
+		FT_ERR("Unknown ep_type");
+	} else if (!strncmp(key->str, "av_type", strlen("av_type"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_AV_MAP, enum fi_av_type, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_AV_TABLE, enum fi_av_type, buf);
+		FT_ERR("Unknown av_type");
+	} else if (!strncmp(key->str, "test_class", strlen("test_class"))) {
+		TEST_SET_N_RETURN(str, len, "FT_CAP_MSG", FT_CAP_MSG, uint64_t, buf);
+		TEST_SET_N_RETURN(str, len, "FT_CAP_TAGGED", FT_CAP_TAGGED, uint64_t, buf);
+		TEST_SET_N_RETURN(str, len, "FT_CAP_RMA", FT_CAP_RMA, uint64_t, buf);
+		TEST_SET_N_RETURN(str, len, "FT_CAP_ATOMIC", FT_CAP_ATOMIC, uint64_t, buf);
+		FT_ERR("Unknown test class");
+	} else if (!strncmp(key->str, "eq_wait_obj", strlen("eq_wait_obj")) ||
+		!strncmp(key->str, "cq_wait_obj", strlen("cq_wait_obj")) ||
+		!strncmp(key->str, "cntr_wait_obj", strlen("cntr_wait_obj"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_WAIT_NONE, enum fi_wait_obj, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_WAIT_UNSPEC, enum fi_wait_obj, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_WAIT_FD, enum fi_wait_obj, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_WAIT_MUTEX_COND, enum fi_wait_obj, buf);
+		FT_ERR("Unknown wait_obj");
+	} else if (!strncmp(key->str, "op", strlen("op"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_MIN, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_MAX, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_SUM, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_PROD, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_LOR, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_LAND, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_BOR, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_BAND, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_LXOR, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_BXOR, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_ATOMIC_READ, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_ATOMIC_WRITE, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_CSWAP, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_CSWAP_NE, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_CSWAP_LE, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_CSWAP_LT, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_CSWAP_GE, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_CSWAP_GT, enum fi_op, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_MSWAP, enum fi_op, buf);
+		FT_ERR("Unknown op");
+	} else if (!strncmp(key->str, "datatype", strlen("datatype"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_INT8, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_UINT8, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_INT16, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_UINT16, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_INT32, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_UINT32, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_INT64, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_UINT64, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_FLOAT, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_DOUBLE, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_FLOAT_COMPLEX, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_DOUBLE_COMPLEX, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_LONG_DOUBLE, enum fi_datatype, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_LONG_DOUBLE_COMPLEX, enum fi_datatype, buf);
+		FT_ERR("Unknown datatype");
+	} else if (!strncmp(key->str, "msg_flags", strlen("msg_flags"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_REMOTE_CQ_DATA, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_COMPLETION, uint64_t, buf);
+		FT_ERR("Unknown message flag");
+	} else if (!strncmp(key->str, "mr_mode", strlen("mr_mode"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_MR_LOCAL, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_MR_VIRT_ADDR, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_MR_ALLOCATED, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_MR_PROV_KEY, uint64_t, buf);
+		FT_ERR("Unknown MR mode");
+	} else if (!strncmp(key->str, "progress", strlen("progress"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_PROGRESS_MANUAL, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_PROGRESS_AUTO, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_PROGRESS_UNSPEC, uint64_t, buf);
+		FT_ERR("Unknown progress mode");
+	} else if (!strncmp(key->str, "constant_caps", strlen("constant_caps"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_RMA, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_MSG, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_SEND, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_RECV, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_READ, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_WRITE, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_REMOTE_READ, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_REMOTE_WRITE, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_TAGGED, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_DIRECTED_RECV, uint64_t, buf);
+		FT_ERR("Unknown caps");
+	} else if (!strncmp(key->str, "rx_cq_bind_flags", strlen("rx_cq_bind_flags"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_SELECTIVE_COMPLETION, uint64_t, buf);
+		FT_ERR("Unknown rx_cq_bind_flags");
+	} else if (!strncmp(key->str, "tx_cq_bind_flags", strlen("tx_cq_bind_flags"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_SELECTIVE_COMPLETION, uint64_t, buf);
+		FT_ERR("Unknown tx_cq_bind_flags");
+	} else if (!strncmp(key->str, "rx_op_flags", strlen("rx_op_flags"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_COMPLETION, uint64_t, buf);
+		FT_ERR("Unknown rx_op_flags");
+	} else if (!strncmp(key->str, "tx_op_flags", strlen("tx_op_flags"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_COMPLETION, uint64_t, buf);
+		FT_ERR("Unknown tx_op_flags");
+	} else {
+		TEST_ENUM_SET_N_RETURN(str, len, FT_COMP_QUEUE, enum ft_comp_type, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_COMP_CNTR, enum ft_comp_type, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FT_COMP_ALL, enum ft_comp_type, buf);
+		TEST_SET_N_RETURN(str, len, "FT_MODE_ALL", FT_MODE_ALL, uint64_t, buf);
+		TEST_SET_N_RETURN(str, len, "FT_MODE_NONE", FT_MODE_NONE, uint64_t, buf);
+		TEST_SET_N_RETURN(str, len, "FT_FLAG_QUICKTEST", FT_FLAG_QUICKTEST, uint64_t, buf);
+		FT_ERR("Unknown comp_type/mode/test_flags");
+	}
+
+	return -1;
+}
+
+static int ft_parse_key_val(char *config, jsmntok_t *token, char *test_set)
+{
+	int i, parsed = 0;
+	jsmntok_t *key_token = token;
+	jsmntok_t *val_token = token + 1;
+	struct key_t *key = NULL;
+	int size = 0;
+
+	if (!strncmp(config + key_token->start, "#", 1)) {
+		parsed += 2;
+		return parsed;
+	}
+
+	for (i = 0; i < sizeof(keys) / sizeof(keys[0]); i++) {
+		if (!strncmp(config + key_token->start, keys[i].str, strlen(keys[i].str))) {
+			key = &keys[i];
+			parsed++;
+			break;
+		}
+	}
+
+	if (!key) {
+		FT_ERR("Unknown key");
+		return -1;
+	}
+
+	switch(val_token->type) {
+	case JSMN_PRIMITIVE:
+	case JSMN_STRING:
+		size = 1;
+		break;
+	case JSMN_ARRAY:
+		size = val_token->size;
+		val_token++;
+		parsed++;
+		break;
+	default:
+		FT_ERR("[jsmn] Unknown token type");
+		return -1;
+	}
+
+	for (i = 0; i < size; i++) {
+		switch(key->val_type) {
+		case VAL_STRING:
+			memcpy(test_set + key->offset + key->val_size * i,
+					config + val_token[i].start,
+					val_token[i].end - val_token[i].start);
+			break;
+		case VAL_NUM:
+			if (ft_parse_num(config + val_token[i].start,
+					val_token[i].end - val_token[i].start, key,
+					test_set + key->offset + key->val_size * i) < 0)
+				return -1;
+			break;
+		default:
+			FT_ERR("Invalid key->val_type");
+			return -1;
+		}
+		parsed++;
+	}
+
+	return parsed;
+}
+
+static int ft_parse_config(char *config, int size,
+		struct ft_set **test_sets_out, int *nsets)
+{
+	struct ft_set *test_sets;
+	jsmn_parser parser;
+	jsmntok_t *tokens;
+	int num_tokens, num_tokens_parsed;
+	int i, ret, ts_count, ts_index;
+
+	jsmn_init(&parser);
+	num_tokens = jsmn_parse(&parser, config, size, NULL, 0);
+	if (num_tokens <= 0)
+		return 1;
+
+	tokens = malloc(sizeof(jsmntok_t) * num_tokens);
+	if (!tokens)
+		return 1;
+
+	/* jsmn parser returns a list of JSON tokens (jsmntok_t)
+	 * e.g. JSMN_OBJECT
+	 * 	JSMN_STRING : <key>
+	 * 	JSMN_STRING : <value>
+	 * 	JSMN_STRING : <key>
+	 * 	JSMN_ARRAY  : <value: array with 2 elements>
+	 * 	JSMN_STRING
+	 * 	JSMN_STRING
+	 * 	JSMN_STRING : <key>
+	 * 	JSMN_STRING : <value>
+	 * In our case, JSMN_OBJECT would represent a ft_set structure. The rest 
+	 * of the tokens would be treated as key-value pairs. The first JSMN_STRING 
+	 * would represent a key and the next would represent a value. A value
+	 * can also be an array. jsmntok_t.size would represent the length of
+	 * the array.
+	 */
+	jsmn_init(&parser);
+	ret = jsmn_parse(&parser, config, size, tokens, num_tokens);
+	if (ret < 0) {
+		switch (ret) {
+		case JSMN_ERROR_INVAL:
+			FT_ERR("[jsmn] bad token, JSON string is corrupted!");
+			break;
+		case JSMN_ERROR_NOMEM:
+			FT_ERR("[jsmn] not enough tokens, JSON string is too large!");
+			break;
+		case JSMN_ERROR_PART:
+			FT_ERR("[jsmn] JSON string is too short, expecting more JSON data!");
+			break;
+		default:
+			FT_ERR("[jsmn] Unknown error!");
+			break;
+		}
+		goto err1;
+	}
+
+	if (ret != num_tokens) {
+		FT_ERR("[jsmn] Expected # of tokens: %d, Got: %d", num_tokens, ret);
+		goto err1;
+	}
+
+	for (i = 0, ts_count = 0; i < num_tokens; i++) {
+		if (tokens[i].type == JSMN_OBJECT)
+			ts_count++;
+	}
+
+	test_sets = calloc(ts_count, sizeof(struct ft_set));
+
+	for (i = 0, ts_index = -1; i < num_tokens;) {
+		switch (tokens[i].type) {
+		case JSMN_OBJECT:
+			ts_index++;
+			i++;
+			break;
+		case JSMN_PRIMITIVE:
+		case JSMN_STRING:
+			num_tokens_parsed = ft_parse_key_val(config, &tokens[i],
+					(char *)(test_sets + ts_index));
+		        if (num_tokens_parsed <= 0)	{
+				FT_ERR("Error parsing config!");
+				goto err2;
+			}
+			i += num_tokens_parsed;
+			break;
+		default:
+			FT_ERR("[jsmn] Unknown token!");
+			goto err2;
+		}
+	}
+
+	*test_sets_out = test_sets;
+	*nsets = ts_count;
+
+	free(tokens);
+	return 0;
+err2:
+	free(test_sets);
+err1:
+	free(tokens);
+	return 1;
+}
+
+struct ft_series *fts_load(char *filename)
+{
+	int nsets = 0;
+	char *config;
+	FILE *fp;
+
+	if (filename) {
+		int size;
+		struct ft_set *test_sets = NULL;
+
+		fp = fopen(filename, "rb");
+		if (!fp) {
+			FT_ERR("Unable to open config file: %s\n", filename);
+			return NULL;
+		}
+
+		fseek(fp, 0, SEEK_END);
+		size = ftell(fp);
+		if (size < 0) {
+			FT_ERR("ftell error");
+			goto err1;
+		}
+		fseek(fp, 0, SEEK_SET);
+
+		config = malloc(size + 1);
+		if (!config) {
+			FT_ERR("Unable to allocate memory");
+			goto err1;
+		}
+
+		if (fread(config, size, 1, fp) != 1) {
+			FT_ERR("Error reading config file");
+			goto err2;
+		}
+
+		config[size] = 0;
+
+		if (ft_parse_config(config, size, &test_sets, &nsets)) {
+			FT_ERR("Unable to parse file");
+			goto err2;
+		}
+
+		test_series.sets = test_sets;
+		test_series.nsets = nsets;
+		free(config);
+		fclose(fp);
+	} else {
+		printf("No config file given. Using default tests.\n");
+		test_series.sets = test_sets_default;
+		test_series.nsets = sizeof(test_sets_default) / sizeof(test_sets_default[0]);
+	}
+
+	for (fts_start(&test_series, 0); !fts_end(&test_series, 0);
+	     fts_next(&test_series))
+		test_series.test_count++;
+	fts_start(&test_series, 0);
+
+	printf("Test configurations loaded: %d\n", test_series.test_count);
+	return &test_series;
+
+err2:
+	free(config);
+err1:
+	fclose(fp);
+	return NULL;
+}
+
+void fts_close(struct ft_series *series)
+{
+	if (series->sets != test_sets_default)
+		free(series->sets);
+}
+
+void fts_start(struct ft_series *series, int index)
+{
+	series->cur_set = 0;
+	series->cur_type = 0;
+	series->cur_ep = 0;
+	series->cur_av = 0;
+	series->cur_comp = 0;
+	series->cur_eq_wait_obj = 0;
+	series->cur_cq_wait_obj = 0;
+	series->cur_cntr_wait_obj = 0;
+	series->cur_mode = 0;
+	series->cur_class = 0;
+	series->cur_progress = 0;
+
+	series->test_index = 1;
+	if (index > 1) {
+		for (; !fts_end(series, index - 1); fts_next(series))
+			;
+	}
+}
+
+int fts_info_is_valid(void)
+{
+	if (test_info.msg_flags && !is_msg_func(test_info.class_function))
+		return 0;
+
+	if (test_info.rx_cq_bind_flags & FI_SELECTIVE_COMPLETION &&
+	    !(test_info.rx_op_flags & FI_COMPLETION) &&
+	    !(test_info.msg_flags & FI_COMPLETION))
+		return 0;
+
+	if (test_info.test_class & (FI_MSG | FI_TAGGED) &&
+	    !ft_check_rx_completion(test_info) &&
+	    !ft_use_comp_cntr(test_info.comp_type))
+		return 0;
+	if (test_info.test_type == FT_TEST_UNIT &&
+	    test_info.ep_type == FI_EP_DGRAM)
+		return 0;
+
+	return 1;
+}
+
+void fts_next(struct ft_series *series)
+{
+	struct ft_set *set;
+
+	if (fts_end(series, 0))
+		return;
+
+	series->test_index++;
+	set = &series->sets[series->cur_set];
+
+	if (set->test_class[++series->cur_class])
+		return;
+	series->cur_class = 0;
+
+	if (set->mode[++series->cur_mode])
+		return;
+	series->cur_mode = 0;
+
+	if (set->class_function[++series->cur_func])
+		return;
+	series->cur_func = 0;
+
+	if (set->op[++series->cur_op])
+		return;
+	series->cur_op = 0;
+
+	if (set->datatype[++series->cur_datatype])
+		return;
+	series->cur_datatype = 0;
+
+	if (set->comp_type[++series->cur_comp])
+		return;
+	series->cur_comp = 0;
+
+	if (set->eq_wait_obj[++series->cur_eq_wait_obj])
+		return;
+	series->cur_eq_wait_obj = 0;
+
+	if (set->cq_wait_obj[++series->cur_cq_wait_obj])
+		return;
+	series->cur_cq_wait_obj = 0;
+
+	if (set->cntr_wait_obj[++series->cur_cntr_wait_obj])
+		return;
+	series->cur_cntr_wait_obj = 0;
+
+	if (set->ep_type[series->cur_ep] == FI_EP_RDM ||
+	    set->ep_type[series->cur_ep] == FI_EP_DGRAM) {
+		if (set->av_type[++series->cur_av])
+			return;
+	}
+	series->cur_av = 0;
+
+	if (set->ep_type[++series->cur_ep])
+		return;
+	series->cur_ep = 0;
+
+	if (set->test_type[++series->cur_type])
+		return;
+	series->cur_type = 0;
+
+	if (set->test_class[++series->cur_progress])
+		return;
+	series->cur_progress = 0;
+
+	series->cur_set++;
+}
+
+int fts_end(struct ft_series *series, int index)
+{
+	return (series->cur_set >= series->nsets) ||
+		((index > 0) && (series->test_index > index));
+}
+
+void fts_cur_info(struct ft_series *series, struct ft_info *info)
+{
+	static struct ft_set *set;
+	int i = 0;
+
+	memset(info, 0, sizeof *info);
+	if (series->cur_set >= series->nsets)
+		return;
+
+	set = &series->sets[series->cur_set];
+	info->test_type = set->test_type[series->cur_type];
+	info->test_index = series->test_index;
+	info->class_function = set->class_function[series->cur_func];
+	info->msg_flags = set->msg_flags;
+	info->op = set->op[series->cur_op];
+	info->datatype = set->datatype[series->cur_datatype];
+	info->test_flags = set->test_flags;
+	info->test_class = set->test_class[series->cur_class];
+	info->progress = set->progress[series->cur_progress];
+
+	if (info->test_class) {
+		info->caps = set->test_class[series->cur_class];
+		if (info->caps & (FT_CAP_RMA | FT_CAP_ATOMIC))
+			info->caps |= FT_CAP_MSG;
+	}
+
+	if (set->constant_caps[0]) {
+		i = 0;
+		while (set->constant_caps[i])
+			info->caps |= set->constant_caps[i++];
+	}
+	if (set->mr_mode[0]) {
+		i = 0;
+		while (set->mr_mode[i])
+			info->mr_mode |= set->mr_mode[i++];
+	}
+	if (set->rx_cq_bind_flags[0]) {
+		i = 0;
+		while (set->rx_cq_bind_flags[i])
+			info->rx_cq_bind_flags |= set->rx_cq_bind_flags[i++];
+	}
+	if (set->tx_cq_bind_flags[0]) {
+		i = 0;
+		while (set->tx_cq_bind_flags[i])
+			info->tx_cq_bind_flags |= set->tx_cq_bind_flags[i++];
+	}
+	if (set->rx_op_flags[0]) {
+		i = 0;
+		while (set->rx_op_flags[i])
+			info->rx_op_flags |= set->rx_op_flags[i++];
+	}
+	if (set->tx_op_flags[0]) {
+		i = 0;
+		while (set->tx_op_flags[i])
+			info->tx_op_flags |= set->tx_op_flags[i++];
+	}
+
+	info->mode = (set->mode[series->cur_mode] == FT_MODE_NONE) ?
+			0 : set->mode[series->cur_mode];
+
+	info->ep_type = set->ep_type[series->cur_ep];
+	info->av_type = set->av_type[series->cur_av];
+	if (set->comp_type[0])
+		info->comp_type = set->comp_type[series->cur_comp];
+	else
+		info->comp_type = FT_COMP_QUEUE;
+
+	if (info->caps & (FT_CAP_RMA | FT_CAP_ATOMIC) &&
+		(ft_use_comp_cntr(info->comp_type)))
+		info->caps |= FI_RMA_EVENT;
+	info->eq_wait_obj = set->eq_wait_obj[series->cur_eq_wait_obj];
+	info->cntr_wait_obj = set->cntr_wait_obj[series->cur_cntr_wait_obj];
+
+	if (set->node[0])
+		strncpy(info->node, set->node, sizeof(info->node) - 1);
+	else if (opts.dst_addr)
+		strncpy(info->node, opts.dst_addr, sizeof(info->node) - 1);
+	if (set->service[0])
+		strncpy(info->service, set->service, sizeof(info->service) - 1);
+	else if (opts.dst_port)
+		strncpy(info->service, opts.dst_port, sizeof(info->service) - 1);
+	strncpy(info->prov_name, set->prov_name, sizeof(info->prov_name) - 1);
+
+	info->node[sizeof(info->node) - 1] = '\0';
+	info->service[sizeof(info->service) - 1] = '\0';
+	info->prov_name[sizeof(info->prov_name) - 1] = '\0';
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/connect.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/connect.c
new file mode 100644
index 000000000..a86b57647
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/connect.c
@@ -0,0 +1,122 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <string.h>
+
+#include "fabtest.h"
+
+static int ft_accept(void)
+{
+	struct fi_eq_cm_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int ret;
+
+	rd = ft_get_event(&event, &entry, sizeof entry,
+			  FI_CONNREQ, sizeof entry);
+	if (rd < 0)
+		return (int) rd;
+
+	fabric_info = entry.info;
+	ret = ft_open_active();
+	if (ret)
+		return ret;
+
+	ret = fi_accept(ep, NULL, 0);
+	if (ret) {
+		FT_PRINTERR("fi_accept", ret);
+		return ret;
+	}
+
+	rd = ft_get_event(&event, &entry, sizeof entry,
+			  FI_CONNECTED, sizeof entry);
+	if (rd < 0)
+		return (int) rd;
+
+	return 0;
+}
+
+static int ft_connect(void)
+{
+	struct fi_eq_cm_entry entry;
+	uint32_t event;
+	ssize_t rd;
+	int ret;
+
+	ret = fi_connect(ep, fabric_info->dest_addr, NULL, 0);
+	if (ret) {
+		FT_PRINTERR("fi_connect", ret);
+		return ret;
+	}
+
+	rd = ft_get_event(&event, &entry, sizeof entry,
+			  FI_CONNECTED, sizeof entry);
+	if (rd < 0)
+		return (int) rd;
+
+	return 0;
+}
+
+static int ft_load_av(void)
+{
+	struct ft_msg msg;
+	size_t len;
+	int ret;
+
+	memset(&msg, 0, sizeof(struct ft_msg));
+	len = sizeof(msg.data);
+	ret = fi_getname(&ep->fid, msg.data, &len);
+	if (ret) {
+		FT_PRINTERR("fi_getname", ret);
+		return ret;
+	}
+
+	msg.len = (uint32_t) len;
+	ret = ft_sock_send(sock, &msg, sizeof msg);
+	if (ret)
+		return ret;
+
+	ret = ft_sock_recv(sock, &msg, sizeof msg);
+	if (ret)
+		return ret;
+
+	ret = ft_av_insert(av, msg.data, 1, &ft_tx_ctrl.addr, 0, NULL);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int ft_enable_comm(void)
+{
+	if (test_info.ep_type == FI_EP_MSG)
+		return pep ? ft_accept() : ft_connect();
+	else
+		return ft_load_av();
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/cq.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/cq.c
new file mode 100644
index 000000000..ebdfa0db9
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/cq.c
@@ -0,0 +1,390 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <string.h>
+
+#include "fabtest.h"
+
+
+static size_t comp_entry_cnt[] = {
+	[FI_CQ_FORMAT_UNSPEC] = 0,
+	[FI_CQ_FORMAT_CONTEXT] = FT_COMP_BUF_SIZE / sizeof(struct fi_cq_entry),
+	[FI_CQ_FORMAT_MSG] = FT_COMP_BUF_SIZE / sizeof(struct fi_cq_msg_entry),
+	[FI_CQ_FORMAT_DATA] = FT_COMP_BUF_SIZE / sizeof(struct fi_cq_data_entry),
+	[FI_CQ_FORMAT_TAGGED] = FT_COMP_BUF_SIZE / sizeof(struct fi_cq_tagged_entry)
+};
+
+/*
+static size_t comp_entry_size[] = {
+	[FI_CQ_FORMAT_UNSPEC] = 0,
+	[FI_CQ_FORMAT_CONTEXT] = sizeof(struct fi_cq_entry),
+	[FI_CQ_FORMAT_MSG] = sizeof(struct fi_cq_msg_entry),
+	[FI_CQ_FORMAT_DATA] = sizeof(struct fi_cq_data_entry),
+	[FI_CQ_FORMAT_TAGGED] = sizeof(struct fi_cq_tagged_entry)
+};
+*/
+
+int ft_use_comp_cntr(enum ft_comp_type comp_type)
+{
+	if ((comp_type == FT_COMP_CNTR) ||
+		(comp_type == FT_COMP_ALL))
+		return 1;
+
+	return 0;
+}
+
+int ft_use_comp_cq(enum ft_comp_type comp_type)
+{
+	if ((comp_type == FT_COMP_QUEUE) ||
+		(comp_type == FT_COMP_ALL))
+		return 1;
+
+	return 0;
+}
+
+int ft_generates_rx_comp(void)
+{
+	if (is_data_func(test_info.class_function) ||
+	    (is_msg_func(test_info.class_function) &&
+	    test_info.msg_flags & FI_REMOTE_CQ_DATA))
+		return 1;
+
+	if (test_info.test_class & (FI_RMA | FI_ATOMIC))
+		return 0;
+
+	if (!(test_info.rx_cq_bind_flags & FI_SELECTIVE_COMPLETION))
+		return 1;
+	if (test_info.rx_op_flags & FI_COMPLETION) {
+		if (is_msg_func(test_info.class_function) &&
+		    !(test_info.msg_flags & FI_COMPLETION))
+			return 0;
+		return 1;
+	}
+	if (is_msg_func(test_info.class_function) &&
+	    test_info.msg_flags & FI_COMPLETION)
+		return 1;
+	return 0;
+}
+
+int ft_generates_tx_comp(void)
+{
+	if (!(test_info.tx_cq_bind_flags & FI_SELECTIVE_COMPLETION)) {
+		if (is_inject_func(test_info.class_function))
+			return 0;
+		return 1;
+	}
+
+	if (test_info.tx_op_flags & FI_COMPLETION) {
+		if (is_msg_func(test_info.class_function) &&
+		    !(test_info.msg_flags & FI_COMPLETION))
+			return 0;
+		return 1;
+	}
+
+	if (test_info.msg_flags & FI_COMPLETION)
+		return 1;
+
+	return 0;
+}
+
+int ft_check_rx_completion(void)
+{
+	if (ft_use_comp_cntr(test_info.comp_type) ||
+	    ft_generates_rx_comp())
+		return 1;
+	else
+		return 0;
+}
+
+int ft_check_tx_completion(void)
+{
+	if (ft_use_comp_cntr(test_info.comp_type) ||
+	    ft_generates_tx_comp())
+		return 1;
+	else
+		return 0;
+}
+
+static int ft_open_cntrs(void)
+{
+	struct fi_cntr_attr attr;
+	int ret;
+
+	if (!txcntr) {
+		memset(&attr, 0, sizeof attr);
+		attr.wait_obj = test_info.cntr_wait_obj;
+		ret = fi_cntr_open(domain, &attr, &txcntr, &txcntr);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_open", ret);
+			return ret;
+		}
+	}
+	if (!rxcntr) {
+		memset(&attr, 0, sizeof attr);
+		attr.wait_obj = test_info.cntr_wait_obj;
+		ret = fi_cntr_open(domain, &attr, &rxcntr, &rxcntr);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_open", ret);
+			return ret;
+		}
+	}
+	return 0;
+}
+
+static int ft_open_cqs(void)
+{
+	struct fi_cq_attr attr;
+	int ret;
+
+	if (!txcq) {
+		memset(&attr, 0, sizeof attr);
+		attr.format = ft_tx_ctrl.cq_format;
+		attr.wait_obj = test_info.cq_wait_obj;
+		attr.size = ft_tx_ctrl.max_credits;
+
+		ret = fi_cq_open(domain, &attr, &txcq, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_cq_open", ret);
+			return ret;
+		}
+	}
+
+	if (!rxcq) {
+		memset(&attr, 0, sizeof attr);
+		attr.format = ft_rx_ctrl.cq_format;
+		attr.wait_obj = test_info.cq_wait_obj;
+		attr.size = ft_rx_ctrl.max_credits;
+
+		ret = fi_cq_open(domain, &attr, &rxcq, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_cq_open", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int ft_open_comp(void)
+{
+	int ret;
+
+	ret = ft_open_cqs();
+	if (ret)
+		return ret;
+
+	switch (test_info.comp_type) {
+	case FT_COMP_QUEUE:
+		break;
+	case FT_COMP_ALL:
+	case FT_COMP_CNTR:
+		ret = ft_open_cntrs();
+		break;
+	default:
+		ret = -FI_ENOSYS;
+	}
+
+	return ret;
+}
+
+int ft_bind_comp(struct fid_ep *ep)
+{
+	int ret;
+	uint64_t flags;
+
+	flags = FI_TRANSMIT | test_info.tx_cq_bind_flags;
+	ret = fi_ep_bind(ep, &txcq->fid, flags);
+	if (ret) {
+		FT_PRINTERR("fi_ep_bind", ret);
+		return ret;
+	}
+
+	if (ft_use_comp_cntr(test_info.comp_type)) {
+		flags = FI_TRANSMIT | FI_READ | FI_WRITE;
+		ret = fi_ep_bind(ep, &txcntr->fid, flags);
+		if (ret) {
+			FT_PRINTERR("fi_ep_bind", ret);
+			return ret;
+		}
+	}
+
+	flags = FI_RECV | test_info.rx_cq_bind_flags;
+	ret = fi_ep_bind(ep, &rxcq->fid, flags);
+	if (ret) {
+		FT_PRINTERR("fi_ep_bind", ret);
+		return ret;
+	}
+
+	if (ft_use_comp_cntr(test_info.comp_type)) {
+		flags = FI_RECV | FI_REMOTE_READ | FI_REMOTE_WRITE;
+		ret = fi_ep_bind(ep, &rxcntr->fid, flags);
+		if (ret) {
+			FT_PRINTERR("fi_ep_bind", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+/* Read CQ until there are no more completions */
+#define ft_cq_read(cq_read, cq, buf, count, completions, str, ret, verify,...)	\
+	do {							\
+		ret = cq_read(cq, buf, count, ##__VA_ARGS__);	\
+		if (ret < 0) {					\
+			if (ret == -FI_EAGAIN)			\
+				break;				\
+			if (ret == -FI_EAVAIL) {		\
+				ret = ft_cq_readerr(cq);	\
+			} else {				\
+				FT_PRINTERR(#cq_read, ret);	\
+			}					\
+			return ret;				\
+		} else {					\
+			completions += ret;			\
+			if (verify)				\
+				ft_verify_comp(buf);		\
+		}						\
+	} while (ret == count)
+
+static int ft_comp_x(struct fid_cq *cq, struct ft_xcontrol *ft_x,
+		const char *x_str, int timeout)
+{
+	uint8_t buf[FT_COMP_BUF_SIZE], start = 0;
+	struct timespec s, e;
+	int poll_time = 0;
+	int ret, verify = (test_info.test_type == FT_TEST_UNIT && cq == rxcq);
+	size_t cur_credits = ft_x->credits;
+
+	switch(test_info.cq_wait_obj) {
+	case FI_WAIT_NONE:
+		do {
+			if (!start) {
+				clock_gettime(CLOCK_MONOTONIC, &s);
+				start = 1;
+			}
+
+			ft_cq_read(fi_cq_read, cq, buf, comp_entry_cnt[ft_x->cq_format],
+					ft_x->credits, x_str, ret, verify);
+
+			clock_gettime(CLOCK_MONOTONIC, &e);
+			poll_time = get_elapsed(&s, &e, MILLI);
+		} while (ret == -FI_EAGAIN && poll_time < timeout &&
+			 ft_x->credits == cur_credits);
+
+		if (ft_x->credits != cur_credits)
+			ret = 0;
+
+		break;
+	case FI_WAIT_UNSPEC:
+	case FI_WAIT_FD:
+	case FI_WAIT_MUTEX_COND:
+		ft_cq_read(fi_cq_sread, cq, buf, comp_entry_cnt[ft_x->cq_format],
+			ft_x->credits, x_str, ret, verify, NULL, timeout);
+		break;
+	case FI_WAIT_SET:
+		FT_ERR("fi_ubertest: Unsupported cq wait object");
+		return -1;
+	default:
+		FT_ERR("Unknown cq wait object");
+		return -1;
+	}
+
+	return (ret == -FI_EAGAIN && timeout) ? ret : 0;
+}
+
+static int ft_cntr_x(struct fid_cntr *cntr, struct ft_xcontrol *ft_x,
+		     int timeout)
+{
+	uint64_t cntr_val;
+	struct timespec s, e;
+	int poll_time = clock_gettime(CLOCK_MONOTONIC, &s);
+
+	do {
+		cntr_val = fi_cntr_read(cntr);
+		clock_gettime(CLOCK_MONOTONIC, &e);
+		poll_time = get_elapsed(&s, &e, MILLI);
+	} while (cntr_val == ft_x->total_comp && poll_time < timeout);
+
+	ft_x->credits += (cntr_val - ft_x->total_comp);
+	ft_x->total_comp = cntr_val;
+
+	return 0;
+}
+
+int ft_comp_rx(int timeout)
+{
+	int ret;
+	size_t cur_credits = ft_rx_ctrl.credits;
+
+	if (ft_use_comp_cntr(test_info.comp_type)) {
+		ret = ft_cntr_x(rxcntr, &ft_rx_ctrl, timeout);
+		if (ret)
+			return ret;
+	}
+	if (ft_use_comp_cq(test_info.comp_type)) {
+		if (test_info.comp_type == FT_COMP_ALL)
+			ft_rx_ctrl.credits = cur_credits;
+		ret = ft_comp_x(rxcq, &ft_rx_ctrl, "rxcq", timeout);
+		if (ret)
+			return ret;
+
+		if (ft_use_comp_cntr(test_info.comp_type))
+			ft_rx_ctrl.credits = cur_credits;
+	}
+	assert(ft_rx_ctrl.credits <= ft_rx_ctrl.max_credits);
+
+	return 0;
+}
+
+int ft_comp_tx(int timeout)
+{
+	int ret;
+	size_t cur_credits = ft_tx_ctrl.credits;
+
+	if (ft_use_comp_cntr(test_info.comp_type)) {
+		ret = ft_cntr_x(txcntr, &ft_tx_ctrl, timeout);
+		if (ret)
+			return ret;
+	}
+
+	if (ft_use_comp_cq(test_info.comp_type)) {
+		if (test_info.comp_type == FT_COMP_ALL)
+			ft_tx_ctrl.credits = cur_credits;
+		ret = ft_comp_x(txcq, &ft_tx_ctrl, "txcq", timeout);
+		if (ret)
+			return ret;
+
+		if (ft_use_comp_cntr(test_info.comp_type))
+			ft_tx_ctrl.credits = cur_credits;
+	}
+	assert(ft_tx_ctrl.credits <= ft_tx_ctrl.max_credits);
+
+	return 0;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/domain.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/domain.c
new file mode 100644
index 000000000..f72484883
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/domain.c
@@ -0,0 +1,354 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <string.h>
+
+#include "fabtest.h"
+
+
+static int ft_open_fabric(void)
+{
+	int ret;
+
+	if (fabric) {
+		if (fabric_info->fabric_attr->fabric &&
+		    fabric_info->fabric_attr->fabric != fabric) {
+			printf("Opened fabric / fabric_attr mismatch\n");
+			return -FI_EOTHER;
+		}
+		return 0;
+	}
+
+	ret = fi_fabric(fabric_info->fabric_attr, &fabric, NULL);
+	if (ret)
+		FT_PRINTERR("fi_fabric", ret);
+
+	return ret;
+}
+
+static int ft_open_eq(void)
+{
+	struct fi_eq_attr attr;
+	int ret;
+
+	if (eq)
+		return 0;
+
+	memset(&attr, 0, sizeof attr);
+	attr.wait_obj = test_info.eq_wait_obj;
+	ret = fi_eq_open(fabric, &attr, &eq, NULL);
+	if (ret)
+		FT_PRINTERR("fi_eq_open", ret);
+
+	return ret;
+}
+
+int ft_eq_readerr(void)
+{
+	struct fi_eq_err_entry err;
+	ssize_t ret;
+
+	memset(&err, 0, sizeof(err));
+	ret = fi_eq_readerr(eq, &err, 0);
+	if (ret != sizeof(err)) {
+		FT_PRINTERR("fi_eq_readerr", ret);
+		return ret;
+	} else {
+		fprintf(stderr, "Error event %d %s\n",
+			err.err, fi_strerror(err.err));
+		return err.err;
+	}
+}
+
+ssize_t ft_get_event(uint32_t *event, void *buf, size_t len,
+		     uint32_t event_check, size_t len_check)
+{
+	ssize_t ret;
+
+	switch(test_info.eq_wait_obj) {
+	case FI_WAIT_NONE:
+		do {
+			ret = fi_eq_read(eq, event, buf, len, 0);
+			if (ret == -FI_EAVAIL) {
+				return ft_eq_readerr();
+			} else if (ret < 0 && ret != -FI_EAGAIN) {
+				FT_PRINTERR("fi_eq_read", ret);
+				return ret;
+			}
+		} while (ret == -FI_EAGAIN);
+		break;
+	case FI_WAIT_UNSPEC:
+	case FI_WAIT_FD:
+	case FI_WAIT_MUTEX_COND:
+		ret = fi_eq_sread(eq, event, buf, len, FT_SREAD_TO, 0);
+		if (ret == -FI_EAVAIL) {
+			return ft_eq_readerr();
+		} else if (ret < 0) {
+			FT_PRINTERR("fi_eq_sread", ret);
+			return ret;
+		}
+		break;
+	case FI_WAIT_SET:
+		FT_ERR("fi_ubertest: Unsupported eq wait object");
+		return -1;
+	default:
+		FT_ERR("Unknown eq wait object");
+		return -1;
+	}
+
+	if (event_check && event_check != *event) {
+		fprintf(stderr, "Unexpected event %d, wanted %d\n",
+			*event, event_check);
+		return -FI_ENOMSG;
+
+	}
+
+	if (ret < len_check) {
+		fprintf(stderr, "Reported event too small\n");
+		return -FI_ETOOSMALL;
+	}
+
+	return ret;
+}
+
+static int ft_open_domain(void)
+{
+	int ret;
+
+	if (domain) {
+		if (fabric_info->domain_attr->domain &&
+		    fabric_info->domain_attr->domain != domain) {
+			fprintf(stderr, "Opened domain / domain_attr mismatch\n");
+			return -FI_EDOMAIN;
+		}
+		return 0;
+	}
+
+	ret = fi_domain(fabric, fabric_info, &domain, NULL);
+	if (ret)
+		FT_PRINTERR("fi_domain", ret);
+
+	return ret;
+}
+
+static int ft_open_av(void)
+{
+	struct fi_av_attr attr;
+	int ret;
+
+	if (av)
+		return 0;
+
+	memset(&attr, 0, sizeof attr);
+	attr.type = test_info.av_type;
+	attr.count = 2;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_av_open", ret);
+		return ret;
+	}
+
+	return ret;
+}
+
+static int ft_setup_xcontrol_bufs(struct ft_xcontrol *ctrl)
+{
+	size_t size;
+	int i, ret;
+
+	size = ft_ctrl.size_array[ft_ctrl.size_cnt - 1];
+	if (!ctrl->buf) {
+		ctrl->buf = calloc(1, size);
+		ctrl->cpy_buf = calloc(1, size);
+		if (!ctrl->buf || !ctrl->cpy_buf)
+			return -FI_ENOMEM;
+	} else {
+		memset(ctrl->buf, 0, size);
+	}
+
+	if ((fabric_info->domain_attr->mr_mode & FI_MR_LOCAL) && !ctrl->mr) {
+		ret = fi_mr_reg(domain, ctrl->buf, size,
+				ft_info_to_mr_access(fabric_info),
+				0, 0, 0, &ctrl->mr, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_mr_reg", ret);
+			return ret;
+		}
+		ctrl->memdesc = fi_mr_desc(ctrl->mr);
+	}
+
+	for (i = 0; i < ft_ctrl.iov_cnt; i++)
+		ctrl->iov_desc[i] = ctrl->memdesc;
+
+	return 0;
+}
+
+static int ft_setup_atomic_control(struct ft_atomic_control *ctrl)
+{
+	size_t size;
+	int ret = 0;
+	uint64_t access;
+
+	size = ft_ctrl.size_array[ft_ctrl.size_cnt - 1];
+	if (!ctrl->res_buf) {
+		ctrl->res_buf = calloc(1, size);
+		if (!ctrl->res_buf)
+			return -FI_ENOMEM;
+	} else {
+		memset(ctrl->res_buf, 0, size);
+	}
+
+	if (!ctrl->comp_buf) {
+		ctrl->comp_buf = calloc(1, size);
+		if (!ctrl->comp_buf)
+			return -FI_ENOMEM;
+	} else {
+		memset(ctrl->comp_buf, 0, size);
+	}
+
+	if (!ctrl->orig_buf) {
+		ctrl->orig_buf = calloc(1, size);
+		if (!ctrl->orig_buf)
+			return -FI_ENOMEM;
+	} else {
+		memset(ctrl->orig_buf, 0, size);
+	}
+
+	if (fabric_info->domain_attr->mr_mode & FI_MR_LOCAL) {
+		access = FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE;
+		if (!ctrl->res_mr) {
+			ret = fi_mr_reg(domain, ctrl->res_buf, size, access,
+				0, 0, 0, &ctrl->res_mr, NULL);
+			if (ret) {
+				FT_PRINTERR("fi_mr_reg", ret);
+				return ret;
+			}
+			ctrl->res_memdesc = fi_mr_desc(ctrl->res_mr);
+		}
+
+		if (!ctrl->comp_mr) {
+			ret = fi_mr_reg(domain, ctrl->comp_buf, size, access,
+				0, 0, 0, &ctrl->comp_mr, NULL);
+			if (ret) {
+				FT_PRINTERR("fi_mr_reg", ret);
+				return ret;
+			}
+			ctrl->comp_memdesc = fi_mr_desc(ctrl->comp_mr);
+		}
+	}
+	ft_atom_ctrl.op = test_info.op;
+	ft_atom_ctrl.datatype = test_info.datatype;
+
+	return ret;
+}
+
+static int ft_setup_mr_control(struct ft_mr_control *ctrl)
+{
+	size_t size;
+	int ret;
+	uint64_t access;
+
+	if (!(fabric_info->caps & (FI_RMA | FI_ATOMIC)))
+		return 0;
+
+	size = ft_ctrl.size_array[ft_ctrl.size_cnt - 1];
+	if (!ctrl->buf) {
+		ctrl->buf = calloc(1, size);
+		if (!ctrl->buf)
+			return -FI_ENOMEM;
+	} else {
+		memset(ctrl->buf, 0, size);
+	}
+
+	if (!ctrl->mr) {
+		access = FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE;
+		ret = fi_mr_reg(domain, ctrl->buf, size, access, 0,
+				FT_MR_KEY, 0, &ctrl->mr, NULL);
+		if (ret) {
+			FT_PRINTERR("fi_mr_reg", ret);
+			return ret;
+		}
+		ctrl->memdesc = fi_mr_desc(ctrl->mr);
+		ctrl->peer_mr_key = ctrl->mr_key = fi_mr_key(ctrl->mr);
+	}
+	
+	return 0;
+}
+
+static int ft_setup_bufs(void)
+{
+	int ret;
+
+	ret = ft_setup_xcontrol_bufs(&ft_rx_ctrl);
+	if (ret)
+		return ret;
+
+	ret = ft_setup_xcontrol_bufs(&ft_tx_ctrl);
+	if (ret)
+		return ret;
+
+	ret = ft_setup_mr_control(&ft_mr_ctrl);
+	if (ret)
+		return ret;
+
+	ret = ft_setup_atomic_control(&ft_atom_ctrl);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+int ft_open_control(void)
+{
+	int ret;
+
+	ret = ft_open_fabric();
+	if (ret)
+		return ret;
+
+	ret = ft_open_eq();
+	if (ret)
+		return ret;
+
+	ret = ft_open_domain();
+	if (ret)
+		return ret;
+
+	ret = ft_setup_bufs();
+	if (ret)
+		return ret;
+
+	if (test_info.ep_type != FI_EP_MSG) {
+		ret = ft_open_av();
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ep.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ep.c
new file mode 100644
index 000000000..91610a6ac
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ep.c
@@ -0,0 +1,140 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <string.h>
+
+#include "fabtest.h"
+
+
+//struct fid_stx	 *stx;
+//struct fid_sep	 *sep;
+
+
+int ft_open_passive(void)
+{
+	int ret;
+
+	if (pep)
+		return 0;
+
+	ret = fi_passive_ep(fabric, fabric_info, &pep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_passive_ep", ret);
+		return ret;
+	}
+
+	ret = fi_pep_bind(pep, &eq->fid, 0);
+	if (ret) {
+		FT_PRINTERR("fi_pep_bind", ret);
+		return ret;
+	}
+
+	ret = fi_listen(pep);
+	if (ret) {
+		FT_PRINTERR("fi_listen", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+int ft_open_active(void)
+{
+	int ret;
+
+	if (ep)
+		return 0;
+
+	ret = ft_open_control();
+	if (ret)
+		return ret;
+
+	ret = ft_open_comp();
+	if (ret)
+		return ret;
+
+	ret = fi_endpoint(domain, fabric_info, &ep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		return ret;
+	}
+
+	ft_rx_ctrl.ep = ep;
+	ft_tx_ctrl.ep = ep;
+
+	if (test_info.ep_type == FI_EP_MSG) {
+		ret = fi_ep_bind(ep, &eq->fid, 0);
+		if (ret) {
+			FT_PRINTERR("fi_ep_bind", ret);
+			return ret;
+		}
+	}
+
+	ret = ft_bind_comp(ep);
+	if (ret)
+		return ret;
+
+	if (test_info.ep_type != FI_EP_MSG) {
+		ret = fi_ep_bind(ep, &av->fid, 0);
+		if (ret) {
+			FT_PRINTERR("fi_ep_bind", ret);
+			return ret;
+		}
+	}
+
+	ret = fi_enable(ep);
+	if (ret) {
+		FT_PRINTERR("fi_enable", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+int ft_reset_ep(void)
+{
+	int ret;
+
+	ret = ft_comp_rx(0);
+	if (ret)
+		return ret;
+
+	while (ft_tx_ctrl.credits < ft_tx_ctrl.max_credits) {
+		ret = ft_comp_tx(0);
+		if (ret)
+			return ret;
+	}
+
+	memset(ft_tx_ctrl.buf, 0, ft_tx_ctrl.msg_size);
+	memset(ft_rx_ctrl.buf, 0, ft_rx_ctrl.msg_size);
+	ft_tx_ctrl.seqno = 0;
+	ft_rx_ctrl.seqno = 0;
+
+	return 0;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/fabtest.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/fabtest.h
new file mode 100644
index 000000000..1ef737a99
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/fabtest.h
@@ -0,0 +1,380 @@
+/*
+ * Copyright (c) 2015-2017 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _FABTEST_H_
+#define _FABTEST_H_
+
+#include <stdlib.h>
+
+#include <rdma/fabric.h>
+#include <rdma/fi_atomic.h>
+#include <rdma/fi_cm.h>
+#include <rdma/fi_domain.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_eq.h>
+#include <rdma/fi_errno.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_tagged.h>
+#include <shared.h>
+#include <assert.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Timeouts in milliseconds */
+#define FT_SREAD_TO 		10000
+#define FT_COMP_TO 		10000
+#define FT_DGRAM_POLL_TO	1
+
+extern int listen_sock, sock;
+
+//extern struct fid_wait	 *waitset;
+//extern struct fid_poll	 *pollset;
+//extern struct fid_stx	 *stx;
+//extern struct fid_sep	 *sep;
+
+extern struct ft_info test_info;
+extern struct fi_info *fabric_info;
+
+extern size_t sm_size_array[];
+extern size_t med_size_array[];
+extern size_t lg_size_array[];
+extern size_t size_array[];
+extern const unsigned int sm_size_cnt;
+extern const unsigned int med_size_cnt;
+extern const unsigned int lg_size_cnt;
+
+struct ft_xcontrol {
+	struct fid_ep		*ep;
+	void			*buf;
+	void			*cpy_buf;
+	struct fid_mr		*mr;
+	void			*memdesc;
+	struct iovec		*iov;
+	void			**iov_desc;
+	int			iov_iter;
+	size_t			msg_size;
+	size_t			rma_msg_size;
+	size_t			credits;
+	size_t			max_credits;
+	fi_addr_t		addr;
+	uint64_t		tag;
+	uint8_t			seqno;
+	uint64_t		total_comp;
+	enum fi_cq_format	cq_format;
+	uint64_t		remote_cq_data;
+	struct fi_context	*ctx;
+	int			curr_ctx;
+};
+
+struct ft_atomic_control {
+	void			*orig_buf;
+	void			*res_buf;
+	struct fid_mr		*res_mr;
+	void			*res_memdesc;
+	void			*comp_buf;
+	struct fid_mr		*comp_mr;
+	void			*comp_memdesc;
+	struct fi_ioc		*ioc;
+	struct fi_ioc		*res_ioc;
+	struct fi_ioc		*comp_ioc;
+	enum fi_op		op;
+	enum fi_datatype	datatype;
+	size_t			count;
+	size_t			datatype_size;
+};
+
+struct ft_mr_control {
+	void			*buf;
+	struct fid_mr		*mr;
+	void			*memdesc;
+	uint64_t		mr_key;
+	uint64_t		peer_mr_addr;
+	uint64_t		peer_mr_key;
+};
+
+struct ft_control {
+	size_t			*size_array;
+	int			size_cnt;
+	size_t			*iov_array;
+	int			iov_cnt;
+	int			inc_step;
+	int			xfer_iter;
+	int			verify_cnt;
+	int			error;
+};
+
+extern struct ft_xcontrol ft_rx_ctrl, ft_tx_ctrl;
+extern struct ft_mr_control ft_mr_ctrl;
+extern struct ft_control ft_ctrl;
+extern struct ft_atomic_control ft_atom_ctrl;
+
+enum {
+	FT_MAX_CAPS		= 64,
+	FT_MAX_CLASS		= 4,
+	FT_MAX_EP_TYPES		= 8,
+	FT_MAX_AV_TYPES		= 3,
+	FT_MAX_PROV_MODES	= 4,
+	FT_MAX_WAIT_OBJ		= 5,
+	FT_MAX_MR_MODES		= 11,
+	FT_DEFAULT_CREDITS	= 128,
+	FT_COMP_BUF_SIZE	= 256,
+	FT_MAX_FLAGS		= 64,
+	FT_MAX_PROGRESS		= 3,
+};
+
+enum ft_comp_type {
+	FT_COMP_UNSPEC,
+	FT_COMP_QUEUE,
+	FT_COMP_CNTR,
+	FT_COMP_ALL,
+	FT_MAX_COMP
+};
+
+enum ft_test_type {
+	FT_TEST_UNSPEC,
+	FT_TEST_LATENCY,
+	FT_TEST_BANDWIDTH,
+	FT_TEST_UNIT,
+	FT_MAX_TEST
+};
+
+enum ft_class_function {
+	FT_FUNC_UNSPEC,
+	FT_FUNC_SEND,
+	FT_FUNC_SENDV,
+	FT_FUNC_SENDMSG,
+	FT_FUNC_INJECT,
+	FT_FUNC_INJECTDATA,
+	FT_FUNC_SENDDATA,
+	FT_FUNC_READ,
+	FT_FUNC_READV,
+	FT_FUNC_READMSG,
+	FT_FUNC_WRITE,
+	FT_FUNC_WRITEV,
+	FT_FUNC_WRITEMSG,
+	FT_FUNC_INJECT_WRITE,
+	FT_FUNC_WRITEDATA,
+	FT_FUNC_INJECT_WRITEDATA,
+	FT_FUNC_ATOMIC,
+	FT_FUNC_ATOMICV,
+	FT_FUNC_ATOMICMSG,
+	FT_FUNC_INJECT_ATOMIC,
+	FT_FUNC_FETCH_ATOMIC,
+	FT_FUNC_FETCH_ATOMICV,
+	FT_FUNC_FETCH_ATOMICMSG,
+	FT_FUNC_COMPARE_ATOMIC,
+	FT_FUNC_COMPARE_ATOMICV,
+	FT_FUNC_COMPARE_ATOMICMSG,
+	FT_MAX_FUNCTIONS
+};
+
+#define FT_FLAG_QUICKTEST	(1ULL << 0)
+
+#define is_inject_func(x) (x == FT_FUNC_INJECT || \
+			   x == FT_FUNC_INJECTDATA || \
+			   x == FT_FUNC_INJECT_WRITE || \
+			   x == FT_FUNC_INJECT_WRITEDATA || \
+			   x == FT_FUNC_INJECT_ATOMIC)
+
+#define is_read_func(x) (x == FT_FUNC_READ || \
+			 x == FT_FUNC_READV || \
+			 x == FT_FUNC_READMSG)
+
+#define is_fetch_func(x) (x == FT_FUNC_FETCH_ATOMIC || \
+			  x == FT_FUNC_FETCH_ATOMICV || \
+			  x == FT_FUNC_FETCH_ATOMICMSG)
+
+#define is_compare_func(x) (x == FT_FUNC_COMPARE_ATOMIC || \
+			    x == FT_FUNC_COMPARE_ATOMICV || \
+			    x == FT_FUNC_COMPARE_ATOMICMSG)
+
+#define is_data_func(x) (x == FT_FUNC_SENDDATA || \
+			 x == FT_FUNC_INJECTDATA || \
+			 x == FT_FUNC_WRITEDATA || \
+			 x == FT_FUNC_INJECT_WRITEDATA)
+
+#define is_msg_func(x)	(x == FT_FUNC_SENDMSG || \
+			 x == FT_FUNC_WRITEMSG || \
+			 x == FT_FUNC_READMSG || \
+			 x == FT_FUNC_ATOMICMSG || \
+			 x == FT_FUNC_FETCH_ATOMICMSG || \
+			 x == FT_FUNC_COMPARE_ATOMICMSG)
+
+struct ft_set {
+	char			node[FI_NAME_MAX];
+	char			service[FI_NAME_MAX];
+	char			prov_name[FI_NAME_MAX];
+	enum ft_test_type	test_type[FT_MAX_TEST];
+	enum ft_class_function	class_function[FT_MAX_FUNCTIONS];
+	uint64_t		msg_flags;
+	enum fi_op		op[FI_ATOMIC_OP_LAST];
+	enum fi_datatype	datatype[FI_DATATYPE_LAST];
+	enum fi_ep_type		ep_type[FT_MAX_EP_TYPES];
+	enum fi_av_type		av_type[FT_MAX_AV_TYPES];
+	enum ft_comp_type	comp_type[FT_MAX_COMP];
+	enum fi_wait_obj	eq_wait_obj[FT_MAX_WAIT_OBJ];
+	enum fi_wait_obj	cq_wait_obj[FT_MAX_WAIT_OBJ];
+	enum fi_wait_obj	cntr_wait_obj[FT_MAX_WAIT_OBJ];
+	enum fi_progress	progress[FT_MAX_PROGRESS];
+	uint64_t		mode[FT_MAX_PROV_MODES];
+	uint64_t		test_class[FT_MAX_CLASS];
+	uint64_t		constant_caps[FT_MAX_CAPS];
+	uint64_t		test_flags;
+	uint64_t		mr_mode[FT_MAX_MR_MODES];
+	uint64_t 		rx_cq_bind_flags[FT_MAX_FLAGS];
+	uint64_t 		tx_cq_bind_flags[FT_MAX_FLAGS];
+	uint64_t 		rx_op_flags[FT_MAX_FLAGS];
+	uint64_t 		tx_op_flags[FT_MAX_FLAGS];
+};
+
+struct ft_series {
+	struct ft_set		*sets;
+	int			nsets;
+	int			test_count;
+	int			test_index;
+	int			cur_set;
+	int			cur_type;
+	int			cur_func;
+	int			cur_op;
+	int			cur_datatype;
+	int			cur_ep;
+	int			cur_av;
+	int			cur_comp;
+	int			cur_eq_wait_obj;
+	int			cur_cq_wait_obj;
+	int			cur_cntr_wait_obj;
+	int			cur_mode;
+	int			cur_class;
+	int			cur_progress;
+};
+
+struct ft_info {
+	enum ft_test_type	test_type;
+	int			test_index;
+	int			test_subindex;
+	enum ft_class_function	class_function;
+	uint64_t		msg_flags;
+	enum fi_op		op;
+	enum fi_datatype	datatype;
+	uint64_t		test_flags;
+	uint64_t		test_class;
+	uint64_t		caps;
+	uint64_t		mode;
+	uint64_t		mr_mode;
+	enum fi_av_type		av_type;
+	enum fi_ep_type		ep_type;
+	enum ft_comp_type	comp_type;
+	enum fi_wait_obj	eq_wait_obj;
+	enum fi_wait_obj	cq_wait_obj;
+	enum fi_wait_obj	cntr_wait_obj;
+	enum fi_progress	progress;
+	uint32_t		protocol;
+	uint32_t		protocol_version;
+	char			node[FI_NAME_MAX];
+	char			service[FI_NAME_MAX];
+	char			prov_name[FI_NAME_MAX];
+	char			fabric_name[FI_NAME_MAX];
+	uint64_t 		rx_cq_bind_flags;
+	uint64_t 		tx_cq_bind_flags;
+	uint64_t 		rx_op_flags;
+	uint64_t 		tx_op_flags;
+};
+
+
+struct ft_series * fts_load(char *filename);
+void fts_close(struct ft_series *series);
+void fts_start(struct ft_series *series, int index);
+void fts_next(struct ft_series *series);
+int  fts_end(struct ft_series *series, int index);
+void fts_cur_info(struct ft_series *series, struct ft_info *info);
+int fts_info_is_valid(void);
+
+
+struct ft_msg {
+	uint32_t	len;
+	uint8_t		data[124];
+};
+
+int ft_fw_send(int fd, void *msg, size_t len);
+int ft_fw_recv(int fd, void *msg, size_t len);
+
+
+int ft_open_control();
+ssize_t ft_get_event(uint32_t *event, void *buf, size_t len,
+		     uint32_t event_check, size_t len_check);
+int ft_open_comp();
+int ft_bind_comp(struct fid_ep *ep);
+int ft_comp_rx(int timeout);
+int ft_comp_tx(int timeout);
+int ft_use_comp_cntr(enum ft_comp_type comp_type);
+int ft_use_comp_cq(enum ft_comp_type comp_type);
+
+int ft_open_active();
+int ft_open_passive();
+int ft_enable_comm();
+int ft_post_recv_bufs();
+void ft_format_iov(struct iovec *iov, size_t cnt, char *buf, size_t len);
+void ft_format_iocs(struct iovec *iov, size_t *iov_count);
+void ft_next_iov_cnt(struct ft_xcontrol *ctrl, size_t max_iov_cnt);
+int ft_get_ctx(struct ft_xcontrol *ctrl, struct fi_context **ctx);
+int ft_generates_rx_comp();
+int ft_generates_tx_comp();
+int ft_check_rx_completion();
+int ft_check_tx_completion();
+
+int ft_send_sync_msg();
+int ft_recv_n_msg();
+int ft_recv_msg();
+int ft_send_msg();
+int ft_send_dgram();
+int ft_send_dgram_done();
+int ft_recv_dgram();
+int ft_recv_dgram_flood(size_t *recv_cnt);
+int ft_send_dgram_flood();
+int ft_sendrecv_dgram();
+int ft_send_rma();
+
+void ft_cleanup(void);
+int ft_open_res();
+int ft_init_test();
+int ft_run_test();
+int ft_reset_ep();
+void ft_record_error(int error);
+
+int ft_verify_bufs();
+int ft_sync_fill_bufs(size_t size);
+void ft_verify_comp(void *buf);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _FABTEST_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ofi_atomic.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ofi_atomic.c
new file mode 100644
index 000000000..075d722c1
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ofi_atomic.c
@@ -0,0 +1,373 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "ofi_atomic.h"
+
+#ifndef UNREFERENCED_PARAMETER
+#define OFI_UNUSED(var) (void)var
+#else
+#define OFI_UNUSED UNREFERENCED_PARAMETER
+#endif
+
+/*
+ * Basic atomic operations
+ */
+
+#define OFI_OP_MIN(type,dst,src)   if ((dst) > (src)) (dst) = (src)
+#define OFI_OP_MAX(type,dst,src)   if ((dst) < (src)) (dst) = (src)
+#define OFI_OP_SUM(type,dst,src)   (dst) += (src)
+#define OFI_OP_PROD(type,dst,src)  (dst) *= (src)
+#define OFI_OP_LOR(type,dst,src)   (dst) = (dst) || (src)
+#define OFI_OP_LAND(type,dst,src)  (dst) = (dst) && (src)
+#define OFI_OP_BOR(type,dst,src)   (dst) |= (src)
+#define OFI_OP_BAND(type,dst,src)  (dst) &= (src)
+#define OFI_OP_LXOR(type,dst,src)  (dst) = ((dst) && !(src)) || (!(dst) && (src))
+#define OFI_OP_BXOR(type,dst,src)  (dst) ^= (src)
+#define OFI_OP_READ(type,dst,src)  /* src unused, dst is written to result */
+#define OFI_OP_WRITE(type,dst,src) (dst) = (src)
+
+#define OFI_OP_CSWAP_EQ(type,dst,src,cmp) if ((dst) == (cmp)) (dst) = (src)
+#define OFI_OP_CSWAP_NE(type,dst,src,cmp) if ((dst) != (cmp)) (dst) = (src)
+#define OFI_OP_CSWAP_LE(type,dst,src,cmp) if ((dst) <= (cmp)) (dst) = (src)
+#define OFI_OP_CSWAP_LT(type,dst,src,cmp) if ((dst) <  (cmp)) (dst) = (src)
+#define OFI_OP_CSWAP_GE(type,dst,src,cmp) if ((dst) >= (cmp)) (dst) = (src)
+#define OFI_OP_CSWAP_GT(type,dst,src,cmp) if ((dst) >  (cmp)) (dst) = (src)
+#define OFI_OP_MSWAP(type,dst,src,cmp)    (dst) = (((src) & (cmp)) | \
+						   ((dst) & ~(cmp)))
+
+/* Need special handlers for complex datatypes for portability */
+#define OFI_OP_SUM_COMPLEX(type,dst,src)  (dst) = ofi_complex_sum_##type(dst,src)
+#define OFI_OP_PROD_COMPLEX(type,dst,src) (dst) = ofi_complex_prod_##type(dst,src)
+#define OFI_OP_LOR_COMPLEX(type,dst,src)  (dst) = ofi_complex_lor_##type(dst,src)
+#define OFI_OP_LAND_COMPLEX(type,dst,src) (dst) = ofi_complex_land_##type(dst,src)
+#define OFI_OP_LXOR_COMPLEX(type,dst,src) (dst) = ofi_complex_lxor_##type(dst,src)
+#define OFI_OP_READ_COMPLEX		  OFI_OP_READ
+#define OFI_OP_WRITE_COMPLEX		  OFI_OP_WRITE
+
+#define OFI_OP_CSWAP_EQ_COMPLEX(type,dst,src,cmp) \
+			if (ofi_complex_eq_##type(dst,cmp)) (dst) = (src)
+#define OFI_OP_CSWAP_NE_COMPLEX(type,dst,src,cmp) \
+			if (!ofi_complex_eq_##type(dst,cmp)) (dst) = (src)
+
+
+/********************************
+ * ATOMIC TYPE function templates
+ ********************************/
+
+#define OFI_DEF_NOOP_NAME NULL,
+#define OFI_DEF_NOOP_FUNC
+
+/*
+ * WRITE
+ */
+#define OFI_DEF_WRITE_NAME(op, type) ofi_write_## op ##_## type,
+#define OFI_DEF_WRITE_COMPLEX_NAME(op, type) ofi_write_## op ##_## type,
+
+#define OFI_DEF_WRITE_FUNC(op, type)					\
+	static void ofi_write_## op ##_## type				\
+		(void *dst, const void *src, size_t cnt)		\
+	{								\
+		size_t i;						\
+		type *d = (dst);					\
+		const type *s = (src);					\
+		for (i = 0; i < cnt; i++)				\
+			op(type, d[i], s[i]);				\
+	}
+
+#define OFI_DEF_WRITE_COMPLEX_FUNC(op, type)				\
+	static void ofi_write_## op ##_## type				\
+		(void *dst, const void *src, size_t cnt)		\
+	{								\
+		size_t i;						\
+		ofi_complex_##type *d = (dst);				\
+		const ofi_complex_##type *s = (src);			\
+		for (i = 0; i < cnt; i++)				\
+			op(type, d[i], s[i]);				\
+	}
+
+/*
+ * READ (fetch)
+ */
+#define OFI_DEF_READ_NAME(op, type) ofi_read_## op ##_## type,
+#define OFI_DEF_READ_COMPLEX_NAME(op, type) ofi_read_## op ##_## type,
+
+#define OFI_DEF_READ_FUNC(op, type)					\
+	static void ofi_read_## op ##_## type				\
+		(void *dst, const void *src, void *res, size_t cnt) 	\
+	{								\
+		size_t i;						\
+		type *d = (dst);					\
+		type *r = (res);					\
+		OFI_UNUSED(src);					\
+		for (i = 0; i < cnt; i++)				\
+			r[i] = d[i];					\
+	}
+
+#define OFI_DEF_READ_COMPLEX_FUNC(op, type)				\
+	static void ofi_read_## op ##_## type				\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		size_t i;						\
+		ofi_complex_##type *d = (dst);				\
+		ofi_complex_##type *r = (res);				\
+		OFI_UNUSED(src);					\
+		for (i = 0; i < cnt; i++)				\
+			r[i] = d[i];					\
+	}
+
+/*
+ * READWRITE (fetch-write)
+ */
+#define OFI_DEF_READWRITE_NAME(op, type) ofi_readwrite_## op ##_## type,
+#define OFI_DEF_READWRITE_COMPLEX_NAME(op, type) ofi_readwrite_## op ##_## type,
+
+#define OFI_DEF_READWRITE_FUNC(op, type)				\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		size_t i;						\
+		type *d = (dst);					\
+		const type *s = (src);					\
+		type *r = (res);					\
+		for (i = 0; i < cnt; i++) {				\
+			r[i] = d[i];					\
+			op(type, d[i], s[i]);				\
+		}							\
+	}
+
+#define OFI_DEF_READWRITE_COMPLEX_FUNC(op, type)			\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		size_t i;						\
+		ofi_complex_##type *d = (dst);				\
+		const ofi_complex_##type *s = (src);			\
+		ofi_complex_##type *r = (res);				\
+		for (i = 0; i < cnt; i++) {				\
+			r[i] = d[i];					\
+			op(type, d[i], s[i]);				\
+		}							\
+	}
+
+/*
+ * CSWAP
+ */
+#define OFI_DEF_CSWAP_NAME(op, type) ofi_cswap_## op ##_## type,
+#define OFI_DEF_CSWAP_COMPLEX_NAME(op, type) ofi_cswap_## op ##_## type,
+
+#define OFI_DEF_CSWAP_FUNC(op, type)					\
+	static void ofi_cswap_## op ##_## type				\
+		(void *dst, const void *src, const void *cmp,		\
+		 void *res, size_t cnt)					\
+	{								\
+		size_t i;						\
+		type *d = (dst);					\
+		const type *s = (src);					\
+		const type *c = (cmp);					\
+		type *r = (res);					\
+		for (i = 0; i < cnt; i++) {				\
+			r[i] = d[i];					\
+			op(type, d[i], s[i], c[i]);			\
+		}							\
+	}
+
+#define OFI_DEF_CSWAP_COMPLEX_FUNC(op, type)				\
+	static void ofi_cswap_## op ##_## type				\
+		(void *dst, const void *src, const void *cmp,		\
+		 void *res, size_t cnt)					\
+	{								\
+		size_t i;						\
+		ofi_complex_##type *d = (dst);				\
+		const ofi_complex_##type *s = (src);			\
+		const ofi_complex_##type *c = (cmp);			\
+		ofi_complex_##type *r = (res);				\
+		for (i = 0; i < cnt; i++) {				\
+			r[i] = d[i];					\
+			op(type, d[i], s[i], c[i]);			\
+		}							\
+	}
+
+
+/*********************************************************************
+ * Macros create atomic functions for each operation for each datatype
+ *********************************************************************/
+
+/*
+ * Define all handlers in order to populate the dispatch table correctly.
+ *
+ * ATOMICTYPE - WRITE, READ, READWRITE, CSWAP, MSWAP
+ * FUNCNAME - Define function or simply generate function name
+ *            The latter is needed to populate the dispatch table
+ * op - OFI_OP_XXX function should perform (e.g. OFI_OP_MIN)
+ */
+#define OFI_DEFINE_ALL_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, float)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, double)			\
+	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, float)	\
+	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, double)\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, long_double)		\
+	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, long_double)
+
+#define OFI_DEFINE_REALNO_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, float)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, double)			\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, long_double)		\
+	OFI_DEF_NOOP_##FUNCNAME
+
+#define OFI_DEFINE_INT_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint64_t)			\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME
+
+
+/**********************
+ * Write dispatch table
+ **********************/
+
+OFI_DEFINE_REALNO_HANDLERS(WRITE, FUNC, OFI_OP_MIN)
+OFI_DEFINE_REALNO_HANDLERS(WRITE, FUNC, OFI_OP_MAX)
+OFI_DEFINE_ALL_HANDLERS(WRITE, FUNC, OFI_OP_SUM)
+OFI_DEFINE_ALL_HANDLERS(WRITE, FUNC, OFI_OP_PROD)
+OFI_DEFINE_ALL_HANDLERS(WRITE, FUNC, OFI_OP_LOR)
+OFI_DEFINE_ALL_HANDLERS(WRITE, FUNC, OFI_OP_LAND)
+OFI_DEFINE_INT_HANDLERS(WRITE, FUNC, OFI_OP_BOR)
+OFI_DEFINE_INT_HANDLERS(WRITE, FUNC, OFI_OP_BAND)
+OFI_DEFINE_ALL_HANDLERS(WRITE, FUNC, OFI_OP_LXOR)
+OFI_DEFINE_INT_HANDLERS(WRITE, FUNC, OFI_OP_BXOR)
+OFI_DEFINE_ALL_HANDLERS(WRITE, FUNC, OFI_OP_WRITE)
+
+void (*ofi_atomic_write_handlers[OFI_WRITE_OP_LAST][FI_DATATYPE_LAST])
+	(void *dst, const void *src, size_t cnt) =
+{
+	{ OFI_DEFINE_REALNO_HANDLERS(WRITE, NAME, OFI_OP_MIN) },
+	{ OFI_DEFINE_REALNO_HANDLERS(WRITE, NAME, OFI_OP_MAX) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_SUM) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_PROD) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_LOR) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_LAND) },
+	{ OFI_DEFINE_INT_HANDLERS(WRITE, NAME, OFI_OP_BOR) },
+	{ OFI_DEFINE_INT_HANDLERS(WRITE, NAME, OFI_OP_BAND) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_LXOR) },
+	{ OFI_DEFINE_INT_HANDLERS(WRITE, NAME, OFI_OP_BXOR) },
+	 /* no-op: FI_ATOMIC_READ */
+	{ NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL},
+	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_WRITE) },
+};
+
+
+/***************************
+ * Read-write dispatch table
+ ***************************/
+
+OFI_DEFINE_REALNO_HANDLERS(READWRITE, FUNC, OFI_OP_MIN)
+OFI_DEFINE_REALNO_HANDLERS(READWRITE, FUNC, OFI_OP_MAX)
+OFI_DEFINE_ALL_HANDLERS(READWRITE, FUNC, OFI_OP_SUM)
+OFI_DEFINE_ALL_HANDLERS(READWRITE, FUNC, OFI_OP_PROD)
+OFI_DEFINE_ALL_HANDLERS(READWRITE, FUNC, OFI_OP_LOR)
+OFI_DEFINE_ALL_HANDLERS(READWRITE, FUNC, OFI_OP_LAND)
+OFI_DEFINE_INT_HANDLERS(READWRITE, FUNC, OFI_OP_BOR)
+OFI_DEFINE_INT_HANDLERS(READWRITE, FUNC, OFI_OP_BAND)
+OFI_DEFINE_ALL_HANDLERS(READWRITE, FUNC, OFI_OP_LXOR)
+OFI_DEFINE_INT_HANDLERS(READWRITE, FUNC, OFI_OP_BXOR)
+OFI_DEFINE_ALL_HANDLERS(READ, FUNC, OFI_OP_READ)
+OFI_DEFINE_ALL_HANDLERS(READWRITE, FUNC, OFI_OP_WRITE)
+
+void (*ofi_atomic_readwrite_handlers[OFI_READWRITE_OP_LAST][FI_DATATYPE_LAST])
+	(void *dst, const void *src, void *res, size_t cnt) =
+{
+	{ OFI_DEFINE_REALNO_HANDLERS(READWRITE, NAME, OFI_OP_MIN) },
+	{ OFI_DEFINE_REALNO_HANDLERS(READWRITE, NAME, OFI_OP_MAX) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITE, NAME, OFI_OP_SUM) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITE, NAME, OFI_OP_PROD) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITE, NAME, OFI_OP_LOR) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITE, NAME, OFI_OP_LAND) },
+	{ OFI_DEFINE_INT_HANDLERS(READWRITE, NAME, OFI_OP_BOR) },
+	{ OFI_DEFINE_INT_HANDLERS(READWRITE, NAME, OFI_OP_BAND) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITE, NAME, OFI_OP_LXOR) },
+	{ OFI_DEFINE_INT_HANDLERS(READWRITE, NAME, OFI_OP_BXOR) },
+	{ OFI_DEFINE_ALL_HANDLERS(READ, NAME, OFI_OP_READ) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITE, NAME, OFI_OP_WRITE) },
+};
+
+
+/*****************************
+ * Compare-swap dispatch table
+ *****************************/
+
+OFI_DEFINE_ALL_HANDLERS(CSWAP, FUNC, OFI_OP_CSWAP_EQ)
+OFI_DEFINE_ALL_HANDLERS(CSWAP, FUNC, OFI_OP_CSWAP_NE)
+OFI_DEFINE_REALNO_HANDLERS(CSWAP, FUNC, OFI_OP_CSWAP_LE)
+OFI_DEFINE_REALNO_HANDLERS(CSWAP, FUNC, OFI_OP_CSWAP_LT)
+OFI_DEFINE_REALNO_HANDLERS(CSWAP, FUNC, OFI_OP_CSWAP_GE)
+OFI_DEFINE_REALNO_HANDLERS(CSWAP, FUNC, OFI_OP_CSWAP_GT)
+OFI_DEFINE_INT_HANDLERS(CSWAP, FUNC, OFI_OP_MSWAP)
+
+void (*ofi_atomic_swap_handlers[OFI_SWAP_OP_LAST][FI_DATATYPE_LAST])
+	(void *dst, const void *src, const void *cmp, void *res, size_t cnt) =
+{
+	{ OFI_DEFINE_ALL_HANDLERS(CSWAP, NAME, OFI_OP_CSWAP_EQ) },
+	{ OFI_DEFINE_ALL_HANDLERS(CSWAP, NAME, OFI_OP_CSWAP_NE) },
+	{ OFI_DEFINE_REALNO_HANDLERS(CSWAP, NAME, OFI_OP_CSWAP_LE) },
+	{ OFI_DEFINE_REALNO_HANDLERS(CSWAP, NAME, OFI_OP_CSWAP_LT) },
+	{ OFI_DEFINE_REALNO_HANDLERS(CSWAP, NAME, OFI_OP_CSWAP_GE) },
+	{ OFI_DEFINE_REALNO_HANDLERS(CSWAP, NAME, OFI_OP_CSWAP_GT) },
+	{ OFI_DEFINE_INT_HANDLERS(CSWAP, NAME, OFI_OP_MSWAP) },
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ofi_atomic.h b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ofi_atomic.h
new file mode 100644
index 000000000..98966e238
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/ofi_atomic.h
@@ -0,0 +1,100 @@
+/*
+ * Copyright (c) 2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistibutions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _OFI_ATOMIC_H_
+#define _OFI_ATOMIC_H_
+
+#include "fabtest.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+typedef long double long_double;
+typedef float complex ofi_complex_float;
+typedef double complex ofi_complex_double;
+typedef long double complex ofi_complex_long_double;
+
+#define OFI_WRITE_OP_LAST	FI_CSWAP
+#define OFI_READWRITE_OP_LAST	FI_CSWAP
+#define OFI_SWAP_OP_START	FI_CSWAP
+#define OFI_SWAP_OP_LAST	(FI_MSWAP - FI_CSWAP + 1)
+
+extern void (*ofi_atomic_write_handlers[OFI_WRITE_OP_LAST][FI_DATATYPE_LAST])
+			(void *dst, const void *src, size_t cnt);
+extern void (*ofi_atomic_readwrite_handlers[OFI_READWRITE_OP_LAST][FI_DATATYPE_LAST])
+			(void *dst, const void *src, void *res, size_t cnt);
+extern void (*ofi_atomic_swap_handlers[OFI_SWAP_OP_LAST][FI_DATATYPE_LAST])
+			(void *dst, const void *src, const void *cmp,
+			 void *res, size_t cnt);
+
+#define OFI_DEF_COMPLEX_OPS(type)				\
+static inline int ofi_complex_eq_## type			\
+	(ofi_complex_## type a, ofi_complex_## type b)		\
+{								\
+	return a == b;						\
+}								\
+static inline ofi_complex_## type ofi_complex_sum_## type	\
+	(ofi_complex_## type a, ofi_complex_## type b)		\
+{								\
+	return a + b;						\
+}								\
+static inline ofi_complex_## type ofi_complex_prod_## type	\
+	(ofi_complex_## type a, ofi_complex_## type b)		\
+{								\
+	return a * b;						\
+}								\
+static inline ofi_complex_## type ofi_complex_land_## type	\
+	(ofi_complex_## type a, ofi_complex_## type b)		\
+{								\
+	return a && b;      					\
+}								\
+static inline ofi_complex_## type ofi_complex_lor_## type	\
+	(ofi_complex_## type a, ofi_complex_## type b)		\
+{								\
+	return a || b;						\
+}								\
+static inline int ofi_complex_lxor_## type			\
+	(ofi_complex_## type a, ofi_complex_## type b)		\
+{								\
+	return (a && !b) || (!a && b);				\
+}								\
+
+OFI_DEF_COMPLEX_OPS(float)
+OFI_DEF_COMPLEX_OPS(double)
+OFI_DEF_COMPLEX_OPS(long_double)
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _OFI_ATOMIC_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/test_ctrl.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/test_ctrl.c
new file mode 100644
index 000000000..2d2388db3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/test_ctrl.c
@@ -0,0 +1,1110 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <sys/socket.h>
+
+#include "fabtest.h"
+
+void ft_record_error(int error)
+{
+	if (!ft_ctrl.error) {
+		fprintf(stderr, "ERROR [%s], continuing with test",
+			fi_strerror(error));
+		ft_ctrl.error = error;
+	}
+}
+
+static int ft_init_xcontrol(struct ft_xcontrol *ctrl)
+{
+	memset(ctrl, 0, sizeof *ctrl);
+	ctrl->credits = FT_DEFAULT_CREDITS;
+	ctrl->max_credits =  FT_DEFAULT_CREDITS;
+
+	ctrl->iov = calloc(ft_ctrl.iov_array[ft_ctrl.iov_cnt - 1], sizeof *ctrl->iov);
+	ctrl->iov_desc = calloc(ft_ctrl.iov_array[ft_ctrl.iov_cnt - 1],
+				sizeof *ctrl->iov_desc);
+	ctrl->ctx = calloc(ctrl->max_credits, sizeof *ctrl->ctx);
+	if (!ctrl->iov || !ctrl->iov_desc || !ctrl->ctx)
+		return -FI_ENOMEM;
+
+	return 0;
+}
+
+static int ft_init_rx_control(void)
+{
+	int ret;
+
+	ret = ft_init_xcontrol(&ft_rx_ctrl);
+	if (ret)
+		return ret;
+
+	ft_rx_ctrl.cq_format = FI_CQ_FORMAT_DATA;
+	ft_rx_ctrl.addr = FI_ADDR_UNSPEC;
+
+	ft_rx_ctrl.msg_size = med_size_array[med_size_cnt - 1];
+	if (fabric_info && fabric_info->ep_attr &&
+	    fabric_info->ep_attr->max_msg_size &&
+	    fabric_info->ep_attr->max_msg_size < ft_rx_ctrl.msg_size)
+		ft_rx_ctrl.msg_size = fabric_info->ep_attr->max_msg_size;
+
+	return 0;
+}
+
+static int ft_init_tx_control(void)
+{
+	int ret;
+
+	ret = ft_init_xcontrol(&ft_tx_ctrl);
+	if (ret)
+		return ret;
+
+	ft_tx_ctrl.cq_format = FI_CQ_FORMAT_CONTEXT;
+	ft_tx_ctrl.remote_cq_data = ft_init_cq_data(fabric_info);
+	return 0;
+}
+
+static int ft_init_atomic_control(struct ft_atomic_control *ctrl)
+{
+	memset(ctrl, 0, sizeof *ctrl);
+	ctrl->op = test_info.op;
+
+	ctrl->ioc = calloc(ft_ctrl.iov_array[ft_ctrl.iov_cnt - 1], sizeof *ctrl->ioc);
+	ctrl->res_ioc = calloc(ft_ctrl.iov_array[ft_ctrl.iov_cnt - 1],
+				sizeof *ctrl->res_ioc);
+	ctrl->comp_ioc = calloc(ft_ctrl.iov_array[ft_ctrl.iov_cnt - 1],
+				sizeof *ctrl->comp_ioc);
+
+	if (!ctrl->ioc || !ctrl->res_ioc || !ctrl->comp_ioc)
+		return -FI_ENOMEM;
+
+	return 0;
+}
+
+static int ft_init_control(void)
+{
+	int ret;
+
+	memset(&ft_ctrl, 0, sizeof ft_ctrl);
+	ft_ctrl.xfer_iter = FT_DEFAULT_CREDITS;
+	ft_ctrl.inc_step = test_info.test_flags & FT_FLAG_QUICKTEST ? 4 : 1;
+
+	ft_ctrl.iov_array = sm_size_array;
+	ft_ctrl.iov_cnt = sm_size_cnt;
+
+	if (test_info.test_class & FI_RMA) {
+		ft_ctrl.size_array = lg_size_array;
+		ft_ctrl.size_cnt = lg_size_cnt;
+	} else {
+		ft_ctrl.size_array = med_size_array;
+		ft_ctrl.size_cnt = med_size_cnt;
+	}
+
+	ret = ft_init_rx_control();
+	if (ret)
+		return ret;
+
+	ret = ft_init_tx_control();
+	if (ret)
+		return ret;
+
+	ret = ft_init_atomic_control(&ft_atom_ctrl);
+	return ret;
+}
+
+static void ft_cleanup_xcontrol(struct ft_xcontrol *ctrl)
+{
+	free(ctrl->buf);
+	free(ctrl->iov);
+	free(ctrl->iov_desc);
+	free(ctrl->ctx);
+	memset(ctrl, 0, sizeof *ctrl);
+}
+
+static void ft_cleanup_atomic_control(struct ft_atomic_control *ctrl)
+{
+	free(ctrl->res_buf);
+	free(ctrl->comp_buf);
+	free(ctrl->ioc);
+	free(ctrl->res_ioc);
+	free(ctrl->comp_ioc);
+	free(ctrl->orig_buf);
+	memset(ctrl, 0, sizeof *ctrl);
+}
+
+static void ft_cleanup_mr_control(struct ft_mr_control *ctrl)
+{
+	free(ctrl->buf);
+	memset(ctrl, 0, sizeof *ctrl);
+}
+
+static void ft_format_iov_distributed(struct iovec *iov, size_t cnt, char *buf,
+		size_t len)
+{
+	size_t offset;
+	int i;
+
+	for (i = 0, offset = 0; i < cnt - 1; i++) {
+		iov[i].iov_base = buf + offset;
+		iov[i].iov_len = len / cnt;
+		offset += iov[i].iov_len;
+	}
+	iov[i].iov_base = buf + offset;
+	iov[i].iov_len = len - offset;
+}
+
+/* One class of bugs is issues involving IOV length handling. The regular
+ * ft_format_iov does not catch this class because it evenly partitions the
+ * entries. Instead partition them proportional to their position in the iovec.
+ */
+static void _ft_format_iov_weighted(struct iovec *iov, size_t cnt, char *buf,
+		size_t len, int reversed)
+{
+	double total_parts;
+	double portion;
+	size_t offset;
+	size_t weight;
+	size_t size;
+	size_t i;
+
+	/* Get the sum of the element positions in the list and calculate the
+	 * base weight.
+	 */
+	total_parts = ((cnt + 1.0) * cnt) / 2.0;
+	portion = len / total_parts;
+
+	for (offset = 0, i = 0; i < cnt; i++) {
+		if (reversed)
+			weight = cnt - i;
+		else
+			weight = i + 1;
+
+		/* Get the weight for this iovec entry and round it to the
+		 * nearest integer.
+		 */
+		size = (portion * weight) + .5;
+
+		iov[i].iov_base = buf + offset;
+		iov[i].iov_len = size;
+
+		offset += size;
+	}
+}
+
+static void ft_format_iov_weighted(struct iovec *iov, size_t cnt, char *buf,
+		size_t len)
+{
+	_ft_format_iov_weighted(iov, cnt, buf, len, 0);
+}
+
+static void ft_format_iov_reversed(struct iovec *iov, size_t cnt, char *buf,
+		size_t len)
+{
+	_ft_format_iov_weighted(iov, cnt, buf, len, 1);
+}
+
+static void ft_format_iov_random(struct iovec *iov, size_t cnt, char *buf,
+		size_t len)
+{
+	size_t offset;
+	size_t weight;
+	size_t i;
+
+	offset = 0;
+	for (i = 0; i < cnt; i++) {
+		/* If last IOV then use remaining data. */
+		if (i == (cnt - 1)) {
+			weight = len;
+		} else {
+			/* Get a weight between 1 and the remaining length minus
+			 * the remaining IOV count. This is so we can reserve at
+			 * least a length of 1 for every IOV.
+			 */
+			weight = (rand() % (len - (cnt - i) + 1)) + 1;
+		}
+
+		len -= weight;
+
+		iov[i].iov_base = buf + offset;
+		iov[i].iov_len = weight;
+
+		offset += weight;
+	}
+}
+
+void ft_format_iov(struct iovec *iov, size_t cnt, char *buf, size_t len)
+{
+	typedef void (*iov_formatter)(struct iovec *iov, size_t cnt, char *buf,
+			size_t len);
+	size_t choice;
+
+	static iov_formatter options[] = {
+		ft_format_iov_distributed,
+		ft_format_iov_weighted,
+		ft_format_iov_reversed,
+		ft_format_iov_random
+	};
+
+	choice = rand() % ARRAY_SIZE(options);
+
+	options[choice](iov, cnt, buf, len);
+}
+
+static void ft_iov_to_ioc(struct iovec *iov, struct fi_ioc *ioc, size_t cnt,
+		   enum fi_datatype datatype, char *buf)
+{
+	int i;
+	size_t offset = 0;
+	for (i = 0; i < cnt; i++) {
+		ioc[i].count = iov[i].iov_len;
+		ioc[i].addr = buf + offset;
+		offset += ioc[i].count * ft_atom_ctrl.datatype_size;
+	}
+}
+
+void ft_format_iocs(struct iovec *iov, size_t *iov_count)
+{
+	while(ft_ctrl.iov_array[ft_tx_ctrl.iov_iter] > ft_atom_ctrl.count)
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+
+	*iov_count = ft_ctrl.iov_array[ft_tx_ctrl.iov_iter];
+	ft_format_iov(iov, *iov_count, ft_tx_ctrl.buf, ft_atom_ctrl.count);
+	ft_iov_to_ioc(iov, ft_atom_ctrl.ioc, *iov_count,
+			ft_atom_ctrl.datatype, ft_tx_ctrl.buf);
+	ft_iov_to_ioc(iov, ft_atom_ctrl.res_ioc, *iov_count,
+			ft_atom_ctrl.datatype, ft_atom_ctrl.res_buf);
+	ft_iov_to_ioc(iov, ft_atom_ctrl.comp_ioc, *iov_count,
+			ft_atom_ctrl.datatype, ft_atom_ctrl.comp_buf);
+}
+
+void ft_next_iov_cnt(struct ft_xcontrol *ctrl, size_t max_iov_cnt)
+{
+	ctrl->iov_iter++;
+	if (ctrl->iov_iter > ft_ctrl.iov_cnt ||
+	    ft_ctrl.iov_array[ctrl->iov_iter] > max_iov_cnt)
+		ctrl->iov_iter = 0;
+}
+
+int ft_get_ctx(struct ft_xcontrol *ctrl, struct fi_context **ctx)
+{
+	int ret;
+
+	ctrl->curr_ctx++;
+	if (ctrl->curr_ctx >= ctrl->max_credits) {
+		if (ctrl == &ft_tx_ctrl) {
+			while (ctrl->credits < ctrl->max_credits) {
+				ret = ft_comp_tx(FT_COMP_TO);
+				if (ret)
+					return ret;
+			}
+		}
+		ctrl->curr_ctx = 0;
+	}
+	*ctx = &(ctrl->ctx[ctrl->curr_ctx]);
+	return 0;
+}
+
+static int check_atomic(size_t *count)
+{
+	int ret;
+
+	switch (test_info.class_function) {
+	case FT_FUNC_ATOMIC:
+	case FT_FUNC_ATOMICV:
+	case FT_FUNC_ATOMICMSG:
+	case FT_FUNC_INJECT_ATOMIC:
+		ret = check_base_atomic_op(ft_tx_ctrl.ep, ft_atom_ctrl.op,
+			ft_atom_ctrl.datatype, count);
+		break;
+	case FT_FUNC_FETCH_ATOMIC:
+	case FT_FUNC_FETCH_ATOMICV:
+	case FT_FUNC_FETCH_ATOMICMSG:
+		ret = check_fetch_atomic_op(ft_tx_ctrl.ep, ft_atom_ctrl.op,
+			ft_atom_ctrl.datatype, count);
+		break;
+	case FT_FUNC_COMPARE_ATOMIC:
+	case FT_FUNC_COMPARE_ATOMICV:
+	default:
+		ret = check_compare_atomic_op(ft_tx_ctrl.ep, ft_atom_ctrl.op,
+			ft_atom_ctrl.datatype, count);
+	}
+
+	ft_atom_ctrl.datatype_size = datatype_to_size(ft_atom_ctrl.datatype);
+
+	return ret;
+}
+
+static int ft_sync_test(int value)
+{
+	int ret;
+
+	ret = ft_reset_ep();
+	if (ret)
+		return ret;
+
+	return ft_sock_sync(value);
+}
+
+static int ft_sync_manual()
+{
+	int ret, value = 0, result = -FI_EOTHER;
+
+	if (listen_sock < 0) {
+		ret = send(sock, &value, sizeof(value), 0);
+		if (ret != sizeof(value))
+			return -FI_EOTHER;
+
+		do {
+			ret = recv(sock, &result, sizeof(result), MSG_DONTWAIT);
+			if (ret == sizeof(result))
+				break;
+
+			ret = ft_comp_rx(0);
+			if (ret)
+				return ret;
+		} while (1);
+	} else {
+		do {
+			ret = recv(sock, &result, sizeof(result), MSG_DONTWAIT);
+			if (ret == sizeof(result))
+				break;
+
+			ret = ft_comp_rx(0);
+			if (ret)
+				return ret;
+		} while (1);
+
+		ret = send(sock, &value, sizeof(value), 0);
+		if (ret != sizeof(value))
+			return -FI_EOTHER;
+	}
+	return 0;
+}
+
+static int ft_sync_progress(int value)
+{
+	if (test_info.progress == FI_PROGRESS_MANUAL)
+		return ft_sync_manual();
+	return ft_sock_sync(value);
+}
+
+static int ft_sync_msg_needed(void)
+{
+	return ft_check_rx_completion() ? 0 : ft_send_sync_msg();
+}
+
+static int ft_check_verify_cnt()
+{
+	if (test_info.msg_flags == FI_REMOTE_CQ_DATA &&
+	    ft_ctrl.verify_cnt != ft_ctrl.xfer_iter)
+		return -FI_EIO;
+	return 0;
+}
+
+static int ft_pingpong_rma(void)
+{
+	int ret = 0, i;
+	size_t count;
+
+	if (test_info.test_class & FI_ATOMIC) {
+		ret = check_atomic(&count);
+
+		ft_atom_ctrl.count = ft_tx_ctrl.rma_msg_size / ft_atom_ctrl.datatype_size;
+		if (ret == -FI_ENOSYS || ret == -FI_EOPNOTSUPP ||
+		    ft_atom_ctrl.count > count || ft_atom_ctrl.count == 0) {
+			return 0;
+		}
+		if (ret)
+			return ret;
+	}
+
+	if (listen_sock < 0) {
+		for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+			ret = ft_send_rma();
+			if (ret)
+				return ret;
+
+			if (ft_check_tx_completion()) {
+				ret = ft_comp_tx(FT_COMP_TO);
+				if (ret)
+					return ret;
+			}
+			ret = ft_sync_msg_needed();
+			if (ret)
+				return ret;
+
+			ret = ft_recv_msg();
+			if (ret)
+				return ret;
+		}
+	} else {
+		for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+			ret = ft_recv_msg();
+			if (ret)
+				return ret;
+
+			ret = ft_send_rma();
+			if (ret)
+				return ret;
+
+			if (ft_check_tx_completion()) {
+				ret = ft_comp_tx(FT_COMP_TO);
+				if (ret)
+					return ret;
+			}
+
+			ret = ft_sync_msg_needed();
+			if (ret)
+				return ret;
+		}
+	}
+	return ret;
+}
+
+static int ft_pingpong(void)
+{
+	int ret, i;
+
+	if (test_info.test_class & (FI_RMA | FI_ATOMIC))
+		return ft_pingpong_rma();
+
+	if (listen_sock < 0) {
+		for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+			ret = ft_send_msg();
+			if (ret)
+				return ret;
+
+			if (ft_check_tx_completion()) {
+				ret = ft_comp_tx(FT_COMP_TO);
+				if (ret)
+					return ret;
+			}
+
+			ret = ft_recv_msg();
+			if (ret)
+				return ret;
+		}
+	} else {
+		for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+			ret = ft_recv_msg();
+			if (ret)
+				return ret;
+
+			ret = ft_send_msg();
+			if (ret)
+				return ret;
+
+			if (ft_check_tx_completion()) {
+				ret = ft_comp_tx(FT_COMP_TO);
+				if (ret)
+					return ret;
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int ft_pingpong_dgram(void)
+{
+	int ret, i;
+
+	if (listen_sock < 0) {
+		for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+			ret = ft_sendrecv_dgram();
+			if (ret)
+				return ret;
+		}
+	} else {
+		for (i = 0; i < 1000; i++) {
+			ret = ft_recv_dgram();
+			if (!ret)
+				break;
+			else if (ret != -FI_ETIMEDOUT)
+				return ret;
+		}
+
+		for (i = 0; i < ft_ctrl.xfer_iter - 1; i++) {
+			ret = ft_sendrecv_dgram();
+			if (ret)
+				return ret;
+		}
+
+		ret = ft_send_dgram();
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+static int ft_run_latency(void)
+{
+	int ret, i;
+
+	for (i = 0; i < ft_ctrl.size_cnt; i += ft_ctrl.inc_step) {
+		if (ft_ctrl.size_array[i] > fabric_info->ep_attr->max_msg_size)
+			break;
+
+		if (test_info.test_class & (FI_RMA | FI_ATOMIC)) {
+			ft_tx_ctrl.msg_size = ft_ctrl.size_array[0];
+			ft_tx_ctrl.rma_msg_size = ft_ctrl.size_array[i];
+		} else {
+			ft_tx_ctrl.msg_size = ft_ctrl.size_array[i];
+		}
+
+		if (is_inject_func(test_info.class_function) &&
+			(ft_ctrl.size_array[i] > fabric_info->tx_attr->inject_size))
+			break;
+
+		ft_ctrl.xfer_iter = test_info.test_flags & FT_FLAG_QUICKTEST ?
+				5 : size_to_count(ft_ctrl.size_array[i]);
+
+		ret = ft_sync_test(0);
+		if (ret)
+			return ret;
+
+		ret = ft_post_recv_bufs();
+		if (ret)
+			return ret;
+
+		clock_gettime(CLOCK_MONOTONIC, &start);
+		ret = (test_info.ep_type == FI_EP_DGRAM) ?
+			ft_pingpong_dgram() : ft_pingpong();
+		clock_gettime(CLOCK_MONOTONIC, &end);
+		if (ret) {
+			FT_PRINTERR("latency test failed!", ret);
+			return ret;
+		}
+
+		ret = ft_sync_progress(0);
+		if (ret)
+			return ret;
+
+		show_perf("lat", ft_ctrl.size_array[i], ft_ctrl.xfer_iter, &start, &end, 2);
+	}
+
+	return 0;
+}
+
+static int ft_bw_rma(void)
+{
+	int ret, i;
+	size_t count;
+
+	if (test_info.test_class & FI_ATOMIC) {
+		ret = check_atomic(&count);
+
+		ft_atom_ctrl.count = ft_tx_ctrl.rma_msg_size / ft_atom_ctrl.datatype_size;
+		if (ret == -FI_ENOSYS || ret == -FI_EOPNOTSUPP ||
+		    ft_atom_ctrl.count > count || ft_atom_ctrl.count == 0) {
+			return 0;
+		}
+		if (ret)
+			return ret;
+	}
+
+	if (listen_sock < 0) {
+		for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+			ret = ft_send_rma();
+			if (ret)
+				return ret;
+		}
+		ret = ft_sync_msg_needed();
+		if (ret)
+			return ret;
+
+		ret = ft_recv_msg();
+		if (ret)
+			return ret;
+	} else {
+		ret = ft_recv_n_msg(ft_check_rx_completion() ?
+				    ft_ctrl.xfer_iter : 1);
+		if (ret)
+			return ret;
+
+		ret = ft_send_sync_msg();
+		if (ret)
+			return ret;
+	}
+	return 0;
+}
+
+static int ft_bw(void)
+{
+	int ret, i;
+
+	if (test_info.test_class & (FI_RMA | FI_ATOMIC))
+		return ft_bw_rma();
+
+	if (listen_sock < 0) {
+		for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+			ret = ft_send_msg();
+			if (ret)
+				return ret;
+		}
+
+		ret = ft_sync_msg_needed();
+		if (ret)
+			return ret;
+
+		ret = ft_recv_msg();
+		if (ret)
+			return ret;
+	} else {
+		ret = ft_recv_n_msg(ft_check_rx_completion() ?
+				    ft_ctrl.xfer_iter : 1);
+		if (ret)
+			return ret;
+
+		ret = ft_send_sync_msg();
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+/*
+ * The datagram streaming test sends datagrams with the initial byte
+ * of the message cleared until we're ready to end the test.  The first
+ * byte is then set to 0xFF.  On the receive side, we count the number
+ * of completions until that message is seen.  Only the receiving side
+ * reports any performance data.  The sender does not know how many
+ * packets were dropped in flight.
+ *
+ * Because we re-use the same buffer for all messages, the receiving
+ * side can notice that the first byte has changed and end the test
+ * before the completion associated with the last message has been
+ * written to the CQ.  As a result, the number of messages that were
+ * counted as received may be slightly lower than the number of messages
+ * that were actually received.
+ *
+ * For a significantly large number of transfers, this falls into the
+ * noise, but it is visible if the number of iterations is small, such
+ * as when running the quick test.  The fix for this would either to use
+ * CQ data to exchange the end of test marker, or to allocate separate
+ * buffers for each receive operation.
+ *
+ * The message with the end of test marker is retried until until the
+ * receiver acknowledges it.  If the receiver ack message is lost, the
+ * bandwidth test will hang.  However, this is the only message that the
+ * receiver sends, so there's a reasonably good chance of it being transmitted
+ * successfully.
+ */
+static int ft_bw_dgram(size_t *recv_cnt)
+{
+	int ret;
+
+	if (listen_sock < 0) {
+		*recv_cnt = 0;
+		ret = ft_send_dgram_flood();
+		if (ret)
+			return ret;
+
+		ft_tx_ctrl.seqno = ~0;
+		ret = ft_sendrecv_dgram();
+	} else {
+		ret = ft_recv_dgram_flood(recv_cnt);
+		if (ret)
+			return ret;
+
+		ret = ft_send_dgram();
+	}
+
+	return ret;
+}
+
+static int ft_run_bandwidth(void)
+{
+	size_t recv_cnt;
+	int ret, i;
+
+	for (i = 0; i < ft_ctrl.size_cnt; i += ft_ctrl.inc_step) {
+		if (ft_ctrl.size_array[i] > fabric_info->ep_attr->max_msg_size)
+			break;
+
+		if (test_info.test_class & (FI_RMA | FI_ATOMIC)) {
+			ft_tx_ctrl.msg_size = ft_ctrl.size_array[0];
+			ft_tx_ctrl.rma_msg_size = ft_ctrl.size_array[i];
+		} else {
+			ft_tx_ctrl.msg_size = ft_ctrl.size_array[i];
+		}
+
+		if (is_inject_func(test_info.class_function) &&
+			(ft_ctrl.size_array[i] > fabric_info->tx_attr->inject_size))
+			break;
+
+		ft_ctrl.xfer_iter = test_info.test_flags & FT_FLAG_QUICKTEST ?
+				5 : size_to_count(ft_ctrl.size_array[i]);
+		recv_cnt = ft_ctrl.xfer_iter;
+
+		ret = ft_sync_test(0);
+		if (ret)
+			return ret;
+
+		ret = ft_post_recv_bufs();
+		if (ret)
+			return ret;
+
+		clock_gettime(CLOCK_MONOTONIC, &start);
+		ret = (test_info.ep_type == FI_EP_DGRAM) ?
+			ft_bw_dgram(&recv_cnt) : ft_bw();
+		clock_gettime(CLOCK_MONOTONIC, &end);
+		if (ret) {
+			FT_PRINTERR("bw test failed!", ret);
+			return ret;
+		}
+
+		ret = ft_sync_progress(0);
+		if (ret)
+			return ret;
+
+		show_perf("bw", ft_ctrl.size_array[i], recv_cnt, &start, &end, 1);
+	}
+
+	return 0;
+}
+
+static int ft_unit_rma(void)
+{
+	int ret, i, fail = 0;
+
+	for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+		ft_sync_fill_bufs(ft_tx_ctrl.rma_msg_size);
+
+		ret = ft_send_rma();
+		if (ret)
+			return ret;
+
+		if (!is_inject_func(test_info.class_function)) {
+			ret = ft_comp_tx(FT_COMP_TO);
+			if (ret)
+				return ret;
+		}
+
+		ret = ft_sync_msg_needed();
+		if (ret)
+			return ret;
+
+		ret = ft_recv_msg();
+		if (ret)
+			return ret;
+
+		ret = ft_verify_bufs();
+		if (ret)
+			fail = -FI_EIO;
+	}
+
+	ret = ft_check_verify_cnt();
+	if (ret)
+		return ret;
+
+	return fail;
+}
+
+static int ft_unit_atomic(void)
+{
+	int ret, i, fail = 0;
+	size_t count;
+
+	ret = check_atomic(&count);
+
+	ft_atom_ctrl.count = ft_tx_ctrl.rma_msg_size / ft_atom_ctrl.datatype_size;
+	if (ret == -FI_ENOSYS || ret == -FI_EOPNOTSUPP ||
+	    ft_atom_ctrl.count > count || ft_atom_ctrl.count == 0) {
+		return 0;
+	}
+	if (ret)
+		return ret;
+
+	for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+		ft_sync_fill_bufs(ft_tx_ctrl.rma_msg_size);
+
+		ret = ft_send_rma();
+		if (ret)
+			return ret;
+
+		if (!is_inject_func(test_info.class_function)) {
+			ret = ft_comp_tx(FT_COMP_TO);
+			if (ret)
+				return ret;
+		}
+		ret = ft_sync_msg_needed();
+		if (ret)
+			return ret;
+
+		ret = ft_recv_msg();
+		if (ret)
+			return ret;
+
+		ret = ft_verify_bufs();
+		if (ret)
+			fail = -FI_EIO;
+	}
+
+	ret = ft_check_verify_cnt();
+	if (ret)
+		return ret;
+	return fail;
+}
+
+static int ft_unit(void)
+{
+	int ret, i, fail = 0;
+
+	ft_ctrl.verify_cnt = 0;
+	if (test_info.test_class & FI_RMA)
+		return ft_unit_rma();
+	else if (test_info.test_class & FI_ATOMIC)
+		return ft_unit_atomic();
+
+	for (i = 0; i < ft_ctrl.xfer_iter; i++) {
+		ft_sync_fill_bufs(ft_tx_ctrl.msg_size);
+
+		ret = ft_send_msg();
+		if (ret)
+			return ret;
+
+		if (ft_check_tx_completion()) {
+			ret = ft_comp_tx(FT_COMP_TO);
+			if (ret)
+				return ret;
+		}
+
+		ret = ft_sync_msg_needed();
+		if (ret)
+			return ret;
+
+		ret = ft_recv_msg();
+		if (ret)
+			return ret;
+
+		ret = ft_verify_bufs();
+		if (ret)
+			fail = -FI_EIO;
+	}
+	ret = ft_check_verify_cnt();
+	if (ret)
+		return ret;
+	return fail;
+}
+
+static int ft_run_unit(void)
+{
+	int i, ret, fail;
+
+	fail = ret = 0;
+
+	for (i = 0; i < ft_ctrl.size_cnt; i += ft_ctrl.inc_step) {
+		if (ft_ctrl.size_array[i] > fabric_info->ep_attr->max_msg_size)
+			break;
+
+		if (test_info.test_class & (FI_RMA | FI_ATOMIC)) {
+			ft_tx_ctrl.msg_size = ft_ctrl.size_array[0];
+			ft_tx_ctrl.rma_msg_size = ft_ctrl.size_array[i];
+		} else {
+			ft_tx_ctrl.msg_size = ft_ctrl.size_array[i];
+		}
+
+		if (is_inject_func(test_info.class_function) &&
+			(ft_ctrl.size_array[i] > fabric_info->tx_attr->inject_size))
+			break;
+
+		ft_ctrl.xfer_iter = test_info.test_flags & FT_FLAG_QUICKTEST ?
+				5 : size_to_count(ft_ctrl.size_array[i]);
+
+		ret = ft_sync_test(0);
+		if (ret)
+			return ret;
+
+		ret = ft_post_recv_bufs();
+		if (ret)
+			return ret;
+
+		ret = ft_unit();
+		if (ret) {
+			if (ret != -FI_EIO)
+				return ret;
+			fail = -FI_EIO;
+		}
+	}
+	if (fail)
+		printf("unit test FAILED\n");
+	else
+		printf("unit test PASSED\n");
+
+	return fail;
+}
+
+void ft_cleanup(void)
+{
+	FT_CLOSE_FID(ft_rx_ctrl.mr);
+	FT_CLOSE_FID(ft_tx_ctrl.mr);
+	FT_CLOSE_FID(ft_mr_ctrl.mr);
+	FT_CLOSE_FID(ft_atom_ctrl.res_mr);
+	FT_CLOSE_FID(ft_atom_ctrl.comp_mr);
+	ft_free_res();
+	ft_cleanup_xcontrol(&ft_rx_ctrl);
+	ft_cleanup_xcontrol(&ft_tx_ctrl);
+	ft_cleanup_mr_control(&ft_mr_ctrl);
+	ft_cleanup_atomic_control(&ft_atom_ctrl);
+	memset(&ft_ctrl, 0, sizeof ft_ctrl);
+}
+
+static int ft_exchange_mr_addr_key(void)
+{
+	struct fi_rma_iov local_rma_iov = {0};
+	struct fi_rma_iov peer_rma_iov = {0};
+	int ret;
+
+	if (!(test_info.mr_mode & (FI_MR_VIRT_ADDR | FI_MR_PROV_KEY)))
+		return 0;
+
+	if (test_info.mr_mode & FI_MR_VIRT_ADDR)
+		local_rma_iov.addr = (uint64_t) ft_mr_ctrl.buf;
+
+	if (test_info.mr_mode & FI_MR_PROV_KEY)
+		local_rma_iov.key = ft_mr_ctrl.mr_key;
+
+	ret = ft_sock_send(sock, &local_rma_iov, sizeof local_rma_iov);
+	if (ret) {
+		FT_PRINTERR("ft_sock_send", ret);
+		return ret;
+	}
+
+	ret = ft_sock_recv(sock, &peer_rma_iov, sizeof peer_rma_iov);
+	if (ret) {
+		FT_PRINTERR("ft_sock_recv", ret);
+		return ret;
+	}
+
+	ft_mr_ctrl.peer_mr_addr = peer_rma_iov.addr;
+	if (test_info.mr_mode & FI_MR_PROV_KEY)
+		ft_mr_ctrl.peer_mr_key = peer_rma_iov.key;
+
+	return 0;
+}
+
+int ft_open_res()
+{
+	int ret;
+
+	ret = ft_init_control();
+	if (ret) {
+		FT_PRINTERR("ft_init_control", ret);
+		goto cleanup;
+	}
+
+	ret = ft_open_control();
+	if (ret) {
+		FT_PRINTERR("ft_open_control", ret);
+		goto cleanup;
+	}
+	if (test_info.ep_type == FI_EP_MSG && listen_sock >= 0) {
+		ret = ft_open_passive();
+		if (ret) {
+			FT_PRINTERR("ft_open_passive", ret);
+			goto cleanup;
+		}
+	}
+	else {
+		ret = ft_open_active();
+		if (ret) {
+			FT_PRINTERR("ft_open_active", ret);
+			goto cleanup;
+		}
+	}
+
+	return 0;
+cleanup:
+	ft_cleanup();
+	return ret;
+}
+
+int ft_init_test()
+{
+	int ret;
+
+	ft_sock_sync(0);
+
+	ret = ft_enable_comm();
+	if (ret) {
+		FT_PRINTERR("ft_enable_comm", ret);
+		goto cleanup;
+	}
+
+	ret = ft_post_recv_bufs();
+	if (ret)
+		return ret;
+
+	ret = ft_exchange_mr_addr_key();
+	if (ret) {
+		FT_PRINTERR("ft_exchange_mr_address", ret);
+		goto cleanup;
+	}
+
+	return 0;
+cleanup:
+	ft_cleanup();
+	return ret;
+}
+
+int ft_run_test()
+{
+	int ret;
+
+	switch (test_info.test_type) {
+	case FT_TEST_UNIT:
+		ret = ft_run_unit();
+		if (ret)
+			FT_PRINTERR("ft_run_unit", ret);
+		break;
+	case FT_TEST_LATENCY:
+		ret = ft_run_latency();
+		if (ret)
+			FT_PRINTERR("ft_run_latency", ret);
+		break;
+	case FT_TEST_BANDWIDTH:
+		ret = ft_run_bandwidth();
+		if (ret)
+			FT_PRINTERR("ft_run_bandwidth", ret);
+		break;
+	default:
+		ret = -FI_ENOSYS;
+		break;
+	}
+
+	ft_sync_test(0);
+	ft_cleanup();
+
+	return ret ? ret : -ft_ctrl.error;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/uber.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/uber.c
new file mode 100644
index 000000000..6a34545b9
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/uber.c
@@ -0,0 +1,971 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include <time.h>
+#include <netdb.h>
+#include <unistd.h>
+#include <sys/wait.h>
+
+#include <limits.h>
+#include <shared.h>
+
+#include "fabtest.h"
+
+static int persistent = 1;
+static int do_fork = 0;
+
+//static struct timespec start, end;
+
+static struct ft_series *series;
+static int test_start_index, test_end_index = INT_MAX;
+struct ft_info test_info;
+struct fi_info *fabric_info;
+struct ft_xcontrol ft_rx_ctrl, ft_tx_ctrl;
+struct ft_mr_control ft_mr_ctrl;
+struct ft_atomic_control ft_atom_ctrl;
+struct ft_control ft_ctrl;
+
+size_t recv_size, send_size;
+
+enum {
+	FT_SUCCESS,
+	FT_SKIP,
+	FT_ENODATA,
+	FT_ENOSYS,
+	FT_ERROR,
+	FT_EIO,
+	FT_MAX_RESULT
+};
+
+static int results[FT_MAX_RESULT];
+static char *filename = NULL;
+static char *provname = NULL;
+static char *testname = NULL;
+
+
+static int ft_nullstr(char *str)
+{
+	return (!str || str[0] == '\0');
+}
+
+static char *ft_strptr(char *str)
+{
+	return ft_nullstr(str) ? NULL : str;
+}
+
+static char *ft_test_type_str(enum ft_test_type enum_str)
+{
+	switch (enum_str) {
+	case FT_TEST_LATENCY:
+		return "latency";
+	case FT_TEST_BANDWIDTH:
+		return "bandwidth";
+	case FT_TEST_UNIT:
+		return "unit";
+	default:
+		return "test_unspec";
+	}
+}
+
+static char *ft_class_func_str(enum ft_class_function enum_str)
+{
+	switch (enum_str) {
+	case FT_FUNC_SEND:
+		return (test_info.test_class & FI_TAGGED) ? "tsend" : "send";
+	case FT_FUNC_SENDV:
+		return (test_info.test_class & FI_TAGGED) ? "tsendv" : "sendv";
+	case FT_FUNC_SENDMSG:
+		return (test_info.test_class & FI_TAGGED) ? "tsendmsg" : "sendmsg";
+	case FT_FUNC_INJECT:
+		return (test_info.test_class & FI_TAGGED) ? "tinject" : "inject";
+	case FT_FUNC_INJECTDATA:
+		return (test_info.test_class & FI_TAGGED) ? "tinjectdata" : "injectdata";
+	case FT_FUNC_SENDDATA:
+		return (test_info.test_class & FI_TAGGED) ? "tsenddata" : "senddata";
+	case FT_FUNC_READ:
+		return "read";
+	case FT_FUNC_READV:
+		return "readv";
+	case FT_FUNC_READMSG:
+		return "readmsg";
+	case FT_FUNC_WRITE:
+		return "write";
+	case FT_FUNC_WRITEV:
+		return "writev";
+	case FT_FUNC_WRITEMSG:
+		return "writemsg";
+	case FT_FUNC_INJECT_WRITE:
+		return "inject_write";
+	case FT_FUNC_WRITEDATA:
+		return "writedata";
+	case FT_FUNC_INJECT_WRITEDATA:
+		return "inject_writedata";
+	case FT_FUNC_ATOMIC:
+		return "atomic";
+	case FT_FUNC_ATOMICV:
+		return "atomicv";
+	case FT_FUNC_ATOMICMSG:
+		return "atomic_msg";
+	case FT_FUNC_INJECT_ATOMIC:
+		return "inject_atomic";
+	case FT_FUNC_FETCH_ATOMIC:
+		return "fetch_atomic";
+	case FT_FUNC_FETCH_ATOMICV:
+		return "fetch_atomicv";
+	case FT_FUNC_FETCH_ATOMICMSG:
+		return "fetch_atomicmsg";
+	case FT_FUNC_COMPARE_ATOMIC:
+		return "compare_atomic";
+	case FT_FUNC_COMPARE_ATOMICV:
+		return "compare_atomicv";
+	case FT_FUNC_COMPARE_ATOMICMSG:
+		return "compare_atomicmsg";
+	default:
+		return "func_unspec";
+	}
+}
+
+static char *ft_wait_obj_str(enum fi_wait_obj enum_str)
+{
+	switch (enum_str) {
+	case FI_WAIT_NONE:
+		return "wait_none";
+	case FI_WAIT_UNSPEC:
+		return "wait_unspec";
+	case FI_WAIT_SET:
+		return "wait_set";
+	case FI_WAIT_FD:
+		return "wait_fd";
+	case FI_WAIT_MUTEX_COND:
+		return "wait_mutex_cond";
+	default:
+		return "";
+	}
+}
+
+static void ft_print_comp_flag(uint64_t bind, uint64_t op)
+{
+	printf("(bind-%s, op-%s)", (bind & FI_SELECTIVE_COMPLETION) ?
+		"FI_SELECTIVE_COMPLETION" : "NONE",
+		op ? fi_tostr(&op, FI_TYPE_OP_FLAGS) : "NONE");
+}
+
+static void ft_print_comp(struct ft_info *test)
+{
+	if (ft_use_comp_cq(test->comp_type)) {
+		printf("comp_queue -- tx ");
+		ft_print_comp_flag(test->tx_cq_bind_flags, test->tx_op_flags);
+		printf(", rx: ");
+		ft_print_comp_flag(test->rx_cq_bind_flags, test->rx_op_flags);
+		printf(", ");
+	}
+	if (ft_use_comp_cntr(test->comp_type))
+		printf("comp_cntr, ");
+} 
+
+static void ft_show_test_info(void)
+{
+	printf("[%s,", test_info.prov_name);
+	printf(" %s,", ft_test_type_str(test_info.test_type));
+	if (test_info.test_class & FI_ATOMIC) {
+		printf(" %s ", ft_class_func_str(test_info.class_function));
+		printf("(%s, ", fi_tostr(&test_info.op, FI_TYPE_ATOMIC_OP));
+		printf("%s)--", fi_tostr(&test_info.datatype, FI_TYPE_ATOMIC_TYPE));
+	} else {
+		printf(" %s--", ft_class_func_str(test_info.class_function));
+	}
+	printf("%s,", fi_tostr(&test_info.msg_flags, FI_TYPE_OP_FLAGS));
+	printf(" %s,", fi_tostr(&test_info.ep_type, FI_TYPE_EP_TYPE));
+	printf(" %s,", fi_tostr(&test_info.av_type, FI_TYPE_AV_TYPE));
+	printf(" eq_%s,", ft_wait_obj_str(test_info.eq_wait_obj));
+	printf(" cq_%s,", ft_wait_obj_str(test_info.cq_wait_obj));
+	printf(" cntr_%s, ", ft_wait_obj_str(test_info.cq_wait_obj));
+	ft_print_comp(&test_info);
+	printf(" %s,", fi_tostr(&test_info.progress, FI_TYPE_PROGRESS));
+	printf(" [%s],", fi_tostr(&test_info.mr_mode, FI_TYPE_MR_MODE));
+	printf(" [%s],", fi_tostr(&test_info.mode, FI_TYPE_MODE));
+	printf(" [%s]]\n", fi_tostr(&test_info.caps, FI_TYPE_CAPS));
+}
+
+static int ft_check_info(struct fi_info *hints, struct fi_info *info)
+{
+	if (info->mode & ~hints->mode) {
+		fprintf(stderr, "fi_getinfo unsupported mode returned:\n");
+		fprintf(stderr, "hints mode: %s\n",
+			fi_tostr(&hints->mode, FI_TYPE_MODE));
+		fprintf(stderr, "info mode: %s\n",
+			fi_tostr(&info->mode, FI_TYPE_MODE));
+		return -FI_EINVAL;
+	}
+	if (hints->caps != (hints->caps & info->caps)) {
+		fprintf(stderr, "fi_getinfo missing caps:\n");
+		fprintf(stderr, "hints caps: %s\n",
+			fi_tostr(&hints->caps, FI_TYPE_CAPS));
+		fprintf(stderr, "info caps: %s\n",
+			fi_tostr(&info->caps, FI_TYPE_CAPS));
+		return -FI_EINVAL;
+	}
+
+	return 0;
+}
+
+static void ft_fw_convert_info(struct fi_info *info, struct ft_info *test_info)
+{
+	info->caps = test_info->caps;
+
+	info->mode = test_info->mode;
+
+	info->domain_attr->mr_mode = test_info->mr_mode;
+	info->domain_attr->av_type = test_info->av_type;
+	info->domain_attr->data_progress = test_info->progress;
+
+	info->ep_attr->type = test_info->ep_type;
+	info->ep_attr->protocol = test_info->protocol;
+	info->ep_attr->protocol_version = test_info->protocol_version;
+
+	if (!ft_nullstr(test_info->prov_name)) {
+		info->fabric_attr->prov_name = strndup(test_info->prov_name,
+					sizeof test_info->prov_name - 1);
+	}
+	if (!ft_nullstr(test_info->fabric_name)) {
+		info->fabric_attr->name = strndup(test_info->fabric_name,
+					sizeof test_info->fabric_name - 1);
+	}
+
+	info->tx_attr->op_flags = test_info->tx_op_flags;
+	info->rx_attr->op_flags = test_info->rx_op_flags;
+
+	if (is_data_func(test_info->class_function) ||
+	    (is_msg_func(test_info->class_function) &&
+	     test_info->msg_flags & FI_REMOTE_CQ_DATA)) {
+		info->domain_attr->cq_data_size = 4;
+		info->mode |= FI_RX_CQ_DATA;
+	}
+}
+
+static void
+ft_fw_update_info(struct ft_info *test_info, struct fi_info *info, int subindex)
+{
+	test_info->test_subindex = subindex;
+
+	if (info->ep_attr) {
+		test_info->protocol = info->ep_attr->protocol;
+		test_info->protocol_version = info->ep_attr->protocol_version;
+	}
+
+	if (info->fabric_attr) {
+		if (info->fabric_attr->prov_name) {
+			strncpy(test_info->prov_name, info->fabric_attr->prov_name,
+				sizeof test_info->prov_name - 1);
+		}
+		if (info->fabric_attr->name) {
+			strncpy(test_info->fabric_name, info->fabric_attr->name,
+				sizeof test_info->fabric_name - 1);
+		}
+	}
+
+	if (info->domain_attr)
+		test_info->progress = info->domain_attr->data_progress;
+}
+
+static int ft_fw_result_index(int fi_errno)
+{
+	switch (fi_errno) {
+	case 0:
+		return FT_SUCCESS;
+	case FI_ENODATA:
+		return FT_ENODATA;
+	case FI_ENOSYS:
+		return FT_ENOSYS;
+	case FI_EIO:
+		return FT_EIO;
+	default:
+		return FT_ERROR;
+	}
+}
+
+static int ft_recv_test_info(void)
+{
+	int ret;
+
+	ret = ft_sock_recv(sock, &test_info, sizeof test_info);
+	if (ret)
+		return ret;
+
+	test_info.node[sizeof(test_info.node) - 1] = '\0';
+	test_info.service[sizeof(test_info.service) - 1] = '\0';
+	test_info.prov_name[sizeof(test_info.prov_name) - 1] = '\0';
+	test_info.fabric_name[sizeof(test_info.fabric_name) - 1] = '\0';
+	return 0;
+}
+
+static int ft_exchange_uint32(uint32_t local, uint32_t *remote)
+{
+	uint32_t local_net = htonl(local);
+	int ret;
+
+	ret = ft_sock_send(sock, &local_net, sizeof local);
+	if (ret) {
+		FT_PRINTERR("ft_sock_send", ret);
+		return ret;
+	}
+
+	ret = ft_sock_recv(sock, remote, sizeof *remote);
+	if (ret) {
+		FT_PRINTERR("ft_sock_recv", ret);
+		return ret;
+	}
+
+	*remote = ntohl(*remote);
+
+	return 0;
+}
+
+static int ft_skip_info(struct fi_info *hints, struct fi_info *info)
+{
+	uint32_t remote_protocol, skip, remote_skip;
+	size_t len;
+	int ret;
+
+	//make sure remote side is using the same protocol
+	ret = ft_exchange_uint32(info->ep_attr->protocol, &remote_protocol);
+	if (ret)
+		return ret;
+
+	if (info->ep_attr->protocol != remote_protocol)
+		return 1;
+
+	//check needed to skip utility providers, unless requested
+	skip = (!ft_util_name(hints->fabric_attr->prov_name, &len) &&
+		strcmp(hints->fabric_attr->prov_name,
+		info->fabric_attr->prov_name));
+
+	ret = ft_exchange_uint32(skip, &remote_skip);
+	if (ret)
+		return ret;
+
+	return skip || remote_skip;
+}
+
+static int ft_transfer_subindex(int subindex, int *remote_idx)
+{
+	int ret;
+
+	ret = ft_sock_send(sock, &subindex, sizeof subindex);
+	if (ret) {
+		FT_PRINTERR("ft_sock_send", ret);
+		return ret;
+	}
+
+	ret = ft_sock_recv(sock, remote_idx, sizeof *remote_idx);
+	if (ret) {
+		FT_PRINTERR("ft_sock_recv", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int ft_fw_process_list_server(struct fi_info *hints, struct fi_info *info)
+{
+	int ret, subindex, remote_idx = 0, result = -FI_ENODATA, end_test = 0;
+	int server_ready = 0;
+	struct fi_info *open_res_info;
+
+	ret = ft_sock_send(sock, &test_info, sizeof test_info);
+	if (ret) {
+		FT_PRINTERR("ft_sock_send", ret);
+		return ret;
+	}
+
+	for (subindex = 1, fabric_info = info; fabric_info;
+	     fabric_info = fabric_info->next, subindex++) {
+
+		ret = ft_check_info(hints, fabric_info);
+		if (ret)
+			return ret;
+
+		/* Stores the fabric_info into a tmp variable, resolves an issue caused
+		*  by ft_accept with FI_EP_MSG which overwrites the fabric_info.
+		*/
+		open_res_info = fabric_info;
+		while (1) {
+			fabric_info = open_res_info;
+			ret = ft_open_res();
+			if (ret) {
+				FT_PRINTERR("ft_open_res", ret);
+				return ret;
+			}
+
+			if (!server_ready) {
+				server_ready = 1;
+				ret = ft_sock_send(sock, &server_ready, sizeof server_ready);
+				if (ret) {
+					FT_PRINTERR("ft_sock_send", ret);
+					return ret;
+				}
+			}
+
+			ret = ft_sock_recv(sock, &end_test, sizeof end_test);
+			if (ret) {
+				FT_PRINTERR("ft_sock_recv", ret);
+				return ret;
+			}
+			if (end_test) {
+				ft_cleanup();
+				break;
+			}
+
+			if (ft_skip_info(hints, fabric_info)) {
+				ft_cleanup();
+				continue;
+			}
+
+			ret = ft_transfer_subindex(subindex, &remote_idx);
+			if (ret)
+				return ret;
+
+			ft_fw_update_info(&test_info, fabric_info, subindex);
+
+			printf("Starting test %d-%d-%d: ", test_info.test_index,
+				subindex, remote_idx);
+			ft_show_test_info();
+
+			result = ft_init_test();
+			if (result)
+				continue;
+
+			result = ft_run_test();
+
+			ret = ft_sock_send(sock, &result, sizeof result);
+			if (result) {
+				FT_PRINTERR("ft_run_test", result);
+			} else if (ret) {
+				FT_PRINTERR("ft_sock_send", ret);
+				return ret;
+			}
+		}
+
+		end_test = (fabric_info->next == NULL);
+		ret = ft_sock_send(sock, &end_test, sizeof end_test);
+		if (ret) {
+			FT_PRINTERR("ft_sock_send", ret);
+			return ret;
+		}
+	}
+
+	test_info.prov_name[0] = '\0';
+	ret = ft_sock_send(sock, &test_info, sizeof test_info);
+	if (ret) {
+		FT_PRINTERR("ft_sock_send", ret);
+		return ret;
+	}
+
+	if (subindex == 1)
+		return -FI_ENODATA;
+
+	return result;
+}
+
+static int ft_fw_process_list_client(struct fi_info *hints, struct fi_info *info)
+{
+	int ret, subindex, remote_idx = 0, result = -FI_ENODATA, sresult, end_test = 0;
+
+	while (!end_test) {
+		for (subindex = 1, fabric_info = info; fabric_info;
+			 fabric_info = fabric_info->next, subindex++) {
+
+			end_test = 0;
+			ret = ft_sock_send(sock, &end_test, sizeof end_test);
+			if (ret) {
+				FT_PRINTERR("ft_sock_send", ret);
+				return ret;
+			}
+
+			if (ft_skip_info(hints, fabric_info))
+				continue;
+
+			ret = ft_transfer_subindex(subindex, &remote_idx);
+			if (ret)
+				return ret;
+
+			ret = ft_check_info(hints, fabric_info);
+			if (ret)
+				return ret;
+
+			ft_fw_update_info(&test_info, fabric_info, subindex);
+			printf("Starting test %d-%d-%d: ", test_info.test_index,
+				subindex, remote_idx);
+			ft_show_test_info();
+
+			ret = ft_open_res();
+			if (ret) {
+				FT_PRINTERR("ft_open_res", ret);
+				return ret;
+			}
+
+			result = ft_init_test();
+			if (result)
+				continue;
+
+			result = ft_run_test();
+
+			ret = ft_sock_recv(sock, &sresult, sizeof sresult);
+			if (result && result != -FI_EIO) {
+				FT_PRINTERR("ft_run_test", result);
+				fprintf(stderr, "Node: %s\nService: %s \n",
+					test_info.node, test_info.service);
+				fprintf(stderr, "%s\n", fi_tostr(hints, FI_TYPE_INFO));
+				return -FI_EOTHER;
+			} else if (ret) {
+				FT_PRINTERR("ft_sock_recv", ret);
+				result = ret;
+				return -FI_EOTHER;
+			} else if (sresult) {
+				result = sresult;
+				if (sresult != -FI_EIO)
+					return -FI_EOTHER;
+			}
+		}
+		end_test = 1;
+		ret = ft_sock_send(sock, &end_test, sizeof end_test);
+		if (ret) {
+			FT_PRINTERR("ft_sock_send", ret);
+			return ret;
+		}
+
+		ret = ft_sock_recv(sock, &end_test, sizeof end_test);
+		if (ret) {
+			FT_PRINTERR("ft_sock_recv", ret);
+			return ret;
+		}
+	}
+
+	if (subindex == 1)
+		return -FI_ENODATA;
+
+	return result;
+}
+
+static int ft_server_child()
+{
+	struct fi_info *hints, *info;
+	int ret;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return -FI_ENOMEM;
+
+	ft_fw_convert_info(hints, &test_info);
+	printf("Starting test %d:\n", test_info.test_index);
+
+	ret = fi_getinfo(FT_FIVERSION, ft_strptr(test_info.node),
+			 ft_strptr(test_info.service), FI_SOURCE,
+			 hints, &info);
+	if (ret && ret != -FI_ENODATA) {
+		FT_PRINTERR("fi_getinfo", ret);
+	} else {
+		ret = ft_fw_process_list_server(hints, info);
+		if (ret != -FI_ENODATA)
+			fi_freeinfo(info);
+
+		if (ret && ret != -FI_EIO) {
+			FT_PRINTERR("ft_fw_process_list", ret);
+			printf("Node: %s\nService: %s\n",
+				test_info.node, test_info.service);
+			printf("%s\n", fi_tostr(hints, FI_TYPE_INFO));
+		}
+	}
+	fi_freeinfo(hints);
+
+	printf("Ending test %d, result: %s\n", test_info.test_index,
+		fi_strerror(-ret));
+
+	return ret;
+}
+
+static int ft_fw_server(void)
+{
+	int ret;
+	pid_t pid;
+
+	do {
+		ret = ft_recv_test_info();
+		if (ret) {
+			if (ret == -FI_ENOTCONN)
+				ret = 0;
+			break;
+		}
+
+		if (do_fork) {
+			pid = fork();
+			if (!pid) {
+				ret = ft_server_child();
+				_exit(-ret);
+			} else {
+				waitpid(pid, &ret, 0);
+				ret = WEXITSTATUS(ret);
+			}
+		} else {
+			ret = ft_server_child();
+		}
+
+		results[ft_fw_result_index(ret)]++;
+
+	} while (!ret || ret == FI_EIO || ret == FI_ENODATA);
+
+	return ret;
+}
+
+static int ft_client_child(void)
+{
+	struct fi_info *hints, *info;
+	int ret, result, server_ready = 0;
+
+	result = -FI_ENODATA;
+	hints = fi_allocinfo();
+	if (!hints)
+		return -FI_ENOMEM;
+
+	ret = ft_getsrcaddr(opts.src_addr, opts.src_port, hints);
+	if (ret)
+		return ret;
+
+	ft_fw_convert_info(hints, &test_info);
+
+	printf("Starting test %d / %d:\n", test_info.test_index,
+		series->test_count);
+	while (!ft_nullstr(test_info.prov_name)) {
+		printf("Starting test %d-%d: ", test_info.test_index,
+			test_info.test_subindex);
+		ft_show_test_info();
+
+		ret = ft_sock_recv(sock, &server_ready, sizeof server_ready);
+		if (ret)
+			return ret;
+
+		if (!server_ready)
+			return -FI_EOTHER;
+
+		result = fi_getinfo(FT_FIVERSION, ft_strptr(test_info.node),
+				 ft_strptr(test_info.service), 0, hints, &info);
+		if (result) {
+			FT_PRINTERR("fi_getinfo", result);
+		}
+
+		ret = ft_fw_process_list_client(hints, info);
+		if (ret != -FI_ENODATA)
+			fi_freeinfo(info);
+		else
+			goto out;
+
+		ret = ft_recv_test_info();
+		if (ret) {
+			FT_PRINTERR("ft_recv_test_info", ret);
+			goto out;
+		}
+		ft_fw_convert_info(hints, &test_info);
+	}
+
+	printf("Ending test %d / %d, result: %s\n", test_info.test_index,
+		series->test_count, fi_strerror(-result));
+out:
+	fi_freeinfo(hints);
+	return result;
+}
+
+static int ft_fw_client(void)
+{
+	int ret, result;
+	pid_t pid;
+
+
+	for (fts_start(series, test_start_index);
+	     !fts_end(series, test_end_index);
+	     fts_next(series)) {
+
+		fts_cur_info(series, &test_info);
+		if (!fts_info_is_valid()) {
+			printf("Skipping test %d (invalid):\n", test_info.test_index);
+			ft_show_test_info();
+			results[FT_SKIP]++;
+			continue;
+		}
+
+		ret = ft_sock_send(sock, &test_info, sizeof test_info);
+		if (ret) {
+			FT_PRINTERR("ft_sock_send", ret);
+			return ret;
+		}
+
+		ret = ft_recv_test_info();
+		if (ret) {
+			FT_PRINTERR("ft_recv_test_info", ret);
+			return ret;
+		}
+
+		if (do_fork) {
+			pid = fork();
+			if (!pid) {
+				result = ft_client_child();
+				_exit(-result);
+			} else {
+				waitpid(pid, &result, 0);
+				result = WEXITSTATUS(result);
+			}
+		} else {
+			result = ft_client_child();
+		}
+
+		results[ft_fw_result_index(result)]++;
+	}
+	return 0;
+}
+
+static void ft_fw_show_results(void)
+{
+	printf("Success: %d\n", results[FT_SUCCESS]);
+	printf("Skipped: %d\n", results[FT_SKIP]);
+	printf("ENODATA: %d\n", results[FT_ENODATA]);
+	printf("ENOSYS : %d\n", results[FT_ENOSYS]);
+	printf("EIO    : %d\n", results[FT_EIO]);
+	printf("ERROR  : %d\n", results[FT_ERROR]);
+}
+
+static void ft_fw_usage(char *program)
+{
+	fprintf(stderr, "Usage:\n");
+	fprintf(stderr, "  %s [OPTIONS] \t\t\tstart server\n", program);
+	fprintf(stderr, "  %s [OPTIONS] <server_node> \tconnect to server\n", program);
+	fprintf(stderr, "\nOptions:\n");
+	FT_PRINT_OPTS_USAGE("-q <service_port>", "Management port for test");
+	FT_PRINT_OPTS_USAGE("-h", "display this help output");
+	fprintf(stderr, "\nServer only options:\n");
+	FT_PRINT_OPTS_USAGE("-x", "exit after test run");
+	fprintf(stderr, "\nClient only options:\n");
+	FT_PRINT_OPTS_USAGE("-u <test_config_file>", "test configuration file "
+		"(Either config file or both provider and test name are required)");
+	FT_PRINT_OPTS_USAGE("-p <provider_name>", " provider name");
+	FT_PRINT_OPTS_USAGE("-t <test_name>", "test name");
+	FT_PRINT_OPTS_USAGE("-y <start_test_index>", "");
+	FT_PRINT_OPTS_USAGE("-z <end_test_index>", "");
+	FT_PRINT_OPTS_USAGE("-s <address>", "source address");
+	FT_PRINT_OPTS_USAGE("-B <src_port>", "non default source port number");
+	FT_PRINT_OPTS_USAGE("-P <dst_port>", "non default destination port number "
+		"(config file service parameter will override this)");
+}
+
+void ft_free()
+{
+	if (filename)
+		free(filename);
+	if (testname)
+		free(testname);
+	if (provname)
+		free(provname);
+}
+
+static int ft_get_config_file(char *provname, char *testname, char **filename)
+{
+	char **prov_vec, **path_vec, *str;
+	size_t i, prov_count, path_count, len;
+	int ret = -FI_ENOMEM;
+
+	// TODO use macro for ";"
+	prov_vec = ft_split_and_alloc(provname, ";", &prov_count);
+	if (!prov_vec) {
+		FT_ERR("Unable to split provname\n");
+		return -FI_EINVAL;
+	}
+
+	/* prov_count + count_of(CONFIG_PATH, "test_configs", "testname", ".test") */
+	path_count = prov_count + 4;
+	path_vec = calloc(path_count, sizeof(*path_vec));
+	if (!path_vec)
+		goto err1;
+
+	path_vec[0] = CONFIG_PATH;
+	path_vec[1] = "test_configs";
+
+	/* Path for "prov1;prov2;prov3;..." is ".../prov3/prov2/prov1" */
+	for (i = 0; i < prov_count; i++)
+		path_vec[i + 2] = prov_vec[prov_count - i - 1];
+
+	path_vec[prov_count + 2] = testname;
+	path_vec[prov_count + 3] = "test";
+
+	for (i = 0, len = 0; i < path_count; i++)
+		len += strlen(path_vec[i]) + 1;
+
+	// NULL char at the end
+	len++;
+
+	*filename = calloc(1, len);
+	if (!*filename)
+		goto err2;
+
+	for (i = 0, str = *filename; i < path_count; i++) {
+		if (i < path_count - 1)
+			ret = snprintf(str, len, "/%s", path_vec[i]);
+		else
+			ret = snprintf(str, len, ".%s", path_vec[i]);
+		if (ret < 0)
+			goto err3;
+
+		if (ret >= (int)len) {
+			ret = -FI_ETRUNC;
+			goto err3;
+		}
+		str += ret;
+		len -= ret;
+	}
+	free(path_vec);
+	ft_free_string_array(prov_vec);
+	return 0;
+err3:
+	free(*filename);
+	*filename = NULL;
+err2:
+	free(path_vec);
+err1:
+	ft_free_string_array(prov_vec);
+	return ret;
+}
+
+int main(int argc, char **argv)
+{
+	char *service = "2710";
+	opts = INIT_OPTS;
+	int ret, op;
+
+	while ((op = getopt(argc, argv, "p:u:t:q:xy:z:hf" ADDR_OPTS)) != -1) {
+		switch (op) {
+		case 'u':
+			filename = strdup(optarg);
+			break;
+		case 'p':
+			provname = strdup(optarg);
+			break;
+		case 't':
+			testname = strdup(optarg);
+			break;
+		case 'q':
+			service = optarg;
+			break;
+		case 'x':
+			persistent = 0;
+			break;
+		case 'y':
+			test_start_index = atoi(optarg);
+			break;
+		case 'z':
+			test_end_index = atoi(optarg);
+			break;
+		case 'f':
+			do_fork = 1;
+			break;
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			break;
+		case '?':
+		case 'h':
+			ft_fw_usage(argv[0]);
+			ft_free();
+			exit(1);
+		}
+	}
+
+	if (optind < argc - 1) {
+		ft_fw_usage(argv[0]);
+		ft_free();
+		exit(1);
+	}
+
+	opts.dst_addr = (optind == argc - 1) ? argv[optind] : NULL;
+	if (opts.dst_addr) {
+		if (!opts.dst_port)
+			opts.dst_port = default_port;
+		if (!filename) {
+			if (!testname || !provname) {
+				ft_fw_usage(argv[0]);
+				ft_free();
+				exit(1);
+			} else {
+				ret = ft_get_config_file(provname, testname,
+							 &filename);
+				if (ret < 0) {
+					ft_free();
+					exit(1);
+				}
+			}
+		} else {
+			testname = NULL;
+			provname = NULL;
+		}
+		series = fts_load(filename);
+		if (!series) {
+			ft_free();
+			exit(1);
+		}
+
+		ret = ft_sock_connect(opts.dst_addr, service);
+		if (ret)
+			goto out;
+
+		ret = ft_fw_client();
+		if (ret)
+			FT_PRINTERR("ft_fw_client", ret);
+		ft_sock_shutdown(sock);
+	} else {
+		ret = ft_sock_listen(opts.src_addr, service);
+		if (ret)
+			goto out;
+
+		do {
+			ret = ft_sock_accept();
+			if (ret)
+				goto out;
+
+			ret = ft_fw_server();
+			if (ret)
+				FT_PRINTERR("ft_fw_server", ret);
+			ft_sock_shutdown(sock);
+		} while (persistent);
+	}
+
+	ft_fw_show_results();
+out:
+	if (opts.dst_addr)
+		fts_close(series);
+	ft_free();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/verify.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/verify.c
new file mode 100644
index 000000000..08011b5c2
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/verify.c
@@ -0,0 +1,184 @@
+/*
+ * Copyright (c) 2017 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2016, Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <float.h>
+
+#include "ofi_atomic.h"
+#include "fabtest.h"
+
+static int alph_index = 0;
+static const char integ_alphabet[] = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";
+static const int integ_alphabet_length = (sizeof(integ_alphabet)/sizeof(*integ_alphabet)) - 1;
+
+#define CHECK_LOCAL(res,local,cnt,ret,TYPE)	\
+	do {					\
+		int i;				\
+		TYPE *r = (res);		\
+		TYPE *l = (local);		\
+		for (i = 0; i < cnt; i++) {	\
+			if (r[i] != l[i]) {	\
+				ret = -FI_EIO;	\
+				break;		\
+			}			\
+		}				\
+	} while (0)				\
+
+
+#define FT_FILL(dst,cnt,TYPE)				\
+	do {								\
+		int i;							\
+		TYPE *d = (dst);					\
+		for (i = 0; i < cnt; i++) {				\
+			d[i] = (TYPE) (integ_alphabet[alph_index++]);	\
+			if (alph_index >= integ_alphabet_length)	\
+				alph_index = 0;				\
+		}							\
+	} while (0)
+
+#define SWITCH_TYPES(type,FUNC,...)				\
+	switch (type) {						\
+	case FI_INT8:	FUNC(__VA_ARGS__,int8_t); break;	\
+	case FI_UINT8:	FUNC(__VA_ARGS__,uint8_t); break;	\
+	case FI_INT16:	FUNC(__VA_ARGS__,int16_t); break;	\
+	case FI_UINT16: FUNC(__VA_ARGS__,uint16_t); break;	\
+	case FI_INT32:	FUNC(__VA_ARGS__,int32_t); break;	\
+	case FI_UINT32: FUNC(__VA_ARGS__,uint32_t); break;	\
+	case FI_INT64:	FUNC(__VA_ARGS__,int64_t); break;	\
+	case FI_UINT64: FUNC(__VA_ARGS__,uint64_t); break;	\
+	case FI_FLOAT:	FUNC(__VA_ARGS__,float); break;		\
+	case FI_DOUBLE:	FUNC(__VA_ARGS__,double); break;	\
+	case FI_LONG_DOUBLE: FUNC(__VA_ARGS__,long_double); break;		\
+	case FI_FLOAT_COMPLEX:	FUNC(__VA_ARGS__,ofi_complex_float); break;	\
+	case FI_DOUBLE_COMPLEX:	FUNC(__VA_ARGS__,ofi_complex_double); break;	\
+	case FI_LONG_DOUBLE_COMPLEX: FUNC(__VA_ARGS__,ofi_complex_long_double); break;\
+	default: return -FI_EOPNOTSUPP;				\
+	}
+
+int ft_sync_fill_bufs(size_t size)
+{
+	ft_sock_sync(0);
+
+	if (test_info.caps & FI_ATOMIC) {
+		SWITCH_TYPES(ft_atom_ctrl.datatype, FT_FILL, ft_tx_ctrl.buf,
+			     ft_atom_ctrl.count);
+		SWITCH_TYPES(ft_atom_ctrl.datatype, FT_FILL, ft_mr_ctrl.buf,
+			     ft_atom_ctrl.count);
+		memcpy(ft_atom_ctrl.orig_buf, ft_mr_ctrl.buf, size);
+		memcpy(ft_tx_ctrl.cpy_buf, ft_tx_ctrl.buf, size);
+	} else if (is_read_func(test_info.class_function)) {
+		ft_fill_buf(ft_mr_ctrl.buf, size);
+	} else {
+		ft_fill_buf(ft_tx_ctrl.buf, size);
+		memcpy(ft_tx_ctrl.cpy_buf, ft_tx_ctrl.buf, size);
+	}
+
+	ft_sock_sync(0);
+
+	return 0;
+}
+
+static int verify_atomic(void)
+{
+	int ret = 0;
+	void *dst, *src, *cmp, *tmp, *res;
+	enum fi_datatype type;
+	enum fi_op op;
+	size_t count;
+
+	dst = ft_atom_ctrl.orig_buf;
+	src = ft_tx_ctrl.cpy_buf;
+	cmp = ft_atom_ctrl.comp_buf;
+	tmp = ft_rx_ctrl.buf;
+	res = ft_atom_ctrl.res_buf;
+
+	type = ft_atom_ctrl.datatype;
+	op = ft_atom_ctrl.op;
+	count = ft_atom_ctrl.count;
+
+	if (is_fetch_func(test_info.class_function) ||
+	    is_compare_func(test_info.class_function)) {
+		SWITCH_TYPES(type, CHECK_LOCAL, dst, res, count, ret);
+		if (ret)
+			return ret;
+	}
+
+	if (is_compare_func(test_info.class_function)) {
+		ofi_atomic_swap_handlers[op - OFI_SWAP_OP_START][type](dst,
+			src, cmp, tmp, count);
+	} else if (is_fetch_func(test_info.class_function)) {
+		ofi_atomic_readwrite_handlers[op][type](dst,
+			src, tmp, count);
+	} else {
+		ofi_atomic_write_handlers[op][type](dst, src, count);
+	}
+
+	SWITCH_TYPES(type, CHECK_LOCAL, dst, ft_mr_ctrl.buf, count, ret);
+
+	return ret;
+}
+
+int ft_verify_bufs()
+{
+	char *compare_buf;
+	size_t compare_size;
+
+	if (test_info.caps & FI_ATOMIC)
+		return verify_atomic();
+
+	if (test_info.caps & FI_RMA) {
+		compare_size = ft_tx_ctrl.rma_msg_size;
+		if (is_read_func(test_info.class_function))
+			compare_buf = (char *) ft_tx_ctrl.buf;
+		else
+			compare_buf = (char *) ft_mr_ctrl.buf;
+	} else {
+		compare_size = ft_tx_ctrl.msg_size;
+		compare_buf = (char *) ft_rx_ctrl.buf;
+	}
+
+	return ft_check_buf(compare_buf, compare_size) ? -FI_EIO : 0;
+}
+
+void ft_verify_comp(void *buf)
+{
+	struct fi_cq_data_entry *comp;
+
+	if (ft_rx_ctrl.cq_format != FI_CQ_FORMAT_DATA)
+		return;
+
+	comp = (struct fi_cq_data_entry *) buf;
+
+	if (comp->flags & FI_REMOTE_CQ_DATA) {
+		if (comp->data == ft_tx_ctrl.remote_cq_data)
+			ft_ctrl.verify_cnt++;
+	}
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/xfer.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/xfer.c
new file mode 100644
index 000000000..7d7bc5fe6
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/ubertest/xfer.c
@@ -0,0 +1,857 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under the BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <time.h>
+
+#include "fabtest.h"
+
+
+static int ft_post_recv(void)
+{
+	struct fi_msg msg;
+	int ret;
+	struct fi_context *ctx = NULL;
+	uint64_t flags = 0;
+
+	if (test_info.msg_flags == FI_COMPLETION)
+		flags = test_info.msg_flags;
+
+	if (test_info.test_class & (FI_RMA | FI_ATOMIC) ||
+	    ft_generates_rx_comp()) {
+		ret = ft_get_ctx(&ft_rx_ctrl, &ctx);
+		if (ret)
+			return ret;
+	}
+
+	if (fabric_info->caps & FI_DIRECTED_RECV)
+		ft_rx_ctrl.addr = ft_tx_ctrl.addr;
+
+	switch (test_info.class_function) {
+	case FT_FUNC_SENDV:
+		ft_format_iov(ft_rx_ctrl.iov, ft_ctrl.iov_array[ft_rx_ctrl.iov_iter],
+				ft_rx_ctrl.buf, ft_rx_ctrl.msg_size);
+		ret = fi_recvv(ft_rx_ctrl.ep, ft_rx_ctrl.iov, ft_rx_ctrl.iov_desc,
+				ft_ctrl.iov_array[ft_rx_ctrl.iov_iter], ft_rx_ctrl.addr, ctx);
+		ft_next_iov_cnt(&ft_rx_ctrl, fabric_info->rx_attr->iov_limit);
+		break;
+	case FT_FUNC_SENDMSG:
+		ft_format_iov(ft_rx_ctrl.iov, ft_ctrl.iov_array[ft_rx_ctrl.iov_iter],
+				ft_rx_ctrl.buf, ft_rx_ctrl.msg_size);
+		msg.msg_iov = ft_rx_ctrl.iov;
+		msg.desc = ft_rx_ctrl.iov_desc;
+		msg.iov_count = ft_ctrl.iov_array[ft_rx_ctrl.iov_iter];
+		msg.addr = ft_rx_ctrl.addr;
+		msg.context = ctx;
+		msg.data = 0;
+		ret = fi_recvmsg(ft_rx_ctrl.ep, &msg, flags);
+		ft_next_iov_cnt(&ft_rx_ctrl, fabric_info->rx_attr->iov_limit);
+		break;
+	default:
+		ret = fi_recv(ft_rx_ctrl.ep, ft_rx_ctrl.buf, ft_rx_ctrl.msg_size,
+				ft_rx_ctrl.memdesc, ft_rx_ctrl.addr, ctx);
+		break;
+	}
+
+	return ret;
+}
+
+static int ft_post_trecv(void)
+{
+	struct fi_msg_tagged msg;
+	int ret;
+	struct fi_context *ctx = NULL;
+	uint64_t flags = 0;
+
+	if (test_info.msg_flags == FI_COMPLETION)
+		flags = test_info.msg_flags;
+
+	if (ft_generates_rx_comp()) {
+		ret = ft_get_ctx(&ft_rx_ctrl, &ctx);
+		if (ret)
+			return ret;
+	}
+
+	if (fabric_info->caps & FI_DIRECTED_RECV)
+		ft_rx_ctrl.addr = ft_tx_ctrl.addr;
+
+	switch (test_info.class_function) {
+	case FT_FUNC_SENDV:
+		ft_format_iov(ft_rx_ctrl.iov, ft_ctrl.iov_array[ft_rx_ctrl.iov_iter],
+				ft_rx_ctrl.buf, ft_rx_ctrl.msg_size);
+		ret = fi_trecvv(ft_rx_ctrl.ep, ft_rx_ctrl.iov, ft_rx_ctrl.iov_desc,
+				ft_ctrl.iov_array[ft_rx_ctrl.iov_iter], ft_rx_ctrl.addr,
+				ft_rx_ctrl.tag, 0, ctx);
+		ft_next_iov_cnt(&ft_rx_ctrl, fabric_info->rx_attr->iov_limit);
+		break;
+	case FT_FUNC_SENDMSG:
+		ft_format_iov(ft_rx_ctrl.iov, ft_ctrl.iov_array[ft_rx_ctrl.iov_iter],
+				ft_rx_ctrl.buf, ft_rx_ctrl.msg_size);
+		msg.msg_iov = ft_rx_ctrl.iov;
+		msg.desc = ft_rx_ctrl.iov_desc;
+		msg.iov_count = ft_ctrl.iov_array[ft_rx_ctrl.iov_iter];
+		msg.addr = ft_rx_ctrl.addr;
+		msg.tag = ft_rx_ctrl.tag;
+		msg.ignore = 0;
+		msg.context = ctx;
+		ret = fi_trecvmsg(ft_rx_ctrl.ep, &msg, flags);
+		ft_next_iov_cnt(&ft_rx_ctrl, fabric_info->rx_attr->iov_limit);
+		break;
+	default:
+		ret = fi_trecv(ft_rx_ctrl.ep, ft_rx_ctrl.buf, ft_rx_ctrl.msg_size,
+				ft_rx_ctrl.memdesc, ft_rx_ctrl.addr, ft_rx_ctrl.tag, 0, ctx);
+		break;
+	}
+	return ret;
+}
+
+#define ft_send_retry(ret, send, ep, ...)		\
+	do {						\
+		ret = send(ep, ##__VA_ARGS__);		\
+		if (ret == -FI_EAGAIN)			\
+			ft_comp_tx(0);			\
+	} while (ret == -FI_EAGAIN)
+
+static int ft_post_send(void)
+{
+	struct fi_msg msg;
+	int ret;
+	struct fi_context *ctx = NULL;
+
+	if (ft_generates_tx_comp()) {
+		ret = ft_get_ctx(&ft_tx_ctrl, &ctx);
+		if (ret)
+			return ret;
+	}
+
+	switch (test_info.class_function) {
+	case FT_FUNC_SENDV:
+		ft_format_iov(ft_tx_ctrl.iov, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+				ft_tx_ctrl.buf, ft_tx_ctrl.msg_size);
+		ft_send_retry(ret, fi_sendv, ft_tx_ctrl.ep, ft_tx_ctrl.iov,
+				ft_tx_ctrl.iov_desc, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+				ft_tx_ctrl.addr, ctx);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_SENDMSG:
+		ft_format_iov(ft_tx_ctrl.iov, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+				ft_tx_ctrl.buf, ft_tx_ctrl.msg_size);
+		msg.msg_iov = ft_tx_ctrl.iov;
+		msg.desc = ft_tx_ctrl.iov_desc;
+		msg.iov_count = ft_ctrl.iov_array[ft_tx_ctrl.iov_iter];
+		msg.addr = ft_tx_ctrl.addr;
+		msg.context = ctx;
+		msg.data = ft_tx_ctrl.remote_cq_data;
+		ft_send_retry(ret, fi_sendmsg, ft_tx_ctrl.ep, &msg, test_info.msg_flags);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_INJECT:
+		ft_send_retry(ret, fi_inject, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_tx_ctrl.msg_size, ft_tx_ctrl.addr);
+		break;
+	case FT_FUNC_INJECTDATA:
+		ft_send_retry(ret, fi_injectdata, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_tx_ctrl.msg_size, ft_tx_ctrl.remote_cq_data,
+				ft_tx_ctrl.addr);
+		break;
+	case FT_FUNC_SENDDATA:
+		ft_send_retry(ret, fi_senddata, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_tx_ctrl.msg_size, ft_tx_ctrl.memdesc,
+				ft_tx_ctrl.remote_cq_data, ft_tx_ctrl.addr, ctx);
+		break;
+	default:
+		ft_send_retry(ret, fi_send, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_tx_ctrl.msg_size, ft_tx_ctrl.memdesc,
+				ft_tx_ctrl.addr, ctx);
+		break;
+	}
+
+	if (ft_check_tx_completion())
+		ft_tx_ctrl.credits--;
+
+	return ret;
+}
+
+static int ft_post_tsend(void)
+{
+	struct fi_msg_tagged msg;
+	int ret;
+	struct fi_context *ctx = NULL;
+
+	if (ft_generates_tx_comp()) {
+		ret = ft_get_ctx(&ft_tx_ctrl, &ctx);
+		if (ret)
+			return ret;
+	}
+
+	switch (test_info.class_function) {
+	case FT_FUNC_SENDV:
+		ft_format_iov(ft_tx_ctrl.iov, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+				ft_tx_ctrl.buf, ft_tx_ctrl.msg_size);
+		ft_send_retry(ret, fi_tsendv, ft_tx_ctrl.ep, ft_tx_ctrl.iov,
+				ft_tx_ctrl.iov_desc, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+				ft_tx_ctrl.addr, ft_tx_ctrl.tag, ctx);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_SENDMSG:
+		ft_format_iov(ft_tx_ctrl.iov, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+				ft_tx_ctrl.buf, ft_tx_ctrl.msg_size);
+		msg.msg_iov = ft_tx_ctrl.iov;
+		msg.desc = ft_tx_ctrl.iov_desc;
+		msg.iov_count = ft_ctrl.iov_array[ft_tx_ctrl.iov_iter];
+		msg.addr = ft_tx_ctrl.addr;
+		msg.tag = ft_tx_ctrl.tag;
+		msg.context = ctx;
+		msg.data = ft_tx_ctrl.remote_cq_data;
+		ft_send_retry(ret, fi_tsendmsg, ft_tx_ctrl.ep, &msg, test_info.msg_flags);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_INJECT:
+		ft_send_retry(ret, fi_tinject, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_tx_ctrl.msg_size, ft_tx_ctrl.addr, ft_tx_ctrl.tag);
+		break;
+	case FT_FUNC_INJECTDATA:
+		ft_send_retry(ret, fi_tinjectdata, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_tx_ctrl.msg_size, ft_tx_ctrl.remote_cq_data,
+				ft_tx_ctrl.addr, ft_tx_ctrl.tag);
+		break;
+	case FT_FUNC_SENDDATA:
+		ft_send_retry(ret, fi_tsenddata, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_tx_ctrl.msg_size, ft_tx_ctrl.memdesc,
+				ft_tx_ctrl.remote_cq_data, ft_tx_ctrl.addr,
+				ft_tx_ctrl.tag, ctx);
+		break;
+	default:
+		ft_send_retry(ret, fi_tsend, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_tx_ctrl.msg_size, ft_tx_ctrl.memdesc,
+				ft_tx_ctrl.addr, ft_tx_ctrl.tag, ctx);
+		break;
+	}
+
+	if (ft_check_tx_completion())
+		ft_tx_ctrl.credits--;
+
+	return ret;
+}
+
+static int ft_post_send_rma(void)
+{
+	int ret, i;
+	struct fi_msg_rma msg;
+	struct fi_rma_iov rma_iov;
+	struct fi_context *ctx = NULL;
+	uint64_t read_flags = 0;
+
+	if (test_info.msg_flags == FI_COMPLETION)
+		read_flags = test_info.msg_flags;
+
+	if (ft_generates_tx_comp()) {
+ 		ret = ft_get_ctx(&ft_tx_ctrl, &ctx);
+ 		if (ret)
+ 			return ret;
+	}
+
+	switch (test_info.class_function) {
+	case FT_FUNC_READ:
+		ft_send_retry(ret, fi_read, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+			ft_tx_ctrl.rma_msg_size, ft_tx_ctrl.memdesc,
+			ft_tx_ctrl.addr, ft_mr_ctrl.peer_mr_addr,
+			ft_mr_ctrl.peer_mr_key, ctx);
+		break;
+	case FT_FUNC_READV:
+		ft_format_iov(ft_tx_ctrl.iov, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+			ft_tx_ctrl.buf, ft_tx_ctrl.rma_msg_size);
+		ft_send_retry(ret, fi_readv, ft_tx_ctrl.ep, ft_tx_ctrl.iov,
+			ft_tx_ctrl.iov_desc, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+			ft_tx_ctrl.addr, ft_mr_ctrl.peer_mr_addr,
+			ft_mr_ctrl.peer_mr_key, ctx);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_READMSG:
+		ft_format_iov(ft_tx_ctrl.iov, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+			ft_tx_ctrl.buf, ft_tx_ctrl.rma_msg_size);
+
+		msg.msg_iov = ft_tx_ctrl.iov;
+		msg.desc = ft_tx_ctrl.iov_desc;
+		msg.iov_count = ft_ctrl.iov_array[ft_tx_ctrl.iov_iter];
+		msg.addr = ft_tx_ctrl.addr;
+		msg.context = ctx;
+		msg.data = 0;
+
+		rma_iov.addr = ft_mr_ctrl.peer_mr_addr;
+		rma_iov.key = ft_mr_ctrl.peer_mr_key;
+		for (i = 0, rma_iov.len = 0; i < msg.iov_count; i++)
+			rma_iov.len += ft_tx_ctrl.iov[i].iov_len;
+
+		msg.rma_iov = &rma_iov;
+		msg.rma_iov_count = 1;
+		ft_send_retry(ret, fi_readmsg, ft_tx_ctrl.ep, &msg, read_flags);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_WRITEV:
+		ft_format_iov(ft_tx_ctrl.iov, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+			ft_tx_ctrl.buf, ft_tx_ctrl.rma_msg_size);
+		ft_send_retry(ret, fi_writev, ft_tx_ctrl.ep, ft_tx_ctrl.iov,
+			ft_tx_ctrl.iov_desc, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+			ft_tx_ctrl.addr, ft_mr_ctrl.peer_mr_addr,
+			ft_mr_ctrl.peer_mr_key, ctx);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_WRITEMSG:
+		ft_format_iov(ft_tx_ctrl.iov, ft_ctrl.iov_array[ft_tx_ctrl.iov_iter],
+			ft_tx_ctrl.buf, ft_tx_ctrl.rma_msg_size);
+
+		msg.msg_iov = ft_tx_ctrl.iov;
+		msg.desc = ft_tx_ctrl.iov_desc;
+		msg.iov_count = ft_ctrl.iov_array[ft_tx_ctrl.iov_iter];
+		msg.addr = ft_tx_ctrl.addr;
+		msg.context = ctx;
+		msg.data = ft_tx_ctrl.remote_cq_data;
+
+		rma_iov.addr = ft_mr_ctrl.peer_mr_addr;
+		rma_iov.key = ft_mr_ctrl.peer_mr_key;
+		for (i = 0, rma_iov.len = 0; i < msg.iov_count; i++)
+			rma_iov.len += ft_tx_ctrl.iov[i].iov_len;
+
+		msg.rma_iov = &rma_iov;
+		msg.rma_iov_count = 1;
+		ft_send_retry(ret, fi_writemsg, ft_tx_ctrl.ep, &msg,
+			test_info.msg_flags);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_INJECT_WRITE:
+		ft_send_retry(ret, fi_inject_write, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+			ft_tx_ctrl.rma_msg_size, ft_tx_ctrl.addr,
+			ft_mr_ctrl.peer_mr_addr, ft_mr_ctrl.peer_mr_key);
+		break;
+	case FT_FUNC_WRITEDATA:
+		ft_send_retry(ret, fi_writedata, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+			ft_tx_ctrl.rma_msg_size, ft_tx_ctrl.memdesc,
+			ft_tx_ctrl.remote_cq_data, ft_tx_ctrl.addr,
+			ft_mr_ctrl.peer_mr_addr, ft_mr_ctrl.peer_mr_key, ctx);
+		break;
+	case FT_FUNC_INJECT_WRITEDATA:
+		ft_send_retry(ret, fi_inject_writedata, ft_tx_ctrl.ep,
+			ft_tx_ctrl.buf, ft_tx_ctrl.rma_msg_size,
+			ft_tx_ctrl.remote_cq_data, ft_tx_ctrl.addr,
+			ft_mr_ctrl.peer_mr_addr, ft_mr_ctrl.peer_mr_key);
+		break;
+	default:
+		ft_send_retry(ret, fi_write, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+			ft_tx_ctrl.rma_msg_size, ft_tx_ctrl.memdesc,
+			ft_tx_ctrl.addr, ft_mr_ctrl.peer_mr_addr,
+			ft_mr_ctrl.peer_mr_key, ctx);
+		break;
+	}
+
+	if (ft_check_tx_completion())
+		ft_tx_ctrl.credits--;
+
+	return ret;
+}
+
+int ft_post_send_atomic(void)
+{
+	int ret, i;
+	struct fi_msg_atomic msg;
+	struct fi_rma_ioc rma_iov;
+	size_t iov_count;
+	struct fi_context *ctx = NULL;
+
+	if (ft_generates_tx_comp()) {
+ 		ret = ft_get_ctx(&ft_tx_ctrl, &ctx);
+ 		if (ret)
+ 			return ret;
+	}
+
+	switch (test_info.class_function) {
+	case FT_FUNC_ATOMICV:
+		ft_format_iocs(ft_tx_ctrl.iov, &iov_count);
+		ft_send_retry(ret, fi_atomicv, ft_tx_ctrl.ep, ft_atom_ctrl.ioc,
+			ft_tx_ctrl.iov_desc, iov_count, ft_tx_ctrl.addr,
+			ft_mr_ctrl.peer_mr_addr, ft_mr_ctrl.peer_mr_key,
+			ft_atom_ctrl.datatype, ft_atom_ctrl.op, ctx);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_ATOMICMSG:
+		ft_format_iocs(ft_tx_ctrl.iov, &iov_count);
+		msg.msg_iov = ft_atom_ctrl.ioc;
+		msg.desc = ft_tx_ctrl.iov_desc;
+		msg.iov_count = iov_count;
+		msg.addr = ft_tx_ctrl.addr;
+		msg.context = ctx;
+		msg.data = ft_tx_ctrl.remote_cq_data;
+		msg.op = ft_atom_ctrl.op;
+		msg.datatype = ft_atom_ctrl.datatype;
+
+		rma_iov.addr = ft_mr_ctrl.peer_mr_addr;
+		rma_iov.key = ft_mr_ctrl.peer_mr_key;
+
+		for (i = 0, rma_iov.count = 0; i < msg.iov_count; i++)
+			rma_iov.count += ft_atom_ctrl.ioc[i].count;
+
+		msg.rma_iov = &rma_iov;
+		msg.rma_iov_count = 1;
+		ft_send_retry(ret, fi_atomicmsg, ft_tx_ctrl.ep, &msg, test_info.msg_flags);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_FETCH_ATOMIC:
+		ft_send_retry(ret, fi_fetch_atomic, ft_tx_ctrl.ep,
+			ft_tx_ctrl.buf, ft_atom_ctrl.count, ft_tx_ctrl.memdesc,
+			ft_atom_ctrl.res_buf, ft_atom_ctrl.res_memdesc,
+			ft_tx_ctrl.addr, ft_mr_ctrl.peer_mr_addr,
+			ft_mr_ctrl.peer_mr_key, ft_atom_ctrl.datatype,
+			ft_atom_ctrl.op, ctx);
+		break;
+	case FT_FUNC_FETCH_ATOMICV:
+		ft_format_iocs(ft_tx_ctrl.iov, &iov_count);
+		ft_send_retry(ret, fi_fetch_atomicv, ft_tx_ctrl.ep,
+			ft_atom_ctrl.ioc, ft_tx_ctrl.iov_desc, iov_count,
+			ft_atom_ctrl.res_ioc, ft_atom_ctrl.res_memdesc,
+			iov_count, ft_tx_ctrl.addr, ft_mr_ctrl.peer_mr_addr,
+			ft_mr_ctrl.peer_mr_key, ft_atom_ctrl.datatype,
+			ft_atom_ctrl.op, ctx);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_FETCH_ATOMICMSG:
+		ft_format_iocs(ft_tx_ctrl.iov, &iov_count);
+		msg.msg_iov = ft_atom_ctrl.ioc;
+		msg.desc = ft_tx_ctrl.iov_desc;
+		msg.iov_count = iov_count;
+		msg.addr = ft_tx_ctrl.addr;
+		msg.context = ctx;
+		msg.data = ft_tx_ctrl.remote_cq_data;
+		msg.op = ft_atom_ctrl.op;
+		msg.datatype = ft_atom_ctrl.datatype;
+
+		rma_iov.addr = ft_mr_ctrl.peer_mr_addr;
+		rma_iov.key = ft_mr_ctrl.peer_mr_key;
+
+		for (i = 0, rma_iov.count = 0; i < msg.iov_count; i++)
+			rma_iov.count += ft_atom_ctrl.ioc[i].count;
+
+		msg.rma_iov = &rma_iov;
+		msg.rma_iov_count = 1;
+
+		ft_send_retry(ret, fi_fetch_atomicmsg, ft_tx_ctrl.ep, &msg,
+			ft_atom_ctrl.res_ioc, ft_atom_ctrl.res_memdesc,
+			iov_count, test_info.msg_flags);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_COMPARE_ATOMIC:
+		ft_send_retry(ret, fi_compare_atomic, ft_tx_ctrl.ep,
+			ft_tx_ctrl.buf, ft_atom_ctrl.count, ft_tx_ctrl.memdesc,
+			ft_atom_ctrl.comp_buf, ft_atom_ctrl.comp_memdesc,
+			ft_atom_ctrl.res_buf, ft_atom_ctrl.res_memdesc,
+			ft_tx_ctrl.addr, ft_mr_ctrl.peer_mr_addr,
+			ft_mr_ctrl.peer_mr_key, ft_atom_ctrl.datatype,
+			ft_atom_ctrl.op, ctx);
+		break;
+	case FT_FUNC_COMPARE_ATOMICV:
+		ft_format_iocs(ft_tx_ctrl.iov, &iov_count);
+		ft_send_retry(ret, fi_compare_atomicv, ft_tx_ctrl.ep,
+			ft_atom_ctrl.ioc, ft_tx_ctrl.iov_desc, iov_count,
+			ft_atom_ctrl.comp_ioc, ft_atom_ctrl.comp_memdesc,
+			iov_count, ft_atom_ctrl.res_ioc,
+			ft_atom_ctrl.res_memdesc, iov_count, ft_tx_ctrl.addr,
+			ft_mr_ctrl.peer_mr_addr, ft_mr_ctrl.peer_mr_key,
+			ft_atom_ctrl.datatype, ft_atom_ctrl.op, ctx);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_COMPARE_ATOMICMSG:
+		ft_format_iocs(ft_tx_ctrl.iov, &iov_count);
+		msg.msg_iov = ft_atom_ctrl.ioc;
+		msg.desc = ft_tx_ctrl.iov_desc;
+		msg.iov_count = iov_count;
+		msg.addr = ft_tx_ctrl.addr;
+		msg.context = ctx;
+		msg.data = ft_tx_ctrl.remote_cq_data;
+		msg.op = ft_atom_ctrl.op;
+		msg.datatype = ft_atom_ctrl.datatype;
+
+		rma_iov.addr = ft_mr_ctrl.peer_mr_addr;
+		rma_iov.key = ft_mr_ctrl.peer_mr_key;
+
+		for (i = 0, rma_iov.count = 0; i < msg.iov_count; i++)
+			rma_iov.count += ft_atom_ctrl.ioc[i].count;
+
+		msg.rma_iov = &rma_iov;
+		msg.rma_iov_count = 1;
+
+		ft_send_retry(ret, fi_compare_atomicmsg, ft_tx_ctrl.ep, &msg,
+			ft_atom_ctrl.comp_ioc, ft_atom_ctrl.comp_memdesc, iov_count,
+			ft_atom_ctrl.res_ioc, ft_atom_ctrl.res_memdesc,
+			iov_count, test_info.msg_flags);
+		ft_next_iov_cnt(&ft_tx_ctrl, fabric_info->tx_attr->iov_limit);
+		break;
+	case FT_FUNC_INJECT_ATOMIC:
+		ft_send_retry(ret, fi_inject_atomic, ft_tx_ctrl.ep,
+			ft_tx_ctrl.buf, ft_atom_ctrl.count, ft_tx_ctrl.addr, 
+			ft_mr_ctrl.peer_mr_addr, ft_mr_ctrl.peer_mr_key,
+			ft_atom_ctrl.datatype, ft_atom_ctrl.op);
+		break;
+	default:
+		ft_send_retry(ret, fi_atomic, ft_tx_ctrl.ep, ft_tx_ctrl.buf,
+				ft_atom_ctrl.count, ft_tx_ctrl.memdesc,
+				ft_tx_ctrl.addr, ft_mr_ctrl.peer_mr_addr,
+				ft_mr_ctrl.peer_mr_key, ft_atom_ctrl.datatype,
+				ft_atom_ctrl.op, ctx);
+	}
+
+	if (ft_check_tx_completion())
+		ft_tx_ctrl.credits--;
+
+	return ret;
+}
+
+int ft_send_rma(void)
+{
+	int ret;
+
+	while (!ft_tx_ctrl.credits) {
+		ret = ft_comp_tx(FT_COMP_TO);
+		if (ret)
+			return ret;
+	}
+
+	if (test_info.test_class & FI_ATOMIC)
+		ret = ft_post_send_atomic();
+	else 	
+		ret = ft_post_send_rma();
+
+	if (ret) {
+		FT_PRINTERR("send_rma", ret);
+		return ret;
+	}
+
+	if (is_inject_func(test_info.class_function) &&
+	    test_info.test_type == FT_TEST_UNIT)
+		memset(ft_tx_ctrl.buf, 0, ft_tx_ctrl.rma_msg_size);
+
+	if (!ft_tx_ctrl.credits) {
+		ret = ft_comp_tx(0);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+int ft_post_recv_bufs(void)
+{
+	int ret;
+
+	for (; ft_rx_ctrl.credits; ft_rx_ctrl.credits--) {
+		if (test_info.test_class & FI_TAGGED) {
+			ret = ft_post_trecv();
+			if (!ret)
+				ft_rx_ctrl.tag++;
+		} else {
+			ret = ft_post_recv();
+		}
+		if (ret) {
+			if (ret == -FI_EAGAIN)
+				break;
+			FT_PRINTERR("recv", ret);
+			return ret;
+		}
+	}
+	return 0;
+}
+
+int ft_recv_n_msg(int n)
+{
+	int credits, ret, recved = 0;
+
+	do {
+		if (ft_rx_ctrl.credits > (ft_rx_ctrl.max_credits >> 1)) {
+			ret = ft_post_recv_bufs();
+			if (ret)
+				return ret;
+		}
+
+		credits = ft_rx_ctrl.credits;
+		ret = ft_comp_rx(0);
+		if (ret)
+			return ret;
+
+		//ft_comp_rx may have found multiple completions (bw testing)
+		recved += (ft_rx_ctrl.credits - credits);
+
+		// handle manual progress. we should progress sends if
+		// we don't get any recv completions. the send could have
+		// been lost.
+		// ft_comp_tx(0);
+	} while (recved < n);
+
+	return 0;
+}
+
+int ft_recv_msg(void)
+{
+	return ft_recv_n_msg(1);
+}
+
+static int ft_rma_sync(void)
+{
+	int ret;
+	struct fi_msg_rma msg;
+	struct iovec msg_iov;
+	struct fi_rma_iov rma_iov;
+	struct fi_context *ctx;
+
+	ret = ft_get_ctx(&ft_tx_ctrl, &ctx);
+	if (ret)
+		return ret;
+
+	msg_iov.iov_base = (void *) ft_tx_ctrl.buf;
+	msg_iov.iov_len = 0;
+	msg.msg_iov = &msg_iov;
+	msg.desc = ft_tx_ctrl.iov_desc;
+	msg.iov_count = 1;
+	msg.addr = ft_tx_ctrl.addr;
+	msg.context = ctx;
+	msg.data = 0;
+
+	rma_iov.addr = ft_mr_ctrl.peer_mr_addr;
+	rma_iov.key = ft_mr_ctrl.peer_mr_key;
+	rma_iov.len = 0;
+
+	msg.rma_iov = &rma_iov;
+	msg.rma_iov_count = 1;
+
+	ft_send_retry(ret, fi_writemsg, ft_tx_ctrl.ep, &msg, FI_COMPLETION);
+
+	ft_tx_ctrl.credits--;
+	return ret;
+}
+
+static int ft_msg_sync(void)
+{
+	int ret;
+	struct fi_msg msg;
+	struct iovec msg_iov;
+	struct fi_context *ctx;
+
+	ret = ft_get_ctx(&ft_tx_ctrl, &ctx);
+	if (ret)
+		return ret;
+
+	msg_iov.iov_base = (void *) buf;
+	msg_iov.iov_len = 0;
+
+	msg.msg_iov = &msg_iov;
+	msg.desc = ft_tx_ctrl.iov_desc;
+	msg.iov_count = 1;
+	msg.addr = ft_tx_ctrl.addr;
+	msg.context = ctx;
+	msg.data = 0;
+
+	ft_send_retry(ret, fi_sendmsg, ft_tx_ctrl.ep, &msg, FI_COMPLETION);
+	ft_tx_ctrl.credits--;
+
+	return ret;
+}
+
+static int ft_tmsg_sync(void)
+{
+	int ret;
+	struct fi_msg_tagged msg;
+	struct iovec msg_iov;
+	struct fi_context *ctx;
+
+	ret = ft_get_ctx(&ft_tx_ctrl, &ctx);
+	if (ret)
+		return ret;
+
+	msg_iov.iov_base = (void *) buf;
+	msg_iov.iov_len = 0;
+
+	msg.msg_iov = &msg_iov;
+	msg.desc = ft_tx_ctrl.iov_desc;
+	msg.iov_count = 1;
+	msg.addr = ft_tx_ctrl.addr;
+	msg.context = ctx;
+	msg.data = 0;
+	msg.tag = ft_tx_ctrl.tag++;
+	msg.context = ctx;
+
+	ft_send_retry(ret, fi_tsendmsg, ft_tx_ctrl.ep, &msg, FI_COMPLETION);
+	ft_tx_ctrl.credits--;
+
+	return ret;
+}
+
+int ft_send_sync_msg(void)
+{
+	int ret;
+
+	while (ft_tx_ctrl.credits != ft_tx_ctrl.max_credits) {
+		ret = ft_comp_tx(0);
+		if (ret)
+			return ret;
+	}
+
+	if (test_info.test_class & FI_TAGGED)
+		ret = ft_tmsg_sync();
+	else if (test_info.caps & FI_MSG)
+		ret = ft_msg_sync();
+	else
+		ret = ft_rma_sync();
+
+	if (ret)
+		return ret;
+
+	return ft_comp_tx(FT_COMP_TO);
+}
+
+int ft_send_msg(void)
+{
+	int ret;
+
+	while (!ft_tx_ctrl.credits) {
+		ret = ft_comp_tx(FT_COMP_TO);
+		if (ret)
+			return ret;
+	}
+
+	if (test_info.test_class & FI_TAGGED) {
+		ret = ft_post_tsend();
+		if (!ret)
+			ft_tx_ctrl.tag++;
+	} else {
+		ret = ft_post_send();
+	}
+
+	if (ret) {
+		FT_PRINTERR("send", ret);
+		return ret;
+	}
+
+	if (is_inject_func(test_info.class_function) &&
+	    test_info.test_type == FT_TEST_UNIT)
+		memset(ft_tx_ctrl.buf, 0, ft_tx_ctrl.msg_size);
+
+	if (!ft_tx_ctrl.credits) {
+		ret = ft_comp_tx(0);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+int ft_send_dgram(void)
+{
+	int ret;
+
+	*(uint8_t*) ft_tx_ctrl.buf = ft_tx_ctrl.seqno++;
+	ret = ft_send_msg();
+	return ret;
+}
+
+int ft_send_dgram_flood(void)
+{
+	int i, ret = 0;
+
+	ft_tx_ctrl.seqno = 0;
+	*(uint8_t*) ft_tx_ctrl.buf = 0;
+	for (i = 0; i < ft_ctrl.xfer_iter - 1; i++) {
+		ret = ft_send_msg();
+		if (ret)
+			break;
+	}
+
+	return ret;
+}
+
+int ft_recv_dgram(void)
+{
+	int credits, ret;
+
+	do {
+		if (ft_rx_ctrl.credits > (ft_rx_ctrl.max_credits >> 1)) {
+			ret = ft_post_recv_bufs();
+			if (ret)
+				return ret;
+		}
+
+		credits = ft_rx_ctrl.credits;
+
+		ret = ft_comp_rx(FT_DGRAM_POLL_TO);
+		if ((credits != ft_rx_ctrl.credits) &&
+		    (*(uint8_t *) ft_rx_ctrl.buf == ft_rx_ctrl.seqno)) {
+			ft_rx_ctrl.seqno++;
+			return 0;
+		}
+	} while (!ret);
+
+	return (ret == -FI_EAGAIN) ? -FI_ETIMEDOUT : ret;
+}
+
+int ft_recv_dgram_flood(size_t *recv_cnt)
+{
+	int ret;
+	size_t cnt = 0;
+
+	do {
+		ret = ft_post_recv_bufs();
+		if (ret)
+			break;
+
+		ret = ft_comp_rx(0);
+		cnt += ft_rx_ctrl.credits;
+
+	} while (!ret && ((*(uint8_t *) ft_rx_ctrl.buf != (uint8_t) ~0) || !cnt));
+
+	*recv_cnt = cnt;
+	return ret;
+}
+
+int ft_sendrecv_dgram(void)
+{
+	int ret, try;
+
+	for (try = 0; try < 1000; try++) {
+		ret = ft_send_dgram();
+		if (ret)
+			return ret;
+
+		ret = ft_recv_dgram();
+		if (ret != -FI_ETIMEDOUT)
+			break;
+
+		/* resend */
+		if (test_info.test_class & FI_TAGGED)
+			ft_tx_ctrl.tag--;
+		ft_tx_ctrl.seqno--;
+	}
+
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/av_test.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/av_test.c
new file mode 100644
index 000000000..54a115a02
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/av_test.c
@@ -0,0 +1,989 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <string.h>
+#include <netdb.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+
+#include <rdma/fi_errno.h>
+
+#include "shared.h"
+#include "unit_common.h"
+
+#define MAX_ADDR 256
+
+char *good_address;
+int num_good_addr;
+char *bad_address;
+
+static enum fi_av_type av_type;
+
+static char err_buf[512];
+
+static int
+check_eq_readerr(struct fid_eq *eq, fid_t fid, void *context, int index)
+{
+	int ret;
+	struct fi_eq_err_entry err_entry;
+
+	memset(&err_entry, 0, sizeof(err_entry));
+	ret = fi_eq_readerr(eq, &err_entry, 0);
+	if (ret != sizeof(err_entry)) {
+		sprintf(err_buf, "fi_eq_readerr ret = %d, %s", ret,
+				(ret < 0) ? fi_strerror(-ret) : "unknown");
+		return -1;
+	}
+	if (err_entry.fid != fid) {
+		sprintf(err_buf, "fi_eq_readerr fid = %p, should be %p",
+				err_entry.fid, fid);
+		return -1;
+	}
+	if (err_entry.context != context) {
+		sprintf(err_buf, "fi_eq_readerr fid = %p, should be %p",
+				err_entry.context, context);
+		return -1;
+	}
+	if (err_entry.data != index) {
+		sprintf(err_buf, "fi_eq_readerr index = %" PRIu64 ", should be %d",
+				err_entry.data, index);
+		return -1;
+	}
+	if (err_entry.err <= 0) {
+		sprintf(err_buf, "fi_eq_readerr err = %d, should be > 0",
+				err_entry.err);
+		return -1;
+	}
+	return 0;
+}
+
+static int
+check_eq_result(int ret, uint32_t event, struct fi_eq_entry *entry,
+		fid_t fid, void *context, uint32_t count)
+{
+	if (ret != sizeof(*entry)) {
+		sprintf(err_buf, "fi_eq_sread ret = %d, %s", ret,
+				(ret < 0) ? fi_strerror(-ret) : "unknown");
+		return -1;
+	}
+	if (event != FI_AV_COMPLETE) {
+		sprintf(err_buf, "fi_eq_sread event = %u, should be %u", event,
+				FI_AV_COMPLETE);
+		return -1;
+	}
+	if (entry->fid != fid) {
+		sprintf(err_buf, "fi_eq_sread fid = %p, should be %p",
+				entry->fid, fid);
+		return -1;
+	}
+	/* context == NULL means skip check */
+	if (context != NULL && entry->context != context) {
+		sprintf(err_buf, "fi_eq_sread fid = %p, should be %p", entry->context,
+				context);
+		return -1;
+	}
+	if (count != ~0 && entry->data != count) {
+		sprintf(err_buf, "count = %" PRIu64 ", should be %u", entry->data, count);
+		return -1;
+	}
+	return 0;
+}
+
+static int
+check_eq_sread(struct fid_eq *eq, fid_t fid, void *context, uint32_t count,
+		int timeout, uint64_t flags)
+{
+	struct fi_eq_entry entry;
+	uint32_t event;
+	int ret;
+
+	event = ~0;
+	memset(&entry, 0, sizeof(entry));
+
+	ret = fi_eq_sread(eq, &event, &entry, sizeof(entry), timeout, flags);
+	return check_eq_result(ret, event, &entry, fid, context, count);
+}
+
+static int
+av_test_open_close(enum fi_av_type type, int count, uint64_t flags)
+{
+	int ret;
+	struct fi_av_attr attr;
+	struct fid_av *av;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = type;
+	attr.count = count;
+	attr.flags = flags;
+
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%d, %s) = %d, %s",
+				count, fi_tostr(&type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		return ret;
+	}
+
+	ret = fi_close(&av->fid);
+	if (ret != 0) {
+		sprintf(err_buf, "close(av) = %d, %s", ret, fi_strerror(-ret));
+		return ret;
+	}
+	return 0;
+}
+
+/*
+ * Tests:
+ * - test open and close of AV
+ */
+static int
+av_open_close()
+{
+	int i;
+	int testret;
+	int ret;
+	int count;
+
+	testret = FAIL;
+
+	for (i = 0; i < 17; ++i) {
+		count = 1 << i;
+		ret = av_test_open_close(av_type, count, 0);
+		if (ret != 0) {
+			goto fail;
+		}
+	}
+	testret = PASS;
+fail:
+	return TEST_RET_VAL(ret, testret);
+}
+
+static int
+av_create_addr_sockaddr_in(char *first_address, int index, void *addr)
+{
+	struct addrinfo hints;
+	struct addrinfo *ai;
+	struct sockaddr_in *sin;
+	uint32_t tmp;
+	int ret;
+
+	memset(&hints, 0, sizeof(hints));
+
+	/* return all 0's for invalid address */
+	if (first_address == NULL) {
+		memset(addr, 0, sizeof(*sin));
+		return 0;
+	}
+
+	hints.ai_family = AF_INET;
+	/* port doesn't matter, set port to discard port */
+	ret = getaddrinfo(first_address, "discard", &hints, &ai);
+	if (ret != 0) {
+		sprintf(err_buf, "getaddrinfo: %s", gai_strerror(ret));
+		return -1;
+	}
+
+	sin = (struct sockaddr_in *)addr;
+	*sin = *(struct sockaddr_in *)ai->ai_addr;
+
+	tmp = ntohl(sin->sin_addr.s_addr);
+	tmp += index;
+	sin->sin_addr.s_addr = htonl(tmp);
+
+	freeaddrinfo(ai);
+	return 0;
+}
+
+/*
+ * Create an address list
+ */
+static int
+av_create_address_list(char *first_address, int base, int num_addr,
+		void *addr_array, int offset, int len)
+{
+	int (*add_address)(char *, int, void *);
+	uint8_t *cur_addr;
+	int addrlen;
+	int ret;
+	int i;
+
+	switch (fi->addr_format) {
+	case FI_SOCKADDR:
+	case FI_SOCKADDR_IN:
+		addrlen = sizeof(struct sockaddr_in);
+		add_address = av_create_addr_sockaddr_in;
+		break;
+	default:
+		sprintf(err_buf, "test does not yet support %s",
+				fi_tostr(&fi->addr_format, FI_TYPE_ADDR_FORMAT));
+		return -FI_ENOSYS;
+	}
+
+	if (len < addrlen * (offset + num_addr)) {
+		sprintf(err_buf, "internal error, not enough room for %d addresses",
+				num_addr);
+		return -FI_ENOMEM;
+	}
+
+	cur_addr = addr_array;
+	cur_addr += offset * addrlen;
+	for (i = 0; i < num_addr; ++i) {
+		ret = add_address(first_address, base + i, cur_addr);
+		if (ret != 0) {
+			return ret;
+		}
+		cur_addr += addrlen;
+	}
+
+	return cur_addr - (uint8_t *)addr_array;
+}
+
+/*
+ * Tests:
+ * - synchronous resolution of good address
+ */
+static int
+av_good_sync()
+{
+	int testret;
+	int ret;
+	struct fid_av *av;
+	struct fi_av_attr attr;
+	uint8_t addrbuf[4096];
+	int buflen;
+	fi_addr_t fi_addr;
+
+	testret = FAIL;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = av_type;
+	attr.count = 32;
+
+	av = NULL;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%s) = %d, %s",
+				fi_tostr(&av_type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	fi_addr = FI_ADDR_NOTAVAIL;
+
+	buflen = sizeof(addrbuf);
+	ret = av_create_address_list(good_address, 0, 1, addrbuf, 0, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+
+	ret = fi_av_insert(av, addrbuf, 1, &fi_addr, 0, NULL);
+	if (ret != 1) {
+		sprintf(err_buf, "fi_av_insert ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+	if (fi_addr == FI_ADDR_NOTAVAIL) {
+		sprintf(err_buf, "fi_addr == FI_ADDR_NOTAVAIL");
+		goto fail;
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(av);
+	return TEST_RET_VAL(ret, testret);
+}
+
+static int
+av_null_fi_addr()
+{
+	int testret;
+	int ret;
+	struct fid_av *av;
+	struct fi_av_attr attr;
+	uint8_t addrbuf[4096];
+	int buflen;
+
+	testret = FAIL;
+
+	if (av_type != FI_AV_TABLE) {
+		ret = 0;
+		testret = SKIPPED;
+		sprintf(err_buf, "test not valid for AV type FI_AV_MAP");
+		goto out1;
+	}
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = av_type;
+	attr.count = 32;
+
+	av = NULL;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%s) = %d, %s",
+				fi_tostr(&av_type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		goto out1;
+	}
+
+	buflen = sizeof(addrbuf);
+	ret = av_create_address_list(good_address, 0, 1, addrbuf, 0, buflen);
+	if (ret < 0) {
+		goto out2;		// av_create_address_list filled err_buf
+	}
+
+	ret = fi_av_insert(av, addrbuf, 1, NULL, 0, NULL);
+	if (ret != 1) {
+		sprintf(err_buf, "fi_av_insert ret=%d, %s", ret, fi_strerror(-ret));
+		goto out2;
+	}
+	testret = PASS;
+out2:
+	FT_CLOSE_FID(av);
+out1:
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - synchronous resolution of bad address
+ */
+static int
+av_bad_sync()
+{
+	int testret;
+	int ret;
+	struct fid_av *av;
+	struct fi_av_attr attr;
+	uint8_t addrbuf[4096];
+	int buflen;
+	fi_addr_t fi_addr;
+
+	testret = FAIL;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = av_type;
+	attr.count = 32;
+
+	av = NULL;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%s) = %d, %s",
+				fi_tostr(&av_type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	fi_addr = ~FI_ADDR_NOTAVAIL;
+
+	buflen = sizeof(addrbuf);
+	ret = av_create_address_list(bad_address, 0, 1, addrbuf, 0, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+
+	ret = fi_av_insert(av, addrbuf, 1, &fi_addr, 0, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_insert ret=%d, should be 0", ret);
+		goto fail;
+	}
+	if (fi_addr != FI_ADDR_NOTAVAIL) {
+		sprintf(err_buf,
+				"fi_addr = 0x%" PRIx64 ", should be 0x%" PRIx64" (FI_ADDR_NOTAVAIL)",
+				fi_addr, FI_ADDR_NOTAVAIL);
+		goto fail;
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(av);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - sync vector with 1 good and 1 bad
+ */
+static int
+av_goodbad_vector_sync()
+{
+	int testret;
+	int ret;
+	int i;
+	struct fid_av *av;
+	struct fi_av_attr attr;
+	uint8_t addrbuf[4096];
+	int buflen;
+	fi_addr_t fi_addr[MAX_ADDR];
+
+	testret = FAIL;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = av_type;
+	attr.count = 32;
+
+	av = NULL;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%s) = %d, %s",
+				fi_tostr(&av_type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	for (i = 0; i < MAX_ADDR; ++i) {
+		fi_addr[i] = FI_ADDR_NOTAVAIL;
+	}
+	fi_addr[1] = ~FI_ADDR_NOTAVAIL;
+
+	buflen = sizeof(addrbuf);
+
+	/* vector is good address + bad address */
+	ret = av_create_address_list(good_address, 0, 1, addrbuf, 0, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+	ret = av_create_address_list(bad_address, 0, 1, addrbuf, 1, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+	ret = fi_av_insert(av, addrbuf, 2, fi_addr, 0, NULL);
+	if (ret != 1) {
+		sprintf(err_buf, "fi_av_insert ret=%d, should be 1", ret);
+		goto fail;
+	}
+
+	/*
+	 * Check returned fi_addrs
+	 */
+	if (fi_addr[0] == FI_ADDR_NOTAVAIL) {
+		sprintf(err_buf, "fi_addr[0] = FI_ADDR_NOTAVAIL");
+		goto fail;
+	}
+	if (fi_addr[1] != FI_ADDR_NOTAVAIL) {
+		sprintf(err_buf, "fi_addr[1] != FI_ADDR_NOTAVAIL");
+		goto fail;
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(av);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - async good vector
+ */
+static int
+av_good_vector_async()
+{
+	int testret;
+	int ret;
+	int i;
+	struct fid_av *av;
+	struct fi_av_attr attr;
+	uint8_t addrbuf[4096];
+	uint32_t ctx;
+	int buflen;
+	fi_addr_t fi_addr[MAX_ADDR];
+
+	testret = FAIL;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = av_type;
+	attr.count = 32;
+	attr.flags = FI_EVENT;
+
+	av = NULL;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%s) = %d, %s",
+				fi_tostr(&av_type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		goto fail;
+	}
+	ret = fi_av_bind(av, &eq->fid, 0);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_bind() = %d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	for (i = 0; i < MAX_ADDR; ++i) {
+		fi_addr[i] = FI_ADDR_NOTAVAIL;
+	}
+
+	buflen = sizeof(addrbuf);
+	ret = av_create_address_list(good_address, 0, num_good_addr,
+			addrbuf, 0, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+
+	for (i = 0; i < num_good_addr; ++i) {
+		fi_addr[i] = FI_ADDR_NOTAVAIL;
+	}
+	ret = fi_av_insert(av, addrbuf, num_good_addr, fi_addr, 0, &ctx);
+	if (ret) {
+		sprintf(err_buf, "fi_av_insert ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	if (check_eq_sread(eq, &av->fid, &ctx, num_good_addr, 20000, 0) != 0) {
+		goto fail;
+	}
+	for (i = 0; i < num_good_addr; ++i) {
+		if (fi_addr[i] == FI_ADDR_NOTAVAIL) {
+			sprintf(err_buf, "fi_addr[%d] = FI_ADDR_NOTAVAIL", i);
+			goto fail;
+		}
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(av);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - async good vector
+ */
+static int
+av_zero_async()
+{
+	int testret;
+	int ret;
+	struct fid_av *av;
+	struct fi_av_attr attr;
+	uint8_t addrbuf[4096];
+	uint32_t ctx;
+	fi_addr_t fi_addr[MAX_ADDR];
+
+	testret = FAIL;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = av_type;
+	attr.count = 32;
+	attr.flags = FI_EVENT;
+
+	av = NULL;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%s) = %d, %s",
+				fi_tostr(&av_type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		goto fail;
+	}
+	ret = fi_av_bind(av, &eq->fid, 0);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_bind() = %d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	ret = fi_av_insert(av, addrbuf, 0, fi_addr, 0, &ctx);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_insert ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	if (check_eq_sread(eq, &av->fid, &ctx, 0, 20000, 0) != 0) {
+		goto fail;
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(av);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - async 2 good vectors
+ */
+static int
+av_good_2vector_async()
+{
+	int testret;
+	int ret;
+	int i;
+	struct fid_av *av;
+	struct fi_av_attr attr;
+	uint8_t addrbuf[4096];
+	uint32_t event;
+	struct fi_eq_entry entry;
+	uint32_t ctx[2];
+	int buflen;
+	fi_addr_t fi_addr[MAX_ADDR];
+
+	testret = FAIL;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = av_type;
+	attr.count = 32;
+	attr.flags = FI_EVENT;
+
+	av = NULL;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%s) = %d, %s",
+				fi_tostr(&av_type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		goto fail;
+	}
+	ret = fi_av_bind(av, &eq->fid, 0);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_bind() = %d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	for (i = 0; i < MAX_ADDR; ++i) {
+		fi_addr[i] = FI_ADDR_NOTAVAIL;
+	}
+
+	buflen = sizeof(addrbuf);
+
+	/* 1st vector is just first address */
+	ret = av_create_address_list(good_address, 0, 1, addrbuf, 0, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+	ret = fi_av_insert(av, addrbuf, 1, fi_addr, FI_MORE, &ctx[0]);
+	if (ret) {
+		sprintf(err_buf, "fi_av_insert ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+	ctx[0] = 1;
+
+	/* 2nd vector is remaining addresses */
+	ret = av_create_address_list(good_address, 1, num_good_addr-1,
+			addrbuf, 0, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+	ret = fi_av_insert(av, addrbuf, num_good_addr-1, &fi_addr[1], 0, &ctx[1]);
+	if (ret != num_good_addr-1) {
+		sprintf(err_buf, "fi_av_insert ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+	ctx[1] = num_good_addr-1;
+
+	/*
+	 * Handle completions in either order
+	 */
+	for (i = 0; i < 2; ++i) {
+		ret = fi_eq_sread(eq, &event, &entry, sizeof(entry), 20000, 0);
+		ret = check_eq_result(ret, event, &entry, &av->fid, NULL, ~0);
+		if (ret != 0) {
+			goto fail;
+		}
+		if (entry.context != &ctx[0] && entry.context != &ctx[1]) {
+			sprintf(err_buf, "bad context: %p", entry.context);
+			goto fail;
+		}
+		if (*(uint32_t *)(entry.context) == ~0) {
+			sprintf(err_buf, "duplicate context: %p", entry.context);
+			goto fail;
+		}
+		if (*(uint32_t *)(entry.context) != entry.data) {
+			sprintf(err_buf, "count = %" PRIu64 ", should be %d", entry.data,
+					*(uint32_t *)(entry.context));
+			goto fail;
+		}
+		*(uint32_t *)(entry.context) = ~0;
+	}
+	for (i = 0; i < num_good_addr; ++i) {
+		if (fi_addr[i] == FI_ADDR_NOTAVAIL) {
+			sprintf(err_buf, "fi_addr[%d] = FI_ADDR_NOTAVAIL", i);
+			goto fail;
+		}
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(av);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - async vector with 1 good and 1 bad
+ */
+static int
+av_goodbad_vector_async()
+{
+	int testret;
+	int ret;
+	int i;
+	struct fid_av *av;
+	struct fi_av_attr attr;
+	uint8_t addrbuf[4096];
+	uint32_t event;
+	uint32_t ctx;
+	struct fi_eq_entry entry;
+	int buflen;
+	fi_addr_t fi_addr[MAX_ADDR];
+
+	testret = FAIL;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.type = av_type;
+	attr.count = 32;
+	attr.flags = FI_EVENT;
+
+	av = NULL;
+	ret = fi_av_open(domain, &attr, &av, NULL);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_open(%s) = %d, %s",
+				fi_tostr(&av_type, FI_TYPE_AV_TYPE),
+				ret, fi_strerror(-ret));
+		goto fail;
+	}
+	ret = fi_av_bind(av, &eq->fid, 0);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_av_bind() = %d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	for (i = 0; i < MAX_ADDR; ++i) {
+		fi_addr[i] = FI_ADDR_NOTAVAIL;
+	}
+	fi_addr[1] = ~FI_ADDR_NOTAVAIL;
+
+	buflen = sizeof(addrbuf);
+
+	/* vector is good address + bad address */
+	ret = av_create_address_list(good_address, 0, 1, addrbuf, 0, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+	ret = av_create_address_list(bad_address, 0, 1, addrbuf, 1, buflen);
+	if (ret < 0) {
+		goto fail;		// av_create_address_list filled err_buf
+	}
+	ret = fi_av_insert(av, addrbuf, 2, fi_addr, 0, &ctx);
+	if (ret) {
+		sprintf(err_buf, "fi_av_insert ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	/*
+	 * Read event after sync, verify we get FI_EAVAIL, then read and
+	 * verify the error completion
+	 */
+	ret = fi_eq_sread(eq, &event, &entry, sizeof(entry), 20000, 0);
+	if (ret != -FI_EAVAIL) {
+		sprintf(err_buf, "fi_eq_sread ret = %d, should be -FI_EAVAIL", ret);
+		goto fail;
+	}
+	ret = check_eq_readerr(eq, &av->fid, &ctx, 1);
+	if (ret != 0) {
+		goto fail;
+	}
+
+	/*
+	 * Now we should get a good completion, and all fi_addr except fd_addr[1]
+	 * should have good values.
+	 */
+	if (check_eq_sread(eq, &av->fid, &ctx, 1, 20000, 0) != 0) {
+		goto fail;
+	}
+	if (fi_addr[0] == FI_ADDR_NOTAVAIL) {
+		sprintf(err_buf, "fi_addr[0] = FI_ADDR_NOTAVAIL");
+		goto fail;
+	}
+	if (fi_addr[1] != FI_ADDR_NOTAVAIL) {
+		sprintf(err_buf, "fi_addr[1] != FI_ADDR_NOTAVAIL");
+		goto fail;
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(av);
+	return TEST_RET_VAL(ret, testret);
+}
+
+struct test_entry test_array_good[] = {
+	TEST_ENTRY(av_open_close, "Test open and close AVs of varying sizes"),
+	TEST_ENTRY(av_good_sync, "Test sync AV insert with good address"),
+	TEST_ENTRY(av_null_fi_addr, "Test AV insert without specifying fi_addr"),
+	TEST_ENTRY(av_good_vector_async,
+			"Test async AV insert with vector of good addresses"),
+	TEST_ENTRY(av_zero_async, "Test async insert AV insert of zero addresses"),
+	TEST_ENTRY(av_good_2vector_async,
+			"Test async AV inserts with two address vectors"),
+	{ NULL, "" }
+};
+
+struct test_entry test_array_bad[] = {
+	TEST_ENTRY(av_bad_sync, "Test sync AV insert of bad address"),
+	TEST_ENTRY(av_goodbad_vector_sync,
+			"Test sync AV insert of 1 good and 1 bad address"),
+	TEST_ENTRY(av_goodbad_vector_async,
+			"Test async AV insert with good and bad address"),
+	{ NULL, "" }
+};
+
+int
+run_test_set()
+{
+	int failed;
+
+	failed = 0;
+
+	failed += run_tests(test_array_good, err_buf);
+	if (bad_address != NULL) {
+		printf("\nTesting with bad_address = \"%s\"\n", bad_address);
+		failed += run_tests(test_array_bad, err_buf);
+	}
+
+	bad_address = NULL;
+	printf("\nTesting with invalid address\n");
+	failed += run_tests(test_array_bad, err_buf);
+
+	return failed;
+}
+
+static void usage(void)
+{
+	ft_unit_usage("av_test", "Unit test for Address Vector (AV)");
+	FT_PRINT_OPTS_USAGE("-g <good_address>", "");
+	FT_PRINT_OPTS_USAGE("-G <bad_address>]", "");
+	fprintf(stderr, FT_OPTS_USAGE_FORMAT " (max=%d)\n", "-n <num_good_addr>",
+			"Number of good addresses", MAX_ADDR - 1);
+	FT_PRINT_OPTS_USAGE("-s <source_address>", "");
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+	int failed;
+
+	opts = INIT_OPTS;
+	opts.options |= FT_OPT_SIZE;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, FAB_OPTS "g:G:n:s:h")) != -1) {
+		switch (op) {
+		case 'g':
+			good_address = optarg;
+			break;
+		case 'G':
+			bad_address = optarg;
+			break;
+		case 'n':
+			num_good_addr = atoi(optarg);
+			break;
+		case 's':
+			opts.src_addr = optarg;
+			break;
+		default:
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			usage();
+			return EXIT_FAILURE;
+
+		}
+	}
+
+	if (good_address == NULL ||  num_good_addr == 0) {
+		printf("Test requires -g and -n\n");
+		return EXIT_FAILURE;
+	}
+
+	if (num_good_addr > MAX_ADDR - 1) {
+		printf("num_good_addr = %d is too big, dropped to %d\n",
+				num_good_addr, MAX_ADDR);
+		num_good_addr = MAX_ADDR - 1;
+	}
+
+	hints->mode = ~0;
+	hints->domain_attr->mode = ~0;
+	hints->domain_attr->mr_mode = ~(FI_MR_BASIC | FI_MR_SCALABLE);
+	hints->addr_format = FI_SOCKADDR;
+
+	// TODO make this test accept endpoint type argument
+	hints->ep_attr->type = FI_EP_RDM;
+	ret = fi_getinfo(FT_FIVERSION, opts.src_addr, 0, FI_SOURCE, hints, &fi);
+
+	if (ret && ret != -FI_ENODATA) {
+		FT_PRINTERR("fi_getinfo", ret);
+		goto err;
+	}
+
+	if (ret == -FI_ENODATA) {
+		hints->ep_attr->type = FI_EP_DGRAM;
+		ret = fi_getinfo(FT_FIVERSION, opts.src_addr, 0, FI_SOURCE, hints, &fi);
+		if (ret) {
+			FT_PRINTERR("fi_getinfo", ret);
+			goto err;
+		}
+	}
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		goto err;
+
+	printf("Testing AVs on fabric %s\n", fi->fabric_attr->name);
+	failed = 0;
+
+	if (fi->domain_attr->av_type == FI_AV_UNSPEC ||
+	    fi->domain_attr->av_type == FI_AV_MAP) {
+		av_type = FI_AV_MAP;
+		printf("\nTesting with type = FI_AV_MAP\n");
+		failed += run_test_set();
+	}
+
+	if (fi->domain_attr->av_type == FI_AV_UNSPEC ||
+	    fi->domain_attr->av_type == FI_AV_TABLE) {
+		av_type = FI_AV_TABLE;
+		printf("\nTesting with type = FI_AV_TABLE\n");
+		failed += run_test_set();
+	}
+
+	if (failed > 0) {
+		printf("\nSummary: %d tests failed\n", failed);
+	} else {
+		printf("\nSummary: all tests passed\n");
+	}
+
+err:
+	ft_free_res();
+	return ret ? ft_exit_code(ret) : (failed > 0) ? EXIT_FAILURE : EXIT_SUCCESS;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/cntr_test.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/cntr_test.c
new file mode 100644
index 000000000..52431d99b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/cntr_test.c
@@ -0,0 +1,203 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <sched.h>
+
+#include <rdma/fi_errno.h>
+
+#include "unit_common.h"
+#include "shared.h"
+
+
+static char err_buf[512];
+#define MAX_COUNTER_CHECK 100
+
+
+static int cntr_loop()
+{
+	size_t i, opened, cntr_cnt;
+	uint64_t value, expected;
+	struct timespec start, stop;
+	int ret, testret = FAIL, timeout = 5000;
+
+	cntr_cnt = MIN(fi->domain_attr->cntr_cnt, MAX_COUNTER_CHECK);
+	struct fid_cntr **cntrs = calloc(cntr_cnt, sizeof(struct fid_cntr *));
+	if (!cntrs) {
+		perror("calloc");
+		return -FI_ENOMEM;
+	}
+
+	for (opened = 0; opened < cntr_cnt; opened++) {
+		ret = ft_cntr_open(&cntrs[opened]);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_open", ret);
+			goto close;
+		}
+	}
+
+	for (i = 0; i < opened; i++) {
+		ret = fi_cntr_set(cntrs[i], i);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_set", ret);
+			goto close;
+		}
+
+		ret = fi_cntr_seterr(cntrs[i], i << 1);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_seterr", ret);
+			goto close;
+		}
+	}
+
+	for (i = 0; i < opened; i++) {
+		ret = fi_cntr_add(cntrs[i], i);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_add", ret);
+			goto close;
+		}
+
+		ret = fi_cntr_adderr(cntrs[i], i);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_adderr", ret);
+			goto close;
+		}
+	}
+
+	for (i = 0; i < opened; i++) {
+		clock_gettime(CLOCK_MONOTONIC, &start);
+		expected = i + i;
+		do {
+			value = fi_cntr_read(cntrs[i]);
+			clock_gettime(CLOCK_MONOTONIC, &stop);
+			sched_yield();
+		} while ((value != expected) &&
+			((stop.tv_sec - start.tv_sec) > timeout));
+		if (value != expected) {
+			FT_PRINTERR("fi_cntr_read", value);
+			goto close;
+		}
+
+		clock_gettime(CLOCK_MONOTONIC, &start);
+		expected = (i << 1) + i;
+		do {
+			value = fi_cntr_readerr(cntrs[i]);
+			clock_gettime(CLOCK_MONOTONIC, &stop);
+			sched_yield();
+		} while ((value != expected) &&
+			((stop.tv_sec - start.tv_sec) > timeout));
+		if (value != expected) {
+			FT_PRINTERR("fi_cntr_readerr", value);
+			goto close;
+		}
+	}
+	testret = PASS;
+
+close:
+	for (i = 0; i < opened; i++) {
+		ret = fi_close(&(cntrs[i])->fid);
+		if (ret) {
+			FT_PRINTERR("fi_cntr_close", ret);
+			break;
+		}
+	}
+
+	if (i < cntr_cnt)	
+		testret = FAIL;
+
+	free(cntrs);
+	return TEST_RET_VAL(ret, testret);
+}
+
+struct test_entry test_array[] = {
+	TEST_ENTRY(cntr_loop, "Test counter open/set/read/close operations"),
+	{ NULL, "" }
+};
+
+static void usage(void)
+{
+	ft_unit_usage("cntr_test", "Unit test for counter (cntr)");
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+	int failed = 0;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, FAB_OPTS "h")) != -1) {
+		switch (op) {
+		default:
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	hints->mode = ~0;
+	hints->domain_attr->mode = ~0;
+	hints->domain_attr->mr_mode = ~(FI_MR_BASIC | FI_MR_SCALABLE);
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, 0, 0, hints, &fi);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		goto out;
+	}
+
+	if (!fi->domain_attr->cntr_cnt)
+		goto out;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		goto out;
+
+	printf("Testing CNTRS on fabric %s\n", fi->fabric_attr->name);
+
+	failed = run_tests(test_array, err_buf);
+	if (failed > 0)
+		printf("Summary: %d tests failed\n", failed);
+	else
+		printf("Summary: all tests passed\n");
+
+out:
+	ft_free_res();
+	return ret ? ft_exit_code(ret) : (failed > 0) ? EXIT_FAILURE : EXIT_SUCCESS;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/common.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/common.c
new file mode 100644
index 000000000..998a7d7b3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/common.c
@@ -0,0 +1,91 @@
+/*
+ * Copyright (c) 2013-2014 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+
+#include "unit_common.h"
+
+void ft_unit_usage(char *name, char *desc)
+{
+	fprintf(stderr, "Usage:\n");
+	fprintf(stderr, "  %s [OPTIONS]\n", name);
+
+	if (desc)
+		fprintf(stderr, "\n%s\n", desc);
+
+	fprintf(stderr, "\nOptions:\n");
+	FT_PRINT_OPTS_USAGE("-f <fabric_name>", "specific fabric to use");
+	FT_PRINT_OPTS_USAGE("-d <domain>", "domain name");
+	FT_PRINT_OPTS_USAGE("-p <provider_name>", "specific provider name eg sockets, verbs");
+	FT_PRINT_OPTS_USAGE("-h", "display this help output");
+}
+
+int
+run_tests(struct test_entry *test_array, char *err_buf)
+{
+	int ret;
+	struct test_entry *tep;
+	int failed;
+
+	failed = 0;
+
+	tep = test_array;
+	while (tep->test != NULL) {
+		printf("Running %s [%s]...", tep->name, tep->desc);
+		fflush(stdout);
+		ret = tep->test();
+		switch (ret) {
+		case PASS:
+			printf("PASS!\n");
+			break;
+		case FAIL:
+			printf("FAIL: %s\n", err_buf);
+			failed++;
+			break;
+		case SKIPPED:
+			printf("skipped because: %s\n", err_buf);
+			break;
+		case NOTSUPP:
+			printf("requires unsupported feature: %s\n", err_buf);
+			break;
+		default:
+			printf("FATAL: unexpected code: %d\n", ret);
+			return failed + 1;
+			break;
+		}
+
+		++tep;
+	}
+
+	return failed;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/cq_test.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/cq_test.c
new file mode 100644
index 000000000..03685a212
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/cq_test.c
@@ -0,0 +1,261 @@
+/*
+ * Copyright (c) 2013-2016 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <string.h>
+
+#include <rdma/fi_errno.h>
+
+#include "unit_common.h"
+#include "shared.h"
+
+static char err_buf[512];
+
+static int
+create_cq(struct fid_cq **cq, size_t size, uint64_t flags,
+		enum fi_cq_format format, enum fi_wait_obj wait_obj)
+{
+	struct fi_cq_attr cq_attr;
+
+	memset(&cq_attr, 0, sizeof(cq_attr));
+	cq_attr.size = size;
+	cq_attr.flags = flags;
+	cq_attr.format = format;
+	cq_attr.wait_obj = wait_obj;
+
+	return fi_cq_open(domain, &cq_attr, cq, NULL);
+}
+
+/* Try opening fi->domain_attr->cq_cnt number of completion queues
+ * simultaneously using a size hint of 0 (indicating the provider should choose
+ * the size)
+ */
+static int cq_open_close_simultaneous(void)
+{
+	int ret;
+	int opened;
+	size_t count;
+	int testret = FAIL;
+	struct fid_cq **cq_array;
+
+	count = fi->domain_attr->cq_cnt;
+	FT_DEBUG("testing creation of up to %zu simultaneous CQs\n", count);
+
+	cq_array = calloc(count, sizeof(*cq_array));
+	if (!cq_array)
+		return -FI_ENOMEM;
+
+	ret = 0;
+	for (opened = 0; opened < count && !ret; opened++) {
+		ret = create_cq(&cq_array[opened], 0, 0, FI_CQ_FORMAT_UNSPEC,
+				FI_WAIT_UNSPEC);
+	}
+	if (ret) {
+		FT_WARN("fi_cq_open failed after %d (cq_cnt: %zu): %s",
+			opened, count, fi_strerror(-ret));
+	}
+
+	testret = PASS;
+
+	FT_CLOSEV_FID(cq_array, opened);
+	free(cq_array);
+
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - test open and close of CQ over a range of sizes
+ */
+static int
+cq_open_close_sizes()
+{
+	int i;
+	int ret;
+	int size;
+	int testret;
+	struct fid_cq *cq;
+
+	testret = FAIL;
+
+	for (i = -1; i < 17; ++i) {
+		size = (i < 0) ? 0 : 1 << i;
+
+		ret = create_cq(&cq, size, 0, FI_CQ_FORMAT_UNSPEC, FI_WAIT_UNSPEC);
+		if (ret == -FI_EINVAL) {
+			FT_WARN("\nSuccessfully completed %d iterations up to "
+				"size %d before the provider returned "
+				"EINVAL...",
+				i + 1, size >> 1);
+			ret = 0;
+			goto pass;
+		}
+		if (ret != 0) {
+			sprintf(err_buf, "fi_cq_open(%d, 0, FI_CQ_FORMAT_UNSPEC, "
+					"FI_WAIT_UNSPEC) = %d, %s",
+					size, ret, fi_strerror(-ret));
+			goto fail;
+		}
+
+		ret = fi_close(&cq->fid);
+		if (ret != 0) {
+			sprintf(err_buf, "close(cq) = %d, %s", ret, fi_strerror(-ret));
+			goto fail;
+		}
+		cq = NULL;
+	}
+
+pass:
+	testret = PASS;
+fail:
+	cq = NULL;
+	return TEST_RET_VAL(ret, testret);
+}
+
+static int
+cq_signal()
+{
+	struct fid_cq *cq;
+	struct fi_cq_tagged_entry entry;
+	int64_t elapsed;
+	int testret;
+	int ret;
+
+	testret = FAIL;
+
+	ret = create_cq(&cq, 1, 0, FI_CQ_FORMAT_UNSPEC, FI_WAIT_UNSPEC);
+	if (ret) {
+		sprintf(err_buf, "fi_cq_open(1, 0, FI_CQ_FORMAT_UNSPEC, "
+				"FI_WAIT_UNSPEC) = %d, %s",
+				ret, fi_strerror(-ret));
+		goto fail1;
+	}
+
+	ret = fi_cq_signal(cq);
+	if (ret) {
+		sprintf(err_buf, "fi_cq_signal = %d %s", ret, fi_strerror(-ret));
+		goto fail2;
+	}
+
+	ft_start();
+	ret = fi_cq_sread(cq, &entry, 1, NULL, 2000);
+	ft_stop();
+	elapsed = get_elapsed(&start, &end, MILLI);
+	if (ret != -FI_EAGAIN && ret != -FI_ECANCELED) {
+		sprintf(err_buf, "fi_cq_sread = %d %s", ret, fi_strerror(-ret));
+		goto fail2;
+	}
+
+	if (elapsed > 1000) {
+		sprintf(err_buf, "fi_cq_sread - signal ignored");
+		goto fail2;
+	}
+
+	ret = fi_close(&cq->fid);
+	if (ret) {
+		sprintf(err_buf, "close(cq) = %d, %s", ret, fi_strerror(-ret));
+		goto fail1;
+	}
+	cq = NULL;
+
+	testret = PASS;
+fail2:
+	FT_CLOSE_FID(cq);
+fail1:
+	cq = NULL;
+	return TEST_RET_VAL(ret, testret);
+}
+
+
+struct test_entry test_array[] = {
+	TEST_ENTRY(cq_open_close_sizes, "Test open and close of CQ for various sizes"),
+	TEST_ENTRY(cq_open_close_simultaneous, "Test opening several CQs at a time"),
+	TEST_ENTRY(cq_signal, "Test fi_cq_signal"),
+	{ NULL, "" }
+};
+
+static void usage(void)
+{
+	ft_unit_usage("cq_test", "Unit test for Completion Queue (CQ)");
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+	int failed;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, FAB_OPTS "h")) != -1) {
+		switch (op) {
+		default:
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	hints->mode = ~0;
+	hints->domain_attr->mode = ~0;
+	hints->domain_attr->mr_mode = ~(FI_MR_BASIC | FI_MR_SCALABLE);
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, 0, 0, hints, &fi);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		goto err;
+	}
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		goto err;
+
+	printf("Testing CQs on fabric %s\n", fi->fabric_attr->name);
+
+	failed = run_tests(test_array, err_buf);
+	if (failed > 0) {
+		printf("Summary: %d tests failed\n", failed);
+	} else {
+		printf("Summary: all tests passed\n");
+	}
+
+err:
+	ft_free_res();
+	return ret ? ft_exit_code(ret) : (failed > 0) ? EXIT_FAILURE : EXIT_SUCCESS;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/dom_test.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/dom_test.c
new file mode 100644
index 000000000..65379978d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/dom_test.c
@@ -0,0 +1,134 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <limits.h>
+
+#include <rdma/fi_errno.h>
+
+#include "shared.h"
+#include "unit_common.h"
+
+#define MAX_ADDR 256
+
+static struct fid_domain **domain_vec = NULL;
+
+/*
+ * Tests:
+ * - test open and close of a domain
+ */
+
+static void usage(void)
+{
+	ft_unit_usage("dom_test", "Unit test for Domain");
+	FT_PRINT_OPTS_USAGE("-n <num_domains>", "num domains to open");
+}
+
+int main(int argc, char **argv)
+{
+	unsigned long i;
+	int op, ret = 0;
+	unsigned long num_domains = 1;
+	char *ptr;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, FAB_OPTS "n:h")) != -1) {
+		switch (op) {
+		case 'n':
+			errno = 0;
+			num_domains = strtol(optarg, &ptr, 10);
+			if (ptr == optarg || *ptr != '\0' ||
+				((num_domains == LONG_MIN || num_domains == LONG_MAX) && errno == ERANGE)) {
+				fprintf(stderr, "Cannot convert from string to long\n");
+				goto out;
+			}
+			break;
+		default:
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	hints->mode = ~0;
+	hints->domain_attr->mode = ~0;
+	hints->domain_attr->mr_mode = ~(FI_MR_BASIC | FI_MR_SCALABLE);
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, 0, 0, hints, &fi);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		goto out;
+	}
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		goto out;
+
+	domain_vec = calloc(num_domains, sizeof(*domain_vec));
+	if (domain_vec == NULL) {
+		perror("malloc");
+		ret = EXIT_FAILURE;
+		goto out;
+	}
+
+	/* Common code will open one domain */
+	for (i = 1; i < num_domains; i++) {
+		ret = fi_domain(fabric, fi, &domain_vec[i], NULL);
+		if (ret != FI_SUCCESS) {
+			printf("fi_domain num %lu %s\n", i, fi_strerror(-ret));
+			break;
+		}
+	}
+
+	while (--i > 0) {
+		ret = fi_close(&domain_vec[i]->fid);
+		if (ret != FI_SUCCESS) {
+			printf("Error %d closing domain num %lu: %s\n", ret,
+				i, fi_strerror(-ret));
+			break;
+		}
+	}
+
+	free(domain_vec);
+out:
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/eq_test.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/eq_test.c
new file mode 100644
index 000000000..f578d9fb3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/eq_test.c
@@ -0,0 +1,644 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <getopt.h>
+#include <poll.h>
+#include <string.h>
+
+#include <rdma/fi_errno.h>
+
+#include "unit_common.h"
+#include "shared.h"
+
+static char err_buf[512];
+
+static int
+create_eq(size_t size, uint64_t flags, enum fi_wait_obj wait_obj)
+{
+	struct fi_eq_attr eq_attr;
+
+	memset(&eq_attr, 0, sizeof(eq_attr));
+	eq_attr.size = size;
+	eq_attr.flags = flags;
+	eq_attr.wait_obj = wait_obj;
+
+	return fi_eq_open(fabric, &eq_attr, &eq, NULL);
+}
+
+/*
+ * Tests:
+ * - test open and close of EQ over a range of sizes
+ */
+static int
+eq_open_close()
+{
+	int i;
+	int ret;
+	int size;
+	int testret;
+
+	testret = FAIL;
+
+	for (i = 0; i < 17; ++i) {
+		size = 1 << i;
+		ret = create_eq(size, 0, FI_WAIT_UNSPEC);
+		if (ret != 0) {
+			sprintf(err_buf, "fi_eq_open(%d, 0, FI_WAIT_UNSPEC) = %d, %s",
+					size, ret, fi_strerror(-ret));
+			goto fail;
+		}
+
+		ret = fi_close(&eq->fid);
+		if (ret != 0) {
+			sprintf(err_buf, "close(eq) = %d, %s", ret, fi_strerror(-ret));
+			goto fail;
+		}
+		eq = NULL;
+	}
+	testret = PASS;
+
+fail:
+	eq = NULL;
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - writing to EQ
+ * - reading from EQ with and without FI_PEEK
+ * - underflow read
+ */
+static int
+eq_write_read_self()
+{
+	struct fi_eq_entry entry;
+	uint32_t event;
+	int testret;
+	int ret;
+	int i;
+
+	testret = FAIL;
+
+	ret = create_eq(32, FI_WRITE, FI_WAIT_NONE);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_eq_open ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	/* Insert some events */
+	for (i = 0; i < 5; ++i) {
+		if (i & 1) {
+			entry.fid = &fabric->fid;
+		} else {
+			entry.fid = &eq->fid;
+		}
+		entry.context = (void *)(uintptr_t)i;
+		ret = fi_eq_write(eq, FI_NOTIFY, &entry, sizeof(entry), 0);
+		if (ret != sizeof(entry)) {
+			sprintf(err_buf, "fi_eq_write ret=%d, %s", ret, fi_strerror(-ret));
+			goto fail;
+		}
+	}
+
+	/* Now read them back, peeking first at each one */
+	for (i = 0; i < 10; ++i) {
+		event = ~0;
+		memset(&entry, 0, sizeof(entry));
+		ret = fi_eq_read(eq, &event, &entry, sizeof(entry),
+				(i & 1) ? 0 : FI_PEEK);
+		if (ret != sizeof(entry)) {
+			sprintf(err_buf, "fi_eq_read ret=%d, %s", ret, fi_strerror(-ret));
+			goto fail;
+		}
+
+		if (event != FI_NOTIFY) {
+			sprintf(err_buf, "iter %d: event = %d, should be %d\n", i, event,
+					FI_NOTIFY);
+			goto fail;
+		}
+
+		if ((int)(uintptr_t)entry.context != i / 2) {
+			sprintf(err_buf, "iter %d: context mismatch %d != %d", i,
+					(int)(uintptr_t)entry.context, i / 2);
+			goto fail;
+		}
+
+		if (entry.fid != ((i & 2) ? &fabric->fid : &eq->fid)) {
+			sprintf(err_buf, "iter %d: fid mismatch %p != %p", i,
+					entry.fid, ((i & 2) ? &fabric->fid : &eq->fid));
+			goto fail;
+		}
+	}
+
+	/* queue is now empty */
+	ret = fi_eq_read(eq, &event, &entry, sizeof(entry), 0);
+	if (ret != -FI_EAGAIN) {
+		sprintf(err_buf, "fi_eq_read of empty EQ returned %d", ret);
+		goto fail;
+	}
+	testret = PASS;
+
+fail:
+	FT_CLOSE_FID(eq);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - eq size test
+ */
+static int
+eq_size_verify()
+{
+	struct fi_eq_entry entry;
+	int testret;
+	int ret;
+	int i;
+
+	testret = FAIL;
+
+	ret = create_eq(32, FI_WRITE, FI_WAIT_NONE);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_eq_open ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	/* Insert some events */
+	for (i = 0; i < 32; ++i) {
+		entry.fid = &fabric->fid;
+		entry.context = (void *)(uintptr_t)i;
+		ret = fi_eq_write(eq, FI_NOTIFY, &entry, sizeof(entry), 0);
+		if (ret != sizeof(entry)) {
+			sprintf(err_buf, "fi_eq_write ret=%d, %s", ret, fi_strerror(-ret));
+			goto fail;
+		}
+	}
+
+	testret = PASS;
+
+fail:
+	FT_CLOSE_FID(eq);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - extracting FD from EQ with FI_WAIT_FD
+ * - wait on fd with nothing pending
+ * - wait on fd with event pending
+ */
+static int
+eq_wait_fd_poll()
+{
+	int fd;
+	struct fi_eq_entry entry;
+	struct pollfd pfd;
+	struct fid *fids[1];
+	int testret;
+	int ret;
+
+	testret = FAIL;
+
+	ret = create_eq(32, FI_WRITE, FI_WAIT_FD);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_eq_open ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	ret = fi_control(&eq->fid, FI_GETWAIT, &fd);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_control ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	fids[0] = &eq->fid;
+	if (fi_trywait(fabric, fids, 1) != FI_SUCCESS) {
+		sprintf(err_buf, "fi_trywait ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	pfd.fd = fd;
+	pfd.events = POLLIN;
+	ret = poll(&pfd, 1, 0);
+	if (ret < 0) {
+		sprintf(err_buf, "poll errno=%d, %s", errno, fi_strerror(-errno));
+		goto fail;
+	}
+	if (ret > 0) {
+		sprintf(err_buf, "poll returned %d, should be 0", ret);
+		goto fail;
+	}
+
+	/* write an event */
+	entry.fid = &eq->fid;
+	entry.context = eq;
+	ret = fi_eq_write(eq, FI_NOTIFY, &entry, sizeof(entry), 0);
+	if (ret != sizeof(entry)) {
+		sprintf(err_buf, "fi_eq_write ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	pfd.fd = fd;
+	pfd.events = POLLIN;
+	ret = poll(&pfd, 1, 0);
+	if (ret < 0) {
+		sprintf(err_buf, "poll errno=%d, %s", errno, fi_strerror(-errno));
+		goto fail;
+	}
+	if (ret != 1) {
+		sprintf(err_buf, "poll returned %d, should be 1", ret);
+		goto fail;
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(eq);
+	return TEST_RET_VAL(ret, testret);
+}
+
+static int insert_events(size_t count)
+{
+	struct fi_eq_entry entry;
+	size_t i;
+	int ret;
+
+	for (i = 0; i < count; i++) {
+		ret = fi_eq_write(eq, FI_NOTIFY, &entry, sizeof(entry), 0);
+		if (ret != sizeof(entry)) {
+			sprintf(err_buf, "fi_eq_write ret=%d, %s", ret,
+					fi_strerror(-ret));
+			return ret;
+		}
+	}
+
+	return FI_SUCCESS;
+}
+
+static int read_events(size_t count, uint64_t flags)
+{
+	struct fi_eq_entry entry;
+	uint32_t event;
+	size_t i;
+	int ret;
+
+	for (i = 0; i < count; i++) {
+		memset(&entry, 0, sizeof(entry));
+		event = 0;
+
+		ret = fi_eq_read(eq, &event, &entry, sizeof(entry), flags);
+		if (ret != sizeof(entry)) {
+			sprintf(err_buf, "fi_eq_read ret=%d, %s", ret,
+					fi_strerror(-ret));
+			return ret;
+		}
+
+		if (event != FI_NOTIFY) {
+			sprintf(err_buf, "iter %zu: event = %d, should be %d\n",
+					i, event, FI_NOTIFY);
+			return -FI_EOTHER;
+		}
+	}
+
+	return FI_SUCCESS;
+}
+
+static int sread_event(int timeout, uint64_t flags)
+{
+	struct fi_eq_entry entry;
+	int64_t elapsed;
+	uint32_t event;
+	int ret;
+
+	ft_start();
+	ret = fi_eq_sread(eq, &event, &entry, sizeof(entry), timeout, flags);
+	ft_stop();
+	if (ret != sizeof(entry)) {
+		sprintf(err_buf, "fi_eq_sread returned %d, %s", ret,
+				fi_strerror(-ret));
+		return ret;
+	}
+
+	/* check timeout accuracy */
+	elapsed = get_elapsed(&start, &end, MILLI);
+	if (elapsed > (int) (timeout * 1.25)) {
+		sprintf(err_buf, "fi_eq_sread slept %d ms, expected %d",
+				(int) elapsed, timeout);
+		return -FI_EOTHER;
+	}
+
+	return FI_SUCCESS;
+}
+
+/* Make sure the peeking works fine on normal read. */
+static int eq_wait_read_peek(void)
+{
+	int testret;
+	int ret;
+
+	testret = FAIL;
+
+	ret = create_eq(32, FI_WRITE, FI_WAIT_NONE);
+	if (ret) {
+		sprintf(err_buf, "fi_eq_open ret=%d, %s", ret,
+				fi_strerror(-ret));
+		goto fail;
+	}
+
+	ret = insert_events(5);
+	if (ret)
+		goto fail;
+
+	ret = read_events(5, FI_PEEK);
+	if (ret)
+		goto fail;
+
+	ret = read_events(5, 0);
+	if (ret)
+		goto fail;
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(eq);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/* Check that the peeking doesn't affect the waiting. If the peek invalidly
+ * clears the FD, then this will fail.
+ */
+static int eq_wait_sread_peek(void)
+{
+	int testret;
+	int ret;
+
+	testret = FAIL;
+
+	ret = create_eq(32, FI_WRITE, FI_WAIT_FD);
+	if (ret) {
+		sprintf(err_buf, "fi_eq_open ret=%d, %s", ret,
+				fi_strerror(-ret));
+		goto fail;
+	}
+
+	/* Write an event */
+	ret = insert_events(1);
+	if (ret)
+		goto fail;
+
+	/* Make sure we can read the event */
+	ret = sread_event(2000, 0);
+	if (ret)
+		goto fail;
+
+	/* Write another event */
+	ret = insert_events(1);
+	if (ret)
+		goto fail;
+
+	/* Peek at the event */
+	ret = sread_event(2000, FI_PEEK);
+	if (ret)
+		goto fail;
+
+	/* Make sure the event is still available for reading */
+	ret = sread_event(2000, 0);
+	if (ret)
+		goto fail;
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(eq);
+	return TEST_RET_VAL(ret, testret);
+}
+
+/*
+ * Tests:
+ * - sread with event pending
+ * - sread with no event pending
+ */
+static int
+eq_wait_fd_sread()
+{
+	struct fi_eq_entry entry;
+	uint32_t event;
+	int64_t elapsed;
+	int testret;
+	int ret;
+
+	testret = FAIL;
+
+	ret = create_eq(32, FI_WRITE, FI_WAIT_FD);
+	if (ret != 0) {
+		sprintf(err_buf, "fi_eq_open ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	/* timed sread on empty EQ, 2s timeout */
+	ft_start();
+	ret = fi_eq_sread(eq, &event, &entry, sizeof(entry), 2000, 0);
+	ft_stop();
+	if (ret != -FI_EAGAIN) {
+		sprintf(err_buf, "fi_eq_read of empty EQ returned %d", ret);
+		goto fail;
+	}
+
+	/* check timeout accuracy */
+	elapsed = get_elapsed(&start, &end, MILLI);
+	if (elapsed < 1500 || elapsed > 2500) {
+		sprintf(err_buf, "fi_eq_sread slept %d ms, expected 2000",
+				(int)elapsed);
+		goto fail;
+	}
+
+	/* write an event */
+	entry.fid = &eq->fid;
+	entry.context = eq;
+	ret = fi_eq_write(eq, FI_NOTIFY, &entry, sizeof(entry), 0);
+	if (ret != sizeof(entry)) {
+		sprintf(err_buf, "fi_eq_write ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	event = ~0;
+	memset(&entry, 0, sizeof(entry));
+	/* timed sread on EQ with event, 2s timeout */
+	ft_start();
+	ret = fi_eq_sread(eq, &event, &entry, sizeof(entry), 2000, 0);
+	ft_stop();
+	if (ret != sizeof(entry)) {
+		sprintf(err_buf, "fi_eq_read ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	/* check that no undue waiting occurred */
+	elapsed = get_elapsed(&start, &end, MILLI);
+	if (elapsed > 5) {
+		sprintf(err_buf, "fi_eq_sread slept %d ms, expected immediate return",
+				(int)elapsed);
+		goto fail;
+	}
+
+	if (event != FI_NOTIFY) {
+		sprintf(err_buf, "fi_eq_sread: event = %d, should be %d\n", event,
+				FI_NOTIFY);
+		goto fail;
+	}
+	if (entry.fid != &eq->fid) {
+		sprintf(err_buf, "fi_eq_sread: fid mismatch: %p should be %p\n",
+				entry.fid, &eq->fid);
+		goto fail;
+	}
+	if (entry.context != eq) {
+		sprintf(err_buf, "fi_eq_sread: context mismatch: %p should be %p\n",
+				entry.context, eq);
+		goto fail;
+	}
+
+	testret = PASS;
+fail:
+	FT_CLOSE_FID(eq);
+	return TEST_RET_VAL(ret, testret);
+}
+
+static int
+eq_readerr_ret_eagain()
+{
+	int testret;
+	int ret;
+	struct fi_eq_err_entry err_entry;
+
+	testret = FAIL;
+
+	memset(&err_entry, 0, sizeof(err_entry));
+
+	/* create EQ  */
+	ret = create_eq(32, FI_WRITE, FI_WAIT_UNSPEC);
+	if (ret) {
+		sprintf(err_buf, "fi_eq_open ret=%d, %s", ret, fi_strerror(-ret));
+		goto fail;
+	}
+
+	ret = insert_events(5);
+	if (ret)
+		goto fail;
+
+	ret = read_events(5, 0);
+	if (ret)
+		goto fail;
+
+	/* Error handling  */
+	ret = fi_eq_readerr(eq, &err_entry, 0);
+	if (ret == -FI_EAGAIN)
+		testret = PASS;
+	else
+		sprintf(err_buf, ", fi_eq_readerr returned: %d: %s, ", ret,
+				fi_eq_strerror(eq, err_entry.prov_errno, err_entry.err_data, NULL, 0));
+
+fail:
+	FT_CLOSE_FID(eq);
+	return TEST_RET_VAL(ret, testret);
+}
+
+struct test_entry test_array[] = {
+	TEST_ENTRY(eq_open_close, "Test open and close of EQ for various sizes"),
+	TEST_ENTRY(eq_write_read_self, "Test writing and reading to EQ"),
+	TEST_ENTRY(eq_size_verify, "Test EQ supports writing # of entries = size"),
+	TEST_ENTRY(eq_wait_fd_poll, "Test polling on fd extracted from EQ"),
+	TEST_ENTRY(eq_wait_fd_sread, "Test EQ sread"),
+	TEST_ENTRY(eq_wait_read_peek, "Test EQ read with FI_PEEK"),
+	TEST_ENTRY(eq_wait_sread_peek, "Test EQ sread with FI_PEEK"),
+	TEST_ENTRY(eq_readerr_ret_eagain, "Test EQ readerr with FI_EAGAIN"),
+	{ NULL, "" }
+};
+
+static void usage(void)
+{
+	ft_unit_usage("eq_test", "Unit test for Event Queue (EQ)");
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+	int failed;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, FAB_OPTS "h")) != -1) {
+		switch (op) {
+		default:
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	hints->mode = FI_CONTEXT | FI_CONTEXT2 | FI_MSG_PREFIX | FI_ASYNC_IOV |
+		FI_RX_CQ_DATA | FI_NOTIFY_FLAGS_ONLY | FI_RESTRICTED_COMP |
+		FI_BUFFERED_RECV;
+	hints->domain_attr->mode = FI_RESTRICTED_COMP;
+	hints->domain_attr->mr_mode = FI_MR_LOCAL| FI_MR_RAW | FI_MR_VIRT_ADDR |
+		FI_MR_ALLOCATED | FI_MR_PROV_KEY | FI_MR_MMU_NOTIFY |
+		FI_MR_RMA_EVENT | FI_MR_ENDPOINT;
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, 0, 0, hints, &fi);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		goto err;
+	}
+
+	ret = fi_fabric(fi->fabric_attr, &fabric, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		goto err;
+	}
+
+	printf("Testing EQs on fabric %s\n", fi->fabric_attr->name);
+
+	failed = run_tests(test_array, err_buf);
+	if (failed > 0) {
+		printf("Summary: %d tests failed\n", failed);
+	} else {
+		printf("Summary: all tests passed\n");
+	}
+
+err:
+	ft_free_res();
+	return ret ? ft_exit_code(ret) : (failed > 0) ? EXIT_FAILURE : EXIT_SUCCESS;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/getinfo_test.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/getinfo_test.c
new file mode 100644
index 000000000..1120a8bd3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/getinfo_test.c
@@ -0,0 +1,805 @@
+/*
+ * Copyright (c) 2013-2015 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2017 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *	- Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *	- Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+#include <string.h>
+
+#include <rdma/fi_errno.h>
+
+#include "shared.h"
+#include "unit_common.h"
+
+#define TEST_ENTRY_GETINFO(name) TEST_ENTRY(getinfo_ ## name,\
+					    getinfo_ ## name ## _desc)
+
+typedef int (*ft_getinfo_init)(struct fi_info *);
+typedef int (*ft_getinfo_test)(char *, char *, uint64_t, struct fi_info *, struct fi_info **);
+typedef int (*ft_getinfo_check)(struct fi_info *);
+
+static char err_buf[512];
+static char new_prov_var[128];
+
+
+static int check_addr(void *addr, size_t addrlen, char *str)
+{
+	if (!addrlen) {
+		sprintf(err_buf, "%s addrlen not set", str);
+		return EXIT_FAILURE;
+	}
+	if (!addr) {
+		sprintf(err_buf, "%s address not set", str);
+		return EXIT_FAILURE;
+	}
+	return 0;
+}
+
+static int check_srcaddr(struct fi_info *info)
+{
+	return check_addr(info->src_addr, info->src_addrlen, "source");
+}
+
+static int check_src_dest_addr(struct fi_info *info)
+{
+	int ret;
+
+	ret = check_addr(info->src_addr, info->src_addrlen, "source");
+	if (ret)
+		return ret;
+
+	return check_addr(info->dest_addr, info->dest_addrlen, "destination");
+}
+
+static int check_util_prov(struct fi_info *info)
+{
+	const char *util_name;
+	size_t len;
+
+	util_name = ft_util_name(info->fabric_attr->prov_name, &len);
+	if (!util_name) {
+		sprintf(err_buf, "Util provider name not appended to core "
+			"provider name: %s", info->fabric_attr->prov_name);
+		return EXIT_FAILURE;
+	}
+	return 0;
+}
+
+static int check_api_version(struct fi_info *info)
+{
+	return info->fabric_attr->api_version != FT_FIVERSION;
+}
+
+static int invalid_dom(struct fi_info *hints)
+{
+	if (hints->domain_attr->name)
+		free(hints->domain_attr->name);
+	hints->domain_attr->name = strdup("invalid_domain");
+	if (!hints->domain_attr->name)
+		return -FI_ENOMEM;
+	return 0;
+}
+
+static int validate_msg_ordering_bits(char *node, char *service, uint64_t flags,
+		struct fi_info *hints, struct fi_info **info)
+{
+	int i, ret;
+	uint64_t ordering_bits = (FI_ORDER_STRICT | FI_ORDER_DATA);
+	uint64_t *msg_order_combinations;
+	int cnt;
+
+	ret = ft_alloc_bit_combo(0, ordering_bits, &msg_order_combinations, &cnt);
+	if (ret) {
+		FT_UNIT_STRERR(err_buf, "ft_alloc_bit_combo failed", ret);
+		return ret;
+	}
+
+	/* test for what ordering support exists on this provider */
+	/* test ordering support in TX ATTRIBUTE */
+	for (i = 0; i < cnt; i++) {
+		hints->tx_attr->msg_order = msg_order_combinations[i];
+		ret = fi_getinfo(FT_FIVERSION, node, service, flags, hints, info);
+		if (ret) {
+			if (ret == -FI_ENODATA)
+				continue;
+			FT_UNIT_STRERR(err_buf, "fi_getinfo failed", ret);
+			goto failed_getinfo;
+		}
+
+		ft_foreach_info(fi, *info) {
+			FT_DEBUG("\nTesting for fabric: %s, domain: %s, endpoint type: %d",
+					fi->fabric_attr->name, fi->domain_attr->name,
+					fi->ep_attr->type);
+			if (hints->tx_attr->msg_order) {
+				if ((fi->tx_attr->msg_order & hints->tx_attr->msg_order) !=
+				    hints->tx_attr->msg_order) {
+					FT_DEBUG("tx msg_order not matching - hints: %"
+						 PRIx64 " prov: %" PRIx64 "\n",
+						 hints->tx_attr->msg_order,
+						 fi->tx_attr->msg_order);
+					ret = -FI_EOTHER;
+					fi_freeinfo(*info);
+					goto failed_getinfo;
+				}
+			}
+		}
+		fi_freeinfo(*info);
+	}
+
+	/* test ordering support in RX ATTRIBUTE */
+	for (i = 0; i < cnt; i++) {
+		hints->tx_attr->msg_order = 0;
+		hints->rx_attr->msg_order = msg_order_combinations[i];
+		ret = fi_getinfo(FT_FIVERSION, node, service, flags, hints, info);
+		if (ret) {
+			if (ret == -FI_ENODATA)
+				continue;
+			FT_UNIT_STRERR(err_buf, "fi_getinfo failed", ret);
+			goto failed_getinfo;
+		}
+		ft_foreach_info(fi, *info) {
+			FT_DEBUG("\nTesting for fabric: %s, domain: %s, endpoint type: %d",
+					fi->fabric_attr->name, fi->domain_attr->name,
+					fi->ep_attr->type);
+			if (hints->rx_attr->msg_order) {
+				if ((fi->rx_attr->msg_order & hints->rx_attr->msg_order) !=
+				    hints->rx_attr->msg_order) {
+					FT_DEBUG("rx msg_order not matching - hints: %"
+						 PRIx64 " prov: %" PRIx64 "\n",
+						 hints->rx_attr->msg_order,
+						 fi->rx_attr->msg_order);
+					ret = -FI_EOTHER;
+					fi_freeinfo(*info);
+					goto failed_getinfo;
+				}
+			}
+		}
+		fi_freeinfo(*info);
+	}
+
+	*info = NULL;
+	ft_free_bit_combo(msg_order_combinations);
+	return 0;
+
+failed_getinfo:
+	*info = NULL;
+	ft_free_bit_combo(msg_order_combinations);
+	return ret;
+}
+
+static int init_valid_rma_RAW_ordering_no_set_size(struct fi_info *hints)
+{
+	hints->caps = FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_RAW;
+	hints->rx_attr->msg_order = FI_ORDER_RAW;
+	hints->ep_attr->max_order_raw_size = 0;
+
+	return 0;
+}
+
+static int init_valid_rma_RAW_ordering_set_size(struct fi_info *hints)
+{
+	int ret;
+	struct fi_info *fi;
+
+	hints->caps = FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_RAW;
+	hints->rx_attr->msg_order = FI_ORDER_RAW;
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, NULL, 0, hints, &fi);
+	if (ret) {
+		sprintf(err_buf, "fi_getinfo failed %s(%d)", fi_strerror(-ret), -ret);
+		return ret;
+	}
+	if (fi->ep_attr->max_order_raw_size > 0)
+		hints->ep_attr->max_order_raw_size = fi->ep_attr->max_order_raw_size - 1;
+
+	fi_freeinfo(fi);
+
+	return 0;
+}
+
+static int init_valid_rma_WAR_ordering_no_set_size(struct fi_info *hints)
+{
+	hints->caps = FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_WAR;
+	hints->rx_attr->msg_order = FI_ORDER_WAR;
+	hints->ep_attr->max_order_war_size = 0;
+
+	return 0;
+}
+
+static int init_valid_rma_WAR_ordering_set_size(struct fi_info *hints)
+{
+	int ret;
+	struct fi_info *fi;
+
+	hints->caps = FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_WAR;
+	hints->rx_attr->msg_order = FI_ORDER_WAR;
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, NULL, 0, hints, &fi);
+	if (ret) {
+		sprintf(err_buf, "fi_getinfo failed %s(%d)", fi_strerror(-ret), -ret);
+		return ret;
+	}
+	if (fi->ep_attr->max_order_war_size > 0)
+		hints->ep_attr->max_order_war_size = fi->ep_attr->max_order_war_size - 1;
+
+	fi_freeinfo(fi);
+
+	return 0;
+}
+
+static int init_valid_rma_WAW_ordering_no_set_size(struct fi_info *hints)
+{
+	hints->caps = FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_WAW;
+	hints->rx_attr->msg_order = FI_ORDER_WAW;
+	hints->ep_attr->max_order_waw_size = 0;
+
+	return 0;
+}
+
+static int init_valid_rma_WAW_ordering_set_size(struct fi_info *hints)
+{
+	int ret;
+	struct fi_info *fi;
+
+	hints->caps = FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_WAW;
+	hints->rx_attr->msg_order = FI_ORDER_WAW;
+	ret = fi_getinfo(FT_FIVERSION, NULL, NULL, 0, hints, &fi);
+	if (ret) {
+		sprintf(err_buf, "fi_getinfo failed %s(%d)", fi_strerror(-ret), -ret);
+		return ret;
+	}
+	if (fi->ep_attr->max_order_waw_size > 0)
+		hints->ep_attr->max_order_waw_size = fi->ep_attr->max_order_waw_size - 1;
+
+	fi_freeinfo(fi);
+
+	return 0;
+}
+
+static int check_valid_rma_ordering_sizes(struct fi_info *info)
+{
+	if ((info->tx_attr->msg_order & FI_ORDER_RAW) ||
+			(info->rx_attr->msg_order & FI_ORDER_RAW)) {
+		if (info->ep_attr->max_order_raw_size <= 0)
+			return EXIT_FAILURE;
+		if (hints->ep_attr->max_order_raw_size) {
+			if (info->ep_attr->max_order_raw_size < hints->ep_attr->max_order_raw_size)
+				return EXIT_FAILURE;
+		}
+	}
+	if ((info->tx_attr->msg_order & FI_ORDER_WAR) ||
+			(info->rx_attr->msg_order & FI_ORDER_WAR)) {
+		if (info->ep_attr->max_order_war_size <= 0)
+			return EXIT_FAILURE;
+		if (hints->ep_attr->max_order_war_size) {
+			if (info->ep_attr->max_order_war_size < hints->ep_attr->max_order_war_size)
+				return EXIT_FAILURE;
+		}
+	}
+	if ((info->tx_attr->msg_order & FI_ORDER_WAW) ||
+			(info->rx_attr->msg_order & FI_ORDER_WAW)) {
+		if (info->ep_attr->max_order_waw_size <= 0)
+			return EXIT_FAILURE;
+		if (hints->ep_attr->max_order_waw_size) {
+			if (info->ep_attr->max_order_waw_size < hints->ep_attr->max_order_waw_size)
+				return EXIT_FAILURE;
+		}
+	}
+
+	return 0;
+}
+
+static int init_invalid_rma_RAW_ordering_size(struct fi_info *hints)
+{
+	int ret;
+	struct fi_info *fi;
+
+	hints->caps |= FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_RAW;
+	hints->rx_attr->msg_order = FI_ORDER_RAW;
+	hints->ep_attr->max_order_war_size = 0;
+	hints->ep_attr->max_order_waw_size = 0;
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, NULL, 0, hints, &fi);
+	if (ret) {
+		sprintf(err_buf, "fi_getinfo failed %s(%d)", fi_strerror(-ret), -ret);
+		return ret;
+	}
+
+	if (fi->ep_attr->max_order_raw_size)
+		hints->ep_attr->max_order_raw_size = fi->ep_attr->max_order_raw_size + 1;
+
+	fi_freeinfo(fi);
+
+	return 0;
+}
+
+static int init_invalid_rma_WAR_ordering_size(struct fi_info *hints)
+{
+	int ret;
+	struct fi_info *fi;
+
+	hints->caps |= FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_WAR;
+	hints->rx_attr->msg_order = FI_ORDER_WAR;
+	hints->ep_attr->max_order_raw_size = 0;
+	hints->ep_attr->max_order_waw_size = 0;
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, NULL, 0, hints, &fi);
+	if (ret) {
+		sprintf(err_buf, "fi_getinfo failed %s(%d)", fi_strerror(-ret), -ret);
+		return ret;
+	}
+
+	if (fi->ep_attr->max_order_war_size)
+		hints->ep_attr->max_order_war_size = fi->ep_attr->max_order_war_size + 1;
+
+	fi_freeinfo(fi);
+
+	return 0;
+}
+
+static int init_invalid_rma_WAW_ordering_size(struct fi_info *hints)
+{
+	int ret;
+	struct fi_info *fi;
+
+	hints->caps |= FI_RMA;
+	hints->tx_attr->msg_order = FI_ORDER_WAW;
+	hints->rx_attr->msg_order = FI_ORDER_WAW;
+	hints->ep_attr->max_order_raw_size = 0;
+	hints->ep_attr->max_order_war_size = 0;
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, NULL, 0, hints, &fi);
+	if (ret) {
+		sprintf(err_buf, "fi_getinfo failed %s(%d)", fi_strerror(-ret), -ret);
+		return ret;
+	}
+
+	if (fi->ep_attr->max_order_waw_size)
+		hints->ep_attr->max_order_waw_size = fi->ep_attr->max_order_waw_size + 1;
+
+	fi_freeinfo(fi);
+
+	return 0;
+}
+
+
+/*
+ * MR mode checks
+ */
+static int init_mr_basic(struct fi_info *hints)
+{
+	hints->caps |= FI_RMA;
+	hints->domain_attr->mr_mode = FI_MR_BASIC;
+	return 0;
+}
+
+static int check_mr_basic(struct fi_info *info)
+{
+	return (info->domain_attr->mr_mode != FI_MR_BASIC) ?
+		EXIT_FAILURE : 0;
+}
+
+static int init_mr_scalable(struct fi_info *hints)
+{
+	hints->caps |= FI_RMA;
+	hints->domain_attr->mr_mode = FI_MR_SCALABLE;
+	return 0;
+}
+
+static int check_mr_scalable(struct fi_info *info)
+{
+	return (info->domain_attr->mr_mode != FI_MR_SCALABLE) ?
+		EXIT_FAILURE : 0;
+}
+
+static int init_mr_unspec(struct fi_info *hints)
+{
+	hints->caps |= FI_RMA;
+	hints->domain_attr->mr_mode = FI_MR_UNSPEC;
+	return 0;
+}
+
+static int test_mr_v1_0(char *node, char *service, uint64_t flags,
+			struct fi_info *test_hints, struct fi_info **info)
+{
+	return fi_getinfo(FI_VERSION(1, 0), node, service, flags, test_hints, info);
+}
+
+static int check_mr_unspec(struct fi_info *info)
+{
+	return (info->domain_attr->mr_mode != FI_MR_BASIC &&
+		info->domain_attr->mr_mode != FI_MR_SCALABLE) ?
+		EXIT_FAILURE : 0;
+}
+
+static int test_mr_modes(char *node, char *service, uint64_t flags,
+			 struct fi_info *hints, struct fi_info **info)
+{
+	struct fi_info *fi;
+	uint64_t *mr_modes;
+	int i, cnt, ret;
+
+	ret = ft_alloc_bit_combo(0, FI_MR_LOCAL | FI_MR_RAW | FI_MR_VIRT_ADDR |
+			FI_MR_ALLOCATED | FI_MR_PROV_KEY | FI_MR_MMU_NOTIFY |
+			FI_MR_RMA_EVENT | FI_MR_ENDPOINT, &mr_modes, &cnt);
+	if (ret)
+		return ret;
+
+	for (i = 0; i < cnt; i++) {
+		hints->domain_attr->mr_mode = (uint32_t) mr_modes[i];
+		ret = fi_getinfo(FT_FIVERSION, node, service, flags, hints, info);
+		if (ret) {
+			if (ret == -FI_ENODATA)
+				continue;
+			FT_UNIT_STRERR(err_buf, "fi_getinfo failed", ret);
+			goto out;
+		}
+
+		ft_foreach_info(fi, *info) {
+			if (fi->domain_attr->mr_mode & ~hints->domain_attr->mr_mode) {
+				ret = -FI_EOTHER;
+				fi_freeinfo(*info);
+				goto out;
+			}
+		}
+		fi_freeinfo(*info);
+	}
+
+out:
+	*info = NULL;
+	ft_free_bit_combo(mr_modes);
+	return ret;
+}
+
+
+/*
+ * getinfo test
+ */
+static int getinfo_unit_test(char *node, char *service, uint64_t flags,
+		struct fi_info *base_hints, ft_getinfo_init init, ft_getinfo_test test,
+		ft_getinfo_check check, int ret_exp)
+{
+	struct fi_info *info, *fi, *test_hints;
+	int ret;
+
+	if (base_hints) {
+		test_hints = fi_dupinfo(base_hints);
+		if (!test_hints)
+			return -FI_ENOMEM;
+	} else {
+		test_hints = NULL;
+	}
+
+	if (init) {
+		ret = init(test_hints);
+		if (ret)
+			return ret;
+	}
+
+	if (test)
+		ret = test(node, service, flags, test_hints, &info);
+	else
+		ret = fi_getinfo(FT_FIVERSION, node, service, flags, test_hints, &info);
+	if (ret) {
+		if (ret == ret_exp)
+			return 0;
+		sprintf(err_buf, "fi_getinfo failed %s(%d)", fi_strerror(-ret), -ret);
+		return ret;
+	}
+
+	if (!info)
+		return ret;
+
+	if (!check)
+		goto out;
+
+	ft_foreach_info(fi, info) {
+		FT_DEBUG("\nTesting for fabric: %s, domain: %s, endpoint type: %d",
+				fi->fabric_attr->name, fi->domain_attr->name,
+				fi->ep_attr->type);
+		ret = check(info);
+		if (ret)
+			break;
+	}
+out:
+	fi_freeinfo(info);
+	return ret;
+}
+
+#define getinfo_test(name, num, desc, node, service, flags, hints, init, test, check,	\
+		ret_exp)							\
+char *getinfo_ ## name ## num ## _desc = desc;					\
+static int getinfo_ ## name ## num(void)					\
+{										\
+	int ret, testret = FAIL;						\
+	ret = getinfo_unit_test(node, service, flags, hints, init, test, check,	\
+			ret_exp);						\
+	if (ret)								\
+		goto fail;							\
+	testret = PASS;								\
+fail:										\
+	return TEST_RET_VAL(ret, testret);					\
+}
+
+/*
+ * Tests:
+ */
+
+
+/* 1. No hints tests
+ * These tests do not receive hints. If a particular provider has been
+ * requested, the environment variable FI_PROVIDER will be set to restrict
+ * the provider used. Otherwise, test failures may occur for any provider.
+ */
+
+/* 1.1 Source address only tests */
+getinfo_test(no_hints, 1, "Test with no node, service, flags or hints",
+		NULL, NULL, 0, NULL, NULL, NULL, check_srcaddr, 0)
+getinfo_test(no_hints, 2, "Test with node, no service, FI_SOURCE flag and no hints",
+		opts.src_addr ? opts.src_addr : "localhost", NULL, FI_SOURCE,
+		NULL, NULL, NULL, check_srcaddr, 0)
+getinfo_test(no_hints, 3, "Test with service, FI_SOURCE flag and no node or hints",
+		 NULL, opts.src_port, FI_SOURCE, NULL, NULL,
+		 NULL, check_srcaddr, 0)	// TODO should we check for wildcard addr?
+getinfo_test(no_hints, 4, "Test with node, service, FI_SOURCE flags and no hints",
+		opts.src_addr ? opts.src_addr : "localhost", opts.src_port,
+		FI_SOURCE, NULL, NULL, NULL, check_srcaddr, 0)
+
+/* 1.2 Source and destination address tests */
+getinfo_test(no_hints, 5, "Test with node, service and no hints",
+		opts.dst_addr ? opts.dst_addr : "localhost", opts.dst_port,
+		0, NULL, NULL, NULL, check_src_dest_addr, 0)
+
+/* 2. Test with hints */
+/* 2.1 Source address only tests */
+getinfo_test(src, 1, "Test with no node, service, or flags",
+		NULL, NULL, 0, hints, NULL, NULL, check_srcaddr, 0)
+getinfo_test(src, 2, "Test with node, no service, FI_SOURCE flag",
+		opts.src_addr ? opts.src_addr : "localhost", NULL, FI_SOURCE,
+		hints, NULL, NULL, check_srcaddr, 0)
+getinfo_test(src, 3, "Test with service, FI_SOURCE flag and no node",
+		 NULL, opts.src_port, FI_SOURCE, hints, NULL,
+		 NULL, check_srcaddr, 0)	// TODO should we check for wildcard addr?
+getinfo_test(src, 4, "Test with node, service, FI_SOURCE flags",
+		opts.src_addr ? opts.src_addr : "localhost", opts.src_port,
+		FI_SOURCE, hints, NULL, NULL, check_srcaddr, 0)
+
+/* 2.2 Source and destination address tests */
+getinfo_test(src_dest, 1, "Test with node, service",
+		opts.dst_addr ? opts.dst_addr : "localhost", opts.dst_port,
+		0, hints, NULL, NULL, check_src_dest_addr, 0)
+
+getinfo_test(src_dest, 2, "Test API version",
+		NULL, NULL, 0, hints, NULL, NULL, check_api_version , 0)
+
+/* Negative tests */
+getinfo_test(neg, 1, "Test with non-existent domain name",
+		NULL, NULL, 0, hints, invalid_dom, NULL, NULL, -FI_ENODATA)
+
+/* Utility provider tests */
+getinfo_test(util, 1, "Test if we get utility provider when requested",
+		NULL, NULL, 0, hints, NULL, NULL, check_util_prov, 0)
+
+/* Message Ordering Tests */
+getinfo_test(msg_ordering, 1, "Test msg ordering bits supported are set",
+		NULL, NULL, 0, hints, NULL, validate_msg_ordering_bits, NULL, 0)
+getinfo_test(raw_ordering, 1, "Test rma RAW ordering size is set",
+		NULL, NULL, 0, hints, init_valid_rma_RAW_ordering_no_set_size,
+		NULL, check_valid_rma_ordering_sizes, 0)
+getinfo_test(raw_ordering, 2, "Test rma RAW ordering size is set to hints",
+		NULL, NULL, 0, hints, init_valid_rma_RAW_ordering_set_size,
+		NULL, check_valid_rma_ordering_sizes, 0)
+getinfo_test(war_ordering, 1, "Test rma WAR ordering size is set",
+		NULL, NULL, 0, hints, init_valid_rma_WAR_ordering_no_set_size,
+		NULL, check_valid_rma_ordering_sizes, 0)
+getinfo_test(war_ordering, 2, "Test rma WAR ordering size is set to hints",
+		NULL, NULL, 0, hints, init_valid_rma_WAR_ordering_set_size,
+		NULL, check_valid_rma_ordering_sizes, 0)
+getinfo_test(waw_ordering, 1, "Test rma WAW ordering size is set",
+		NULL, NULL, 0, hints, init_valid_rma_WAW_ordering_no_set_size,
+		NULL, check_valid_rma_ordering_sizes, 0)
+getinfo_test(waw_ordering, 2, "Test rma WAW ordering size is set to hints",
+		NULL, NULL, 0, hints, init_valid_rma_WAW_ordering_set_size,
+		NULL, check_valid_rma_ordering_sizes, 0)
+getinfo_test(bad_raw_ordering, 1, "Test invalid rma RAW ordering size",
+		NULL, NULL, 0, hints, init_invalid_rma_RAW_ordering_size,
+		NULL, NULL, -FI_ENODATA)
+getinfo_test(bad_war_ordering, 1, "Test invalid rma WAR ordering size",
+		NULL, NULL, 0, hints, init_invalid_rma_WAR_ordering_size,
+		NULL, NULL, -FI_ENODATA)
+getinfo_test(bad_waw_ordering, 1, "Test invalid rma WAW ordering size",
+		NULL, NULL, 0, hints, init_invalid_rma_WAW_ordering_size,
+		NULL, NULL, -FI_ENODATA)
+
+/* MR mode tests */
+getinfo_test(mr_mode, 1, "Test FI_MR_BASIC", NULL, NULL, 0,
+	     hints, init_mr_basic, NULL, check_mr_basic, -FI_ENODATA)
+getinfo_test(mr_mode, 2, "Test FI_MR_SCALABLE", NULL, NULL, 0,
+	     hints, init_mr_scalable, NULL, check_mr_scalable, -FI_ENODATA)
+getinfo_test(mr_mode, 3, "Test FI_MR_UNSPEC (v1.0)", NULL, NULL, 0,
+	     hints, init_mr_unspec, test_mr_v1_0, check_mr_unspec, -FI_ENODATA)
+getinfo_test(mr_mode, 4, "Test FI_MR_BASIC (v1.0)", NULL, NULL, 0,
+	     hints, init_mr_basic, test_mr_v1_0, check_mr_basic, -FI_ENODATA)
+getinfo_test(mr_mode, 5, "Test FI_MR_SCALABLE (v1.0)", NULL, NULL, 0,
+     	     hints, init_mr_scalable, test_mr_v1_0, check_mr_scalable, -FI_ENODATA)
+getinfo_test(mr_mode, 6, "Test mr_mode bits", NULL, NULL, 0,
+	     hints, NULL, test_mr_modes, NULL, 0)
+
+
+static void usage(void)
+{
+	ft_unit_usage("getinfo_test", "Unit tests for fi_getinfo");
+	FT_PRINT_OPTS_USAGE("-e <ep_type>", "Endpoint type: msg|rdm|dgram (default:rdm)");
+	ft_addr_usage();
+}
+
+static int set_prov(char *prov_name)
+{
+	const char *util_name;
+	const char *core_name;
+	char *core_name_dup;
+	size_t len;
+
+	util_name = ft_util_name(prov_name, &len);
+	core_name = ft_core_name(prov_name, &len);
+
+	if (util_name && !core_name)
+		return 0;
+
+	core_name_dup = strndup(core_name, len);
+	if (!core_name_dup)
+		return -FI_ENOMEM;
+
+	snprintf(new_prov_var, sizeof(new_prov_var) - 1, "FI_PROVIDER=%s",
+		 core_name_dup);
+
+	putenv(new_prov_var);
+	free(core_name_dup);
+	return 0;
+}
+
+int main(int argc, char **argv)
+{
+	int failed;
+	int op;
+	size_t len;
+	const char *util_name;
+
+	struct test_entry no_hint_tests[] = {
+		TEST_ENTRY_GETINFO(no_hints1),
+		TEST_ENTRY_GETINFO(no_hints2),
+		TEST_ENTRY_GETINFO(no_hints3),
+		TEST_ENTRY_GETINFO(no_hints4),
+		TEST_ENTRY_GETINFO(no_hints5),
+		{ NULL, "" }
+	};
+
+	struct test_entry hint_tests[] = {
+		TEST_ENTRY_GETINFO(src1),
+		TEST_ENTRY_GETINFO(src2),
+		TEST_ENTRY_GETINFO(src3),
+		TEST_ENTRY_GETINFO(src4),
+		TEST_ENTRY_GETINFO(src_dest1),
+		TEST_ENTRY_GETINFO(src_dest2),
+		TEST_ENTRY_GETINFO(msg_ordering1),
+		TEST_ENTRY_GETINFO(raw_ordering1),
+		TEST_ENTRY_GETINFO(raw_ordering2),
+		TEST_ENTRY_GETINFO(war_ordering1),
+		TEST_ENTRY_GETINFO(war_ordering2),
+		TEST_ENTRY_GETINFO(waw_ordering1),
+		TEST_ENTRY_GETINFO(waw_ordering2),
+		TEST_ENTRY_GETINFO(bad_raw_ordering1),
+		TEST_ENTRY_GETINFO(bad_war_ordering1),
+		TEST_ENTRY_GETINFO(bad_waw_ordering1),
+		TEST_ENTRY_GETINFO(neg1),
+		TEST_ENTRY_GETINFO(mr_mode1),
+		TEST_ENTRY_GETINFO(mr_mode2),
+		TEST_ENTRY_GETINFO(mr_mode3),
+		TEST_ENTRY_GETINFO(mr_mode4),
+		TEST_ENTRY_GETINFO(mr_mode5),
+		TEST_ENTRY_GETINFO(mr_mode6),
+		{ NULL, "" }
+	};
+
+	struct test_entry util_prov_tests[] = {
+		TEST_ENTRY_GETINFO(util1),
+		{ NULL, "" }
+	};
+
+	opts = INIT_OPTS;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, ADDR_OPTS INFO_OPTS "h")) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'h':
+			usage();
+			return EXIT_SUCCESS;
+		case '?':
+			usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	if (optind < argc)
+		opts.dst_addr = argv[optind];
+	if (!opts.dst_port)
+		opts.dst_port = "9228";
+	if (!opts.src_port)
+		opts.src_port = "9228";
+
+	hints->mode = ~0;
+
+	if (hints->fabric_attr->prov_name) {
+		if (set_prov(hints->fabric_attr->prov_name))
+			return EXIT_FAILURE;
+	} else {
+	       FT_WARN("\nTests getinfo1 to getinfo5 may not run exclusively "
+		       "for a particular provider since we don't pass hints.\n"
+		       "So the failures in any of those tests may not be "
+		       "attributable to a single provider.\n");
+	}
+
+	failed = run_tests(no_hint_tests, err_buf);
+
+	if (hints->fabric_attr->prov_name) {
+		util_name = ft_util_name(hints->fabric_attr->prov_name, &len);
+		if (util_name)
+			failed += run_tests(util_prov_tests, err_buf);
+	}
+
+	failed += run_tests(hint_tests, err_buf);
+
+	if (failed > 0) {
+		printf("\nSummary: %d tests failed\n", failed);
+	} else {
+		printf("\nSummary: all tests passed\n");
+	}
+
+	ft_free_res();
+	return (failed > 0) ? EXIT_FAILURE : EXIT_SUCCESS;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/mr_test.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/mr_test.c
new file mode 100644
index 000000000..16cfb3f70
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/mr_test.c
@@ -0,0 +1,273 @@
+/*
+ * Copyright (c) 2013-2017 Intel Corporation.  All rights reserved.
+ * Copyright (c) 2014-2016 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <getopt.h>
+
+#include <rdma/fi_domain.h>
+#include <rdma/fi_errno.h>
+
+#include "unit_common.h"
+#include "shared.h"
+
+static char err_buf[512];
+
+/*
+ * Tests:
+ */
+static int mr_reg()
+{
+	int i, j;
+	int ret = 0;
+	int testret = FAIL;
+	struct fid_mr *mr;
+	uint64_t access;
+	uint64_t *access_combinations;
+	int cnt;
+
+	access = ft_info_to_mr_access(fi);
+	ret = ft_alloc_bit_combo(0, access, &access_combinations, &cnt);
+	if (ret) {
+		FT_UNIT_STRERR(err_buf, "ft_alloc_bit_combo failed", ret);
+		goto out;
+	}
+
+	for (i = 0; i < test_cnt; i++) {
+		buf_size = test_size[i].size;
+		for (j = 0; j < cnt; j++) {
+			ret = fi_mr_reg(domain, buf, buf_size,
+					access_combinations[j], 0,
+					FT_MR_KEY, 0, &mr, NULL);
+			if (ret) {
+				FT_UNIT_STRERR(err_buf, "fi_mr_reg failed", ret);
+				goto free;
+			}
+
+			ret = fi_close(&mr->fid);
+			if (ret) {
+				FT_UNIT_STRERR(err_buf, "fi_close failed", ret);
+				goto free;
+			}
+		}
+	}
+	testret = PASS;
+free:
+	ft_free_bit_combo(access_combinations);
+out:
+	return TEST_RET_VAL(ret, testret);
+}
+
+static int mr_regv()
+{
+	int i, j, n;
+	int ret = 0;
+	int testret = FAIL;
+	struct fid_mr *mr;
+	struct iovec *iov;
+	char *base;
+
+	iov = calloc(fi->domain_attr->mr_iov_limit, sizeof(*iov));
+	if (!iov) {
+		perror("calloc");
+		ret = -FI_ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < test_cnt &&
+	     test_size[i].size <= fi->domain_attr->mr_iov_limit; i++) {
+		n = test_size[i].size;
+		base = buf;
+
+		for (j = 0; j < n; j++) {
+			iov[j].iov_base = base;
+			iov[j].iov_len = test_size[test_cnt - 1].size / n;
+			base += iov[j].iov_len;
+		}
+
+		ret = fi_mr_regv(domain, &iov[0], n, ft_info_to_mr_access(fi), 0,
+				 FT_MR_KEY, 0, &mr, NULL);
+		if (ret) {
+			FT_UNIT_STRERR(err_buf, "fi_mr_regv failed", ret);
+			goto free;
+		}
+
+		ret = fi_close(&mr->fid);
+		if (ret) {
+			FT_UNIT_STRERR(err_buf, "fi_close failed", ret);
+			goto free;
+		}
+	}
+	testret = PASS;
+free:
+	free(iov);
+out:
+	return TEST_RET_VAL(ret, testret);
+}
+
+static int mr_regattr()
+{
+	int i, j, n;
+	int ret = 0;
+	int testret = FAIL;
+	struct fid_mr *mr;
+	struct iovec *iov;
+	struct fi_mr_attr attr;
+	char *base;
+
+	attr.access = ft_info_to_mr_access(fi);
+	attr.requested_key = FT_MR_KEY;
+	attr.context = NULL;
+
+	iov = calloc(fi->domain_attr->mr_iov_limit, sizeof(*iov));
+	if (!iov) {
+		perror("calloc");
+		ret = -FI_ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < test_cnt &&
+	     test_size[i].size <= fi->domain_attr->mr_iov_limit; i++) {
+
+		n = test_size[i].size;
+		base = buf;
+		for (j = 0; j < n; j++) {
+			iov[j].iov_base = base;
+			iov[j].iov_len = test_size[test_cnt - 1].size / n;
+			base += iov[j].iov_len;
+		}
+
+		attr.iov_count = n;
+		attr.mr_iov = &iov[0];
+		ret = fi_mr_regattr(domain, &attr, 0, &mr);
+		if (ret) {
+			FT_UNIT_STRERR(err_buf, "fi_mr_regattr failed", ret);
+			goto free;
+		}
+
+		ret = fi_close(&mr->fid);
+		if (ret) {
+			FT_UNIT_STRERR(err_buf, "fi_close failed", ret);
+			goto free;
+		}
+	}
+	testret = PASS;
+free:
+	free(iov);
+out:
+	return TEST_RET_VAL(ret, testret);
+}
+
+struct test_entry test_array[] = {
+	TEST_ENTRY(mr_reg, "Test fi_mr_reg across different access combinations"),
+	TEST_ENTRY(mr_regv, "Test fi_mr_regv across various buffer sizes"),
+	TEST_ENTRY(mr_regattr, "Test fi_mr_regattr across various buffer sizes"),
+	{ NULL, "" }
+};
+
+static void usage(void)
+{
+	ft_unit_usage("mr_test", "Unit test for Memory Region (MR)");
+}
+
+int main(int argc, char **argv)
+{
+	int op, ret;
+	int failed = 0;
+
+	buf = NULL;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, FAB_OPTS "h")) != -1) {
+		switch (op) {
+		default:
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case '?':
+		case 'h':
+			usage();
+			return EXIT_FAILURE;
+		}
+	}
+
+	hints->mode = ~0;
+	hints->domain_attr->mode = ~0;
+	hints->domain_attr->mr_mode = ~(FI_MR_BASIC | FI_MR_SCALABLE);
+
+	hints->caps |= FI_MSG | FI_RMA;
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, 0, 0, hints, &fi);
+	if (ret) {
+		hints->caps &= ~FI_RMA;
+		ret = fi_getinfo(FT_FIVERSION, NULL, 0, 0, hints, &fi);
+		if (ret) {
+			FT_PRINTERR("fi_getinfo", ret);
+			goto out;
+		}
+	}
+
+	if (!ft_info_to_mr_access(fi))
+		goto out;
+
+	if (!fi->domain_attr->mr_iov_limit) {
+		ret = -FI_EINVAL;
+		FT_PRINTERR("mr_iov_limit not set", ret);
+		goto out;
+	}
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		goto out;
+
+	buf = malloc(test_size[test_cnt - 1].size);
+	if (!buf) {
+		ret = -FI_ENOMEM;
+		goto out;
+	}
+
+	printf("Testing MR on fabric %s\n", fi->fabric_attr->name);
+
+	failed = run_tests(test_array, err_buf);
+	if (failed > 0) {
+		printf("Summary: %d tests failed\n", failed);
+	} else {
+		printf("Summary: all tests passed\n");
+	}
+
+out:
+	ft_free_res();
+	return ret ? ft_exit_code(ret) : (failed > 0) ? EXIT_FAILURE : EXIT_SUCCESS;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/resource_freeing.c b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/resource_freeing.c
new file mode 100644
index 000000000..f3da76f2c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/fabtests/unit/resource_freeing.c
@@ -0,0 +1,303 @@
+/*
+ * Copyright (c) 2017 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <getopt.h>
+#include "shared.h"
+
+#define lengthof(arr) (sizeof(arr) / sizeof(*arr))
+
+enum test_depth {
+	DEPTH_FABRIC,
+	DEPTH_DOMAIN,
+	DEPTH_ENABLE_ENDPOINT
+};
+
+int test_resource_freeing(enum test_depth test_depth,
+		const char *fabric_service)
+{
+	int our_ret = FI_SUCCESS;
+	int ret;
+	uint64_t flags;
+	struct fi_info *info;
+
+	/* Setup fabric */
+
+	hints = fi_allocinfo();
+	if (!hints) {
+		our_ret = -FI_ENOMEM;
+		goto error_return;
+	}
+
+	flags = FI_SOURCE;
+	hints->caps = FI_RMA;
+	hints->ep_attr->type = FI_EP_RDM;
+
+	ret = fi_getinfo(FT_FIVERSION, NULL, fabric_service, flags,
+			 hints, &info);
+	if (ret) {
+		FT_PRINTERR("fi_getinfo", ret);
+		our_ret = ret;
+		goto free_hints;
+	}
+
+	ret = fi_fabric(info->fabric_attr, &fabric, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_fabric", ret);
+		our_ret = ret;
+		goto free_info;
+	}
+
+	if (test_depth == DEPTH_FABRIC) {
+		goto close_fabric;
+	}
+
+	ret = fi_domain(fabric, info, &domain, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_domain", ret);
+		our_ret = ret;
+		goto close_fabric;
+	}
+
+	if (test_depth == DEPTH_DOMAIN) {
+		goto close_domain;
+	}
+
+	/* Create pre-endpoint resources */
+
+	av_attr.type = info->domain_attr->av_type;
+	av_attr.count = 0;
+	av_attr.name = NULL;
+	ret = fi_av_open(domain, &av_attr, &av, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_av_open", ret);
+		our_ret = ret;
+		goto close_domain;
+	}
+
+	cntr_attr.events = FI_CNTR_EVENTS_COMP;
+	cntr_attr.wait_obj = FI_WAIT_UNSPEC;
+	ret = fi_cntr_open(domain, &cntr_attr, &txcntr, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_cntr_open", ret);
+		our_ret = ret;
+		goto close_av;
+	}
+
+	ret = fi_cq_open(domain, &cq_attr, &txcq, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_cq_open", ret);
+		our_ret = ret;
+		goto close_txcntr;
+	}
+
+	ret = fi_endpoint(domain, info, &ep, NULL);
+	if (ret) {
+		FT_PRINTERR("fi_endpoint", ret);
+		our_ret = ret;
+		goto close_txcq;
+	}
+
+	/* Bind pre-endpoint resources to ep */
+
+	ret = fi_ep_bind(ep, &txcntr->fid, FI_WRITE);
+	if (ret) {
+		FT_PRINTERR("fi_ep_bind", ret);
+		our_ret = ret;
+		goto close_ep;
+	}
+
+	ret = fi_ep_bind(ep, &av->fid, 0);
+	if (ret) {
+		FT_PRINTERR("fi_ep_bind", ret);
+		our_ret = ret;
+		goto close_ep;
+	}
+
+	ret = fi_ep_bind(ep, &txcq->fid, FI_TRANSMIT);
+	if (ret) {
+		FT_PRINTERR("fi_ep_bind", ret);
+		our_ret = ret;
+		goto close_ep;
+	}
+
+	/* Enable ep */
+
+	ret = fi_enable(ep);
+	if (ret) {
+		FT_PRINTERR("fi_enable", ret);
+		our_ret = ret;
+		goto close_ep;
+	}
+
+	if (test_depth == DEPTH_ENABLE_ENDPOINT) {
+		goto close_ep;
+	}
+
+close_ep:
+	ret = fi_close(&ep->fid);
+	if (ret) {
+		FT_PRINTERR("fi_close", ret);
+		our_ret = our_ret ? our_ret : ret;
+	}
+
+close_txcq:
+	ret = fi_close(&txcq->fid);
+	if (ret) {
+		FT_PRINTERR("fi_close", ret);
+		our_ret = our_ret ? our_ret : ret;
+	}
+
+close_txcntr:
+	ret = fi_close(&txcntr->fid);
+	if (ret) {
+		FT_PRINTERR("fi_close", ret);
+		our_ret = our_ret ? our_ret : ret;
+	}
+
+close_av:
+	ret = fi_close(&av->fid);
+	if (ret) {
+		FT_PRINTERR("fi_close", ret);
+		our_ret = our_ret ? our_ret : ret;
+	}
+
+close_domain:
+	ret = fi_close(&domain->fid);
+	if (ret) {
+		FT_PRINTERR("fi_close", ret);
+		our_ret = our_ret ? our_ret : ret;
+	}
+
+close_fabric:
+	ret = fi_close(&fabric->fid);
+	if (ret) {
+		FT_PRINTERR("fi_close", ret);
+		our_ret = our_ret ? our_ret : ret;
+	}
+
+free_info:
+	fi_freeinfo(info);
+
+free_hints:
+	fi_freeinfo(hints);
+
+error_return:
+	return our_ret;
+}
+
+void print_test_resource_freeing_call(enum test_depth test_depth, int iter)
+{
+	fprintf(stdout,
+		"Running test_resource_freeing with "
+		"[%s] for %d iterations\n",
+		(test_depth == DEPTH_FABRIC) ? "DEPTH_FABRIC"
+		: (test_depth == DEPTH_DOMAIN) ? "DEPTH_DOMAIN"
+		: (test_depth == DEPTH_ENABLE_ENDPOINT) ? "DEPTH_ENABLE_ENDPOINT"
+		: "(unknown test depth)",
+		iter
+	);
+
+	fflush(stderr);
+	fflush(stdout);
+}
+
+void print_test_resource_freeing_result_call(int success,
+		enum test_depth test_depth,
+		int iter)
+{
+	fprintf(success ? stdout : stderr,
+		"%s: test_resource_freeing %s with "
+		"[%s]\n",
+		success ? "GOOD" : "ERROR",
+		success ? "succeeded" : "failed",
+		(test_depth == DEPTH_FABRIC) ? "DEPTH_FABRIC"
+		: (test_depth == DEPTH_DOMAIN) ? "DEPTH_DOMAIN"
+		: (test_depth == DEPTH_ENABLE_ENDPOINT) ? "DEPTH_ENABLE_ENDPOINT"
+		: "(unknown test depth)"
+	);
+
+	fflush(stderr);
+	fflush(stdout);
+}
+
+int main(int argc, char **argv)
+{
+	int op, i, td_idx, ret = 0, iters = 2, exit_code = 0;
+
+	opts = INIT_OPTS;
+
+	hints = fi_allocinfo();
+	if (!hints)
+		return EXIT_FAILURE;
+
+	while ((op = getopt(argc, argv, "i:h" ADDR_OPTS INFO_OPTS)) != -1) {
+		switch (op) {
+		default:
+			ft_parse_addr_opts(op, optarg, &opts);
+			ft_parseinfo(op, optarg, hints);
+			break;
+		case 'i':
+			iters = atoi(optarg);
+			break;
+		case '?':
+		case 'h':
+			ft_usage(argv[0], "Test which exercises resource freeing in a provider\n");
+			FT_PRINT_OPTS_USAGE("-i <int>", "number of iterations to test");
+			return EXIT_FAILURE;
+		}
+	}
+
+	enum test_depth test_depth[] = {
+		DEPTH_FABRIC, DEPTH_DOMAIN, DEPTH_ENABLE_ENDPOINT};
+
+	for (td_idx = 0; td_idx < lengthof(test_depth); td_idx += 1) {
+		print_test_resource_freeing_call(
+			test_depth[td_idx], iters);
+		for (i = 0; i < iters; i += 1) {
+			ret = test_resource_freeing(
+				test_depth[td_idx], default_port);
+			if (ret) {
+				exit_code = EXIT_FAILURE;
+				break;
+			}
+		}
+		print_test_resource_freeing_result_call(
+			!ret, /* int success */
+			test_depth[td_idx],
+			i);
+	}
+
+	return ft_exit_code(exit_code);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/freebsd/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/include/freebsd/osd.h
index f3bef8f8a..62cd8f483 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/freebsd/osd.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/freebsd/osd.h
@@ -1,5 +1,6 @@
 /*
  * Copyright (c) 2016 Intel Corp, Inc. All rights reserved.
+ * Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -51,6 +52,21 @@ static inline int ofi_shm_remap(struct util_shm *shm, size_t newsize, void **map
 	return -1;
 }
 
+static inline ssize_t ofi_get_hugepage_size(void)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int ofi_alloc_hugepage_buf(void **memptr, size_t size)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int ofi_free_hugepage_buf(void *memptr, size_t size)
+{
+	return -FI_ENOSYS;
+}
+
 #endif /* _FREEBSD_OSD_H_ */
 
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/linux/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/include/linux/osd.h
index bd54c7916..3ab031321 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/linux/osd.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/linux/osd.h
@@ -1,5 +1,6 @@
 /*
  * Copyright (c) 2015 Los Alamos Nat. Security, LLC. All rights reserved.
+ * Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -53,4 +54,22 @@ static inline int ofi_shm_remap(struct util_shm *shm,
 	return shm->ptr == MAP_FAILED ? -FI_EINVAL : FI_SUCCESS;
 }
 
+ssize_t ofi_get_hugepage_size(void);
+
+static inline int ofi_alloc_hugepage_buf(void **memptr, size_t size)
+{
+	*memptr = mmap(NULL, size, PROT_READ | PROT_WRITE,
+		       MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB, -1, 0);
+
+	if (*memptr == MAP_FAILED)
+		return -errno;
+
+	return FI_SUCCESS;
+}
+
+static inline int ofi_free_hugepage_buf(void *memptr, size_t size)
+{
+	return munmap(memptr, size);
+}
+
 #endif /* _LINUX_OSD_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi.h
index c664fb917..920ffafc5 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi.h
@@ -1,6 +1,6 @@
 /*
  * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
- * Copyright (c) 2016 Cisco Systems, Inc. All rights reserved.
+ * Copyright (c) 2016-2018 Cisco Systems, Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -81,6 +81,10 @@ extern "C" {
 		_a > _b ? _a : _b; })
 #endif
 
+#define ofi_div_ceil(a, b) ((a + b - 1) / b)
+
+#define OFI_MAGIC_64 (0x0F1C0DE0F1C0DE64)
+
 
 /*
  * CPU specific features
@@ -97,10 +101,16 @@ enum {
 int ofi_cpu_supports(unsigned func, unsigned reg, unsigned bit);
 
 
-/* Restrict to size of struct fi_context */
+enum ofi_prov_type {
+	OFI_PROV_CORE,
+	OFI_PROV_UTIL,
+	OFI_PROV_HOOK,
+};
+
+/* Restrict to size of struct fi_provider::context (struct fi_context) */
 struct fi_prov_context {
+	enum ofi_prov_type type;
 	int disable_logging;
-	int is_util_prov;
 };
 
 struct fi_filter {
@@ -115,11 +125,21 @@ void ofi_create_filter(struct fi_filter *filter, const char *env_name);
 void ofi_free_filter(struct fi_filter *filter);
 int ofi_apply_filter(struct fi_filter *filter, const char *name);
 
+int ofi_nic_close(struct fid *fid);
+struct fid_nic *ofi_nic_dup(const struct fid_nic *nic);
+int ofi_nic_tostr(const struct fid *fid_nic, char *buf, size_t len);
+
+struct fi_provider *ofi_get_hook(const char *name);
+
 void fi_log_init(void);
 void fi_log_fini(void);
 void fi_param_init(void);
 void fi_param_fini(void);
 void fi_param_undefine(const struct fi_provider *provider);
+void ofi_hook_init(void);
+void ofi_hook_fini(void);
+void ofi_hook_install(struct fid_fabric *hfabric, struct fid_fabric **fabric,
+		      struct fi_provider *prov);
 
 const char *ofi_hex_str(const uint8_t *data, size_t len);
 
@@ -150,6 +170,7 @@ static inline size_t fi_get_aligned_sz(size_t size, size_t alignment)
 uint64_t ofi_max_tag(uint64_t mem_tag_format);
 uint64_t ofi_tag_format(uint64_t max_tag);
 uint8_t ofi_msb(uint64_t num);
+uint8_t ofi_lsb(uint64_t num);
 
 int ofi_send_allowed(uint64_t caps);
 int ofi_recv_allowed(uint64_t caps);
@@ -162,7 +183,6 @@ int ofi_check_rx_mode(const struct fi_info *info, uint64_t flags);
 uint64_t fi_gettime_ms(void);
 uint64_t fi_gettime_us(void);
 
-
 #define OFI_ENUM_VAL(X) X
 #define OFI_STR(X) #X
 #define OFI_STR_INT(X) OFI_STR(X)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_abi.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_abi.h
index cd0286697..8ba35a4a3 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_abi.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_abi.h
@@ -111,7 +111,7 @@ extern "C" {
  * name appended with the ABI version that it is compatible with.
  */
 
-#define CURRENT_ABI "FABRIC_1.1"
+#define CURRENT_ABI "FABRIC_1.2"
 
 #if  HAVE_ALIAS_ATTRIBUTE == 1
 #define DEFAULT_SYMVER_PRE(a) a##_
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_atomic.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_atomic.h
index 3f4585b6d..a146e75bc 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_atomic.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_atomic.h
@@ -11,7 +11,7 @@
  *     without modification, are permitted provided that the following
  *     conditions are met:
  *
- *      - Redistibutions of source code must retain the above
+ *      - Redistributions of source code must retain the above
  *        copyright notice, this list of conditions and the following
  *        disclaimer.
  *
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_epoll.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_epoll.h
new file mode 100644
index 000000000..def823ed3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_epoll.h
@@ -0,0 +1,149 @@
+/*
+ * Copyright (c) 2011-s2018 Intel Corporation.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ */
+
+#ifndef _OFI_EPOLL_H_
+#define _OFI_EPOLL_H_
+
+#include <unistd.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+
+#include <ofi_list.h>
+#include <ofi_signal.h>
+
+#ifdef HAVE_EPOLL
+#include <sys/epoll.h>
+
+#define FI_EPOLL_IN  EPOLLIN
+#define FI_EPOLL_OUT EPOLLOUT
+
+typedef int fi_epoll_t;
+
+static inline int fi_epoll_create(int *ep)
+{
+	*ep = epoll_create(4);
+	return *ep < 0 ? -ofi_syserr() : 0;
+}
+
+static inline int fi_epoll_add(int ep, int fd, uint32_t events, void *context)
+{
+	struct epoll_event event;
+	int ret;
+
+	event.data.ptr = context;
+	event.events = events;
+	ret = epoll_ctl(ep, EPOLL_CTL_ADD, fd, &event);
+	if ((ret == -1) && (ofi_syserr() != EEXIST))
+		return -ofi_syserr();
+	return 0;
+}
+
+static inline int fi_epoll_mod(int ep, int fd, uint32_t events, void *context)
+{
+	struct epoll_event event;
+
+	event.data.ptr = context;
+	event.events = events;
+	return epoll_ctl(ep, EPOLL_CTL_MOD, fd, &event) ? -ofi_syserr() : 0;
+}
+
+static inline int fi_epoll_del(int ep, int fd)
+{
+	return epoll_ctl(ep, EPOLL_CTL_DEL, fd, NULL) ? -ofi_syserr() : 0;
+}
+
+static inline int fi_epoll_wait(int ep, void **contexts, int max_contexts,
+                                int timeout)
+{
+	struct epoll_event events[max_contexts];
+	int ret;
+	int i;
+
+	ret = epoll_wait(ep, events, max_contexts, timeout);
+	if (ret == -1)
+		return -ofi_syserr();
+
+	for (i = 0; i < ret; i++)
+		contexts[i] = events[i].data.ptr;
+	return ret;
+}
+
+static inline void fi_epoll_close(int ep)
+{
+	close(ep);
+}
+
+#else
+#include <poll.h>
+
+#define FI_EPOLL_IN  POLLIN
+#define FI_EPOLL_OUT POLLOUT
+
+enum fi_epoll_ctl {
+	EPOLL_CTL_ADD,
+	EPOLL_CTL_DEL,
+	EPOLL_CTL_MOD,
+};
+
+struct fi_epoll_work_item {
+	int		fd;
+	uint32_t	events;
+	void		*context;
+	enum fi_epoll_ctl type;
+	struct slist_entry entry;
+};
+
+typedef struct fi_epoll {
+	int		size;
+	int		nfds;
+	struct pollfd	*fds;
+	void		**context;
+	int		index;
+	struct fd_signal signal;
+	struct slist	work_item_list;
+	fastlock_t	lock;
+} *fi_epoll_t;
+
+int fi_epoll_create(struct fi_epoll **ep);
+int fi_epoll_add(struct fi_epoll *ep, int fd, uint32_t events, void *context);
+int fi_epoll_mod(struct fi_epoll *ep, int fd, uint32_t events, void *context);
+int fi_epoll_del(struct fi_epoll *ep, int fd);
+int fi_epoll_wait(struct fi_epoll *ep, void **contexts, int max_contexts,
+                  int timeout);
+void fi_epoll_close(struct fi_epoll *ep);
+
+#endif /* HAVE_EPOLL */
+
+#endif  /* _OFI_EPOLL_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_hook.h
similarity index 81%
rename from prov/hook/src/hook.h
rename to include/ofi_hook.h
index 43f83b1f3..abf827d6a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_hook.h
@@ -44,6 +44,19 @@
 #include <rdma/fi_rma.h>
 #include <rdma/fi_tagged.h>
 
+#include <rdma/providers/fi_prov.h>
+
+
+/*
+ * Hooks are installed from top down.
+ * Values must start at 0 and increment by one.
+ */
+enum ofi_hook_class {
+	HOOK_NOOP,
+	HOOK_PERF,
+	MAX_HOOKS
+};
+
 
 /*
  * Define hook structs so we can cast from fid to parent using simple cast.
@@ -52,18 +65,25 @@
 
 extern struct fi_ops hook_fid_ops;
 struct fid *hook_to_hfid(const struct fid *fid);
+struct fid_wait *hook_to_hwait(const struct fid_wait *wait);
+
 
 struct hook_fabric {
-	struct fid_fabric fabric;
-	struct fid_fabric *hfabric;
+	struct fid_fabric	fabric;
+	struct fid_fabric	*hfabric;
+	enum ofi_hook_class	hclass;
+	struct fi_provider	*prov;
 };
 
-int hook_fabric(struct fid_fabric *hfabric, struct fid_fabric **fabric);
+void hook_fabric_init(struct hook_fabric *fabric, enum ofi_hook_class hclass,
+		      struct fid_fabric *hfabric, struct fi_provider *hprov,
+		      struct fi_ops *f_ops);
 
 
 struct hook_domain {
 	struct fid_domain domain;
 	struct fid_domain *hdomain;
+	struct hook_fabric *fabric;
 };
 
 int hook_domain(struct fid_fabric *fabric, struct fi_info *info,
@@ -73,6 +93,7 @@ int hook_domain(struct fid_fabric *fabric, struct fi_info *info,
 struct hook_av {
 	struct fid_av av;
 	struct fid_av *hav;
+	struct hook_domain *domain;
 };
 
 int hook_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
@@ -82,6 +103,7 @@ int hook_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 struct hook_wait {
 	struct fid_wait wait;
 	struct fid_wait *hwait;
+	struct hook_fabric *fabric;
 };
 
 int hook_wait_open(struct fid_fabric *fabric, struct fi_wait_attr *attr,
@@ -92,6 +114,7 @@ int hook_trywait(struct fid_fabric *fabric, struct fid **fids, int count);
 struct hook_poll {
 	struct fid_poll poll;
 	struct fid_poll *hpoll;
+	struct hook_domain *domain;
 };
 
 int hook_poll_open(struct fid_domain *domain, struct fi_poll_attr *attr,
@@ -101,6 +124,7 @@ int hook_poll_open(struct fid_domain *domain, struct fi_poll_attr *attr,
 struct hook_eq {
 	struct fid_eq eq;
 	struct fid_eq *heq;
+	struct hook_fabric *fabric;
 };
 
 int hook_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
@@ -110,15 +134,20 @@ int hook_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
 struct hook_cq {
 	struct fid_cq cq;
 	struct fid_cq *hcq;
+	struct hook_domain *domain;
 };
 
 int hook_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
 		 struct fid_cq **cq, void *context);
+const char *
+hook_cq_strerror(struct fid_cq *cq, int prov_errno,
+		 const void *err_data, char *buf, size_t len);
 
 
 struct hook_cntr {
 	struct fid_cntr cntr;
 	struct fid_cntr *hcntr;
+	struct hook_domain *domain;
 };
 
 int hook_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
@@ -128,6 +157,7 @@ int hook_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
 struct hook_ep {
 	struct fid_ep ep;
 	struct fid_ep *hep;
+	struct hook_domain *domain;
 };
 
 int hook_endpoint(struct fid_domain *domain, struct fi_info *info,
@@ -148,6 +178,7 @@ extern struct fi_ops_atomic hook_atomic_ops;
 struct hook_pep {
 	struct fid_pep pep;
 	struct fid_pep *hpep;
+	struct hook_fabric *fabric;
 };
 
 int hook_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
@@ -157,6 +188,7 @@ int hook_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
 struct hook_stx {
 	struct fid_stx stx;
 	struct fid_stx *hstx;
+	struct hook_domain *domain;
 };
 
 int hook_stx_ctx(struct fid_domain *domain,
@@ -167,6 +199,7 @@ int hook_stx_ctx(struct fid_domain *domain,
 struct hook_mr {
 	struct fid_mr mr;
 	struct fid_mr *hmr;
+	struct hook_domain *domain;
 };
 
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_iov.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_iov.h
index dbf4b377d..b8ca7f574 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_iov.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_iov.h
@@ -61,6 +61,15 @@ static inline size_t ofi_total_ioc_cnt(const struct fi_ioc *ioc, size_t ioc_coun
 	return cnt;
 }
 
+static inline size_t ofi_total_rma_ioc_cnt(const struct fi_rma_ioc *rma_ioc,
+					   size_t ioc_count)
+{
+	size_t i, cnt = 0;
+	for (i = 0; i < ioc_count; i++)
+		cnt += rma_ioc[i].count;
+	return cnt;
+}
+
 #define OFI_COPY_IOV_TO_BUF 0
 #define OFI_COPY_BUF_TO_IOV 1
 
@@ -99,6 +108,28 @@ ofi_copy_from_iov(void *buf, uint64_t bufsize,
 	}
 }
 
+static inline void ofi_ioc_to_iov(const struct fi_ioc *ioc, struct iovec *iov,
+				  size_t count, size_t size)
+{
+	int i;
+	for (i = 0; i < count; i++) {
+		iov[i].iov_base = ioc[i].addr;
+		iov[i].iov_len = ioc[i].count * size;
+	}
+}
+
+static inline void ofi_rma_ioc_to_iov(const struct fi_rma_ioc *ioc,
+				      struct fi_rma_iov *iov,
+				      size_t count, size_t size)
+{
+	int i;
+	for (i = 0; i < count; i++) {
+		iov[i].addr = ioc[i].addr;
+		iov[i].len = ioc[i].count * size;
+		iov[i].key = ioc[i].key;
+	}
+}
+
 static inline void *
 ofi_iov_end(const struct iovec *iov)
 {
@@ -142,4 +173,13 @@ void ofi_consume_iov(struct iovec *iovec, size_t *iovec_count, size_t offset);
 
 int ofi_truncate_iov(struct iovec *iov, size_t *iov_count, size_t trim_size);
 
+/* Copy 'len' bytes worth of src iovec to dst */
+int ofi_copy_iov_desc(struct iovec *dst_iov, void **dst_desc, size_t *dst_count,
+		      struct iovec *src_iov, void **src_desc, size_t src_count,
+		      size_t *index, size_t *offset, size_t len);
+
+/* Copy 'len' bytes worth of src fi_rma_iov to dst */
+int ofi_copy_rma_iov(struct fi_rma_iov *dst_iov, size_t *dst_count,
+		struct fi_rma_iov *src_iov, size_t src_count,
+		size_t *index, size_t *offset, size_t len);
 #endif /* _OFI_IOV_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_list.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_list.h
index 07970716e..fdc405a9f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_list.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_list.h
@@ -40,8 +40,10 @@
 #include <sys/types.h>
 #include <stdlib.h>
 
-#include <ofi_signal.h>
+#include <rdma/fabric.h>
 
+#include <ofi_signal.h>
+#include <ofi_lock.h>
 
 /*
  * Double-linked list
@@ -104,16 +106,29 @@ static inline void dlist_remove_init(struct dlist_entry *item)
 #define dlist_foreach(head, item) 						\
 	for ((item) = (head)->next; (item) != (head); (item) = (item)->next)
 
+#define dlist_foreach_reverse(head, item) 					\
+	for ((item) = (head)->prev; (item) != (head); (item) = (item)->prev
+
 #define dlist_foreach_container(head, type, container, member)			\
 	for ((container) = container_of((head)->next, type, member);		\
 	     &((container)->member) != (head);					\
 	     (container) = container_of((container)->member.next,		\
 					type, member))
 
+#define dlist_foreach_container_reverse(head, type, container, member)		\
+	for ((container) = container_of((head)->prev, type, member);		\
+	     &((container)->member) != (head);					\
+	     (container) = container_of((container)->member.prev,		\
+					type, member))
+
 #define dlist_foreach_safe(head, item, tmp)					\
 	for ((item) = (head)->next, (tmp) = (item)->next; (item) != (head);	\
              (item) = (tmp), (tmp) = (item)->next)
 
+#define dlist_foreach_reverse_safe(head, item, tmp)				\
+	for ((item) = (head)->prev, (tmp) = (item)->prev; (item) != (head);	\
+             (item) = (tmp), (tmp) = (item)->prev)
+
 #define dlist_foreach_container_safe(head, type, container, member, tmp)	\
 	for ((container) = container_of((head)->next, type, member),		\
 	     (tmp) = (container)->member.next;					\
@@ -121,6 +136,13 @@ static inline void dlist_remove_init(struct dlist_entry *item)
 	     (container) = container_of((tmp), type, member),			\
 	     (tmp) = (container)->member.next)
 
+#define dlist_foreach_container_reverse_safe(head, type, container, member, tmp)\
+	for ((container) = container_of((head)->prev, type, member),		\
+	     (tmp) = (container)->member.prev;					\
+	     &((container)->member) != (head);					\
+	     (container) = container_of((tmp), type, member),			\
+	     (tmp) = (container)->member.prev)
+
 typedef int dlist_func_t(struct dlist_entry *item, const void *arg);
 
 static inline struct dlist_entry *
@@ -150,6 +172,18 @@ dlist_remove_first_match(struct dlist_entry *head, dlist_func_t *match,
 	return item;
 }
 
+static inline void dlist_insert_order(struct dlist_entry *head, dlist_func_t *order,
+				      struct dlist_entry *entry)
+{
+	struct dlist_entry *item;
+
+	item = dlist_find_first_match(head, order, entry);
+	if (item)
+		dlist_insert_before(entry, item);
+	else
+		dlist_insert_tail(entry, head);
+}
+
 /* splices list at the front of the list 'head'
  *
  * BEFORE:
@@ -194,6 +228,150 @@ static inline void dlist_splice_tail(struct dlist_entry *head,
 	dlist_splice_head(head->prev, to_splice);
 }
 
+/*
+ * Multi-threaded Double-linked list
+ */
+struct dlist_ts {
+	struct dlist_entry	head;
+	fastlock_t		lock;
+};
+
+static inline void dlist_ts_init(struct dlist_ts *list)
+{
+	fastlock_init(&list->lock);
+	dlist_init(&list->head);
+}
+
+static inline int dlist_ts_empty(struct dlist_ts *list)
+{
+	return dlist_empty(&list->head);
+}
+
+static inline void
+dlist_ts_insert_after(struct dlist_ts *list, struct dlist_entry *item,
+		      struct dlist_entry *head)
+{
+	fastlock_acquire(&list->lock);
+	dlist_insert_after(item, head);
+	fastlock_release(&list->lock);
+}
+
+static inline void
+dlist_ts_insert_before(struct dlist_ts *list, struct dlist_entry *item,
+		       struct dlist_entry *head)
+{
+	dlist_ts_insert_after(list, item, head->prev);
+}
+
+#define dlist_ts_insert_head(list, item) dlist_ts_insert_after(list, item, &(list)->head)
+#define dlist_ts_insert_tail(list, item) dlist_ts_insert_before(list, item, &(list)->head)
+
+static inline void
+dlist_ts_remove(struct dlist_ts *list, struct dlist_entry *item)
+{
+	fastlock_acquire(&list->lock);
+	dlist_remove(item);
+	fastlock_release(&list->lock);
+}
+
+#define dlist_ts_pop_front(list, type, container, member)		\
+	do {								\
+		fastlock_acquire(&(list)->lock);			\
+		if (dlist_ts_empty(list)) {				\
+			container = NULL;				\
+		} else {						\
+			dlist_pop_front(&(list)->head, type,		\
+					container, member);		\
+		}							\
+		fastlock_release(&(list)->lock);			\
+	} while (0)
+
+#define dlist_ts_foreach_end(list)				\
+		fastlock_release(&(list)->lock);		\
+	} while (0)
+
+#define dlist_ts_foreach(list, head, item)			\
+	{							\
+		fastlock_acquire(&(list)->lock);		\
+		dlist_foreach(list, head, item)
+
+#define dlist_ts_foreach_reverse(list, head, item)		\
+	{							\
+		fastlock_acquire(&(list)->lock);		\
+		dlist_foreach_reverse(list, head, item)
+
+#define dlist_ts_foreach_container(list, head, type, container, member)		\
+	{									\
+		fastlock_acquire(&(list)->lock);				\
+		dlist_foreach_container(type, container, member)
+
+#define dlist_ts_foreach_container_reverse(list, head, type, container, member)\
+	{									\
+		fastlock_acquire(&(list)->lock);				\
+		dlist_foreach_container_reverse(type, container, member)
+
+#define dlist_ts_foreach_safe(list, head, item, tmp)				\
+	{									\
+		fastlock_acquire(&(list)->lock);				\
+		dlist_foreach_safe(head, item, tmp)
+
+#define dlist_ts_foreach_reverse_safe(list, head, item, tmp)			\
+	{									\
+		fastlock_acquire(&(list)->lock);				\
+		dlist_foreach_reverse_safe(head, item, tmp)
+
+#define dlist_ts_foreach_container_safe(list, head, type, container,	\
+					member, tmp)			\
+	{								\
+		fastlock_acquire(&(list)->lock);			\
+		dlist_foreach_container_safe(head, type, container,	\
+					     member, tmp)
+
+#define dlist_ts_foreach_container_reverse_safe(list, head, type, container,\
+					member, tmp)				\
+	{									\
+		fastlock_acquire(&(list)->lock);				\
+		dlist_foreach_container_reverse_safe(head, type, container,	\
+					     member, tmp)
+
+static inline struct dlist_entry *
+dlist_ts_find_first_match(struct dlist_ts *list, struct dlist_entry *head,
+			  dlist_func_t *match, const void *arg)
+{
+	struct dlist_entry *item;
+
+	fastlock_acquire(&list->lock);
+	item = dlist_find_first_match(head, match, arg);
+	fastlock_release(&list->lock);
+
+	return item;
+}
+
+static inline struct dlist_entry *
+dlist_ts_remove_first_match(struct dlist_ts *list, struct dlist_entry *head,
+			    dlist_func_t *match, const void *arg)
+{
+	struct dlist_entry *item;
+
+	fastlock_acquire(&list->lock);
+	item = dlist_remove_first_match(head, match, arg);
+	fastlock_release(&list->lock);
+
+	return item;
+}
+
+#define dlist_ts_splice_head(list, head, to_splice)	\
+	{						\
+		fastlock_acquire(&(list)->lock);	\
+		dlist_splice_head(head, to_splice);	\
+		fastlock_release(&list->lock);		\
+	} while(0)
+
+#define dlist_ts_splice_tail(list, head, to_splice)		\
+	{							\
+		dlist_ts_splice_head(head->prev, to_splice);	\
+	} while(0)
+
 /*
  * Single-linked list
  */
@@ -258,6 +436,17 @@ static inline struct slist_entry *slist_remove_head(struct slist *list)
 			(prev) = (item), (item) = (item)->next)
 
 
+#define slist_remove_head_container(list, type, container, member)	\
+	do {								\
+		if (slist_empty(list)) {				\
+			container = NULL;				\
+		} else {						\
+			container = container_of((list)->head, type,    \
+					member);			\
+			slist_remove_head(list);			\
+		}							\
+	} while (0)
+
 typedef int slist_func_t(struct slist_entry *item, const void *arg);
 
 static inline struct slist_entry *
@@ -273,6 +462,26 @@ slist_find_first_match(const struct slist *list, slist_func_t *match,
 	return NULL;
 }
 
+static inline void
+slist_insert_before_first_match(struct slist *list, slist_func_t *match,
+				struct slist_entry *entry)
+{
+	struct slist_entry *cur, *prev;
+
+	slist_foreach(list, cur, prev) {
+		if (match(cur, entry)) {
+			if (!prev) {
+				slist_insert_head(entry, list);
+			} else {
+				entry->next = prev->next;
+				prev->next = entry;
+			}
+			return;
+		}
+	}
+	slist_insert_tail(entry, list);
+}
+
 static inline void slist_remove(struct slist *list,
 		struct slist_entry *item, struct slist_entry *prev)
 {
@@ -300,6 +509,139 @@ slist_remove_first_match(struct slist *list, slist_func_t *match, const void *ar
 	return NULL;
 }
 
+static inline void slist_swap(struct slist *dst, struct slist *src)
+{
+	struct slist_entry *dst_head = dst->head;
+	struct slist_entry *dst_tail = dst->tail;
+
+	dst->head = src->head;
+	dst->tail = src->tail;
+
+	src->head = dst_head;
+	src->tail = dst_tail;
+}
+
+/* splices src list at the front of the dst list
+ *
+ * BEFORE:
+ * dst: HEAD->a->b->c->TAIL
+ * src: HEAD->d->e->TAIL
+ *
+ * AFTER:
+ * dst: HEAD->d->e->a->b->c->TAIL
+ * src: HEAD->TAIL (empty list)
+ */
+static inline struct slist *
+slist_splice_head(struct slist *dst, struct slist *src)
+{
+	if (slist_empty(src))
+		return dst;
+
+	if (slist_empty(dst)) {
+		slist_swap(dst, src);
+		return dst;
+	}
+
+	src->tail->next = dst->head;
+	dst->head = src->head;
+
+	slist_init(src);
+
+	return dst;
+}
+
+/* splices src list at the back of the dst list
+ *
+ * BEFORE:
+ * dst: HEAD->a->b->c->TAIL
+ * src: HEAD->d->e->TAIL
+ *
+ * AFTER:
+ * dst: HEAD->a->b->c->d->e->TAIL
+ * src: HEAD->TAIL (empty list)
+ */
+static inline struct slist *
+slist_splice_tail(struct slist *dst, struct slist *src)
+{
+	if (slist_empty(src))
+		return dst;
+
+	if (slist_empty(dst)) {
+		slist_swap(dst, src);
+		return dst;
+	}
+
+	dst->tail->next = src->head;
+	dst->tail = src->tail;
+
+	slist_init(src);
+
+	return dst;
+}
+
+/*
+ * Singly-linked list with blocking wait-until-avail support
+ */
+
+struct slistfd {
+	struct slist 		list;
+	struct fd_signal	signal;
+};
+
+static inline int slistfd_init(struct slistfd *list)
+{
+	slist_init(&list->list);
+	return fd_signal_init(&list->signal);
+}
+
+static inline void slistfd_free(struct slistfd *list)
+{
+	fd_signal_free(&list->signal);
+}
+
+static inline int slistfd_empty(struct slistfd *list)
+{
+	return slist_empty(&list->list);
+}
+
+static inline void
+slistfd_insert_head(struct slist_entry *item, struct slistfd *list)
+{
+	slist_insert_head(item, &list->list);
+	fd_signal_set(&list->signal);
+}
+
+static inline void
+slistfd_insert_tail(struct slist_entry *item, struct slistfd *list)
+{
+	slist_insert_tail(item, &list->list);
+	fd_signal_set(&list->signal);
+}
+
+static inline struct slist_entry *slistfd_remove_head(struct slistfd *list)
+{
+	struct slist_entry *entry = slist_remove_head(&list->list);
+	if (entry)
+		fd_signal_reset(&list->signal);
+	return entry;
+}
+
+static inline int slistfd_wait_avail(struct slistfd *list, int timeout)
+{
+	int ret;
+
+	if (!slistfd_empty(list))
+		return 1;
+
+	ret = fd_signal_poll(&list->signal, timeout);
+	return ret ? ret : !slistfd_empty(list);
+}
+
+static inline int slistfd_get_fd(struct slistfd *list)
+{
+	return fd_signal_get(&list->signal);
+}
+
 /*
  * Double-linked list with blocking wait-until-avail support
  */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_lock.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_lock.h
index 9fc7f400a..afde786b0 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_lock.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_lock.h
@@ -76,6 +76,7 @@ int fi_wait_cond(pthread_cond_t *cond, pthread_mutex_t *mut, int timeout_ms);
 typedef struct {
 	fastlock_t_ impl;
 	int is_initialized;
+	int in_use;
 } fastlock_t;
 
 static inline int fastlock_init(fastlock_t *lock)
@@ -84,6 +85,8 @@ static inline int fastlock_init(fastlock_t *lock)
 
 	ret = fastlock_init_(&lock->impl);
 	lock->is_initialized = !ret;
+	lock->in_use = 0;
+
 	return ret;
 }
 
@@ -104,19 +107,28 @@ static inline void fastlock_acquire(fastlock_t *lock)
 	assert(lock->is_initialized);
 	ret = fastlock_acquire_(&lock->impl);
 	assert(!ret);
+	lock->in_use++;
 }
 
 static inline int fastlock_tryacquire(fastlock_t *lock)
 {
+	int ret;
+
 	assert(lock->is_initialized);
-	return fastlock_tryacquire_(&lock->impl);
+	ret = fastlock_tryacquire_(&lock->impl);
+	if (!ret)
+		lock->in_use++;
+
+	return ret;
 }
 
 static inline void fastlock_release(fastlock_t *lock)
 {
 	int ret;
 
+	assert(lock->in_use);
 	assert(lock->is_initialized);
+	lock->in_use--;
 	ret = fastlock_release_(&lock->impl);
 	assert(!ret);
 }
@@ -132,7 +144,32 @@ static inline void fastlock_release(fastlock_t *lock)
 
 #endif
 
+typedef void(*ofi_fastlock_acquire_t)(fastlock_t *lock);
+typedef void(*ofi_fastlock_release_t)(fastlock_t *lock);
 
+static inline void ofi_fastlock_acquire(fastlock_t *lock)
+{
+	fastlock_acquire(lock);
+}
+static inline void ofi_fastlock_release(fastlock_t *lock)
+{
+	fastlock_release(lock);
+}
+static inline void ofi_fastlock_acquire_noop(fastlock_t *lock)
+{
+#if ENABLE_DEBUG
+	/* These non-op routines must be used only by a single-threaded code*/
+	assert(!lock->in_use);
+	lock->in_use = 1;
+#endif
+}
+static inline void ofi_fastlock_release_noop(fastlock_t *lock)
+{
+#if ENABLE_DEBUG
+	assert(lock->in_use);
+	lock->in_use = 0;
+#endif
+}
 
 #ifdef __cplusplus
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_mem.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_mem.h
index 93c87ee50..abe2104aa 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_mem.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_mem.h
@@ -1,5 +1,6 @@
 /*
  * Copyright (c) 2015-2016 Intel Corporation, Inc.  All rights reserved.
+ * Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -63,12 +64,34 @@ static inline void *mem_dup(const void *src, size_t size)
 	return dest;
 }
 
+static inline int ofi_str_dup(const char *src, char **dst)
+{
+	if (src) {
+		*dst = strdup(src);
+		if (!*dst)
+			return -FI_ENOMEM;
+	} else {
+		*dst = NULL;
+	}
+	return 0;
+}
 
 /*
  * Buffer pool (free stack) template
  */
 #define FREESTACK_EMPTY	NULL
 
+#define freestack_get_next(user_buf)	((char *)user_buf - sizeof(void *))
+#define freestack_get_user_buf(entry)	((char *)entry + sizeof(void *))
+
+#if ENABLE_DEBUG
+#define freestack_init_next(entry)	*((void **)entry) = NULL
+#define freestack_check_next(entry)	assert(*((void **)entry) == NULL)
+#else
+#define freestack_init_next(entry)
+#define freestack_check_next(entry)
+#endif
+
 #define FREESTACK_HEADER 					\
 	size_t		size;					\
 	void		*next;					\
@@ -76,8 +99,9 @@ static inline void *mem_dup(const void *src, size_t size)
 #define freestack_isempty(fs)	((fs)->next == FREESTACK_EMPTY)
 #define freestack_push(fs, p)					\
 do {								\
-	*(void **) p = (fs)->next;				\
-	(fs)->next = p;						\
+	freestack_check_next(freestack_get_next(p));		\
+	*(void **) (freestack_get_next(p)) = (fs)->next;	\
+	(fs)->next = (freestack_get_next(p));			\
 } while (0)
 #define freestack_pop(fs) freestack_pop_impl(fs, (fs)->next)
 
@@ -88,40 +112,59 @@ static inline void* freestack_pop_impl(void *fs, void *fs_next)
 	} *freestack = fs;
 	assert(!freestack_isempty(freestack));
 	freestack->next = *((void **)fs_next);
-	return fs_next;
+	freestack_init_next(fs_next);
+	return freestack_get_user_buf(fs_next);
 }
 
 #define DECLARE_FREESTACK(entrytype, name)			\
+struct name ## _entry {						\
+	void		*next;					\
+	entrytype	buf;					\
+};								\
 struct name {							\
 	FREESTACK_HEADER					\
-	entrytype	buf[];					\
+	struct name ## _entry	entry[];			\
 };								\
 								\
-static inline void name ## _init(struct name *fs, size_t size)	\
+typedef void (*name ## _entry_init_func)(entrytype *buf,	\
+					 void *arg);		\
+								\
+static inline void						\
+name ## _init(struct name *fs, size_t size,			\
+	      name ## _entry_init_func init, void *arg)		\
 {								\
 	ssize_t i;						\
 	assert(size == roundup_power_of_two(size));		\
-	assert(sizeof(fs->buf[0]) >= sizeof(void *));		\
+	assert(sizeof(fs->entry[0].buf) >= sizeof(void *));	\
 	fs->size = size;					\
 	fs->next = FREESTACK_EMPTY;				\
-	for (i = size - 1; i >= 0; i--)				\
-		freestack_push(fs, &fs->buf[i]);		\
+	for (i = size - 1; i >= 0; i--) {			\
+		if (init)					\
+			init(&fs->entry[i].buf, arg);		\
+		freestack_push(fs, &fs->entry[i].buf);		\
+	}							\
 }								\
 								\
-static inline struct name * name ## _create(size_t size)	\
+static inline struct name *					\
+name ## _create(size_t size, name ## _entry_init_func init,	\
+		void *arg)					\
 {								\
 	struct name *fs;					\
-	fs = calloc(1, sizeof(*fs) + sizeof(entrytype) *	\
-		    (roundup_power_of_two(size)));		\
+	fs = calloc(1, sizeof(*fs) +				\
+		       sizeof(struct name ## _entry) *		\
+		       (roundup_power_of_two(size)));		\
 	if (fs)							\
-		name ##_init(fs, roundup_power_of_two(size));	\
+		name ##_init(fs, roundup_power_of_two(size),	\
+			     init, arg);			\
 	return fs;						\
 }								\
 								\
 static inline int name ## _index(struct name *fs,		\
-		entrytype *entry)				\
+				 entrytype *entry)		\
 {								\
-	return (int)(entry - fs->buf);				\
+	return (int)((struct name ## _entry *)			\
+			(freestack_get_next(entry))		\
+			- (struct name ## _entry *)fs->entry);	\
 }								\
 								\
 static inline void name ## _free(struct name *fs)		\
@@ -142,8 +185,10 @@ static inline void name ## _free(struct name *fs)		\
 #define smr_freestack_isempty(fs)	((fs)->next == SMR_FREESTACK_EMPTY)
 #define smr_freestack_push(fs, local_p)				\
 do {								\
-	void *p = (char **) fs->base_addr + ((char **) local_p - (char **) fs); \
-	*(void **) local_p = (fs)->next;				\
+	void *p = (char **) fs->base_addr +			\
+	    ((char **) freestack_get_next(local_p) -		\
+		(char **) fs);					\
+	*(void **) freestack_get_next(local_p) = (fs)->next;	\
 	(fs)->next = p;						\
 } while (0)
 #define smr_freestack_pop(fs) smr_freestack_pop_impl(fs, fs->next)
@@ -160,25 +205,29 @@ static inline void* smr_freestack_pop_impl(void *fs, void *next)
 	local = (char **) fs + ((char **) next -
 		(char **) freestack->base_addr);
 	next = *((void **) local);
-	return local;
+	return freestack_get_user_buf(local);
 }
 
 #define DECLARE_SMR_FREESTACK(entrytype, name)			\
+struct name ## _entry {						\
+	void		*next;					\
+	entrytype	buf;					\
+};								\
 struct name {							\
 	SMR_FREESTACK_HEADER					\
-	entrytype	buf[];					\
+	struct name ## _entry	entry[];			\
 };								\
 								\
 static inline void name ## _init(struct name *fs, size_t size)	\
 {								\
 	ssize_t i;						\
 	assert(size == roundup_power_of_two(size));		\
-	assert(sizeof(fs->buf[0]) >= sizeof(void *));		\
+	assert(sizeof(fs->entry[0].buf) >= sizeof(void *));	\
 	fs->size = size;					\
 	fs->next = SMR_FREESTACK_EMPTY;				\
 	fs->base_addr = fs;					\
 	for (i = size - 1; i >= 0; i--)				\
-		smr_freestack_push(fs, &fs->buf[i]);		\
+		smr_freestack_push(fs, &fs->entry[i].buf);	\
 }								\
 								\
 static inline struct name * name ## _create(size_t size)	\
@@ -194,7 +243,9 @@ static inline struct name * name ## _create(size_t size)	\
 static inline int name ## _index(struct name *fs,		\
 		entrytype *entry)				\
 {								\
-	return (int)(entry - fs->buf);				\
+	return (int)((struct name ## _entry *)			\
+			(freestack_get_next(entry))		\
+			- (struct name ## _entry *)fs->entry);	\
 }								\
 								\
 static inline void name ## _free(struct name *fs)		\
@@ -206,45 +257,72 @@ static inline void name ## _free(struct name *fs)		\
 /*
  * Buffer Pool
  */
+
+#define UTIL_BUF_POOL_REGION_CHUNK_CNT	16
+
 struct util_buf_pool;
 typedef int (*util_buf_region_alloc_hndlr) (void *pool_ctx, void *addr, size_t len,
 					    void **context);
 typedef void (*util_buf_region_free_hndlr) (void *pool_ctx, void *context);
+typedef void (*util_buf_region_init_func) (void *pool_ctx, void *buf);
+
+struct util_buf_attr {
+	size_t 				size;
+	size_t 				alignment;
+	size_t	 			max_cnt;
+	size_t 				chunk_cnt;
+	util_buf_region_alloc_hndlr 	alloc_hndlr;
+	util_buf_region_free_hndlr 	free_hndlr;
+	util_buf_region_init_func 	init;
+	void 				*ctx;
+	uint8_t				track_used;
+	uint8_t				is_mmap_region;
+	struct {
+		uint8_t			used;
+		/* if the `ordered` capability is used, the buffer
+		 * with the lowest index is returned */
+		uint8_t			ordered;
+	} indexing;
+};
 
 struct util_buf_pool {
-	size_t data_sz;
-	size_t entry_sz;
-	size_t max_cnt;
-	size_t chunk_cnt;
-	size_t alignment;
-	size_t num_allocated;
-	struct slist buf_list;
-	struct slist region_list;
-	util_buf_region_alloc_hndlr alloc_hndlr;
-	util_buf_region_free_hndlr free_hndlr;
-	void *ctx;
+	size_t 			entry_sz;
+	size_t 			num_allocated;
+	union {
+		struct slist		buffers;
+		struct dlist_entry	regions;
+	} list;
+	struct util_buf_region	**regions_table;
+	size_t			regions_cnt;
+	struct util_buf_attr	attr;
 };
 
 struct util_buf_region {
-	struct slist_entry entry;
+	struct dlist_entry entry;
+	struct dlist_entry buf_list;
 	char *mem_region;
+	size_t size;
 	void *context;
-#if ENABLE_DEBUG
+	struct util_buf_pool *pool;
+#ifndef NDEBUG
 	size_t num_used;
 #endif
 };
 
 struct util_buf_footer {
+	union {
+		struct slist_entry slist;
+		struct dlist_entry dlist;
+	} entry;
 	struct util_buf_region *region;
+	size_t index;
 };
 
-union util_buf {
-	struct slist_entry entry;
-	uint8_t data[0];
-};
+int util_buf_pool_create_attr(struct util_buf_attr *attr,
+			      struct util_buf_pool **buf_pool);
 
 /* create buffer pool with alloc/free handlers */
-int util_buf_pool_create_ex(struct util_buf_pool **pool,
+int util_buf_pool_create_ex(struct util_buf_pool **buf_pool,
 			    size_t size, size_t alignment,
 			    size_t max_cnt, size_t chunk_cnt,
 			    util_buf_region_alloc_hndlr alloc_hndlr,
@@ -261,91 +339,144 @@ static inline int util_buf_pool_create(struct util_buf_pool **pool,
 				       NULL, NULL, NULL);
 }
 
-static inline int util_buf_avail(struct util_buf_pool *pool)
-{
-	return !slist_empty(&pool->buf_list);
-}
-
 int util_buf_grow(struct util_buf_pool *pool);
 
-#if ENABLE_DEBUG
-
-void *util_buf_get(struct util_buf_pool *pool);
-void util_buf_release(struct util_buf_pool *pool, void *buf);
+static inline struct util_buf_footer *
+util_buf_get_ftr(struct util_buf_pool *pool, void *buf)
+{
+	return (struct util_buf_footer *) ((char *) buf + pool->attr.size);
+}
 
-#else
+static inline void *util_buf_get_data(struct util_buf_pool *pool,
+			       struct util_buf_footer *buf_ftr)
+{
+	return ((char *) buf_ftr - pool->attr.size);
+}
 
 static inline void *util_buf_get(struct util_buf_pool *pool)
 {
-	struct slist_entry *entry;
-	entry = slist_remove_head(&pool->buf_list);
-	return entry;
+	struct util_buf_footer *buf_ftr;
+
+	assert(!pool->attr.indexing.ordered);
+
+	slist_remove_head_container(&pool->list.buffers, struct util_buf_footer,
+				    buf_ftr, entry.slist);
+	assert(++buf_ftr->region->num_used);
+	return util_buf_get_data(pool, buf_ftr);
 }
 
 static inline void util_buf_release(struct util_buf_pool *pool, void *buf)
 {
-	union util_buf *util_buf = buf;
-	slist_insert_head(&util_buf->entry, &pool->buf_list);
+	assert(util_buf_get_ftr(pool, buf)->region->num_used--);
+	assert(!pool->attr.indexing.ordered);
+	slist_insert_head(&util_buf_get_ftr(pool, buf)->entry.slist, &pool->list.buffers);
 }
-#endif
 
-static inline void *util_buf_get_ex(struct util_buf_pool *pool, void **context)
+static inline void *util_buf_indexed_get(struct util_buf_pool *pool)
 {
-	union util_buf *buf;
 	struct util_buf_footer *buf_ftr;
-
-	buf = util_buf_get(pool);
-	buf_ftr = (struct util_buf_footer *) ((char *) buf + pool->data_sz);
-	assert(context);
-	*context = buf_ftr->region->context;
-	return buf;
+	struct util_buf_region *buf_region;
+
+	assert(pool->attr.indexing.ordered);
+
+	buf_region = container_of(pool->list.regions.next,
+				  struct util_buf_region, entry);
+	dlist_pop_front(&buf_region->buf_list, struct util_buf_footer,
+			buf_ftr, entry.dlist);
+	assert(++buf_ftr->region->num_used);
+	if (dlist_empty(&buf_region->buf_list))
+		dlist_remove_init(&buf_region->entry);
+	return util_buf_get_data(pool, buf_ftr);
 }
 
-static inline void *util_buf_alloc(struct util_buf_pool *pool)
+int util_buf_is_lower(struct dlist_entry *item, const void *arg);
+int util_buf_region_is_lower(struct dlist_entry *item, const void *arg);
+
+static inline void util_buf_indexed_release(struct util_buf_pool *pool, void *buf)
 {
-	if (!util_buf_avail(pool)) {
-		if (util_buf_grow(pool))
-			return NULL;
+	struct util_buf_footer *buf_ftr;
+
+	assert(pool->attr.indexing.ordered);
+
+	buf_ftr = util_buf_get_ftr(pool, buf);
+
+	assert(buf_ftr->region->num_used--);
+
+	dlist_insert_order(&buf_ftr->region->buf_list,
+			   util_buf_is_lower, &buf_ftr->entry.dlist);
+
+	if (dlist_empty(&buf_ftr->region->entry)) {
+		dlist_insert_order(&pool->list.regions,
+				   util_buf_region_is_lower,
+				   &buf_ftr->region->entry);
 	}
-	return util_buf_get(pool);
 }
 
-static inline void *util_buf_alloc_ex(struct util_buf_pool *pool, void **context)
+static inline size_t util_get_buf_index(struct util_buf_pool *pool, void *buf)
 {
-	union util_buf *buf;
-	struct util_buf_footer *buf_ftr;
-
-	buf = util_buf_alloc(pool);
-	if (OFI_UNLIKELY(!buf))
-		return NULL;
+	assert(util_buf_get_ftr(pool, buf)->region->num_used);
+	assert(pool->attr.indexing.used);
+	return util_buf_get_ftr(pool, buf)->index;
+}
 
-	buf_ftr = (struct util_buf_footer *) ((char *) buf + pool->data_sz);
-	assert(context);
-	*context = buf_ftr->region->context;
+static inline void *util_buf_get_by_index(struct util_buf_pool *pool, size_t index)
+{
+	void *buf;
+	assert(pool->attr.indexing.used);
+	buf = pool->regions_table[(size_t)(index / pool->attr.chunk_cnt)]->
+		mem_region + (index % pool->attr.chunk_cnt) * pool->entry_sz;
+	assert(util_buf_get_ftr(pool, buf)->region->num_used);
 	return buf;
 }
 
-#if ENABLE_DEBUG
-static inline int util_buf_use_ftr(struct util_buf_pool *pool)
+static inline void *util_buf_get_ctx(struct util_buf_pool *pool, void *buf)
 {
-	OFI_UNUSED(pool);
-	return 1;
+	return util_buf_get_ftr(pool, buf)->region->context;
 }
-#else
-static inline int util_buf_use_ftr(struct util_buf_pool *pool)
+
+static inline int util_buf_avail(struct util_buf_pool *pool)
 {
-	return (pool->alloc_hndlr || pool->free_hndlr) ? 1 : 0;
+	return !slist_empty(&pool->list.buffers);
 }
-#endif
 
-static inline void *util_buf_get_ctx(struct util_buf_pool *pool, void *buf)
+static inline int util_buf_indexed_avail(struct util_buf_pool *pool)
 {
-	struct util_buf_footer *buf_ftr;
-	assert(util_buf_use_ftr(pool));
-	buf_ftr = (struct util_buf_footer *) ((char *) buf + pool->data_sz);
-	return buf_ftr->region->context;
+	return !dlist_empty(&pool->list.regions);
+}
+
+#define UTIL_BUF_DEFINE_GETTERS(name)						\
+static inline void *util_buf ## name ## get_ex(struct util_buf_pool *pool,	\
+					       void **context)			\
+{										\
+	void *buf = util_buf ## name ## get(pool);				\
+	assert(context);							\
+	*context = util_buf_get_ctx(pool, buf);					\
+	return buf;								\
+}										\
+										\
+static inline void *util_buf ## name ## alloc(struct util_buf_pool *pool)	\
+{										\
+	if (OFI_UNLIKELY(!util_buf ## name ## avail(pool))) {			\
+		if (util_buf_grow(pool))					\
+			return NULL;						\
+	}									\
+	return util_buf ## name ## get(pool);					\
+}										\
+										\
+static inline void *util_buf ## name ## alloc_ex(struct util_buf_pool *pool,	\
+						 void **context)		\
+{										\
+	void *buf = util_buf ## name ## alloc(pool);				\
+	if (OFI_UNLIKELY(!buf))							\
+		return NULL;							\
+	assert(context);							\
+	*context = util_buf_get_ctx(pool, buf);					\
+	return buf;								\
 }
 
+UTIL_BUF_DEFINE_GETTERS(_);
+UTIL_BUF_DEFINE_GETTERS(_indexed_);
+
 void util_buf_pool_destroy(struct util_buf_pool *pool);
 
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_mr.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_mr.h
index 05c156871..4cd05d984 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_mr.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_mr.h
@@ -51,10 +51,23 @@
 
 /* FI_LOCAL_MR is valid in pre-libfaric-1.5 and can be valid in
  * post-libfabric-1.5 */
-#define OFI_CHECK_MR_LOCAL(info)						\
-	((info->domain_attr->mr_mode & FI_MR_LOCAL) ||				\
-	 (!(info->domain_attr->mr_mode & ~(FI_MR_BASIC | FI_MR_SCALABLE)) &&	\
-	  (info->mode & FI_LOCAL_MR)))
+static inline int ofi_mr_local(const struct fi_info *info)
+{
+	if (!info)
+		return 0;
+
+	if (!info->domain_attr)
+		goto check_local_mr;
+
+	if (info->domain_attr->mr_mode & FI_MR_LOCAL)
+		return 1;
+
+	if (info->domain_attr->mr_mode & ~(FI_MR_BASIC | FI_MR_SCALABLE))
+		return 0;
+
+check_local_mr:
+	return (info->mode & FI_LOCAL_MR) ? 1 : 0;
+}
 
 #define OFI_MR_MODE_RMA_TARGET (FI_MR_RAW | FI_MR_VIRT_ADDR |			\
 				 FI_MR_PROV_KEY | FI_MR_RMA_EVENT)
@@ -88,11 +101,10 @@ struct ofi_notification_queue;
 struct ofi_mem_monitor {
 	ofi_atomic32_t			refcnt;
 
-	int (*subscribe)(struct ofi_mem_monitor *notifier, void *addr,
-			 size_t len, struct ofi_subscription *subscription);
-	void (*unsubscribe)(struct ofi_mem_monitor *notifier, void *addr,
-			    size_t len, struct ofi_subscription *subscription);
-	struct ofi_subscription *(*get_event)(struct ofi_mem_monitor *notifier);
+	int (*subscribe)(struct ofi_mem_monitor *notifier,
+			 struct ofi_subscription *subscription);
+	void (*unsubscribe)(struct ofi_mem_monitor *notifier,
+			    struct ofi_subscription *subscription);
 };
 
 struct ofi_notification_queue {
@@ -105,8 +117,7 @@ struct ofi_notification_queue {
 struct ofi_subscription {
 	struct ofi_notification_queue	*nq;
 	struct dlist_entry		entry;
-	void				*addr;
-	size_t				len;
+	struct iovec			iov;
 };
 
 void ofi_monitor_init(struct ofi_mem_monitor *monitor);
@@ -120,7 +131,19 @@ int ofi_monitor_subscribe(struct ofi_notification_queue *nq,
 			  struct ofi_subscription *subscription);
 void ofi_monitor_unsubscribe(struct ofi_subscription *subscription);
 struct ofi_subscription *ofi_monitor_get_event(struct ofi_notification_queue *nq);
-
+static inline void
+ofi_monitor_add_event_to_nq(struct ofi_subscription *subscription)
+{
+	FI_DBG(&core_prov, FI_LOG_MR,
+	       "Add event to NQ, context=%p, addr=%p, len=%"PRIu64" nq=%p\n",
+	       subscription, subscription->iov.iov_base,
+	       subscription->iov.iov_len, subscription->nq);
+	fastlock_acquire(&subscription->nq->lock);
+	if (dlist_empty(&subscription->entry))
+		dlist_insert_tail(&subscription->entry,
+				  &subscription->nq->list);
+	fastlock_release(&subscription->nq->lock);
+}
 
 /*
  * MR map
@@ -181,6 +204,32 @@ struct ofi_mr_entry {
 	uint8_t				data[];
 };
 
+struct ofi_mr_storage;
+
+typedef void (*ofi_mr_destroy_t)(struct ofi_mr_storage *storage);
+typedef struct ofi_mr_entry *(*ofi_mr_find_t)(struct ofi_mr_storage *storage,
+					      const struct iovec *key);
+typedef int (*ofi_mr_insert_t)(struct ofi_mr_storage *storage,
+			       struct iovec *key,
+			       struct ofi_mr_entry *entry);
+typedef int (*ofi_mr_erase_t)(struct ofi_mr_storage *storage,
+			      struct ofi_mr_entry *entry);
+
+enum ofi_mr_storage_type {
+	OFI_MR_STORAGE_DEFAULT = 0,
+	OFI_MR_STORAGE_RBT,
+	OFI_MR_STORAGE_USER,
+};
+
+struct ofi_mr_storage {
+	enum ofi_mr_storage_type type;
+	void *storage;
+	ofi_mr_destroy_t destroy;
+	ofi_mr_find_t find;
+	ofi_mr_insert_t insert;
+	ofi_mr_erase_t erase;
+};
+
 struct ofi_mr_cache {
 	struct util_domain		*domain;
 	struct ofi_notification_queue	nq;
@@ -189,7 +238,7 @@ struct ofi_mr_cache {
 	int				merge_regions;
 	size_t				entry_data_size;
 
-	RbtHandle			mr_tree;
+	struct ofi_mr_storage		mr_storage;
 	struct dlist_entry		lru_list;
 
 	size_t				cached_cnt;
@@ -197,6 +246,7 @@ struct ofi_mr_cache {
 	size_t				search_cnt;
 	size_t				delete_cnt;
 	size_t				hit_cnt;
+	struct util_buf_pool		*entry_pool;
 
 	int				(*add_region)(struct ofi_mr_cache *cache,
 						      struct ofi_mr_entry *entry);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_net.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_net.h
index d962bb336..dbb8cb5fd 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_net.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_net.h
@@ -105,12 +105,17 @@ static inline int ofi_sendall_socket(SOCKET sock, const void *buf, size_t len)
 	size_t sent;
 	ssize_t ret;
 
-	for (sent = 0, ret = 0; (sent < len) && (ret >= 0); sent += ret)
+	for (sent = 0, ret = 0; (sent < len) && (ret >= 0); ) {
 		ret = ofi_send_socket(sock, ((char *) buf) + sent, len - sent, 0);
+		if (ret > 0)
+			sent += ret;
+	}
 
-	return (size_t) ret != len;
+	return (size_t) sent != len;
 }
 
+int ofi_discard_socket(SOCKET sock, size_t len);
+
 /*
  * Address utility functions
  */
@@ -119,6 +124,13 @@ static inline int ofi_sendall_socket(SOCKET sock, const void *buf, size_t len)
 #define AF_IB 27
 #endif
 
+union ofi_sock_ip {
+	struct sockaddr		sa;
+	struct sockaddr_in	sin;
+	struct sockaddr_in6	sin6;
+	uint8_t			align[32];
+};
+
 int ofi_addr_cmp(const struct fi_provider *prov, const struct sockaddr *sa1,
 		const struct sockaddr *sa2);
 int ofi_getifaddrs(struct ifaddrs **ifap);
@@ -141,22 +153,21 @@ static inline size_t ofi_sizeofaddr(const struct sockaddr *addr)
 		return sizeof(struct sockaddr_in6);
 	default:
 		FI_WARN(&core_prov, FI_LOG_CORE, "Unknown address format");
-		assert(0);
 		return 0;
 	}
 }
 
-static inline int ofi_equals_ipaddr(const struct sockaddr_in *addr1,
-				    const struct sockaddr_in *addr2)
+static inline size_t ofi_sizeofip(const struct sockaddr *addr)
 {
-        return (addr1->sin_addr.s_addr == addr2->sin_addr.s_addr);
-}
-
-static inline int ofi_equals_sockaddr(const struct sockaddr_in *addr1,
-				      const struct sockaddr_in *addr2)
-{
-        return (ofi_equals_ipaddr(addr1, addr2) &&
-	       (addr1->sin_port == addr2->sin_port));
+	switch (addr->sa_family) {
+	case AF_INET:
+		return sizeof(struct in_addr);
+	case AF_INET6:
+		return sizeof(struct in6_addr);
+	default:
+		FI_WARN(&core_prov, FI_LOG_CORE, "Unknown address format");
+		return 0;
+	}
 }
 
 static inline int ofi_translate_addr_format(int family)
@@ -173,19 +184,7 @@ static inline int ofi_translate_addr_format(int family)
 	}
 }
 
-static inline int ofi_get_sa_family(uint32_t addr_format)
-{
-	switch (addr_format) {
-	case FI_SOCKADDR_IN:
-		return AF_INET;
-	case FI_SOCKADDR_IN6:
-		return AF_INET6;
-	case FI_SOCKADDR_IB:
-		return AF_IB;
-	default:
-		return 0;
-	}
-}
+uint16_t ofi_get_sa_family(const struct fi_info *info);
 
 static inline int ofi_ipv4_is_any_addr(struct sockaddr *sa)
 {
@@ -226,16 +225,16 @@ static inline int ofi_is_any_addr(struct sockaddr *sa)
 	}
 }
 
-static inline uint16_t ofi_addr_get_port(struct sockaddr *addr)
+static inline uint16_t ofi_addr_get_port(const struct sockaddr *addr)
 {
 	if (!addr)
 		return 0;
 
 	switch (ofi_sa_family(addr)) {
 	case AF_INET:
-		return ntohs(ofi_sin_port(addr));
+		return ntohs(ofi_sin_port((const struct sockaddr_in *) addr));
 	case AF_INET6:
-		return ntohs(ofi_sin6_port(addr));
+		return ntohs(ofi_sin6_port((const struct sockaddr_in6 *) addr));
 	default:
 		FI_WARN(&core_prov, FI_LOG_FABRIC, "Unknown address format\n");
 		assert(0);
@@ -258,9 +257,50 @@ static inline void ofi_addr_set_port(struct sockaddr *addr, uint16_t port)
 	}
 }
 
+static inline void * ofi_get_ipaddr(const struct sockaddr *addr)
+{
+	switch (addr->sa_family) {
+	case AF_INET:
+		return &ofi_sin_addr((const struct sockaddr_in *) addr);
+	case AF_INET6:
+		return &ofi_sin6_addr((const struct sockaddr_in6 *) addr);
+	default:
+		return NULL;
+	}
+}
+
+static inline int ofi_equals_ipaddr(const struct sockaddr *addr1,
+				    const struct sockaddr *addr2)
+{
+	if (addr1->sa_family != addr2->sa_family)
+		return 0;
+
+	switch (addr1->sa_family) {
+	case AF_INET:
+	        return !memcmp(&ofi_sin_addr(addr1), &ofi_sin_addr(addr2),
+				sizeof(ofi_sin_addr(addr1)));
+	case AF_INET6:
+	        return !memcmp(&ofi_sin6_addr(addr1), &ofi_sin6_addr(addr2),
+				sizeof(ofi_sin6_addr(addr1)));
+	default:
+		return 0;
+	}
+}
+
+static inline int ofi_equals_sockaddr(const struct sockaddr *addr1,
+				      const struct sockaddr *addr2)
+{
+        return (ofi_addr_get_port(addr1) == ofi_addr_get_port(addr2)) &&
+		ofi_equals_ipaddr(addr1, addr2);
+}
+
 int ofi_is_wildcard_listen_addr(const char *node, const char *service,
 				uint64_t flags, const struct fi_info *hints);
 
+size_t ofi_mask_addr(struct sockaddr *maskaddr, const struct sockaddr *srcaddr,
+		     const struct sockaddr *netmask);
+
+
 /*
  * Address logging
  */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_osd.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_osd.h
index 432d80960..97be08b7b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_osd.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_osd.h
@@ -33,6 +33,7 @@
 #ifndef _OFI_OSD_H_
 #define _OFI_OSD_H_
 
+#include <stdint.h>
 
 /* We use macros to create atomic and complex function definitions,
  * and we can't have spaces in function names */
@@ -76,4 +77,34 @@ typedef long double long_double;
 #define OFI_UNLIKELY(x)	(x)
 #endif
 
+enum {
+	OFI_ENDIAN_UNKNOWN,
+	OFI_ENDIAN_BIG,
+	OFI_ENDIAN_LITTLE,
+	OFI_ENDIAN_BIG_WORD,	/* Middle-endian, Honeywell 316 style */
+	OFI_ENDIAN_LITTLE_WORD,	/* Middle-endian, PDP-11 style */
+};
+
+static inline int ofi_detect_endianness(void)
+{
+	union {
+		uint8_t data[sizeof(uint32_t)];
+		uint32_t value;
+	} checker = {
+		.data = { 0x00, 0x01, 0x02, 0x03 },
+	};
+	switch (checker.value) {
+	case 0x00010203UL:
+		return OFI_ENDIAN_BIG;
+	case 0x03020100UL:
+		return OFI_ENDIAN_LITTLE;
+	case 0x02030001UL:
+		return OFI_ENDIAN_BIG_WORD;
+	case 0x01000302UL:
+		return OFI_ENDIAN_LITTLE_WORD;
+	default:
+		return OFI_ENDIAN_UNKNOWN;
+	}
+}
+
 #endif /* _OFI_OSD_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_perf.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_perf.h
index 64c4ac178..617d6798f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_perf.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_perf.h
@@ -35,6 +35,7 @@
 
 #include "config.h"
 
+#include <assert.h>
 #include <string.h>
 #include <ofi_osd.h>
 #include <rdma/providers/fi_prov.h>
@@ -83,6 +84,12 @@ struct ofi_perf_data {
 };
 
 
+void ofi_perf_init(void);
+extern enum ofi_perf_domain	perf_domain;
+extern uint32_t			perf_cntr;
+extern uint32_t			perf_flags;
+
+
 /*
  * Performance management unit:
  *
@@ -147,9 +154,7 @@ static inline void ofi_perf_end(struct ofi_perf_ctx *ctx,
 
 struct ofi_perfset {
 	const struct fi_provider *prov;
-	char			**names;
 	size_t			size;
-	size_t			count;
 	struct ofi_perf_ctx	*ctx;
 	struct ofi_perf_data	*data;
 };
@@ -160,9 +165,19 @@ int ofi_perfset_create(const struct fi_provider *prov,
 		       uint32_t flags);
 void ofi_perfset_close(struct ofi_perfset *set);
 
-struct ofi_perf_data *ofi_perfset_data(struct ofi_perfset *set,
-				       const char *name);
-void ofi_perfset_log(struct ofi_perfset *set);
+void ofi_perfset_log(struct ofi_perfset *set, const char **names);
+
+static inline void ofi_perfset_start(struct ofi_perfset *set, size_t index)
+{
+	assert(index < set->size);
+	ofi_perf_start(set->ctx, &set->data[index]);
+}
+
+static inline void ofi_perfset_end(struct ofi_perfset *set, size_t index)
+{
+	assert(index < set->size);
+	ofi_perf_end(set->ctx, &set->data[index]);
+}
 
 
 #ifdef __cplusplus
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_proto.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_proto.h
index 5a569b1d8..6e63e59a5 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_proto.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_proto.h
@@ -58,6 +58,9 @@ enum {
 	ofi_ctrl_ack,
 	ofi_ctrl_nack,
 	ofi_ctrl_discard,
+	ofi_ctrl_seg_data,
+	ofi_ctrl_atomic,
+	ofi_ctrl_atomic_resp,
 };
 
 /*
@@ -66,13 +69,6 @@ enum {
  *
  * version: OFI_CTRL_VERSION
  * type
- * seg_size:
- *     Data packets - size of current message, in bytes.
- *     Large data packets - size of current message, 2 ^ seg_size, in bytes
- *     Ctrl packets - number of segments in window allowed past seg_no.
- * seg_no:
- *     Data packets - position 0..(n-1) of segment in current message.
- *     Ctrl packets - last segment ack'ed.
  * conn_id: Communication identifier.  Conn_id values are exchanged between
  *     peer endpoints as part of communication setup.  This field is valid
  *     as part of the first message in any data transfer.
@@ -80,6 +76,13 @@ enum {
  *     Unique number identifying all segments of a message
  *     Message id can be formed using an equation similar to:
  *     (seq_no++ << tx size) | tx_key
+ * seg_size:
+ *     Data packets - size of current message, in bytes.
+ *     Large data packets - size of current message, 2 ^ seg_size, in bytes
+ *     Ctrl packets - number of segments in window allowed past seg_no.
+ * seg_no:
+ *     Data packets - position 0..(n-1) of segment in current message.
+ *     Ctrl packets - last segment ack'ed.
  * conn_data: Connection specific data.  This may be set to the index
  *     of the transmit endpoint's address in its local AV, which may
  *     be used as a hint at the Rx side to locate the Tx EP address in
@@ -89,19 +92,21 @@ enum {
  * rx_key: This is the receiver's identifier for a message (receive side
  *     equivalent of msg_id).  Key returned by the Rx side, that the
  *     Tx side includes in subsequent packets.  This field is used for
- *     rendezvous and segmentation and reassembly protocols.
+ *     rendezvous protocol.
  *     The rx_key may be formed similar to message_id.
+ * ctrl_data: This is provider specific data for remote side
  */
 struct ofi_ctrl_hdr {
-	uint8_t			version;
-	uint8_t			type;
-	uint16_t		seg_size;
-	uint32_t		seg_no;
-	uint64_t		conn_id;
-	uint64_t		msg_id;
+	uint8_t				version;
+	uint8_t				type;
+	uint16_t			seg_size;
+	uint32_t			seg_no;
+	uint64_t			conn_id;
+	uint64_t			msg_id;
 	union {
-		uint64_t	conn_data;
-		uint64_t	rx_key;
+		uint64_t		conn_data;
+		uint64_t		rx_key;
+		uint64_t		ctrl_data;
 	};
 };
 
@@ -128,6 +133,7 @@ enum {
 #define OFI_REMOTE_CQ_DATA	(1 << 0)
 #define OFI_TRANSMIT_COMPLETE	(1 << 1)
 #define OFI_DELIVERY_COMPLETE	(1 << 2)
+#define OFI_COMMIT_COMPLETE	(1 << 3)
 
 /*
  * Common command header
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_prov.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_prov.h
index 68281b880..c4c94a478 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_prov.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_prov.h
@@ -206,4 +206,38 @@ SHM_INI ;
 #  define SHM_INIT NULL
 #endif
 
+#if (HAVE_MRAIL) && (HAVE_MRAIL_DL)
+#  define MRAIL_INI FI_EXT_INI
+#  define MRAIL_INIT NULL
+#elif (HAVE_MRAIL)
+#  define MRAIL_INI INI_SIG(fi_mrail_ini)
+#  define MRAIL_INIT fi_mrail_ini()
+MRAIL_INI ;
+#else
+#  define MRAIL_INIT NULL
+#endif
+
+#if (HAVE_RSTREAM) && (HAVE_RSTREAM_DL)
+#  define RSTREAM_INI FI_EXT_INI
+#  define RSTREAM_INIT NULL
+#elif (HAVE_RSTREAM)
+#  define RSTREAM_INI INI_SIG(fi_rstream_ini)
+#  define RSTREAM_INIT fi_rstream_ini()
+RSTREAM_INI ;
+#else
+#  define RSTREAM_INIT NULL
+#endif
+
+#if(HAVE_PERF)
+#  define PERF_HOOK_INI INI_SIG(fi_perf_hook_ini)
+#  define PERF_HOOK_INIT fi_perf_hook_ini()
+PERF_HOOK_INI ;
+#else
+#  define PERF_HOOK_INIT NULL
+#endif
+
+#  define NOOP_HOOK_INI INI_SIG(fi_noop_hook_ini)
+#  define NOOP_HOOK_INIT fi_noop_hook_ini()
+NOOP_HOOK_INI ;
+
 #endif /* _OFI_PROV_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_recvwin.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_recvwin.h
new file mode 100644
index 000000000..917a0c34e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_recvwin.h
@@ -0,0 +1,118 @@
+/*
+ * Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+/*
+ * This utility provides a sliding receive window implementation. It uses a
+ * circular queue to order incoming messages based on the message ID in the
+ * transport protocol.
+ */
+
+#if !defined(FI_RECVWIN_H)
+#define FI_RECVWIN_H
+
+#include "config.h"
+
+#include <assert.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <ofi.h>
+#include <ofi_rbuf.h>
+
+#define OFI_DECL_RECVWIN_BUF(entrytype, name)				\
+OFI_DECLARE_CIRQUE(entrytype, recvwin_cirq);				\
+struct name {								\
+	uint64_t exp_msg_id;						\
+	unsigned int win_size;						\
+	struct recvwin_cirq *pending;					\
+};									\
+									\
+static inline struct name *						\
+ofi_recvwin_buf_alloc(struct name *recvq, unsigned int size)		\
+{									\
+	assert(size == roundup_power_of_two(size));			\
+	recvq->exp_msg_id = 0;						\
+	recvq->win_size	= size;						\
+	recvq->pending	= recvwin_cirq_create(recvq->win_size);		\
+	return recvq;							\
+}									\
+									\
+static inline void							\
+ofi_recvwin_free(struct name *recvq)					\
+{									\
+	recvwin_cirq_free(recvq->pending);				\
+}									\
+									\
+static inline int							\
+ofi_recvwin_queue_msg(struct name *recvq, entrytype * msg, uint64_t id)	\
+{									\
+	int write_idx;							\
+									\
+	assert(ofi_recvwin_is_allowed(recvq, id));			\
+	write_idx = (ofi_cirque_rindex(recvq->pending)			\
+		    + (id - recvq->exp_msg_id))				\
+		    & recvq->pending->size_mask;			\
+	recvq->pending->buf[write_idx] = *msg;				\
+	ofi_cirque_commit(recvq->pending);				\
+	return 0;							\
+}									\
+									\
+static inline entrytype *						\
+ofi_recvwin_get_next_msg(struct name *recvq)				\
+{									\
+	if (ofi_cirque_head(recvq->pending)) {				\
+		ofi_recvwin_exp_inc(recvq);				\
+		return ofi_cirque_remove(recvq->pending);		\
+	} else {							\
+		return NULL;						\
+	}								\
+}									\
+									\
+static inline void							\
+ofi_recvwin_slide(struct name *recvq)					\
+{									\
+	ofi_recvwin_exp_inc(recvq);					\
+	ofi_cirque_discard(recvq->pending);				\
+	ofi_cirque_commit(recvq->pending);				\
+}
+
+#define ofi_recvwin_peek(rq)		(ofi_cirque_head(rq->pending))
+#define ofi_recvwin_is_empty(rq)	(ofi_cirque_isempty(rq->pending))
+#define ofi_recvwin_exp_inc(rq)		((rq)->exp_msg_id++)
+#define ofi_recvwin_is_exp(rq, id)	((rq)->exp_msg_id == id)
+#define ofi_recvwin_next_exp_id(rq)	((rq)->exp_msg_id)
+#define ofi_recvwin_is_delayed(rq, id)	((rq)->exp_msg_id > id)
+#define ofi_recvwin_is_allowed(rq, id)	(id >= rq->exp_msg_id \
+					&& id < (rq->win_size + rq->exp_msg_id))
+
+#endif /* FI_RECVWIN_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_shm.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_shm.h
index b6e4c4777..bb667f7fd 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_shm.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_shm.h
@@ -177,7 +177,12 @@ struct smr_region {
 	struct smr_map	*map;
 
 	size_t		total_size;
-	size_t		cmd_cnt;
+	size_t		cmd_cnt; /* Doubles as a tracker for number of cmds AND
+				    number of inject buffers available for use,
+				    to ensure 1:1 ratio of cmds to inject bufs.
+				    Might not always be paired consistently with
+				    cmd alloc/free depending on protocol
+				    (Ex. unexpected messages, RMA requests) */
 
 	/* offsets from start of smr_region */
 	size_t		cmd_queue_offset;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_signal.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_signal.h
index 3a2974f89..b4f3ff366 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_signal.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_signal.h
@@ -113,74 +113,9 @@ static inline int fd_signal_poll(struct fd_signal *signal, int timeout)
 	return (ret == 0) ? -FI_ETIMEDOUT : 0;
 }
 
-#ifdef HAVE_EPOLL
-#include <sys/epoll.h>
-
-typedef int fi_epoll_t;
-
-static inline int fi_epoll_create(int *ep)
-{
-	*ep = epoll_create(4);
-	return *ep < 0 ? -ofi_syserr() : 0;
-}
-
-static inline int fi_epoll_add(int ep, int fd, void *context)
-{
-	struct epoll_event event;
-	int ret;
-
-	event.data.ptr = context;
-	event.events = EPOLLIN;
-	ret = epoll_ctl(ep, EPOLL_CTL_ADD, fd, &event);
-	if ((ret == -1) && (ofi_syserr() != EEXIST))
-		return -ofi_syserr();
-	return 0;
-}
-
-static inline int fi_epoll_del(int ep, int fd)
+static inline int fd_signal_get(struct fd_signal *signal)
 {
-	return epoll_ctl(ep, EPOLL_CTL_DEL, fd, NULL) ? -ofi_syserr() : 0;
+	return signal->fd[FI_READ_FD];
 }
 
-static inline int fi_epoll_wait(int ep, void **contexts, int max_contexts,
-                                int timeout)
-{
-	struct epoll_event events[max_contexts];
-	int ret;
-	int i;
-
-	ret = epoll_wait(ep, events, max_contexts, timeout);
-	if (ret == -1)
-		return -ofi_syserr();
-
-	for (i = 0; i < ret; i++)
-		contexts[i] = events[i].data.ptr;
-	return ret;
-}
-
-static inline void fi_epoll_close(int ep)
-{
-	close(ep);
-}
-
-#else
-#include <poll.h>
-
-typedef struct fi_epoll {
-	int		size;
-	int		nfds;
-	struct pollfd	*fds;
-	void		**context;
-	int		index;
-} *fi_epoll_t;
-
-int fi_epoll_create(struct fi_epoll **ep);
-int fi_epoll_add(struct fi_epoll *ep, int fd, void *context);
-int fi_epoll_del(struct fi_epoll *ep, int fd);
-int fi_epoll_wait(struct fi_epoll *ep, void **contexts, int max_contexts,
-                  int timeout);
-void fi_epoll_close(struct fi_epoll *ep);
-
-#endif /* HAVE_EPOLL */
-
 #endif /* _OFI_SIGNAL_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_tree.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_tree.h
new file mode 100644
index 000000000..6bb79377a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_tree.h
@@ -0,0 +1,87 @@
+/*
+ * Copyright (c) 2015 Cray Inc. All rights reserved.
+ * Copyright (c) 2018 Intel Corp, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+/*
+ * Copied from http://oopweb.com/Algorithms/Documents/Sman/VolumeFrames.html?/Algorithms/Documents/Sman/Volume/RedBlackTrees_files/s_rbt.htm
+ *
+ * Disclosure from the author's main page:
+ * (http://oopweb.com/Algorithms/Documents/Sman/VolumeFrames.html?/Algorithms/Documents/Sman/Volume/RedBlackTrees_files/s_rbt.htm)
+ *
+ *     Source code when part of a software project may be used freely
+ *     without reference to the author.
+ *
+ */
+
+#ifndef _OFI_TREE_H_
+#define _OFI_TREE_H_
+
+#include <stdlib.h>
+
+
+enum ofi_node_color {
+	BLACK,
+	RED
+};
+
+struct ofi_rbnode {
+	struct ofi_rbnode	*left;
+	struct ofi_rbnode	*right;
+	struct ofi_rbnode	*parent;
+	enum ofi_node_color	color;
+	void			*data;
+};
+
+struct ofi_rbmap {
+	struct ofi_rbnode	*root;
+	struct ofi_rbnode	sentinel;
+
+	/* compare()
+	 *	= 0: a == b
+	 *	< 0: a < b
+	 *	> 0: a > b
+	 */
+	int			(*compare)(struct ofi_rbmap *map,
+					   void *key, void *data);
+};
+
+
+void ofi_rbmap_init(struct ofi_rbmap *map);
+void ofi_rbmap_cleanup(struct ofi_rbmap *map);
+
+struct ofi_rbnode *ofi_rbmap_find(struct ofi_rbmap *map, void *key);
+int ofi_rbmap_insert(struct ofi_rbmap *map, void *key, void *data);
+void ofi_rbmap_delete(struct ofi_rbmap *map, struct ofi_rbnode *node);
+int ofi_rbmap_empty(struct ofi_rbmap *map);
+
+
+#endif /* OFI_TREE_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_util.h b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_util.h
index 1db1c9c9b..9bfc72d12 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_util.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/ofi_util.h
@@ -61,38 +61,16 @@
 #include <ofi_enosys.h>
 #include <ofi_osd.h>
 #include <ofi_indexer.h>
+#include <ofi_epoll.h>
+#include <ofi_proto.h>
 
 #include "rbtree.h"
+#include "uthash.h"
 
-#define UTIL_FLAG_ERROR	(1ULL << 60)
-	
-#define OFI_CNTR_ENABLED	(1ULL << 61)
-
-#define OFI_Q_STRERROR(prov, log, q, q_str, entry, strerror)			\
-	FI_WARN(prov, log, "fi_" q_str "_readerr: err: %d, prov_err: %s (%d)\n",\
-			entry.err,						\
-			strerror(q, entry.prov_errno, entry.err_data, NULL, 0), \
-			entry.prov_errno)
+#define UTIL_FLAG_ERROR		(1ULL << 60)
+#define UTIL_FLAG_OVERFLOW	(1ULL << 61)
 
-#define OFI_Q_READERR(prov, log, q, q_str, readerr, strerror, ret, err_entry)	\
-	do {									\
-		ret = readerr(q, &err_entry, 0);				\
-		if (ret != sizeof(err_entry)) {					\
-			FI_WARN(prov, log,					\
-					"Unable to fi_" q_str "_readerr\n");	\
-		} else {							\
-			OFI_Q_STRERROR(prov, log, q, q_str,			\
-					err_entry, strerror);			\
-		}								\
-	} while (0)
-
-#define OFI_CQ_READERR(prov, log, cq, ret, err_entry)		\
-	OFI_Q_READERR(prov, log, cq, "cq", fi_cq_readerr,	\
-			fi_cq_strerror, ret, err_entry)
-
-#define OFI_EQ_READERR(prov, log, eq, ret, err_entry)		\
-	OFI_Q_READERR(prov, log, eq, "eq", fi_eq_readerr, 	\
-			fi_eq_strerror, ret, err_entry)
+#define OFI_CNTR_ENABLED	(1ULL << 61)
 
 #define FI_INFO_FIELD(provider, prov_attr, user_attr, prov_str, user_str, type)	\
 	do {										\
@@ -130,6 +108,9 @@
 	FI_INFO_STRING(provider, prov->name, user->name, "Supported",	\
 		       "Requested")
 
+#define ofi_after_eq(a,b)	((long)((a) - (b)) >= 0)
+#define ofi_before(a,b)		((long)((a) - (b)) < 0)
+
 enum {
 	UTIL_TX_SHARED_CTX = 1 << 0,
 	UTIL_RX_SHARED_CTX = 1 << 1,
@@ -195,6 +176,8 @@ struct util_domain {
 	uint32_t		addr_format;
 	enum fi_av_type		av_type;
 	struct ofi_mr_map	mr_map;
+	enum fi_threading	threading;
+	enum fi_progress	data_progress;
 };
 
 int ofi_domain_init(struct fid_fabric *fabric_fid, const struct fi_info *info,
@@ -202,6 +185,23 @@ int ofi_domain_init(struct fid_fabric *fabric_fid, const struct fi_info *info,
 int ofi_domain_bind_eq(struct util_domain *domain, struct util_eq *eq);
 int ofi_domain_close(struct util_domain *domain);
 
+static const uint64_t ofi_rx_mr_flags[] = {
+	[ofi_op_msg] = FI_RECV,
+	[ofi_op_tagged] = FI_RECV,
+	[ofi_op_read_req] = FI_REMOTE_READ,
+	[ofi_op_write] = FI_REMOTE_WRITE,
+	[ofi_op_atomic] = FI_REMOTE_WRITE,
+	[ofi_op_atomic_fetch] = FI_REMOTE_WRITE | FI_REMOTE_READ,
+	[ofi_op_atomic_compare] = FI_REMOTE_WRITE | FI_REMOTE_READ,
+};
+
+static inline uint64_t ofi_rx_mr_reg_flags(uint32_t op, uint16_t atomic_op)
+{
+	if (atomic_op == FI_ATOMIC_READ)
+		return FI_REMOTE_READ;
+
+	return ofi_rx_mr_flags[op];
+}
 
 /*
  * Passive Endpoint
@@ -222,8 +222,10 @@ int ofi_pep_close(struct util_pep *pep);
  * Endpoint
  */
 
+struct util_cntr;
 struct util_ep;
 typedef void (*ofi_ep_progress_func)(struct util_ep *util_ep);
+typedef void (*ofi_cntr_inc_func)(struct util_cntr *util_cntr);
 
 struct util_ep {
 	struct fid_ep		ep_fid;
@@ -237,6 +239,7 @@ struct util_ep {
 	uint64_t		rx_op_flags;
 	struct util_cq		*tx_cq;
 	uint64_t		tx_op_flags;
+	uint64_t		inject_op_flags;
 
 	/* CNTR entries */
 	struct util_cntr	*tx_cntr;     /* transmit/send */
@@ -246,11 +249,20 @@ struct util_ep {
 	struct util_cntr	*rem_rd_cntr; /* remote read   */
 	struct util_cntr	*rem_wr_cntr; /* remote write  */
 
+	ofi_cntr_inc_func	tx_cntr_inc;
+	ofi_cntr_inc_func	rx_cntr_inc;
+	ofi_cntr_inc_func	rd_cntr_inc;
+	ofi_cntr_inc_func	wr_cntr_inc;
+	ofi_cntr_inc_func	rem_rd_cntr_inc;
+	ofi_cntr_inc_func	rem_wr_cntr_inc;
+
+	enum fi_ep_type		type;
 	uint64_t		caps;
 	uint64_t		flags;
 	ofi_ep_progress_func	progress;
-	struct util_cmap	*cmap;
 	fastlock_t		lock;
+	ofi_fastlock_acquire_t	lock_acquire;
+	ofi_fastlock_release_t	lock_release;
 };
 
 int ofi_ep_bind_av(struct util_ep *util_ep, struct util_av *av);
@@ -264,6 +276,119 @@ int ofi_endpoint_init(struct fid_domain *domain, const struct util_prov *util_pr
 
 int ofi_endpoint_close(struct util_ep *util_ep);
 
+static inline void ofi_ep_lock_acquire(struct util_ep *ep)
+{
+	ep->lock_acquire(&ep->lock);
+}
+
+static inline void ofi_ep_lock_release(struct util_ep *ep)
+{
+	ep->lock_release(&ep->lock);
+}
+
+static inline void ofi_ep_tx_cntr_inc(struct util_ep *ep)
+{
+	ep->tx_cntr_inc(ep->tx_cntr);
+}
+
+static inline void ofi_ep_rx_cntr_inc(struct util_ep *ep)
+{
+	ep->rx_cntr_inc(ep->rx_cntr);
+}
+
+static inline void ofi_ep_rd_cntr_inc(struct util_ep *ep)
+{
+	ep->rd_cntr_inc(ep->rd_cntr);
+}
+
+static inline void ofi_ep_wr_cntr_inc(struct util_ep *ep)
+{
+	ep->wr_cntr_inc(ep->wr_cntr);
+}
+
+static inline void ofi_ep_rem_rd_cntr_inc(struct util_ep *ep)
+{
+	ep->rem_rd_cntr_inc(ep->rem_rd_cntr);
+}
+
+static inline void ofi_ep_rem_wr_cntr_inc(struct util_ep *ep)
+{
+	ep->rem_wr_cntr_inc(ep->rem_wr_cntr);
+}
+
+typedef void (*ofi_ep_cntr_inc_func)(struct util_ep *);
+
+static const ofi_ep_cntr_inc_func ofi_ep_cntr_inc_funcs[] = {
+	[FI_TRANSMIT] = ofi_ep_tx_cntr_inc,
+	[FI_RECV] = ofi_ep_rx_cntr_inc,
+	[FI_READ] = ofi_ep_rd_cntr_inc,
+	[FI_WRITE] = ofi_ep_wr_cntr_inc,
+	[FI_REMOTE_READ] = ofi_ep_rem_rd_cntr_inc,
+	[FI_REMOTE_WRITE] = ofi_ep_rem_wr_cntr_inc,
+};
+
+/*
+ * Tag and address match
+ */
+
+static inline int ofi_match_addr(fi_addr_t recv_addr, fi_addr_t addr)
+{
+	return (recv_addr == FI_ADDR_UNSPEC) || (recv_addr == addr);
+}
+
+static inline int ofi_match_tag(uint64_t recv_tag, uint64_t recv_ignore,
+				uint64_t tag)
+{
+	return ((recv_tag | recv_ignore) == (tag | recv_ignore));
+}
+
+/*
+ * Wait set
+ */
+struct util_wait;
+typedef void (*fi_wait_signal_func)(struct util_wait *wait);
+typedef int (*fi_wait_try_func)(struct util_wait *wait);
+
+struct util_wait {
+	struct fid_wait		wait_fid;
+	struct util_fabric	*fabric;
+	struct util_poll	*pollset;
+	ofi_atomic32_t		ref;
+	const struct fi_provider *prov;
+
+	enum fi_wait_obj	wait_obj;
+	fi_wait_signal_func	signal;
+	fi_wait_try_func	try;
+};
+
+int fi_wait_init(struct util_fabric *fabric, struct fi_wait_attr *attr,
+		 struct util_wait *wait);
+int fi_wait_cleanup(struct util_wait *wait);
+
+struct util_wait_fd {
+	struct util_wait	util_wait;
+	struct fd_signal	signal;
+	fi_epoll_t		epoll_fd;
+	struct dlist_entry	fd_list;
+	fastlock_t		lock;
+};
+
+typedef int (*ofi_wait_fd_try_func)(void *arg);
+
+struct ofi_wait_fd_entry {
+	struct dlist_entry	entry;
+	int 			fd;
+	ofi_wait_fd_try_func	try;
+	void			*arg;
+	ofi_atomic32_t		ref;
+};
+
+int ofi_wait_fd_open(struct fid_fabric *fabric, struct fi_wait_attr *attr,
+		struct fid_wait **waitset);
+int ofi_wait_fd_add(struct util_wait *wait, int fd, uint32_t events,
+		    ofi_wait_fd_try_func try, void *arg, void *context);
+int ofi_wait_fd_del(struct util_wait *wait, int fd);
+
 /*
  * Completion queue
  *
@@ -273,13 +398,14 @@ int ofi_endpoint_close(struct util_ep *util_ep);
  * entries on the CQ.  This allows poll sets to drive progress
  * without introducing private interfaces to the CQ.
  */
-#define FI_DEFAULT_CQ_SIZE	1024
 
 typedef void (*fi_cq_read_func)(void **dst, void *src);
 
-struct util_cq_err_entry {
-	struct fi_cq_err_entry	err_entry;
-	struct slist_entry	list_entry;
+struct util_cq_oflow_err_entry {
+	struct fi_cq_tagged_entry	*parent_comp;
+	struct fi_cq_err_entry		comp;
+	fi_addr_t			src;
+	struct slist_entry		list_entry;
 };
 
 OFI_DECLARE_CIRQUE(struct fi_cq_tagged_entry, util_comp_cirq);
@@ -294,11 +420,13 @@ struct util_cq {
 	struct dlist_entry	ep_list;
 	fastlock_t		ep_list_lock;
 	fastlock_t		cq_lock;
+	ofi_fastlock_acquire_t	cq_fastlock_acquire;
+	ofi_fastlock_release_t	cq_fastlock_release;
 
 	struct util_comp_cirq	*cirq;
 	fi_addr_t		*src;
 
-	struct slist		err_list;
+	struct slist		oflow_err_list;
 	fi_cq_read_func		read_entry;
 	int			internal_wait;
 	ofi_atomic32_t		signaled;
@@ -312,6 +440,7 @@ int ofi_check_bind_cq_flags(struct util_ep *ep, struct util_cq *cq,
 			    uint64_t flags);
 void ofi_cq_progress(struct util_cq *cq);
 int ofi_cq_cleanup(struct util_cq *cq);
+int ofi_cq_control(struct fid *fid, int command, void *arg);
 ssize_t ofi_cq_read(struct fid_cq *cq_fid, void *buf, size_t count);
 ssize_t ofi_cq_readfrom(struct fid_cq *cq_fid, void *buf, size_t count,
 		fi_addr_t *src_addr);
@@ -322,8 +451,82 @@ ssize_t ofi_cq_sread(struct fid_cq *cq_fid, void *buf, size_t count,
 ssize_t ofi_cq_sreadfrom(struct fid_cq *cq_fid, void *buf, size_t count,
 		fi_addr_t *src_addr, const void *cond, int timeout);
 int ofi_cq_signal(struct fid_cq *cq_fid);
-int ofi_cq_write(struct util_cq *cq, void *context, uint64_t flags, size_t len,
-		 void *buf, uint64_t data, uint64_t tag);
+
+int ofi_cq_write_overflow(struct util_cq *cq, void *context, uint64_t flags, size_t len,
+			  void *buf, uint64_t data, uint64_t tag, fi_addr_t src);
+
+static inline void util_cq_signal(struct util_cq *cq)
+{
+	assert(cq->wait);
+	cq->wait->signal(cq->wait);
+}
+
+static inline void
+ofi_cq_write_comp_entry(struct util_cq *cq, void *context, uint64_t flags,
+			size_t len, void *buf, uint64_t data, uint64_t tag)
+{
+	struct fi_cq_tagged_entry *comp = ofi_cirque_tail(cq->cirq);
+	comp->op_context = context;
+	comp->flags = flags;
+	comp->len = len;
+	comp->buf = buf;
+	comp->data = data;
+	comp->tag = tag;
+	ofi_cirque_commit(cq->cirq);
+}
+
+static inline int
+ofi_cq_write_thread_unsafe(struct util_cq *cq, void *context, uint64_t flags,
+			   size_t len, void *buf, uint64_t data, uint64_t tag)
+{
+	if (OFI_UNLIKELY(ofi_cirque_isfull(cq->cirq))) {
+		FI_DBG(cq->domain->prov, FI_LOG_CQ,
+		       "util_cq cirq is full!\n");
+		return ofi_cq_write_overflow(cq, context, flags, len,
+					     buf, data, tag, 0);
+	}
+	ofi_cq_write_comp_entry(cq, context, flags, len, buf, data, tag);
+	return 0;
+}
+
+static inline int
+ofi_cq_write(struct util_cq *cq, void *context, uint64_t flags, size_t len,
+	     void *buf, uint64_t data, uint64_t tag)
+{
+	int ret;
+	cq->cq_fastlock_acquire(&cq->cq_lock);
+	ret = ofi_cq_write_thread_unsafe(cq, context, flags, len, buf, data, tag);
+	cq->cq_fastlock_release(&cq->cq_lock);
+	return ret;
+}
+
+static inline int
+ofi_cq_write_src_thread_unsafe(struct util_cq *cq, void *context, uint64_t flags, size_t len,
+			       void *buf, uint64_t data, uint64_t tag, fi_addr_t src)
+{
+	if (OFI_UNLIKELY(ofi_cirque_isfull(cq->cirq))) {
+		FI_DBG(cq->domain->prov, FI_LOG_CQ,
+		       "util_cq cirq is full!\n");
+		return ofi_cq_write_overflow(cq, context, flags, len,
+					     buf, data, tag, src);
+	}
+	cq->src[ofi_cirque_windex(cq->cirq)] = src;
+	ofi_cq_write_comp_entry(cq, context, flags, len, buf, data, tag);
+	return 0;
+}
+
+static inline int
+ofi_cq_write_src(struct util_cq *cq, void *context, uint64_t flags, size_t len,
+		 void *buf, uint64_t data, uint64_t tag, fi_addr_t src)
+{
+	int ret;
+	cq->cq_fastlock_acquire(&cq->cq_lock);
+	ret = ofi_cq_write_src_thread_unsafe(cq, context, flags, len,
+					     buf, data, tag, src);
+	cq->cq_fastlock_release(&cq->cq_lock);
+	return ret;
+}
+
 int ofi_cq_write_error(struct util_cq *cq,
 		       const struct fi_cq_err_entry *err_entry);
 int ofi_cq_write_error_peek(struct util_cq *cq, uint64_t tag, void *context);
@@ -338,10 +541,39 @@ static inline int ofi_need_completion(uint64_t cq_flags, uint64_t op_flags)
 			     FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)));
 }
 
+static const uint64_t ofi_rx_flags[] = {
+	[ofi_op_msg] = FI_RECV,
+	[ofi_op_tagged] = FI_RECV | FI_TAGGED,
+	[ofi_op_read_req] = FI_RMA | FI_REMOTE_READ,
+	[ofi_op_write] = FI_RMA | FI_REMOTE_WRITE,
+	[ofi_op_atomic] = FI_ATOMIC | FI_REMOTE_WRITE,
+	[ofi_op_atomic_fetch] = FI_ATOMIC | FI_REMOTE_READ,
+	[ofi_op_atomic_compare] = FI_ATOMIC | FI_REMOTE_READ,
+};
+
+static inline uint64_t ofi_rx_cq_flags(uint32_t op)
+{
+	return ofi_rx_flags[op];
+}
+
+static const uint64_t ofi_tx_flags[] = {
+	[ofi_op_msg] = FI_SEND,
+	[ofi_op_tagged] = FI_SEND | FI_TAGGED,
+	[ofi_op_read_req] = FI_RMA | FI_READ,
+	[ofi_op_write] = FI_RMA | FI_WRITE,
+	[ofi_op_atomic] = FI_ATOMIC | FI_WRITE,
+	[ofi_op_atomic_fetch] = FI_ATOMIC | FI_READ,
+	[ofi_op_atomic_compare] = FI_ATOMIC | FI_READ,
+};
+
+static inline uint64_t ofi_tx_cq_flags(uint32_t op)
+{
+	return ofi_tx_flags[op];
+}
+
 /*
  * Counter
  */
-struct util_cntr;
 typedef void (*ofi_cntr_progress_func)(struct util_cntr *cntr);
 
 struct util_cntr {
@@ -368,22 +600,30 @@ int ofi_cntr_init(const struct fi_provider *prov, struct fid_domain *domain,
 		  struct fi_cntr_attr *attr, struct util_cntr *cntr,
 		  ofi_cntr_progress_func progress, void *context);
 int ofi_cntr_cleanup(struct util_cntr *cntr);
+static inline void util_cntr_signal(struct util_cntr *cntr)
+{
+	assert(cntr->wait);
+	cntr->wait->signal(cntr->wait);
+}
+
+static inline void ofi_cntr_inc_noop(struct util_cntr *cntr)
+{
+	OFI_UNUSED(cntr);
+}
 
+static inline void ofi_cntr_inc(struct util_cntr *cntr)
+{
+	cntr->cntr_fid.ops->add(&cntr->cntr_fid, 1);
+}
 
 /*
  * AV / addressing
  */
-struct util_av_hash_entry {
-	int			index;
-	ofi_atomic32_t		use_cnt;
-	int			next;
-};
 
-struct util_av_hash {
-	struct util_av_hash_entry *table;
-	int			free_list;
-	int			slots;
-	int			total_count;
+struct util_av_entry {
+	ofi_atomic32_t	use_cnt;
+	UT_hash_handle	hh;
+	char		addr[0];
 };
 
 struct util_av {
@@ -394,179 +634,73 @@ struct util_av {
 	fastlock_t		lock;
 	const struct fi_provider *prov;
 
+	struct util_av_entry	*hash;
+	struct util_buf_pool	*av_entry_pool;
+
 	void			*context;
 	uint64_t		flags;
 	size_t			count;
 	size_t			addrlen;
-	ssize_t			free_list;
-	struct util_av_hash	hash;
-	void			*data;
 	struct dlist_entry	ep_list;
 };
 
-#define OFI_AV_HASH	(1 << 0)
-
 struct util_av_attr {
-	size_t			addrlen;
-	size_t			overhead;
-	int			flags;
+	size_t	addrlen;
+	int	flags;
 };
 
+typedef int (*ofi_av_apply_func)(struct util_av *av, void *addr,
+				 fi_addr_t fi_addr, void *arg);
+
 int ofi_av_init(struct util_domain *domain,
 	       const struct fi_av_attr *attr, const struct util_av_attr *util_attr,
 	       struct util_av *av, void *context);
+int ofi_av_init_lightweight(struct util_domain *domain, const struct fi_av_attr *attr,
+			    struct util_av *av, void *context);
 int ofi_av_close(struct util_av *av);
+int ofi_av_close_lightweight(struct util_av *av);
 
-int ofi_av_insert_addr(struct util_av *av, const void *addr, int slot, int *index);
-int ofi_av_remove_addr(struct util_av *av, int slot, int index);
-int ofi_av_lookup_index(struct util_av *av, const void *addr, int slot);
+int ofi_av_insert_addr(struct util_av *av, const void *addr, fi_addr_t *fi_addr);
+int ofi_av_remove_addr(struct util_av *av, fi_addr_t fi_addr);
+fi_addr_t ofi_av_lookup_fi_addr(struct util_av *av, const void *addr);
+int ofi_av_elements_iter(struct util_av *av, ofi_av_apply_func apply, void *arg);
 int ofi_av_bind(struct fid *av_fid, struct fid *eq_fid, uint64_t flags);
 void ofi_av_write_event(struct util_av *av, uint64_t data,
 			int err, void *context);
 
-int ip_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
-		 struct fid_av **av, void *context);
-int ip_av_create_flags(struct fid_domain *domain_fid, struct fi_av_attr *attr,
-		       struct fid_av **av, void *context, int flags);
+int ofi_ip_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+		     struct fid_av **av, void *context);
+int ofi_ip_av_create_flags(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+			   struct fid_av **av, void *context, int flags);
 
-void *ofi_av_get_addr(struct util_av *av, int index);
-#define ip_av_get_addr ofi_av_get_addr
-int ip_av_get_index(struct util_av *av, const void *addr);
+void *ofi_av_get_addr(struct util_av *av, fi_addr_t fi_addr);
+#define ofi_ip_av_get_addr ofi_av_get_addr
+fi_addr_t ofi_ip_av_get_fi_addr(struct util_av *av, const void *addr);
 
-int ofi_get_addr(uint32_t addr_format, uint64_t flags,
+int ofi_get_addr(uint32_t *addr_format, uint64_t flags,
 		 const char *node, const char *service,
 		 void **addr, size_t *addrlen);
 int ofi_get_src_addr(uint32_t addr_format,
 		     const void *dest_addr, size_t dest_addrlen,
 		     void **src_addr, size_t *src_addrlen);
-void ofi_getnodename(char *buf, int buflen);
+void ofi_getnodename(uint16_t sa_family, char *buf, int buflen);
 int ofi_av_get_index(struct util_av *av, const void *addr);
 
-/*
- * Connection Map
- */
-
-// TODO explore replacing this with a simple connection hash map that is common
-// for both AV and RX only connections.
-
-#define UTIL_CMAP_IDX_BITS OFI_IDX_INDEX_BITS
-
-enum ofi_cmap_signal {
-	OFI_CMAP_FREE,
-	OFI_CMAP_EXIT,
-};
-
-enum util_cmap_state {
-	CMAP_IDLE,
-	CMAP_CONNREQ_SENT,
-	CMAP_CONNREQ_RECV,
-	CMAP_ACCEPT,
-	CMAP_CONNECTED,
-	CMAP_SHUTDOWN,
-};
-
-struct util_cmap_handle {
-	struct util_cmap *cmap;
-	enum util_cmap_state state;
-	/* Unique identifier for a connection. Can be exchanged with a peer
-	 * during connection setup and can later be used in a message header
-	 * to identify the source of the message (Used for FI_SOURCE, RNDV
-	 * protocol, etc.) */
-	uint64_t key;
-	uint64_t remote_key;
-	fi_addr_t fi_addr;
-	struct util_cmap_peer *peer;
-};
-
-struct util_cmap_peer {
-	struct util_cmap_handle *handle;
-	struct dlist_entry entry;
-	uint8_t addr[];
-};
-
-typedef struct util_cmap_handle* (*ofi_cmap_alloc_handle_func)(void);
-typedef void (*ofi_cmap_handle_func)(struct util_cmap_handle *handle);
-typedef int (*ofi_cmap_connect_func)(struct util_ep *cmap,
-				     struct util_cmap_handle *handle,
-				     const void *addr, size_t addrlen);
-typedef void *(*ofi_cmap_event_handler_func)(void *arg);
-typedef int (*ofi_cmap_signal_func)(struct util_ep *ep, void *context,
-				    enum ofi_cmap_signal signal);
-
-struct util_cmap_attr {
-	void 				*name;
-	ofi_cmap_alloc_handle_func 	alloc;
-	ofi_cmap_handle_func 		close;
-	ofi_cmap_handle_func 		free;
-	ofi_cmap_connect_func 		connect;
-	ofi_cmap_event_handler_func	event_handler;
-	ofi_cmap_signal_func		signal;
-};
-
-struct util_cmap {
-	struct util_ep *ep;
-	struct util_av *av;
-
-	/* cmap handles that correspond to addresses in AV */
-	struct util_cmap_handle **handles_av;
-
-	/* Store all cmap handles (inclusive of handles_av) in an indexer.
-	 * This allows reverse lookup of the handle using the index. */
-	struct indexer handles_idx;
-
-	struct ofi_key_idx key_idx;
-
-	struct dlist_entry peer_list;
-	struct util_cmap_attr attr;
-	pthread_t event_handler_thread;
-	int av_updated;
-	fastlock_t lock;
-};
-
-struct util_cmap_handle *ofi_cmap_key2handle(struct util_cmap *cmap, uint64_t key);
-int ofi_cmap_get_handle(struct util_cmap *cmap, fi_addr_t fi_addr,
-			struct util_cmap_handle **handle);
-void ofi_cmap_update(struct util_cmap *cmap, const void *addr, fi_addr_t fi_addr);
-
-void ofi_cmap_process_connect(struct util_cmap *cmap,
-			      struct util_cmap_handle *handle,
-			      uint64_t *remote_key);
-void ofi_cmap_process_reject(struct util_cmap *cmap,
-			     struct util_cmap_handle *handle);
-int ofi_cmap_process_connreq(struct util_cmap *cmap, void *addr,
-			     struct util_cmap_handle **handle);
-void ofi_cmap_process_shutdown(struct util_cmap *cmap,
-			       struct util_cmap_handle *handle);
-void ofi_cmap_del_handle(struct util_cmap_handle *handle);
-void ofi_cmap_free(struct util_cmap *cmap);
-struct util_cmap *ofi_cmap_alloc(struct util_ep *ep,
-				 struct util_cmap_attr *attr);
-extern struct util_cmap_handle *
-util_cmap_get_handle(struct util_cmap *cmap, fi_addr_t fi_addr);
-extern int
-util_cmap_alloc_handle(struct util_cmap *cmap, fi_addr_t fi_addr,
-		       enum util_cmap_state state,
-		       struct util_cmap_handle **handle);
-/* Caller must hold `cmap::lock` */
-static inline struct util_cmap_handle *
-ofi_cmap_acquire_handle(struct util_cmap *cmap, fi_addr_t fi_addr)
-
-{
-	struct util_cmap_handle *handle =
-		util_cmap_get_handle(cmap, fi_addr);
-	if (!handle) {
-		int ret;
-
-		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-		       "No handle found for given fi_addr\n");
-		ret = util_cmap_alloc_handle(cmap, fi_addr, CMAP_IDLE, &handle);
-		if (OFI_UNLIKELY(ret))
-			return NULL;
-	}
-	return handle;
-}
-int ofi_cmap_handle_connect(struct util_cmap *cmap, fi_addr_t fi_addr,
-			    struct util_cmap_handle *handle);
+int ofi_verify_av_insert(struct util_av *av, uint64_t flags);
+int ofi_ip_av_insertv(struct util_av *av, const void *addr, size_t addrlen,
+		      size_t count, fi_addr_t *fi_addr, void *context);
+/* Caller should free *addr */
+int ofi_ip_av_sym_getaddr(struct util_av *av, const char *node,
+			  size_t nodecnt, const char *service,
+			  size_t svccnt, void **addr, size_t *addrlen);
+int ofi_ip_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
+		     fi_addr_t *fi_addr, uint64_t flags, void *context);
+int ofi_ip_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr,
+		     size_t count, uint64_t flags);
+int ofi_ip_av_lookup(struct fid_av *av_fid, fi_addr_t fi_addr,
+		     void *addr, size_t *addrlen);
+const char *
+ofi_ip_av_straddr(struct fid_av *av, const void *addr, char *buf, size_t *len);
 
 /*
  * Poll set
@@ -585,55 +719,6 @@ int fi_poll_create_(const struct fi_provider *prov, struct fid_domain *domain,
 int fi_poll_create(struct fid_domain *domain, struct fi_poll_attr *attr,
 		   struct fid_poll **pollset);
 
-
-/*
- * Wait set
- */
-struct util_wait;
-typedef void (*fi_wait_signal_func)(struct util_wait *wait);
-typedef int (*fi_wait_try_func)(struct util_wait *wait);
-
-struct util_wait {
-	struct fid_wait		wait_fid;
-	struct util_fabric	*fabric;
-	struct util_poll	*pollset;
-	ofi_atomic32_t		ref;
-	const struct fi_provider *prov;
-
-	enum fi_wait_obj	wait_obj;
-	fi_wait_signal_func	signal;
-	fi_wait_try_func	try;
-};
-
-int fi_wait_init(struct util_fabric *fabric, struct fi_wait_attr *attr,
-		 struct util_wait *wait);
-int fi_wait_cleanup(struct util_wait *wait);
-
-struct util_wait_fd {
-	struct util_wait	util_wait;
-	struct fd_signal	signal;
-	fi_epoll_t		epoll_fd;
-	struct dlist_entry	fd_list;
-	fastlock_t		lock;
-};
-
-typedef int (*ofi_wait_fd_try_func)(void *arg);
-
-struct ofi_wait_fd_entry {
-	struct dlist_entry	entry;
-	int 			fd;
-	ofi_wait_fd_try_func	try;
-	void			*arg;
-	ofi_atomic32_t		ref;
-};
-
-int ofi_wait_fd_open(struct fid_fabric *fabric, struct fi_wait_attr *attr,
-		struct fid_wait **waitset);
-int ofi_wait_fd_add(struct util_wait *wait, int fd, ofi_wait_fd_try_func try,
-		    void *arg, void *context);
-int ofi_wait_fd_del(struct util_wait *wait, int fd);
-
-
 /*
  * EQ
  */
@@ -646,6 +731,9 @@ struct util_eq {
 	const struct fi_provider *prov;
 
 	struct slist		list;
+	/* This contains error data that are read by user and need to
+	 * be freed in subsequent fi_eq_readerr call against the EQ */
+	void			*saved_err_data;
 	int			internal_wait;
 };
 
@@ -659,6 +747,19 @@ struct util_event {
 
 int ofi_eq_create(struct fid_fabric *fabric, struct fi_eq_attr *attr,
 		 struct fid_eq **eq_fid, void *context);
+void ofi_eq_handle_err_entry(uint32_t api_version, uint64_t flags,
+			     struct fi_eq_err_entry *err_entry,
+			     struct fi_eq_err_entry *user_err_entry);
+ssize_t ofi_eq_read(struct fid_eq *eq_fid, uint32_t *event,
+		    void *buf, size_t len, uint64_t flags);
+ssize_t ofi_eq_sread(struct fid_eq *eq_fid, uint32_t *event, void *buf,
+		     size_t len, int timeout, uint64_t flags);
+ssize_t ofi_eq_readerr(struct fid_eq *eq_fid, struct fi_eq_err_entry *buf,
+		       uint64_t flags);
+ssize_t ofi_eq_write(struct fid_eq *eq_fid, uint32_t event,
+		     const void *buf, size_t len, uint64_t flags);
+const char *ofi_eq_strerror(struct fid_eq *eq_fid, int prov_errno,
+			    const void *err_data, char *buf, size_t len);
 
 /*
 
@@ -740,6 +841,14 @@ void ofi_fabric_remove(struct util_fabric *fabric);
  * Utility Providers
  */
 
+#define OFI_NAME_DELIM	';'
+#define OFI_UTIL_PREFIX "ofi_"
+
+static inline int ofi_has_util_prefix(const char *str)
+{
+	return !strncasecmp(str, OFI_UTIL_PREFIX, strlen(OFI_UTIL_PREFIX));
+}
+
 typedef int (*ofi_alter_info_t)(uint32_t version, const struct fi_info *src_info,
 				struct fi_info *dest_info);
 
@@ -751,18 +860,15 @@ int ofix_getinfo(uint32_t version, const char *node, const char *service,
 		 uint64_t flags, const struct util_prov *util_prov,
 		 const struct fi_info *hints, ofi_alter_info_t info_to_core,
 		 ofi_alter_info_t info_to_util, struct fi_info **info);
-int ofi_get_core_info_fabric(struct fi_fabric_attr *util_attr,
+int ofi_get_core_info_fabric(const struct fi_provider *prov,
+			     const struct fi_fabric_attr *util_attr,
 			     struct fi_info **core_info);
 
 
-#define OFI_NAME_DELIM	';'
-#define OFI_UTIL_PREFIX "ofi_"
-
 char *ofi_strdup_append(const char *head, const char *tail);
 // char *ofi_strdup_head(const char *str);
 // char *ofi_strdup_tail(const char *str);
-const char *ofi_util_name(const char *prov_name, size_t *len);
-const char *ofi_core_name(const char *prov_name, size_t *len);
+int ofi_exclude_prov_name(char **prov_name, const char *util_prov_name);
 
 
 int ofi_shm_map(struct util_shm *shm, const char *name, size_t size,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/osx/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/include/osx/osd.h
index db7005205..8fd0d5983 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/osx/osd.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/osx/osd.h
@@ -1,6 +1,7 @@
 /*
  * Copyright (c) 2015 Los Alamos Nat. Security, LLC. All rights reserved.
  * Copyright (c) 2016 Cisco Systems, Inc. All rights reserved.
+ * Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -67,6 +68,21 @@ static inline int ofi_shm_remap(struct util_shm *shm, size_t newsize, void **map
 	return -1;
 }
 
+static inline ssize_t ofi_get_hugepage_size(void)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int ofi_alloc_hugepage_buf(void **memptr, size_t size)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int ofi_free_hugepage_buf(void *memptr, size_t size)
+{
+	return -FI_ENOSYS;
+}
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/rbtree.h b/src/mpid/ch4/netmod/ofi/libfabric/include/rbtree.h
index 34ff3dbe8..a0434b717 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/rbtree.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/rbtree.h
@@ -95,5 +95,12 @@ RbtIterator rbtFindLeftmost(RbtHandle h, void *key,
 RbtIterator rbtFind(RbtHandle h, void *key);
 // returns iterator associated with key
 
+void rbtTraversal(RbtHandle h, RbtIterator it, void *handler_arg,
+          void(*handler)(void *arg, RbtIterator it));
+// tree traversal that visits (applies handler()) each node in the tree data
+//   strucutre exactly once.
+
+void *rbtRoot(RbtHandle h);
+// returns the root of the tree
 
 #endif /* RBTREE_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fabric.h b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fabric.h
index 3d29686f0..83854339f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fabric.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fabric.h
@@ -37,6 +37,7 @@
 #include <stdint.h>
 #include <stddef.h>
 #include <sys/types.h>
+#include <sys/uio.h>
 
 #ifdef __GNUC__
 #define FI_DEPRECATED_FUNC __attribute__((deprecated))
@@ -75,11 +76,8 @@ extern "C" {
 	((sizeof(x)/sizeof(0[x])) / ((size_t)(!(sizeof(x) % sizeof(0[x])))))
 #endif
 
-/* API version (which is not necessarily the same as the
- * tarball/libfabric package version number).
- */
 #define FI_MAJOR_VERSION 1
-#define FI_MINOR_VERSION 6
+#define FI_MINOR_VERSION 7
 
 enum {
 	FI_PATH_MAX		= 256,
@@ -91,10 +89,13 @@ enum {
 #define FI_MAJOR(version)	(version >> 16)
 #define FI_MINOR(version)	(version & 0xFFFF)
 #define FI_VERSION_GE(v1, v2)   ((FI_MAJOR(v1) > FI_MAJOR(v2)) || \
-				 (FI_MAJOR(v1) == FI_MAJOR(v2) && FI_MINOR(v1) == FI_MINOR(v2)) || \
-				 (FI_MAJOR(v1) == FI_MAJOR(v2) && FI_MINOR(v1) > FI_MINOR(v2)))
+				 (FI_MAJOR(v1) == FI_MAJOR(v2) && \
+				  FI_MINOR(v1) == FI_MINOR(v2)) || \
+				 (FI_MAJOR(v1) == FI_MAJOR(v2) && \
+				  FI_MINOR(v1) > FI_MINOR(v2)))
 #define FI_VERSION_LT(v1, v2)	((FI_MAJOR(v1) < FI_MAJOR(v2)) || \
-				 (FI_MAJOR(v1) == FI_MAJOR(v2) && FI_MINOR(v1) < FI_MINOR(v2)))
+				 (FI_MAJOR(v1) == FI_MAJOR(v2) && \
+				  FI_MINOR(v1) < FI_MINOR(v2)))
 
 uint32_t fi_version(void);
 
@@ -111,6 +112,7 @@ struct fid_ep;
 struct fid_pep;
 struct fid_stx;
 struct fid_mr;
+struct fid_nic;
 
 typedef struct fid *fid_t;
 
@@ -157,7 +159,9 @@ typedef struct fid *fid_t;
 #define FI_DELIVERY_COMPLETE	(1ULL << 28)
 #define FI_AFFINITY		(1ULL << 29)
 #define FI_COMMIT_COMPLETE	(1ULL << 30)
+#define FI_MATCH_COMPLETE	(1ULL << 31)
 
+#define FI_VARIABLE_MSG		(1ULL << 48)
 #define FI_RMA_PMEM		(1ULL << 49)
 #define FI_SOURCE_ERR		(1ULL << 50)
 #define FI_LOCAL_COMM		(1ULL << 51)
@@ -171,6 +175,11 @@ typedef struct fid *fid_t;
 #define FI_DIRECTED_RECV	(1ULL << 59)
 
 
+/* Tagged messages, buffered receives, CQ flags */
+#define FI_CLAIM		(1ULL << 59)
+#define FI_DISCARD		(1ULL << 58)
+
+
 struct fi_ioc {
 	void			*addr;
 	size_t			count;
@@ -289,6 +298,9 @@ enum {
 	FI_PROTO_NETWORKDIRECT,
 	FI_PROTO_PSMX2,
 	FI_PROTO_SHM,
+	FI_PROTO_MRAIL,
+	FI_PROTO_RSTREAM,
+	FI_PROTO_RDMA_CM_IB_XRC,
 };
 
 /* Mode bits */
@@ -300,6 +312,7 @@ enum {
 #define FI_NOTIFY_FLAGS_ONLY	(1ULL << 54)
 #define FI_RESTRICTED_COMP	(1ULL << 53)
 #define FI_CONTEXT2		(1ULL << 52)
+#define FI_BUFFERED_RECV	(1ULL << 51)
 
 struct fi_tx_attr {
 	uint64_t		caps;
@@ -392,6 +405,50 @@ struct fi_info {
 	struct fi_ep_attr	*ep_attr;
 	struct fi_domain_attr	*domain_attr;
 	struct fi_fabric_attr	*fabric_attr;
+	struct fid_nic		*nic;
+};
+
+struct fi_device_attr {
+	char			*name;
+	char			*device_id;
+	char			*device_version;
+	char			*vendor_id;
+	char			*driver;
+	char			*firmware;
+};
+
+enum fi_bus_type {
+	FI_BUS_UNSPEC,
+	FI_BUS_UNKNOWN = FI_BUS_UNSPEC,
+	FI_BUS_PCI,
+};
+
+struct fi_pci_attr {
+	uint16_t		domain_id;
+	uint8_t			bus_id;
+	uint8_t			device_id;
+	uint8_t			function_id;
+};
+
+struct fi_bus_attr {
+	enum fi_bus_type	bus_type;
+	union {
+		struct fi_pci_attr	pci;
+	} attr;
+};
+
+enum fi_link_state {
+	FI_LINK_UNKNOWN,
+	FI_LINK_DOWN,
+	FI_LINK_UP,
+};
+
+struct fi_link_attr {
+	char			*address;
+	size_t			mtu;
+	size_t			speed;
+	enum fi_link_state	state;
+	char			*network_type;
 };
 
 enum {
@@ -415,6 +472,7 @@ enum {
 	FI_CLASS_POLL,
 	FI_CLASS_CONNREQ,
 	FI_CLASS_MC,
+	FI_CLASS_NIC,
 };
 
 struct fi_eq_attr;
@@ -429,7 +487,8 @@ struct fi_ops {
 	int	(*bind)(struct fid *fid, struct fid *bfid, uint64_t flags);
 	int	(*control)(struct fid *fid, int command, void *arg);
 	int	(*ops_open)(struct fid *fid, const char *name,
-			uint64_t flags, void **ops, void *context);
+			    uint64_t flags, void **ops, void *context);
+	int	(*tostr)(const struct fid *fid, char *buf, size_t len);
 };
 
 /* All fabric interface descriptors must start with this structure */
@@ -472,6 +531,14 @@ struct fid_fabric {
 
 int fi_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric, void *context);
 
+struct fid_nic {
+	struct fid		fid;
+	struct fi_device_attr	*device_attr;
+	struct fi_bus_attr	*bus_attr;
+	struct fi_link_attr	*link_attr;
+	void			*prov_attr;
+};
+
 #define FI_CHECK_OP(ops, opstype, op) \
 	((ops->size > offsetof(opstype, op)) && ops->op)
 
@@ -517,6 +584,7 @@ enum {
 	FI_CANCEL_WORK,		/* struct fi_deferred_work */
 	FI_FLUSH_WORK,		/* NULL */
 	FI_REFRESH,		/* mr: fi_mr_modify */
+	FI_DUP,			/* struct fid ** */
 };
 
 static inline int fi_control(struct fid *fid, int command, void *arg)
@@ -563,6 +631,7 @@ enum fi_type {
 	FI_TYPE_CQ_EVENT_FLAGS,
 	FI_TYPE_MR_MODE,
 	FI_TYPE_OP_TYPE,
+	FI_TYPE_FID,
 };
 
 char *fi_tostr(const void *data, enum fi_type datatype);
@@ -599,6 +668,11 @@ struct fi_context2 {
 };
 #endif
 
+struct fi_recv_context {
+	struct fid_ep		*ep;
+	void			*context;
+};
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_domain.h b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_domain.h
index 1fecb1f29..9deed9b90 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_domain.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_domain.h
@@ -341,7 +341,9 @@ static inline int
 fi_mr_refresh(struct fid_mr *mr, const struct iovec *iov, size_t count,
 	      uint64_t flags)
 {
-	struct fi_mr_modify modify = {0};
+	struct fi_mr_modify modify = {0, 
+		{NULL, 0, 0, 0, 0, NULL, 0, NULL}
+	};
 	modify.flags = flags;
 	modify.attr.mr_iov = iov;
 	modify.attr.iov_count = count;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_endpoint.h b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_endpoint.h
index d2ef6babd..fa65b1188 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_endpoint.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_endpoint.h
@@ -60,6 +60,12 @@ enum {
 enum {
 	FI_OPT_MIN_MULTI_RECV,		/* size_t */
 	FI_OPT_CM_DATA_SIZE,		/* size_t */
+	FI_OPT_BUFFERED_MIN,		/* size_t */
+	FI_OPT_BUFFERED_LIMIT,		/* size_t */
+	FI_OPT_SEND_BUF_SIZE,
+	FI_OPT_RECV_BUF_SIZE,
+	FI_OPT_TX_SIZE,
+	FI_OPT_RX_SIZE,
 };
 
 struct fi_ops_ep {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_errno.h b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_errno.h
index 8ee376c2a..63a6acbfd 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_errno.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_errno.h
@@ -118,7 +118,7 @@ extern "C" {
 //#define	FI_EMULTIHOP		EMULTIHOP	/* Multihop attempted */
 //#define	FI_EDOTDOT		EDOTDOT		/* RFS specific error */
 //#define	FI_EBADMSG		EBADMSG		/* Not a data message */
-//#define	FI_EOVERFLOW		EOVERFLOW	/* Value too large for defined data type */
+#define	FI_EOVERFLOW		EOVERFLOW	/* Value too large for defined data type */
 //#define	FI_ENOTUNIQ		ENOTUNIQ	/* Name not unique on network */
 //#define	FI_EBADFD		EBADFD		/* File descriptor in bad state */
 //#define	FI_EREMCHG		EREMCHG		/* Remote address changed */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_tagged.h b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_tagged.h
index 75e9785a2..61eba4e86 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_tagged.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/rdma/fi_tagged.h
@@ -41,8 +41,6 @@
 extern "C" {
 #endif
 
-#define FI_CLAIM		(1ULL << 59)
-#define FI_DISCARD		(1ULL << 58)
 
 struct fi_msg_tagged {
 	const struct iovec	*msg_iov;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/shared/ofi_str.h b/src/mpid/ch4/netmod/ofi/libfabric/include/shared/ofi_str.h
new file mode 100644
index 000000000..d352c07a0
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/shared/ofi_str.h
@@ -0,0 +1,54 @@
+/*
+ * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2016-2018 Cisco Systems, Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _OFI_STR_H_
+#define _OFI_STR_H_
+
+#include <string.h>
+
+#include "config.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+int ofi_rm_substr(char *str, const char *substr);
+int ofi_rm_substr_delim(char *str, const char *substr, const char delim);
+char **ofi_split_and_alloc(const char *s, const char *delim, size_t *count);
+void ofi_free_string_array(char **s);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _OFI_STR_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/unix/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/include/unix/osd.h
index dddb25ce1..e07487407 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/unix/osd.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/unix/osd.h
@@ -43,6 +43,10 @@
 #include <netinet/in.h>
 #include <sys/uio.h>
 
+#ifdef HAVE_GLIBC_MALLOC_HOOKS
+# include <malloc.h>
+#endif
+
 /* MSG_NOSIGNAL doesn't exist on OS X */
 #ifndef MSG_NOSIGNAL
 #define MSG_NOSIGNAL 0
@@ -75,6 +79,8 @@
 #define OFI_SOCK_TRY_CONN_AGAIN(err)	\
 	((err) == EINPROGRESS)
 
+#define OFI_MAX_SOCKET_BUF_SIZE	SIZE_MAX
+
 struct util_shm
 {
 	int		shared_fd;
@@ -106,6 +112,11 @@ static inline int ofi_getsockname(SOCKET fd, struct sockaddr *addr, socklen_t *l
 	return getsockname(fd, addr, len);
 }
 
+static inline int ofi_getpeername(SOCKET fd, struct sockaddr *addr, socklen_t *len)
+{
+	return getpeername(fd, addr, len);
+}
+
 static inline SOCKET ofi_socket(int domain, int type, int protocol)
 {
 	return socket(domain, type, protocol);
@@ -127,10 +138,10 @@ static inline ssize_t ofi_recv_socket(SOCKET fd, void *buf, size_t count,
 	return recv(fd, buf, count, flags);
 }
 
-static inline ssize_t ofi_recvfrom_socket(SOCKET fd, const void *buf, size_t count, int flags,
-					  const struct sockaddr *to, socklen_t tolen)
+static inline ssize_t ofi_recvfrom_socket(SOCKET fd, void *buf, size_t count, int flags,
+					  struct sockaddr *from, socklen_t *fromlen)
 {
-	return sendto(fd, buf, count, flags, to, tolen);
+	return recvfrom(fd, buf, count, flags, from, fromlen);
 }
 
 static inline ssize_t ofi_send_socket(SOCKET fd, const void *buf, size_t count,
@@ -155,6 +166,30 @@ static inline ssize_t ofi_readv_socket(SOCKET fd, struct iovec *iov, int iov_cnt
 	return readv(fd, iov, iov_cnt);
 }
 
+static inline ssize_t
+ofi_sendmsg_tcp(SOCKET fd, const struct msghdr *msg, int flags)
+{
+	return sendmsg(fd, msg, flags);
+}
+
+static inline ssize_t
+ofi_sendmsg_udp(SOCKET fd, const struct msghdr *msg, int flags)
+{
+	return sendmsg(fd, msg, flags);
+}
+
+static inline ssize_t
+ofi_recvmsg_tcp(SOCKET fd, struct msghdr *msg, int flags)
+{
+	return recvmsg(fd, msg, flags);
+}
+
+static inline ssize_t
+ofi_recvmsg_udp(SOCKET fd, struct msghdr *msg, int flags)
+{
+	return recvmsg(fd, msg, flags);
+}
+
 static inline int ofi_shutdown(SOCKET socket, int how)
 {
 	return shutdown(socket, how);
@@ -279,6 +314,121 @@ ofi_cpuid(unsigned func, unsigned subfunc, unsigned cpuinfo[4])
 
 #endif /* defined(__x86_64__) || defined(__amd64__) */
 
+typedef void (*ofi_mem_free_hook)(void *, const void *);
+typedef void *(*ofi_mem_realloc_hook)(void *, size_t, const void *);
+
+#ifdef HAVE_GLIBC_MALLOC_HOOKS
+
+static inline void ofi_set_mem_free_hook(ofi_mem_free_hook free_hook)
+{
+#ifdef __INTEL_COMPILER /* ICC */
+# pragma warning push
+# pragma warning disable 1478
+	__free_hook = free_hook;
+# pragma warning pop
+#elif defined __clang__ /* Clang */
+# pragma clang diagnostic push
+# pragma clang diagnostic ignored "-Wdeprecated-declarations"
+	__free_hook = free_hook;
+# pragma clang diagnostic pop
+#elif __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6) /* GCC >= 4.6 */
+# pragma GCC diagnostic push
+# pragma GCC diagnostic ignored "-Wdeprecated-declarations"
+	__free_hook = free_hook;
+# pragma GCC diagnostic pop
+#else /* others */
+	__free_hook = free_hook;
+#endif
+}
+
+static inline void ofi_set_mem_realloc_hook(ofi_mem_realloc_hook realloc_hook)
+{
+#ifdef __INTEL_COMPILER /* ICC */
+# pragma warning push
+# pragma warning disable 1478
+	__realloc_hook = realloc_hook;
+# pragma warning pop
+#elif defined __clang__ /* Clang */
+# pragma clang diagnostic push
+# pragma clang diagnostic ignored "-Wdeprecated-declarations"
+	__realloc_hook = realloc_hook;
+# pragma clang diagnostic pop
+#elif __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6) /* GCC >= 4.6 */
+# pragma GCC diagnostic push
+# pragma GCC diagnostic ignored "-Wdeprecated-declarations"
+	__realloc_hook = realloc_hook;
+# pragma GCC diagnostic pop
+#else /* others */
+	__realloc_hook = realloc_hook;
+#endif
+}
+
+static inline ofi_mem_free_hook ofi_get_mem_free_hook(void)
+{
+#ifdef __INTEL_COMPILER /* ICC */
+# pragma warning push
+# pragma warning disable 1478
+	return __free_hook;
+# pragma warning pop
+#elif defined __clang__ /* Clang */
+# pragma clang diagnostic push
+# pragma clang diagnostic ignored "-Wdeprecated-declarations"
+	return __free_hook;
+# pragma clang diagnostic pop
+#elif __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6) /* GCC >= 4.6 */
+# pragma GCC diagnostic push
+# pragma GCC diagnostic ignored "-Wdeprecated-declarations"
+	return __free_hook;
+# pragma GCC diagnostic pop
+#else /* others */
+	return __free_hook;
+#endif
+}
+
+static inline ofi_mem_realloc_hook ofi_get_mem_realloc_hook(void)
+{
+#ifdef __INTEL_COMPILER /* ICC */
+# pragma warning push
+# pragma warning disable 1478
+	return __realloc_hook;
+# pragma warning pop
+#elif defined __clang__ /* Clang */
+# pragma clang diagnostic push
+# pragma clang diagnostic ignored "-Wdeprecated-declarations"
+	return __realloc_hook;
+# pragma clang diagnostic pop
+#elif __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6) /* GCC >= 4.6 */
+# pragma GCC diagnostic push
+# pragma GCC diagnostic ignored "-Wdeprecated-declarations"
+	return __realloc_hook;
+# pragma GCC diagnostic pop
+#else /* others */
+	return __realloc_hook;
+#endif
+}
+
+#else /* !HAVE_GLIBC_MALLOC_HOOKS */
+
+static inline void ofi_set_mem_free_hook(ofi_mem_free_hook free_hook)
+{
+	OFI_UNUSED(free_hook);
+}
+
+static inline void ofi_set_mem_realloc_hook(ofi_mem_realloc_hook realloc_hook)
+{
+	OFI_UNUSED(realloc_hook);
+}
+
+static inline ofi_mem_free_hook ofi_get_mem_free_hook(void)
+{
+	return NULL;
+}
+
+static inline ofi_mem_realloc_hook ofi_get_mem_realloc_hook(void)
+{
+	return NULL;
+}
 
+#endif /* HAVE_GLIBC_MALLOC_HOOKS */
 
 #endif /* _FI_UNIX_OSD_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/uthash.h b/src/mpid/ch4/netmod/ofi/libfabric/include/uthash.h
index 7e64cac75..f34c1f98a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/uthash.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/uthash.h
@@ -1,5 +1,5 @@
 /*
-Copyright (c) 2003-2017, Troy D. Hanson     http://troydhanson.github.com/uthash/
+Copyright (c) 2003-2018, Troy D. Hanson     http://troydhanson.github.com/uthash/
 All rights reserved.
 
 Redistribution and use in source and binary forms, with or without
@@ -478,11 +478,20 @@ do {
 
 /* convenience forms of HASH_FIND/HASH_ADD/HASH_DEL */
 #define HASH_FIND_STR(head,findstr,out)                                          \
-    HASH_FIND(hh,head,findstr,(unsigned)uthash_strlen(findstr),out)
+do {                                                                             \
+    unsigned _uthash_hfstr_keylen = (unsigned)uthash_strlen(findstr);            \
+    HASH_FIND(hh, head, findstr, _uthash_hfstr_keylen, out);                     \
+} while (0)
 #define HASH_ADD_STR(head,strfield,add)                                          \
-    HASH_ADD(hh,head,strfield[0],(unsigned)uthash_strlen(add->strfield),add)
+do {                                                                             \
+    unsigned _uthash_hastr_keylen = (unsigned)uthash_strlen((add)->strfield);    \
+    HASH_ADD(hh, head, strfield[0], _uthash_hastr_keylen, add);                  \
+} while (0)
 #define HASH_REPLACE_STR(head,strfield,add,replaced)                             \
-    HASH_REPLACE(hh,head,strfield[0],(unsigned)uthash_strlen(add->strfield),add,replaced)
+do {                                                                             \
+    unsigned _uthash_hrstr_keylen = (unsigned)uthash_strlen((add)->strfield);    \
+    HASH_REPLACE(hh, head, strfield[0], _uthash_hrstr_keylen, add, replaced);    \
+} while (0)
 #define HASH_FIND_INT(head,findint,out)                                          \
     HASH_FIND(hh,head,findint,sizeof(int),out)
 #define HASH_ADD_INT(head,intfield,add)                                          \
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/windows/config.h b/src/mpid/ch4/netmod/ofi/libfabric/include/windows/config.h
index e41c6e9f5..341d0e159 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/windows/config.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/windows/config.h
@@ -50,6 +50,9 @@
 /* psm provider is built */
 /* #undef HAVE_PSM */
 
+/* perf provider is built */
+#define HAVE_PERF 1
+
 /* psm2 provider is built */
 /* #undef HAVE_PSM2 */
 
@@ -68,14 +71,14 @@
 /* Define to 1 if you have the <rdma/rsocket.h> header file. */
 /* #undef HAVE_RDMA_RSOCKET_H */
 
-/* sockets provider is built */
-#define HAVE_SOCKETS 1
-
 /* UDP provider is built */
 #define HAVE_UDP 1
 
-/* TCP provider is built */
-#define HAVE_TCP 1
+/* UDP provider is built as DSO */
+/* #undef HAVE_UDP_DL */
+
+/* sockets provider is built */
+#define HAVE_SOCKETS 1
 
 /* sockets provider is built as DSO */
 /* #undef HAVE_SOCKETS_DL */
@@ -159,7 +162,7 @@
 #define PACKAGE_NAME "libfabric"
 
 /* Define to the full name and version of this package. */
-#define PACKAGE_STRING "libfabric 1.6.2"
+#define PACKAGE_STRING "libfabric 1.7.0"
 
 /* Define to the one symbol short name of this package. */
 #define PACKAGE_TARNAME "libfabric"
@@ -168,7 +171,7 @@
 #define PACKAGE_URL ""
 
 /* Define to the version of this package. */
-#define PACKAGE_VERSION "1.6.2"
+#define PACKAGE_VERSION "1.7.0"
 
 /* Define to 1 if pthread_spin_init is available. */
 /* #undef PT_LOCK_SPIN */
@@ -192,7 +195,7 @@
 /* Version number of package */
 #define _FI_EXP(s) #s
 #define _FI_TO_STRING(s) _FI_EXP(s)
-#define VERSION _FI_TO_STRING(FI_MAJOR_VERSION) "." _FI_TO_STRING(FI_MINOR_VERSION) ".0"
+#define VERSION _FI_TO_STRING(FI_MAJOR_VERSION) "." _FI_TO_STRING(FI_MINOR_VERSION) ".1a1"
 
 #ifndef BUILD_ID
 #define BUILD_ID ""
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/include/windows/osd.h b/src/mpid/ch4/netmod/ofi/libfabric/include/windows/osd.h
index 61982faae..2258cbecc 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/include/windows/osd.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/include/windows/osd.h
@@ -1,6 +1,7 @@
 /*
  * Copyright (c) 2016 Intel Corporation.  All rights reserved.
  * Copyright (c) 2016 Cisco Systems, Inc.  All rights reserved.
+ * Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
  *
  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
@@ -18,6 +19,7 @@
 #include "config.h"
 
 #include <WinSock2.h>
+#include <Mswsock.h>
 #include <ws2tcpip.h>
 #include <windows.h>
 #include <io.h>
@@ -39,6 +41,8 @@
 extern "C" {
 #endif
 
+#define OFI_MAX_SOCKET_BUF_SIZE	INT_MAX
+
 /*
  * The following defines redefine the Windows Socket
  * errors as BSD errors.
@@ -277,6 +281,7 @@ int fd_set_nonblock(int fd);
 int socketpair(int af, int type, int protocol, int socks[2]);
 void sock_get_ip_addr_table(struct slist *addr_list);
 int ofi_getsockname(SOCKET fd, struct sockaddr *addr, socklen_t *len);
+int ofi_getpeername(SOCKET fd, struct sockaddr *addr, socklen_t *len);
 
 /*
  * Win32 error code should be passed as a parameter.
@@ -712,10 +717,11 @@ static inline ssize_t ofi_recv_socket(SOCKET fd, void *buf, size_t count,
 	return recv(fd, (char *)buf, (int)count, flags);
 }
 
-static inline ssize_t ofi_recvfrom_socket(SOCKET fd, const void *buf, size_t count, int flags,
-					  const struct sockaddr *to, socklen_t tolen)
+static inline ssize_t
+ofi_recvfrom_socket(SOCKET fd, void *buf, size_t count, int flags,
+		    struct sockaddr *from, socklen_t *fromlen)
 {
-	return sendto(fd, (const char*)buf, (int)count, flags, to, tolen);
+	return recvfrom(fd, (char*)buf, (int)count, flags, from, fromlen);
 }
 
 static inline ssize_t ofi_send_socket(SOCKET fd, const void *buf, size_t count,
@@ -724,14 +730,29 @@ static inline ssize_t ofi_send_socket(SOCKET fd, const void *buf, size_t count,
 	return send(fd, (const char*)buf, (int)count, flags);
 }
 
-static inline ssize_t ofi_sendto_socket(SOCKET fd, const void *buf, size_t count, int flags,
-					const struct sockaddr *to, socklen_t tolen)
+static inline ssize_t
+ofi_sendto_socket(SOCKET fd, const void *buf, size_t count, int flags,
+		  const struct sockaddr *to, socklen_t tolen)
 {
 	return sendto(fd, (const char*)buf, (int)count, flags, to, tolen);
 }
 
 ssize_t ofi_writev_socket(SOCKET fd, const struct iovec *iovec, size_t iov_cnt);
 ssize_t ofi_readv_socket(SOCKET fd, const struct iovec *iovec, size_t iov_cnt);
+ssize_t ofi_sendmsg_tcp(SOCKET fd, const struct msghdr *msg, int flags);
+ssize_t ofi_recvmsg_tcp(SOCKET fd, struct msghdr *msg, int flags);
+
+static inline ssize_t
+ofi_sendmsg_udp(SOCKET fd, const struct msghdr *msg, int flags)
+{
+	DWORD bytes;
+	int ret;
+
+	ret = WSASendMsg(fd, msg, flags, &bytes, NULL, NULL);
+	return ret ? ret : bytes;
+}
+
+ssize_t ofi_recvmsg_udp(SOCKET fd, struct msghdr *msg, int flags);
 
 static inline int ofi_shutdown(SOCKET socket, int how)
 {
@@ -817,6 +838,21 @@ static inline int ofi_sysconf(int name)
 
 int ofi_shm_unmap(struct util_shm *shm);
 
+static inline ssize_t ofi_get_hugepage_size(void)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int ofi_alloc_hugepage_buf(void **memptr, size_t size)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int ofi_free_hugepage_buf(void *memptr, size_t size)
+{
+	return -FI_ENOSYS;
+}
+
 static inline int ofi_is_loopback_addr(struct sockaddr *addr) {
 	return (addr->sa_family == AF_INET &&
 		((struct sockaddr_in *)addr)->sin_addr.s_addr == ntohl(INADDR_LOOPBACK)) ||
@@ -936,6 +972,28 @@ ofi_cpuid(unsigned func, unsigned subfunc, unsigned cpuinfo[4])
 
 #endif /* defined(_M_X64) || defined(_M_AMD64) */
 
+typedef void (*ofi_mem_free_hook)(void *, const void *);
+typedef void *(*ofi_mem_realloc_hook)(void *, size_t, const void *);
+
+static inline void ofi_set_mem_free_hook(ofi_mem_free_hook free_hook)
+{
+	OFI_UNUSED(free_hook);
+}
+
+static inline void ofi_set_mem_realloc_hook(ofi_mem_realloc_hook realloc_hook)
+{
+	OFI_UNUSED(realloc_hook);
+}
+
+static inline ofi_mem_free_hook ofi_get_mem_free_hook(void)
+{
+	return NULL;
+}
+
+static inline ofi_mem_realloc_hook ofi_get_mem_realloc_hook(void)
+{
+	return NULL;
+}
 
 #ifdef __cplusplus
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/info.vcxproj b/src/mpid/ch4/netmod/ofi/libfabric/info.vcxproj
index 0beac7e7e..e772aea94 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/info.vcxproj
+++ b/src/mpid/ch4/netmod/ofi/libfabric/info.vcxproj
@@ -30,8 +30,8 @@
     <ProjectGuid>{90850937-D15C-491D-B294-66DCA165254D}</ProjectGuid>
     <Keyword>Win32Proj</Keyword>
     <RootNamespace>info</RootNamespace>
-    <WindowsTargetPlatformVersion>8.1</WindowsTargetPlatformVersion>
   </PropertyGroup>
+  <Import Project="$(SolutionDir)\Libfabric.Build.Default.props" />
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
   <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'" Label="Configuration">
     <ConfigurationType>Application</ConfigurationType>
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/libfabric.map.in b/src/mpid/ch4/netmod/ofi/libfabric/libfabric.map.in
index ef2f53d47..53a3ed3c9 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/libfabric.map.in
+++ b/src/mpid/ch4/netmod/ofi/libfabric/libfabric.map.in
@@ -24,3 +24,10 @@ FABRIC_1.1 {
 		fi_dupinfo;
 		fi_fabric;
 } FABRIC_1.0;
+
+FABRIC_1.2 {
+	global:
+		fi_getinfo;
+		fi_freeinfo;
+		fi_dupinfo;
+} FABRIC_1.1;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/libfabric.vcxproj b/src/mpid/ch4/netmod/ofi/libfabric/libfabric.vcxproj
index 15b84a539..43a05e722 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/libfabric.vcxproj
+++ b/src/mpid/ch4/netmod/ofi/libfabric/libfabric.vcxproj
@@ -1,4 +1,4 @@
-﻿<?xml version="1.0" encoding="utf-8"?>
+<?xml version="1.0" encoding="utf-8"?>
 <Project DefaultTargets="Build" ToolsVersion="14.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
   <ItemGroup Label="ProjectConfigurations">
     <ProjectConfiguration Include="Debug-ICC|x64">
@@ -30,8 +30,8 @@
     <ProjectGuid>{6B3A874F-B14C-4F16-B7C3-31E94859AE3E}</ProjectGuid>
     <Keyword>Win32Proj</Keyword>
     <RootNamespace>libfabric</RootNamespace>
-    <WindowsTargetPlatformVersion>8.1</WindowsTargetPlatformVersion>
   </PropertyGroup>
+  <Import Project="$(SolutionDir)\Libfabric.Build.Default.props" />
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
   <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'" Label="Configuration">
     <ConfigurationType>DynamicLibrary</ConfigurationType>
@@ -125,7 +125,7 @@
       <Optimization>Disabled</Optimization>
       <PreprocessorDefinitions>WIN32;_WINSOCKAPI_=;_CRT_SECURE_NO_WARNINGS;_WINSOCK_DEPRECATED_NO_WARNINGS;_WINDOWS;_USRDLL;LIBFABRIC_EXPORTS;HAVE_CONFIG_H;ENABLE_DEBUG;%(PreprocessorDefinitions)</PreprocessorDefinitions>
       <SDLCheck>true</SDLCheck>
-      <AdditionalIncludeDirectories>$(ProjectDir);$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect</AdditionalIncludeDirectories>
+      <AdditionalIncludeDirectories>$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect;$(ProjectDir)prov\hook\src;$(ProjectDir)prov\hook\include;$(ProjectDir)prov\hook\perf\include</AdditionalIncludeDirectories>
       <CompileAs>CompileAsC</CompileAs>
       <DisableSpecificWarnings>4127;4200;4204;4221;4115;4201;4100</DisableSpecificWarnings>
       <C99Support>true</C99Support>
@@ -148,7 +148,7 @@
       <Optimization>Disabled</Optimization>
       <PreprocessorDefinitions>WIN32;_WINSOCKAPI_=;_CRT_SECURE_NO_WARNINGS;_WINSOCK_DEPRECATED_NO_WARNINGS;_WINDOWS;_USRDLL;LIBFABRIC_EXPORTS;HAVE_CONFIG_H;ENABLE_DEBUG;%(PreprocessorDefinitions)</PreprocessorDefinitions>
       <SDLCheck>true</SDLCheck>
-      <AdditionalIncludeDirectories>$(ProjectDir);$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect</AdditionalIncludeDirectories>
+      <AdditionalIncludeDirectories>$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect;$(ProjectDir)prov\hook\src;$(ProjectDir)prov\hook\include;$(ProjectDir)prov\hook\perf\include;</AdditionalIncludeDirectories>
       <CompileAs>CompileAsC</CompileAs>
       <DisableSpecificWarnings>4127;4200;4204;4221;4115;4201;4100</DisableSpecificWarnings>
       <C99Support>true</C99Support>
@@ -171,7 +171,7 @@
       <Optimization>Disabled</Optimization>
       <PreprocessorDefinitions>WIN32;_WINSOCKAPI_=;_CRT_SECURE_NO_WARNINGS;_WINSOCK_DEPRECATED_NO_WARNINGS;_WINDOWS;_USRDLL;LIBFABRIC_EXPORTS;HAVE_CONFIG_H;ENABLE_DEBUG;%(PreprocessorDefinitions)</PreprocessorDefinitions>
       <SDLCheck>true</SDLCheck>
-      <AdditionalIncludeDirectories>$(ProjectDir);$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect</AdditionalIncludeDirectories>
+      <AdditionalIncludeDirectories>$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect;$(ProjectDir)prov\hook\src;$(ProjectDir)prov\hook\include;$(ProjectDir)prov\hook\perf\include</AdditionalIncludeDirectories>
       <CompileAs>CompileAsC</CompileAs>
       <DisableSpecificWarnings>4127;4200;94;4204;4221;869</DisableSpecificWarnings>
       <C99Support>true</C99Support>
@@ -195,7 +195,7 @@
       <IntrinsicFunctions>true</IntrinsicFunctions>
       <PreprocessorDefinitions>WIN32;_WINSOCKAPI_=;_CRT_SECURE_NO_WARNINGS;_WINSOCK_DEPRECATED_NO_WARNINGS;_WINDOWS;_USRDLL;LIBFABRIC_EXPORTS;HAVE_CONFIG_H;%(PreprocessorDefinitions)</PreprocessorDefinitions>
       <SDLCheck>true</SDLCheck>
-      <AdditionalIncludeDirectories>$(ProjectDir);$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect</AdditionalIncludeDirectories>
+      <AdditionalIncludeDirectories>$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect;$(ProjectDir)prov\hook\src;$(ProjectDir)prov\hook\include;$(ProjectDir)prov\hook\perf\include</AdditionalIncludeDirectories>
       <DisableSpecificWarnings>4127;4200;4204;4221;4115;4201;4100</DisableSpecificWarnings>
       <C99Support>true</C99Support>
       <ShowIncludes>false</ShowIncludes>
@@ -220,7 +220,7 @@
       <IntrinsicFunctions>true</IntrinsicFunctions>
       <PreprocessorDefinitions>WIN32;_WINSOCKAPI_=;_CRT_SECURE_NO_WARNINGS;_WINSOCK_DEPRECATED_NO_WARNINGS;_WINDOWS;_USRDLL;LIBFABRIC_EXPORTS;HAVE_CONFIG_H;%(PreprocessorDefinitions)</PreprocessorDefinitions>
       <SDLCheck>true</SDLCheck>
-      <AdditionalIncludeDirectories>$(ProjectDir);$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect</AdditionalIncludeDirectories>
+      <AdditionalIncludeDirectories>$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect;$(ProjectDir)prov\hook\src;$(ProjectDir)prov\hook\include;$(ProjectDir)prov\hook\perf\include;</AdditionalIncludeDirectories>
       <DisableSpecificWarnings>4127;4200;4204;4221;4115;4201;4100</DisableSpecificWarnings>
       <C99Support>true</C99Support>
       <ShowIncludes>false</ShowIncludes>
@@ -245,7 +245,7 @@
       <IntrinsicFunctions>true</IntrinsicFunctions>
       <PreprocessorDefinitions>WIN32;_WINSOCKAPI_=;_CRT_SECURE_NO_WARNINGS;_WINSOCK_DEPRECATED_NO_WARNINGS;_WINDOWS;_USRDLL;LIBFABRIC_EXPORTS;HAVE_CONFIG_H;%(PreprocessorDefinitions)</PreprocessorDefinitions>
       <SDLCheck>true</SDLCheck>
-      <AdditionalIncludeDirectories>$(ProjectDir);$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect</AdditionalIncludeDirectories>
+      <AdditionalIncludeDirectories>$(ProjectDir)include;$(ProjectDir)include\windows;$(ProjectDir)prov\netdir\NetDirect;$(ProjectDir)prov\hook\src;$(ProjectDir)prov\hook\include;$(ProjectDir)prov\hook\perf\include;</AdditionalIncludeDirectories>
       <DisableSpecificWarnings>4127;4200;94;4204;4221;869</DisableSpecificWarnings>
       <C99Support>true</C99Support>
       <ShowIncludes>false</ShowIncludes>
@@ -262,6 +262,17 @@
     </Link>
   </ItemDefinitionGroup>
   <ItemGroup>
+    <ClCompile Include="prov\hook\perf\src\hook_perf.c" />
+    <ClCompile Include="prov\hook\src\hook.c" />
+    <ClCompile Include="prov\hook\src\hook_av.c" />
+    <ClCompile Include="prov\hook\src\hook_cm.c" />
+    <ClCompile Include="prov\hook\src\hook_cntr.c" />
+    <ClCompile Include="prov\hook\src\hook_cq.c" />
+    <ClCompile Include="prov\hook\src\hook_domain.c" />
+    <ClCompile Include="prov\hook\src\hook_ep.c" />
+    <ClCompile Include="prov\hook\src\hook_eq.c" />
+    <ClCompile Include="prov\hook\src\hook_wait.c" />
+    <ClCompile Include="prov\hook\src\hook_xfer.c" />
     <ClCompile Include="prov\netdir\src\netdir_cntr.c" />
     <ClCompile Include="prov\netdir\src\netdir_ep_msg.c" />
     <ClCompile Include="prov\netdir\src\netdir_ep_rma.c" />
@@ -274,6 +285,10 @@
     <ClCompile Include="prov\rxd\src\rxd_cq.c" />
     <ClCompile Include="prov\rxd\src\rxd_domain.c" />
     <ClCompile Include="prov\rxd\src\rxd_ep.c" />
+    <ClCompile Include="prov\rxd\src\rxd_msg.c" />
+    <ClCompile Include="prov\rxd\src\rxd_tagged.c" />
+    <ClCompile Include="prov\rxd\src\rxd_rma.c" />
+    <ClCompile Include="prov\rxd\src\rxd_atomic.c" />
     <ClCompile Include="prov\rxd\src\rxd_fabric.c" />
     <ClCompile Include="prov\rxd\src\rxd_init.c">
       <ForcedIncludeFiles Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'">
@@ -289,14 +304,15 @@
       <ForcedIncludeFiles Condition="'$(Configuration)|$(Platform)'=='Release-ICC|x64'">
       </ForcedIncludeFiles>
     </ClCompile>
-    <ClCompile Include="prov\rxd\src\rxd_rma.c" />
     <ClCompile Include="prov\rxm\src\rxm_attr.c" />
     <ClCompile Include="prov\rxm\src\rxm_conn.c" />
     <ClCompile Include="prov\rxm\src\rxm_rma.c" />
     <ClCompile Include="prov\rxm\src\rxm_cq.c" />
+    <ClCompile Include="prov\rxm\src\rxm_av.c" />
     <ClCompile Include="prov\rxm\src\rxm_domain.c" />
     <ClCompile Include="prov\rxm\src\rxm_ep.c" />
     <ClCompile Include="prov\rxm\src\rxm_fabric.c" />
+    <ClCompile Include="prov\rxm\src\rxm_atomic.c" />
     <ClCompile Include="prov\rxm\src\rxm_init.c">
       <ForcedIncludeFiles Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'">
       </ForcedIncludeFiles>
@@ -312,14 +328,6 @@
       </ForcedIncludeFiles>
     </ClCompile>
     <ClCompile Include="prov\netdir\src\netdir_addr.c" />
-    <ClCompile Include="prov\netdir\src\netdir_attr.c">
-      <UseMSVC Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'">false</UseMSVC>
-      <UseMSVC Condition="'$(Configuration)|$(Platform)'=='Debug-v141|x64'">false</UseMSVC>
-      <UseMSVC Condition="'$(Configuration)|$(Platform)'=='Debug-ICC|x64'">false</UseMSVC>
-      <UseMSVC Condition="'$(Configuration)|$(Platform)'=='Release-v140|x64'">false</UseMSVC>
-      <UseMSVC Condition="'$(Configuration)|$(Platform)'=='Release-v141|x64'">false</UseMSVC>
-      <UseMSVC Condition="'$(Configuration)|$(Platform)'=='Release-ICC|x64'">false</UseMSVC>
-    </ClCompile>
     <ClCompile Include="prov\netdir\src\netdir_ov.c" />
     <ClCompile Include="prov\netdir\src\netdir_cq.c" />
     <ClCompile Include="prov\netdir\src\netdir_domain.c" />
@@ -509,10 +517,13 @@
     <ClCompile Include="prov\tcp\src\tcpx_attr.c" />
     <ClCompile Include="prov\tcp\src\tcpx_comm.c" />
     <ClCompile Include="prov\tcp\src\tcpx_conn_mgr.c" />
+    <ClCompile Include="prov\tcp\src\tcpx_shared_ctx.c" />
     <ClCompile Include="prov\tcp\src\tcpx_cq.c" />
     <ClCompile Include="prov\tcp\src\tcpx_domain.c" />
+    <ClCompile Include="prov\tcp\src\tcpx_rma.c" />
     <ClCompile Include="prov\tcp\src\tcpx_ep.c" />
     <ClCompile Include="prov\tcp\src\tcpx_fabric.c" />
+    <ClCompile Include="prov\tcp\src\tcpx_eq.c" />
     <ClCompile Include="prov\tcp\src\tcpx_init.c" />
     <ClCompile Include="prov\tcp\src\tcpx_progress.c" />
     <ClCompile Include="prov\udp\src\udpx_attr.c" />
@@ -555,10 +566,12 @@
     <ClCompile Include="src\fi_tostr.c" />
     <ClCompile Include="src\indexer.c" />
     <ClCompile Include="src\iov.c" />
+    <ClCompile Include="src\shared\ofi_str.c" />
     <ClCompile Include="src\log.c" />
     <ClCompile Include="src\perf.c" />
     <ClCompile Include="src\mem.c" />
     <ClCompile Include="src\rbtree.c" />
+    <ClCompile Include="src\tree.c" />
     <ClCompile Include="src\var.c" />
     <ClCompile Include="src\windows\osd.c" />
   </ItemGroup>
@@ -568,6 +581,7 @@
     <ClInclude Include="include\ofi_abi.h" />
     <ClInclude Include="include\ofi_atom.h" />
     <ClInclude Include="include\ofi_atomic.h" />
+    <ClInclude Include="include\ofi_hook.h" />
     <ClInclude Include="include\ofi_mr.h" />
     <ClInclude Include="include\ofi_net.h" />
     <ClInclude Include="include\ofi_enosys.h" />
@@ -575,6 +589,7 @@
     <ClInclude Include="include\ofi_iov.h" />
     <ClInclude Include="include\ofi_indexer.h" />
     <ClInclude Include="include\ofi_list.h" />
+    <ClInclude Include="include\shared\ofi_str.h" />
     <ClInclude Include="include\ofi_lock.h" />
     <ClInclude Include="include\ofi_mem.h" />
     <ClInclude Include="include\ofi_osd.h" />
@@ -582,6 +597,7 @@
     <ClInclude Include="include\ofi_proto.h" />
     <ClInclude Include="include\ofi_rbuf.h" />
     <ClInclude Include="include\ofi_signal.h" />
+    <ClInclude Include="include\ofi_tree.h" />
     <ClInclude Include="include\ofi_util.h" />
     <ClInclude Include="include\ofi_prov.h" />
     <ClInclude Include="include\rbtree.h" />
@@ -619,15 +635,16 @@
     <ClInclude Include="include\windows\sys\uio.h" />
     <ClInclude Include="include\windows\sys\wait.h" />
     <ClInclude Include="include\windows\unistd.h" />
+    <ClInclude Include="prov\hook\src\hook.h" />
     <ClInclude Include="prov\netdir\src\netdir_buf.h" />
     <ClInclude Include="prov\netdir\src\netdir_cq.h" />
     <ClInclude Include="prov\netdir\src\netdir_queue.h" />
     <ClInclude Include="prov\netdir\src\netdir_unexp.h" />
     <ClInclude Include="prov\netdir\src\netdir_util.h" />
     <ClInclude Include="prov\rxd\src\rxd.h" />
+    <ClInclude Include="prov\rxd\src\rxd_proto.h" />
     <ClInclude Include="prov\rxm\src\rxm.h" />
     <ClInclude Include="prov\netdir\src\netdir.h" />
-    <ClInclude Include="prov\netdir\src\netdir_err.h" />
     <ClInclude Include="prov\netdir\src\netdir_iface.h" />
     <ClInclude Include="prov\netdir\src\netdir_log.h" />
     <ClInclude Include="prov\netdir\src\netdir_ov.h" />
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/libfabric.vcxproj.filters b/src/mpid/ch4/netmod/ofi/libfabric/libfabric.vcxproj.filters
index 323fc1c68..c0348416f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/libfabric.vcxproj.filters
+++ b/src/mpid/ch4/netmod/ofi/libfabric/libfabric.vcxproj.filters
@@ -1,4 +1,4 @@
-﻿<?xml version="1.0" encoding="utf-8"?>
+<?xml version="1.0" encoding="utf-8"?>
 <Project ToolsVersion="4.0" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
   <ItemGroup>
     <Filter Include="Source Files">
@@ -97,6 +97,18 @@
     <Filter Include="Source Files\prov\tcp\src">
       <UniqueIdentifier>{8c151366-dd08-48d5-aa21-50a500cbde73}</UniqueIdentifier>
     </Filter>
+    <Filter Include="Source Files\prov\hook">
+      <UniqueIdentifier>{b85ecf6c-fb76-4d65-a7f0-cba470a0adee}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Source Files\prov\hook\src">
+      <UniqueIdentifier>{b4689956-b61f-4c5b-b827-9af0797ea087}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Source Files\prov\hook\perf">
+      <UniqueIdentifier>{06bbf944-2165-474f-a574-2e61ec0bec25}</UniqueIdentifier>
+    </Filter>
+    <Filter Include="Source Files\prov\hook\perf\src">
+      <UniqueIdentifier>{be316a01-6bff-4203-b070-ffaa66bb398e}</UniqueIdentifier>
+    </Filter>
   </ItemGroup>
   <ItemGroup>
     <ClCompile Include="src\common.c">
@@ -123,12 +135,18 @@
     <ClCompile Include="src\perf.c">
       <Filter>Source Files\src</Filter>
     </ClCompile>
+    <ClCompile Include="src\shared\ofi_str.c">
+      <Filter>Source Files\src\shared</Filter>
+    </ClCompile>
     <ClCompile Include="src\mem.c">
       <Filter>Source Files\src</Filter>
     </ClCompile>
     <ClCompile Include="src\rbtree.c">
       <Filter>Source Files\src</Filter>
     </ClCompile>
+    <ClCompile Include="src\tree.c">
+      <Filter>Source Files\src</Filter>
+    </ClCompile>
     <ClCompile Include="src\var.c">
       <Filter>Source Files\src</Filter>
     </ClCompile>
@@ -273,15 +291,24 @@
     <ClCompile Include="prov\rxd\src\rxd_ep.c">
       <Filter>Source Files\prov\rxd\src</Filter>
     </ClCompile>
-    <ClCompile Include="prov\rxd\src\rxd_fabric.c">
+    <ClCompile Include="prov\rxd\src\rxd_msg.c">
       <Filter>Source Files\prov\rxd\src</Filter>
     </ClCompile>
-    <ClCompile Include="prov\rxd\src\rxd_init.c">
+    <ClCompile Include="prov\rxd\src\rxd_tagged.c">
       <Filter>Source Files\prov\rxd\src</Filter>
     </ClCompile>
     <ClCompile Include="prov\rxd\src\rxd_rma.c">
       <Filter>Source Files\prov\rxd\src</Filter>
     </ClCompile>
+    <ClCompile Include="prov\rxd\src\rxd_atomic.c">
+      <Filter>Source Files\prov\rxd\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\rxd\src\rxd_fabric.c">
+      <Filter>Source Files\prov\rxd\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\rxd\src\rxd_init.c">
+      <Filter>Source Files\prov\rxd\src</Filter>
+    </ClCompile>
     <ClCompile Include="prov\rxm\src\rxm_attr.c">
       <Filter>Source Files\prov\rxm\src</Filter>
     </ClCompile>
@@ -291,6 +318,9 @@
     <ClCompile Include="prov\rxm\src\rxm_cq.c">
       <Filter>Source Files\prov\rxm\src</Filter>
     </ClCompile>
+    <ClCompile Include="prov\rxm\src\rxm_av.c">
+      <Filter>Source Files\prov\rxm\src</Filter>
+    </ClCompile>
     <ClCompile Include="prov\rxm\src\rxm_domain.c">
       <Filter>Source Files\prov\rxm\src</Filter>
     </ClCompile>
@@ -300,6 +330,9 @@
     <ClCompile Include="prov\rxm\src\rxm_fabric.c">
       <Filter>Source Files\prov\rxm\src</Filter>
     </ClCompile>
+    <ClCompile Include="prov\rxm\src\rxm_atomic.c">
+      <Filter>Source Files\prov\rxm\src</Filter>
+    </ClCompile>
     <ClCompile Include="prov\rxm\src\rxm_init.c">
       <Filter>Source Files\prov\rxm\src</Filter>
     </ClCompile>
@@ -312,9 +345,6 @@
     <ClCompile Include="prov\netdir\src\netdir_addr.c">
       <Filter>Source Files\prov\netdir\src</Filter>
     </ClCompile>
-    <ClCompile Include="prov\netdir\src\netdir_attr.c">
-      <Filter>Source Files\prov\netdir\src</Filter>
-    </ClCompile>
     <ClCompile Include="prov\netdir\src\netdir_cq.c">
       <Filter>Source Files\prov\netdir\src</Filter>
     </ClCompile>
@@ -384,18 +414,27 @@
     <ClCompile Include="prov\tcp\src\tcpx_conn_mgr.c">
       <Filter>Source Files\prov\tcp\src</Filter>
     </ClCompile>
+    <ClCompile Include="prov\tcp\src\tcpx_shared_ctx.c">
+      <Filter>Source Files\prov\tcp\src</Filter>
+    </ClCompile>
     <ClCompile Include="prov\tcp\src\tcpx_cq.c">
       <Filter>Source Files\prov\tcp\src</Filter>
     </ClCompile>
     <ClCompile Include="prov\tcp\src\tcpx_domain.c">
       <Filter>Source Files\prov\tcp\src</Filter>
     </ClCompile>
+    <ClCompile Include="prov\tcp\src\tcpx_rma.c">
+      <Filter>Source Files\prov\tcp\src</Filter>
+    </ClCompile>
     <ClCompile Include="prov\tcp\src\tcpx_ep.c">
       <Filter>Source Files\prov\tcp\src</Filter>
     </ClCompile>
     <ClCompile Include="prov\tcp\src\tcpx_fabric.c">
       <Filter>Source Files\prov\tcp\src</Filter>
     </ClCompile>
+    <ClCompile Include="prov\tcp\src\tcpx_eq.c">
+      <Filter>Source Files\prov\tcp\src</Filter>
+    </ClCompile>
     <ClCompile Include="prov\tcp\src\tcpx_init.c">
       <Filter>Source Files\prov\tcp\src</Filter>
     </ClCompile>
@@ -405,6 +444,39 @@
     <ClCompile Include="prov\util\src\util_pep.c">
       <Filter>Source Files\prov\util</Filter>
     </ClCompile>
+    <ClCompile Include="prov\hook\src\hook.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_av.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_cm.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_cntr.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_cq.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_domain.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_ep.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_eq.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_wait.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\src\hook_xfer.c">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClCompile>
+    <ClCompile Include="prov\hook\perf\src\hook_perf.c">
+      <Filter>Source Files\prov\hook\perf\src</Filter>
+    </ClCompile>
   </ItemGroup>
   <ItemGroup>
     <ClInclude Include="include\fasthash.h">
@@ -419,6 +491,9 @@
     <ClInclude Include="include\ofi_indexer.h">
       <Filter>Header Files</Filter>
     </ClInclude>
+    <ClInclude Include="include\shared\ofi_str.h">
+      <Filter>Header Files</Filter>
+    </ClInclude>
     <ClInclude Include="include\ofi_list.h">
       <Filter>Header Files</Filter>
     </ClInclude>
@@ -434,6 +509,9 @@
     <ClInclude Include="include\rbtree.h">
       <Filter>Header Files</Filter>
     </ClInclude>
+    <ClInclude Include="include\ofi_tree.h">
+      <Filter>Header Files</Filter>
+    </ClInclude>
     <ClInclude Include="include\rdma\fabric.h">
       <Filter>Header Files\rdma</Filter>
     </ClInclude>
@@ -560,6 +638,9 @@
     <ClInclude Include="prov\rxd\src\rxd.h">
       <Filter>Source Files\prov\rxd\include</Filter>
     </ClInclude>
+    <ClInclude Include="prov\rxd\src\rxd_proto.h">
+      <Filter>Source Files\prov\rxd\include</Filter>
+    </ClInclude>
     <ClInclude Include="prov\rxm\src\rxm.h">
       <Filter>Source Files\prov\rxm\include</Filter>
     </ClInclude>
@@ -572,9 +653,6 @@
     <ClInclude Include="prov\netdir\src\netdir_iface.h">
       <Filter>Source Files\prov\netdir\include</Filter>
     </ClInclude>
-    <ClInclude Include="prov\netdir\src\netdir_err.h">
-      <Filter>Source Files\prov\netdir\include</Filter>
-    </ClInclude>
     <ClInclude Include="prov\netdir\src\netdir_ov.h">
       <Filter>Source Files\prov\netdir\include</Filter>
     </ClInclude>
@@ -623,6 +701,9 @@
     <ClInclude Include="include\windows\netdb.h">
       <Filter>Header Files\windows</Filter>
     </ClInclude>
+    <ClInclude Include="prov\hook\src\hook.h">
+      <Filter>Source Files\prov\hook\src</Filter>
+    </ClInclude>
   </ItemGroup>
   <ItemGroup>
     <None Include="libfabric.def">
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fabric.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fabric.7.md
index 905534907..e54c50f9f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fabric.7.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fabric.7.md
@@ -238,6 +238,34 @@ FI_LOG_SUBSYS environment variables.
 - *mr*
 : Provides output specific to memory registration.
 
+# PROVIDER INSTALLATION AND SELECTION
+
+The libfabric build scripts will install all providers that are supported
+by the installation system.  Providers that are missing build prerequisites
+will be disabled.  Installed providers will dynamically check for necessary
+hardware on library initialization and respond appropriately to application
+queries.
+
+Users can enable or disable available providers through build configuration
+options.  See 'configure --help' for details.  In general, a specific provider
+can be controlled using the configure option '--enable-<provider_name>'.  For
+example, '--enable-udp' (or '--enable-udp=yes') will add the udp provider to the
+build.  To disable the provider, '--enable-udp=no' can be used.
+
+Providers can also be enable or disabled at run time using the FI_PROVIDER
+environment variable.  The FI_PROVIDER variable is set to a comma separated
+list of providers to include.  If the list begins with the '^' symbol, then
+the list will be negated.
+
+  Example: To enable the udp and tcp providers only, set:
+	FI_PROVIDER="udp,tcp"
+
+The fi_info utility, which is included as part of the libfabric package, can
+be used to retrieve information about which providers are available in the
+system.  Additionally, it can retrieve a list of all environment variables
+that may be used to configure libfabric and each provider.  See
+[`fi_info`(1)](fi_info.1.html) for more details.
+
 # NOTES
 
 Because libfabric is designed to provide applications direct access to
@@ -258,6 +286,7 @@ portability across providers.
 
 # SEE ALSO
 
+[`fi_info`(1)](fi_info.1.html),
 [`fi_provider`(7)](fi_provider.7.html),
 [`fi_getinfo`(3)](fi_getinfo.3.html),
 [`fi_endpoint`(3)](fi_endpoint.3.html),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_atomic.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_atomic.3.md
index 7a3ff9cdc..85f261e1c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_atomic.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_atomic.3.md
@@ -143,7 +143,9 @@ int fi_query_atomic(struct fid_domain *domain,
 : Additional flags to apply for the atomic operation
 
 *context*
-: User specified pointer to associate with the operation.
+: User specified pointer to associate with the operation.  This parameter is
+  ignored if the operation will not generate a successful completion, unless
+  an op flag specifies the context parameter be used for required input.
 
 # DESCRIPTION
 
@@ -518,19 +520,31 @@ size field indicates the size in bytes of the atomic datatype.
 
 ## Completions
 
-Completed atomic operations are reported to the user through one or
-more event collectors associated with the endpoint.  Users provide
-context which are associated with each operation, and is returned to
-the user as part of the event completion.  See fi_cq for completion
-event details.
-
-Updates to the target buffer of an atomic operation are visible to
-processes running on the target system either after a completion has
-been generated, or after the completion of an operation initiated
-after the atomic call with a fencing operation occurring in between.
-For example, the target process may be notified by the initiator
-sending a message after the atomic call completes, or sending a fenced
-message immediately after initiating the atomic operation.
+Completed atomic operations are reported to the initiator of the
+request through an associated completion queue or counter.
+Any user provided context specified with the request will be
+returned as part of any completion event written to a CQ.
+See fi_cq for completion event details.
+
+Any results returned to the initiator as part of an atomic operation
+will be available prior to a completion event being generated.  This
+will be true even if the requested completion semantic provides a weaker
+guarantee.  That is, atomic fetch operations have FI_DELIVERY_COMPLETE
+semantics.  Completions generated for other types of atomic operations
+indicate that it is safe to re-use the source data buffers.
+
+Any updates to data at the target of an atomic operation will be
+visible to processes running on the target node prior to one of
+the following occurring.  If the atomic operation generates a
+completion event or updates a completion counter at the target
+endpoint, the results will be available prior to the completion
+notification.  After processing a completion for the atomic, if
+the initiator submits a transfer between the same endpoints that
+generates a completion at the target, the results will be available
+prior to the subsequent transfer's event.  Or, if a fenced data
+transfer from the initiator follows the atomic request, the results
+will be available prior to a completion at the target for the
+fenced transfer.
 
 # FLAGS
 
@@ -554,13 +568,15 @@ with atomic message calls.
   its access to the fabric hardware.
 
 *FI_INJECT*
-: Indicates that the outbound non-const data buffers (buf and compare
-  parameters) should be returned to user immediately after the call
-  returns, even if the operation is handled asynchronously.  This may
-  require that the underlying provider implementation copy the data
-  into a local buffer and transfer out of that buffer.  The use of
-  output result buffers are not affected by this flag. This flag can only
-  be used with messages smaller than inject_size.
+: Indicates that the control of constant data buffers should be returned to
+  the user immediately after the call returns, even if the operation
+  is handled asynchronously.  This may require that the underlying
+  provider implementation copy the data into a local buffer and
+  transfer out of that buffer.  Constant data buffers refers to any
+  data buffer or iovec used by the atomic APIs that are marked as
+  'const'.  Non-constant or output buffers are unaffected by this flag
+  and may be accessed by the provider at anytime until the operation has
+  completed. This flag can only be used with messages smaller than inject_size.
 
 *FI_FENCE*
 : Applies to transmits.  Indicates that the requested operation, also
@@ -622,6 +638,14 @@ parameter.  This must be between 1 and the maximum returned through the
 relevant valid operation, inclusive.  The requested operation and data
 type must also be valid for the given provider.
 
+The ordering of atomic operations carried as part of different request
+messages is subject to the message and data ordering definitions assigned
+to the transmitting and receiving endpoints.  Both message and data ordering
+are required if the results of two atomic operations to the same memory
+buffers are to reflect the second operation acting on the results of the
+first.  See [`fi_endpoint`(3)](fi_endpoint.3.html) for further details
+and message size restrictions.
+
 # SEE ALSO
 
 [`fi_getinfo`(3)](fi_getinfo.3.html),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_cntr.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_cntr.3.md
index 0c203ad61..cddfaf64c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_cntr.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_cntr.3.md
@@ -258,8 +258,15 @@ counter values (e.g. fi_cntr_set or fi_cntr_add) may not be immediately
 visible to counter read operations (i.e. fi_cntr_read or fi_cntr_readerr).
 A small, but undefined, delay may occur between the counter changing and
 the reported value being updated.  However, a final updated value will
-eventually be reflected in the read counter value, with the order of the
-updates maintained.
+eventually be reflected in the read counter value.
+
+Additionally, applications should ensure that the value of a counter is
+stable and not subject to change prior to calling fi_cntr_set
+or fi_cntr_seterr.  Otherwise, the resulting value of the counter after
+fi_cntr_set / fi_cntr_seterr is undefined, as updates to the counter may
+be lost.  A counter value is considered stable if all previous
+updates using fi_cntr_set / fi_cntr_seterr and results of related operations
+are reflected in the observed value of the counter.
 
 # SEE ALSO
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_cq.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_cq.3.md
index 1657e2857..c1eaa8769 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_cq.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_cq.3.md
@@ -353,23 +353,26 @@ be the same as the count parameter.
 
 Returned source addressing data is converted from the native address
 used by the underlying fabric into an fi_addr_t, which may be used in
-transmit operations.  Typically, returning fi_addr_t requires that
-the source address be inserted into the address vector associated with the
-receiving endpoint.  For endpoints allocated using the FI_SOURCE_ERR
-capability, if the source address has not been inserted into the
-address vector, fi_cq_readfrom will return -FI_EAVAIL.  The
-completion will then be reported through fi_cq_readerr with error
-code -FI_EADDRNOTAVAIL.  See fi_cq_readerr for details.
+transmit operations.  Under most circumstances, returning fi_addr_t
+requires that the source address already have been inserted into the
+address vector associated with the receiving endpoint.  This is true for
+address vectors of type FI_AV_TABLE.  In select providers when FI_AV_MAP is
+used, source addresses may be converted algorithmically into a
+usable fi_addr_t, even though the source address has not been inserted
+into the address vector.  This is permitted by the API, as it allows
+the provider to avoid address look-up as part of receive message processing.
+In no case do providers insert addresses into an AV separate from an
+application calling fi_av_insert or similar call.
+
+For endpoints allocated using the FI_SOURCE_ERR capability, if the
+source address cannot be converted into a valid fi_addr_t value,
+fi_cq_readfrom will return -FI_EAVAIL, even if the data were received
+successfully.  The completion will then be reported through fi_cq_readerr
+with error code -FI_EADDRNOTAVAIL.  See fi_cq_readerr for details.
 
 If FI_SOURCE is specified without FI_SOURCE_ERR, source addresses
-which cannot be mapped to a local fi_addr_t will be reported as
-FI_ADDR_NOTAVAIL.  The behavior is dependent on the type of address
-vector in use.  For AVs of type FI_AV_MAP, source addresses may be
-mapped directly to an fi_addr_t value, even if the source address
-were not inserted into the AV.  This allows the provider to optimize
-the reporting of the source fi_addr_t without the overhead of
-verifying whether the address is in the AV.  If full address
-validation is necessary, FI_SOURCE_ERR must be used.
+which cannot be mapped to a usable fi_addr_t will be reported as
+FI_ADDR_NOTAVAIL.
 
 ## fi_cq_sread / fi_cq_sreadfrom
 
@@ -415,11 +418,20 @@ convert provider specific error information into a printable string
 for debugging purposes.  See field details below for more information
 on the use of err_data and err_data_size.
 
+Note that error completions are generated for all operations, including
+those for which a completion was not requested (e.g. an endpoint
+is configured with FI_SELECTIVE_COMPLETION, but the request did not have
+the FI_COMPLETION flag set).  In such cases, providers will return as
+much information as made available by the underlying software and
+hardware about the failure, other fields will be set to NULL or 0.  This
+includes the op_context value, which may not have been provided or was
+ignored on input as part of the transfer.
+
 Notable completion error codes are given below.
 
 *FI_EADDRNOTAVAIL*
 : This error code is used by CQs configured with FI_SOURCE_ERR to report
-  completions for which a matching fi_addr_t source address could not
+  completions for which a usable fi_addr_t source address could not
   be found.  An error code of FI_EADDRNOTAVAIL indicates that the data
   transfer was successfully received and processed, with the
   fi_cq_err_entry fields containing information about the completion.
@@ -594,6 +606,130 @@ operation.  The following completion flags are defined.
   buffer has been released, and the completion entry is not associated
   with a received message.
 
+*FI_MORE*
+: See the 'Buffered Receives' section in `fi_msg`(3) for more details.
+  This flag is associated with receive completions on endpoints that
+  have FI_BUFFERED_RECV mode enabled.  When set to one, it indicates that
+  the buffer referenced by the completion is limited by the
+  FI_OPT_BUFFERED_LIMIT threshold, and additional message data must be
+  retrieved by the application using an FI_CLAIM operation.  
+
+*FI_CLAIM*
+: See the 'Buffered Receives' section in `fi_msg`(3) for more details.
+  This flag is set on completions associated with receive operations
+  that claim buffered receive data.  Note that this flag only applies
+  to endpoints configured with the FI_BUFFERED_RECV mode bit.
+
+# COMPLETION EVENT SEMANTICS
+
+Libfabric defines several completion 'levels', identified using operational
+flags.  Each flag indicates the soonest that a completion event may be
+generated by a provider, and the assumptions that an application may make
+upon processing a completion.  The operational flags are defined below,
+along with an example of how a provider might implement the semantic.  Note
+that only meeting the semantic is required of the provider and not the
+implementation.  Providers may implement stronger completion semantics
+than necessary for a given operation, but only the behavior defined by the
+completion level is guaranteed.
+
+To help understand the conceptual differences in completion levels, consider
+mailing a letter.  Placing the letter into the local mailbox for pick-up is
+similar to 'inject complete'.  Having the letter picked up and dropped off
+at the destination mailbox is equivalent to 'transmit complete'.  The
+'delivery complete' semantic is a stronger guarantee, with a person at the
+destination signing for the letter.  However, the person who signed for the
+letter is not necessarily the intended recipient.  The 'match complete'
+option is similar to delivery complete, but requires the intended recipient
+to sign for the letter.
+
+The 'commit complete' level has different semantics than the previously
+mentioned levels.  Commit complete would be closer to the the letter
+arriving at the destination and being placed into a fire proof safe.
+
+The operational flags for the described completion levels are defined below.
+
+*FI_INJECT_COMPLETE*
+: Indicates that a completion should be generated when the
+  source buffer(s) may be reused.  A completion guarantees that
+  the buffers will not be read from again and the application may
+  reclaim them.  No other guarantees are made with respect to the
+  state of the operation.
+
+  Example: A provider may generate this completion event after copying
+  the source buffer into a network buffer, either in host memory or
+  on the NIC.  An inject completion does not indicate that the data has
+  been transmitted onto the network, and a local error could occur after
+  the completion event has been generated that could prevent it from being
+  transmitted.
+
+  Inject complete allows for the fastest completion reporting (and, hence,
+  buffer reuse), but provides the weakest guarantees against network errors.
+
+  Note: This flag is used to control when a completion entry is inserted
+  into a completion queue.  It does not apply to operations that do not
+  generate a completion queue entry, such as the fi_inject operation, and
+  is not subject to the inject_size message limit restriction.
+
+*FI_TRANSMIT_COMPLETE*
+: Indicates that a completion should be generated when the transmit
+  operation has completed relative to the local provider.  The exact
+  behavior is dependent on the endpoint type.
+
+  For reliable endpoints:
+
+  Indicates that a completion should be generated when the operation has
+  been delivered to the peer endpoint.  A completion guarantees that the
+  operation is no longer dependent on the fabric or local resources.  The
+  state of the operation at the peer endpoint is not defined.
+
+  Example: A provider may generate a transmit complete event upon receiving
+  an ack from the peer endpoint.  The state of the message at the peer is
+  unknown and may be buffered in the target NIC at the time the ack has been
+  generated.
+
+  For unreliable endpoints:
+
+  Indicates that a completion should be generated when the operation has
+  been delivered to the fabric.  A completion guarantees that the
+  operation is no longer dependent on local resources.  The state of the
+  operation within the fabric is not defined.
+
+*FI_DELIVERY_COMPLETE*
+: Indicates that a completion should not be generated until an operation
+  has been processed by the destination endpoint(s).  A completion
+  guarantees that the result of the operation is available; however,
+  additional steps may need to be taken at the destination to retrieve the
+  results.  For example, an application may need to provide a receive buffers
+  in order to retrieve messages that were buffered by the provider.
+
+  Delivery complete indicates that the message has been processed by the peer.
+  If an application buffer was ready to receive the results of the message
+  when it arrived, then delivery complete indicates that the data was placed
+  into the application's buffer.
+
+  This completion mode applies only to reliable endpoints.  For operations
+  that return data to the initiator, such as RMA read or atomic-fetch,
+  the source endpoint is also considered a destination endpoint.  This is the
+  default completion mode for such operations.
+
+*FI_MATCH_COMPLETE*
+: Indicates that a completion should be generated only after the operation
+  has been matched with an application specified buffer.  Operations using
+  this completion semantic are dependent on the application at the target
+  claiming the message or results.  As a result, match complete may involve
+  additional provider level acknowledgements or lengthy delays.  However, this
+  completion model enables peer applications to synchronize their execution.
+
+*FI_COMMIT_COMPLETE*
+: Indicates that a completion should not be generated (locally or at the
+  peer) until the result of an operation have been made persistent.
+  A completion guarantees that the result is both available and durable,
+  in the case of power failure.
+
+  This completion mode applies only to operations that target persistent
+  memory regions over reliable endpoints.  This completion mode is
+  experimental.
+
 # NOTES
 
 A completion queue must be bound to at least one enabled endpoint before any
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_endpoint.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_endpoint.3.md
index 33a2c5523..d876de1b5 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_endpoint.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_endpoint.3.md
@@ -284,10 +284,11 @@ together when binding an endpoint to a completion domain CQ.
   into a completion queue after they have successfully completed.
   Applications can use this bind flag to selectively enable when
   completions are generated.  If FI_SELECTIVE_COMPLETION is specified,
-  data transfer operations will not generate entries for successful
+  data transfer operations will not generate entries for _successful_
   completions unless FI_COMPLETION is set as an operational flag for the
-  given operation.  FI_SELECTIVE_COMPLETION must be OR'ed with FI_TRANSMIT
-  and/or FI_RECV flags.
+  given operation.  Operations that fail asynchronously will still generate
+  completions, even if a completion is not requested.  FI_SELECTIVE_COMPLETION
+  must be OR'ed with FI_TRANSMIT and/or FI_RECV flags.
 
   When FI_SELECTIVE_COMPLETION is set, the user must determine when a
   request that does NOT have FI_COMPLETION set has completed indirectly,
@@ -347,22 +348,22 @@ binding an endpoint to a counter, the following flags may be specified.
   and normal message operations.
 
 *FI_READ*
-: Increments the specified counter whenever an RMA read or atomic fetch
-  operation initiated from the endpoint has completed successfully or
-  in error.
+: Increments the specified counter whenever an RMA read, atomic fetch,
+  or atomic compare operation initiated from the endpoint has completed
+  successfully or in error.
 
 *FI_WRITE*
-: Increments the specified counter whenever an RMA write or atomic operation
-  initiated from the endpoint has completed successfully or in error.
+: Increments the specified counter whenever an RMA write or base atomic
+  operation initiated from the endpoint has completed successfully or in error.
 
 *FI_REMOTE_READ*
-: Increments the specified counter whenever an RMA read or
-  atomic fetch operation is initiated from a remote endpoint that
+: Increments the specified counter whenever an RMA read, atomic fetch, or
+  atomic compare operation is initiated from a remote endpoint that
   targets the given endpoint.  Use of this flag requires that the
   endpoint be created using FI_RMA_EVENT.
 
 *FI_REMOTE_WRITE*
-: Increments the specified counter whenever an RMA write or
+: Increments the specified counter whenever an RMA write or base
   atomic operation is initiated from a remote endpoint that targets
   the given endpoint.  Use of this flag requires that the
   endpoint be created using FI_RMA_EVENT.
@@ -513,6 +514,35 @@ The following option levels and option names and parameters are defined.
   the maximum size of the data that may be present as part of a connection
   request event. This option is read only.
 
+- *FI_OPT_BUFFERED_LIMIT - size_t*
+: Defines the maximum size of a buffered message that will be reported
+  to users as part of a receive completion when the FI_BUFFERED_RECV mode
+  is enabled on an endpoint.
+  
+  fi_getopt() will return the currently configured threshold, or the
+  provider's default threshold if one has not be set by the application.
+  fi_setopt() allows an application to configure the threshold.  If the
+  provider cannot support the requested threshold, it will fail the
+  fi_setopt() call with FI_EMSGSIZE.  Calling fi_setopt() with the
+  threshold set to SIZE_MAX will set the threshold to the maximum
+  supported by the provider.  fi_getopt() can then be used to retrieve
+  the set size.
+
+  In most cases, the sending and receiving endpoints must be
+  configured to use the same threshold value, and the threshold must be
+  set prior to enabling the endpoint.
+
+- *FI_OPT_BUFFERED_MIN - size_t*
+: Defines the minimum size of a buffered message that will be reported.
+  Applications would set this to a size that's big enough to decide whether
+  to discard or claim a buffered receive or when to claim a buffered receive
+  on getting a buffered receive completion. The value is typically used by a
+  provider when sending a rendezvous protocol request where it would send
+  atleast FI_OPT_BUFFERED_MIN bytes of application data along with it. A smaller
+  sized renedezvous protocol message usually results in better latency for the
+  overall transfer of a large message.
+
+
 ## fi_rx_size_left (DEPRECATED)
 
 This function has been deprecated and will be removed in a future version
@@ -753,7 +783,9 @@ For example, a mem_tag_format of 0x30FF indicates support for 14
 tagged bits, separated into 3 fields.  The first field consists of
 2-bits, the second field 4-bits, and the final field 8-bits.  Valid
 masks for such a tagged field would be a bitwise OR'ing of zero or
-more of the following values: 0x3000, 0x0F00, and 0x00FF.
+more of the following values: 0x3000, 0x0F00, and 0x00FF. The provider
+may not validate the mask provided by the application for performance
+reasons.
 
 By identifying fields within a tag, a provider may be able to optimize
 their search routines.  An application which requests tag fields must
@@ -763,8 +795,9 @@ can request a specific number of fields of a given size.  A provider
 must return a tag format that supports the requested number of fields,
 with each field being at least the size requested, or fail the
 request.  A provider may increase the size of the fields. When reporting
-completions (see FI_CQ_FORMAT_TAGGED), the provider must provide the 
-exact value of the received tag, clearing out any unsupported tag bits.
+completions (see FI_CQ_FORMAT_TAGGED), it is not guaranteed that the
+provider would clear out any unsupported tag bits in the tag field of
+the completion entry.
 
 It is recommended that field sizes be ordered from smallest to
 largest.  A generic, unstructured tag and mask can be achieved by
@@ -1311,54 +1344,24 @@ value of transmit or receive context attributes of an endpoint.
 
 *FI_INJECT_COMPLETE*
 : Indicates that a completion should be generated when the
-  source buffer(s) may be reused.  A completion guarantees that
-  the buffers will not be read from again and the application may
-  reclaim them.  No other guarantees are made with respect to the
-  state of the operation.
-
-  Note: This flag is used to control when a completion entry is inserted
-  into a completion queue.  It does not apply to operations that do not
-  generate a completion queue entry, such as the fi_inject operation, and
-  is not subject to the inject_size message limit restriction.
+  source buffer(s) may be reused.  See [`fi_cq`(3)](fi_cq.3.html) for
+  additional details on completion semantics.
 
 *FI_TRANSMIT_COMPLETE*
 : Indicates that a completion should be generated when the transmit
-  operation has completed relative to the local provider.  The exact
-  behavior is dependent on the endpoint type.
-
-  For reliable endpoints:
-
-  Indicates that a completion should be generated when the operation has
-  been delivered to the peer endpoint.  A completion guarantees that the
-  operation is no longer dependent on the fabric or local resources.  The
-  state of the operation at the peer endpoint is not defined.
-
-  For unreliable endpoints:
-
-  Indicates that a completion should be generated when the operation has
-  been delivered to the fabric.  A completion guarantees that the
-  operation is no longer dependent on local resources.  The state of the
-  operation within the fabric is not defined.
+  operation has completed relative to the local provider.  See
+  [`fi_cq`(3)](fi_cq.3.html) for additional details on completion semantics.
 
 *FI_DELIVERY_COMPLETE*
-: Indicates that a completion should not be generated until an operation
-  has been processed by the destination endpoint(s).  A completion
-  guarantees that the result of the operation is available.
-
-  This completion mode applies only to reliable endpoints.  For operations
-  that return data to the initiator, such as RMA read or atomic-fetch,
-  the source endpoint is also considered a destination endpoint.  This is the
-  default completion mode for such operations.
+: Indicates that a completion should be generated when the operation has been
+  processed by the destination endpoint(s).  See [`fi_cq`(3)](fi_cq.3.html)
+  for additional details on completion semantics.
 
 *FI_COMMIT_COMPLETE*
 : Indicates that a completion should not be generated (locally or at the
   peer) until the result of an operation have been made persistent.
-  A completion guarantees that the result is both available and durable,
-  in the case of power failure.
-
-  This completion mode applies only to operations that target persistent
-  memory regions over reliable endpoints.  This completion mode is
-  experimental.
+  See [`fi_cq`(3)](fi_cq.3.html) for additional details on completion
+  semantics.
 
 *FI_MULTICAST*
 : Indicates that data transfers will target multicast addresses by default.
@@ -1427,6 +1430,7 @@ Fabric errno values are defined in `rdma/fi_errno.h`.
 
 [`fi_getinfo`(3)](fi_getinfo.3.html),
 [`fi_domain`(3)](fi_domain.3.html),
+[`fi_cq`(3)](fi_cq.3.html)
 [`fi_msg`(3)](fi_msg.3.html),
 [`fi_tagged`(3)](fi_tagged.3.html),
 [`fi_rma`(3)](fi_rma.3.html)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_fabric.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_fabric.3.md
index 5ff66b19b..bb3aa0af4 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_fabric.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_fabric.3.md
@@ -70,7 +70,7 @@ values for the datatype are listed below, along with the corresponding
 datatype or field value.
 
 *FI_TYPE_INFO*
-: struct fi_info
+: struct fi_info, including all substructures and fields
 
 *FI_TYPE_EP_TYPE*
 : struct fi_info::type field
@@ -99,25 +99,51 @@ datatype or field value.
 *FI_TYPE_FABRIC_ATTR*
 : struct fi_fabric_attr
 
-*FI_TYPE_DOMAIN_CAP*
-: struct fi_info::domain_cap field
-
 *FI_TYPE_THREADING*
 : enum fi_threading
 
 *FI_TYPE_PROGRESS*
 : enum fi_progress
 
-*FI_TYPE_PROTO*
+*FI_TYPE_PROTOCOL*
 : struct fi_ep_attr::protocol field
 
 *FI_TYPE_MSG_ORDER*
 : struct fi_ep_attr::msg_order field
 
+*FI_TYPE_MODE*
+: struct fi_info::mode field
+
+*FI_TYPE_AV_TYPE*
+: enum fi_av_type
+
+*FI_TYPE_ATOMIC_TYPE*
+: enum fi_datatype
+
+*FI_TYPE_ATOMIC_OP*
+: enum fi_op
+
 *FI_TYPE_VERSION*
 : Returns the library version of libfabric in string form.  The data
   parameter is ignored.
 
+*FI_TYPE_EQ_EVENT*
+: uint32_t event parameter returned from fi_eq_read().  See `fi_eq(3)`
+  for a list of known values.
+
+*FI_TYPE_CQ_EVENT_FLAGS*
+: uint64_t flags field in fi_cq_xxx_entry structures.  See `fi_cq(3)`
+  for valid flags.
+
+*FI_TYPE_MR_MODE*
+: struct fi_domain_attr::mr_mode flags
+
+*FI_TYPE_OP_TYPE*
+: enum fi_op_type
+
+*FI_TYPE_FID*
+: struct fid *
+
 fi_tostr() will return a pointer to an internal libfabric buffer that
 should not be modified, and will be overwritten the next time
 fi_tostr() is invoked.  fi_tostr() is not thread safe.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_getinfo.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_getinfo.3.md
index 6511b4519..ce0916301 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_getinfo.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_getinfo.3.md
@@ -133,6 +133,7 @@ struct fi_info {
 	struct fi_ep_attr     *ep_attr;
 	struct fi_domain_attr *domain_attr;
 	struct fi_fabric_attr *fabric_attr;
+	struct fid_nic        *nic;
 };
 ```
 
@@ -183,15 +184,15 @@ struct fi_info {
   that any returned address is only usable locally.
 
 *handle - provider context handle*
-: References a provider specific handle.  The use of this field
-  is operation specific.  Unless its use is described for a given operation,
-  the handle field must be NULL.  It is commonly used by applications
-  that make use of connection-oriented endpoints.  For other applications,
-  the field should usually be NULL.
-
-  This field is used when processing connection requests and
-  responses.  It is also used to inherit endpoint's attributes.
-  See fi_eq(3), fi_reject(3), and fi_endpoint(3) .
+: The use of this field is operation specific. If hints->handle is set to struct
+  fid_pep, the hints->handle will be copied to info->handle on output from
+  fi_getinfo.  Other values of hints->handle will be handled in a provider
+  specific manner.  The fi_info::handle field is also used by fi_endpoint()
+  and fi_reject() calls when processing connection requests or to inherit
+  another endpoint's attributes.  See [`fi_eq`(3)](fi_eq.3.html),
+  [`fi_reject`(3)](fi_reject.3.html), and
+  [`fi_endpoint`(3)](fi_endpoint.3.html).  The info->handle field will be
+  ignored by fi_dupinfo and fi_freeinfo.
 
 *tx_attr - transmit context attributes*
 : Optionally supplied transmit context attributes.  Transmit context
@@ -215,7 +216,7 @@ struct fi_info {
   hints, requested values of struct fi_ep_attr should be set.  On
   output, the actual endpoint attributes that can be provided will be
   returned.  Output values will be greater than or equal to requested
-  input values.  See fi_endpoint(3) for details.
+  input values.  See [`fi_endpoint`(3)](fi_endpoint.3.html) for details.
 
 *domain_attr - domain attributes*
 : Optionally supplied domain attributes.  Domain attributes may be
@@ -223,14 +224,21 @@ struct fi_info {
   hints, requested values of struct fi_domain_attr should be set.  On
   output, the actual domain attributes that can be provided will be
   returned.  Output values will be greater than or equal to requested
-  input values.  See fi_domain(3) for details.
+  input values.  See [`fi_domain`(3)](fi_domain.3.html) for details.
 
 *fabric_attr - fabric attributes*
 : Optionally supplied fabric attributes.  Fabric attributes may be
   specified and returned as part of fi_getinfo.  When provided as
   hints, requested values of struct fi_fabric_attr should be set.  On
   output, the actual fabric attributes that can be provided will be
-  returned.  See fi_fabric(3) for details.
+  returned.  See [`fi_fabric`(3)](fi_fabric.3.html) for details.
+
+*nic - network interface details*
+: Optional attributes related to the hardware NIC associated with
+  the specified fabric, domain, and endpoint data.  This field is
+  only valid for providers where the corresponding attributes are
+  closely associated with a hardware NIC.  See [`fi_nic`(3)]
+  (fi_nic.3.html) for details.
 
 # CAPABILITIES
 
@@ -402,6 +410,16 @@ additional optimizations.
   completion semantics.  This flag requires that FI_RMA be set.
   This capability is experimental.
 
+*FI_VARIABLE_MSG*
+
+: Requests that the provider must notify a receiver when a variable
+  length message is ready to be received prior to attempting to place
+  the data.  Such notification will include the size of the message and
+  any associated message tag (for FI_TAGGED).  See 'Variable Length
+  Messages' in fi_msg.3 for full details.  Variable length messages
+  are any messages larger than an endpoint configurable size.  This
+  flag requires that FI_MSG and/or FI_TAGGED be set.
+
 Capabilities may be grouped into two general categories: primary and
 secondary.  Primary capabilities must explicitly be requested by an
 application, and a provider must enable support for only those primary
@@ -413,7 +431,7 @@ would not compromise performance or security.
 
 Primary capabilities: FI_MSG, FI_RMA, FI_TAGGED, FI_ATOMIC, FI_MULTICAST,
 FI_NAMED_RX_CTX, FI_DIRECTED_RECV, FI_READ, FI_WRITE, FI_RECV, FI_SEND,
-FI_REMOTE_READ, and FI_REMOTE_WRITE.
+FI_REMOTE_READ, FI_REMOTE_WRITE, and FI_VARIABLE_MSG.
 
 Secondary capabilities: FI_MULTI_RECV, FI_SOURCE, FI_RMA_EVENT, FI_SHARED_AV,
 FI_TRIGGER, FI_FENCE, FI_LOCAL_COMM, FI_REMOTE_COMM, FI_SOURCE_ERR, FI_RMA_PMEM.
@@ -537,14 +555,25 @@ supported set of modes will be returned in the info structure(s).
   completion flags which simply report the type of operation that
   completed (e.g. send or receive) may not be set.  However,
   completion flags that are used for remote notifications will still
-  be set when applicable.  See `fi_cq`(3) for details on which completion
-  flags are valid when this mode bit is enabled.
+  be set when applicable.  See [`fi_cq`(3)](fi_cq.3.html) for details on
+  which completion flags are valid when this mode bit is enabled.
 
 *FI_RESTRICTED_COMP*
 : This bit indicates that the application will only share completion queues
   and counters among endpoints, transmit contexts, and receive contexts that
   have the same set of capability flags.
 
+*FI_BUFFERED_RECV*
+: The buffered receive mode bit indicates that the provider owns the
+  data buffer(s) that are accessed by the networking layer for received
+  messages.  Typically, this implies that data must be copied from the
+  provider buffer into the application buffer.  Applications that can
+  handle message processing from network allocated data buffers can set
+  this mode bit to avoid copies.  For full details on application
+  requirements to support this mode, see the 'Buffered Receives' section
+  in [`fi_msg`(3)](fi_msg.3.html).  This mode bit applies to FI_MSG and
+  FI_TAGGED receive operations.
+
 # ADDRESSING FORMATS
 
 Multiple fabric interfaces take as input either a source or
@@ -556,7 +585,7 @@ field indicates the expected address format for these operations.
 A provider may support one or more of the following addressing
 formats.  In some cases, a selected addressing format may need to be
 translated or mapped into an address which is native to the
-fabric.  See `fi_av`(3).
+fabric.  See [`fi_av`(3)](fi_av.3.html).
 
 *FI_FORMAT_UNSPEC*
 : FI_FORMAT_UNSPEC indicates that a provider specific address format
@@ -685,4 +714,5 @@ Multiple threads may call
 
 [`fi_open`(3)](fi_open.3.html),
 [`fi_endpoint`(3)](fi_endpoint.3.html),
-[`fi_domain`(3)](fi_domain.3.html)
+[`fi_domain`(3)](fi_domain.3.html),
+[`fi_nic`(3)](fi_nic.3.html)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_hook.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_hook.7.md
new file mode 100644
index 000000000..8ab726128
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_hook.7.md
@@ -0,0 +1,71 @@
+---
+layout: page
+title: fi_hook(7)
+tagline: Libfabric Programmer's Manual
+---
+{% include JB/setup %}
+
+# NAME
+
+fi_hook \- The Hook Fabric Provider Utility
+
+# OVERVIEW
+
+The hooking provider is a utility function that can intercept calls to any
+provider.  The hook provider is always available, but has zero impact on
+calls unless enabled.  It is useful for providing performance data on
+selected calls or debugging information.
+
+# SUPPORTED FEATURES
+
+Hooking support is enabled through the FI_HOOK environment variable.  To
+enable hooking, FI_HOOK must be set to the name of one or more of the
+available hooking providers.  When multiple hooks are specified, the
+names must be separated by a semi-colon.  To obtain a list of hooking
+providers available on the current system, one can use the fi_info
+utility with the '--env' command line option.  Hooking providers are
+usually identified by 'hook' appearing in the provider name.
+
+Known hooking providers include the following:
+
+*ofi_perf_hook*
+: This hooks 'fast path' data operation calls.  Performance data is
+  captured on call entrance and exit, in order to provide an average of
+  how long each call takes to complete.  See the PERFORMANCE HOOKS section
+  for available performance data.
+
+# PERFORMANCE HOOKS
+
+The hook provider allows capturing inline performance data by accessing the
+CPU Performance Management Unit (PMU).  PMU data is only available on Linux
+systems.  Additionally, access to PMU data may be restricted to privileged
+(super-user) applications.
+
+Performance data is captured for critical data transfer calls:
+fi_msg, fi_rma, fi_tagged, fi_cq, and fi_cntr.  Captured data is displayed
+as logged data using the FI_LOG_LEVEL trace level.  Performance data is
+logged when the associated fabric is destroyed.
+
+The environment variable FI_PERF_CNTR is used to identify which performance
+counter is tracked.  The following counters are available:
+
+*cpu_cycles*
+: Counts the number of CPU cycles each function takes to complete.
+
+*cpu_instr*
+: Counts the number of CPU instructions each function takes to complete.
+  This is the default performance counter if none is specified.
+
+# LIMITATIONS
+
+Hooking functionality is not available for providers built using the
+FI_FABRIC_DIRECT feature.  That is, directly linking to a provider prevents
+hooking.
+
+The hooking provider does not work with triggered operations.  Application
+that use FI_TRIGGER operations that attempt to hook calls will likely crash.
+
+# SEE ALSO
+
+[`fabric`(7)](fabric.7.html),
+[`fi_provider`(7)](fi_provider.7.html)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mlx.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mlx.7.md
index ba3bdb59f..c6688ebad 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mlx.7.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mlx.7.md
@@ -49,6 +49,22 @@ Unsupported features
 
 # RUNTIME PARAMETERS
 
+*FI_MLX_CONFIG*
+: The path to the MLX configuration file (default: none).
+
+*FI_MLX_TINJECT_LIMIT*
+: Maximal tinject message size (default: 1024).
+
+*FI_MLX_NS_ENABLE*
+: Enforce usage of name server functionality for MLX provider
+  (default: disabled).
+
+*FI_MLX_NS_PORT*
+: MLX provider's name server port (default: 12345).
+
+*FI_MLX_NS_IFACE*
+: IPv4 network interface for MLX provider's name server
+  (default: any).
 
 # SEE ALSO
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mr.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mr.3.md
index 7a0aaaee8..20cbcae7c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mr.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mr.3.md
@@ -361,6 +361,13 @@ this routine.  Use of this call is required if the FI_RAW_MR mode bit has
 been set by the provider; however, it is safe to use this call with any
 memory region.
 
+On input, the key_size parameter should indicate the size of the raw_key
+buffer.  If the actual key is larger than what can fit into the buffer, it
+will return -FI_ETOOSMALL.  On output, key_size is set to the size of the
+buffer needed to store the key, which may be larger than the input value.
+The needed key_size can also be obtained through the mr_key_size domain
+attribute (fi_domain_attr) field.
+
 A raw key must be mapped by a peer before it can be used in data transfer
 operations.  See fi_mr_map_raw below.
 
@@ -440,6 +447,7 @@ struct fi_mr_attr {
 	const struct iovec *mr_iov;
 	size_t             iov_count;
 	uint64_t           access;
+	uint64_t           offset;
 	uint64_t           requested_key;
 	void               *context;
 	size_t             auth_key_size;
@@ -487,6 +495,10 @@ bitwise OR of the following flags:
 : The memory buffer may be used as the target buffer of an RMA write
   or atomic operation.
 
+## offset
+
+The offset field is reserved for future use and must be 0.
+
 ## requested_key
 
 An application specified access key associated with the memory region.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mrail.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mrail.7.md
new file mode 100644
index 000000000..6c12cab6e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_mrail.7.md
@@ -0,0 +1,87 @@
+---
+layout: page
+title: fi_mrail(7)
+tagline: Libfabric Programmer's Manual
+---
+{% include JB/setup %}
+
+# NAME
+
+fi_mrail \- The Multi-Rail Utility Provider
+
+# OVERVIEW
+
+The mrail provider (ofi_mrail) is an utility provider that layers over an underlying
+provider to enable the use of multiple network ports (rails). This increases
+the total available bandwidth of an underlying proivder. The current status of
+mrail provider is experimental - not all libfabric features are supported and
+performance is not guaranteed.
+
+# REQUIREMENTS
+
+## Requirements for underlying provider
+
+mrail provider requires the underlying provider to support the following
+capabilities / modes:
+
+  * Buffered receive (FI_BUFFERED_RECV)
+
+  * FI_SOURCE
+
+  * FI_AV_TABLE
+
+## Requirements for applications
+
+Applications need to:
+  * Support FI_MR_RAW MR mode bit to make use of FI_RMA capability.
+  * Set FI_OFI_MRAIL_ADDR_STRC env variable (see RUNTIME PARAMETERS section below).
+
+# SUPPORTED FEATURES
+
+*Endpoint types*
+: The provider supports only *FI_EP_RDM*.
+
+*Endpoint capabilities*
+: The following data transfer interface is supported: *FI_MSG*, *FI_TAGGED*, *FI_RMA*.
+
+# LIMITATIONS
+
+: Limitations of the underlying provider may show up as that of mrail provider.
+: mrail provider doesn't allow pass-through of any mode bits to the underlying
+  provider.
+
+## Unsupported features
+
+The following are the major libfabric features that are not supported. Any other
+feature not listed in "Supported features" can be assumed as unsupported.
+
+  * FI_ATOMIC
+
+  * Scalable endpoints
+
+  * Shared contexts
+
+  * FABRIC_DIRECT
+
+  * Multicast
+
+  * Triggered operations
+
+# FUNCTIONALITY OVERVIEW
+
+For messages (FI_MSG, FI_TAGGED), the provider sends one message per rail in a
+round-robin manner. Ordering is guaranteed through the use of sequence numbers.
+For RMA, the data is striped equally across all rails.
+
+# RUNTIME PARAMETERS
+
+The ofi_mrail provider checks for the following environment variables.
+
+*FI_OFI_MRAIL_ADDR_STRC*
+: Comma delimited list of individual rail addresses in FI_ADDR_STR format.
+
+# SEE ALSO
+
+[`fabric`(7)](fabric.7.html),
+[`fi_provider`(7)](fi_provider.7.html),
+[`fi_getinfo`(3)](fi_getinfo.3.html)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_msg.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_msg.3.md
index 146fa76f7..e12b3c13b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_msg.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_msg.3.md
@@ -90,7 +90,9 @@ ssize_t fi_injectdata(struct fid_ep *ep, const void *buf, size_t len,
 : Additional flags to apply for the send or receive operation.
 
 *context*
-: User specified pointer to associate with the operation.
+: User specified pointer to associate with the operation.  This parameter is
+  ignored if the operation will not generate a successful completion, unless
+  an op flag specifies the context parameter be used for required input.
 
 # DESCRIPTION
 
@@ -161,7 +163,7 @@ struct fi_msg {
 The send inject call is an optimized version of fi_send.  The
 fi_inject function behaves as if the FI_INJECT transfer flag were
 set, and FI_COMPLETION were not.  That is, the data buffer is
-available for reuse immediately on returning from from fi_inject, and
+available for reuse immediately on returning from fi_inject, and
 no completion event will be generated for this send.  The completion
 event will be suppressed even if the CQ was bound without
 FI_SELECTIVE_COMPLETION or the endpoint's op_flags contain
@@ -220,12 +222,24 @@ fi_sendmsg.
   request.  See fi_getinfo for additional details on
   FI_REMOTE_CQ_DATA.
 
+*FI_CLAIM*
+: Applies to posted receive operations for endpoints configured
+  for FI_BUFFERED_RECV or FI_VARIABLE_MSG.  This flag is used to
+  retrieve a message that was buffered by the provider.  See the
+  Buffered Receives section for details.
+
 *FI_COMPLETION*
 : Indicates that a completion entry should be generated for the
   specified operation.  The endpoint must be bound to a completion
   queue with FI_SELECTIVE_COMPLETION that corresponds to the
   specified operation, or this flag is ignored.
 
+*FI_DISCARD*
+: Applies to posted receive operations for endpoints configured
+  for FI_BUFFERED_RECV or FI_VARIABLE_MSG.  This flag is used to
+  free a message that was buffered by the provider.  See the
+  Buffered Receives section for details.
+
 *FI_MORE*
 : Indicates that the user has additional requests that will
   immediately be posted after the current call returns.  Use of this
@@ -288,6 +302,114 @@ fi_sendmsg.
   be used in all multicast transfers, in conjunction with a multicast
   fi_addr_t.
 
+# Buffered Receives
+
+Buffered receives indicate that the networking layer allocates and
+manages the data buffers used to receive network data transfers.  As
+a result, received messages must be copied from the network buffers
+into application buffers for processing.  However, applications can
+avoid this copy if they are able to process the message in place
+(directly from the networking buffers).
+
+Handling buffered receives differs based on the size of the message
+being sent.  In general, smaller messages are passed directly to the
+application for processing.  However, for large messages, an application
+will only receive the start of the message and must claim the rest.
+The details for how small messages are reported and large messages may
+be claimed are described below.
+
+When a provider receives a message, it will write an entry to the completion
+queue associated with the receiving endpoint.  For discussion purposes,
+the completion queue is assumed to be configured for FI_CQ_FORMAT_DATA.
+Since buffered receives are not associated with application posted buffers,
+the CQ entry op_context will point to a struct fi_recv_context.
+
+{% highlight c %}
+struct fi_recv_context {
+	struct fid_ep *ep;
+	void *context;
+};
+{% endhighlight %}
+
+The 'ep' field will point to the receiving endpoint or Rx context, and
+'context' will be NULL.  The CQ entry's 'buf' will point to a provider
+managed buffer where the start of the received message is located, and
+'len' will be set to the total size of the message.
+
+The maximum sized message that a provider can buffer is limited by
+an FI_OPT_BUFFERED_LIMIT. This threshold can be obtained and may be adjusted
+by the application using the fi_getopt and fi_setopt calls, respectively.
+Any adjustments must be made prior to enabling the endpoint. The CQ entry 'buf'
+will point to a buffer of received data. If the sent message is larger than the
+buffered amount, the CQ entry 'flags' will have the FI_MORE bit set. When the
+FI_MORE bit is set, 'buf' will reference at least FI_OPT_BUFFERED_MIN bytes
+of data (see fi_endpoint.3 for more info).
+
+After being notified that a buffered receive has arrived,
+applications must either claim or discard the message.  Typically,
+small messages are processed and discarded, while large messages
+are claimed.  However, an application is free to claim or discard any
+message regardless of message size.
+
+To claim a message, an application must post a receive operation with the
+FI_CLAIM flag set.  The struct fi_recv_context returned as part of the
+notification must be provided as the receive operation's context.  The
+struct fi_recv_context contains a 'context' field.  Applications may
+modify this field prior to claiming the message.  When the claim
+operation completes, a standard receive completion entry will be
+generated on the completion queue.  The 'context' of the associated
+CQ entry will be set to the 'context' value passed in through
+the fi_recv_context structure, and the CQ entry flags will have the
+FI_CLAIM bit set.
+
+Buffered receives that are not claimed must be discarded by the application
+when it is done processing the CQ entry data.  To discard a message, an
+application must post a receive operation with the FI_DISCARD flag set.
+The struct fi_recv_context returned as part of the notification must be
+provided as the receive operation's context. When the FI_DISCARD flag is set
+for a receive operation, the receive input buffer(s) and length parameters
+are ignored.
+
+IMPORTANT: Buffered receives must be claimed or discarded in a timely manner.
+Failure to do so may result in increased memory usage for network buffering
+or communication stalls.  Once a buffered receive has been claimed or
+discarded, the original CQ entry 'buf' or struct fi_recv_context data may no
+longer be accessed by the application.
+
+The use of the FI_CLAIM and FI_DISCARD operation flags is also
+described with respect to tagged message transfers in fi_tagged.3.
+Buffered receives of tagged messages will include the message tag as part
+of the CQ entry, if available.
+
+The handling of buffered receives follows all message ordering
+restrictions assigned to an endpoint.  For example, completions
+may indicate the order in which received messages arrived at the
+receiver based on the endpoint attributes.
+
+# Variable Length Messages
+
+Variable length messages, or simply variable messages, are transfers
+where the size of the message is unknown to the receiver prior to the
+message being sent.  It indicates that the recipient of a message does
+not know the amount of data to expect prior to the message arriving.
+It is most commonly used when the size of message transfers varies
+greatly, with very large messages interspersed with much smaller
+messages, making receive side message buffering difficult to manage.
+Variable messages are not subject to max message length
+restrictions (i.e. struct fi_ep_attr::max_msg_size limits), and may
+be up to the maximum value of size_t (e.g. SIZE_MAX) in length.
+
+Variable length messages support requests that the provider allocate and
+manage the network message buffers.  As a result, the application
+requirements and provider behavior is identical as those defined
+for supporting the FI_BUFFERED_RECV mode bit.  See the Buffered
+Receive section above for details.  The main difference is that buffered
+receives are limited by the fi_ep_attr::max_msg_size threshold, whereas
+variable length messages are not.
+
+Support for variable messages is indicated through the FI_VARIABLE_MSG
+capability bit.
+
 # NOTES
 
 If an endpoint has been configured with FI_MSG_PREFIX, the application
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_nic.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_nic.3.md
new file mode 100644
index 000000000..dcdfef98b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_nic.3.md
@@ -0,0 +1,158 @@
+---
+layout: page
+title: fi_nic(3)
+tagline: Libfabric Programmer's Manual
+---
+{% include JB/setup %}
+
+# NAME
+
+fi_nic \- Fabric network interface card attributes
+
+# NETWORK INTERFACE CARD ATTRIBUTES
+
+The fid_nic structure defines attributes for a struct fi_info that
+is directly associated with underlying networking hardware and may
+be returned directly from calling [`fi_getinfo`(3)](fi_getinfo.3.html).
+The format of fid_nic and the related substructures are defined below.
+
+Note that not all fields of all structures may be available.  Unavailable
+or fields that are not applicable to the indicated device will be set to
+NULL or 0.
+
+```c
+struct fid_nic {
+	struct fid             fid;
+	struct fi_device_attr *device_attr;
+	struct fi_bus_attr    *bus_attr;
+	struct fi_link_attr   *link_attr;
+	void                  *prov_attr;
+};
+
+struct fi_device_attr {
+	char *name;
+	char *device_id;
+	char *device_version;
+	char *vendor_id;
+	char *driver;
+	char *firmware;
+};
+
+struct fi_pci_attr {
+	uint16_t domain_id;
+	uint8_t  bus_id;
+	uint8_t  device_id;
+	uint8_t  function_id;
+};
+
+struct fi_bus_attr {
+	enum fi_bus_type       bus_type;
+	union {
+		struct fi_pci_attr pci;
+	} attr;
+};
+
+struct fi_link_attr {
+	char               *address;
+	size_t             mtu;
+	size_t             speed;
+	enum fi_link_state state;
+	char               *network_type;
+};
+
+```
+
+## Device Attributes
+
+Device attributes are used to identify the specific virtual or hardware
+NIC associated with an fi_info structure.
+
+*name*
+: The operating system name associated with the device.  This may be a
+  logical network interface name (e.g. eth0 or eno1) or an absolute
+  filename.
+
+*device_id*
+: This is a vendor specific identifier for the device or product.
+
+*device_version*
+: Indicates the version of the device.
+
+*vendor_id*
+: Indicates the name of the vendor that distributes the NIC.
+
+*driver*
+: The name of the driver associated with the device
+
+*firmware*
+: The device's firmware version.
+
+## Bus Attributes
+
+The bus attributes are used to identify the physical location of the NIC in
+the system.
+
+*bus_type*
+: Indicates the type of system bus where the NIC is located.  Valid values
+  are FI_BUS_PCI or FI_BUS_UNKNOWN.
+
+*attr.pci.domain_id*
+: The domain where the PCI bus is located.  Valid only if bus_type is
+  FI_BUS_PCI.
+
+*attr.pci.bus_id*
+: The PCI bus identifier where the device is located.  Valid only if
+  bus_type is FI_BUS_PCI.
+
+*attr.pci.device_id*
+: The identifier on the PCI bus where the device is located.  Valid only
+  if bus_type is FI_BUS_PCI.
+
+*attr.pci.function_id*
+: The function on the device being referenced.  Valid only if bus_type is
+  FI_BUS_PCI.
+
+## Link Attributes
+
+Link attributes describe low-level details about the network connection
+into the fabric.
+
+*address*
+: The primary link-level address associated with the NIC, such as a MAC
+  address.  If multiple addresses are available, only one will be reported.
+
+*mtu*
+: The maximum transfer unit of link level frames or packets, in bytes.
+
+*speed*
+: The active link data rate, given in bits per second.
+
+*state*
+: The current physical port state.  Possible values are FI_LINK_UNKNOWN,
+  FI_LINK_DOWN, and FI_LINK_UP, to indicate if the port state is unknown
+  or not applicable (unknown), inactive (down), or active (up).
+
+*network_type*
+: Specifies the type of network interface currently active, such as
+  Ethernet or InfiniBand.
+
+## Provider Attributes
+
+Provider attributes reference provider specific details of the device.
+These attributes are both provider and device specific.  The attributes
+can be interpretted by [`fi_tostr`(3)](fi_tostr.3.html).  Applications
+may also use the other attribute fields, such as related fi_fabric_attr:
+prov_name field, to determine an appropriate structure to cast the
+attributes.  The format and definition of this field is outside the
+scope of the libfabric core framework, but may be available as part
+of a provider specific header file included with libfabric package.
+
+# NOTES
+
+The fid_nic structure is returned as part of a call to
+[`fi_getinfo`(3)](fi_getinfo.3.html).  It is automatically freed as part
+of calling [`fi_freeinfo`(3)](fi_freeinfo.3.html)
+
+# SEE ALSO
+
+[`fi_getinfo`(3)](fi_getinfo.3.html)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_provider.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_provider.7.md
index f20545d12..b8e795e3e 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_provider.7.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_provider.7.md
@@ -65,6 +65,17 @@ This distribution of libfabric contains the following providers
   endpoints emulated over MSG endpoints of a core provider.
   See [`fi_rxm`(7)](fi_rxm.7.html) for more information.
 
+## Special providers
+
+*Hook*
+: The hook provider is a special type of provider that can layer over any
+  other provider, unless FI_FABRIC_DIRECT is used.  The hook provider is
+  always available, but has no impact unless enabled.  When enabled, the
+  hook provider will intercept all calls to the underlying core or utility
+  provider(s).  The hook provider is useful for capturing performance data
+  or providing debugging information, even in release builds of the library.
+  See [`fi_hook`(7)](fi_hook.7.html) for more information.
+
 # CORE VERSUS UTILITY PROVIDERS
 
 Core providers implement the libfabric interfaces directly over low-level
@@ -194,6 +205,7 @@ Logging is performed using the FI_ERR, FI_LOG, and FI_DEBUG macros.
 # SEE ALSO
 
 [`fi_gni`(7)](fi_gni.7.html),
+[`fi_hook`(7)](fi_hook.7.html),
 [`fi_psm`(7)](fi_psm.7.html),
 [`fi_sockets`(7)](fi_sockets.7.html),
 [`fi_usnic`(7)](fi_usnic.7.html),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_psm2.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_psm2.7.md
index f5bc4556f..fcb62c2a4 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_psm2.7.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_psm2.7.md
@@ -194,21 +194,6 @@ The *psm2* provider checks for the following environment variables:
 
   The default setting is 2.
 
-*FI_PSM2_LAZY_CONN*
-: Control when connections are established between PSM2 endpoints that OFI
-  endpoints are built on top of. When set to 0, connections are established
-  when addresses are inserted into the address vector. This is the eager
-  connection mode. When set to 1, connections are established when addresses
-  are used the first time in communication. This is the lazy connection mode.
-
-  Lazy connection mode may reduce the start-up time on large systems at the
-  expense of slightly higher data path overhead. For applications that use
-  multiple endpoints, lazy connection mode can be especially helpful with
-  the potential of greatly reduce the time to set up address vectors and to
-  close endpoints.
-
-  The default setting is 0.
-
 *FI_PSM2_DISCONNECT*
 : The provider has a mechanism to automatically send disconnection notifications
   to all connected peers before the local endpoint is closed. As the response,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rma.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rma.3.md
index 04eca193d..1072b4fbf 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rma.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rma.3.md
@@ -101,7 +101,9 @@ ssize_t fi_inject_writedata(struct fid_ep *ep, const void *buf, size_t len,
 : Additional flags to apply for the read or write operation.
 
 *context*
-: User specified pointer to associate with the operation.
+: User specified pointer to associate with the operation.  This parameter is
+  ignored if the operation will not generate a successful completion, unless
+  an op flag specifies the context parameter be used for required input.
 
 # DESCRIPTION
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rstream.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rstream.7.md
new file mode 100644
index 000000000..9b58e60fd
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rstream.7.md
@@ -0,0 +1,86 @@
+---
+layout: page
+title: fi_rstream(7)
+tagline: Libfabric Programmer's Manual
+---
+{% include JB/setup %}
+
+# NAME
+
+fi_rstream
+
+# OVERVIEW
+
+The rstream provider supports stream messaging over
+ message based RMA. It maps stream to message over
+ a core RMA-based OFI provider. Only Endpoints and EQs
+ are needed for connection start-up and messaging. Unlike other
+ OFI providers, rstream does not support CQs or memory registration
+ of any kind. In order to asynchronously wait for a completion (cm/msg),
+ one can use fi_control on the endpoint/eq to get an fd to use in a poll call.
+ For messaging completions, use FI_PEEK on send/recv after poll to see what type of
+ transaction has transpired.
+
+# SUPPORTED FEATURES
+
+The rstream provider currently supports *FI_MSG* capabilities.
+
+*Endpoint types*
+: The provider supports only endpoint type *FI_EP_SOCK_STREAM*.
+
+*Endpoint capabilities* : The following data transfer interface is
+supported: *fi_msg*.
+
+*Modes*
+: The provider does not require the use of any mode bits but supports
+  core providers that require FI_CONTEXT and FI_RX_CQ_DATA.
+
+*Progress*
+: The rstream provider only supports *FI_PROGRESS_MANUAL*.
+
+*Threading Model*
+: The provider supports FI_THREAD_SAFE
+
+*Verbs-iWarp*
+: The provider has added features to enable iWarp. To use this feature, the ep protocol
+ IWARP must be requested in a getinfo call.
+
+# LIMITATIONS
+
+The rstream provider is experimental and lacks performance validation and
+ extensive testing. The iWarp protocol may need extra initialization work to re-enable.
+ Currently the rstream provider is used to by the rsockets-OFI library as a ULP and
+ hooks into the core provider verbs. It is not interoperable with the previous rsockets(v1)
+ protocol. There are default settings that limit the message stream (provider
+ memory region size and CQ size). These can be modified by fi_setopt.
+
+
+
+# SETTINGS
+
+The *rstream* provider settings can be modified via fi_setopt on the
+ endpoint (FI_OPT_ENDPOINT) along with the following parameters:
+
+*FI_OPT_SEND_BUF_SIZE*
+: Size of the send buffer. Default is 32KB.
+
+*FI_OPT_RECV_BUF_SIZE*
+: Size of the recv buffer. Default is 32KB.
+
+*FI_OPT_TX_SIZE*
+: Size of the send queue. Default is 384.
+
+*FI_OPT_RX_SIZE*
+: Size of the recv queue. Default is 384.
+
+# OFI EXTENSIONS
+
+The rstream provider has extended the current OFI API set in order to enable a
+ user implemenation of Poll. Specifically sendmsg(FI_PEEK) is supported which replicates
+ the behavior of the recvmsg(FI_PEEK) feature.
+
+# SEE ALSO
+
+[`fabric`(7)](fabric.7.html),
+[`fi_provider`(7)](fi_provider.7.html),
+[`fi_getinfo`(3)](fi_getinfo.3.html)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rxd.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rxd.7.md
index bfa2ca6ea..40e31cbe5 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rxd.7.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rxd.7.md
@@ -16,23 +16,20 @@ emulated over a base DGRAM provider.
 
 # SUPPORTED FEATURES
 
-The RxD provider currently supports *FI_MSG*, *FI_TAGGED* and *FI_RMA*
-capabilities. It requires the base DGRAM provider to support *FI_MSG*
-capabilities.
+The RxD provider currently supports *FI_MSG* capabilities.
 
 *Endpoint types*
 : The provider supports only endpoint type *FI_EP_RDM*.
 
 *Endpoint capabilities* : The following data transfer interface is
-supported: *fi_msg*, *fi_tagged* and *fi_rma*.
+supported: *fi_msg*.
 
 *Modes*
-: The provider does not require the use of any mode bits.
+: The provider does not require the use of any mode bits but supports
+  core DGRAM providers that require FI_CONTEXT and FI_MSG_PREFIX.
 
 *Progress*
-: The RxD provider supports both *FI_PROGRESS_AUTO* and *FI_PROGRESS_MANUAL*,
-  with a default set to auto.  However, receive side data buffers are not
-  modified outside of completion processing routines.
+: The RxD provider only supports *FI_PROGRESS_MANUAL*.
 
 # LIMITATIONS
 
@@ -49,7 +46,21 @@ tested.
 
 # RUNTIME PARAMETERS
 
-No runtime parameters are currently defined.
+The *rxd* provider checks for the following environment variables:
+
+*FI_OFI_RXD_SPIN_COUNT*
+: Number of times to read the core provider's CQ for a segment completion
+  before trying to progress sends. Default is 1000.
+
+*FI_OFI_RXD_RETRY*
+: Toggles retrying of packets and assumes reliability of individual packets
+  and will reassemble all received packets. Retrying is turned on by default.
+
+*FI_OFI_RXD_MAX_PEERS*
+: Maximum number of peers the provider should prepare to track. Default: 1024
+
+*FI_OFI_RXD_MAX_UNACKED*
+: Maximum number of packets (per peer) to send at a time. Default: 128
 
 # SEE ALSO
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rxm.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rxm.7.md
index db377a3b3..522d2bc96 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rxm.7.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_rxm.7.md
@@ -11,31 +11,50 @@ fi_rxm \- The RxM (RDM over MSG) Utility Provider
 
 # OVERVIEW
 
-The RxM provider (ofi_rxm) is an utility provider that supports RDM
-endpoint emulated over MSG endpoint of a core provider.
+The RxM provider (ofi_rxm) is an utility provider that supports FI_EP_RDM type
+endpoint emulated over FI_EP_MSG type endpoint(s) of an underlying core provider.
+FI_EP_RDM endpoints have a reliable unconnected messaging interface and RxM
+emulates this by hiding the connection management of underlying FI_EP_MSG
+endpoints from the user. Additionally, RxM can hide memory registration
+requirement from a core provider like verbs if the apps don't support it.
 
 # REQUIREMENTS
 
+## Requirements for core provider
+
 RxM provider requires the core provider to support the following features:
 
   * MSG endpoints (FI_EP_MSG)
 
-  * RMA read/write (FI_RMA)
+  * RMA read/write (FI_RMA) - Used for implementing rendezvous protocol for
+    large messages.
+
+  * FI_OPT_CM_DATA_SIZE of at least 48 bytes
+
+## Requirements for applications
 
-  * FI_OPT_CM_DATA_SIZE of at least 24 bytes
+Since RxM emulates RDM endpoints by hiding connection management and connections
+are established only on-demand (when app tries to send data), the first several
+data transfer calls would return EAGAIN. Applications should be aware of this and
+retry until the operation succeeds.
+
+If an application has chosen manual progress for data progress, it should also
+read the CQ so that the connection establishment progresses. Not doing so would
+result in a stall. See also the ERRORS section in fi_msg(3).
 
 # SUPPORTED FEATURES
 
-The RxM provider currently supports *FI_MSG*, *FI_TAGGED* and *FI_RMA* capabilities.
+The RxM provider currently supports *FI_MSG*, *FI_TAGGED*, *FI_RMA* and *FI_ATOMIC* capabilities.
 
 *Endpoint types*
 : The provider supports only *FI_EP_RDM*.
 
 *Endpoint capabilities*
-: The following data transfer interface is supported: *FI_MSG*, *FI_TAGGED*, *FI_RMA*.
+: The following data transfer interface is supported: *FI_MSG*, *FI_TAGGED*, *FI_RMA*, *FI_ATOMIC*.
 
 *Progress*
-: The RxM provider supports *FI_PROGRESS_AUTO*.
+: The RxM provider supports both *FI_PROGRESS_MANUAL* and *FI_PROGRESS_AUTO*.
+  The former is more optimal.
 
 *Addressing Formats*
 : FI_SOCKADDR, FI_SOCKADDR_IN
@@ -55,8 +74,6 @@ RxM provider does not support the following features:
 
   * op_flags: FI_FENCE.
 
-  * FI_ATOMIC
-
   * Scalable endpoints
 
   * Shared contexts
@@ -77,11 +94,22 @@ RxM provider does not support the following features:
 
   * Triggered operations
 
-## Auto progress
+## Progress limitations
 
 When sending large messages, an app doing an sread or waiting on the CQ file descriptor
 may not get a completion when reading the CQ after being woken up from the wait.
-The app has to do sread or wait on the file descriptor again.
+The app has to do sread or wait on the file descriptor again. This is needed
+because RxM uses a rendezvous protocol for large message sends. An app would get
+woken up from waiting on CQ fd when rendezvous protocol request completes but it
+would have to wait again to get an ACK from the receiver indicating completion of
+large message transfer by remote RMA read.
+
+## FI_ATOMIC limitations
+
+The FI_ATOMIC capability will only be listed in the fi_info if the fi_info
+hints parameter specifies FI_ATOMIC. If FI_ATOMIC is requested, message order
+FI_ORDER_RAR, FI_ORDER_RAW, FI_ORDER_WAR, FI_ORDER_WAW, FI_ORDER_SAR, and
+FI_ORDER_SAW can not be supported.
 
 # RUNTIME PARAMETERS
 
@@ -90,13 +118,22 @@ The ofi_rxm provider checks for the following environment variables.
 *FI_OFI_RXM_BUFFER_SIZE*
 : Defines the transmit buffer size / inject size. Messages of size less than this
   would be transmitted via an eager protocol and those above would be transmitted
-  via a rendezvous protocol. Transmit data would be copied up to this size
-  (default: ~16k).
+  via a rendezvous or SAR (Segmentation And Reassembly) protocol. Transmit data
+  would be copied up to this size (default: ~16k).
 
 *FI_OFI_RXM_COMP_PER_PROGRESS*
 : Defines the maximum number of MSG provider CQ entries (default: 1) that would
   be read per progress (RxM CQ read).
 
+*FI_OFI_RXM_SAR_LIMIT*
+: Set this environment variable to control the RxM SAR (Segmentation And Reassembly)
+  protocol. Messages of size greater than this (default: 256 Kb) would be transmitted
+  via rendezvous protocol.
+
+*FI_OFI_RXM_USE_SRX*
+: Set this to 1 to use shared receive context from MSG provider. This reduces
+  overall memory usage but there may be a slight increase in latency (default: 0).
+
 *FI_OFI_RXM_TX_SIZE*
 : Defines default TX context size (default: 1024)
 
@@ -122,12 +159,21 @@ FI_OFI_RXM_TX_SIZE, FI_OFI_RXM_RX_SIZE, FI_OFI_RXM_MSG_TX_SIZE, FI_OFI_RXM_MSG_R
 subject to memory limits of the system and the tx and rx sizes supported by the
 MSG provider.
 
+FI_OFI_RXM_SAR_LIMIT is another knob that can be experimented with to optimze for
+bandwidth.
+
 ## Memory
 
 To conserve memory, ensure FI_UNIVERSE_SIZE set to what is required. Similarly
 check that FI_OFI_RXM_TX_SIZE, FI_OFI_RXM_RX_SIZE, FI_OFI_RXM_MSG_TX_SIZE and
 FI_OFI_RXM_MSG_RX_SIZE env variables are set to only required values.
 
+# NOTES
+
+The data transfer API may return -FI_EAGAIN during on-demand connection setup
+of the core provider FI_MSG_EP. See [`fi_msg`(3)](fi_msg.3.html) for a detailed
+description of handling FI_EAGAIN.
+
 # SEE ALSO
 
 [`fabric`(7)](fabric.7.html),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_sockets.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_sockets.7.md
index 66041d2a6..a75c1cb94 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_sockets.7.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_sockets.7.md
@@ -60,6 +60,9 @@ The sockets provider checks for the following environment variables -
 *FI_SOCKETS_PE_WAITTIME*
 : An integer value that specifies how many milliseconds to spin while waiting for progress in *FI_PROGRESS_AUTO* mode.
 
+*FI_SOCKETS_CONN_TIMEOUT*
+: An integer value that specifies how many milliseconds to wait for one connection establishment.
+
 *FI_SOCKETS_MAX_CONN_RETRY*
 : An integer value that specifies the number of socket connection retries before reporting as failure.
 
@@ -93,6 +96,9 @@ The sockets provider checks for the following environment variables -
 *FI_SOCKETS_KEEPALIVE_PROBES*
 : An integer to specify the maximum number of keepalive probes sent before dropping the connection. Only relevant if *FI_SOCKETS_KEEPALIVE_ENABLE* is enabled.
 
+*FI_SOCKETS_IFACE*
+: The prefix or the name of the network interface (default: any)
+
 # LARGE SCALE JOBS
 
 For large scale runs one can use these environment variables to set the default parameters e.g. size of the address vector(AV), completion queue (CQ), connection map etc. that satisfies the requirement of the particular benchmark. The recommended parameters for large scale runs are *FI_SOCKETS_MAX_CONN_RETRY*, *FI_SOCKETS_DEF_CONN_MAP_SZ*, *FI_SOCKETS_DEF_AV_SZ*, *FI_SOCKETS_DEF_CQ_SZ*, *FI_SOCKETS_DEF_EQ_SZ*.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_tagged.3.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_tagged.3.md
index 2bddfe08d..d6c3d54bf 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_tagged.3.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_tagged.3.md
@@ -97,7 +97,9 @@ ssize_t fi_tinjectdata(struct fid_ep *ep, const void *buf, size_t len,
 : Additional flags to apply for the send or receive operation.
 
 *context*
-: User specified pointer to associate with the operation.
+: User specified pointer to associate with the operation.  This parameter is
+  ignored if the operation will not generate a successful completion, unless
+  an op flag specifies the context parameter be used for required input.
 
 # DESCRIPTION
 
@@ -184,7 +186,7 @@ struct fi_msg_tagged {
 The tagged inject call is an optimized version of fi_tsend.  The
 fi_tinject function behaves as if the FI_INJECT transfer flag were
 set, and FI_COMPLETION were not.  That is, the data buffer is
-available for reuse immediately on returning from from fi_tinject, and
+available for reuse immediately on returning from fi_tinject, and
 no completion event will be generated for this send.  The completion
 event will be suppressed even if the endpoint has not been configured
 with FI_SELECTIVE_COMPLETION.  See the flags discussion below for more
@@ -268,6 +270,11 @@ and/or fi_tsendmsg.
   generated until the operation has been successfully transmitted and
   is no longer being tracked by the provider.
 
+*FI_MATCH_COMPLETE*
+: Applies to fi_tsendmsg.  Indicates that a completion should be generated
+  only after the message has either been matched with a tagged
+  buffer or was discarded by the target application.
+
 *FI_FENCE*
 : Applies to transmits.  Indicates that the requested operation, also
   known as the fenced operation, and any operation posted after the
@@ -323,21 +330,73 @@ The following flags may be used with fi_trecvmsg.
   set is used to retrieve a previously claimed message.
 
   In order to use the FI_CLAIM flag, an application must supply a struct
-  fi_context structure as the context for the receive operation.  The same
+  fi_context structure as the context for the receive operation, or a
+  struct fi_recv_context in the case of buffered receives.  The same
   fi_context structure used for an FI_PEEK + FI_CLAIM operation must be used
   by the paired FI_CLAIM request.
 
+  This flag also applies to endpoints configured for FI_BUFFERED_RECV or
+  FI_VARIABLE_MSG.  When set, it is used to retrieve a tagged message that
+  was buffered by the provider.  See Buffered Tagged Receives section for
+  details.
+
 *FI_DISCARD*
-: This flag must be used in conjunction with either FI_PEEK or FI_CLAIM.
+: This flag may be used in conjunction with either FI_PEEK or FI_CLAIM.
   If this flag is used in conjunction with FI_PEEK, it indicates if the
   peek request completes successfully -- indicating that a matching message
   was located -- the message is discarded by the provider, as the data is not
   needed by the application.  This flag may also be used in conjunction with
-  FI_CLAIM in order to retrieve and discard a message previously claimed
+  FI_CLAIM in order to discard a message previously claimed
   using an FI_PEEK + FI_CLAIM request.
 
+  This flag also applies to endpoints configured for FI_BUFFERED_RECV or
+  FI_VARIABLE_MSG.  When set, it indicates that the provider should free
+  a buffered messages.  See Buffered Tagged Receives section for details.
+
   If this flag is set, the input buffer(s) and length parameters are ignored.
 
+# Buffered Tagged Receives
+
+See [`fi_msg`(3)](fi_msg.3.html) for an introduction to buffered receives.
+The handling of buffered receives differs between fi_msg operations and
+fi_tagged.  Although the provider is responsible for allocating and
+managing network buffers, the application is responsible for identifying
+the tags that will be used to match incoming messages.  The provider
+handles matching incoming receives to the application specified tags.
+
+When FI_BUFFERED_RECV is enabled, the application posts the tags that
+will be used for matching purposes.  Tags are posted using fi_trecv,
+fi_trecvv, and fi_trecvmsg; however, parameters related
+to the input buffers are ignored (e.g. buf, len, iov, desc).  When
+a provider receives a message for which there is a matching tag,
+it will write an entry to the completion queue associated with the
+receiving endpoint.
+
+For discussion purposes, the completion queue is assumed to be configured
+for FI_CQ_FORMAT_TAGGED.  The op_context field will point to a struct
+fi_recv_contex.
+
+{% highlight c %}
+struct fi_recv_context {
+	struct fid_ep *ep;
+	void *context;
+};
+{% endhighlight %}
+
+The 'ep' field will be NULL.  The 'context' field will match the
+application context specified when posting the tag.  Other fields are
+set as defined in [`fi_msg`(3)](fi_msg.3.html).
+
+After being notified that a buffered receive has arrived,
+applications must either claim or discard the message as described in
+[`fi_msg`(3)](fi_msg.3.html).
+
+# Variable Length Tagged Messages
+
+Variable length messages are defined in [`fi_msg`(3)](fi_msg.3.html).
+The requirements for handling variable length tagged messages is identical
+to those defined above for buffered tagged receives.
+
 # RETURN VALUE
 
 The tagged send and receive calls return 0 on success.  On error, a
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_tcp.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_tcp.7.md
new file mode 100644
index 000000000..99f122d05
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_tcp.7.md
@@ -0,0 +1,45 @@
+---
+layout: page
+title: fi_tcp(7)
+tagline: Libfabric Programmer's Manual
+---
+{% include JB/setup %}
+
+# NAME
+
+fi_tcp \- The msg sockets Fabric Provider
+
+# OVERVIEW
+
+The tcp provider can be used on any system that supports TCP sockets. The
+provider is not intended to provide performance improvements over regular
+TCP sockets, but rather to allow developers to write, test,and debug
+application code even on platforms that do not have high-performance
+fabric hardware.
+
+# SUPPORTED FEATURES
+
+The following features are supported
+
+*Endpoint types*
+: *FI_EP_MSG* is the only supported endpoint type. Reliable
+datagram endpoint over TCP sockets can be achieved by layering RxM over
+tcp provider.
+
+*Endpoint capabilities*
+: The tcp provider currently supports *FI_MSG*, *FI_RMA*
+
+*Progress*
+: Currently tcp provider supports only *FI_PROGRESS_MANUAL*
+
+# LIMITATIONS
+
+tcp provider is implemented over TCP sockets to emulate libfabric API. Hence
+the performance is lower than what an application might see implementing to
+sockets directly.
+
+# SEE ALSO
+
+[`fabric`(7)](fabric.7.html),
+[`fi_provider`(7)](fi_provider.7.html),
+[`fi_getinfo`(3)](fi_getinfo.3.html)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_verbs.7.md b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_verbs.7.md
index d9ce6efd8..a8b3bf010 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/fi_verbs.7.md
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/fi_verbs.7.md
@@ -159,6 +159,10 @@ The support for fork in the provider has the following limitations:
     marks the entire page that a memory region belongs to as not to be re-mapped
     when the process is forked (MADV_DONTFORK).
 
+### XRC Transport
+The XRC transport is intended to be used when layered with the RXM provider and
+requires the use of shared receive contexts. See [`fi_rxm`(7)](fi_rxm.7.thml).
+
 # RUNTIME PARAMETERS
 
 The verbs provider checks for the following environment variables.
@@ -203,6 +207,9 @@ The verbs provider checks for the following environment variables.
 *FI_VERBS_MR_MAX_CACHED_SIZE*
 : Maximum total size of cache entries (default: 4 GB)
 
+*FI_VERBS_PREFER_XRC*
+: Prioritize XRC transport fi_info before RC transport fi_info (default: 0, RC fi_info will be before XRC fi_info)
+
 ### Variables specific to RDM (internal - deprecated) endpoints
 
 *FI_VERBS_RDM_BUFFER_NUM*
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_info.1 b/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_info.1
index 8f55ab2bf..f878e4742 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_info.1
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_info.1
@@ -1,4 +1,7 @@
-.TH "fi_info" "1" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_info" "1" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_info \- Simple utility to query for fabric interfaces
@@ -21,59 +24,90 @@ If no filters are specified, then all available fabric interfaces for
 all providers and endpoint types will be returned.
 .SH OPTIONS
 .SS Filtering
-.PP
-\f[I]\-n, \-\-node=<NAME>\f[] : Node name or address used to filter
-interfaces.
+.TP
+.B \f[I]\-n, \-\-node=<NAME>\f[]
+Node name or address used to filter interfaces.
 Only interfaces which can reach the given node or address will respond.
-.PP
-\f[I]\-P, \-\-port=<PORT>\f[] : Port number used to filter interfaces.
-.PP
-\f[I]\-c, \-\-caps=<CAP1|CAP2>..\f[] : Pipe separated list of
-capabilities used to filter interfaces.
+.RS
+.RE
+.TP
+.B \f[I]\-P, \-\-port=<PORT>\f[]
+Port number used to filter interfaces.
+.RS
+.RE
+.TP
+.B \f[I]\-c, \-\-caps=<CAP1|CAP2>..\f[]
+Pipe separated list of capabilities used to filter interfaces.
 Only interfaces supporting all of the given capabilities will respond.
 For more information on capabilities, see fi_getinfo(3).
-.PP
-\f[I]\-m, \-\-mode=<MOD1|MOD2>..\f[] : Pipe separated list of modes used
-to filter interfaces.
+.RS
+.RE
+.TP
+.B \f[I]\-m, \-\-mode=<MOD1|MOD2>..\f[]
+Pipe separated list of modes used to filter interfaces.
 Only interfaces supporting all of the given modes will respond.
 For more information on, modes see fi_getinfo(3).
-.PP
-\f[I]\-t, \-\-ep_type=<EPTYPE>\f[] : Specifies the type of fabric
-interface communication desired.
+.RS
+.RE
+.TP
+.B \f[I]\-t, \-\-ep_type=<EPTYPE>\f[]
+Specifies the type of fabric interface communication desired.
 For example, specifying FI_EP_DGRAM would return only interfaces which
 support unreliable datagram.
 For more information on endpoint types, see fi_endpoint(3).
-.PP
-\f[I]\-a, \-\-addr_format=<FMT>\f[] : Filter fabric interfaces by their
-address format.
+.RS
+.RE
+.TP
+.B \f[I]\-a, \-\-addr_format=<FMT>\f[]
+Filter fabric interfaces by their address format.
 For example, specifying FI_SOCKADDR_IN would return only interfaces
 which use sockaddr_in structures for addressing.
 For more information on address formats, see fi_getinfo(3).
-.PP
-\f[I]\-p, \-\-provider=<PROV>\f[] : Filter fabric interfaces by the
-provider implementation.
+.RS
+.RE
+.TP
+.B \f[I]\-p, \-\-provider=<PROV>\f[]
+Filter fabric interfaces by the provider implementation.
 For a list of providers, see the \f[C]\-\-list\f[] option.
-.PP
-\f[I]\-d, \-\-domain=<DOMAIN>\f[] : Filter interfaces to only those with
-the given domain name.
-.PP
-\f[I]\-f, \-\-fabric=<FABRIC>\f[] : Filter interfaces to only those with
-the given fabric name.
+.RS
+.RE
+.TP
+.B \f[I]\-d, \-\-domain=<DOMAIN>\f[]
+Filter interfaces to only those with the given domain name.
+.RS
+.RE
+.TP
+.B \f[I]\-f, \-\-fabric=<FABRIC>\f[]
+Filter interfaces to only those with the given fabric name.
+.RS
+.RE
 .SS Discovery
-.PP
-\f[I]\-e, \-\-env\f[] : List libfabric related environment levels which
-can be used to enable extra configuration or tuning.
-.PP
-\f[I]\-l, \-\-list\f[] : List available libfabric providers.
-.PP
-\f[I]\-v, \-\-verbose\f[] : By default, fi_info will display a summary
-of each of the interfaces discovered.
+.TP
+.B \f[I]\-e, \-\-env\f[]
+List libfabric related environment levels which can be used to enable
+extra configuration or tuning.
+.RS
+.RE
+.TP
+.B \f[I]\-l, \-\-list\f[]
+List available libfabric providers.
+.RS
+.RE
+.TP
+.B \f[I]\-v, \-\-verbose\f[]
+By default, fi_info will display a summary of each of the interfaces
+discovered.
 If the verbose option is enabled, then all of the contents of the
 fi_info structure are displayed.
 For more information on the data contained in the fi_info structure, see
 fi_getinfo(3).
-.PP
-\f[I]\-\-version\f[] : Display versioning information.
+.RS
+.RE
+.TP
+.B \f[I]\-\-version\f[]
+Display versioning information.
+.RS
+.RE
 .SH USAGE EXAMPLES
 .IP
 .nf
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_pingpong.1 b/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_pingpong.1
index e64fb8d6a..c9b859c54 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_pingpong.1
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_pingpong.1
@@ -1,4 +1,7 @@
-.TH "fi_pingpong" "1" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_pingpong" "1" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_pingpong \- Quick and simple pingpong test for libfabric
@@ -55,44 +58,72 @@ be specified on the server.
 If both the server and client specify the \f[C]\-d\f[] option and the
 given domains cannot communicate, then the application will fail.
 .SS Control Messaging
-.PP
-\f[I]\-B <src_port>\f[] : The non\-default source port number of the
-control socket.
+.TP
+.B \f[I]\-B <src_port>\f[]
+The non\-default source port number of the control socket.
 If this is not provided then the server will bind to port 47592 by
 default and the client will allow the port to be selected automatically.
-.PP
-\f[I]\-P <dest_port>\f[] : The non\-default destination port number of
-the control socket.
+.RS
+.RE
+.TP
+.B \f[I]\-P <dest_port>\f[]
+The non\-default destination port number of the control socket.
 If this is not provided then the client will connect to 47592 by
 default.
 The server ignores this option.
+.RS
+.RE
 .SS Fabric Filtering
-.PP
-\f[I]\-p <provider_name>\f[] : The name of the underlying fabric
-provider (e.g., sockets, psm, usnic, etc.).
+.TP
+.B \f[I]\-p <provider_name>\f[]
+The name of the underlying fabric provider (e.g., sockets, psm, usnic,
+etc.).
 If a provider is not specified via the \-p switch, the test will pick
 one from the list of available providers (as returned by fi_getinfo(3)).
-.PP
-\f[I]\-e <endpoint>\f[] : The type of endpoint to be used for data
-messaging between the two processes.
+.RS
+.RE
+.TP
+.B \f[I]\-e <endpoint>\f[]
+The type of endpoint to be used for data messaging between the two
+processes.
 Supported values are dgram, rdm, and msg.
 For more information on endpoint types, see fi_endpoint(3).
-.PP
-\f[I]\-d <domain>\f[] : The name of the specific domain to be used.
+.RS
+.RE
+.TP
+.B \f[I]\-d <domain>\f[]
+The name of the specific domain to be used.
+.RS
+.RE
 .SS Test Options
-.PP
-\f[I]\-I <iter>\f[] : The number of iterations of the test will run.
-.PP
-\f[I]\-S <msg_size>\f[] : The specific size of the message in bytes the
-test will use or \[aq]all\[aq] to run all the default sizes.
-.PP
-\f[I]\-c\f[] : Activate data integrity checks at the receiver (note:
-this will degrade performance).
+.TP
+.B \f[I]\-I <iter>\f[]
+The number of iterations of the test will run.
+.RS
+.RE
+.TP
+.B \f[I]\-S <msg_size>\f[]
+The specific size of the message in bytes the test will use or
+\[aq]all\[aq] to run all the default sizes.
+.RS
+.RE
+.TP
+.B \f[I]\-c\f[]
+Activate data integrity checks at the receiver (note: this will degrade
+performance).
+.RS
+.RE
 .SS Utility
-.PP
-\f[I]\-v\f[] : Activate output debugging (warning: highly verbose)
-.PP
-\f[I]\-h\f[] : Displays help output for the pingpong test.
+.TP
+.B \f[I]\-v\f[]
+Activate output debugging (warning: highly verbose)
+.RS
+.RE
+.TP
+.B \f[I]\-h\f[]
+Displays help output for the pingpong test.
+.RS
+.RE
 .SH USAGE EXAMPLES
 .SS A simple example
 .SS Server: \f[C]fi_pingpong\ \-p\ <provider_name>\f[]
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_strerror.1 b/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_strerror.1
index f5ebedc4c..f2f8676b3 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_strerror.1
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man1/fi_strerror.1
@@ -1,4 +1,7 @@
-.TH "fi_strerror" "1" "2016\-06\-30" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_strerror" "1" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_strerror \- display libfabric error strings
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_atomic.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_atomic.3
index 4724d892e..063d20c22 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_atomic.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_atomic.3
@@ -1,17 +1,27 @@
-.TH "fi_atomic" "3" "2017\-09\-25" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_atomic" "3" "2018\-11\-28" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_atomic \- Remote atomic functions
-.PP
-fi_atomic / fi_atomicv / fi_atomicmsg / fi_inject_atomic : Initiates an
-atomic operation to remote memory
-.PP
-fi_fetch_atomic / fi_fetch_atomicv / fi_fetch_atomicmsg : Initiates an
-atomic operation to remote memory, retrieving the initial value.
-.PP
-fi_compare_atomic / fi_compare_atomicv / fi_compare_atomicmsg :
+.TP
+.B fi_atomic / fi_atomicv / fi_atomicmsg / fi_inject_atomic
+Initiates an atomic operation to remote memory
+.RS
+.RE
+.TP
+.B fi_fetch_atomic / fi_fetch_atomicv / fi_fetch_atomicmsg
+Initiates an atomic operation to remote memory, retrieving the initial
+value.
+.RS
+.RE
+.TP
+.B fi_compare_atomic / fi_compare_atomicv / fi_compare_atomicmsg
 Initiates an atomic compare\-operation to remote memory, retrieving the
 initial value.
+.RS
+.RE
 .PP
 fi_atomicvalid / fi_fetch_atomicvalid / fi_compare_atomicvalid /
 fi_query_atomic : Indicates if a provider supports a specific atomic
@@ -89,46 +99,88 @@ int\ fi_query_atomic(struct\ fid_domain\ *domain,
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]ep\f[] : Fabric endpoint on which to initiate atomic operation.
-.PP
-\f[I]buf\f[] : Local data buffer that specifies first operand of atomic
-operation
-.PP
-\f[I]iov / comparev / resultv\f[] : Vectored data buffer(s).
-.PP
-\f[I]count / compare_count / result_count\f[] : Count of vectored data
-entries.
+.TP
+.B \f[I]ep\f[]
+Fabric endpoint on which to initiate atomic operation.
+.RS
+.RE
+.TP
+.B \f[I]buf\f[]
+Local data buffer that specifies first operand of atomic operation
+.RS
+.RE
+.TP
+.B \f[I]iov / comparev / resultv\f[]
+Vectored data buffer(s).
+.RS
+.RE
+.TP
+.B \f[I]count / compare_count / result_count\f[]
+Count of vectored data entries.
 The number of elements referenced, where each element is the indicated
 datatype.
-.PP
-\f[I]addr\f[] : Address of remote memory to access.
-.PP
-\f[I]key\f[] : Protection key associated with the remote memory.
-.PP
-\f[I]datatype\f[] : Datatype associated with atomic operands
-.PP
-\f[I]op\f[] : Atomic operation to perform
-.PP
-\f[I]compare\f[] : Local compare buffer, containing comparison data.
-.PP
-\f[I]result\f[] : Local data buffer to store initial value of remote
-buffer
-.PP
-\f[I]desc / compare_desc / result_desc\f[] : Data descriptor associated
-with the local data buffer, local compare buffer, and local result
-buffer, respectively.
-.PP
-\f[I]dest_addr\f[] : Destination address for connectionless atomic
-operations.
+.RS
+.RE
+.TP
+.B \f[I]addr\f[]
+Address of remote memory to access.
+.RS
+.RE
+.TP
+.B \f[I]key\f[]
+Protection key associated with the remote memory.
+.RS
+.RE
+.TP
+.B \f[I]datatype\f[]
+Datatype associated with atomic operands
+.RS
+.RE
+.TP
+.B \f[I]op\f[]
+Atomic operation to perform
+.RS
+.RE
+.TP
+.B \f[I]compare\f[]
+Local compare buffer, containing comparison data.
+.RS
+.RE
+.TP
+.B \f[I]result\f[]
+Local data buffer to store initial value of remote buffer
+.RS
+.RE
+.TP
+.B \f[I]desc / compare_desc / result_desc\f[]
+Data descriptor associated with the local data buffer, local compare
+buffer, and local result buffer, respectively.
+.RS
+.RE
+.TP
+.B \f[I]dest_addr\f[]
+Destination address for connectionless atomic operations.
 Ignored for connected endpoints.
-.PP
-\f[I]msg\f[] : Message descriptor for atomic operations
-.PP
-\f[I]flags\f[] : Additional flags to apply for the atomic operation
-.PP
-\f[I]context\f[] : User specified pointer to associate with the
-operation.
+.RS
+.RE
+.TP
+.B \f[I]msg\f[]
+Message descriptor for atomic operations
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply for the atomic operation
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified pointer to associate with the operation.
+This parameter is ignored if the operation will not generate a
+successful completion, unless an op flag specifies the context parameter
+be used for required input.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Atomic transfers are used to read and update data located in remote
@@ -149,40 +201,73 @@ Atomic functions may operate on one of the following identified data
 types.
 A given atomic function may support any datatype, subject to provider
 implementation constraints.
-.PP
-\f[I]FI_INT8\f[] : Signed 8\-bit integer.
-.PP
-\f[I]FI_UINT8\f[] : Unsigned 8\-bit integer.
-.PP
-\f[I]FI_INT16\f[] : Signed 16\-bit integer.
-.PP
-\f[I]FI_UINT16\f[] : Unsigned 16\-bit integer.
-.PP
-\f[I]FI_INT32\f[] : Signed 32\-bit integer.
-.PP
-\f[I]FI_UINT32\f[] : Unsigned 32\-bit integer.
-.PP
-\f[I]FI_INT64\f[] : Signed 64\-bit integer.
-.PP
-\f[I]FI_UINT64\f[] : Unsigned 64\-bit integer.
-.PP
-\f[I]FI_FLOAT\f[] : A single\-precision floating point value (IEEE 754).
-.PP
-\f[I]FI_DOUBLE\f[] : A double\-precision floating point value (IEEE
-754).
-.PP
-\f[I]FI_FLOAT_COMPLEX\f[] : An ordered pair of single\-precision
-floating point values (IEEE 754), with the first value representing the
-real portion of a complex number and the second representing the
-imaginary portion.
-.PP
-\f[I]FI_DOUBLE_COMPLEX\f[] : An ordered pair of double\-precision
-floating point values (IEEE 754), with the first value representing the
-real portion of a complex number and the second representing the
-imaginary portion.
-.PP
-\f[I]FI_LONG_DOUBLE\f[] : A double\-extended precision floating point
-value (IEEE 754).
+.TP
+.B \f[I]FI_INT8\f[]
+Signed 8\-bit integer.
+.RS
+.RE
+.TP
+.B \f[I]FI_UINT8\f[]
+Unsigned 8\-bit integer.
+.RS
+.RE
+.TP
+.B \f[I]FI_INT16\f[]
+Signed 16\-bit integer.
+.RS
+.RE
+.TP
+.B \f[I]FI_UINT16\f[]
+Unsigned 16\-bit integer.
+.RS
+.RE
+.TP
+.B \f[I]FI_INT32\f[]
+Signed 32\-bit integer.
+.RS
+.RE
+.TP
+.B \f[I]FI_UINT32\f[]
+Unsigned 32\-bit integer.
+.RS
+.RE
+.TP
+.B \f[I]FI_INT64\f[]
+Signed 64\-bit integer.
+.RS
+.RE
+.TP
+.B \f[I]FI_UINT64\f[]
+Unsigned 64\-bit integer.
+.RS
+.RE
+.TP
+.B \f[I]FI_FLOAT\f[]
+A single\-precision floating point value (IEEE 754).
+.RS
+.RE
+.TP
+.B \f[I]FI_DOUBLE\f[]
+A double\-precision floating point value (IEEE 754).
+.RS
+.RE
+.TP
+.B \f[I]FI_FLOAT_COMPLEX\f[]
+An ordered pair of single\-precision floating point values (IEEE 754),
+with the first value representing the real portion of a complex number
+and the second representing the imaginary portion.
+.RS
+.RE
+.TP
+.B \f[I]FI_DOUBLE_COMPLEX\f[]
+An ordered pair of double\-precision floating point values (IEEE 754),
+with the first value representing the real portion of a complex number
+and the second representing the imaginary portion.
+.RS
+.RE
+.TP
+.B \f[I]FI_LONG_DOUBLE\f[]
+A double\-extended precision floating point value (IEEE 754).
 Note that the size of a long double and number of bits used for
 precision is compiler, platform, and/or provider specific.
 Developers that use long double should ensure that libfabric is built
@@ -190,11 +275,15 @@ using a long double format that is compatible with their application,
 and that format is supported by the provider.
 The mechanism used for this validation is currently beyond the scope of
 the libfabric API.
-.PP
-\f[I]FI_LONG_DOUBLE_COMPLEX\f[] : An ordered pair of double\-extended
-precision floating point values (IEEE 754), with the first value
-representing the real portion of a complex number and the second
-representing the imaginary portion.
+.RS
+.RE
+.TP
+.B \f[I]FI_LONG_DOUBLE_COMPLEX\f[]
+An ordered pair of double\-extended precision floating point values
+(IEEE 754), with the first value representing the real portion of a
+complex number and the second representing the imaginary portion.
+.RS
+.RE
 .SS Atomic Operations
 .PP
 The following atomic operations are defined.
@@ -203,8 +292,11 @@ memory buffer and source value provided with the atomic function.
 It may also carry source data to replace the target value in compare and
 swap operations.
 A conceptual description of each operation is provided.
-.PP
-\f[I]FI_MIN\f[] : Minimum
+.TP
+.B \f[I]FI_MIN\f[]
+Minimum
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -212,8 +304,11 @@ if\ (buf[i]\ <\ addr[i])
 \ \ \ \ addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_MAX\f[] : Maximum
+.TP
+.B \f[I]FI_MAX\f[]
+Maximum
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -221,88 +316,121 @@ if\ (buf[i]\ >\ addr[i])
 \ \ \ \ addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_SUM\f[] : Sum
+.TP
+.B \f[I]FI_SUM\f[]
+Sum
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ addr[i]\ +\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_PROD\f[] : Product
+.TP
+.B \f[I]FI_PROD\f[]
+Product
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ addr[i]\ *\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_LOR\f[] : Logical OR
+.TP
+.B \f[I]FI_LOR\f[]
+Logical OR
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ (addr[i]\ ||\ buf[i])
 \f[]
 .fi
-.PP
-\f[I]FI_LAND\f[] : Logical AND
+.TP
+.B \f[I]FI_LAND\f[]
+Logical AND
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ (addr[i]\ &&\ buf[i])
 \f[]
 .fi
-.PP
-\f[I]FI_BOR\f[] : Bitwise OR
+.TP
+.B \f[I]FI_BOR\f[]
+Bitwise OR
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ addr[i]\ |\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_BAND\f[] : Bitwise AND
+.TP
+.B \f[I]FI_BAND\f[]
+Bitwise AND
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ addr[i]\ &\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_LXOR\f[] : Logical exclusive\-OR (XOR)
+.TP
+.B \f[I]FI_LXOR\f[]
+Logical exclusive\-OR (XOR)
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ ((addr[i]\ &&\ !buf[i])\ ||\ (!addr[i]\ &&\ buf[i]))
 \f[]
 .fi
-.PP
-\f[I]FI_BXOR\f[] : Bitwise exclusive\-OR (XOR)
+.TP
+.B \f[I]FI_BXOR\f[]
+Bitwise exclusive\-OR (XOR)
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ addr[i]\ ^\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_ATOMIC_READ\f[] : Read data atomically
+.TP
+.B \f[I]FI_ATOMIC_READ\f[]
+Read data atomically
+.RS
+.RE
 .IP
 .nf
 \f[C]
 result[i]\ =\ addr[i]
 \f[]
 .fi
-.PP
-\f[I]FI_ATOMIC_WRITE\f[] : Write data atomically
+.TP
+.B \f[I]FI_ATOMIC_WRITE\f[]
+Write data atomically
+.RS
+.RE
 .IP
 .nf
 \f[C]
 addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_CSWAP\f[] : Compare values and if equal swap with data
+.TP
+.B \f[I]FI_CSWAP\f[]
+Compare values and if equal swap with data
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -310,8 +438,11 @@ if\ (compare[i]\ ==\ addr[i])
 \ \ \ \ addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_CSWAP_NE\f[] : Compare values and if not equal swap with data
+.TP
+.B \f[I]FI_CSWAP_NE\f[]
+Compare values and if not equal swap with data
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -319,9 +450,11 @@ if\ (compare[i]\ !=\ addr[i])
 \ \ \ \ addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_CSWAP_LE\f[] : Compare values and if less than or equal swap
-with data
+.TP
+.B \f[I]FI_CSWAP_LE\f[]
+Compare values and if less than or equal swap with data
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -329,8 +462,11 @@ if\ (compare[i]\ <=\ addr[i])
 \ \ \ \ addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_CSWAP_LT\f[] : Compare values and if less than swap with data
+.TP
+.B \f[I]FI_CSWAP_LT\f[]
+Compare values and if less than swap with data
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -338,9 +474,11 @@ if\ (compare[i]\ <\ addr[i])
 \ \ \ \ addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_CSWAP_GE\f[] : Compare values and if greater than or equal swap
-with data
+.TP
+.B \f[I]FI_CSWAP_GE\f[]
+Compare values and if greater than or equal swap with data
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -348,8 +486,11 @@ if\ (compare[i]\ >=\ addr[i])
 \ \ \ \ addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_CSWAP_GT\f[] : Compare values and if greater than swap with data
+.TP
+.B \f[I]FI_CSWAP_GT\f[]
+Compare values and if greater than swap with data
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -357,8 +498,11 @@ if\ (compare[i]\ >\ addr[i])
 \ \ \ \ addr[i]\ =\ buf[i]
 \f[]
 .fi
-.PP
-\f[I]FI_MSWAP\f[] : Swap masked bits with data
+.TP
+.B \f[I]FI_MSWAP\f[]
+Swap masked bits with data
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -523,19 +667,33 @@ The count attribute field is as defined for the atomic valid calls.
 The size field indicates the size in bytes of the atomic datatype.
 .SS Completions
 .PP
-Completed atomic operations are reported to the user through one or more
-event collectors associated with the endpoint.
-Users provide context which are associated with each operation, and is
-returned to the user as part of the event completion.
+Completed atomic operations are reported to the initiator of the request
+through an associated completion queue or counter.
+Any user provided context specified with the request will be returned as
+part of any completion event written to a CQ.
 See fi_cq for completion event details.
 .PP
-Updates to the target buffer of an atomic operation are visible to
-processes running on the target system either after a completion has
-been generated, or after the completion of an operation initiated after
-the atomic call with a fencing operation occurring in between.
-For example, the target process may be notified by the initiator sending
-a message after the atomic call completes, or sending a fenced message
-immediately after initiating the atomic operation.
+Any results returned to the initiator as part of an atomic operation
+will be available prior to a completion event being generated.
+This will be true even if the requested completion semantic provides a
+weaker guarantee.
+That is, atomic fetch operations have FI_DELIVERY_COMPLETE semantics.
+Completions generated for other types of atomic operations indicate that
+it is safe to re\-use the source data buffers.
+.PP
+Any updates to data at the target of an atomic operation will be visible
+to processes running on the target node prior to one of the following
+occurring.
+If the atomic operation generates a completion event or updates a
+completion counter at the target endpoint, the results will be available
+prior to the completion notification.
+After processing a completion for the atomic, if the initiator submits a
+transfer between the same endpoints that generates a completion at the
+target, the results will be available prior to the subsequent
+transfer\[aq]s event.
+Or, if a fenced data transfer from the initiator follows the atomic
+request, the results will be available prior to a completion at the
+target for the fenced transfer.
 .SH FLAGS
 .PP
 The fi_atomicmsg, fi_fetch_atomicmsg, and fi_compare_atomicmsg calls
@@ -545,58 +703,83 @@ Flags specified with atomic message operations override most flags
 previously configured with the endpoint, except where noted (see
 fi_control).
 The following list of flags are usable with atomic message calls.
-.PP
-\f[I]FI_COMPLETION\f[] : Indicates that a completion entry should be
-generated for the specified operation.
+.TP
+.B \f[I]FI_COMPLETION\f[]
+Indicates that a completion entry should be generated for the specified
+operation.
 The endpoint must be bound to a completion queue with
 FI_SELECTIVE_COMPLETION that corresponds to the specified operation, or
 this flag is ignored.
-.PP
-\f[I]FI_MORE\f[] : Indicates that the user has additional requests that
-will immediately be posted after the current call returns.
+.RS
+.RE
+.TP
+.B \f[I]FI_MORE\f[]
+Indicates that the user has additional requests that will immediately be
+posted after the current call returns.
 Use of this flag may improve performance by enabling the provider to
 optimize its access to the fabric hardware.
-.PP
-\f[I]FI_INJECT\f[] : Indicates that the outbound non\-const data buffers
-(buf and compare parameters) should be returned to user immediately
-after the call returns, even if the operation is handled asynchronously.
+.RS
+.RE
+.TP
+.B \f[I]FI_INJECT\f[]
+Indicates that the control of constant data buffers should be returned
+to the user immediately after the call returns, even if the operation is
+handled asynchronously.
 This may require that the underlying provider implementation copy the
 data into a local buffer and transfer out of that buffer.
-The use of output result buffers are not affected by this flag.
+Constant data buffers refers to any data buffer or iovec used by the
+atomic APIs that are marked as \[aq]const\[aq].
+Non\-constant or output buffers are unaffected by this flag and may be
+accessed by the provider at anytime until the operation has completed.
 This flag can only be used with messages smaller than inject_size.
-.PP
-\f[I]FI_FENCE\f[] : Applies to transmits.
+.RS
+.RE
+.TP
+.B \f[I]FI_FENCE\f[]
+Applies to transmits.
 Indicates that the requested operation, also known as the fenced
 operation, and any operation posted after the fenced operation will be
 deferred until all previous operations targeting the same peer endpoint
 have completed.
 Operations posted after the fencing will see and/or replace the results
 of any operations initiated prior to the fenced operation.
+.RS
+.RE
 .PP
 The ordering of operations starting at the posting of the fenced
 operation (inclusive) to the posting of a subsequent fenced operation
 (exclusive) is controlled by the endpoint\[aq]s ordering semantics.
-.PP
-\f[I]FI_TAGGED\f[] : Specifies that the target of the atomic operation
-is a tagged receive buffer instead of an RMA buffer.
+.TP
+.B \f[I]FI_TAGGED\f[]
+Specifies that the target of the atomic operation is a tagged receive
+buffer instead of an RMA buffer.
 When a tagged buffer is the target memory region, the addr parameter is
 used as a 0\-based byte offset into the tagged buffer, with the key
 parameter specifying the tag.
+.RS
+.RE
 .SH RETURN VALUE
 .PP
 Returns 0 on success.
 On error, a negative value corresponding to fabric errno is returned.
 Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
 .SH ERRORS
-.PP
-\f[I]\-FI_EAGAIN\f[] : See \f[C]fi_msg\f[](3) for a detailed description
-of handling FI_EAGAIN.
-.PP
-\f[I]\-FI_EOPNOTSUPP\f[] : The requested atomic operation is not
-supported on this endpoint.
-.PP
-\f[I]\-FI_EMSGSIZE\f[] : The number of atomic operations in a single
-request exceeds that supported by the underlying provider.
+.TP
+.B \f[I]\-FI_EAGAIN\f[]
+See \f[C]fi_msg\f[](3) for a detailed description of handling FI_EAGAIN.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_EOPNOTSUPP\f[]
+The requested atomic operation is not supported on this endpoint.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_EMSGSIZE\f[]
+The number of atomic operations in a single request exceeds that
+supported by the underlying provider.
+.RS
+.RE
 .SH NOTES
 .PP
 Atomic operations operate on an array of values of a specific data type.
@@ -625,6 +808,15 @@ This must be between 1 and the maximum returned through the relevant
 valid operation, inclusive.
 The requested operation and data type must also be valid for the given
 provider.
+.PP
+The ordering of atomic operations carried as part of different request
+messages is subject to the message and data ordering definitions
+assigned to the transmitting and receiving endpoints.
+Both message and data ordering are required if the results of two atomic
+operations to the same memory buffers are to reflect the second
+operation acting on the results of the first.
+See \f[C]fi_endpoint\f[](3) for further details and message size
+restrictions.
 .SH SEE ALSO
 .PP
 \f[C]fi_getinfo\f[](3), \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_av.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_av.3
index aa4ec5fac..565ed4591 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_av.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_av.3
@@ -1,18 +1,35 @@
-.TH "fi_av" "3" "2017\-06\-21" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_av" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_av \- Address vector operations
-.PP
-fi_av_open / fi_close : Open or close an address vector
-.PP
-fi_av_bind : Associate an address vector with an event queue.
-.PP
-fi_av_insert / fi_av_insertsvc / fi_av_remove : Insert/remove an address
-into/from the address vector.
-.PP
-fi_av_lookup : Retrieve an address stored in the address vector.
-.PP
-fi_av_straddr : Convert an address into a printable string.
+.TP
+.B fi_av_open / fi_close
+Open or close an address vector
+.RS
+.RE
+.TP
+.B fi_av_bind
+Associate an address vector with an event queue.
+.RS
+.RE
+.TP
+.B fi_av_insert / fi_av_insertsvc / fi_av_remove
+Insert/remove an address into/from the address vector.
+.RS
+.RE
+.TP
+.B fi_av_lookup
+Retrieve an address stored in the address vector.
+.RS
+.RE
+.TP
+.B fi_av_straddr
+Convert an address into a printable string.
+.RS
+.RE
 .SH SYNOPSIS
 .IP
 .nf
@@ -51,31 +68,60 @@ const\ char\ *\ fi_av_straddr(struct\ fid_av\ *av,\ const\ void\ *addr,
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]domain\f[] : Resource domain
-.PP
-\f[I]av\f[] : Address vector
-.PP
-\f[I]eq\f[] : Event queue
-.PP
-\f[I]attr\f[] : Address vector attributes
-.PP
-\f[I]context\f[] : User specified context associated with the address
-vector or insert operation.
-.PP
-\f[I]addr\f[] : Buffer containing one or more addresses to insert into
-address vector.
-.PP
-\f[I]addrlen\f[] : On input, specifies size of addr buffer.
+.TP
+.B \f[I]domain\f[]
+Resource domain
+.RS
+.RE
+.TP
+.B \f[I]av\f[]
+Address vector
+.RS
+.RE
+.TP
+.B \f[I]eq\f[]
+Event queue
+.RS
+.RE
+.TP
+.B \f[I]attr\f[]
+Address vector attributes
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified context associated with the address vector or insert
+operation.
+.RS
+.RE
+.TP
+.B \f[I]addr\f[]
+Buffer containing one or more addresses to insert into address vector.
+.RS
+.RE
+.TP
+.B \f[I]addrlen\f[]
+On input, specifies size of addr buffer.
 On output, stores number of bytes written to addr buffer.
-.PP
-\f[I]fi_addr\f[] : For insert, a reference to an array where returned
-fabric addresses will be written.
+.RS
+.RE
+.TP
+.B \f[I]fi_addr\f[]
+For insert, a reference to an array where returned fabric addresses will
+be written.
 For remove, one or more fabric addresses to remove.
-.PP
-\f[I]count\f[] : Number of addresses to insert/remove from an AV.
-.PP
-\f[I]flags\f[] : Additional flags to apply to the operation.
+.RS
+.RE
+.TP
+.B \f[I]count\f[]
+Number of addresses to insert/remove from an AV.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply to the operation.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Address vectors are used to map higher level addresses, which may be
@@ -105,15 +151,19 @@ struct\ fi_av_attr\ {
 };
 \f[]
 .fi
-.PP
-\f[I]type\f[] : An AV type corresponds to a conceptual implementation of
-an address vector.
+.TP
+.B \f[I]type\f[]
+An AV type corresponds to a conceptual implementation of an address
+vector.
 The type specifies how an application views data stored in the AV,
 including how it may be accessed.
 Valid values are:
-.IP \[bu] 2
-\f[I]FI_AV_MAP\f[] : Addresses which are inserted into an AV are mapped
-to a native fabric address for use by the application.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_AV_MAP\f[]
+Addresses which are inserted into an AV are mapped to a native fabric
+address for use by the application.
 The use of FI_AV_MAP requires that an application store the returned
 fi_addr_t value that is associated with each inserted address.
 The advantage of using FI_AV_MAP is that the returned fi_addr_t value
@@ -126,9 +176,12 @@ store the returned addresses.
 Addresses are stored in the AV using a provider specific mechanism,
 including, but not limited to a tree, hash table, or maintained on the
 heap.
-.IP \[bu] 2
-\f[I]FI_AV_TABLE\f[] : Addresses which are inserted into an AV of type
-FI_AV_TABLE are accessible using a simple index.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_AV_TABLE\f[]
+Addresses which are inserted into an AV of type FI_AV_TABLE are
+accessible using a simple index.
 Conceptually, the AV may be treated as an array of addresses, though the
 provider may implement the AV using a variety of mechanisms.
 When FI_AV_TABLE is used, the returned fi_addr_t is an index, with the
@@ -138,46 +191,64 @@ The index of the first address inserted into an FI_AV_TABLE will be 0,
 and successive insertions will be given sequential indices.
 Sequential indices will be assigned across insertion calls on the same
 AV.
-.IP \[bu] 2
-\f[I]FI_AV_UNSPEC\f[] : Provider will choose its preferred AV type.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_AV_UNSPEC\f[]
+Provider will choose its preferred AV type.
 The AV type used will be returned through the type field in fi_av_attr.
-.PP
-\f[I]Receive Context Bits (rx_ctx_bits)\f[] : The receive context bits
-field is only for use with scalable endpoints.
+.RS
+.RE
+.TP
+.B \f[I]Receive Context Bits (rx_ctx_bits)\f[]
+The receive context bits field is only for use with scalable endpoints.
 It indicates the number of bits reserved in a returned fi_addr_t, which
 will be used to identify a specific target receive context.
 See fi_rx_addr() and fi_endpoint(3) for additional details on receive
 contexts.
 The requested number of bits should be selected such that 2 ^
 rx_ctx_bits >= rx_ctx_cnt for the endpoint.
-.PP
-\f[I]count\f[] : Indicates the expected number of addresses that will be
-inserted into the AV.
+.RS
+.RE
+.TP
+.B \f[I]count\f[]
+Indicates the expected number of addresses that will be inserted into
+the AV.
 The provider uses this to optimize resource allocations.
-.PP
-\f[I]ep_per_node\f[] : This field indicates the number of endpoints that
-will be associated with a specific fabric, or network, address.
+.RS
+.RE
+.TP
+.B \f[I]ep_per_node\f[]
+This field indicates the number of endpoints that will be associated
+with a specific fabric, or network, address.
 If the number of endpoints per node is unknown, this value should be set
 to 0.
 The provider uses this value to optimize resource allocations.
 For example, distributed, parallel applications may set this to the
 number of processes allocated per node, times the number of endpoints
 each process will open.
-.PP
-\f[I]name\f[] : An optional system name associated with the address
-vector to create or open.
+.RS
+.RE
+.TP
+.B \f[I]name\f[]
+An optional system name associated with the address vector to create or
+open.
 Address vectors may be shared across multiple processes which access the
 same named domain on the same node.
 The name field allows the underlying provider to identify a shared AV.
+.RS
+.RE
 .PP
 If the name field is non\-NULL and the AV is not opened for read\-only
 access, a named AV will be created, if it does not already exist.
-.PP
-\f[I]map_addr\f[] : The map_addr determines the base fi_addr_t address
-that a provider should use when sharing an AV of type FI_AV_MAP between
-processes.
+.TP
+.B \f[I]map_addr\f[]
+The map_addr determines the base fi_addr_t address that a provider
+should use when sharing an AV of type FI_AV_MAP between processes.
 Processes that provide the same value for map_addr to a shared AV may
 use the same fi_addr_t values returned from an fi_av_insert call.
+.RS
+.RE
 .PP
 The map_addr may be used by the provider to mmap memory allocated for a
 shared AV between processes; however, the provider is not required to
@@ -191,11 +262,15 @@ defined.
 If name is non\-NULL and map_addr is 0, then the map_addr used by the
 provider will be returned through the attribute structure.
 The map_addr field is ignored if name is NULL.
-.PP
-\f[I]flags\f[] : The following flags may be used when opening an AV.
-.IP \[bu] 2
-\f[I]FI_EVENT\f[] : When the flag FI_EVENT is specified, all insert
-operations on this AV will occur asynchronously.
+.TP
+.B \f[I]flags\f[]
+The following flags may be used when opening an AV.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_EVENT\f[]
+When the flag FI_EVENT is specified, all insert operations on this AV
+will occur asynchronously.
 There will be one EQ error entry generated for each failed address
 insertion, followed by one non\-error event indicating that the
 insertion operation has completed.
@@ -212,6 +287,8 @@ specified in the insert call; the data field will contain the index of
 the failed address.
 There will be one error completion returned for each address that fails
 to insert into the AV.
+.RS
+.RE
 .PP
 If an AV is opened with FI_EVENT, any insertions attempted before an EQ
 is bound to the AV will fail with \-FI_ENOEQ.
@@ -223,16 +300,26 @@ Note that the order of delivery of insert completions may not match the
 order in which the calls to fi_av_insert were made.
 The only guarantee is that all error completions for a given call to
 fi_av_insert will precede the single associated non\-error completion.
-.IP \[bu] 2
-\f[I]FI_READ\f[] : Opens an AV for read\-only access.
+\[bu] .RS 2
+.TP
+.B \f[I]FI_READ\f[]
+Opens an AV for read\-only access.
 An AV opened for read\-only access must be named (name attribute
 specified), and the AV must exist.
-.IP \[bu] 2
-\f[I]FI_SYMMETRIC\f[] : Indicates that each node will be associated with
-the same number of endpoints, the same transport addresses will be
-allocated on each node, and the transport addresses will be sequential.
+.RS
+.RE
+.RE
+\[bu] .RS 2
+.TP
+.B \f[I]FI_SYMMETRIC\f[]
+Indicates that each node will be associated with the same number of
+endpoints, the same transport addresses will be allocated on each node,
+and the transport addresses will be sequential.
 This feature targets distributed applications on large fabrics and
 allows for highly\-optimized storage of remote endpoint addressing.
+.RS
+.RE
+.RE
 .SS fi_close
 .PP
 The fi_close call is used to release all resources associated with an
@@ -304,27 +391,36 @@ to fi_av_insert following a call to fi_av_remove always reference a
 valid buffer in the fi_addr parameter.
 Otherwise it may be difficult to determine what the next assigned index
 will be.
-.PP
-\f[I]flags\f[] : The following flag may be passed to AV insertion calls:
-fi_av_insert, fi_av_insertsvc, or fi_av_insertsym.
-.IP \[bu] 2
-\f[I]FI_MORE\f[] : In order to allow optimized address insertion, the
-application may specify the FI_MORE flag to the insert call to give a
-hint to the provider that more insertion requests will follow, allowing
-the provider to aggregate insertion requests if desired.
+.TP
+.B \f[I]flags\f[]
+The following flag may be passed to AV insertion calls: fi_av_insert,
+fi_av_insertsvc, or fi_av_insertsym.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_MORE\f[]
+In order to allow optimized address insertion, the application may
+specify the FI_MORE flag to the insert call to give a hint to the
+provider that more insertion requests will follow, allowing the provider
+to aggregate insertion requests if desired.
 An application may make any number of insertion calls with FI_MORE set,
 provided that they are followed by an insertion call without FI_MORE.
 This signifies to the provider that the insertion list is complete.
 Providers are free to ignore FI_MORE.
-.IP \[bu] 2
-\f[I]FI_SYNC_ERR\f[] : This flag applies to synchronous insertions only,
-and is used to retrieve error details of failed insertions.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_SYNC_ERR\f[]
+This flag applies to synchronous insertions only, and is used to
+retrieve error details of failed insertions.
 If set, the context parameter of insertion calls references an array of
 integers, with context set to address of the first element of the array.
 The resulting status of attempting to insert each address will be
 written to the corresponding array location.
 Successful insertions will be updated to 0.
 Failures will contain a fabric errno code.
+.RS
+.RE
 .SS fi_av_insertsvc
 .PP
 The fi_av_insertsvc call behaves similar to fi_av_insert, but allows the
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cm.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cm.3
index 71042efb4..d48f467ed 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cm.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cm.3
@@ -1,16 +1,25 @@
-.TH "fi_cm" "3" "2017\-06\-06" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_cm" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_cm \- Connection management operations
-.PP
-fi_connect / fi_listen / fi_accept / fi_reject / fi_shutdown : Manage
-endpoint connection state.
-.PP
-fi_setname / fi_getname / fi_getpeer : Set local, or return local or
-peer endpoint address.
-.PP
-fi_join / fi_close / fi_mc_addr : Join, leave, or retrieve a multicast
-address.
+.TP
+.B fi_connect / fi_listen / fi_accept / fi_reject / fi_shutdown
+Manage endpoint connection state.
+.RS
+.RE
+.TP
+.B fi_setname / fi_getname / fi_getpeer
+Set local, or return local or peer endpoint address.
+.RS
+.RE
+.TP
+.B fi_join / fi_close / fi_mc_addr
+Join, leave, or retrieve a multicast address.
+.RS
+.RE
 .SH SYNOPSIS
 .IP
 .nf
@@ -44,34 +53,60 @@ fi_addr_t\ fi_mc_addr(struct\ fid_mc\ *mc);
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]ep / pep\f[] : Fabric endpoint on which to change connection state.
+.TP
+.B \f[I]ep / pep\f[]
+Fabric endpoint on which to change connection state.
+.RS
+.RE
 .PP
 \f[I]fid\f[] Active or passive endpoint to get/set address.
-.PP
-\f[I]addr\f[] : Buffer to address.
+.TP
+.B \f[I]addr\f[]
+Buffer to address.
 On a set call, the endpoint will be assigned the specified address.
 On a get, the local address will be copied into the buffer, up to the
 space provided.
 For connect, this parameter indicates the peer address to connect to.
 The address must be in the same format as that specified using fi_info:
 addr_format when the endpoint was created.
-.PP
-\f[I]addrlen\f[] : On input, specifies size of addr buffer.
+.RS
+.RE
+.TP
+.B \f[I]addrlen\f[]
+On input, specifies size of addr buffer.
 On output, stores number of bytes written to addr buffer.
-.PP
-\f[I]param\f[] : User\-specified data exchanged as part of the
-connection exchange.
-.PP
-\f[I]paramlen\f[] : Size of param buffer.
-.PP
-\f[I]info\f[] : Fabric information associated with a connection request.
-.PP
-\f[I]mc\f[] : Multicast group associated with an endpoint.
-.PP
-\f[I]flags\f[] : Additional flags for controlling connection operation.
-.PP
-\f[I]context\f[] : User context associated with the request.
+.RS
+.RE
+.TP
+.B \f[I]param\f[]
+User\-specified data exchanged as part of the connection exchange.
+.RS
+.RE
+.TP
+.B \f[I]paramlen\f[]
+Size of param buffer.
+.RS
+.RE
+.TP
+.B \f[I]info\f[]
+Fabric information associated with a connection request.
+.RS
+.RE
+.TP
+.B \f[I]mc\f[]
+Multicast group associated with an endpoint.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags for controlling connection operation.
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User context associated with the request.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Connection management functions are used to connect an
@@ -232,18 +267,24 @@ and paired with the FI_MULTICAST operation flag.
 .SH FLAGS
 .PP
 Except in functions noted below, flags are reserved and must be 0.
-.PP
-\f[I]FI_SEND\f[] : Applies to fi_join.
+.TP
+.B \f[I]FI_SEND\f[]
+Applies to fi_join.
 This flag indicates that the endpoint should join the multicast group as
 a send only member.
 The endpoint must be configured for transmit operations to use this
 flag, or an error will occur.
-.PP
-\f[I]FI_RECV\f[] : Applies to fi_join.
+.RS
+.RE
+.TP
+.B \f[I]FI_RECV\f[]
+Applies to fi_join.
 This flag indicates that the endpoint should join the multicast group
 with receive permissions only.
 The endpoint must be configured for receive operations to use this flag,
 or an error will occur.
+.RS
+.RE
 .SH RETURN VALUE
 .PP
 Returns 0 on success.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cntr.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cntr.3
index a37a2e385..959f30614 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cntr.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cntr.3
@@ -1,21 +1,40 @@
-.TH "fi_cntr" "3" "2017\-09\-14" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_cntr" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_cntr \- Completion and event counter operations
-.PP
-fi_cntr_open / fi_close : Allocate/free a counter
-.PP
-fi_cntr_read : Read the current value of a counter
-.PP
-fi_cntr_readerr : Reads the number of operations which have completed in
-error.
-.PP
-fi_cntr_add : Increment a counter by a specified value
-.PP
-fi_cntr_set : Set a counter to a specified value
-.PP
-fi_cntr_wait : Wait for a counter to be greater or equal to a threshold
-value
+.TP
+.B fi_cntr_open / fi_close
+Allocate/free a counter
+.RS
+.RE
+.TP
+.B fi_cntr_read
+Read the current value of a counter
+.RS
+.RE
+.TP
+.B fi_cntr_readerr
+Reads the number of operations which have completed in error.
+.RS
+.RE
+.TP
+.B fi_cntr_add
+Increment a counter by a specified value
+.RS
+.RE
+.TP
+.B fi_cntr_set
+Set a counter to a specified value
+.RS
+.RE
+.TP
+.B fi_cntr_wait
+Wait for a counter to be greater or equal to a threshold value
+.RS
+.RE
 .SH SYNOPSIS
 .IP
 .nf
@@ -44,21 +63,42 @@ int\ fi_cntr_wait(struct\ fid_cntr\ *cntr,\ uint64_t\ threshold,
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]domain\f[] : Fabric domain
-.PP
-\f[I]cntr\f[] : Fabric counter
-.PP
-\f[I]attr\f[] : Counter attributes
-.PP
-\f[I]context\f[] : User specified context associated with the counter
-.PP
-\f[I]value\f[] : Value to increment or set counter
-.PP
-\f[I]threshold\f[] : Value to compare counter against
-.PP
-\f[I]timeout\f[] : Time in milliseconds to wait.
+.TP
+.B \f[I]domain\f[]
+Fabric domain
+.RS
+.RE
+.TP
+.B \f[I]cntr\f[]
+Fabric counter
+.RS
+.RE
+.TP
+.B \f[I]attr\f[]
+Counter attributes
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified context associated with the counter
+.RS
+.RE
+.TP
+.B \f[I]value\f[]
+Value to increment or set counter
+.RS
+.RE
+.TP
+.B \f[I]threshold\f[]
+Value to compare counter against
+.RS
+.RE
+.TP
+.B \f[I]timeout\f[]
+Time in milliseconds to wait.
 A negative value indicates infinite timeout.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Counters record the number of requested operations that have completed.
@@ -91,20 +131,26 @@ struct\ fi_cntr_attr\ {
 };
 \f[]
 .fi
-.PP
-\f[I]events\f[] : A counter captures different types of events.
+.TP
+.B \f[I]events\f[]
+A counter captures different types of events.
 The specific type which is to counted are one of the following:
-.IP \[bu] 2
-\f[I]FI_CNTR_EVENTS_COMP\f[] : The counter increments for every
-successful completion that occurs on an associated bound endpoint.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_CNTR_EVENTS_COMP\f[]
+The counter increments for every successful completion that occurs on an
+associated bound endpoint.
 The type of completions \-\- sends and/or receives \-\- which are
 counted may be restricted using control flags when binding the counter
 and the endpoint.
 Counters increment on all successful completions, separately from
 whether the operation generates an entry in an event queue.
-.PP
-\f[I]wait_obj\f[] : Counters may be associated with a specific wait
-object.
+.RS
+.RE
+.TP
+.B \f[I]wait_obj\f[]
+Counters may be associated with a specific wait object.
 Wait objects allow applications to block until the wait object is
 signaled, indicating that a counter has reached a specific threshold.
 Users may use fi_control to retrieve the underlying wait object
@@ -113,43 +159,65 @@ The following values may be used to specify the type of wait object
 associated with a counter: FI_WAIT_NONE, FI_WAIT_UNSPEC, FI_WAIT_SET,
 FI_WAIT_FD, and FI_WAIT_MUTEX_COND.
 The default is FI_WAIT_NONE.
-.IP \[bu] 2
-\f[I]FI_WAIT_NONE\f[] : Used to indicate that the user will not block
-(wait) for events on the counter.
-.IP \[bu] 2
-\f[I]FI_WAIT_UNSPEC\f[] : Specifies that the user will only wait on the
-counter using fabric interface calls, such as fi_cntr_wait.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_NONE\f[]
+Used to indicate that the user will not block (wait) for events on the
+counter.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_UNSPEC\f[]
+Specifies that the user will only wait on the counter using fabric
+interface calls, such as fi_cntr_wait.
 In this case, the underlying provider may select the most appropriate or
 highest performing wait object available, including custom wait
 mechanisms.
 Applications that select FI_WAIT_UNSPEC are not guaranteed to retrieve
 the underlying wait object.
-.IP \[bu] 2
-\f[I]FI_WAIT_SET\f[] : Indicates that the event counter should use a
-wait set object to wait for events.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_SET\f[]
+Indicates that the event counter should use a wait set object to wait
+for events.
 If specified, the wait_set field must reference an existing wait set
 object.
-.IP \[bu] 2
-\f[I]FI_WAIT_FD\f[] : Indicates that the counter should use a file
-descriptor as its wait mechanism.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_FD\f[]
+Indicates that the counter should use a file descriptor as its wait
+mechanism.
 A file descriptor wait object must be usable in select, poll, and epoll
 routines.
 However, a provider may signal an FD wait object by marking it as
 readable, writable, or with an error.
-.IP \[bu] 2
-\f[I]FI_WAIT_MUTEX_COND\f[] : Specifies that the counter should use a
-pthread mutex and cond variable as a wait object.
-.PP
-\f[I]wait_set\f[] : If wait_obj is FI_WAIT_SET, this field references a
-wait object to which the event counter should attach.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_MUTEX_COND\f[]
+Specifies that the counter should use a pthread mutex and cond variable
+as a wait object.
+.RS
+.RE
+.TP
+.B \f[I]wait_set\f[]
+If wait_obj is FI_WAIT_SET, this field references a wait object to which
+the event counter should attach.
 When an event is added to the event counter, the corresponding wait set
 will be signaled if all necessary conditions are met.
 The use of a wait_set enables an optimized method of waiting for events
 across multiple event counters.
 This field is ignored if wait_obj is not FI_WAIT_SET.
-.PP
-\f[I]flags\f[] : Flags are reserved for future use, and must be set to
-0.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Flags are reserved for future use, and must be set to 0.
+.RS
+.RE
 .SS fi_close
 .PP
 The fi_close call releases all resources associated with a counter.
@@ -166,18 +234,27 @@ Access to the counter should be serialized across all calls when
 fi_cntr_control is invoked, as it may redirect the implementation of
 counter operations.
 The following control commands are usable with a counter:
-.PP
-\f[I]FI_GETOPSFLAG (uint64_t *)\f[] : Returns the current default
-operational flags associated with the counter.
-.PP
-\f[I]FI_SETOPSFLAG (uint64_t *)\f[] : Modifies the current default
-operational flags associated with the counter.
-.PP
-\f[I]FI_GETWAIT (void **)\f[] : This command allows the user to retrieve
-the low\-level wait object associated with the counter.
+.TP
+.B \f[I]FI_GETOPSFLAG (uint64_t *)\f[]
+Returns the current default operational flags associated with the
+counter.
+.RS
+.RE
+.TP
+.B \f[I]FI_SETOPSFLAG (uint64_t *)\f[]
+Modifies the current default operational flags associated with the
+counter.
+.RS
+.RE
+.TP
+.B \f[I]FI_GETWAIT (void **)\f[]
+This command allows the user to retrieve the low\-level wait object
+associated with the counter.
 The format of the wait\-object is specified during counter creation,
 through the counter attributes.
 See fi_eq.3 for addition details using control with FI_GETWAIT.
+.RS
+.RE
 .SS fi_cntr_read
 .PP
 The fi_cntr_read call returns the current value of the counter.
@@ -218,9 +295,11 @@ been configured with a wait object of FI_WAIT_NONE or FI_WAIT_SET.
 .PP
 Returns 0 on success.
 On error, a negative value corresponding to fabric errno is returned.
-.PP
-fi_cntr_read / fi_cntr_readerr : Returns the current value of the
-counter.
+.TP
+.B fi_cntr_read / fi_cntr_readerr
+Returns the current value of the counter.
+.RS
+.RE
 .PP
 Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
 .SH NOTES
@@ -233,7 +312,16 @@ fi_cntr_read or fi_cntr_readerr).
 A small, but undefined, delay may occur between the counter changing and
 the reported value being updated.
 However, a final updated value will eventually be reflected in the read
-counter value, with the order of the updates maintained.
+counter value.
+.PP
+Additionally, applications should ensure that the value of a counter is
+stable and not subject to change prior to calling fi_cntr_set or
+fi_cntr_seterr.
+Otherwise, the resulting value of the counter after fi_cntr_set /
+fi_cntr_seterr is undefined, as updates to the counter may be lost.
+A counter value is considered stable if all previous updates using
+fi_cntr_set / fi_cntr_seterr and results of related operations are
+reflected in the observed value of the counter.
 .SH SEE ALSO
 .PP
 \f[C]fi_getinfo\f[](3), \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_control.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_control.3
index 2669e1791..c6bc5b3bb 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_control.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_control.3
@@ -1,4 +1,7 @@
-.TH "fi_control" "3" "2016\-02\-28" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_control" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_control \- Perform an operation on a fabric resource.
@@ -12,12 +15,21 @@ int\ fi_control(struct\ fid\ *fid,\ int\ command,\ void\ *arg);
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]fid\f[] : Fabric resource
-.PP
-\f[I]command\f[] : Operation to perform
-.PP
-\f[I]arg\f[] : Optional argument to the command
+.TP
+.B \f[I]fid\f[]
+Fabric resource
+.RS
+.RE
+.TP
+.B \f[I]command\f[]
+Operation to perform
+.RS
+.RE
+.TP
+.B \f[I]arg\f[]
+Optional argument to the command
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 The fi_control operation is used to perform one or more operations on a
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cq.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cq.3
index 723360c4f..e1e52a29c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cq.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_cq.3
@@ -1,24 +1,41 @@
-.TH "fi_cq" "3" "2017\-12\-06" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_cq" "3" "2018\-11\-28" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_cq \- Completion queue operations
-.PP
-fi_cq_open / fi_close : Open/close a completion queue
-.PP
-fi_control : Control CQ operation or attributes.
-.PP
-fi_cq_read / fi_cq_readfrom / fi_cq_readerr : Read a completion from a
-completion queue
-.PP
-fi_cq_sread / fi_cq_sreadfrom : A synchronous (blocking) read that waits
-until a specified condition has been met before reading a completion
-from a completion queue.
-.PP
-fi_cq_signal : Unblock any thread waiting in fi_cq_sread or
-fi_cq_sreadfrom.
-.PP
-fi_cq_strerror : Converts provider specific error information into a
-printable string
+.TP
+.B fi_cq_open / fi_close
+Open/close a completion queue
+.RS
+.RE
+.TP
+.B fi_control
+Control CQ operation or attributes.
+.RS
+.RE
+.TP
+.B fi_cq_read / fi_cq_readfrom / fi_cq_readerr
+Read a completion from a completion queue
+.RS
+.RE
+.TP
+.B fi_cq_sread / fi_cq_sreadfrom
+A synchronous (blocking) read that waits until a specified condition has
+been met before reading a completion from a completion queue.
+.RS
+.RE
+.TP
+.B fi_cq_signal
+Unblock any thread waiting in fi_cq_sread or fi_cq_sreadfrom.
+.RS
+.RE
+.TP
+.B fi_cq_strerror
+Converts provider specific error information into a printable string
+.RS
+.RE
 .SH SYNOPSIS
 .IP
 .nf
@@ -53,43 +70,85 @@ const\ char\ *\ fi_cq_strerror(struct\ fid_cq\ *cq,\ int\ prov_errno,
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]domain\f[] : Open resource domain
-.PP
-\f[I]cq\f[] : Completion queue
-.PP
-\f[I]attr\f[] : Completion queue attributes
-.PP
-\f[I]context\f[] : User specified context associated with the completion
-queue.
-.PP
-\f[I]buf\f[] : For read calls, the data buffer to write completions
-into.
+.TP
+.B \f[I]domain\f[]
+Open resource domain
+.RS
+.RE
+.TP
+.B \f[I]cq\f[]
+Completion queue
+.RS
+.RE
+.TP
+.B \f[I]attr\f[]
+Completion queue attributes
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified context associated with the completion queue.
+.RS
+.RE
+.TP
+.B \f[I]buf\f[]
+For read calls, the data buffer to write completions into.
 For write calls, a completion to insert into the completion queue.
 For fi_cq_strerror, an optional buffer that receives printable error
 information.
-.PP
-\f[I]count\f[] : Number of CQ entries.
-.PP
-\f[I]len\f[] : Length of data buffer
-.PP
-\f[I]src_addr\f[] : Source address of a completed receive operation
-.PP
-\f[I]flags\f[] : Additional flags to apply to the operation
-.PP
-\f[I]command\f[] : Command of control operation to perform on CQ.
-.PP
-\f[I]arg\f[] : Optional control argument
-.PP
-\f[I]cond\f[] : Condition that must be met before a completion is
-generated
-.PP
-\f[I]timeout\f[] : Time in milliseconds to wait.
+.RS
+.RE
+.TP
+.B \f[I]count\f[]
+Number of CQ entries.
+.RS
+.RE
+.TP
+.B \f[I]len\f[]
+Length of data buffer
+.RS
+.RE
+.TP
+.B \f[I]src_addr\f[]
+Source address of a completed receive operation
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply to the operation
+.RS
+.RE
+.TP
+.B \f[I]command\f[]
+Command of control operation to perform on CQ.
+.RS
+.RE
+.TP
+.B \f[I]arg\f[]
+Optional control argument
+.RS
+.RE
+.TP
+.B \f[I]cond\f[]
+Condition that must be met before a completion is generated
+.RS
+.RE
+.TP
+.B \f[I]timeout\f[]
+Time in milliseconds to wait.
 A negative value indicates infinite timeout.
-.PP
-\f[I]prov_errno\f[] : Provider specific error value
-.PP
-\f[I]err_data\f[] : Provider specific error data related to a completion
+.RS
+.RE
+.TP
+.B \f[I]prov_errno\f[]
+Provider specific error value
+.RS
+.RE
+.TP
+.B \f[I]err_data\f[]
+Provider specific error data related to a completion
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Completion queues are used to report events associated with data
@@ -121,17 +180,26 @@ struct\ fi_cq_attr\ {
 };
 \f[]
 .fi
-.PP
-\f[I]size\f[] : Specifies the minimum size of a completion queue.
+.TP
+.B \f[I]size\f[]
+Specifies the minimum size of a completion queue.
 A value of 0 indicates that the provider may choose a default value.
-.PP
-\f[I]flags\f[] : Flags that control the configuration of the CQ.
-.IP \[bu] 2
-\f[I]FI_AFFINITY\f[] : Indicates that the signaling_vector field (see
-below) is valid.
-.PP
-\f[I]format\f[] : Completion queues allow the application to select the
-amount of detail that it must store and report.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Flags that control the configuration of the CQ.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_AFFINITY\f[]
+Indicates that the signaling_vector field (see below) is valid.
+.RS
+.RE
+.TP
+.B \f[I]format\f[]
+Completion queues allow the application to select the amount of detail
+that it must store and report.
 The format attribute allows the application to select one of several
 completion formats, indicating the structure of the data that the
 completion queue should return when read.
@@ -139,12 +207,20 @@ Supported formats and the structures that correspond to each are listed
 below.
 The meaning of the CQ entry fields are defined in the \f[I]Completion
 Fields\f[] section.
-.IP \[bu] 2
-\f[I]FI_CQ_FORMAT_UNSPEC\f[] : If an unspecified format is requested,
-then the CQ will use a provider selected default format.
-.IP \[bu] 2
-\f[I]FI_CQ_FORMAT_CONTEXT\f[] : Provides only user specified context
-that was associated with the completion.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_CQ_FORMAT_UNSPEC\f[]
+If an unspecified format is requested, then the CQ will use a provider
+selected default format.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_CQ_FORMAT_CONTEXT\f[]
+Provides only user specified context that was associated with the
+completion.
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -153,10 +229,14 @@ struct\ fi_cq_entry\ {
 };
 \f[]
 .fi
-.IP \[bu] 2
-\f[I]FI_CQ_FORMAT_MSG\f[] : Provides minimal data for processing
-completions, with expanded support for reporting information about
-received messages.
+\[bu] .RS 2
+.TP
+.B \f[I]FI_CQ_FORMAT_MSG\f[]
+Provides minimal data for processing completions, with expanded support
+for reporting information about received messages.
+.RS
+.RE
+.RE
 .IP
 .nf
 \f[C]
@@ -167,10 +247,15 @@ struct\ fi_cq_msg_entry\ {
 };
 \f[]
 .fi
-.IP \[bu] 2
-\f[I]FI_CQ_FORMAT_DATA\f[] : Provides data associated with a completion.
+\[bu] .RS 2
+.TP
+.B \f[I]FI_CQ_FORMAT_DATA\f[]
+Provides data associated with a completion.
 Includes support for received message length, remote CQ data, and
 multi\-receive buffers.
+.RS
+.RE
+.RE
 .IP
 .nf
 \f[C]
@@ -183,9 +268,14 @@ struct\ fi_cq_data_entry\ {
 };
 \f[]
 .fi
-.IP \[bu] 2
-\f[I]FI_CQ_FORMAT_TAGGED\f[] : Expands completion data to include
-support for the tagged message interfaces.
+\[bu] .RS 2
+.TP
+.B \f[I]FI_CQ_FORMAT_TAGGED\f[]
+Expands completion data to include support for the tagged message
+interfaces.
+.RS
+.RE
+.RE
 .IP
 .nf
 \f[C]
@@ -199,9 +289,9 @@ struct\ fi_cq_tagged_entry\ {
 };
 \f[]
 .fi
-.PP
-\f[I]wait_obj\f[] : CQ\[aq]s may be associated with a specific wait
-object.
+.TP
+.B \f[I]wait_obj\f[]
+CQ\[aq]s may be associated with a specific wait object.
 Wait objects allow applications to block until the wait object is
 signaled, indicating that a completion is available to be read.
 Users may use fi_control to retrieve the underlying wait object
@@ -210,52 +300,77 @@ The following values may be used to specify the type of wait object
 associated with a CQ: FI_WAIT_NONE, FI_WAIT_UNSPEC, FI_WAIT_SET,
 FI_WAIT_FD, and FI_WAIT_MUTEX_COND.
 The default is FI_WAIT_NONE.
-.IP \[bu] 2
-\f[I]FI_WAIT_NONE\f[] : Used to indicate that the user will not block
-(wait) for completions on the CQ.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_NONE\f[]
+Used to indicate that the user will not block (wait) for completions on
+the CQ.
 When FI_WAIT_NONE is specified, the application may not call fi_cq_sread
 or fi_cq_sreadfrom.
-.IP \[bu] 2
-\f[I]FI_WAIT_UNSPEC\f[] : Specifies that the user will only wait on the
-CQ using fabric interface calls, such as fi_cq_sread or fi_cq_sreadfrom.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_UNSPEC\f[]
+Specifies that the user will only wait on the CQ using fabric interface
+calls, such as fi_cq_sread or fi_cq_sreadfrom.
 In this case, the underlying provider may select the most appropriate or
 highest performing wait object available, including custom wait
 mechanisms.
 Applications that select FI_WAIT_UNSPEC are not guaranteed to retrieve
 the underlying wait object.
-.IP \[bu] 2
-\f[I]FI_WAIT_SET\f[] : Indicates that the completion queue should use a
-wait set object to wait for completions.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_SET\f[]
+Indicates that the completion queue should use a wait set object to wait
+for completions.
 If specified, the wait_set field must reference an existing wait set
 object.
-.IP \[bu] 2
-\f[I]FI_WAIT_FD\f[] : Indicates that the CQ should use a file descriptor
-as its wait mechanism.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_FD\f[]
+Indicates that the CQ should use a file descriptor as its wait
+mechanism.
 A file descriptor wait object must be usable in select, poll, and epoll
 routines.
 However, a provider may signal an FD wait object by marking it as
 readable, writable, or with an error.
-.IP \[bu] 2
-\f[I]FI_WAIT_MUTEX_COND\f[] : Specifies that the CQ should use a pthread
-mutex and cond variable as a wait object.
-.IP \[bu] 2
-\f[I]FI_WAIT_CRITSEC_COND\f[] : Windows specific.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_MUTEX_COND\f[]
+Specifies that the CQ should use a pthread mutex and cond variable as a
+wait object.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_CRITSEC_COND\f[]
+Windows specific.
 Specifies that the CQ should use a critical section and condition
 variable as a wait object.
-.PP
-\f[I]signaling_vector\f[] : If the FI_AFFINITY flag is set, this
-indicates the logical cpu number (0..max cpu \- 1) that interrupts
-associated with the CQ should target.
+.RS
+.RE
+.TP
+.B \f[I]signaling_vector\f[]
+If the FI_AFFINITY flag is set, this indicates the logical cpu number
+(0..max cpu \- 1) that interrupts associated with the CQ should target.
 This field should be treated as a hint to the provider and may be
 ignored if the provider does not support interrupt affinity.
-.PP
-\f[I]wait_cond\f[] : By default, when a completion is inserted into a CQ
-that supports blocking reads (fi_cq_sread/fi_cq_sreadfrom), the
-corresponding wait object is signaled.
+.RS
+.RE
+.TP
+.B \f[I]wait_cond\f[]
+By default, when a completion is inserted into a CQ that supports
+blocking reads (fi_cq_sread/fi_cq_sreadfrom), the corresponding wait
+object is signaled.
 Users may specify a condition that must first be met before the wait is
 satisfied.
 This field indicates how the provider should interpret the cond field,
 which describes the condition needed to signal the wait object.
+.RS
+.RE
 .PP
 A wait condition should be treated as an optimization.
 Providers are not required to meet the requirements of the condition
@@ -272,14 +387,17 @@ The threshold indicates the number of entries that are to be queued
 before at the CQ before the wait is satisfied.
 .PP
 This field is ignored if wait_obj is set to FI_WAIT_NONE.
-.PP
-\f[I]wait_set\f[] : If wait_obj is FI_WAIT_SET, this field references a
-wait object to which the completion queue should attach.
+.TP
+.B \f[I]wait_set\f[]
+If wait_obj is FI_WAIT_SET, this field references a wait object to which
+the completion queue should attach.
 When an event is inserted into the completion queue, the corresponding
 wait set will be signaled if all necessary conditions are met.
 The use of a wait_set enables an optimized method of waiting for events
 across multiple event and completion queues.
 This field is ignored if wait_obj is not FI_WAIT_SET.
+.RS
+.RE
 .SS fi_close
 .PP
 The fi_close call releases all resources associated with a completion
@@ -297,14 +415,17 @@ specific details of the completion queue.
 Access to the CQ should be serialized across all calls when fi_control
 is invoked, as it may redirect the implementation of CQ operations.
 The following control commands are usable with a CQ.
-.PP
-\f[I]FI_GETWAIT (void **)\f[] : This command allows the user to retrieve
-the low\-level wait object associated with the CQ.
+.TP
+.B \f[I]FI_GETWAIT (void **)\f[]
+This command allows the user to retrieve the low\-level wait object
+associated with the CQ.
 The format of the wait\-object is specified during CQ creation, through
 the CQ attributes.
 The fi_control arg parameter should be an address where a pointer to the
 returned wait object will be written.
 See fi_eq.3 for addition details using fi_control with FI_GETWAIT.
+.RS
+.RE
 .SS fi_cq_read
 .PP
 The fi_cq_read operation performs a non\-blocking read of completion
@@ -343,26 +464,29 @@ parameter.
 Returned source addressing data is converted from the native address
 used by the underlying fabric into an fi_addr_t, which may be used in
 transmit operations.
-Typically, returning fi_addr_t requires that the source address be
-inserted into the address vector associated with the receiving endpoint.
+Under most circumstances, returning fi_addr_t requires that the source
+address already have been inserted into the address vector associated
+with the receiving endpoint.
+This is true for address vectors of type FI_AV_TABLE.
+In select providers when FI_AV_MAP is used, source addresses may be
+converted algorithmically into a usable fi_addr_t, even though the
+source address has not been inserted into the address vector.
+This is permitted by the API, as it allows the provider to avoid address
+look\-up as part of receive message processing.
+In no case do providers insert addresses into an AV separate from an
+application calling fi_av_insert or similar call.
+.PP
 For endpoints allocated using the FI_SOURCE_ERR capability, if the
-source address has not been inserted into the address vector,
-fi_cq_readfrom will return \-FI_EAVAIL.
+source address cannot be converted into a valid fi_addr_t value,
+fi_cq_readfrom will return \-FI_EAVAIL, even if the data were received
+successfully.
 The completion will then be reported through fi_cq_readerr with error
 code \-FI_EADDRNOTAVAIL.
 See fi_cq_readerr for details.
 .PP
 If FI_SOURCE is specified without FI_SOURCE_ERR, source addresses which
-cannot be mapped to a local fi_addr_t will be reported as
+cannot be mapped to a usable fi_addr_t will be reported as
 FI_ADDR_NOTAVAIL.
-The behavior is dependent on the type of address vector in use.
-For AVs of type FI_AV_MAP, source addresses may be mapped directly to an
-fi_addr_t value, even if the source address were not inserted into the
-AV.
-This allows the provider to optimize the reporting of the source
-fi_addr_t without the overhead of verifying whether the address is in
-the AV.
-If full address validation is necessary, FI_SOURCE_ERR must be used.
 .SS fi_cq_sread / fi_cq_sreadfrom
 .PP
 The fi_cq_sread and fi_cq_sreadfrom calls are the blocking equivalent
@@ -410,11 +534,22 @@ information into a printable string for debugging purposes.
 See field details below for more information on the use of err_data and
 err_data_size.
 .PP
-Notable completion error codes are given below.
+Note that error completions are generated for all operations, including
+those for which a completion was not requested (e.g.
+an endpoint is configured with FI_SELECTIVE_COMPLETION, but the request
+did not have the FI_COMPLETION flag set).
+In such cases, providers will return as much information as made
+available by the underlying software and hardware about the failure,
+other fields will be set to NULL or 0.
+This includes the op_context value, which may not have been provided or
+was ignored on input as part of the transfer.
 .PP
-\f[I]FI_EADDRNOTAVAIL\f[] : This error code is used by CQs configured
-with FI_SOURCE_ERR to report completions for which a matching fi_addr_t
-source address could not be found.
+Notable completion error codes are given below.
+.TP
+.B \f[I]FI_EADDRNOTAVAIL\f[]
+This error code is used by CQs configured with FI_SOURCE_ERR to report
+completions for which a usable fi_addr_t source address could not be
+found.
 An error code of FI_EADDRNOTAVAIL indicates that the data transfer was
 successfully received and processed, with the fi_cq_err_entry fields
 containing information about the completion.
@@ -423,6 +558,8 @@ The source address will be in the same format as specified through the
 fi_info addr_format field for the opened domain.
 This may be passed directly into an fi_av_insert call to add the source
 address to the address vector.
+.RS
+.RE
 .SS fi_cq_signal
 .PP
 The fi_cq_signal call will unblock any thread waiting in fi_cq_sread or
@@ -436,81 +573,109 @@ with a wait object.
 The CQ entry data structures share many of the same fields.
 The meanings of these fields are the same for all CQ entry structure
 formats.
-.PP
-\f[I]op_context\f[] : The operation context is the application specified
-context value that was provided with an asynchronous operation.
+.TP
+.B \f[I]op_context\f[]
+The operation context is the application specified context value that
+was provided with an asynchronous operation.
 The op_context field is valid for all completions that are associated
 with an asynchronous operation.
+.RS
+.RE
 .PP
 For completion events that are not associated with a posted operation,
 this field will be set to NULL.
 This includes completions generated at the target in response to RMA
 write operations that carry CQ data (FI_REMOTE_WRITE | FI_REMOTE_CQ_DATA
 flags set), when the FI_RX_CQ_DATA mode bit is not required.
-.PP
-\f[I]flags\f[] : This specifies flags associated with the completed
-operation.
+.TP
+.B \f[I]flags\f[]
+This specifies flags associated with the completed operation.
 The \f[I]Completion Flags\f[] section below lists valid flag values.
 Flags are set for all relevant completions.
-.PP
-\f[I]len\f[] : This len field only applies to completed receive
-operations (e.g.
+.RS
+.RE
+.TP
+.B \f[I]len\f[]
+This len field only applies to completed receive operations (e.g.
 fi_recv, fi_trecv, etc.).
 It indicates the size of received \f[I]message\f[] data \-\- i.e.
 how many data bytes were placed into the associated receive buffer by a
 corresponding fi_send/fi_tsend/et al call.
 If an endpoint has been configured with the FI_MSG_PREFIX mode, the len
 also reflects the size of the prefix buffer.
-.PP
-\f[I]buf\f[] : The buf field is only valid for completed receive
-operations, and only applies when the receive buffer was posted with the
-FI_MULTI_RECV flag.
+.RS
+.RE
+.TP
+.B \f[I]buf\f[]
+The buf field is only valid for completed receive operations, and only
+applies when the receive buffer was posted with the FI_MULTI_RECV flag.
 In this case, buf points to the starting location where the receive data
 was placed.
-.PP
-\f[I]data\f[] : The data field is only valid if the FI_REMOTE_CQ_DATA
-completion flag is set, and only applies to receive completions.
+.RS
+.RE
+.TP
+.B \f[I]data\f[]
+The data field is only valid if the FI_REMOTE_CQ_DATA completion flag is
+set, and only applies to receive completions.
 If FI_REMOTE_CQ_DATA is set, this field will contain the completion data
 provided by the peer as part of their transmit request.
 The completion data will be given in host byte order.
-.PP
-\f[I]tag\f[] : A tag applies only to received messages that occur using
-the tagged interfaces.
+.RS
+.RE
+.TP
+.B \f[I]tag\f[]
+A tag applies only to received messages that occur using the tagged
+interfaces.
 This field contains the tag that was included with the received message.
 The tag will be in host byte order.
-.PP
-\f[I]olen\f[] : The olen field applies to received messages.
+.RS
+.RE
+.TP
+.B \f[I]olen\f[]
+The olen field applies to received messages.
 It is used to indicate that a received message has overrun the available
 buffer space and has been truncated.
 The olen specifies the amount of data that did not fit into the
 available receive buffer and was discarded.
-.PP
-\f[I]err\f[] : This err code is a positive fabric errno associated with
-a completion.
+.RS
+.RE
+.TP
+.B \f[I]err\f[]
+This err code is a positive fabric errno associated with a completion.
 The err value indicates the general reason for an error, if one
 occurred.
 See fi_errno.3 for a list of possible error codes.
-.PP
-\f[I]prov_errno\f[] : On an error, prov_errno may contain a provider
-specific error code.
+.RS
+.RE
+.TP
+.B \f[I]prov_errno\f[]
+On an error, prov_errno may contain a provider specific error code.
 The use of this field and its meaning is provider specific.
 It is intended to be used as a debugging aid.
 See fi_cq_strerror for additional details on converting this error value
 into a human readable string.
-.PP
-\f[I]err_data\f[] : On an error, err_data may reference a provider
-specific amount of data associated with an error.
+.RS
+.RE
+.TP
+.B \f[I]err_data\f[]
+On an error, err_data may reference a provider specific amount of data
+associated with an error.
 The use of this field and its meaning is provider specific.
 It is intended to be used as a debugging aid.
 See fi_cq_strerror for additional details on converting this error data
 into a human readable string.
-.PP
-\f[I]err_data_size\f[] : On input, err_data_size indicates the size of
-the err_data buffer in bytes.
+.RS
+.RE
+.TP
+.B \f[I]err_data_size\f[]
+On input, err_data_size indicates the size of the err_data buffer in
+bytes.
 On output, err_data_size will be set to the number of bytes copied to
 the err_data buffer.
 The err_data information is typically used with fi_cq_strerror to
 provide details about the type of error that occurred.
+.RS
+.RE
 .PP
 For compatibility purposes, if err_data_size is 0 on input, or the
 fabric was opened with release < 1.5, err_data will be set to a data
@@ -524,62 +689,98 @@ ensure that the buffer referenced by err_data does not change.
 Completion flags provide additional details regarding the completed
 operation.
 The following completion flags are defined.
-.PP
-\f[I]FI_SEND\f[] : Indicates that the completion was for a send
-operation.
+.TP
+.B \f[I]FI_SEND\f[]
+Indicates that the completion was for a send operation.
 This flag may be combined with an FI_MSG or FI_TAGGED flag.
-.PP
-\f[I]FI_RECV\f[] : Indicates that the completion was for a receive
-operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_RECV\f[]
+Indicates that the completion was for a receive operation.
 This flag may be combined with an FI_MSG or FI_TAGGED flag.
-.PP
-\f[I]FI_RMA\f[] : Indicates that an RMA operation completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_RMA\f[]
+Indicates that an RMA operation completed.
 This flag may be combined with an FI_READ, FI_WRITE, FI_REMOTE_READ, or
 FI_REMOTE_WRITE flag.
-.PP
-\f[I]FI_ATOMIC\f[] : Indicates that an atomic operation completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_ATOMIC\f[]
+Indicates that an atomic operation completed.
 This flag may be combined with an FI_READ, FI_WRITE, FI_REMOTE_READ, or
 FI_REMOTE_WRITE flag.
-.PP
-\f[I]FI_MSG\f[] : Indicates that a message\-based operation completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_MSG\f[]
+Indicates that a message\-based operation completed.
 This flag may be combined with an FI_SEND or FI_RECV flag.
-.PP
-\f[I]FI_TAGGED\f[] : Indicates that a tagged message operation
-completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_TAGGED\f[]
+Indicates that a tagged message operation completed.
 This flag may be combined with an FI_SEND or FI_RECV flag.
-.PP
-\f[I]FI_MULTICAST\f[] : Indicates that a multicast operation completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_MULTICAST\f[]
+Indicates that a multicast operation completed.
 This flag may be combined with FI_MSG and relevant flags.
 This flag is only guaranteed to be valid for received messages if the
 endpoint has been configured with FI_SOURCE.
-.PP
-\f[I]FI_READ\f[] : Indicates that a locally initiated RMA or atomic read
-operation has completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_READ\f[]
+Indicates that a locally initiated RMA or atomic read operation has
+completed.
 This flag may be combined with an FI_RMA or FI_ATOMIC flag.
-.PP
-\f[I]FI_WRITE\f[] : Indicates that a locally initiated RMA or atomic
-write operation has completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_WRITE\f[]
+Indicates that a locally initiated RMA or atomic write operation has
+completed.
 This flag may be combined with an FI_RMA or FI_ATOMIC flag.
-.PP
-\f[I]FI_REMOTE_READ\f[] : Indicates that a remotely initiated RMA or
-atomic read operation has completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_READ\f[]
+Indicates that a remotely initiated RMA or atomic read operation has
+completed.
 This flag may be combined with an FI_RMA or FI_ATOMIC flag.
-.PP
-\f[I]FI_REMOTE_WRITE\f[] : Indicates that a remotely initiated RMA or
-atomic write operation has completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_WRITE\f[]
+Indicates that a remotely initiated RMA or atomic write operation has
+completed.
 This flag may be combined with an FI_RMA or FI_ATOMIC flag.
-.PP
-\f[I]FI_REMOTE_CQ_DATA\f[] : This indicates that remote CQ data is
-available as part of the completion.
-.PP
-\f[I]FI_MULTI_RECV\f[] : This flag applies to receive buffers that were
-posted with the FI_MULTI_RECV flag set.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_CQ_DATA\f[]
+This indicates that remote CQ data is available as part of the
+completion.
+.RS
+.RE
+.TP
+.B \f[I]FI_MULTI_RECV\f[]
+This flag applies to receive buffers that were posted with the
+FI_MULTI_RECV flag set.
 This completion flag indicates that the original receive buffer
 referenced by the completion has been consumed and was released by the
 provider.
 Providers may set this flag on the last message that is received into
 the multi\- recv buffer, or may generate a separate completion that
 indicates that the buffer has been released.
+.RS
+.RE
 .PP
 Applications can distinguish between these two cases by examining the
 completion entry flags field.
@@ -592,6 +793,165 @@ received message.
 If other flag bits are zero, the provider is reporting that the
 multi\-recv buffer has been released, and the completion entry is not
 associated with a received message.
+.TP
+.B \f[I]FI_MORE\f[]
+See the \[aq]Buffered Receives\[aq] section in \f[C]fi_msg\f[](3) for
+more details.
+This flag is associated with receive completions on endpoints that have
+FI_BUFFERED_RECV mode enabled.
+When set to one, it indicates that the buffer referenced by the
+completion is limited by the FI_OPT_BUFFERED_LIMIT threshold, and
+additional message data must be retrieved by the application using an
+FI_CLAIM operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_CLAIM\f[]
+See the \[aq]Buffered Receives\[aq] section in \f[C]fi_msg\f[](3) for
+more details.
+This flag is set on completions associated with receive operations that
+claim buffered receive data.
+Note that this flag only applies to endpoints configured with the
+FI_BUFFERED_RECV mode bit.
+.RS
+.RE
+.SH COMPLETION EVENT SEMANTICS
+.PP
+Libfabric defines several completion \[aq]levels\[aq], identified using
+operational flags.
+Each flag indicates the soonest that a completion event may be generated
+by a provider, and the assumptions that an application may make upon
+processing a completion.
+The operational flags are defined below, along with an example of how a
+provider might implement the semantic.
+Note that only meeting the semantic is required of the provider and not
+the implementation.
+Providers may implement stronger completion semantics than necessary for
+a given operation, but only the behavior defined by the completion level
+is guaranteed.
+.PP
+To help understand the conceptual differences in completion levels,
+consider mailing a letter.
+Placing the letter into the local mailbox for pick\-up is similar to
+\[aq]inject complete\[aq].
+Having the letter picked up and dropped off at the destination mailbox
+is equivalent to \[aq]transmit complete\[aq].
+The \[aq]delivery complete\[aq] semantic is a stronger guarantee, with a
+person at the destination signing for the letter.
+However, the person who signed for the letter is not necessarily the
+intended recipient.
+The \[aq]match complete\[aq] option is similar to delivery complete, but
+requires the intended recipient to sign for the letter.
+.PP
+The \[aq]commit complete\[aq] level has different semantics than the
+previously mentioned levels.
+Commit complete would be closer to the the letter arriving at the
+destination and being placed into a fire proof safe.
+.PP
+The operational flags for the described completion levels are defined
+below.
+.TP
+.B \f[I]FI_INJECT_COMPLETE\f[]
+Indicates that a completion should be generated when the source
+buffer(s) may be reused.
+A completion guarantees that the buffers will not be read from again and
+the application may reclaim them.
+No other guarantees are made with respect to the state of the operation.
+.RS
+.RE
+.PP
+Example: A provider may generate this completion event after copying the
+source buffer into a network buffer, either in host memory or on the
+NIC.
+An inject completion does not indicate that the data has been
+transmitted onto the network, and a local error could occur after the
+completion event has been generated that could prevent it from being
+transmitted.
+.PP
+Inject complete allows for the fastest completion reporting (and, hence,
+buffer reuse), but provides the weakest guarantees against network
+errors.
+.PP
+Note: This flag is used to control when a completion entry is inserted
+into a completion queue.
+It does not apply to operations that do not generate a completion queue
+entry, such as the fi_inject operation, and is not subject to the
+inject_size message limit restriction.
+.TP
+.B \f[I]FI_TRANSMIT_COMPLETE\f[]
+Indicates that a completion should be generated when the transmit
+operation has completed relative to the local provider.
+The exact behavior is dependent on the endpoint type.
+.RS
+.RE
+.PP
+For reliable endpoints:
+.PP
+Indicates that a completion should be generated when the operation has
+been delivered to the peer endpoint.
+A completion guarantees that the operation is no longer dependent on the
+fabric or local resources.
+The state of the operation at the peer endpoint is not defined.
+.PP
+Example: A provider may generate a transmit complete event upon
+receiving an ack from the peer endpoint.
+The state of the message at the peer is unknown and may be buffered in
+the target NIC at the time the ack has been generated.
+.PP
+For unreliable endpoints:
+.PP
+Indicates that a completion should be generated when the operation has
+been delivered to the fabric.
+A completion guarantees that the operation is no longer dependent on
+local resources.
+The state of the operation within the fabric is not defined.
+.TP
+.B \f[I]FI_DELIVERY_COMPLETE\f[]
+Indicates that a completion should not be generated until an operation
+has been processed by the destination endpoint(s).
+A completion guarantees that the result of the operation is available;
+however, additional steps may need to be taken at the destination to
+retrieve the results.
+For example, an application may need to provide a receive buffers in
+order to retrieve messages that were buffered by the provider.
+.RS
+.RE
+.PP
+Delivery complete indicates that the message has been processed by the
+peer.
+If an application buffer was ready to receive the results of the message
+when it arrived, then delivery complete indicates that the data was
+placed into the application\[aq]s buffer.
+.PP
+This completion mode applies only to reliable endpoints.
+For operations that return data to the initiator, such as RMA read or
+atomic\-fetch, the source endpoint is also considered a destination
+endpoint.
+This is the default completion mode for such operations.
+.TP
+.B \f[I]FI_MATCH_COMPLETE\f[]
+Indicates that a completion should be generated only after the operation
+has been matched with an application specified buffer.
+Operations using this completion semantic are dependent on the
+application at the target claiming the message or results.
+As a result, match complete may involve additional provider level
+acknowledgements or lengthy delays.
+However, this completion model enables peer applications to synchronize
+their execution.
+.RS
+.RE
+.TP
+.B \f[I]FI_COMMIT_COMPLETE\f[]
+Indicates that a completion should not be generated (locally or at the
+peer) until the result of an operation have been made persistent.
+A completion guarantees that the result is both available and durable,
+in the case of power failure.
+.RS
+.RE
+.PP
+This completion mode applies only to operations that target persistent
+memory regions over reliable endpoints.
+This completion mode is experimental.
 .SH NOTES
 .PP
 A completion queue must be bound to at least one enabled endpoint before
@@ -615,9 +975,12 @@ CQ will result in it returning an FI_EOVERRUN error event.
 Overrun completion queues are considered fatal and may not be used to
 report additional completions once the overrun occurs.
 .SH RETURN VALUES
-.PP
-fi_cq_open / fi_cq_signal : Returns 0 on success.
+.TP
+.B fi_cq_open / fi_cq_signal
+Returns 0 on success.
 On error, a negative value corresponding to fabric errno is returned.
+.RS
+.RE
 .PP
 fi_cq_read / fi_cq_readfrom / fi_cq_readerr fi_cq_sread /
 fi_cq_sreadfrom : On success, returns the number of completion events
@@ -625,9 +988,12 @@ retrieved from the completion queue.
 On error, a negative value corresponding to fabric errno is returned.
 If no completions are available to return from the CQ, \-FI_EAGAIN will
 be returned.
-.PP
-fi_cq_strerror : Returns a character string interpretation of the
-provider specific error returned with a completion.
+.TP
+.B fi_cq_strerror
+Returns a character string interpretation of the provider specific error
+returned with a completion.
+.RS
+.RE
 .PP
 Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
 .SH SEE ALSO
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_domain.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_domain.3
index 9aaae9b7b..a358698f8 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_domain.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_domain.3
@@ -1,5 +1,8 @@
 .\"t
-.TH "fi_domain" "3" "2018\-02\-13" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_domain" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_domain \- Open a fabric access domain
@@ -24,24 +27,43 @@ int\ fi_open_ops(struct\ fid\ *domain,\ const\ char\ *name,\ uint64_t\ flags,
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]fabric\f[] : Fabric domain
-.PP
-\f[I]info\f[] : Fabric information, including domain capabilities and
-attributes.
-.PP
-\f[I]domain\f[] : An opened access domain.
-.PP
-\f[I]context\f[] : User specified context associated with the domain.
+.TP
+.B \f[I]fabric\f[]
+Fabric domain
+.RS
+.RE
+.TP
+.B \f[I]info\f[]
+Fabric information, including domain capabilities and attributes.
+.RS
+.RE
+.TP
+.B \f[I]domain\f[]
+An opened access domain.
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified context associated with the domain.
 This context is returned as part of any asynchronous event associated
 with the domain.
-.PP
-\f[I]eq\f[] : Event queue for asynchronous operations initiated on the
-domain.
-.PP
-\f[I]name\f[] : Name associated with an interface.
-.PP
-\f[I]ops\f[] : Fabric interface operations.
+.RS
+.RE
+.TP
+.B \f[I]eq\f[]
+Event queue for asynchronous operations initiated on the domain.
+.RS
+.RE
+.TP
+.B \f[I]name\f[]
+Name associated with an interface.
+.RS
+.RE
+.TP
+.B \f[I]ops\f[]
+Fabric interface operations.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 An access domain typically refers to a physical or virtual NIC or
@@ -145,25 +167,33 @@ accessed by multiple threads.
 Applications which can guarantee serialization in their access of
 provider allocated resources and interfaces enables a provider to
 eliminate lower\-level locks.
-.PP
-\f[I]FI_THREAD_UNSPEC\f[] : This value indicates that no threading model
-has been defined.
+.TP
+.B \f[I]FI_THREAD_UNSPEC\f[]
+This value indicates that no threading model has been defined.
 It may be used on input hints to the fi_getinfo call.
 When specified, providers will return a threading model that allows for
 the greatest level of parallelism.
-.PP
-\f[I]FI_THREAD_SAFE\f[] : A thread safe serialization model allows a
-multi\-threaded application to access any allocated resources through
-any interface without restriction.
+.RS
+.RE
+.TP
+.B \f[I]FI_THREAD_SAFE\f[]
+A thread safe serialization model allows a multi\-threaded application
+to access any allocated resources through any interface without
+restriction.
 All providers are required to support FI_THREAD_SAFE.
-.PP
-\f[I]FI_THREAD_FID\f[] : A fabric descriptor (FID) serialization model
-requires applications to serialize access to individual fabric resources
-associated with data transfer operations and completions.
+.RS
+.RE
+.TP
+.B \f[I]FI_THREAD_FID\f[]
+A fabric descriptor (FID) serialization model requires applications to
+serialize access to individual fabric resources associated with data
+transfer operations and completions.
 Multiple threads must be serialized when accessing the same endpoint,
 transmit context, receive context, completion queue, counter, wait set,
 or poll set.
 Serialization is required only by threads accessing the same object.
+.RS
+.RE
 .PP
 For example, one thread may be initiating a data transfer on an
 endpoint, while another thread reads from a completion queue associated
@@ -181,21 +211,26 @@ needing internal locking when handling data transfers.
 Conceptually, FI_THREAD_FID maps well to providers that implement fabric
 services in hardware and provide separate command queues to different
 data flows.
-.PP
-\f[I]FI_THREAD_ENDPOINT\f[] : The endpoint threading model is similar to
-FI_THREAD_FID, but with the added restriction that serialization is
-required when accessing the same endpoint, even if multiple transmit and
-receive contexts are used.
+.TP
+.B \f[I]FI_THREAD_ENDPOINT\f[]
+The endpoint threading model is similar to FI_THREAD_FID, but with the
+added restriction that serialization is required when accessing the same
+endpoint, even if multiple transmit and receive contexts are used.
 Conceptually, FI_THREAD_ENDPOINT maps well to providers that implement
 fabric services in hardware but use a single command queue to access
 different data flows.
-.PP
-\f[I]FI_THREAD_COMPLETION\f[] : The completion threading model is
-intended for providers that make use of manual progress.
+.RS
+.RE
+.TP
+.B \f[I]FI_THREAD_COMPLETION\f[]
+The completion threading model is intended for providers that make use
+of manual progress.
 Applications must serialize access to all objects that are associated
 through the use of having a shared completion structure.
 This includes endpoint, transmit context, receive context, completion
 queue, counter, wait set, and poll set objects.
+.RS
+.RE
 .PP
 For example, threads must serialize access to an endpoint and its bound
 completion queue(s) and/or counters.
@@ -204,9 +239,12 @@ serialized.
 .PP
 The use of FI_THREAD_COMPLETION can increase parallelism over
 FI_THREAD_SAFE, but requires the use of isolated resources.
-.PP
-\f[I]FI_THREAD_DOMAIN\f[] : A domain serialization model requires
-applications to serialize access to all objects belonging to a domain.
+.TP
+.B \f[I]FI_THREAD_DOMAIN\f[]
+A domain serialization model requires applications to serialize access
+to all objects belonging to a domain.
+.RS
+.RE
 .SS Progress Models (control_progress / data_progress)
 .PP
 Progress is the ability of the underlying implementation to complete
@@ -238,33 +276,40 @@ and acknowledgement processing.
 .PP
 To balance between performance and ease of use, two progress models are
 defined.
-.PP
-\f[I]FI_PROGRESS_UNSPEC\f[] : This value indicates that no progress
-model has been defined.
+.TP
+.B \f[I]FI_PROGRESS_UNSPEC\f[]
+This value indicates that no progress model has been defined.
 It may be used on input hints to the fi_getinfo call.
-.PP
-\f[I]FI_PROGRESS_AUTO\f[] : This progress model indicates that the
-provider will make forward progress on an asynchronous operation without
-further intervention by the application.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROGRESS_AUTO\f[]
+This progress model indicates that the provider will make forward
+progress on an asynchronous operation without further intervention by
+the application.
 When FI_PROGRESS_AUTO is provided as output to fi_getinfo in the absence
 of any progress hints, it often indicates that the desired functionality
 is implemented by the provider hardware or is a standard service of the
 operating system.
+.RS
+.RE
 .PP
 All providers are required to support FI_PROGRESS_AUTO.
 However, if a provider does not natively support automatic progress,
 forcing the use of FI_PROGRESS_AUTO may result in threads being
 allocated below the fabric interfaces.
-.PP
-\f[I]FI_PROGRESS_MANUAL\f[] : This progress model indicates that the
-provider requires the use of an application thread to complete an
-asynchronous request.
+.TP
+.B \f[I]FI_PROGRESS_MANUAL\f[]
+This progress model indicates that the provider requires the use of an
+application thread to complete an asynchronous request.
 When manual progress is set, the provider will attempt to advance an
 asynchronous operation forward when the application attempts to wait on
 or read an event queue, completion queue, or counter where the completed
 operation will be reported.
 Progress also occurs when the application processes a poll or wait set
 that has been associated with the event or completion queue.
+.RS
+.RE
 .PP
 Only wait operations defined by the fabric interface will result in an
 operation progressing.
@@ -301,18 +346,24 @@ provider implementation and protocol may still provide some level of
 protection against overruns.
 However, such protection is not guaranteed.
 The following values for resource management are defined.
-.PP
-\f[I]FI_RM_UNSPEC\f[] : This value indicates that no resource management
-model has been defined.
+.TP
+.B \f[I]FI_RM_UNSPEC\f[]
+This value indicates that no resource management model has been defined.
 It may be used on input hints to the fi_getinfo call.
-.PP
-\f[I]FI_RM_DISABLED\f[] : The provider is free to select an
-implementation and protocol that does not protect against resource
-overruns.
+.RS
+.RE
+.TP
+.B \f[I]FI_RM_DISABLED\f[]
+The provider is free to select an implementation and protocol that does
+not protect against resource overruns.
 The application is responsible for resource protection.
-.PP
-\f[I]FI_RM_ENABLED\f[] : Resource management is enabled for this
-provider domain.
+.RS
+.RE
+.TP
+.B \f[I]FI_RM_ENABLED\f[]
+Resource management is enabled for this provider domain.
+.RS
+.RE
 .PP
 The behavior of the various resource management options depends on
 whether the endpoint is reliable or unreliable, as well as provider and
@@ -322,7 +373,7 @@ The table assumes that all peers enable or disable RM the same.
 .PP
 .TS
 tab(@);
-c c c c c.
+cw(8.0n) cw(16.0n) cw(16.0n) cw(15.3n) cw(14.6n).
 T{
 Resource
 T}@T{
@@ -438,17 +489,21 @@ T}
 .PP
 The resource column indicates the resource being accessed by a data
 transfer operation.
-.PP
-\f[I]Tx Ctx / Rx Ctx\f[] : Refers to the transmit/receive contexts when
-a data transfer operation is submitted.
+.TP
+.B \f[I]Tx Ctx / Rx Ctx\f[]
+Refers to the transmit/receive contexts when a data transfer operation
+is submitted.
 When RM is enabled, attempting to submit a request will fail if the
 context is full.
 If RM is disabled, an undefined error (provider specific) will occur.
 Such errors should be considered fatal to the context, and applications
 must take steps to avoid queue overruns.
-.PP
-\f[I]Tx CQ / Rx CQ\f[] : Refers to the completion queue associated with
-the Tx or Rx context when a local operation completes.
+.RS
+.RE
+.TP
+.B \f[I]Tx CQ / Rx CQ\f[]
+Refers to the completion queue associated with the Tx or Rx context when
+a local operation completes.
 When RM is disabled, applications must take care to ensure that
 completion queues do not get overrun.
 When an overrun occurs, an undefined, but fatal, error will occur
@@ -463,9 +518,12 @@ that could result in CQ overruns, or internally retrying requests (which
 will be hidden from the application).
 See notes at the end of this section regarding CQ resource management
 restrictions.
-.PP
-\f[I]Target EP / No Rx Buffer\f[] : Target EP refers to resources
-associated with the endpoint that is the target of a transmit operation.
+.RS
+.RE
+.TP
+.B \f[I]Target EP / No Rx Buffer\f[]
+Target EP refers to resources associated with the endpoint that is the
+target of a transmit operation.
 This includes the target endpoint\[aq]s receive queue, posted receive
 buffers (no Rx buffers), the receive side completion queue, and other
 related packet processing queues.
@@ -475,10 +533,12 @@ incoming messages, received messages will be dropped.
 For reliable endpoints, if RM is disabled, the transmit operation will
 complete in error.
 If RM is enabled, the provider will internally retry the operation.
-.PP
-\f[I]Rx Buffer Overrun\f[] : This refers to buffers posted to receive
-incoming tagged or untagged messages, with the behavior defined from the
-viewpoint of the sender.
+.RS
+.RE
+.TP
+.B \f[I]Rx Buffer Overrun\f[]
+This refers to buffers posted to receive incoming tagged or untagged
+messages, with the behavior defined from the viewpoint of the sender.
 The behavior for handling received messages that are larger than the
 buffers provided by the application is provider specific.
 Providers may either truncate the message and report a successful
@@ -492,13 +552,18 @@ application buffer is made available.
 The completion status may also be dependent upon the completion model
 selected byt the application (e.g.
 FI_DELIVERY_COMPLETE versus FI_TRANSMIT_COMPLETE).
-.PP
-\f[I]Unmatched RMA / RMA Overrun\f[] : Unmatched RMA and RMA overruns
-deal with the processing of RMA and atomic operations.
+.RS
+.RE
+.TP
+.B \f[I]Unmatched RMA / RMA Overrun\f[]
+Unmatched RMA and RMA overruns deal with the processing of RMA and
+atomic operations.
 Unlike send operations, RMA operations that attempt to access a memory
 address that is either not registered for such operations, or attempt to
 access outside of the target memory region will fail, resulting in a
 transmit error.
+.RS
+.RE
 .PP
 When a resource management error occurs on an endpoint, the endpoint is
 transitioned into a disabled state.
@@ -533,15 +598,21 @@ size as the endpoint queue(s) that are bound to it.
 Specifies the type of address vectors that are usable with this domain.
 For additional details on AV type, see \f[C]fi_av\f[](3).
 The following values may be specified.
-.PP
-\f[I]FI_AV_UNSPEC\f[] : Any address vector format is requested and
-supported.
-.PP
-\f[I]FI_AV_MAP\f[] : Only address vectors of type AV map are requested
-or supported.
-.PP
-\f[I]FI_AV_TABLE\f[] : Only address vectors of type AV index are
-requested or supported.
+.TP
+.B \f[I]FI_AV_UNSPEC\f[]
+Any address vector format is requested and supported.
+.RS
+.RE
+.TP
+.B \f[I]FI_AV_MAP\f[]
+Only address vectors of type AV map are requested or supported.
+.RS
+.RE
+.TP
+.B \f[I]FI_AV_TABLE\f[]
+Only address vectors of type AV index are requested or supported.
+.RS
+.RE
 .PP
 Address vectors are only used by connectionless endpoints.
 Applications that require the use of a specific type of address vector
@@ -557,60 +628,85 @@ optimal AV type supported by this domain.
 Defines memory registration specific mode bits used with this domain.
 Full details on MR mode options are available in \f[C]fi_mr\f[](3).
 The following values may be specified.
-.PP
-\f[I]FI_MR_LOCAL\f[] : The provider is optimized around having
-applications register memory for locally accessed data buffers.
+.TP
+.B \f[I]FI_MR_LOCAL\f[]
+The provider is optimized around having applications register memory for
+locally accessed data buffers.
 Data buffers used in send and receive operations and as the source
 buffer for RMA and atomic operations must be registered by the
 application for access domains opened with this capability.
-.PP
-\f[I]FI_MR_RAW\f[] : The provider requires additional setup as part of
-their memory registration process.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_RAW\f[]
+The provider requires additional setup as part of their memory
+registration process.
 This mode is required by providers that use a memory key that is larger
 than 64\-bits.
-.PP
-\f[I]FI_MR_VIRT_ADDR\f[] : Registered memory regions are referenced by
-peers using the virtual address of the registered memory region, rather
-than a 0\-based offset.
-.PP
-\f[I]FI_MR_ALLOCATED\f[] : Indicates that memory registration occurs on
-allocated data buffers, and physical pages must back all virtual
-addresses being registered.
-.PP
-\f[I]FI_MR_PROV_KEY\f[] : Memory registration keys are selected and
-returned by the provider.
-.PP
-\f[I]FI_MR_MMU_NOTIFY\f[] : Indicates that the application is
-responsible for notifying the provider when the page tables referencing
-a registered memory region may have been updated.
-.PP
-\f[I]FI_MR_RMA_EVENT\f[] : Indicates that the memory regions associated
-with completion counters must be explicitly enabled after being bound to
-any counter.
-.PP
-\f[I]FI_MR_ENDPOINT\f[] : Memory registration occurs at the endpoint
-level, rather than domain.
-.PP
-\f[I]FI_MR_UNSPEC\f[] : Defined for compatibility \-\- library versions
-1.4 and earlier.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_VIRT_ADDR\f[]
+Registered memory regions are referenced by peers using the virtual
+address of the registered memory region, rather than a 0\-based offset.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_ALLOCATED\f[]
+Indicates that memory registration occurs on allocated data buffers, and
+physical pages must back all virtual addresses being registered.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_PROV_KEY\f[]
+Memory registration keys are selected and returned by the provider.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_MMU_NOTIFY\f[]
+Indicates that the application is responsible for notifying the provider
+when the page tables referencing a registered memory region may have
+been updated.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_RMA_EVENT\f[]
+Indicates that the memory regions associated with completion counters
+must be explicitly enabled after being bound to any counter.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_ENDPOINT\f[]
+Memory registration occurs at the endpoint level, rather than domain.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_UNSPEC\f[]
+Defined for compatibility \-\- library versions 1.4 and earlier.
 Setting mr_mode to 0 indicates that FI_MR_BASIC or FI_MR_SCALABLE are
 requested and supported.
-.PP
-\f[I]FI_MR_BASIC\f[] : Defined for compatibility \-\- library versions
-1.4 and earlier.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_BASIC\f[]
+Defined for compatibility \-\- library versions 1.4 and earlier.
 Only basic memory registration operations are requested or supported.
 This mode is equivalent to the FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, and
 FI_MR_PROV_KEY flags being set in later library versions.
 This flag may not be used in conjunction with other mr_mode bits.
-.PP
-\f[I]FI_MR_SCALABLE\f[] : Defined for compatibility \-\- library
-versions 1.4 and earlier.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_SCALABLE\f[]
+Defined for compatibility \-\- library versions 1.4 and earlier.
 Only scalable memory registration operations are requested or supported.
 Scalable registration uses offset based addressing, with application
 selectable memory keys.
 For library versions 1.5 and later, this is the default if no mr_mode
 bits are set.
 This flag may not be used in conjunction with other mr_mode bits.
+.RS
+.RE
 .PP
 Buffers used in data transfer operations may require notifying the
 provider of their use before a data transfer can occur.
@@ -710,26 +806,33 @@ a single memory registration operation may reference.
 Domain level capabilities.
 Domain capabilities indicate domain level features that are supported by
 the provider.
-.PP
-\f[I]FI_LOCAL_COMM\f[] : At a conceptual level, this field indicates
-that the underlying device supports loopback communication.
+.TP
+.B \f[I]FI_LOCAL_COMM\f[]
+At a conceptual level, this field indicates that the underlying device
+supports loopback communication.
 More specifically, this field indicates that an endpoint may communicate
 with other endpoints that are allocated from the same underlying named
 domain.
 If this field is not set, an application may need to use an alternate
 domain or mechanism (e.g.
 shared memory) to communicate with peers that execute on the same node.
-.PP
-\f[I]FI_REMOTE_COMM\f[] : This field indicates that the underlying
-provider supports communication with nodes that are reachable over the
-network.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_COMM\f[]
+This field indicates that the underlying provider supports communication
+with nodes that are reachable over the network.
 If this field is not set, then the provider only supports communication
 between processes that execute on the same node \-\- a shared memory
 provider, for example.
-.PP
-\f[I]FI_SHARED_AV\f[] : Indicates that the domain supports the ability
-to share address vectors among multiple processes using the named
-address vector feature.
+.RS
+.RE
+.TP
+.B \f[I]FI_SHARED_AV\f[]
+Indicates that the domain supports the ability to share address vectors
+among multiple processes using the named address vector feature.
+.RS
+.RE
 .PP
 See \f[C]fi_getinfo\f[](3) for a discussion on primary versus secondary
 capabilities.
@@ -737,11 +840,13 @@ All domain capabilities are considered secondary capabilities.
 .SS mode
 .PP
 The operational mode bit related to using the domain.
-.PP
-\f[I]FI_RESTRICTED_COMP\f[] : This bit indicates that the domain limits
-completion queues and counters to only be used with endpoints, transmit
-contexts, and receive contexts that have the same set of capability
-flags.
+.TP
+.B \f[I]FI_RESTRICTED_COMP\f[]
+This bit indicates that the domain limits completion queues and counters
+to only be used with endpoints, transmit contexts, and receive contexts
+that have the same set of capability flags.
+.RS
+.RE
 .SS Default authorization key (auth_key)
 .PP
 The default authorization key to associate with endpoint and memory
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_endpoint.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_endpoint.3
index d11f7dc4e..53b3a2c57 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_endpoint.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_endpoint.3
@@ -1,4 +1,7 @@
-.TH "fi_endpoint" "3" "2018\-02\-13" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_endpoint" "3" "2018\-11\-30" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_endpoint \- Fabric endpoint operations
@@ -123,41 +126,85 @@ DEPRECATED\ ssize_t\ fi_tx_size_left(struct\ fid_ep\ *ep);
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]fid\f[] : On creation, specifies a fabric or access domain.
+.TP
+.B \f[I]fid\f[]
+On creation, specifies a fabric or access domain.
 On bind, identifies the event queue, completion queue, counter, or
 address vector to bind to the endpoint.
 In other cases, it\[aq]s a fabric identifier of an associated resource.
-.PP
-\f[I]info\f[] : Details about the fabric interface endpoint to be
-opened, obtained from fi_getinfo.
-.PP
-\f[I]ep\f[] : A fabric endpoint.
-.PP
-\f[I]sep\f[] : A scalable fabric endpoint.
-.PP
-\f[I]pep\f[] : A passive fabric endpoint.
-.PP
-\f[I]context\f[] : Context associated with the endpoint or asynchronous
-operation.
-.PP
-\f[I]index\f[] : Index to retrieve a specific transmit/receive context.
-.PP
-\f[I]attr\f[] : Transmit or receive context attributes.
-.PP
-\f[I]flags\f[] : Additional flags to apply to the operation.
-.PP
-\f[I]command\f[] : Command of control operation to perform on endpoint.
-.PP
-\f[I]arg\f[] : Optional control argument.
-.PP
-\f[I]level\f[] : Protocol level at which the desired option resides.
-.PP
-\f[I]optname\f[] : The protocol option to read or set.
-.PP
-\f[I]optval\f[] : The option value that was read or to set.
-.PP
-\f[I]optlen\f[] : The size of the optval buffer.
+.RS
+.RE
+.TP
+.B \f[I]info\f[]
+Details about the fabric interface endpoint to be opened, obtained from
+fi_getinfo.
+.RS
+.RE
+.TP
+.B \f[I]ep\f[]
+A fabric endpoint.
+.RS
+.RE
+.TP
+.B \f[I]sep\f[]
+A scalable fabric endpoint.
+.RS
+.RE
+.TP
+.B \f[I]pep\f[]
+A passive fabric endpoint.
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+Context associated with the endpoint or asynchronous operation.
+.RS
+.RE
+.TP
+.B \f[I]index\f[]
+Index to retrieve a specific transmit/receive context.
+.RS
+.RE
+.TP
+.B \f[I]attr\f[]
+Transmit or receive context attributes.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply to the operation.
+.RS
+.RE
+.TP
+.B \f[I]command\f[]
+Command of control operation to perform on endpoint.
+.RS
+.RE
+.TP
+.B \f[I]arg\f[]
+Optional control argument.
+.RS
+.RE
+.TP
+.B \f[I]level\f[]
+Protocol level at which the desired option resides.
+.RS
+.RE
+.TP
+.B \f[I]optname\f[]
+The protocol option to read or set.
+.RS
+.RE
+.TP
+.B \f[I]optval\f[]
+The option value that was read or to set.
+.RS
+.RE
+.TP
+.B \f[I]optlen\f[]
+The size of the optval buffer.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Endpoints are transport level communication portals.
@@ -287,27 +334,37 @@ based on the type of operation.
 This is specified using fi_ep_bind flags.
 The following flags may be used separately or OR\[aq]ed together when
 binding an endpoint to a completion domain CQ.
-.PP
-\f[I]FI_TRANSMIT\f[] : Directs the completion of outbound data transfer
-requests to the specified completion queue.
+.TP
+.B \f[I]FI_TRANSMIT\f[]
+Directs the completion of outbound data transfer requests to the
+specified completion queue.
 This includes send message, RMA, and atomic operations.
-.PP
-\f[I]FI_RECV\f[] : Directs the notification of inbound data transfers to
-the specified completion queue.
+.RS
+.RE
+.TP
+.B \f[I]FI_RECV\f[]
+Directs the notification of inbound data transfers to the specified
+completion queue.
 This includes received messages.
 This binding automatically includes FI_REMOTE_WRITE, if applicable to
 the endpoint.
-.PP
-\f[I]FI_SELECTIVE_COMPLETION\f[] : By default, data transfer operations
-generate completion entries into a completion queue after they have
-successfully completed.
+.RS
+.RE
+.TP
+.B \f[I]FI_SELECTIVE_COMPLETION\f[]
+By default, data transfer operations generate completion entries into a
+completion queue after they have successfully completed.
 Applications can use this bind flag to selectively enable when
 completions are generated.
 If FI_SELECTIVE_COMPLETION is specified, data transfer operations will
-not generate entries for successful completions unless FI_COMPLETION is
-set as an operational flag for the given operation.
+not generate entries for \f[I]successful\f[] completions unless
+FI_COMPLETION is set as an operational flag for the given operation.
+Operations that fail asynchronously will still generate completions,
+even if a completion is not requested.
 FI_SELECTIVE_COMPLETION must be OR\[aq]ed with FI_TRANSMIT and/or
 FI_RECV flags.
+.RS
+.RE
 .PP
 When FI_SELECTIVE_COMPLETION is set, the user must determine when a
 request that does NOT have FI_COMPLETION set has completed indirectly,
@@ -362,35 +419,52 @@ completions for all non\-fi_inject calls:
 An endpoint may also be bound to a fabric counter.
 When binding an endpoint to a counter, the following flags may be
 specified.
-.PP
-\f[I]FI_SEND\f[] : Increments the specified counter whenever a message
-transfer initiated over the endpoint has completed successfully or in
-error.
+.TP
+.B \f[I]FI_SEND\f[]
+Increments the specified counter whenever a message transfer initiated
+over the endpoint has completed successfully or in error.
 Sent messages include both tagged and normal message operations.
-.PP
-\f[I]FI_RECV\f[] : Increments the specified counter whenever a message
-is received over the endpoint.
+.RS
+.RE
+.TP
+.B \f[I]FI_RECV\f[]
+Increments the specified counter whenever a message is received over the
+endpoint.
 Received messages include both tagged and normal message operations.
-.PP
-\f[I]FI_READ\f[] : Increments the specified counter whenever an RMA read
-or atomic fetch operation initiated from the endpoint has completed
-successfully or in error.
-.PP
-\f[I]FI_WRITE\f[] : Increments the specified counter whenever an RMA
-write or atomic operation initiated from the endpoint has completed
+.RS
+.RE
+.TP
+.B \f[I]FI_READ\f[]
+Increments the specified counter whenever an RMA read, atomic fetch, or
+atomic compare operation initiated from the endpoint has completed
 successfully or in error.
-.PP
-\f[I]FI_REMOTE_READ\f[] : Increments the specified counter whenever an
-RMA read or atomic fetch operation is initiated from a remote endpoint
-that targets the given endpoint.
+.RS
+.RE
+.TP
+.B \f[I]FI_WRITE\f[]
+Increments the specified counter whenever an RMA write or base atomic
+operation initiated from the endpoint has completed successfully or in
+error.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_READ\f[]
+Increments the specified counter whenever an RMA read, atomic fetch, or
+atomic compare operation is initiated from a remote endpoint that
+targets the given endpoint.
 Use of this flag requires that the endpoint be created using
 FI_RMA_EVENT.
-.PP
-\f[I]FI_REMOTE_WRITE\f[] : Increments the specified counter whenever an
-RMA write or atomic operation is initiated from a remote endpoint that
-targets the given endpoint.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_WRITE\f[]
+Increments the specified counter whenever an RMA write or base atomic
+operation is initiated from a remote endpoint that targets the given
+endpoint.
 Use of this flag requires that the endpoint be created using
 FI_RMA_EVENT.
+.RS
+.RE
 .PP
 An endpoint may only be bound to a single CQ or counter for a given type
 of operation.
@@ -491,35 +565,45 @@ The base operation of an endpoint is selected during creation using
 struct fi_info.
 The following control commands and arguments may be assigned to an
 endpoint.
-.PP
-**FI_GETOPSFLAG \-\- uint64_t *flags** : Used to retrieve the current
-value of flags associated with the data transfer operations initiated on
-the endpoint.
+.TP
+.B **FI_GETOPSFLAG \-\- uint64_t *flags**
+Used to retrieve the current value of flags associated with the data
+transfer operations initiated on the endpoint.
 The control argument must include FI_TRANSMIT or FI_RECV (not both)
 flags to indicate the type of data transfer flags to be returned.
 See below for a list of control flags.
-.PP
-**FI_SETOPSFLAG \-\- uint64_t *flags** : Used to change the data
-transfer operation flags associated with an endpoint.
+.RS
+.RE
+.TP
+.B **FI_SETOPSFLAG \-\- uint64_t *flags**
+Used to change the data transfer operation flags associated with an
+endpoint.
 The control argument must include FI_TRANSMIT or FI_RECV (not both) to
 indicate the type of data transfer that the flags should apply to, with
 other flags OR\[aq]ed in.
 The given flags will override the previous transmit and receive
 attributes that were set when the endpoint was created.
 Valid control flags are defined below.
-.PP
-**FI_BACKLOG \- int *value** : This option only applies to passive
-endpoints.
+.RS
+.RE
+.TP
+.B **FI_BACKLOG \- int *value**
+This option only applies to passive endpoints.
 It is used to set the connection request backlog for listening
 endpoints.
-.PP
-\f[I]FI_GETWAIT (void **)\f[] : This command allows the user to retrieve
-the file descriptor associated with a socket endpoint.
+.RS
+.RE
+.TP
+.B \f[I]FI_GETWAIT (void **)\f[]
+This command allows the user to retrieve the file descriptor associated
+with a socket endpoint.
 The fi_control arg parameter should be an address where a pointer to the
 returned file descriptor will be written.
 See fi_eq.3 for addition details using fi_control with FI_GETWAIT.
 The file descriptor may be used for notification that the endpoint is
 ready to send or receive data.
+.RS
+.RE
 .SS fi_getopt / fi_setopt
 .PP
 Endpoint protocol operations may be retrieved using fi_getopt or set
@@ -532,18 +616,24 @@ and implementation specific details of an endpoint.
 The following option levels and option names and parameters are defined.
 .PP
 \f[I]FI_OPT_ENDPOINT\f[]
-.IP \[bu] 2
-\f[I]FI_OPT_MIN_MULTI_RECV \- size_t\f[] : Defines the minimum receive
-buffer space available when the receive buffer is released by the
-provider (see FI_MULTI_RECV).
+\[bu] .RS 2
+.TP
+.B \f[I]FI_OPT_MIN_MULTI_RECV \- size_t\f[]
+Defines the minimum receive buffer space available when the receive
+buffer is released by the provider (see FI_MULTI_RECV).
 Modifying this value is only guaranteed to set the minimum buffer space
 needed on receives posted after the value has been changed.
 It is recommended that applications that want to override the default
 MIN_MULTI_RECV value set this option before enabling the corresponding
 endpoint.
-.IP \[bu] 2
-\f[I]FI_OPT_CM_DATA_SIZE \- size_t\f[] : Defines the size of available
-space in CM messages for user\-defined data.
+.RS
+.RE
+.RE
+\[bu] .RS 2
+.TP
+.B \f[I]FI_OPT_CM_DATA_SIZE \- size_t\f[]
+Defines the size of available space in CM messages for user\-defined
+data.
 This value limits the amount of data that applications can exchange
 between peer endpoints using the fi_connect, fi_accept, and fi_reject
 operations.
@@ -552,6 +642,47 @@ except in the case of passive endpoints, in which the size reflects the
 maximum size of the data that may be present as part of a connection
 request event.
 This option is read only.
+.RS
+.RE
+.RE
+\[bu] .RS 2
+.TP
+.B \f[I]FI_OPT_BUFFERED_LIMIT \- size_t\f[]
+Defines the maximum size of a buffered message that will be reported to
+users as part of a receive completion when the FI_BUFFERED_RECV mode is
+enabled on an endpoint.
+.RS
+.RE
+.RE
+.PP
+fi_getopt() will return the currently configured threshold, or the
+provider\[aq]s default threshold if one has not be set by the
+application.
+fi_setopt() allows an application to configure the threshold.
+If the provider cannot support the requested threshold, it will fail the
+fi_setopt() call with FI_EMSGSIZE.
+Calling fi_setopt() with the threshold set to SIZE_MAX will set the
+threshold to the maximum supported by the provider.
+fi_getopt() can then be used to retrieve the set size.
+.PP
+In most cases, the sending and receiving endpoints must be configured to
+use the same threshold value, and the threshold must be set prior to
+enabling the endpoint.
+\[bu] .RS 2
+.TP
+.B \f[I]FI_OPT_BUFFERED_MIN \- size_t\f[]
+Defines the minimum size of a buffered message that will be reported.
+Applications would set this to a size that\[aq]s big enough to decide
+whether to discard or claim a buffered receive or when to claim a
+buffered receive on getting a buffered receive completion.
+The value is typically used by a provider when sending a rendezvous
+protocol request where it would send atleast FI_OPT_BUFFERED_MIN bytes
+of application data along with it.
+A smaller sized renedezvous protocol message usually results in better
+latency for the overall transfer of a large message.
+.RS
+.RE
+.RE
 .SS fi_rx_size_left (DEPRECATED)
 .PP
 This function has been deprecated and will be removed in a future
@@ -609,39 +740,55 @@ struct\ fi_ep_attr\ {
 If specified, indicates the type of fabric interface communication
 desired.
 Supported types are:
-.PP
-\f[I]FI_EP_UNSPEC\f[] : The type of endpoint is not specified.
+.TP
+.B \f[I]FI_EP_UNSPEC\f[]
+The type of endpoint is not specified.
 This is usually provided as input, with other attributes of the endpoint
 or the provider selecting the type.
-.PP
-\f[I]FI_EP_MSG\f[] : Provides a reliable, connection\-oriented data
-transfer service with flow control that maintains message boundaries.
-.PP
-\f[I]FI_EP_DGRAM\f[] : Supports a connectionless, unreliable datagram
-communication.
+.RS
+.RE
+.TP
+.B \f[I]FI_EP_MSG\f[]
+Provides a reliable, connection\-oriented data transfer service with
+flow control that maintains message boundaries.
+.RS
+.RE
+.TP
+.B \f[I]FI_EP_DGRAM\f[]
+Supports a connectionless, unreliable datagram communication.
 Message boundaries are maintained, but the maximum message size may be
 limited to the fabric MTU.
 Flow control is not guaranteed.
-.PP
-\f[I]FI_EP_RDM\f[] : Reliable datagram message.
+.RS
+.RE
+.TP
+.B \f[I]FI_EP_RDM\f[]
+Reliable datagram message.
 Provides a reliable, unconnected data transfer service with flow control
 that maintains message boundaries.
-.PP
-\f[I]FI_EP_SOCK_STREAM\f[] : Data streaming endpoint with TCP
-socket\-like semantics.
+.RS
+.RE
+.TP
+.B \f[I]FI_EP_SOCK_STREAM\f[]
+Data streaming endpoint with TCP socket\-like semantics.
 Provides a reliable, connection\-oriented data transfer service that
 does not maintain message boundaries.
 FI_EP_SOCK_STREAM is most useful for applications designed around using
 TCP sockets.
 See the SOCKET ENDPOINT section for additional details and restrictions
 that apply to stream endpoints.
-.PP
-\f[I]FI_EP_SOCK_DGRAM\f[] : A connectionless, unreliable datagram
-endpoint with UDP socket\-like semantics.
+.RS
+.RE
+.TP
+.B \f[I]FI_EP_SOCK_DGRAM\f[]
+A connectionless, unreliable datagram endpoint with UDP socket\-like
+semantics.
 FI_EP_SOCK_DGRAM is most useful for applications designed around using
 UDP sockets.
 See the SOCKET ENDPOINT section for additional details and restrictions
 that apply to datagram socket endpoints.
+.RS
+.RE
 .SS Protocol
 .PP
 Specifies the low\-level end to end protocol employed by the provider.
@@ -651,61 +798,96 @@ The following protocol values are defined.
 Provider specific protocols are also allowed.
 Provider specific protocols will be indicated by having the upper bit of
 the protocol value set to one.
-.PP
-\f[I]FI_PROTO_UNSPEC\f[] : The protocol is not specified.
+.TP
+.B \f[I]FI_PROTO_UNSPEC\f[]
+The protocol is not specified.
 This is usually provided as input, with other attributes of the socket
 or the provider selecting the actual protocol.
-.PP
-\f[I]FI_PROTO_RDMA_CM_IB_RC\f[] : The protocol runs over Infiniband
-reliable\-connected queue pairs, using the RDMA CM protocol for
-connection establishment.
-.PP
-\f[I]FI_PROTO_IWARP\f[] : The protocol runs over the Internet wide area
-RDMA protocol transport.
-.PP
-\f[I]FI_PROTO_IB_UD\f[] : The protocol runs over Infiniband unreliable
-datagram queue pairs.
-.PP
-\f[I]FI_PROTO_PSMX\f[] : The protocol is based on an Intel proprietary
-protocol known as PSM, performance scaled messaging.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_RDMA_CM_IB_RC\f[]
+The protocol runs over Infiniband reliable\-connected queue pairs, using
+the RDMA CM protocol for connection establishment.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_IWARP\f[]
+The protocol runs over the Internet wide area RDMA protocol transport.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_IB_UD\f[]
+The protocol runs over Infiniband unreliable datagram queue pairs.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_PSMX\f[]
+The protocol is based on an Intel proprietary protocol known as PSM,
+performance scaled messaging.
 PSMX is an extended version of the PSM protocol to support the libfabric
 interfaces.
-.PP
-\f[I]FI_PROTO_UDP\f[] : The protocol sends and receives UDP datagrams.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_UDP\f[]
+The protocol sends and receives UDP datagrams.
 For example, an endpoint using \f[I]FI_PROTO_UDP\f[] will be able to
 communicate with a remote peer that is using Berkeley
 \f[I]SOCK_DGRAM\f[] sockets using \f[I]IPPROTO_UDP\f[].
-.PP
-\f[I]FI_PROTO_SOCK_TCP\f[] : The protocol is layered over TCP packets.
-.PP
-\f[I]FI_PROTO_IWARP_RDM\f[] : Reliable\-datagram protocol implemented
-over iWarp reliable\-connected queue pairs.
-.PP
-\f[I]FI_PROTO_IB_RDM\f[] : Reliable\-datagram protocol implemented over
-InfiniBand reliable\-connected queue pairs.
-.PP
-\f[I]FI_PROTO_GNI\f[] : Protocol runs over Cray GNI low\-level
-interface.
-.PP
-\f[I]FI_PROTO_RXM\f[] : Reliable\-datagram protocol implemented over
-message endpoints.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_SOCK_TCP\f[]
+The protocol is layered over TCP packets.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_IWARP_RDM\f[]
+Reliable\-datagram protocol implemented over iWarp reliable\-connected
+queue pairs.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_IB_RDM\f[]
+Reliable\-datagram protocol implemented over InfiniBand
+reliable\-connected queue pairs.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_GNI\f[]
+Protocol runs over Cray GNI low\-level interface.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_RXM\f[]
+Reliable\-datagram protocol implemented over message endpoints.
 RXM is a libfabric utility component that adds RDM endpoint semantics
 over MSG endpoint semantics.
-.PP
-\f[I]FI_PROTO_RXD\f[] : Reliable\-datagram protocol implemented over
-datagram endpoints.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_RXD\f[]
+Reliable\-datagram protocol implemented over datagram endpoints.
 RXD is a libfabric utility component that adds RDM endpoint semantics
 over DGRAM endpoint semantics.
-.PP
-\f[I]FI_PROTO_NETWORKDIRECT\f[] : Protocol runs over Microsoft
-NetworkDirect service provider interface.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_NETWORKDIRECT\f[]
+Protocol runs over Microsoft NetworkDirect service provider interface.
 This adds reliable\-datagram semantics over the NetworkDirect
 connection\- oriented endpoint semantics.
-.PP
-\f[I]FI_PROTO_PSMX2\f[] : The protocol is based on an Intel proprietary
-protocol known as PSM2, performance scaled messaging version 2.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROTO_PSMX2\f[]
+The protocol is based on an Intel proprietary protocol known as PSM2,
+performance scaled messaging version 2.
 PSMX2 is an extended version of the PSM2 protocol to support the
 libfabric interfaces.
+.RS
+.RE
 .SS protocol_version \- Protocol Version
 .PP
 Identifies which version of the protocol is employed by the provider.
@@ -755,28 +937,37 @@ Providers specify when data ordering is maintained through the following
 values.
 Note that even if data ordering is not maintained, message ordering may
 be.
-.PP
-\f[I]max_order_raw_size\f[] : Read after write size.
+.TP
+.B \f[I]max_order_raw_size\f[]
+Read after write size.
 If set, an RMA or atomic read operation issued after an RMA or atomic
 write operation, both of which are smaller than the size, will be
 ordered.
 Where the target memory locations overlap, the RMA or atomic read
 operation will see the results of the previous RMA or atomic write.
-.PP
-\f[I]max_order_war_size\f[] : Write after read size.
+.RS
+.RE
+.TP
+.B \f[I]max_order_war_size\f[]
+Write after read size.
 If set, an RMA or atomic write operation issued after an RMA or atomic
 read operation, both of which are smaller than the size, will be
 ordered.
 The RMA or atomic read operation will see the initial value of the
 target memory location before a subsequent RMA or atomic write updates
 the value.
-.PP
-\f[I]max_order_waw_size\f[] : Write after write size.
+.RS
+.RE
+.TP
+.B \f[I]max_order_waw_size\f[]
+Write after write size.
 If set, an RMA or atomic write operation issued after an RMA or atomic
 write operation, both of which are smaller than the size, will be
 ordered.
 The target memory location will reflect the results of the second RMA or
 atomic write.
+.RS
+.RE
 .PP
 An order size value of 0 indicates that ordering is not guaranteed.
 A value of \-1 guarantees ordering for any data size.
@@ -801,6 +992,8 @@ The first field consists of 2\-bits, the second field 4\-bits, and the
 final field 8\-bits.
 Valid masks for such a tagged field would be a bitwise OR\[aq]ing of
 zero or more of the following values: 0x3000, 0x0F00, and 0x00FF.
+The provider may not validate the mask provided by the application for
+performance reasons.
 .PP
 By identifying fields within a tag, a provider may be able to optimize
 their search routines.
@@ -812,9 +1005,9 @@ A provider must return a tag format that supports the requested number
 of fields, with each field being at least the size requested, or fail
 the request.
 A provider may increase the size of the fields.
-When reporting completions (see FI_CQ_FORMAT_TAGGED), the provider must
-provide the exact value of the received tag, clearing out any
-unsupported tag bits.
+When reporting completions (see FI_CQ_FORMAT_TAGGED), it is not
+guaranteed that the provider would clear out any unsupported tag bits in
+the tag field of the completion entry.
 .PP
 It is recommended that field sizes be ordered from smallest to largest.
 A generic, unstructured tag and mask can be achieved by requesting a bit
@@ -943,63 +1136,93 @@ which message data is sent or received by the transport layer.
 Message ordering requires matching ordering semantics on the receiving
 side of a data transfer operation in order to guarantee that ordering is
 met.
-.PP
-\f[I]FI_ORDER_NONE\f[] : No ordering is specified.
+.TP
+.B \f[I]FI_ORDER_NONE\f[]
+No ordering is specified.
 This value may be used as input in order to obtain the default message
 order supported by the provider.
 FI_ORDER_NONE is an alias for the value 0.
-.PP
-\f[I]FI_ORDER_RAR\f[] : Read after read.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_RAR\f[]
+Read after read.
 If set, RMA and atomic read operations are transmitted in the order
 submitted relative to other RMA and atomic read operations.
 If not set, RMA and atomic reads may be transmitted out of order from
 their submission.
-.PP
-\f[I]FI_ORDER_RAW\f[] : Read after write.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_RAW\f[]
+Read after write.
 If set, RMA and atomic read operations are transmitted in the order
 submitted relative to RMA and atomic write operations.
 If not set, RMA and atomic reads may be transmitted ahead of RMA and
 atomic writes.
-.PP
-\f[I]FI_ORDER_RAS\f[] : Read after send.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_RAS\f[]
+Read after send.
 If set, RMA and atomic read operations are transmitted in the order
 submitted relative to message send operations, including tagged sends.
 If not set, RMA and atomic reads may be transmitted ahead of sends.
-.PP
-\f[I]FI_ORDER_WAR\f[] : Write after read.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_WAR\f[]
+Write after read.
 If set, RMA and atomic write operations are transmitted in the order
 submitted relative to RMA and atomic read operations.
 If not set, RMA and atomic writes may be transmitted ahead of RMA and
 atomic reads.
-.PP
-\f[I]FI_ORDER_WAW\f[] : Write after write.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_WAW\f[]
+Write after write.
 If set, RMA and atomic write operations are transmitted in the order
 submitted relative to other RMA and atomic write operations.
 If not set, RMA and atomic writes may be transmitted out of order from
 their submission.
-.PP
-\f[I]FI_ORDER_WAS\f[] : Write after send.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_WAS\f[]
+Write after send.
 If set, RMA and atomic write operations are transmitted in the order
 submitted relative to message send operations, including tagged sends.
 If not set, RMA and atomic writes may be transmitted ahead of sends.
-.PP
-\f[I]FI_ORDER_SAR\f[] : Send after read.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_SAR\f[]
+Send after read.
 If set, message send operations, including tagged sends, are transmitted
 in order submitted relative to RMA and atomic read operations.
 If not set, message sends may be transmitted ahead of RMA and atomic
 reads.
-.PP
-\f[I]FI_ORDER_SAW\f[] : Send after write.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_SAW\f[]
+Send after write.
 If set, message send operations, including tagged sends, are transmitted
 in order submitted relative to RMA and atomic write operations.
 If not set, message sends may be transmitted ahead of RMA and atomic
 writes.
-.PP
-\f[I]FI_ORDER_SAS\f[] : Send after send.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_SAS\f[]
+Send after send.
 If set, message send operations, including tagged sends, are transmitted
 in the order submitted relative to other message send.
 If not set, message sends may be transmitted out of order from their
 submission.
+.RS
+.RE
 .SS comp_order \- Completion Ordering
 .PP
 Completion ordering refers to the order in which completed requests are
@@ -1028,13 +1251,18 @@ Providers should return the completion order that they actually provide,
 with the constraint that the returned ordering is stricter than that
 specified by the application.
 Supported completion order values are:
-.PP
-\f[I]FI_ORDER_NONE\f[] : No ordering is defined for completed
-operations.
+.TP
+.B \f[I]FI_ORDER_NONE\f[]
+No ordering is defined for completed operations.
 Requests submitted to the transmit context may complete in any order.
-.PP
-\f[I]FI_ORDER_STRICT\f[] : Requests complete in the order in which they
-are submitted to the transmit context.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_STRICT\f[]
+Requests complete in the order in which they are submitted to the
+transmit context.
+.RS
+.RE
 .SS inject_size
 .PP
 The requested inject operation size (see the FI_INJECT flag) that the
@@ -1120,20 +1348,27 @@ FI_ORDER_WAS, FI_ORDER_SAR, FI_ORDER_SAW, and FI_ORDER_SAS.
 .PP
 For a description of completion ordering, see the comp_order field in
 the \f[I]Transmit Context Attribute\f[] section.
-.PP
-\f[I]FI_ORDER_NONE\f[] : No ordering is defined for completed
-operations.
+.TP
+.B \f[I]FI_ORDER_NONE\f[]
+No ordering is defined for completed operations.
 Receive operations may complete in any order, regardless of their
 submission order.
-.PP
-\f[I]FI_ORDER_STRICT\f[] : Receive operations complete in the order in
-which they are processed by the receive context, based on the receive
-side msg_order attribute.
-.PP
-\f[I]FI_ORDER_DATA\f[] : When set, this bit indicates that received data
-is written into memory in order.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_STRICT\f[]
+Receive operations complete in the order in which they are processed by
+the receive context, based on the receive side msg_order attribute.
+.RS
+.RE
+.TP
+.B \f[I]FI_ORDER_DATA\f[]
+When set, this bit indicates that received data is written into memory
+in order.
 Data ordering applies to memory accessed as part of a single operation
 and between operations if message ordering is guaranteed.
+.RS
+.RE
 .SS total_buffered_recv
 .PP
 This field is supported for backwards compatibility purposes.
@@ -1355,17 +1590,21 @@ Operation flags define the default flags applied to an endpoint\[aq]s
 data transfer operations, where a flags parameter is not available.
 Data transfer operations that take flags as input override the op_flags
 value of transmit or receive context attributes of an endpoint.
-.PP
-\f[I]FI_INJECT\f[] : Indicates that all outbound data buffers should be
-returned to the user\[aq]s control immediately after a data transfer
-call returns, even if the operation is handled asynchronously.
+.TP
+.B \f[I]FI_INJECT\f[]
+Indicates that all outbound data buffers should be returned to the
+user\[aq]s control immediately after a data transfer call returns, even
+if the operation is handled asynchronously.
 This may require that the provider copy the data into a local buffer and
 transfer out of that buffer.
 A provider can limit the total amount of send data that may be buffered
 and/or the size of a single send that can use this flag.
 This limit is indicated using inject_size (see inject_size above).
-.PP
-\f[I]FI_MULTI_RECV\f[] : Applies to posted receive operations.
+.RS
+.RE
+.TP
+.B \f[I]FI_MULTI_RECV\f[]
+Applies to posted receive operations.
 This flag allows the user to post a single buffer that will receive
 multiple incoming messages.
 Received messages will be packed into the receive buffer until the
@@ -1376,71 +1615,53 @@ The placement of received data into the buffer may be subjected to
 provider specific alignment restrictions.
 The buffer will be released by the provider when the available buffer
 space falls below the specified minimum (see FI_OPT_MIN_MULTI_RECV).
-.PP
-\f[I]FI_COMPLETION\f[] : Indicates that a completion entry should be
-generated for data transfer operations.
+.RS
+.RE
+.TP
+.B \f[I]FI_COMPLETION\f[]
+Indicates that a completion entry should be generated for data transfer
+operations.
 This flag only applies to operations issued on endpoints that were bound
 to a CQ or counter with the FI_SELECTIVE_COMPLETION flag.
 See the fi_ep_bind section above for more detail.
-.PP
-\f[I]FI_INJECT_COMPLETE\f[] : Indicates that a completion should be
-generated when the source buffer(s) may be reused.
-A completion guarantees that the buffers will not be read from again and
-the application may reclaim them.
-No other guarantees are made with respect to the state of the operation.
-.PP
-Note: This flag is used to control when a completion entry is inserted
-into a completion queue.
-It does not apply to operations that do not generate a completion queue
-entry, such as the fi_inject operation, and is not subject to the
-inject_size message limit restriction.
-.PP
-\f[I]FI_TRANSMIT_COMPLETE\f[] : Indicates that a completion should be
-generated when the transmit operation has completed relative to the
-local provider.
-The exact behavior is dependent on the endpoint type.
-.PP
-For reliable endpoints:
-.PP
-Indicates that a completion should be generated when the operation has
-been delivered to the peer endpoint.
-A completion guarantees that the operation is no longer dependent on the
-fabric or local resources.
-The state of the operation at the peer endpoint is not defined.
-.PP
-For unreliable endpoints:
-.PP
+.RS
+.RE
+.TP
+.B \f[I]FI_INJECT_COMPLETE\f[]
+Indicates that a completion should be generated when the source
+buffer(s) may be reused.
+See \f[C]fi_cq\f[](3) for additional details on completion semantics.
+.RS
+.RE
+.TP
+.B \f[I]FI_TRANSMIT_COMPLETE\f[]
+Indicates that a completion should be generated when the transmit
+operation has completed relative to the local provider.
+See \f[C]fi_cq\f[](3) for additional details on completion semantics.
+.RS
+.RE
+.TP
+.B \f[I]FI_DELIVERY_COMPLETE\f[]
 Indicates that a completion should be generated when the operation has
-been delivered to the fabric.
-A completion guarantees that the operation is no longer dependent on
-local resources.
-The state of the operation within the fabric is not defined.
-.PP
-\f[I]FI_DELIVERY_COMPLETE\f[] : Indicates that a completion should not
-be generated until an operation has been processed by the destination
-endpoint(s).
-A completion guarantees that the result of the operation is available.
-.PP
-This completion mode applies only to reliable endpoints.
-For operations that return data to the initiator, such as RMA read or
-atomic\-fetch, the source endpoint is also considered a destination
-endpoint.
-This is the default completion mode for such operations.
-.PP
-\f[I]FI_COMMIT_COMPLETE\f[] : Indicates that a completion should not be
-generated (locally or at the peer) until the result of an operation have
-been made persistent.
-A completion guarantees that the result is both available and durable,
-in the case of power failure.
-.PP
-This completion mode applies only to operations that target persistent
-memory regions over reliable endpoints.
-This completion mode is experimental.
-.PP
-\f[I]FI_MULTICAST\f[] : Indicates that data transfers will target
-multicast addresses by default.
+been processed by the destination endpoint(s).
+See \f[C]fi_cq\f[](3) for additional details on completion semantics.
+.RS
+.RE
+.TP
+.B \f[I]FI_COMMIT_COMPLETE\f[]
+Indicates that a completion should not be generated (locally or at the
+peer) until the result of an operation have been made persistent.
+See \f[C]fi_cq\f[](3) for additional details on completion semantics.
+.RS
+.RE
+.TP
+.B \f[I]FI_MULTICAST\f[]
+Indicates that data transfers will target multicast addresses by
+default.
 Any fi_addr_t passed into a data transfer operation will be treated as a
 multicast address.
+.RS
+.RE
 .SH NOTES
 .PP
 Users should call fi_close to release all resources allocated to the
@@ -1492,18 +1713,25 @@ submitted for processing.
 .PP
 Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
 .SH ERRORS
-.PP
-\f[I]\-FI_EDOMAIN\f[] : A resource domain was not bound to the endpoint
-or an attempt was made to bind multiple domains.
-.PP
-\f[I]\-FI_ENOCQ\f[] : The endpoint has not been configured with
-necessary event queue.
-.PP
-\f[I]\-FI_EOPBADSTATE\f[] : The endpoint\[aq]s state does not permit the
-requested operation.
+.TP
+.B \f[I]\-FI_EDOMAIN\f[]
+A resource domain was not bound to the endpoint or an attempt was made
+to bind multiple domains.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_ENOCQ\f[]
+The endpoint has not been configured with necessary event queue.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_EOPBADSTATE\f[]
+The endpoint\[aq]s state does not permit the requested operation.
+.RS
+.RE
 .SH SEE ALSO
 .PP
-\f[C]fi_getinfo\f[](3), \f[C]fi_domain\f[](3), \f[C]fi_msg\f[](3),
-\f[C]fi_tagged\f[](3), \f[C]fi_rma\f[](3)
+\f[C]fi_getinfo\f[](3), \f[C]fi_domain\f[](3), \f[C]fi_cq\f[](3)
+\f[C]fi_msg\f[](3), \f[C]fi_tagged\f[](3), \f[C]fi_rma\f[](3)
 .SH AUTHORS
 OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_eq.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_eq.3
index 9ee313602..ae9a1a0ce 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_eq.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_eq.3
@@ -1,20 +1,40 @@
-.TH "fi_eq" "3" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_eq" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_eq \- Event queue operations
-.PP
-fi_eq_open / fi_close : Open/close an event queue
-.PP
-fi_control : Control operation of EQ
-.PP
-fi_eq_read / fi_eq_readerr : Read an event from an event queue
-.PP
-fi_eq_write : Writes an event to an event queue
-.PP
-fi_eq_sread : A synchronous (blocking) read of an event queue
-.PP
-fi_eq_strerror : Converts provider specific error information into a
-printable string
+.TP
+.B fi_eq_open / fi_close
+Open/close an event queue
+.RS
+.RE
+.TP
+.B fi_control
+Control operation of EQ
+.RS
+.RE
+.TP
+.B fi_eq_read / fi_eq_readerr
+Read an event from an event queue
+.RS
+.RE
+.TP
+.B fi_eq_write
+Writes an event to an event queue
+.RS
+.RE
+.TP
+.B fi_eq_sread
+A synchronous (blocking) read of an event queue
+.RS
+.RE
+.TP
+.B fi_eq_strerror
+Converts provider specific error information into a printable string
+.RS
+.RE
 .SH SYNOPSIS
 .IP
 .nf
@@ -45,36 +65,74 @@ const\ char\ *\ fi_eq_strerror(struct\ fid_eq\ *eq,\ int\ prov_errno,
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]fabric\f[] : Opened fabric descriptor
-.PP
-\f[I]eq\f[] : Event queue
-.PP
-\f[I]attr\f[] : Event queue attributes
-.PP
-\f[I]context\f[] : User specified context associated with the event
-queue.
-.PP
-\f[I]event\f[] : Reported event
-.PP
-\f[I]buf\f[] : For read calls, the data buffer to write events into.
+.TP
+.B \f[I]fabric\f[]
+Opened fabric descriptor
+.RS
+.RE
+.TP
+.B \f[I]eq\f[]
+Event queue
+.RS
+.RE
+.TP
+.B \f[I]attr\f[]
+Event queue attributes
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified context associated with the event queue.
+.RS
+.RE
+.TP
+.B \f[I]event\f[]
+Reported event
+.RS
+.RE
+.TP
+.B \f[I]buf\f[]
+For read calls, the data buffer to write events into.
 For write calls, an event to insert into the event queue.
 For fi_eq_strerror, an optional buffer that receives printable error
 information.
-.PP
-\f[I]len\f[] : Length of data buffer
-.PP
-\f[I]flags\f[] : Additional flags to apply to the operation
-.PP
-\f[I]command\f[] : Command of control operation to perform on EQ.
-.PP
-\f[I]arg\f[] : Optional control argument
-.PP
-\f[I]prov_errno\f[] : Provider specific error value
-.PP
-\f[I]err_data\f[] : Provider specific error data related to a completion
-.PP
-\f[I]timeout\f[] : Timeout specified in milliseconds
+.RS
+.RE
+.TP
+.B \f[I]len\f[]
+Length of data buffer
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply to the operation
+.RS
+.RE
+.TP
+.B \f[I]command\f[]
+Command of control operation to perform on EQ.
+.RS
+.RE
+.TP
+.B \f[I]arg\f[]
+Optional control argument
+.RS
+.RE
+.TP
+.B \f[I]prov_errno\f[]
+Provider specific error value
+.RS
+.RE
+.TP
+.B \f[I]err_data\f[]
+Provider specific error data related to a completion
+.RS
+.RE
+.TP
+.B \f[I]timeout\f[]
+Timeout specified in milliseconds
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Event queues are used to report events associated with control
@@ -102,76 +160,112 @@ struct\ fi_eq_attr\ {
 };
 \f[]
 .fi
-.PP
-\f[I]size\f[] : Specifies the minimum size of an event queue.
-.PP
-\f[I]flags\f[] : Flags that control the configuration of the EQ.
-.IP \[bu] 2
-\f[I]FI_WRITE\f[] : Indicates that the application requires support for
-inserting user events into the EQ.
+.TP
+.B \f[I]size\f[]
+Specifies the minimum size of an event queue.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Flags that control the configuration of the EQ.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WRITE\f[]
+Indicates that the application requires support for inserting user
+events into the EQ.
 If this flag is set, then the fi_eq_write operation must be supported by
 the provider.
 If the FI_WRITE flag is not set, then the application may not invoke
 fi_eq_write.
-.IP \[bu] 2
-\f[I]FI_AFFINITY\f[] : Indicates that the signaling_vector field (see
-below) is valid.
-.PP
-\f[I]wait_obj\f[] : EQ\[aq]s may be associated with a specific wait
-object.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_AFFINITY\f[]
+Indicates that the signaling_vector field (see below) is valid.
+.RS
+.RE
+.TP
+.B \f[I]wait_obj\f[]
+EQ\[aq]s may be associated with a specific wait object.
 Wait objects allow applications to block until the wait object is
 signaled, indicating that an event is available to be read.
 Users may use fi_control to retrieve the underlying wait object
 associated with an EQ, in order to use it in other system calls.
 The following values may be used to specify the type of wait object
 associated with an EQ:
-.IP \[bu] 2
-\f[I]FI_WAIT_NONE\f[] : Used to indicate that the user will not block
-(wait) for events on the EQ.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_NONE\f[]
+Used to indicate that the user will not block (wait) for events on the
+EQ.
 When FI_WAIT_NONE is specified, the application may not call
 fi_eq_sread.
 This is the default is no wait object is specified.
-.IP \[bu] 2
-\f[I]FI_WAIT_UNSPEC\f[] : Specifies that the user will only wait on the
-EQ using fabric interface calls, such as fi_eq_sread.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_UNSPEC\f[]
+Specifies that the user will only wait on the EQ using fabric interface
+calls, such as fi_eq_sread.
 In this case, the underlying provider may select the most appropriate or
 highest performing wait object available, including custom wait
 mechanisms.
 Applications that select FI_WAIT_UNSPEC are not guaranteed to retrieve
 the underlying wait object.
-.IP \[bu] 2
-\f[I]FI_WAIT_SET\f[] : Indicates that the event queue should use a wait
-set object to wait for events.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_SET\f[]
+Indicates that the event queue should use a wait set object to wait for
+events.
 If specified, the wait_set field must reference an existing wait set
 object.
-.IP \[bu] 2
-\f[I]FI_WAIT_FD\f[] : Indicates that the EQ should use a file descriptor
-as its wait mechanism.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_FD\f[]
+Indicates that the EQ should use a file descriptor as its wait
+mechanism.
 A file descriptor wait object must be usable in select, poll, and epoll
 routines.
 However, a provider may signal an FD wait object by marking it as
 readable or with an error.
-.IP \[bu] 2
-\f[I]FI_WAIT_MUTEX_COND\f[] : Specifies that the EQ should use a pthread
-mutex and cond variable as a wait object.
-.IP \[bu] 2
-\f[I]FI_WAIT_CRITSEC_COND\f[] : Windows specific.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_MUTEX_COND\f[]
+Specifies that the EQ should use a pthread mutex and cond variable as a
+wait object.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_CRITSEC_COND\f[]
+Windows specific.
 Specifies that the EQ should use a critical section and condition
 variable as a wait object.
-.PP
-\f[I]signaling_vector\f[] : If the FI_AFFINITY flag is set, this
-indicates the logical cpu number (0..max cpu \- 1) that interrupts
-associated with the EQ should target.
+.RS
+.RE
+.TP
+.B \f[I]signaling_vector\f[]
+If the FI_AFFINITY flag is set, this indicates the logical cpu number
+(0..max cpu \- 1) that interrupts associated with the EQ should target.
 This field should be treated as a hint to the provider and may be
 ignored if the provider does not support interrupt affinity.
-.PP
-\f[I]wait_set\f[] : If wait_obj is FI_WAIT_SET, this field references a
-wait object to which the event queue should attach.
+.RS
+.RE
+.TP
+.B \f[I]wait_set\f[]
+If wait_obj is FI_WAIT_SET, this field references a wait object to which
+the event queue should attach.
 When an event is inserted into the event queue, the corresponding wait
 set will be signaled if all necessary conditions are met.
 The use of a wait_set enables an optimized method of waiting for events
 across multiple event queues.
 This field is ignored if wait_obj is not FI_WAIT_SET.
+.RS
+.RE
 .SS fi_close
 .PP
 The fi_close call releases all resources associated with an event queue.
@@ -186,15 +280,18 @@ specific details of the event queue.
 Access to the EQ should be serialized across all calls when fi_control
 is invoked, as it may redirect the implementation of EQ operations.
 The following control commands are usable with an EQ.
-.PP
-\f[I]FI_GETWAIT (void **)\f[] : This command allows the user to retrieve
-the low\-level wait object associated with the EQ.
+.TP
+.B \f[I]FI_GETWAIT (void **)\f[]
+This command allows the user to retrieve the low\-level wait object
+associated with the EQ.
 The format of the wait\-object is specified during EQ creation, through
 the EQ attributes.
 The fi_control arg parameter should be an address where a pointer to the
 returned wait object will be written.
 This should be an \[aq]int *\[aq] for FI_WAIT_FD, or \[aq]struct
 fi_mutex_cond\[aq] for FI_WAIT_MUTEX_COND.
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -220,12 +317,14 @@ from the EQ.
 .PP
 The following types of events may be reported to an EQ, along with
 information regarding the format associated with each event.
-.PP
-\f[I]Asynchronous Control Operations\f[] : Asynchronous control
-operations are basic requests that simply need to generate an event to
-indicate that they have completed.
+.TP
+.B \f[I]Asynchronous Control Operations\f[]
+Asynchronous control operations are basic requests that simply need to
+generate an event to indicate that they have completed.
 These include the following types of events: memory registration,
 address vector resolution, and multicast joins.
+.RS
+.RE
 .PP
 Control requests report their completion by inserting a
 \f[C]struct\ \ \ fi_eq_entry\f[] into the EQ.
@@ -254,14 +353,16 @@ the fabric descriptor.
 The data field will be set as described in the man page for the
 corresponding object type (e.g., see \f[C]fi_av\f[](3) for a description
 of how asynchronous address vector insertions are completed).
-.PP
-\f[I]Connection Notification\f[] : Connection notifications are
-connection management notifications used to setup or tear down
-connections between endpoints.
+.TP
+.B \f[I]Connection Notification\f[]
+Connection notifications are connection management notifications used to
+setup or tear down connections between endpoints.
 There are three connection notification events: FI_CONNREQ,
 FI_CONNECTED, and FI_SHUTDOWN.
 Connection notifications are reported using
 \f[C]struct\ \ \ fi_eq_cm_entry\f[]:
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -318,13 +419,15 @@ is done through the FI_SHUTDOWN event.
 Shutdown notification uses struct fi_eq_cm_entry as declared above.
 The fid field for a shutdown notification refers to the active
 endpoint\[aq]s fid_ep.
-.PP
-\f[I]Asynchronous Error Notification\f[] : Asynchronous errors are used
-to report problems with fabric resources.
+.TP
+.B \f[I]Asynchronous Error Notification\f[]
+Asynchronous errors are used to report problems with fabric resources.
 Reported errors may be fatal or transient, based on the error, and
 result in the resource becoming disabled.
 Disabled resources will fail operations submitted against them until
 they are explicitly re\-enabled by the application.
+.RS
+.RE
 .PP
 Asynchronous errors may be reported for completion queues and endpoints
 of all types.
@@ -423,9 +526,9 @@ ensure that the buffer referenced by err_data does not change.
 The EQ entry data structures share many of the same fields.
 The meanings are the same or similar for all EQ structure formats, with
 specific details described below.
-.PP
-\f[I]fid\f[] : This corresponds to the fabric descriptor associated with
-the event.
+.TP
+.B \f[I]fid\f[]
+This corresponds to the fabric descriptor associated with the event.
 The type of fid depends on the event being reported.
 For FI_CONNREQ this will be the fid of the passive endpoint.
 FI_CONNECTED and FI_SHUTDOWN will reference the active endpoint.
@@ -435,42 +538,60 @@ FI_JOIN_COMPLETE will point to the multicast descriptor returned as part
 of the join operation.
 Applications can use fid\->context value to retrieve the context
 associated with the fabric descriptor.
-.PP
-\f[I]context\f[] : The context value is set to the context parameter
-specified with the operation that generated the event.
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+The context value is set to the context parameter specified with the
+operation that generated the event.
 If no context parameter is associated with the operation, this field
 will be NULL.
-.PP
-\f[I]data\f[] : Data is an operation specific value or set of bytes.
+.RS
+.RE
+.TP
+.B \f[I]data\f[]
+Data is an operation specific value or set of bytes.
 For connection events, data is application data exchanged as part of the
 connection protocol.
-.PP
-\f[I]err\f[] : This err code is a positive fabric errno associated with
-an event.
+.RS
+.RE
+.TP
+.B \f[I]err\f[]
+This err code is a positive fabric errno associated with an event.
 The err value indicates the general reason for an error, if one
 occurred.
 See fi_errno.3 for a list of possible error codes.
-.PP
-\f[I]prov_errno\f[] : On an error, prov_errno may contain a provider
-specific error code.
+.RS
+.RE
+.TP
+.B \f[I]prov_errno\f[]
+On an error, prov_errno may contain a provider specific error code.
 The use of this field and its meaning is provider specific.
 It is intended to be used as a debugging aid.
 See fi_eq_strerror for additional details on converting this error value
 into a human readable string.
-.PP
-\f[I]err_data\f[] : On an error, err_data may reference a provider
-specific amount of data associated with an error.
+.RS
+.RE
+.TP
+.B \f[I]err_data\f[]
+On an error, err_data may reference a provider specific amount of data
+associated with an error.
 The use of this field and its meaning is provider specific.
 It is intended to be used as a debugging aid.
 See fi_eq_strerror for additional details on converting this error data
 into a human readable string.
-.PP
-\f[I]err_data_size\f[] : On input, err_data_size indicates the size of
-the err_data buffer in bytes.
+.RS
+.RE
+.TP
+.B \f[I]err_data_size\f[]
+On input, err_data_size indicates the size of the err_data buffer in
+bytes.
 On output, err_data_size will be set to the number of bytes copied to
 the err_data buffer.
 The err_data information is typically used with fi_eq_strerror to
 provide details about the type of error that occurred.
+.RS
+.RE
 .PP
 For compatibility purposes, if err_data_size is 0 on input, or the
 fabric was opened with release < 1.5, err_data will be set to a data
@@ -491,22 +612,32 @@ will result in it returning an FI_EOVERRUN error event.
 Overrun event queues are considered fatal and may not be used to report
 additional events once the overrun occurs.
 .SH RETURN VALUES
-.PP
-fi_eq_open : Returns 0 on success.
+.TP
+.B fi_eq_open
+Returns 0 on success.
 On error, a negative value corresponding to fabric errno is returned.
-.PP
-fi_eq_read / fi_eq_readerr / fi_eq_sread : On success, returns the
-number of bytes read from the event queue.
+.RS
+.RE
+.TP
+.B fi_eq_read / fi_eq_readerr / fi_eq_sread
+On success, returns the number of bytes read from the event queue.
 On error, a negative value corresponding to fabric errno is returned.
 If no data is available to be read from the event queue, \-FI_EAGAIN is
 returned.
-.PP
-fi_eq_write : On success, returns the number of bytes written to the
-event queue.
+.RS
+.RE
+.TP
+.B fi_eq_write
+On success, returns the number of bytes written to the event queue.
 On error, a negative value corresponding to fabric errno is returned.
-.PP
-fi_eq_strerror : Returns a character string interpretation of the
-provider specific error returned with a completion.
+.RS
+.RE
+.TP
+.B fi_eq_strerror
+Returns a character string interpretation of the provider specific error
+returned with a completion.
+.RS
+.RE
 .PP
 Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
 .SH SEE ALSO
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_errno.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_errno.3
index b02d36171..1b1c2f701 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_errno.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_errno.3
@@ -1,4 +1,7 @@
-.TH "fi_errno" "3" "2016\-02\-28" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_errno" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_errno \- fabric errors
@@ -14,94 +17,226 @@ const\ char\ *fi_strerror(int\ errno);
 \f[]
 .fi
 .SH ERRORS
-.PP
-\f[I]FI_ENOENT\f[] : No such file or directory.
-.PP
-\f[I]FI_EIO\f[] : I/O error
-.PP
-\f[I]FI_E2BIG\f[] : Argument list too long.
-.PP
-\f[I]FI_EBADF\f[] : Bad file number.
-.PP
-\f[I]FI_EAGAIN\f[] : Try again.
-.PP
-\f[I]FI_ENOMEM\f[] : Out of memory.
-.PP
-\f[I]FI_EACCES\f[] : Permission denied.
-.PP
-\f[I]FI_EBUSY\f[] : Device or resource busy
-.PP
-\f[I]FI_ENODEV\f[] : No such device
-.PP
-\f[I]FI_EINVAL\f[] : Invalid argument
-.PP
-\f[I]FI_EMFILE\f[] : Too many open files
-.PP
-\f[I]FI_ENOSPC\f[] : No space left on device
-.PP
-\f[I]FI_ENOSYS\f[] : Function not implemented
-.PP
-\f[I]FI_ENOMSG\f[] : No message of desired type
-.PP
-\f[I]FI_ENODATA\f[] : No data available
-.PP
-\f[I]FI_EMSGSIZE\f[] : Message too long
-.PP
-\f[I]FI_ENOPROTOOPT\f[] : Protocol not available
-.PP
-\f[I]FI_EOPNOTSUPP\f[] : Operation not supported on transport endpoint
-.PP
-\f[I]FI_EADDRINUSE\f[] : Address already in use
-.PP
-\f[I]FI_EADDRNOTAVAIL\f[] : Cannot assign requested address
-.PP
-\f[I]FI_ENETDOWN\f[] : Network is down
-.PP
-\f[I]FI_ENETUNREACH\f[] : Network is unreachable
-.PP
-\f[I]FI_ECONNABORTED\f[] : Software caused connection abort
-.PP
-\f[I]FI_ECONNRESET\f[] : Connection reset by peer
-.PP
-\f[I]FI_EISCONN\f[] : Transport endpoint is already connected
-.PP
-\f[I]FI_ENOTCONN\f[] : Transport endpoint is not connected
-.PP
-\f[I]FI_ESHUTDOWN\f[] : Cannot send after transport endpoint shutdown
-.PP
-\f[I]FI_ETIMEDOUT\f[] : Operation timed out
-.PP
-\f[I]FI_ECONNREFUSED\f[] : Connection refused
-.PP
-\f[I]FI_EHOSTUNREACH\f[] : No route to host
-.PP
-\f[I]FI_EALREADY\f[] : Operation already in progress
-.PP
-\f[I]FI_EINPROGRESS\f[] : Operation now in progress
-.PP
-\f[I]FI_EREMOTEIO\f[] : Remote I/O error
-.PP
-\f[I]FI_ECANCELED\f[] : Operation Canceled
-.PP
-\f[I]FI_ENOKEY\f[] : Required key not available
-.PP
-\f[I]FI_EKEYREJECTED\f[] : Key was rejected by service
-.PP
-\f[I]FI_EOTHER\f[] : Unspecified error
-.PP
-\f[I]FI_ETOOSMALL\f[] : Provided buffer is too small
-.PP
-\f[I]FI_EOPBADSTATE\f[] : Operation not permitted in current state
-.PP
-\f[I]FI_EAVAIL\f[] : Error available
-.PP
-\f[I]FI_EBADFLAGS\f[] : Flags not supported
-.PP
-\f[I]FI_ENOEQ\f[] : Missing or unavailable event queue
-.PP
-\f[I]FI_EDOMAIN\f[] : Invalid resource domain
-.PP
-\f[I]FI_ENOCQ\f[] : Missing or unavailable completion queue
+.TP
+.B \f[I]FI_ENOENT\f[]
+No such file or directory.
+.RS
+.RE
+.TP
+.B \f[I]FI_EIO\f[]
+I/O error
+.RS
+.RE
+.TP
+.B \f[I]FI_E2BIG\f[]
+Argument list too long.
+.RS
+.RE
+.TP
+.B \f[I]FI_EBADF\f[]
+Bad file number.
+.RS
+.RE
+.TP
+.B \f[I]FI_EAGAIN\f[]
+Try again.
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOMEM\f[]
+Out of memory.
+.RS
+.RE
+.TP
+.B \f[I]FI_EACCES\f[]
+Permission denied.
+.RS
+.RE
+.TP
+.B \f[I]FI_EBUSY\f[]
+Device or resource busy
+.RS
+.RE
+.TP
+.B \f[I]FI_ENODEV\f[]
+No such device
+.RS
+.RE
+.TP
+.B \f[I]FI_EINVAL\f[]
+Invalid argument
+.RS
+.RE
+.TP
+.B \f[I]FI_EMFILE\f[]
+Too many open files
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOSPC\f[]
+No space left on device
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOSYS\f[]
+Function not implemented
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOMSG\f[]
+No message of desired type
+.RS
+.RE
+.TP
+.B \f[I]FI_ENODATA\f[]
+No data available
+.RS
+.RE
+.TP
+.B \f[I]FI_EMSGSIZE\f[]
+Message too long
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOPROTOOPT\f[]
+Protocol not available
+.RS
+.RE
+.TP
+.B \f[I]FI_EOPNOTSUPP\f[]
+Operation not supported on transport endpoint
+.RS
+.RE
+.TP
+.B \f[I]FI_EADDRINUSE\f[]
+Address already in use
+.RS
+.RE
+.TP
+.B \f[I]FI_EADDRNOTAVAIL\f[]
+Cannot assign requested address
+.RS
+.RE
+.TP
+.B \f[I]FI_ENETDOWN\f[]
+Network is down
+.RS
+.RE
+.TP
+.B \f[I]FI_ENETUNREACH\f[]
+Network is unreachable
+.RS
+.RE
+.TP
+.B \f[I]FI_ECONNABORTED\f[]
+Software caused connection abort
+.RS
+.RE
+.TP
+.B \f[I]FI_ECONNRESET\f[]
+Connection reset by peer
+.RS
+.RE
+.TP
+.B \f[I]FI_EISCONN\f[]
+Transport endpoint is already connected
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOTCONN\f[]
+Transport endpoint is not connected
+.RS
+.RE
+.TP
+.B \f[I]FI_ESHUTDOWN\f[]
+Cannot send after transport endpoint shutdown
+.RS
+.RE
+.TP
+.B \f[I]FI_ETIMEDOUT\f[]
+Operation timed out
+.RS
+.RE
+.TP
+.B \f[I]FI_ECONNREFUSED\f[]
+Connection refused
+.RS
+.RE
+.TP
+.B \f[I]FI_EHOSTUNREACH\f[]
+No route to host
+.RS
+.RE
+.TP
+.B \f[I]FI_EALREADY\f[]
+Operation already in progress
+.RS
+.RE
+.TP
+.B \f[I]FI_EINPROGRESS\f[]
+Operation now in progress
+.RS
+.RE
+.TP
+.B \f[I]FI_EREMOTEIO\f[]
+Remote I/O error
+.RS
+.RE
+.TP
+.B \f[I]FI_ECANCELED\f[]
+Operation Canceled
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOKEY\f[]
+Required key not available
+.RS
+.RE
+.TP
+.B \f[I]FI_EKEYREJECTED\f[]
+Key was rejected by service
+.RS
+.RE
+.TP
+.B \f[I]FI_EOTHER\f[]
+Unspecified error
+.RS
+.RE
+.TP
+.B \f[I]FI_ETOOSMALL\f[]
+Provided buffer is too small
+.RS
+.RE
+.TP
+.B \f[I]FI_EOPBADSTATE\f[]
+Operation not permitted in current state
+.RS
+.RE
+.TP
+.B \f[I]FI_EAVAIL\f[]
+Error available
+.RS
+.RE
+.TP
+.B \f[I]FI_EBADFLAGS\f[]
+Flags not supported
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOEQ\f[]
+Missing or unavailable event queue
+.RS
+.RE
+.TP
+.B \f[I]FI_EDOMAIN\f[]
+Invalid resource domain
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOCQ\f[]
+Missing or unavailable completion queue
+.RS
+.RE
 .SH SEE ALSO
 .PP
 \f[C]fabric\f[](7)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_fabric.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_fabric.3
index b1e85383a..18d4ceb91 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_fabric.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_fabric.3
@@ -1,12 +1,20 @@
-.TH "fi_fabric" "3" "2017\-10\-18" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_fabric" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_fabric \- Fabric domain operations
-.PP
-fi_fabric / fi_close : Open / close a fabric domain
-.PP
-fi_tostr : Convert fabric attributes, flags, and capabilities to
-printable string
+.TP
+.B fi_fabric / fi_close
+Open / close a fabric domain
+.RS
+.RE
+.TP
+.B fi_tostr
+Convert fabric attributes, flags, and capabilities to printable string
+.RS
+.RE
 .SH SYNOPSIS
 .IP
 .nf
@@ -22,14 +30,22 @@ char\ *\ fi_tostr(const\ void\ *data,\ enum\ fi_type\ datatype);
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]attr\f[] : Attributes of fabric to open.
-.PP
-\f[I]fabric\f[] : Fabric domain
-.PP
-\f[I]context\f[] : User specified context associated with the opened
-object.
+.TP
+.B \f[I]attr\f[]
+Attributes of fabric to open.
+.RS
+.RE
+.TP
+.B \f[I]fabric\f[]
+Fabric domain
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified context associated with the opened object.
 This context is returned as part of any associated asynchronous event.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 A fabric domain represents a collection of hardware and software
@@ -58,41 +74,129 @@ display, with the datatype parameter indicating the type of data
 referenced by the data parameter.
 Valid values for the datatype are listed below, along with the
 corresponding datatype or field value.
-.PP
-\f[I]FI_TYPE_INFO\f[] : struct fi_info
-.PP
-\f[I]FI_TYPE_EP_TYPE\f[] : struct fi_info::type field
-.PP
-\f[I]FI_TYPE_EP_CAP\f[] : struct fi_info::ep_cap field
-.PP
-\f[I]FI_TYPE_OP_FLAGS\f[] : struct fi_info::op_flags field, or general
-uint64_t flags
-.PP
-\f[I]FI_TYPE_ADDR_FORMAT\f[] : struct fi_info::addr_format field
-.PP
-\f[I]FI_TYPE_TX_ATTR\f[] : struct fi_tx_attr
-.PP
-\f[I]FI_TYPE_RX_ATTR\f[] : struct fi_rx_attr
-.PP
-\f[I]FI_TYPE_EP_ATTR\f[] : struct fi_ep_attr
-.PP
-\f[I]FI_TYPE_DOMAIN_ATTR\f[] : struct fi_domain_attr
-.PP
-\f[I]FI_TYPE_FABRIC_ATTR\f[] : struct fi_fabric_attr
-.PP
-\f[I]FI_TYPE_DOMAIN_CAP\f[] : struct fi_info::domain_cap field
-.PP
-\f[I]FI_TYPE_THREADING\f[] : enum fi_threading
-.PP
-\f[I]FI_TYPE_PROGRESS\f[] : enum fi_progress
-.PP
-\f[I]FI_TYPE_PROTO\f[] : struct fi_ep_attr::protocol field
-.PP
-\f[I]FI_TYPE_MSG_ORDER\f[] : struct fi_ep_attr::msg_order field
-.PP
-\f[I]FI_TYPE_VERSION\f[] : Returns the library version of libfabric in
-string form.
+.TP
+.B \f[I]FI_TYPE_INFO\f[]
+struct fi_info, including all substructures and fields
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_EP_TYPE\f[]
+struct fi_info::type field
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_EP_CAP\f[]
+struct fi_info::ep_cap field
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_OP_FLAGS\f[]
+struct fi_info::op_flags field, or general uint64_t flags
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_ADDR_FORMAT\f[]
+struct fi_info::addr_format field
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_TX_ATTR\f[]
+struct fi_tx_attr
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_RX_ATTR\f[]
+struct fi_rx_attr
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_EP_ATTR\f[]
+struct fi_ep_attr
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_DOMAIN_ATTR\f[]
+struct fi_domain_attr
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_FABRIC_ATTR\f[]
+struct fi_fabric_attr
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_THREADING\f[]
+enum fi_threading
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_PROGRESS\f[]
+enum fi_progress
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_PROTOCOL\f[]
+struct fi_ep_attr::protocol field
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_MSG_ORDER\f[]
+struct fi_ep_attr::msg_order field
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_MODE\f[]
+struct fi_info::mode field
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_AV_TYPE\f[]
+enum fi_av_type
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_ATOMIC_TYPE\f[]
+enum fi_datatype
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_ATOMIC_OP\f[]
+enum fi_op
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_VERSION\f[]
+Returns the library version of libfabric in string form.
 The data parameter is ignored.
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_EQ_EVENT\f[]
+uint32_t event parameter returned from fi_eq_read().
+See \f[C]fi_eq(3)\f[] for a list of known values.
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_CQ_EVENT_FLAGS\f[]
+uint64_t flags field in fi_cq_xxx_entry structures.
+See \f[C]fi_cq(3)\f[] for valid flags.
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_MR_MODE\f[]
+struct fi_domain_attr::mr_mode flags
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_OP_TYPE\f[]
+enum fi_op_type
+.RS
+.RE
+.TP
+.B \f[I]FI_TYPE_FID\f[]
+struct fid *
+.RS
+.RE
 .PP
 fi_tostr() will return a pointer to an internal libfabric buffer that
 should not be modified, and will be overwritten the next time fi_tostr()
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_getinfo.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_getinfo.3
index 84f0a6d62..47fd4f40f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_getinfo.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_getinfo.3
@@ -1,4 +1,7 @@
-.TH "fi_getinfo" "3" "2018\-02\-13" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_getinfo" "3" "2018\-10\-10" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_getinfo, fi_freeinfo \- Obtain / free fabric interface information
@@ -21,20 +24,38 @@ struct\ fi_info\ *fi_dupinfo(const\ struct\ fi_info\ *info);
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]version\f[] : Interface version requested by application.
-.PP
-\f[I]node\f[] : Optional, name or fabric address to resolve.
-.PP
-\f[I]service\f[] : Optional, service name or port number of address.
-.PP
-\f[I]flags\f[] : Operation flags for the fi_getinfo call.
-.PP
-\f[I]hints\f[] : Reference to an fi_info structure that specifies
-criteria for selecting the returned fabric information.
-.PP
-\f[I]info\f[] : A pointer to a linked list of fi_info structures
-containing response information.
+.TP
+.B \f[I]version\f[]
+Interface version requested by application.
+.RS
+.RE
+.TP
+.B \f[I]node\f[]
+Optional, name or fabric address to resolve.
+.RS
+.RE
+.TP
+.B \f[I]service\f[]
+Optional, service name or port number of address.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Operation flags for the fi_getinfo call.
+.RS
+.RE
+.TP
+.B \f[I]hints\f[]
+Reference to an fi_info structure that specifies criteria for selecting
+the returned fabric information.
+.RS
+.RE
+.TP
+.B \f[I]info\f[]
+A pointer to a linked list of fi_info structures containing response
+information.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 fi_getinfo returns information about available fabric services for
@@ -130,42 +151,58 @@ struct\ fi_info\ {
 \ \ \ \ struct\ fi_ep_attr\ \ \ \ \ *ep_attr;
 \ \ \ \ struct\ fi_domain_attr\ *domain_attr;
 \ \ \ \ struct\ fi_fabric_attr\ *fabric_attr;
+\ \ \ \ struct\ fid_nic\ \ \ \ \ \ \ \ *nic;
 };
 \f[]
 .fi
-.PP
-\f[I]next\f[] : Pointer to the next fi_info structure in the list.
+.TP
+.B \f[I]next\f[]
+Pointer to the next fi_info structure in the list.
 Will be NULL if no more structures exist.
-.PP
-\f[I]caps \- fabric interface capabilities\f[] : If specified, indicates
-the desired capabilities of the fabric interfaces.
+.RS
+.RE
+.TP
+.B \f[I]caps \- fabric interface capabilities\f[]
+If specified, indicates the desired capabilities of the fabric
+interfaces.
 Supported capabilities are listed in the \f[I]Capabilities\f[] section
 below.
-.PP
-\f[I]mode\f[] : Operational modes supported by the application.
+.RS
+.RE
+.TP
+.B \f[I]mode\f[]
+Operational modes supported by the application.
 See the \f[I]Mode\f[] section below.
-.PP
-\f[I]addr_format \- address format\f[] : If specified, indicates the
-format of addresses referenced by the fabric interfaces and data
-structures.
+.RS
+.RE
+.TP
+.B \f[I]addr_format \- address format\f[]
+If specified, indicates the format of addresses referenced by the fabric
+interfaces and data structures.
 Supported formats are listed in the \f[I]Addressing formats\f[] section
 below.
-.PP
-\f[I]src_addrlen \- source address length\f[] : Indicates the length of
-the source address.
+.RS
+.RE
+.TP
+.B \f[I]src_addrlen \- source address length\f[]
+Indicates the length of the source address.
 This value must be > 0 if \f[I]src_addr\f[] is non\-NULL.
 This field will be ignored in hints if FI_SOURCE flag is set, or
 \f[I]src_addr\f[] is NULL.
-.PP
-\f[I]dest_addrlen \- destination address length\f[] : Indicates the
-length of the destination address.
+.RS
+.RE
+.TP
+.B \f[I]dest_addrlen \- destination address length\f[]
+Indicates the length of the destination address.
 This value must be > 0 if \f[I]dest_addr\f[] is non\-NULL.
 This field will be ignored in hints unless the node and service
 parameters are NULL or FI_SOURCE flag is set, or if \f[I]dst_addr\f[] is
 NULL.
-.PP
-\f[I]src_addr \- source address\f[] : If specified, indicates the source
-address.
+.RS
+.RE
+.TP
+.B \f[I]src_addr \- source address\f[]
+If specified, indicates the source address.
 This field will be ignored in hints if FI_SOURCE flag is set.
 On output a provider shall return an address that corresponds to the
 indicated fabric, domain, node, and/or service fields.
@@ -174,31 +211,37 @@ The format of the address is indicated by the returned
 Note that any returned address is only used when opening a local
 endpoint.
 The address is not guaranteed to be usable by a peer process.
-.PP
-\f[I]dest_addr \- destination address\f[] : If specified, indicates the
-destination address.
+.RS
+.RE
+.TP
+.B \f[I]dest_addr \- destination address\f[]
+If specified, indicates the destination address.
 This field will be ignored in hints unless the node and service
 parameters are NULL or FI_SOURCE flag is set.
 If FI_SOURCE is not specified, on output a provider shall return an
 address the corresponds to the indicated node and/or service fields,
 relative to the fabric and domain.
 Note that any returned address is only usable locally.
-.PP
-\f[I]handle \- provider context handle\f[] : References a provider
-specific handle.
+.RS
+.RE
+.TP
+.B \f[I]handle \- provider context handle\f[]
 The use of this field is operation specific.
-Unless its use is described for a given operation, the handle field must
-be NULL.
-It is commonly used by applications that make use of
-connection\-oriented endpoints.
-For other applications, the field should usually be NULL.
-.PP
-This field is used when processing connection requests and responses.
-It is also used to inherit endpoint\[aq]s attributes.
-See fi_eq(3), fi_reject(3), and fi_endpoint(3) .
-.PP
-\f[I]tx_attr \- transmit context attributes\f[] : Optionally supplied
-transmit context attributes.
+If hints\->handle is set to struct fid_pep, the hints\->handle will be
+copied to info\->handle on output from fi_getinfo.
+Other values of hints\->handle will be handled in a provider specific
+manner.
+The fi_info::handle field is also used by fi_endpoint() and fi_reject()
+calls when processing connection requests or to inherit another
+endpoint\[aq]s attributes.
+See \f[C]fi_eq\f[](3), \f[C]fi_reject\f[](3), and
+\f[C]fi_endpoint\f[](3).
+The info\->handle field will be ignored by fi_dupinfo and fi_freeinfo.
+.RS
+.RE
+.TP
+.B \f[I]tx_attr \- transmit context attributes\f[]
+Optionally supplied transmit context attributes.
 Transmit context attributes may be specified and returned as part of
 fi_getinfo.
 When provided as hints, requested values of struct fi_tx_ctx_attr should
@@ -207,9 +250,11 @@ On output, the actual transmit context attributes that can be provided
 will be returned.
 Output values will be greater than or equal to the requested input
 values.
-.PP
-\f[I]rx_attr \- receive context attributes\f[] : Optionally supplied
-receive context attributes.
+.RS
+.RE
+.TP
+.B \f[I]rx_attr \- receive context attributes\f[]
+Optionally supplied receive context attributes.
 Receive context attributes may be specified and returned as part of
 fi_getinfo.
 When provided as hints, requested values of struct fi_rx_ctx_attr should
@@ -218,35 +263,52 @@ On output, the actual receive context attributes that can be provided
 will be returned.
 Output values will be greater than or or equal to the requested input
 values.
-.PP
-\f[I]ep_attr \- endpoint attributes\f[] : Optionally supplied endpoint
-attributes.
+.RS
+.RE
+.TP
+.B \f[I]ep_attr \- endpoint attributes\f[]
+Optionally supplied endpoint attributes.
 Endpoint attributes may be specified and returned as part of fi_getinfo.
 When provided as hints, requested values of struct fi_ep_attr should be
 set.
 On output, the actual endpoint attributes that can be provided will be
 returned.
 Output values will be greater than or equal to requested input values.
-See fi_endpoint(3) for details.
-.PP
-\f[I]domain_attr \- domain attributes\f[] : Optionally supplied domain
-attributes.
+See \f[C]fi_endpoint\f[](3) for details.
+.RS
+.RE
+.TP
+.B \f[I]domain_attr \- domain attributes\f[]
+Optionally supplied domain attributes.
 Domain attributes may be specified and returned as part of fi_getinfo.
 When provided as hints, requested values of struct fi_domain_attr should
 be set.
 On output, the actual domain attributes that can be provided will be
 returned.
 Output values will be greater than or equal to requested input values.
-See fi_domain(3) for details.
-.PP
-\f[I]fabric_attr \- fabric attributes\f[] : Optionally supplied fabric
-attributes.
+See \f[C]fi_domain\f[](3) for details.
+.RS
+.RE
+.TP
+.B \f[I]fabric_attr \- fabric attributes\f[]
+Optionally supplied fabric attributes.
 Fabric attributes may be specified and returned as part of fi_getinfo.
 When provided as hints, requested values of struct fi_fabric_attr should
 be set.
 On output, the actual fabric attributes that can be provided will be
 returned.
-See fi_fabric(3) for details.
+See \f[C]fi_fabric\f[](3) for details.
+.RS
+.RE
+.TP
+.B \f[I]nic \- network interface details\f[]
+Optional attributes related to the hardware NIC associated with the
+specified fabric, domain, and endpoint data.
+This field is only valid for providers where the corresponding
+attributes are closely associated with a hardware NIC.
+See [\f[C]fi_nic\f[](3)] (fi_nic.3.html) for details.
+.RS
+.RE
 .SH CAPABILITIES
 .PP
 Interface capabilities are obtained by OR\-ing the following flags
@@ -262,12 +324,15 @@ that which was requested.
 Applications may use this feature to request a minimal set of
 requirements, then check the returned capabilities to enable additional
 optimizations.
-.PP
-\f[I]FI_MSG\f[] : Specifies that an endpoint should support sending and
-receiving messages or datagrams.
+.TP
+.B \f[I]FI_MSG\f[]
+Specifies that an endpoint should support sending and receiving messages
+or datagrams.
 Message capabilities imply support for send and/or receive queues.
 Endpoints supporting this capability support operations defined by
 struct fi_ops_msg.
+.RS
+.RE
 .PP
 The caps may be used to specify or restrict the type of messaging
 operations that are supported.
@@ -275,9 +340,10 @@ In the absence of any relevant flags, FI_MSG implies the ability to send
 and receive messages.
 Applications can use the FI_SEND and FI_RECV flags to optimize an
 endpoint as send\-only or receive\-only.
-.PP
-\f[I]FI_RMA\f[] : Specifies that the endpoint should support RMA read
-and write operations.
+.TP
+.B \f[I]FI_RMA\f[]
+Specifies that the endpoint should support RMA read and write
+operations.
 Endpoints supporting this capability support operations defined by
 struct fi_ops_rma.
 In the absence of any relevant flags, FI_RMA implies the ability to
@@ -285,9 +351,11 @@ initiate and be the target of remote memory reads and writes.
 Applications can use the FI_READ, FI_WRITE, FI_REMOTE_READ, and
 FI_REMOTE_WRITE flags to restrict the types of RMA operations supported
 by an endpoint.
-.PP
-\f[I]FI_TAGGED\f[] : Specifies that the endpoint should handle tagged
-message transfers.
+.RS
+.RE
+.TP
+.B \f[I]FI_TAGGED\f[]
+Specifies that the endpoint should handle tagged message transfers.
 Tagged message transfers associate a user\-specified key or tag with
 each message that is used for matching purposes at the remote side.
 Endpoints supporting this capability support operations defined by
@@ -296,9 +364,11 @@ In the absence of any relevant flags, FI_TAGGED implies the ability to
 send and receive tagged messages.
 Applications can use the FI_SEND and FI_RECV flags to optimize an
 endpoint as send\-only or receive\-only.
-.PP
-\f[I]FI_ATOMIC\f[] : Specifies that the endpoint supports some set of
-atomic operations.
+.RS
+.RE
+.TP
+.B \f[I]FI_ATOMIC\f[]
+Specifies that the endpoint supports some set of atomic operations.
 Endpoints supporting this capability support operations defined by
 struct fi_ops_atomic.
 In the absence of any relevant flags, FI_ATOMIC implies the ability to
@@ -306,28 +376,41 @@ initiate and be the target of remote atomic reads and writes.
 Applications can use the FI_READ, FI_WRITE, FI_REMOTE_READ, and
 FI_REMOTE_WRITE flags to restrict the types of atomic operations
 supported by an endpoint.
-.PP
-\f[I]FI_MULTICAST\f[] : Indicates that the endpoint support multicast
-data transfers.
+.RS
+.RE
+.TP
+.B \f[I]FI_MULTICAST\f[]
+Indicates that the endpoint support multicast data transfers.
 This capability must be paired with at least one other data transfer
 capability, (e.g.
 FI_MSG, FI_SEND, FI_RECV, ...).
-.PP
-\f[I]FI_NAMED_RX_CTX\f[] : Requests that endpoints which support
-multiple receive contexts allow an initiator to target (or name) a
-specific receive context as part of a data transfer operation.
-.PP
-\f[I]FI_DIRECTED_RECV\f[] : Requests that the communication endpoint use
-the source address of an incoming message when matching it with a
-receive buffer.
+.RS
+.RE
+.TP
+.B \f[I]FI_NAMED_RX_CTX\f[]
+Requests that endpoints which support multiple receive contexts allow an
+initiator to target (or name) a specific receive context as part of a
+data transfer operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_DIRECTED_RECV\f[]
+Requests that the communication endpoint use the source address of an
+incoming message when matching it with a receive buffer.
 If this capability is not set, then the src_addr parameter for msg and
 tagged receive operations is ignored.
-.PP
-\f[I]FI_MULTI_RECV\f[] : Specifies that the endpoint must support the
-FI_MULTI_RECV flag when posting receive buffers.
-.PP
-\f[I]FI_SOURCE\f[] : Requests that the endpoint return source addressing
-data as part of its completion data.
+.RS
+.RE
+.TP
+.B \f[I]FI_MULTI_RECV\f[]
+Specifies that the endpoint must support the FI_MULTI_RECV flag when
+posting receive buffers.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOURCE\f[]
+Requests that the endpoint return source addressing data as part of its
+completion data.
 This capability only applies to connectionless endpoints.
 Note that returning source address information may require that the
 provider perform address translation and/or look\-up based on data
@@ -335,58 +418,88 @@ available in the underlying protocol in order to provide the requested
 data, which may adversely affect performance.
 The performance impact may be greater for address vectors of type
 FI_AV_TABLE.
-.PP
-\f[I]FI_READ\f[] : Indicates that the user requires an endpoint capable
-of initiating reads against remote memory regions.
+.RS
+.RE
+.TP
+.B \f[I]FI_READ\f[]
+Indicates that the user requires an endpoint capable of initiating reads
+against remote memory regions.
 This flag requires that FI_RMA and/or FI_ATOMIC be set.
-.PP
-\f[I]FI_WRITE\f[] : Indicates that the user requires an endpoint capable
-of initiating writes against remote memory regions.
+.RS
+.RE
+.TP
+.B \f[I]FI_WRITE\f[]
+Indicates that the user requires an endpoint capable of initiating
+writes against remote memory regions.
 This flag requires that FI_RMA and/or FI_ATOMIC be set.
-.PP
-\f[I]FI_SEND\f[] : Indicates that the user requires an endpoint capable
-of sending message data transfers.
+.RS
+.RE
+.TP
+.B \f[I]FI_SEND\f[]
+Indicates that the user requires an endpoint capable of sending message
+data transfers.
 Message transfers include base message operations as well as tagged
 message functionality.
-.PP
-\f[I]FI_RECV\f[] : Indicates that the user requires an endpoint capable
-of receiving message data transfers.
+.RS
+.RE
+.TP
+.B \f[I]FI_RECV\f[]
+Indicates that the user requires an endpoint capable of receiving
+message data transfers.
 Message transfers include base message operations as well as tagged
 message functionality.
-.PP
-\f[I]FI_REMOTE_READ\f[] : Indicates that the user requires an endpoint
-capable of receiving read memory operations from remote endpoints.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_READ\f[]
+Indicates that the user requires an endpoint capable of receiving read
+memory operations from remote endpoints.
 This flag requires that FI_RMA and/or FI_ATOMIC be set.
-.PP
-\f[I]FI_REMOTE_WRITE\f[] : Indicates that the user requires an endpoint
-capable of receiving write memory operations from remote endpoints.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_WRITE\f[]
+Indicates that the user requires an endpoint capable of receiving write
+memory operations from remote endpoints.
 This flag requires that FI_RMA and/or FI_ATOMIC be set.
-.PP
-\f[I]FI_RMA_EVENT\f[] : Requests that an endpoint support the generation
-of completion events when it is the target of an RMA and/or atomic
-operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_RMA_EVENT\f[]
+Requests that an endpoint support the generation of completion events
+when it is the target of an RMA and/or atomic operation.
 This flag requires that FI_REMOTE_READ and/or FI_REMOTE_WRITE be enabled
 on the endpoint.
-.PP
-\f[I]FI_SHARED_AV\f[] : Requests or indicates support for address
-vectors which may be shared among multiple processes.
-.PP
-\f[I]FI_TRIGGER\f[] : Indicates that the endpoint should support
-triggered operations.
+.RS
+.RE
+.TP
+.B \f[I]FI_SHARED_AV\f[]
+Requests or indicates support for address vectors which may be shared
+among multiple processes.
+.RS
+.RE
+.TP
+.B \f[I]FI_TRIGGER\f[]
+Indicates that the endpoint should support triggered operations.
 Endpoints support this capability must meet the usage model as described
 by fi_trigger.3.
-.PP
-\f[I]FI_FENCE\f[] : Indicates that the endpoint support the FI_FENCE
-flag on data transfer operations.
+.RS
+.RE
+.TP
+.B \f[I]FI_FENCE\f[]
+Indicates that the endpoint support the FI_FENCE flag on data transfer
+operations.
 Support requires tracking that all previous transmit requests to a
 specified remote endpoint complete prior to initiating the fenced
 operation.
 Fenced operations are often used to enforce ordering between operations
 that are not otherwise guaranteed by the underlying provider or
 protocol.
-.PP
-\f[I]FI_LOCAL_COMM\f[] : Indicates that the endpoint support host local
-communication.
+.RS
+.RE
+.TP
+.B \f[I]FI_LOCAL_COMM\f[]
+Indicates that the endpoint support host local communication.
 This flag may be used in conjunction with FI_REMOTE_COMM to indicate
 that local and remote communication are required.
 If neither FI_LOCAL_COMM or FI_REMOTE_COMM are specified, then the
@@ -395,31 +508,52 @@ affects performance.
 Providers that set FI_LOCAL_COMM but not FI_REMOTE_COMM, for example a
 shared memory provider, may only be used to communication between
 processes on the same system.
-.PP
-\f[I]FI_REMOTE_COMM\f[] : Indicates that the endpoint support
-communication with endpoints located at remote nodes (across the
-fabric).
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_COMM\f[]
+Indicates that the endpoint support communication with endpoints located
+at remote nodes (across the fabric).
 See FI_LOCAL_COMM for additional details.
 Providers that set FI_REMOTE_COMM but not FI_LOCAL_COMM, for example
 NICs that lack loopback support, cannot be used to communicate with
 processes on the same system.
-.PP
-\f[I]FI_SOURCE_ERR\f[] : Must be paired with FI_SOURCE.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOURCE_ERR\f[]
+Must be paired with FI_SOURCE.
 When specified, this requests that raw source addressing data be
 returned as part of completion data for any address that has not been
 inserted into the local address vector.
 Use of this capability may require the provider to validate incoming
 source address data against addresses stored in the local address
 vector, which may adversely affect performance.
-.PP
-\f[I]FI_RMA_PMEM\f[] : Indicates that the provider is \[aq]persistent
-memory aware\[aq] and supports RMA operations to and from persistent
-memory.
+.RS
+.RE
+.TP
+.B \f[I]FI_RMA_PMEM\f[]
+Indicates that the provider is \[aq]persistent memory aware\[aq] and
+supports RMA operations to and from persistent memory.
 Persistent memory aware providers must support registration of memory
 that is backed by non\- volatile memory, RMA transfers to/from
 persistent memory, and enhanced completion semantics.
 This flag requires that FI_RMA be set.
 This capability is experimental.
+.RS
+.RE
+.TP
+.B \f[I]FI_VARIABLE_MSG\f[]
+Requests that the provider must notify a receiver when a variable length
+message is ready to be received prior to attempting to place the data.
+Such notification will include the size of the message and any
+associated message tag (for FI_TAGGED).
+See \[aq]Variable Length Messages\[aq] in fi_msg.3 for full details.
+Variable length messages are any messages larger than an endpoint
+configurable size.
+This flag requires that FI_MSG and/or FI_TAGGED be set.
+.RS
+.RE
 .PP
 Capabilities may be grouped into two general categories: primary and
 secondary.
@@ -434,7 +568,7 @@ doing so would not compromise performance or security.
 .PP
 Primary capabilities: FI_MSG, FI_RMA, FI_TAGGED, FI_ATOMIC,
 FI_MULTICAST, FI_NAMED_RX_CTX, FI_DIRECTED_RECV, FI_READ, FI_WRITE,
-FI_RECV, FI_SEND, FI_REMOTE_READ, and FI_REMOTE_WRITE.
+FI_RECV, FI_SEND, FI_REMOTE_READ, FI_REMOTE_WRITE, and FI_VARIABLE_MSG.
 .PP
 Secondary capabilities: FI_MULTI_RECV, FI_SOURCE, FI_RMA_EVENT,
 FI_SHARED_AV, FI_TRIGGER, FI_FENCE, FI_LOCAL_COMM, FI_REMOTE_COMM,
@@ -458,10 +592,11 @@ the fabric interfaces created using the returned fi_info.
 The set of modes are listed below.
 If a NULL hints structure is provided, then the provider\[aq]s supported
 set of modes will be returned in the info structure(s).
-.PP
-\f[I]FI_CONTEXT\f[] : Specifies that the provider requires that
-applications use struct fi_context as their per operation context
-parameter for operations that generated full completions.
+.TP
+.B \f[I]FI_CONTEXT\f[]
+Specifies that the provider requires that applications use struct
+fi_context as their per operation context parameter for operations that
+generated full completions.
 This structure should be treated as opaque to the application.
 For performance reasons, this structure must be allocated by the user,
 but may be used by the fabric provider to track the operation.
@@ -479,9 +614,12 @@ the endpoint was configured with FI_SELECTIVE_COMPLETION and the
 operation was not initiated with the FI_COMPLETION flag) then the
 context parameter is ignored by the fabric provider.The structure is
 specified in rdma/fabric.h.
-.PP
-\f[I]FI_CONTEXT2\f[] : This bit is similar to FI_CONTEXT, but doubles
-the provider\[aq]s requirement on the size of the per context structure.
+.RS
+.RE
+.TP
+.B \f[I]FI_CONTEXT2\f[]
+This bit is similar to FI_CONTEXT, but doubles the provider\[aq]s
+requirement on the size of the per context structure.
 When set, this specifies that the provider requires that applications
 use struct fi_context2 as their per operation context parameter.
 Or, optionally, an application can provide an array of two fi_context
@@ -489,9 +627,12 @@ structures (e.g.
 struct fi_context[2]) instead.
 The requirements for using struct fi_context2 are identical as defined
 for FI_CONTEXT above.
-.PP
-\f[I]FI_LOCAL_MR\f[] : The provider is optimized around having
-applications register memory for locally accessed data buffers.
+.RS
+.RE
+.TP
+.B \f[I]FI_LOCAL_MR\f[]
+The provider is optimized around having applications register memory for
+locally accessed data buffers.
 Data buffers used in send and receive operations and as the source
 buffer for RMA and atomic operations must be registered by the
 application for access domains opened with this capability.
@@ -500,16 +641,21 @@ version is 1.5 or later and the domain mr_mode is set to anything other
 than FI_MR_BASIC or FI_MR_SCALABLE.
 See the domain attribute mr_mode \f[C]fi_domain\f[](3) and
 \f[C]fi_mr\f[](3).
-.PP
-\f[I]FI_MSG_PREFIX\f[] : Message prefix mode indicates that an
-application will provide buffer space in front of all message send and
-receive buffers for use by the provider.
+.RS
+.RE
+.TP
+.B \f[I]FI_MSG_PREFIX\f[]
+Message prefix mode indicates that an application will provide buffer
+space in front of all message send and receive buffers for use by the
+provider.
 Typically, the provider uses this space to implement a protocol, with
 the protocol headers being written into the prefix area.
 The contents of the prefix space should be treated as opaque.
 The use of FI_MSG_PREFIX may improve application performance over
 certain providers by reducing the number of IO vectors referenced by
 underlying hardware and eliminating provider buffer allocation.
+.RS
+.RE
 .PP
 FI_MSG_PREFIX only applies to send and receive operations, including
 tagged sends and receives.
@@ -538,9 +684,10 @@ payload).
 For scatter\-gather send/recv operations, the prefix buffer must be a
 contiguous region, though it may or may not be directly adjacent to the
 payload portion of the buffer.
-.PP
-\f[I]FI_ASYNC_IOV\f[] : Applications can reference multiple data buffers
-as part of a single operation through the use of IO vectors (SGEs).
+.TP
+.B \f[I]FI_ASYNC_IOV\f[]
+Applications can reference multiple data buffers as part of a single
+operation through the use of IO vectors (SGEs).
 Typically, the contents of an IO vector are copied by the provider into
 an internal buffer area, or directly to the underlying hardware.
 However, when a large number of IOV entries are supported, IOV buffering
@@ -550,17 +697,21 @@ buffering needed for the IO vectors.
 When set, an application must not modify an IO vector of length > 1,
 including any related memory descriptor array, until the associated
 operation has completed.
-.PP
-\f[I]FI_RX_CQ_DATA\f[] : This mode bit only applies to data transfers
-that set FI_REMOTE_CQ_DATA.
+.RS
+.RE
+.TP
+.B \f[I]FI_RX_CQ_DATA\f[]
+This mode bit only applies to data transfers that set FI_REMOTE_CQ_DATA.
 When set, a data transfer that carries remote CQ data will consume a
 receive buffer at the target.
 This is true even for operations that would normally not consume posted
 receive buffers, such as RMA write operations.
-.PP
-\f[I]FI_NOTIFY_FLAGS_ONLY\f[] : This bit indicates that general
-completion flags may not be set by the provider, and are not needed by
-the application.
+.RS
+.RE
+.TP
+.B \f[I]FI_NOTIFY_FLAGS_ONLY\f[]
+This bit indicates that general completion flags may not be set by the
+provider, and are not needed by the application.
 If specified, completion flags which simply report the type of operation
 that completed (e.g.
 send or receive) may not be set.
@@ -568,11 +719,29 @@ However, completion flags that are used for remote notifications will
 still be set when applicable.
 See \f[C]fi_cq\f[](3) for details on which completion flags are valid
 when this mode bit is enabled.
-.PP
-\f[I]FI_RESTRICTED_COMP\f[] : This bit indicates that the application
-will only share completion queues and counters among endpoints, transmit
-contexts, and receive contexts that have the same set of capability
-flags.
+.RS
+.RE
+.TP
+.B \f[I]FI_RESTRICTED_COMP\f[]
+This bit indicates that the application will only share completion
+queues and counters among endpoints, transmit contexts, and receive
+contexts that have the same set of capability flags.
+.RS
+.RE
+.TP
+.B \f[I]FI_BUFFERED_RECV\f[]
+The buffered receive mode bit indicates that the provider owns the data
+buffer(s) that are accessed by the networking layer for received
+messages.
+Typically, this implies that data must be copied from the provider
+buffer into the application buffer.
+Applications that can handle message processing from network allocated
+data buffers can set this mode bit to avoid copies.
+For full details on application requirements to support this mode, see
+the \[aq]Buffered Receives\[aq] section in \f[C]fi_msg\f[](3).
+This mode bit applies to FI_MSG and FI_TAGGED receive operations.
+.RS
+.RE
 .SH ADDRESSING FORMATS
 .PP
 Multiple fabric interfaces take as input either a source or destination
@@ -587,9 +756,10 @@ A provider may support one or more of the following addressing formats.
 In some cases, a selected addressing format may need to be translated or
 mapped into an address which is native to the fabric.
 See \f[C]fi_av\f[](3).
-.PP
-\f[I]FI_FORMAT_UNSPEC\f[] : FI_FORMAT_UNSPEC indicates that a provider
-specific address format should be selected.
+.TP
+.B \f[I]FI_FORMAT_UNSPEC\f[]
+FI_FORMAT_UNSPEC indicates that a provider specific address format
+should be selected.
 Provider specific addresses may be protocol specific or a vendor
 proprietary format.
 Applications that select FI_FORMAT_UNSPEC should be prepared to treat
@@ -598,27 +768,49 @@ FI_FORMAT_UNSPEC targets apps which make use of an out of band address
 exchange.
 Applications which use FI_FORMAT_UNSPEC may use fi_getname() to obtain a
 provider specific address assigned to an allocated endpoint.
-.PP
-\f[I]FI_SOCKADDR\f[] : Address is of type sockaddr.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKADDR\f[]
+Address is of type sockaddr.
 The specific socket address format will be determined at run time by
 interfaces examining the sa_family field.
-.PP
-\f[I]FI_SOCKADDR_IN\f[] : Address is of type sockaddr_in (IPv4).
-.PP
-\f[I]FI_SOCKADDR_IN6\f[] : Address is of type sockaddr_in6 (IPv6).
-.PP
-\f[I]FI_SOCKADDR_IB\f[] : Address is of type sockaddr_ib (defined in
-Linux kernel source)
-.PP
-\f[I]FI_ADDR_PSMX\f[] : Address is an Intel proprietary format that is
-used with their PSMX (extended performance scaled messaging) protocol.
-.PP
-\f[I]FI_ADDR_GNI\f[] : Address is a Cray proprietary format that is used
-with their GNI protocol.
-.PP
-\f[I]FI_ADDR_STR\f[] : Address is a formatted character string.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKADDR_IN\f[]
+Address is of type sockaddr_in (IPv4).
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKADDR_IN6\f[]
+Address is of type sockaddr_in6 (IPv6).
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKADDR_IB\f[]
+Address is of type sockaddr_ib (defined in Linux kernel source)
+.RS
+.RE
+.TP
+.B \f[I]FI_ADDR_PSMX\f[]
+Address is an Intel proprietary format that is used with their PSMX
+(extended performance scaled messaging) protocol.
+.RS
+.RE
+.TP
+.B \f[I]FI_ADDR_GNI\f[]
+Address is a Cray proprietary format that is used with their GNI
+protocol.
+.RS
+.RE
+.TP
+.B \f[I]FI_ADDR_STR\f[]
+Address is a formatted character string.
 The length and content of the string is address and/or provider
 specific, but in general follows a URI model:
+.RS
+.RE
 .IP
 .nf
 \f[C]
@@ -638,26 +830,34 @@ should be used to filter by provider if necessary.
 The operation of the fi_getinfo call may be controlled through the use
 of input flags.
 Valid flags include the following.
-.PP
-\f[I]FI_NUMERICHOST\f[] : Indicates that the node parameter is a numeric
-string representation of a fabric address, such as a dotted decimal IP
-address.
+.TP
+.B \f[I]FI_NUMERICHOST\f[]
+Indicates that the node parameter is a numeric string representation of
+a fabric address, such as a dotted decimal IP address.
 Use of this flag will suppress any lengthy name resolution protocol.
-.PP
-\f[I]FI_SOURCE\f[] : Indicates that the node and service parameters
-specify the local source address to associate with an endpoint.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOURCE\f[]
+Indicates that the node and service parameters specify the local source
+address to associate with an endpoint.
 If specified, either the node and/or service parameter must be
 non\-NULL.
 This flag is often used with passive endpoints.
-.PP
-\f[I]FI_PROV_ATTR_ONLY\f[] : Indicates that the caller is only querying
-for what providers are potentially available.
+.RS
+.RE
+.TP
+.B \f[I]FI_PROV_ATTR_ONLY\f[]
+Indicates that the caller is only querying for what providers are
+potentially available.
 All providers will return exactly one fi_info struct, regardless of
 whether that provider is usable on the current platform or not.
 The returned fi_info struct will contain default values for all members,
 with the exception of fabric_attr.
 The fabric_attr member will have the prov_name and prov_version values
 filled in.
+.RS
+.RE
 .SH RETURN VALUE
 .PP
 fi_getinfo() returns 0 on success.
@@ -673,20 +873,28 @@ structure on success, or NULL on error.
 Both calls require that the returned fi_info structure be freed via
 fi_freeinfo().
 .SH ERRORS
-.PP
-\f[I]FI_EBADFLAGS\f[] : The specified endpoint or domain capability or
-operation flags are invalid.
-.PP
-\f[I]FI_ENOMEM\f[] : Indicates that there was insufficient memory to
-complete the operation.
-.PP
-\f[I]FI_ENODATA\f[] : Indicates that no providers could be found which
-support the requested fabric information.
+.TP
+.B \f[I]FI_EBADFLAGS\f[]
+The specified endpoint or domain capability or operation flags are
+invalid.
+.RS
+.RE
+.TP
+.B \f[I]FI_ENOMEM\f[]
+Indicates that there was insufficient memory to complete the operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_ENODATA\f[]
+Indicates that no providers could be found which support the requested
+fabric information.
+.RS
+.RE
 .SH NOTES
 .PP
 If hints are provided, the operation will be controlled by the values
 that are supplied in the various fields (see section on
-\f[I]fi\f[]info_).
+\f[I]fi_info\f[]).
 Applications that require specific communication interfaces, domains,
 capabilities or other requirements, can specify them using fields in
 \f[I]hints\f[].
@@ -709,6 +917,7 @@ Multiple threads may call \f[C]fi_getinfo\f[] simultaneously, without
 any requirement for serialization.
 .SH SEE ALSO
 .PP
-\f[C]fi_open\f[](3), \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3)
+\f[C]fi_open\f[](3), \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3),
+\f[C]fi_nic\f[](3)
 .SH AUTHORS
 OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_mr.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_mr.3
index a6ce08d92..9d72acd3e 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_mr.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_mr.3
@@ -1,33 +1,61 @@
-.TH "fi_mr" "3" "2018\-02\-13" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_mr" "3" "2018\-10\-15" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_mr \- Memory region operations
-.PP
-fi_mr_reg / fi_mr_regv / fi_mr_regattr : Register local memory buffers
-for direct fabric access
-.PP
-fi_close : Deregister registered memory buffers.
-.PP
-fi_mr_desc : Return a local descriptor associated with a registered
-memory region
-.PP
-fi_mr_key : Return the remote key needed to access a registered memory
-region
-.PP
-fi_mr_raw_attr : Return raw memory region attributes.
-.PP
-fi_mr_map_raw : Converts a raw memory region key into a key that is
-usable for data transfer operations.
-.PP
-fi_mr_unmap_key : Releases a previously mapped raw memory region key.
-.PP
-fi_mr_bind : Associate a registered memory region with a completion
-counter.
-.PP
-fi_mr_refresh : Updates the memory pages associated with a memory
-region.
-.PP
-fi_mr_enable : Enables a memory region for use.
+.TP
+.B fi_mr_reg / fi_mr_regv / fi_mr_regattr
+Register local memory buffers for direct fabric access
+.RS
+.RE
+.TP
+.B fi_close
+Deregister registered memory buffers.
+.RS
+.RE
+.TP
+.B fi_mr_desc
+Return a local descriptor associated with a registered memory region
+.RS
+.RE
+.TP
+.B fi_mr_key
+Return the remote key needed to access a registered memory region
+.RS
+.RE
+.TP
+.B fi_mr_raw_attr
+Return raw memory region attributes.
+.RS
+.RE
+.TP
+.B fi_mr_map_raw
+Converts a raw memory region key into a key that is usable for data
+transfer operations.
+.RS
+.RE
+.TP
+.B fi_mr_unmap_key
+Releases a previously mapped raw memory region key.
+.RS
+.RE
+.TP
+.B fi_mr_bind
+Associate a registered memory region with a completion counter.
+.RS
+.RE
+.TP
+.B fi_mr_refresh
+Updates the memory pages associated with a memory region.
+.RS
+.RE
+.TP
+.B fi_mr_enable
+Enables a memory region for use.
+.RS
+.RE
 .SH SYNOPSIS
 .IP
 .nf
@@ -68,36 +96,72 @@ int\ fi_mr_enable(struct\ fid_mr\ *mr);
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]domain\f[] : Resource domain
-.PP
-\f[I]mr\f[] : Memory region
-.PP
-\f[I]bfid\f[] : Fabric identifier of an associated resource.
-.PP
-\f[I]context\f[] : User specified context associated with the memory
-region.
-.PP
-\f[I]buf\f[] : Memory buffer to register with the fabric hardware
-.PP
-\f[I]len\f[] : Length of memory buffer to register
-.PP
-\f[I]iov\f[] : Vectored memory buffer.
-.PP
-\f[I]count\f[] : Count of vectored buffer entries.
-.PP
-\f[I]access\f[] : Memory access permissions associated with registration
-.PP
-\f[I]offset\f[] : Optional specified offset for accessing specified
-registered buffers.
+.TP
+.B \f[I]domain\f[]
+Resource domain
+.RS
+.RE
+.TP
+.B \f[I]mr\f[]
+Memory region
+.RS
+.RE
+.TP
+.B \f[I]bfid\f[]
+Fabric identifier of an associated resource.
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified context associated with the memory region.
+.RS
+.RE
+.TP
+.B \f[I]buf\f[]
+Memory buffer to register with the fabric hardware
+.RS
+.RE
+.TP
+.B \f[I]len\f[]
+Length of memory buffer to register
+.RS
+.RE
+.TP
+.B \f[I]iov\f[]
+Vectored memory buffer.
+.RS
+.RE
+.TP
+.B \f[I]count\f[]
+Count of vectored buffer entries.
+.RS
+.RE
+.TP
+.B \f[I]access\f[]
+Memory access permissions associated with registration
+.RS
+.RE
+.TP
+.B \f[I]offset\f[]
+Optional specified offset for accessing specified registered buffers.
 This parameter is reserved for future use and must be 0.
-.PP
-\f[I]requested_key\f[] : Optional requested remote key associated with
-registered buffers.
-.PP
-\f[I]attr\f[] : Memory region attributes
-.PP
-\f[I]flags\f[] : Additional flags to apply to the operation.
+.RS
+.RE
+.TP
+.B \f[I]requested_key\f[]
+Optional requested remote key associated with registered buffers.
+.RS
+.RE
+.TP
+.B \f[I]attr\f[]
+Memory region attributes
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply to the operation.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Registered memory regions associate memory buffers with permissions
@@ -110,9 +174,9 @@ Memory registration restrictions are controlled using a separate set of
 mode bits, specified through the domain attributes (mr_mode field).
 .PP
 The following apply to memory registration.
-.PP
-\f[I]Scalable Memory Registration\f[] : By default, memory registration
-is considered scalable.
+.TP
+.B \f[I]Scalable Memory Registration\f[]
+By default, memory registration is considered scalable.
 (For library versions 1.4 and earlier, this is indicated by setting
 mr_mode to FI_MR_SCALABLE, with the fi_info mode bit FI_LOCAL_MR set to
 0).
@@ -121,6 +185,8 @@ mr_mode bits being set.
 The setting of mr_mode bits therefore adjusts application behavior as
 described below.
 Default, scalable registration has several properties.
+.RS
+.RE
 .PP
 In scalable mode, registration occurs on memory address ranges.
 Because registration refers to memory regions, versus data buffers, the
@@ -144,15 +210,17 @@ registered.
 This includes source buffers for all transmit operations \-\- sends,
 tagged sends, RMA, and atomics \-\- as well as buffers posted for
 receive and tagged receive operations.
-.PP
-\f[I]FI_MR_LOCAL\f[] : When the FI_MR_LOCAL mode bit is set,
-applications must register all data buffers that will be accessed by the
-local hardware and provide a valid mem_desc parameter into applicable
-data transfer operations.
+.TP
+.B \f[I]FI_MR_LOCAL\f[]
+When the FI_MR_LOCAL mode bit is set, applications must register all
+data buffers that will be accessed by the local hardware and provide a
+valid mem_desc parameter into applicable data transfer operations.
 When FI_MR_LOCAL is zero, applications are not required to register data
 buffers before using them for local operations (e.g.
 send and receive data buffers), and the mem_desc parameter into data
 transfer operations is ignored.
+.RS
+.RE
 .PP
 A provider may hide local registration requirements from applications by
 making use of an internal registration cache or similar mechanisms.
@@ -166,38 +234,48 @@ registration calls.
 Note: the FI_MR_LOCAL mr_mode bit replaces the FI_LOCAL_MR fi_info mode
 bit.
 When FI_MR_LOCAL is set, FI_LOCAL_MR is ignored.
-.PP
-\f[I]FI_MR_RAW\f[] : Raw memory regions are used to support providers
-with keys larger than 64\-bits or require setup at the peer.
+.TP
+.B \f[I]FI_MR_RAW\f[]
+Raw memory regions are used to support providers with keys larger than
+64\-bits or require setup at the peer.
 When the FI_MR_RAW bit is set, applications must use fi_mr_raw_attr()
 locally and fi_mr_map_raw() at the peer before targeting a memory region
 as part of any data transfer request.
-.PP
-\f[I]FI_MR_VIRT_ADDR\f[] : The FI_MR_VIRT_ADDR bit indicates that the
-provider references memory regions by virtual address, rather than a
-0\-based offset.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_VIRT_ADDR\f[]
+The FI_MR_VIRT_ADDR bit indicates that the provider references memory
+regions by virtual address, rather than a 0\-based offset.
 Peers that target memory regions registered with FI_MR_VIRT_ADDR specify
 the destination memory buffer using the target\[aq]s virtual address,
 with any offset into the region specified as virtual address + offset.
 Support of this bit typically implies that peers must exchange
 addressing data prior to initiating any RMA or atomic operation.
-.PP
-\f[I]FI_MR_ALLOCATED\f[] : When set, all registered memory regions must
-be backed by physical memory pages at the time the registration call is
-made.
-.PP
-\f[I]FI_MR_PROV_KEY\f[] : This memory region mode indicates that the
-provider does not support application requested MR keys.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_ALLOCATED\f[]
+When set, all registered memory regions must be backed by physical
+memory pages at the time the registration call is made.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_PROV_KEY\f[]
+This memory region mode indicates that the provider does not support
+application requested MR keys.
 MR keys are returned by the provider.
 Applications that support FI_MR_PROV_KEY can obtain the provider key
 using fi_mr_key(), unless FI_MR_RAW is also set.
 The returned key should then be exchanged with peers prior to initiating
 an RMA or atomic operation.
-.PP
-\f[I]FI_MR_MMU_NOTIFY\f[] : FI_MR_MMU_NOTIFY is typically set by
-providers that support memory registration against memory regions that
-are not necessarily backed by allocated physical pages at the time the
-memory registration occurs.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_MMU_NOTIFY\f[]
+FI_MR_MMU_NOTIFY is typically set by providers that support memory
+registration against memory regions that are not necessarily backed by
+allocated physical pages at the time the memory registration occurs.
 (That is, FI_MR_ALLOCATED is typically 0).
 However, such providers require that applications notify the provider
 prior to the MR being accessed as part of a data transfer operation.
@@ -206,10 +284,12 @@ now back the region.
 The notification is necessary for providers that cannot hook directly
 into the operating system page tables or memory management unit.
 See fi_mr_refresh() for notification details.
-.PP
-\f[I]FI_MR_RMA_EVENT\f[] : This mode bit indicates that the provider
-must configure memory regions that are associated with RMA events prior
-to their use.
+.RS
+.RE
+.TP
+.B \f[I]FI_MR_RMA_EVENT\f[]
+This mode bit indicates that the provider must configure memory regions
+that are associated with RMA events prior to their use.
 This includes all memory regions that are associated with completion
 counters.
 When set, applications must indicate if a memory region will be
@@ -217,22 +297,27 @@ associated with a completion counter as part of the region\[aq]s
 creation.
 This is done by passing in the FI_RMA_EVENT flag to the memory
 registration call.
+.RS
+.RE
 .PP
 Such memory regions will be created in a disabled state and must be
 associated with all completion counters prior to being enabled.
 To enable a memory region, the application must call fi_mr_enable().
 After calling fi_mr_enable(), no further resource bindings may be made
 to the memory region.
-.PP
-\f[I]FI_MR_ENDPOINT\f[] : This mode bit indicates that the provider
-associates memory regions with endpoints rather than domains.
+.TP
+.B \f[I]FI_MR_ENDPOINT\f[]
+This mode bit indicates that the provider associates memory regions with
+endpoints rather than domains.
 Memory regions that are registered with the provider are created in a
 disabled state and must be bound to an endpoint prior to being enabled.
 To bind the MR with an endpoint, the application must use fi_mr_bind().
 To enable the memory region, the application must call fi_mr_enable().
-.PP
-\f[I]Basic Memory Registration\f[] : Basic memory registration is
-indicated by the FI_MR_BASIC mr_mode bit.
+.RS
+.RE
+.TP
+.B \f[I]Basic Memory Registration\f[]
+Basic memory registration is indicated by the FI_MR_BASIC mr_mode bit.
 FI_MR_BASIC is maintained for backwards compatibility (libfabric version
 1.4 or earlier).
 The behavior of basic registration is equivalent to setting the
@@ -246,6 +331,8 @@ Other mr_mode bit pairings are invalid.
 Unlike other mr_mode bits, if FI_MR_BASIC is set on input to
 fi_getinfo(), it will not be cleared by the provider.
 That is, setting FI_MR_BASIC to one requests basic registration.
+.RS
+.RE
 .PP
 The registrations functions \-\- fi_mr_reg, fi_mr_regv, and
 fi_mr_regattr \-\- are used to register one or more memory regions with
@@ -363,6 +450,15 @@ Use of this call is required if the FI_RAW_MR mode bit has been set by
 the provider; however, it is safe to use this call with any memory
 region.
 .PP
+On input, the key_size parameter should indicate the size of the raw_key
+buffer.
+If the actual key is larger than what can fit into the buffer, it will
+return \-FI_ETOOSMALL.
+On output, key_size is set to the size of the buffer needed to store the
+key, which may be larger than the input value.
+The needed key_size can also be obtained through the mr_key_size domain
+attribute (fi_domain_attr) field.
+.PP
 A raw key must be mapped by a peer before it can be used in data
 transfer operations.
 See fi_mr_map_raw below.
@@ -394,11 +490,14 @@ with endpoints (see FI_MR_ENDPOINT).
 .PP
 When binding with a counter, the type of events tracked against the
 memory region is based on the bitwise OR of the following flags.
-.PP
-\f[I]FI_REMOTE_WRITE\f[] : Generates an event whenever a remote RMA
-write or atomic operation modifies the memory region.
+.TP
+.B \f[I]FI_REMOTE_WRITE\f[]
+Generates an event whenever a remote RMA write or atomic operation
+modifies the memory region.
 Use of this flag requires that the endpoint through which the MR is
 accessed be created with the FI_RMA_EVENT capability.
+.RS
+.RE
 .PP
 When binding the memory region to an endpoint, flags should be 0.
 .SS fi_mr_refresh
@@ -442,6 +541,7 @@ struct\ fi_mr_attr\ {
 \ \ \ \ const\ struct\ iovec\ *mr_iov;
 \ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ \ \ \ iov_count;
 \ \ \ \ uint64_t\ \ \ \ \ \ \ \ \ \ \ access;
+\ \ \ \ uint64_t\ \ \ \ \ \ \ \ \ \ \ offset;
 \ \ \ \ uint64_t\ \ \ \ \ \ \ \ \ \ \ requested_key;
 \ \ \ \ void\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ *context;
 \ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ \ \ \ auth_key_size;
@@ -465,26 +565,45 @@ See \f[C]fi_domain(3)\f[].
 Indicates the type of access that the local or a peer endpoint has to
 the registered memory region.
 Supported access permissions are the bitwise OR of the following flags:
-.PP
-\f[I]FI_SEND\f[] : The memory buffer may be used in outgoing message
-data transfers.
+.TP
+.B \f[I]FI_SEND\f[]
+The memory buffer may be used in outgoing message data transfers.
 This includes fi_msg and fi_tagged operations.
-.PP
-\f[I]FI_RECV\f[] : The memory buffer may be used to receive inbound
-message transfers.
+.RS
+.RE
+.TP
+.B \f[I]FI_RECV\f[]
+The memory buffer may be used to receive inbound message transfers.
 This includes fi_msg and fi_tagged operations.
-.PP
-\f[I]FI_READ\f[] : The memory buffer may be used as the result buffer
-for RMA read and atomic operations on the initiator side.
-.PP
-\f[I]FI_WRITE\f[] : The memory buffer may be used as the source buffer
-for RMA write and atomic operations on the initiator side.
-.PP
-\f[I]FI_REMOTE_READ\f[] : The memory buffer may be used as the source
-buffer of an RMA read operation on the target side.
-.PP
-\f[I]FI_REMOTE_WRITE\f[] : The memory buffer may be used as the target
-buffer of an RMA write or atomic operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_READ\f[]
+The memory buffer may be used as the result buffer for RMA read and
+atomic operations on the initiator side.
+.RS
+.RE
+.TP
+.B \f[I]FI_WRITE\f[]
+The memory buffer may be used as the source buffer for RMA write and
+atomic operations on the initiator side.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_READ\f[]
+The memory buffer may be used as the source buffer of an RMA read
+operation on the target side.
+.RS
+.RE
+.TP
+.B \f[I]FI_REMOTE_WRITE\f[]
+The memory buffer may be used as the target buffer of an RMA write or
+atomic operation.
+.RS
+.RE
+.SS offset
+.PP
+The offset field is reserved for future use and must be 0.
 .SS requested_key
 .PP
 An application specified access key associated with the memory region.
@@ -547,16 +666,21 @@ footprint overhead, making it less desirable for highly scalable apps.
 .SH FLAGS
 .PP
 The follow flag may be specified to any memory registration call.
-.PP
-\f[I]FI_RMA_EVENT\f[] : This flag indicates that the specified memory
-region will be associated with a completion counter used to count RMA
-operations that access the MR.
-.PP
-\f[I]FI_RMA_PMEM\f[] : This flag indicates that the underlying memory
-region is backed by persistent memory and will be used in RMA
-operations.
+.TP
+.B \f[I]FI_RMA_EVENT\f[]
+This flag indicates that the specified memory region will be associated
+with a completion counter used to count RMA operations that access the
+MR.
+.RS
+.RE
+.TP
+.B \f[I]FI_RMA_PMEM\f[]
+This flag indicates that the underlying memory region is backed by
+persistent memory and will be used in RMA operations.
 It must be specified if persistent completion semantics or persistent
 data transfers are required when accessing the registered region.
+.RS
+.RE
 .SH RETURN VALUES
 .PP
 Returns 0 on success.
@@ -564,18 +688,29 @@ On error, a negative value corresponding to fabric errno is returned.
 .PP
 Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
 .SH ERRORS
-.PP
-\f[I]\-FI_ENOKEY\f[] : The requested_key is already in use.
-.PP
-\f[I]\-FI_EKEYREJECTED\f[] : The requested_key is not available.
+.TP
+.B \f[I]\-FI_ENOKEY\f[]
+The requested_key is already in use.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_EKEYREJECTED\f[]
+The requested_key is not available.
 They key may be out of the range supported by the provider, or the
 provider may not support user\-requested memory registration keys.
-.PP
-\f[I]\-FI_ENOSYS\f[] : Returned by fi_mr_bind if the provider does not
-support reporting events based on access to registered memory regions.
-.PP
-\f[I]\-FI_EBADFLAGS\f[] : Returned if the specified flags are not
-supported by the provider.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_ENOSYS\f[]
+Returned by fi_mr_bind if the provider does not support reporting events
+based on access to registered memory regions.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_EBADFLAGS\f[]
+Returned if the specified flags are not supported by the provider.
+.RS
+.RE
 .SH SEE ALSO
 .PP
 \f[C]fi_getinfo\f[](3), \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_msg.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_msg.3
index 4c35ad6ff..c89d44c44 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_msg.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_msg.3
@@ -1,4 +1,7 @@
-.TH "fi_msg" "3" "2018\-01\-08" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_msg" "3" "2018\-11\-28" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_msg \- Message data transfer operations
@@ -48,40 +51,74 @@ ssize_t\ fi_injectdata(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ len,
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]ep\f[] : Fabric endpoint on which to initiate send or post receive
-buffer.
-.PP
-\f[I]buf\f[] : Data buffer to send or receive.
-.PP
-\f[I]len\f[] : Length of data buffer to send or receive, specified in
-bytes.
+.TP
+.B \f[I]ep\f[]
+Fabric endpoint on which to initiate send or post receive buffer.
+.RS
+.RE
+.TP
+.B \f[I]buf\f[]
+Data buffer to send or receive.
+.RS
+.RE
+.TP
+.B \f[I]len\f[]
+Length of data buffer to send or receive, specified in bytes.
 Valid transfers are from 0 bytes up to the endpoint\[aq]s max_msg_size.
-.PP
-\f[I]iov\f[] : Vectored data buffer.
-.PP
-\f[I]count\f[] : Count of vectored data entries.
-.PP
-\f[I]desc\f[] : Descriptor associated with the data buffer
-.PP
-\f[I]data\f[] : Remote CQ data to transfer with the sent message.
-.PP
-\f[I]dest_addr\f[] : Destination address for connectionless transfers.
+.RS
+.RE
+.TP
+.B \f[I]iov\f[]
+Vectored data buffer.
+.RS
+.RE
+.TP
+.B \f[I]count\f[]
+Count of vectored data entries.
+.RS
+.RE
+.TP
+.B \f[I]desc\f[]
+Descriptor associated with the data buffer
+.RS
+.RE
+.TP
+.B \f[I]data\f[]
+Remote CQ data to transfer with the sent message.
+.RS
+.RE
+.TP
+.B \f[I]dest_addr\f[]
+Destination address for connectionless transfers.
 Ignored for connected endpoints.
-.PP
-\f[I]src_addr\f[] : Source address to receive from for connectionless
-transfers.
+.RS
+.RE
+.TP
+.B \f[I]src_addr\f[]
+Source address to receive from for connectionless transfers.
 Applies only to connectionless endpoints with the FI_DIRECTED_RECV
 capability enabled, otherwise this field is ignored.
 If set to FI_ADDR_UNSPEC, any source address may match.
-.PP
-\f[I]msg\f[] : Message descriptor for send and receive operations.
-.PP
-\f[I]flags\f[] : Additional flags to apply for the send or receive
-operation.
-.PP
-\f[I]context\f[] : User specified pointer to associate with the
-operation.
+.RS
+.RE
+.TP
+.B \f[I]msg\f[]
+Message descriptor for send and receive operations.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply for the send or receive operation.
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified pointer to associate with the operation.
+This parameter is ignored if the operation will not generate a
+successful completion, unless an op flag specifies the context parameter
+be used for required input.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 The send functions \-\- fi_send, fi_sendv, fi_sendmsg, fi_inject, and
@@ -152,8 +189,7 @@ The send inject call is an optimized version of fi_send.
 The fi_inject function behaves as if the FI_INJECT transfer flag were
 set, and FI_COMPLETION were not.
 That is, the data buffer is available for reuse immediately on returning
-from from fi_inject, and no completion event will be generated for this
-send.
+from fi_inject, and no completion event will be generated for this send.
 The completion event will be suppressed even if the CQ was bound without
 FI_SELECTIVE_COMPLETION or the endpoint\[aq]s op_flags contain
 FI_COMPLETION.
@@ -200,32 +236,62 @@ previously configured with the endpoint, except where noted (see
 fi_endpoint.3).
 The following list of flags are usable with fi_recvmsg and/or
 fi_sendmsg.
-.PP
-\f[I]FI_REMOTE_CQ_DATA\f[] : Applies to fi_sendmsg and fi_senddata.
+.TP
+.B \f[I]FI_REMOTE_CQ_DATA\f[]
+Applies to fi_sendmsg and fi_senddata.
 Indicates that remote CQ data is available and should be sent as part of
 the request.
 See fi_getinfo for additional details on FI_REMOTE_CQ_DATA.
-.PP
-\f[I]FI_COMPLETION\f[] : Indicates that a completion entry should be
-generated for the specified operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_CLAIM\f[]
+Applies to posted receive operations for endpoints configured for
+FI_BUFFERED_RECV or FI_VARIABLE_MSG.
+This flag is used to retrieve a message that was buffered by the
+provider.
+See the Buffered Receives section for details.
+.RS
+.RE
+.TP
+.B \f[I]FI_COMPLETION\f[]
+Indicates that a completion entry should be generated for the specified
+operation.
 The endpoint must be bound to a completion queue with
 FI_SELECTIVE_COMPLETION that corresponds to the specified operation, or
 this flag is ignored.
-.PP
-\f[I]FI_MORE\f[] : Indicates that the user has additional requests that
-will immediately be posted after the current call returns.
+.RS
+.RE
+.TP
+.B \f[I]FI_DISCARD\f[]
+Applies to posted receive operations for endpoints configured for
+FI_BUFFERED_RECV or FI_VARIABLE_MSG.
+This flag is used to free a message that was buffered by the provider.
+See the Buffered Receives section for details.
+.RS
+.RE
+.TP
+.B \f[I]FI_MORE\f[]
+Indicates that the user has additional requests that will immediately be
+posted after the current call returns.
 Use of this flag may improve performance by enabling the provider to
 optimize its access to the fabric hardware.
-.PP
-\f[I]FI_INJECT\f[] : Applies to fi_sendmsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_INJECT\f[]
+Applies to fi_sendmsg.
 Indicates that the outbound data buffer should be returned to user
 immediately after the send call returns, even if the operation is
 handled asynchronously.
 This may require that the underlying provider implementation copy the
 data into a local buffer and transfer out of that buffer.
 This flag can only be used with messages smaller than inject_size.
-.PP
-\f[I]FI_MULTI_RECV\f[] : Applies to posted receive operations.
+.RS
+.RE
+.TP
+.B \f[I]FI_MULTI_RECV\f[]
+Applies to posted receive operations.
 This flag allows the user to post a single buffer that will receive
 multiple incoming messages.
 Received messages will be packed into the receive buffer until the
@@ -234,6 +300,8 @@ Use of this flag may cause a single posted receive operation to generate
 multiple events as messages are placed into the buffer.
 The placement of received data into the buffer may be subjected to
 provider specific alignment restrictions.
+.RS
+.RE
 .PP
 The buffer will be released by the provider when the available buffer
 space falls below the specified minimum (see FI_OPT_MIN_MULTI_RECV).
@@ -242,37 +310,175 @@ always be generated when the buffer has been consumed, even if other
 receive completions have been suppressed (i.e.
 the Rx context has been configured for FI_SELECTIVE_COMPLETION).
 See the FI_MULTI_RECV completion flag \f[C]fi_cq\f[](3).
-.PP
-\f[I]FI_INJECT_COMPLETE\f[] : Applies to fi_sendmsg.
+.TP
+.B \f[I]FI_INJECT_COMPLETE\f[]
+Applies to fi_sendmsg.
 Indicates that a completion should be generated when the source
 buffer(s) may be reused.
-.PP
-\f[I]FI_TRANSMIT_COMPLETE\f[] : Applies to fi_sendmsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_TRANSMIT_COMPLETE\f[]
+Applies to fi_sendmsg.
 Indicates that a completion should not be generated until the operation
 has been successfully transmitted and is no longer being tracked by the
 provider.
-.PP
-\f[I]FI_DELIVERY_COMPLETE\f[] : Applies to fi_sendmsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_DELIVERY_COMPLETE\f[]
+Applies to fi_sendmsg.
 Indicates that a completion should be generated when the operation has
 been processed by the destination.
-.PP
-\f[I]FI_FENCE\f[] : Applies to transmits.
+.RS
+.RE
+.TP
+.B \f[I]FI_FENCE\f[]
+Applies to transmits.
 Indicates that the requested operation, also known as the fenced
 operation, and any operation posted after the fenced operation will be
 deferred until all previous operations targeting the same peer endpoint
 have completed.
 Operations posted after the fencing will see and/or replace the results
 of any operations initiated prior to the fenced operation.
+.RS
+.RE
 .PP
 The ordering of operations starting at the posting of the fenced
 operation (inclusive) to the posting of a subsequent fenced operation
 (exclusive) is controlled by the endpoint\[aq]s ordering semantics.
-.PP
-\f[I]FI_MULTICAST\f[] : Applies to transmits.
+.TP
+.B \f[I]FI_MULTICAST\f[]
+Applies to transmits.
 This flag indicates that the address specified as the data transfer
 destination is a multicast address.
 This flag must be used in all multicast transfers, in conjunction with a
 multicast fi_addr_t.
+.RS
+.RE
+.SH Buffered Receives
+.PP
+Buffered receives indicate that the networking layer allocates and
+manages the data buffers used to receive network data transfers.
+As a result, received messages must be copied from the network buffers
+into application buffers for processing.
+However, applications can avoid this copy if they are able to process
+the message in place (directly from the networking buffers).
+.PP
+Handling buffered receives differs based on the size of the message
+being sent.
+In general, smaller messages are passed directly to the application for
+processing.
+However, for large messages, an application will only receive the start
+of the message and must claim the rest.
+The details for how small messages are reported and large messages may
+be claimed are described below.
+.PP
+When a provider receives a message, it will write an entry to the
+completion queue associated with the receiving endpoint.
+For discussion purposes, the completion queue is assumed to be
+configured for FI_CQ_FORMAT_DATA.
+Since buffered receives are not associated with application posted
+buffers, the CQ entry op_context will point to a struct fi_recv_context.
+.IP
+.nf
+\f[C]
+struct\ fi_recv_context\ {
+\ \ \ \ struct\ fid_ep\ *ep;
+\ \ \ \ void\ *context;
+};
+\f[]
+.fi
+.PP
+The \[aq]ep\[aq] field will point to the receiving endpoint or Rx
+context, and \[aq]context\[aq] will be NULL.
+The CQ entry\[aq]s \[aq]buf\[aq] will point to a provider managed buffer
+where the start of the received message is located, and \[aq]len\[aq]
+will be set to the total size of the message.
+.PP
+The maximum sized message that a provider can buffer is limited by an
+FI_OPT_BUFFERED_LIMIT.
+This threshold can be obtained and may be adjusted by the application
+using the fi_getopt and fi_setopt calls, respectively.
+Any adjustments must be made prior to enabling the endpoint.
+The CQ entry \[aq]buf\[aq] will point to a buffer of received data.
+If the sent message is larger than the buffered amount, the CQ entry
+\[aq]flags\[aq] will have the FI_MORE bit set.
+When the FI_MORE bit is set, \[aq]buf\[aq] will reference at least
+FI_OPT_BUFFERED_MIN bytes of data (see fi_endpoint.3 for more info).
+.PP
+After being notified that a buffered receive has arrived, applications
+must either claim or discard the message.
+Typically, small messages are processed and discarded, while large
+messages are claimed.
+However, an application is free to claim or discard any message
+regardless of message size.
+.PP
+To claim a message, an application must post a receive operation with
+the FI_CLAIM flag set.
+The struct fi_recv_context returned as part of the notification must be
+provided as the receive operation\[aq]s context.
+The struct fi_recv_context contains a \[aq]context\[aq] field.
+Applications may modify this field prior to claiming the message.
+When the claim operation completes, a standard receive completion entry
+will be generated on the completion queue.
+The \[aq]context\[aq] of the associated CQ entry will be set to the
+\[aq]context\[aq] value passed in through the fi_recv_context structure,
+and the CQ entry flags will have the FI_CLAIM bit set.
+.PP
+Buffered receives that are not claimed must be discarded by the
+application when it is done processing the CQ entry data.
+To discard a message, an application must post a receive operation with
+the FI_DISCARD flag set.
+The struct fi_recv_context returned as part of the notification must be
+provided as the receive operation\[aq]s context.
+When the FI_DISCARD flag is set for a receive operation, the receive
+input buffer(s) and length parameters are ignored.
+.PP
+IMPORTANT: Buffered receives must be claimed or discarded in a timely
+manner.
+Failure to do so may result in increased memory usage for network
+buffering or communication stalls.
+Once a buffered receive has been claimed or discarded, the original CQ
+entry \[aq]buf\[aq] or struct fi_recv_context data may no longer be
+accessed by the application.
+.PP
+The use of the FI_CLAIM and FI_DISCARD operation flags is also described
+with respect to tagged message transfers in fi_tagged.3.
+Buffered receives of tagged messages will include the message tag as
+part of the CQ entry, if available.
+.PP
+The handling of buffered receives follows all message ordering
+restrictions assigned to an endpoint.
+For example, completions may indicate the order in which received
+messages arrived at the receiver based on the endpoint attributes.
+.SH Variable Length Messages
+.PP
+Variable length messages, or simply variable messages, are transfers
+where the size of the message is unknown to the receiver prior to the
+message being sent.
+It indicates that the recipient of a message does not know the amount of
+data to expect prior to the message arriving.
+It is most commonly used when the size of message transfers varies
+greatly, with very large messages interspersed with much smaller
+messages, making receive side message buffering difficult to manage.
+Variable messages are not subject to max message length restrictions
+(i.e.
+struct fi_ep_attr::max_msg_size limits), and may be up to the maximum
+value of size_t (e.g.
+SIZE_MAX) in length.
+.PP
+Variable length messages support requests that the provider allocate and
+manage the network message buffers.
+As a result, the application requirements and provider behavior is
+identical as those defined for supporting the FI_BUFFERED_RECV mode bit.
+See the Buffered Receive section above for details.
+The main difference is that buffered receives are limited by the
+fi_ep_attr::max_msg_size threshold, whereas variable length messages are
+not.
+.PP
+Support for variable messages is indicated through the FI_VARIABLE_MSG
+capability bit.
 .SH NOTES
 .PP
 If an endpoint has been configured with FI_MSG_PREFIX, the application
@@ -291,12 +497,15 @@ Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
 .PP
 See the discussion below for details handling FI_EAGAIN.
 .SH ERRORS
-.PP
-\f[I]\-FI_EAGAIN\f[] : Indicates that the underlying provider currently
-lacks the resources needed to initiate the requested operation.
+.TP
+.B \f[I]\-FI_EAGAIN\f[]
+Indicates that the underlying provider currently lacks the resources
+needed to initiate the requested operation.
 The reasons for a provider returning FI_EAGAIN are varied.
 However, common reasons include insufficient internal buffering or full
 processing queues.
+.RS
+.RE
 .PP
 Insufficient internal buffering is often associated with operations that
 use FI_INJECT.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_nic.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_nic.3
new file mode 100644
index 000000000..4f21557f0
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_nic.3
@@ -0,0 +1,186 @@
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_nic" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
+.SH NAME
+.PP
+fi_nic \- Fabric network interface card attributes
+.SH NETWORK INTERFACE CARD ATTRIBUTES
+.PP
+The fid_nic structure defines attributes for a struct fi_info that is
+directly associated with underlying networking hardware and may be
+returned directly from calling \f[C]fi_getinfo\f[](3).
+The format of fid_nic and the related substructures are defined below.
+.PP
+Note that not all fields of all structures may be available.
+Unavailable or fields that are not applicable to the indicated device
+will be set to NULL or 0.
+.IP
+.nf
+\f[C]
+struct\ fid_nic\ {
+\ \ \ \ struct\ fid\ \ \ \ \ \ \ \ \ \ \ \ \ fid;
+\ \ \ \ struct\ fi_device_attr\ *device_attr;
+\ \ \ \ struct\ fi_bus_attr\ \ \ \ *bus_attr;
+\ \ \ \ struct\ fi_link_attr\ \ \ *link_attr;
+\ \ \ \ void\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ *prov_attr;
+};
+
+struct\ fi_device_attr\ {
+\ \ \ \ char\ *name;
+\ \ \ \ char\ *device_id;
+\ \ \ \ char\ *device_version;
+\ \ \ \ char\ *vendor_id;
+\ \ \ \ char\ *driver;
+\ \ \ \ char\ *firmware;
+};
+
+struct\ fi_pci_attr\ {
+\ \ \ \ uint16_t\ domain_id;
+\ \ \ \ uint8_t\ \ bus_id;
+\ \ \ \ uint8_t\ \ device_id;
+\ \ \ \ uint8_t\ \ function_id;
+};
+
+struct\ fi_bus_attr\ {
+\ \ \ \ enum\ fi_bus_type\ \ \ \ \ \ \ bus_type;
+\ \ \ \ union\ {
+\ \ \ \ \ \ \ \ struct\ fi_pci_attr\ pci;
+\ \ \ \ }\ attr;
+};
+
+struct\ fi_link_attr\ {
+\ \ \ \ char\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ *address;
+\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ \ \ \ mtu;
+\ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ \ \ \ speed;
+\ \ \ \ enum\ fi_link_state\ state;
+\ \ \ \ char\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ *network_type;
+};
+\f[]
+.fi
+.SS Device Attributes
+.PP
+Device attributes are used to identify the specific virtual or hardware
+NIC associated with an fi_info structure.
+.TP
+.B \f[I]name\f[]
+The operating system name associated with the device.
+This may be a logical network interface name (e.g.
+eth0 or eno1) or an absolute filename.
+.RS
+.RE
+.TP
+.B \f[I]device_id\f[]
+This is a vendor specific identifier for the device or product.
+.RS
+.RE
+.TP
+.B \f[I]device_version\f[]
+Indicates the version of the device.
+.RS
+.RE
+.TP
+.B \f[I]vendor_id\f[]
+Indicates the name of the vendor that distributes the NIC.
+.RS
+.RE
+.TP
+.B \f[I]driver\f[]
+The name of the driver associated with the device
+.RS
+.RE
+.TP
+.B \f[I]firmware\f[]
+The device\[aq]s firmware version.
+.RS
+.RE
+.SS Bus Attributes
+.PP
+The bus attributes are used to identify the physical location of the NIC
+in the system.
+.TP
+.B \f[I]bus_type\f[]
+Indicates the type of system bus where the NIC is located.
+Valid values are FI_BUS_PCI or FI_BUS_UNKNOWN.
+.RS
+.RE
+.TP
+.B \f[I]attr.pci.domain_id\f[]
+The domain where the PCI bus is located.
+Valid only if bus_type is FI_BUS_PCI.
+.RS
+.RE
+.TP
+.B \f[I]attr.pci.bus_id\f[]
+The PCI bus identifier where the device is located.
+Valid only if bus_type is FI_BUS_PCI.
+.RS
+.RE
+.TP
+.B \f[I]attr.pci.device_id\f[]
+The identifier on the PCI bus where the device is located.
+Valid only if bus_type is FI_BUS_PCI.
+.RS
+.RE
+.TP
+.B \f[I]attr.pci.function_id\f[]
+The function on the device being referenced.
+Valid only if bus_type is FI_BUS_PCI.
+.RS
+.RE
+.SS Link Attributes
+.PP
+Link attributes describe low\-level details about the network connection
+into the fabric.
+.TP
+.B \f[I]address\f[]
+The primary link\-level address associated with the NIC, such as a MAC
+address.
+If multiple addresses are available, only one will be reported.
+.RS
+.RE
+.TP
+.B \f[I]mtu\f[]
+The maximum transfer unit of link level frames or packets, in bytes.
+.RS
+.RE
+.TP
+.B \f[I]speed\f[]
+The active link data rate, given in bits per second.
+.RS
+.RE
+.TP
+.B \f[I]state\f[]
+The current physical port state.
+Possible values are FI_LINK_UNKNOWN, FI_LINK_DOWN, and FI_LINK_UP, to
+indicate if the port state is unknown or not applicable (unknown),
+inactive (down), or active (up).
+.RS
+.RE
+.TP
+.B \f[I]network_type\f[]
+Specifies the type of network interface currently active, such as
+Ethernet or InfiniBand.
+.RS
+.RE
+.SS Provider Attributes
+.PP
+Provider attributes reference provider specific details of the device.
+These attributes are both provider and device specific.
+The attributes can be interpretted by \f[C]fi_tostr\f[](3).
+Applications may also use the other attribute fields, such as related
+fi_fabric_attr: prov_name field, to determine an appropriate structure
+to cast the attributes.
+The format and definition of this field is outside the scope of the
+libfabric core framework, but may be available as part of a provider
+specific header file included with libfabric package.
+.SH NOTES
+.PP
+The fid_nic structure is returned as part of a call to
+\f[C]fi_getinfo\f[](3).
+It is automatically freed as part of calling \f[C]fi_freeinfo\f[](3)
+.SH SEE ALSO
+.PP
+\f[C]fi_getinfo\f[](3)
+.SH AUTHORS
+OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_poll.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_poll.3
index 2e0231f6f..30594f142 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_poll.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_poll.3
@@ -1,24 +1,46 @@
-.TH "fi_poll" "3" "2016\-12\-07" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_poll" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_poll \- Polling and wait set operations
-.PP
-fi_poll_open / fi_close : Open/close a polling set
-.PP
-fi_poll_add / fi_poll_del : Add/remove a completion queue or counter
-to/from a poll set.
-.PP
-fi_poll : Poll for progress and events across multiple completion queues
-and counters.
-.PP
-fi_wait_open / fi_close : Open/close a wait set
-.PP
-fi_wait : Waits for one or more wait objects in a set to be signaled.
-.PP
-fi_trywait : Indicate when it is safe to block on wait objects using
-native OS calls.
-.PP
-fi_control : Control wait set operation or attributes.
+.TP
+.B fi_poll_open / fi_close
+Open/close a polling set
+.RS
+.RE
+.TP
+.B fi_poll_add / fi_poll_del
+Add/remove a completion queue or counter to/from a poll set.
+.RS
+.RE
+.TP
+.B fi_poll
+Poll for progress and events across multiple completion queues and
+counters.
+.RS
+.RE
+.TP
+.B fi_wait_open / fi_close
+Open/close a wait set
+.RS
+.RE
+.TP
+.B fi_wait
+Waits for one or more wait objects in a set to be signaled.
+.RS
+.RE
+.TP
+.B fi_trywait
+Indicate when it is safe to block on wait objects using native OS calls.
+.RS
+.RE
+.TP
+.B fi_control
+Control wait set operation or attributes.
+.RS
+.RE
 .SH SYNOPSIS
 .IP
 .nf
@@ -51,31 +73,63 @@ int\ fi_control(struct\ fid\ *waitset,\ int\ command,\ void\ *arg);
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]fabric\f[] : Fabric provider
-.PP
-\f[I]domain\f[] : Resource domain
-.PP
-\f[I]pollset\f[] : Event poll set
-.PP
-\f[I]waitset\f[] : Wait object set
-.PP
-\f[I]attr\f[] : Poll or wait set attributes
-.PP
-\f[I]context\f[] : On success, an array of user context values
-associated with completion queues or counters.
-.PP
-\f[I]fids\f[] : An array of fabric descriptors, each one associated with
-a native wait object.
-.PP
-\f[I]count\f[] : Number of entries in context or fids array.
-.PP
-\f[I]timeout\f[] : Time to wait for a signal, in milliseconds.
-.PP
-\f[I]command\f[] : Command of control operation to perform on the wait
-set.
-.PP
-\f[I]arg\f[] : Optional control argument.
+.TP
+.B \f[I]fabric\f[]
+Fabric provider
+.RS
+.RE
+.TP
+.B \f[I]domain\f[]
+Resource domain
+.RS
+.RE
+.TP
+.B \f[I]pollset\f[]
+Event poll set
+.RS
+.RE
+.TP
+.B \f[I]waitset\f[]
+Wait object set
+.RS
+.RE
+.TP
+.B \f[I]attr\f[]
+Poll or wait set attributes
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+On success, an array of user context values associated with completion
+queues or counters.
+.RS
+.RE
+.TP
+.B \f[I]fids\f[]
+An array of fabric descriptors, each one associated with a native wait
+object.
+.RS
+.RE
+.TP
+.B \f[I]count\f[]
+Number of entries in context or fids array.
+.RS
+.RE
+.TP
+.B \f[I]timeout\f[]
+Time to wait for a signal, in milliseconds.
+.RS
+.RE
+.TP
+.B \f[I]command\f[]
+Command of control operation to perform on the wait set.
+.RS
+.RE
+.TP
+.B \f[I]arg\f[]
+Optional control argument.
+.RS
+.RE
 .SH DESCRIPTION
 .SS fi_poll_open
 .PP
@@ -93,9 +147,12 @@ struct\ fi_poll_attr\ {
 };
 \f[]
 .fi
-.PP
-\f[I]flags\f[] : Flags that set the default operation of the poll set.
+.TP
+.B \f[I]flags\f[]
+Flags that set the default operation of the poll set.
 The use of this field is reserved and must be set to 0 by the caller.
+.RS
+.RE
 .SS fi_close
 .PP
 The fi_close call releases all resources associated with a poll set.
@@ -148,25 +205,31 @@ struct\ fi_wait_attr\ {
 };
 \f[]
 .fi
-.PP
-\f[I]wait_obj\f[] : Wait sets are associated with specific wait
-object(s).
+.TP
+.B \f[I]wait_obj\f[]
+Wait sets are associated with specific wait object(s).
 Wait objects allow applications to block until the wait object is
 signaled, indicating that an event is available to be read.
 The following values may be used to specify the type of wait object
 associated with a wait set: FI_WAIT_UNSPEC, FI_WAIT_FD, and
 FI_WAIT_MUTEX_COND.
-.IP \[bu] 2
-\f[I]FI_WAIT_UNSPEC\f[] : Specifies that the user will only wait on the
-wait set using fabric interface calls, such as fi_wait.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_UNSPEC\f[]
+Specifies that the user will only wait on the wait set using fabric
+interface calls, such as fi_wait.
 In this case, the underlying provider may select the most appropriate or
 highest performing wait object available, including custom wait
 mechanisms.
 Applications that select FI_WAIT_UNSPEC are not guaranteed to retrieve
 the underlying wait object.
-.IP \[bu] 2
-\f[I]FI_WAIT_FD\f[] : Indicates that the wait set should use file
-descriptor(s) as its wait mechanism.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_FD\f[]
+Indicates that the wait set should use file descriptor(s) as its wait
+mechanism.
 It may not always be possible for a wait set to be implemented using a
 single underlying file descriptor, but all wait objects will be file
 descriptors.
@@ -174,16 +237,27 @@ File descriptor wait objects must be usable in the POSIX select(2),
 poll(2), and epoll(7) routines (if available).
 However, a provider may signal an FD wait object by marking it as
 readable or with an error.
-.IP \[bu] 2
-\f[I]FI_WAIT_MUTEX_COND\f[] : Specifies that the wait set should use a
-pthread mutex and cond variable as a wait object.
-.IP \[bu] 2
-\f[I]FI_WAIT_CRITSEC_COND\f[] : Windows specific.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_MUTEX_COND\f[]
+Specifies that the wait set should use a pthread mutex and cond variable
+as a wait object.
+.RS
+.RE
+.TP
+.B \- \f[I]FI_WAIT_CRITSEC_COND\f[]
+Windows specific.
 Specifies that the EQ should use a critical section and condition
 variable as a wait object.
-.PP
-\f[I]flags\f[] : Flags that set the default operation of the wait set.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Flags that set the default operation of the wait set.
 The use of this field is reserved and must be set to 0 by the caller.
+.RS
+.RE
 .SS fi_close
 .PP
 The fi_close call releases all resources associated with a wait set.
@@ -260,9 +334,10 @@ Access to the wait set should be serialized across all calls when
 fi_control is invoked, as it may redirect the implementation of wait set
 operations.
 The following control commands are usable with a wait set.
-.PP
-\f[I]FI_GETWAIT (void **)\f[] : This command allows the user to retrieve
-the low\-level wait object associated with the wait set.
+.TP
+.B \f[I]FI_GETWAIT (void **)\f[]
+This command allows the user to retrieve the low\-level wait object
+associated with the wait set.
 The format of the wait set is specified during wait set creation,
 through the wait set attributes.
 The fi_control arg parameter should be an address where a pointer to the
@@ -272,15 +347,20 @@ fi_mutex_cond\[aq] for FI_WAIT_MUTEX_COND.
 Support for FI_GETWAIT is provider specific and may fail if not
 supported or if the wait set is implemented using more than one wait
 object.
+.RS
+.RE
 .SH RETURN VALUES
 .PP
 Returns FI_SUCCESS on success.
 On error, a negative value corresponding to fabric errno is returned.
 .PP
 Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
-.PP
-fi_poll : On success, if events are available, returns the number of
-entries written to the context array.
+.TP
+.B fi_poll
+On success, if events are available, returns the number of entries
+written to the context array.
+.RS
+.RE
 .SH NOTES
 .SH SEE ALSO
 .PP
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_rma.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_rma.3
index b1404bdd7..0bacb8d77 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_rma.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_rma.3
@@ -1,4 +1,7 @@
-.TH "fi_rma" "3" "2018\-02\-13" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_rma" "3" "2018\-11\-28" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_rma \- Remote memory access operations
@@ -52,46 +55,86 @@ ssize_t\ fi_inject_writedata(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ l
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]ep\f[] : Fabric endpoint on which to initiate read or write
-operation.
-.PP
-\f[I]buf\f[] : Local data buffer to read into (read target) or write
-from (write source)
-.PP
-\f[I]len\f[] : Length of data to read or write, specified in bytes.
+.TP
+.B \f[I]ep\f[]
+Fabric endpoint on which to initiate read or write operation.
+.RS
+.RE
+.TP
+.B \f[I]buf\f[]
+Local data buffer to read into (read target) or write from (write
+source)
+.RS
+.RE
+.TP
+.B \f[I]len\f[]
+Length of data to read or write, specified in bytes.
 Valid transfers are from 0 bytes up to the endpoint\[aq]s max_msg_size.
-.PP
-\f[I]iov\f[] : Vectored data buffer.
-.PP
-\f[I]count\f[] : Count of vectored data entries.
-.PP
-\f[I]addr\f[] : Address of remote memory to access.
+.RS
+.RE
+.TP
+.B \f[I]iov\f[]
+Vectored data buffer.
+.RS
+.RE
+.TP
+.B \f[I]count\f[]
+Count of vectored data entries.
+.RS
+.RE
+.TP
+.B \f[I]addr\f[]
+Address of remote memory to access.
 This will be the virtual address of the remote region in the case of
 FI_MR_BASIC, or the offset from the starting address in the case of
 FI_MR_SCALABLE.
-.PP
-\f[I]key\f[] : Protection key associated with the remote memory.
-.PP
-\f[I]desc\f[] : Descriptor associated with the local data buffer
-.PP
-\f[I]data\f[] : Remote CQ data to transfer with the operation.
-.PP
-\f[I]dest_addr\f[] : Destination address for connectionless write
-transfers.
+.RS
+.RE
+.TP
+.B \f[I]key\f[]
+Protection key associated with the remote memory.
+.RS
+.RE
+.TP
+.B \f[I]desc\f[]
+Descriptor associated with the local data buffer
+.RS
+.RE
+.TP
+.B \f[I]data\f[]
+Remote CQ data to transfer with the operation.
+.RS
+.RE
+.TP
+.B \f[I]dest_addr\f[]
+Destination address for connectionless write transfers.
 Ignored for connected endpoints.
-.PP
-\f[I]src_addr\f[] : Source address to read from for connectionless
-transfers.
+.RS
+.RE
+.TP
+.B \f[I]src_addr\f[]
+Source address to read from for connectionless transfers.
 Ignored for connected endpoints.
-.PP
-\f[I]msg\f[] : Message descriptor for read and write operations.
-.PP
-\f[I]flags\f[] : Additional flags to apply for the read or write
-operation.
-.PP
-\f[I]context\f[] : User specified pointer to associate with the
-operation.
+.RS
+.RE
+.TP
+.B \f[I]msg\f[]
+Message descriptor for read and write operations.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply for the read or write operation.
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified pointer to associate with the operation.
+This parameter is ignored if the operation will not generate a
+successful completion, unless an op flag specifies the context parameter
+be used for required input.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 RMA (remote memory access) operations are used to transfer data directly
@@ -213,56 +256,82 @@ previously configured with the endpoint, except where noted (see
 fi_endpoint.3).
 The following list of flags are usable with fi_readmsg and/or
 fi_writemsg.
-.PP
-\f[I]FI_REMOTE_CQ_DATA\f[] : Applies to fi_writemsg and fi_writedata.
+.TP
+.B \f[I]FI_REMOTE_CQ_DATA\f[]
+Applies to fi_writemsg and fi_writedata.
 Indicates that remote CQ data is available and should be sent as part of
 the request.
 See fi_getinfo for additional details on FI_REMOTE_CQ_DATA.
-.PP
-\f[I]FI_COMPLETION\f[] : Indicates that a completion entry should be
-generated for the specified operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_COMPLETION\f[]
+Indicates that a completion entry should be generated for the specified
+operation.
 The endpoint must be bound to a completion queue with
 FI_SELECTIVE_COMPLETION that corresponds to the specified operation, or
 this flag is ignored.
-.PP
-\f[I]FI_MORE\f[] : Indicates that the user has additional requests that
-will immediately be posted after the current call returns.
+.RS
+.RE
+.TP
+.B \f[I]FI_MORE\f[]
+Indicates that the user has additional requests that will immediately be
+posted after the current call returns.
 Use of this flag may improve performance by enabling the provider to
 optimize its access to the fabric hardware.
-.PP
-\f[I]FI_INJECT\f[] : Applies to fi_writemsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_INJECT\f[]
+Applies to fi_writemsg.
 Indicates that the outbound data buffer should be returned to user
 immediately after the write call returns, even if the operation is
 handled asynchronously.
 This may require that the underlying provider implementation copy the
 data into a local buffer and transfer out of that buffer.
 This flag can only be used with messages smaller than inject_size.
-.PP
-\f[I]FI_INJECT_COMPLETE\f[] : Applies to fi_writemsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_INJECT_COMPLETE\f[]
+Applies to fi_writemsg.
 Indicates that a completion should be generated when the source
 buffer(s) may be reused.
-.PP
-\f[I]FI_TRANSMIT_COMPLETE\f[] : Applies to fi_writemsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_TRANSMIT_COMPLETE\f[]
+Applies to fi_writemsg.
 Indicates that a completion should not be generated until the operation
 has been successfully transmitted and is no longer being tracked by the
 provider.
-.PP
-\f[I]FI_DELIVERY_COMPLETE\f[] : Applies to fi_writemsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_DELIVERY_COMPLETE\f[]
+Applies to fi_writemsg.
 Indicates that a completion should be generated when the operation has
 been processed by the destination.
-.PP
-\f[I]FI_COMMIT_COMPLETE\f[] : Applies to fi_writemsg when targeting
-persistent memory regions.
+.RS
+.RE
+.TP
+.B \f[I]FI_COMMIT_COMPLETE\f[]
+Applies to fi_writemsg when targeting persistent memory regions.
 Indicates that a completion should be generated only after the result of
 the operation has been made durable.
-.PP
-\f[I]FI_FENCE\f[] : Applies to transmits.
+.RS
+.RE
+.TP
+.B \f[I]FI_FENCE\f[]
+Applies to transmits.
 Indicates that the requested operation, also known as the fenced
 operation, and any operation posted after the fenced operation will be
 deferred until all previous operations targeting the same peer endpoint
 have completed.
 Operations posted after the fencing will see and/or replace the results
 of any operations initiated prior to the fenced operation.
+.RS
+.RE
 .PP
 The ordering of operations starting at the posting of the fenced
 operation (inclusive) to the posting of a subsequent fenced operation
@@ -273,9 +342,11 @@ Returns 0 on success.
 On error, a negative value corresponding to fabric errno is returned.
 Fabric errno values are defined in \f[C]rdma/fi_errno.h\f[].
 .SH ERRORS
-.PP
-\f[I]\-FI_EAGAIN\f[] : See \f[C]fi_msg\f[](3) for a detailed description
-of handling FI_EAGAIN.
+.TP
+.B \f[I]\-FI_EAGAIN\f[]
+See \f[C]fi_msg\f[](3) for a detailed description of handling FI_EAGAIN.
+.RS
+.RE
 .SH SEE ALSO
 .PP
 \f[C]fi_getinfo\f[](3), \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_tagged.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_tagged.3
index 652b8879e..beb8fc421 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_tagged.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_tagged.3
@@ -1,4 +1,7 @@
-.TH "fi_tagged" "3" "2017\-10\-20" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_tagged" "3" "2018\-11\-28" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_tagged \- Tagged data transfer operations
@@ -50,43 +53,83 @@ ssize_t\ fi_tinjectdata(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ len,
 \f[]
 .fi
 .SH ARGUMENTS
-.PP
-\f[I]fid\f[] : Fabric endpoint on which to initiate tagged communication
-operation.
-.PP
-\f[I]buf\f[] : Data buffer to send or receive.
-.PP
-\f[I]len\f[] : Length of data buffer to send or receive.
-.PP
-\f[I]iov\f[] : Vectored data buffer.
-.PP
-\f[I]count\f[] : Count of vectored data entries.
-.PP
-\f[I]tag\f[] : Tag associated with the message.
-.PP
-\f[I]ignore\f[] : Mask of bits to ignore applied to the tag for receive
-operations.
-.PP
-\f[I]desc\f[] : Memory descriptor associated with the data buffer
-.PP
-\f[I]data\f[] : Remote CQ data to transfer with the sent data.
-.PP
-\f[I]dest_addr\f[] : Destination address for connectionless transfers.
+.TP
+.B \f[I]fid\f[]
+Fabric endpoint on which to initiate tagged communication operation.
+.RS
+.RE
+.TP
+.B \f[I]buf\f[]
+Data buffer to send or receive.
+.RS
+.RE
+.TP
+.B \f[I]len\f[]
+Length of data buffer to send or receive.
+.RS
+.RE
+.TP
+.B \f[I]iov\f[]
+Vectored data buffer.
+.RS
+.RE
+.TP
+.B \f[I]count\f[]
+Count of vectored data entries.
+.RS
+.RE
+.TP
+.B \f[I]tag\f[]
+Tag associated with the message.
+.RS
+.RE
+.TP
+.B \f[I]ignore\f[]
+Mask of bits to ignore applied to the tag for receive operations.
+.RS
+.RE
+.TP
+.B \f[I]desc\f[]
+Memory descriptor associated with the data buffer
+.RS
+.RE
+.TP
+.B \f[I]data\f[]
+Remote CQ data to transfer with the sent data.
+.RS
+.RE
+.TP
+.B \f[I]dest_addr\f[]
+Destination address for connectionless transfers.
 Ignored for connected endpoints.
-.PP
-\f[I]src_addr\f[] : Source address to receive from for connectionless
-transfers.
+.RS
+.RE
+.TP
+.B \f[I]src_addr\f[]
+Source address to receive from for connectionless transfers.
 Applies only to connectionless endpoints with the FI_DIRECTED_RECV
 capability enabled, otherwise this field is ignored.
 If set to FI_ADDR_UNSPEC, any source address may match.
-.PP
-\f[I]msg\f[] : Message descriptor for send and receive operations.
-.PP
-\f[I]flags\f[] : Additional flags to apply for the send or receive
-operation.
-.PP
-\f[I]context\f[] : User specified pointer to associate with the
-operation.
+.RS
+.RE
+.TP
+.B \f[I]msg\f[]
+Message descriptor for send and receive operations.
+.RS
+.RE
+.TP
+.B \f[I]flags\f[]
+Additional flags to apply for the send or receive operation.
+.RS
+.RE
+.TP
+.B \f[I]context\f[]
+User specified pointer to associate with the operation.
+This parameter is ignored if the operation will not generate a
+successful completion, unless an op flag specifies the context parameter
+be used for required input.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 Tagged messages are data transfers which carry a key or tag with the
@@ -177,7 +220,7 @@ The tagged inject call is an optimized version of fi_tsend.
 The fi_tinject function behaves as if the FI_INJECT transfer flag were
 set, and FI_COMPLETION were not.
 That is, the data buffer is available for reuse immediately on returning
-from from fi_tinject, and no completion event will be generated for this
+from fi_tinject, and no completion event will be generated for this
 send.
 The completion event will be suppressed even if the endpoint has not
 been configured with FI_SELECTIVE_COMPLETION.
@@ -223,56 +266,85 @@ previously configured with the endpoint, except where noted (see
 fi_endpoint).
 The following list of flags are usable with fi_trecvmsg and/or
 fi_tsendmsg.
-.PP
-\f[I]FI_REMOTE_CQ_DATA\f[] : Applies to fi_tsendmsg and fi_tsenddata.
+.TP
+.B \f[I]FI_REMOTE_CQ_DATA\f[]
+Applies to fi_tsendmsg and fi_tsenddata.
 Indicates that remote CQ data is available and should be sent as part of
 the request.
 See fi_getinfo for additional details on FI_REMOTE_CQ_DATA.
-.PP
-\f[I]FI_COMPLETION\f[] : Indicates that a completion entry should be
-generated for the specified operation.
+.RS
+.RE
+.TP
+.B \f[I]FI_COMPLETION\f[]
+Indicates that a completion entry should be generated for the specified
+operation.
 The endpoint must be bound to a completion queue with
 FI_SELECTIVE_COMPLETION that corresponds to the specified operation, or
 this flag is ignored.
-.PP
-\f[I]FI_MORE\f[] : Indicates that the user has additional requests that
-will immediately be posted after the current call returns.
+.RS
+.RE
+.TP
+.B \f[I]FI_MORE\f[]
+Indicates that the user has additional requests that will immediately be
+posted after the current call returns.
 Use of this flag may improve performance by enabling the provider to
 optimize its access to the fabric hardware.
-.PP
-\f[I]FI_INJECT\f[] : Applies to fi_tsendmsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_INJECT\f[]
+Applies to fi_tsendmsg.
 Indicates that the outbound data buffer should be returned to user
 immediately after the send call returns, even if the operation is
 handled asynchronously.
 This may require that the underlying provider implementation copy the
 data into a local buffer and transfer out of that buffer.
 This flag can only be used with messages smaller than inject_size.
-.PP
-\f[I]FI_INJECT_COMPLETE\f[] : Applies to fi_tsendmsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_INJECT_COMPLETE\f[]
+Applies to fi_tsendmsg.
 Indicates that a completion should be generated when the source
 buffer(s) may be reused.
-.PP
-\f[I]FI_TRANSMIT_COMPLETE\f[] : Applies to fi_tsendmsg.
+.RS
+.RE
+.TP
+.B \f[I]FI_TRANSMIT_COMPLETE\f[]
+Applies to fi_tsendmsg.
 Indicates that a completion should not be generated until the operation
 has been successfully transmitted and is no longer being tracked by the
 provider.
-.PP
-\f[I]FI_FENCE\f[] : Applies to transmits.
+.RS
+.RE
+.TP
+.B \f[I]FI_MATCH_COMPLETE\f[]
+Applies to fi_tsendmsg.
+Indicates that a completion should be generated only after the message
+has either been matched with a tagged buffer or was discarded by the
+target application.
+.RS
+.RE
+.TP
+.B \f[I]FI_FENCE\f[]
+Applies to transmits.
 Indicates that the requested operation, also known as the fenced
 operation, and any operation posted after the fenced operation will be
 deferred until all previous operations targeting the same peer endpoint
 have completed.
 Operations posted after the fencing will see and/or replace the results
 of any operations initiated prior to the fenced operation.
+.RS
+.RE
 .PP
 The ordering of operations starting at the posting of the fenced
 operation (inclusive) to the posting of a subsequent fenced operation
 (exclusive) is controlled by the endpoint\[aq]s ordering semantics.
 .PP
 The following flags may be used with fi_trecvmsg.
-.PP
-\f[I]FI_PEEK\f[] : The peek flag may be used to see if a specified
-message has arrived.
+.TP
+.B \f[I]FI_PEEK\f[]
+The peek flag may be used to see if a specified message has arrived.
 A peek request is often useful on endpoints that have provider allocated
 buffering enabled (see fi_rx_attr total_buffered_recv).
 Unlike standard receive operations, a receive operation with the FI_PEEK
@@ -284,6 +356,8 @@ endpoint.
 If no message is found matching the tags specified in the peek request,
 then a completion queue error entry with err field set to FI_ENOMSG will
 be available.
+.RS
+.RE
 .PP
 If a peek request locates a matching message, the operation will
 complete successfully.
@@ -308,33 +382,96 @@ A provider may return NULL even if the peek operation completes
 successfully.
 Note that the CQ entry len field will reference the size of the message,
 not necessarily the size of the returned data.
-.PP
-\f[I]FI_CLAIM\f[] : If this flag is used in conjunction with FI_PEEK, it
-indicates if the peek request completes successfully \-\- indicating
-that a matching message was located \-\- the message is claimed by
-caller.
+.TP
+.B \f[I]FI_CLAIM\f[]
+If this flag is used in conjunction with FI_PEEK, it indicates if the
+peek request completes successfully \-\- indicating that a matching
+message was located \-\- the message is claimed by caller.
 Claimed messages can only be retrieved using a subsequent, paired
 receive operation with the FI_CLAIM flag set.
 A receive operation with the FI_CLAIM flag set, but FI_PEEK not set is
 used to retrieve a previously claimed message.
+.RS
+.RE
 .PP
 In order to use the FI_CLAIM flag, an application must supply a struct
-fi_context structure as the context for the receive operation.
+fi_context structure as the context for the receive operation, or a
+struct fi_recv_context in the case of buffered receives.
 The same fi_context structure used for an FI_PEEK + FI_CLAIM operation
 must be used by the paired FI_CLAIM request.
 .PP
-\f[I]FI_DISCARD\f[] : This flag must be used in conjunction with either
-FI_PEEK or FI_CLAIM.
+This flag also applies to endpoints configured for FI_BUFFERED_RECV or
+FI_VARIABLE_MSG.
+When set, it is used to retrieve a tagged message that was buffered by
+the provider.
+See Buffered Tagged Receives section for details.
+.TP
+.B \f[I]FI_DISCARD\f[]
+This flag may be used in conjunction with either FI_PEEK or FI_CLAIM.
 If this flag is used in conjunction with FI_PEEK, it indicates if the
 peek request completes successfully \-\- indicating that a matching
 message was located \-\- the message is discarded by the provider, as
 the data is not needed by the application.
 This flag may also be used in conjunction with FI_CLAIM in order to
-retrieve and discard a message previously claimed using an FI_PEEK +
-FI_CLAIM request.
+discard a message previously claimed using an FI_PEEK + FI_CLAIM
+request.
+.RS
+.RE
+.PP
+This flag also applies to endpoints configured for FI_BUFFERED_RECV or
+FI_VARIABLE_MSG.
+When set, it indicates that the provider should free a buffered
+messages.
+See Buffered Tagged Receives section for details.
 .PP
 If this flag is set, the input buffer(s) and length parameters are
 ignored.
+.SH Buffered Tagged Receives
+.PP
+See \f[C]fi_msg\f[](3) for an introduction to buffered receives.
+The handling of buffered receives differs between fi_msg operations and
+fi_tagged.
+Although the provider is responsible for allocating and managing network
+buffers, the application is responsible for identifying the tags that
+will be used to match incoming messages.
+The provider handles matching incoming receives to the application
+specified tags.
+.PP
+When FI_BUFFERED_RECV is enabled, the application posts the tags that
+will be used for matching purposes.
+Tags are posted using fi_trecv, fi_trecvv, and fi_trecvmsg; however,
+parameters related to the input buffers are ignored (e.g.
+buf, len, iov, desc).
+When a provider receives a message for which there is a matching tag, it
+will write an entry to the completion queue associated with the
+receiving endpoint.
+.PP
+For discussion purposes, the completion queue is assumed to be
+configured for FI_CQ_FORMAT_TAGGED.
+The op_context field will point to a struct fi_recv_contex.
+.IP
+.nf
+\f[C]
+struct\ fi_recv_context\ {
+\ \ \ \ struct\ fid_ep\ *ep;
+\ \ \ \ void\ *context;
+};
+\f[]
+.fi
+.PP
+The \[aq]ep\[aq] field will be NULL.
+The \[aq]context\[aq] field will match the application context specified
+when posting the tag.
+Other fields are set as defined in \f[C]fi_msg\f[](3).
+.PP
+After being notified that a buffered receive has arrived, applications
+must either claim or discard the message as described in
+\f[C]fi_msg\f[](3).
+.SH Variable Length Tagged Messages
+.PP
+Variable length messages are defined in \f[C]fi_msg\f[](3).
+The requirements for handling variable length tagged messages is
+identical to those defined above for buffered tagged receives.
 .SH RETURN VALUE
 .PP
 The tagged send and receive calls return 0 on success.
@@ -342,14 +479,21 @@ On error, a negative value corresponding to fabric \f[I]errno \f[] is
 returned.
 Fabric errno values are defined in \f[C]fi_errno.h\f[].
 .SH ERRORS
-.PP
-\f[I]\-FI_EAGAIN\f[] : See \f[C]fi_msg\f[](3) for a detailed description
-of handling FI_EAGAIN.
-.PP
-\f[I]\-FI_EINVAL\f[] : Indicates that an invalid argument was supplied
-by the user.
-.PP
-\f[I]\-FI_EOTHER\f[] : Indicates that an unspecified error occurred.
+.TP
+.B \f[I]\-FI_EAGAIN\f[]
+See \f[C]fi_msg\f[](3) for a detailed description of handling FI_EAGAIN.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_EINVAL\f[]
+Indicates that an invalid argument was supplied by the user.
+.RS
+.RE
+.TP
+.B \f[I]\-FI_EOTHER\f[]
+Indicates that an unspecified error occurred.
+.RS
+.RE
 .SH SEE ALSO
 .PP
 \f[C]fi_getinfo\f[](3), \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_trigger.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_trigger.3
index 10a2d2971..701569913 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_trigger.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_trigger.3
@@ -1,4 +1,7 @@
-.TH "fi_trigger" "3" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_trigger" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_trigger \- Triggered operations
@@ -71,11 +74,13 @@ event type.
 .SS TRIGGER EVENTS
 .PP
 The following trigger events are defined.
-.PP
-\f[I]FI_TRIGGER_THRESHOLD\f[] : This indicates that the data transfer
-operation will be deferred until an event counter crosses an application
-specified threshold value.
+.TP
+.B \f[I]FI_TRIGGER_THRESHOLD\f[]
+This indicates that the data transfer operation will be deferred until
+an event counter crosses an application specified threshold value.
 The threshold is specified using struct fi_trigger_threshold:
+.RS
+.RE
 .IP
 .nf
 \f[C]
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_version.3 b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_version.3
index e2e8fc1b8..27e508097 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_version.3
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man3/fi_version.3
@@ -1,4 +1,7 @@
-.TH "fi_version" "3" "2016\-02\-28" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_version" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_version \- Version of the library interfaces
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fabric.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fabric.7
index 4964e5ce4..a8e476fd7 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fabric.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fabric.7
@@ -1,4 +1,7 @@
-.TH "fabric" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fabric" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fabric \- Fabric Interface Library
@@ -22,10 +25,10 @@ system interventions.
 Data transfers can occur directly to and from application memory.
 .PP
 There are two components to the libfabric software:
-.PP
-\f[I]Fabric Providers\f[] : Conceptually, a fabric provider may be
-viewed as a local hardware NIC driver, though a provider is not limited
-by this definition.
+.TP
+.B \f[I]Fabric Providers\f[]
+Conceptually, a fabric provider may be viewed as a local hardware NIC
+driver, though a provider is not limited by this definition.
 The first component of libfabric is a general purpose framework that is
 capable of handling different types of fabric hardware.
 All fabric hardware devices and their software drivers are required to
@@ -33,14 +36,18 @@ support this framework.
 Devices and the drivers that plug into the libfabric framework are
 referred to as fabric providers, or simply providers.
 Provider details may be found in \f[C]fi_provider\f[](7).
-.PP
-\f[I]Fabric Interfaces\f[] : The second component is a set of
-communication operations.
+.RS
+.RE
+.TP
+.B \f[I]Fabric Interfaces\f[]
+The second component is a set of communication operations.
 Libfabric defines several sets of communication functions that providers
 can support.
 It is not required that providers implement all the interfaces that are
 defined; however, providers clearly indicate which interfaces they do
 support.
+.RS
+.RE
 .SH FABRIC INTERFACES
 .PP
 The fabric interfaces are designed such that they are cohesive and not
@@ -66,14 +73,16 @@ The control interfaces APIs provide applications access to network
 resources.
 This involves listing all the interfaces available, obtaining the
 capabilities of the interfaces and opening a provider.
-.PP
-\f[I]fi_getinfo \- Fabric Information\f[] : The fi_getinfo call is the
-base call used to discover and request fabric services offered by the
-system.
+.TP
+.B \f[I]fi_getinfo \- Fabric Information\f[]
+The fi_getinfo call is the base call used to discover and request fabric
+services offered by the system.
 Applications can use this call to indicate the type of communication
 that they desire.
 The results from fi_getinfo, fi_info, are used to reserve and configure
 fabric resources.
+.RS
+.RE
 .PP
 fi_getinfo returns a list of fi_info structures.
 Each structure references a single fabric provider, indicating the
@@ -81,60 +90,79 @@ interfaces that the provider supports, along with a named set of
 resources.
 A fabric provider may include multiple fi_info structures in the
 returned list.
-.PP
-\f[I]fi_fabric \- Fabric Domain\f[] : A fabric domain represents a
-collection of hardware and software resources that access a single
-physical or virtual network.
+.TP
+.B \f[I]fi_fabric \- Fabric Domain\f[]
+A fabric domain represents a collection of hardware and software
+resources that access a single physical or virtual network.
 All network ports on a system that can communicate with each other
 through the fabric belong to the same fabric domain.
 A fabric domain shares network addresses and can span multiple
 providers.
 libfabric supports systems connected to multiple fabrics.
-.PP
-\f[I]fi_domain \- Access Domains\f[] : An access domain represents a
-single logical connection into a fabric.
+.RS
+.RE
+.TP
+.B \f[I]fi_domain \- Access Domains\f[]
+An access domain represents a single logical connection into a fabric.
 It may map to a single physical or virtual NIC or a port.
 An access domain defines the boundary across which fabric resources may
 be associated.
 Each access domain belongs to a single fabric domain.
-.PP
-\f[I]fi_endpoint \- Fabric Endpoint\f[] : A fabric endpoint is a
-communication portal.
+.RS
+.RE
+.TP
+.B \f[I]fi_endpoint \- Fabric Endpoint\f[]
+A fabric endpoint is a communication portal.
 An endpoint may be either active or passive.
 Passive endpoints are used to listen for connection requests.
 Active endpoints can perform data transfers.
 Endpoints are configured with specific communication capabilities and
 data transfer interfaces.
-.PP
-\f[I]fi_eq \- Event Queue\f[] : Event queues, are used to collect and
-report the completion of asynchronous operations and events.
+.RS
+.RE
+.TP
+.B \f[I]fi_eq \- Event Queue\f[]
+Event queues, are used to collect and report the completion of
+asynchronous operations and events.
 Event queues report events that are not directly associated with data
 transfer operations.
-.PP
-\f[I]fi_cq \- Completion Queue\f[] : Completion queues are
-high\-performance event queues used to report the completion of data
-transfer operations.
-.PP
-\f[I]fi_cntr \- Event Counters\f[] : Event counters are used to report
-the number of completed asynchronous operations.
+.RS
+.RE
+.TP
+.B \f[I]fi_cq \- Completion Queue\f[]
+Completion queues are high\-performance event queues used to report the
+completion of data transfer operations.
+.RS
+.RE
+.TP
+.B \f[I]fi_cntr \- Event Counters\f[]
+Event counters are used to report the number of completed asynchronous
+operations.
 Event counters are considered light\-weight, in that a completion simply
 increments a counter, rather than placing an entry into an event queue.
-.PP
-\f[I]fi_mr \- Memory Region\f[] : Memory regions describe application
-local memory buffers.
+.RS
+.RE
+.TP
+.B \f[I]fi_mr \- Memory Region\f[]
+Memory regions describe application local memory buffers.
 In order for fabric resources to access application memory, the
 application must first grant permission to the fabric provider by
 constructing a memory region.
 Memory regions are required for specific types of data transfer
 operations, such as RMA transfers (see below).
-.PP
-\f[I]fi_av \- Address Vector\f[] : Address vectors are used to map
-higher level addresses, such as IP addresses, which may be more natural
-for an application to use, into fabric specific addresses.
+.RS
+.RE
+.TP
+.B \f[I]fi_av \- Address Vector\f[]
+Address vectors are used to map higher level addresses, such as IP
+addresses, which may be more natural for an application to use, into
+fabric specific addresses.
 The use of address vectors allows providers to reduce the amount of
 memory required to maintain large address look\-up tables, and eliminate
 expensive address resolution and look\-up methods during data transfer
 operations.
+.RS
+.RE
 .SH DATA TRANSFER INTERFACES
 .PP
 Fabric endpoints are associated with multiple data transfer interfaces.
@@ -142,95 +170,184 @@ Each interface set is designed to support a specific style of
 communication, with an endpoint allowing the different interfaces to be
 used in conjunction.
 The following data transfer interfaces are defined by libfabric.
-.PP
-\f[I]fi_msg \- Message Queue\f[] : Message queues expose a simple,
-message\-based FIFO queue interface to the application.
+.TP
+.B \f[I]fi_msg \- Message Queue\f[]
+Message queues expose a simple, message\-based FIFO queue interface to
+the application.
 Message data transfers allow applications to send and receive data with
 message boundaries being maintained.
-.PP
-\f[I]fi_tagged \- Tagged Message Queues\f[] : Tagged message lists
-expose send/receive data transfer operations built on the concept of
-tagged messaging.
+.RS
+.RE
+.TP
+.B \f[I]fi_tagged \- Tagged Message Queues\f[]
+Tagged message lists expose send/receive data transfer operations built
+on the concept of tagged messaging.
 The tagged message queue is conceptually similar to standard message
 queues, but with the addition of 64\-bit tags for each message.
 Sent messages are matched with receive buffers that are tagged with a
 similar value.
-.PP
-\f[I]fi_rma \- Remote Memory Access\f[] : RMA transfers are one\-sided
-operations that read or write data directly to a remote memory region.
+.RS
+.RE
+.TP
+.B \f[I]fi_rma \- Remote Memory Access\f[]
+RMA transfers are one\-sided operations that read or write data directly
+to a remote memory region.
 Other than defining the appropriate memory region, RMA operations do not
 require interaction at the target side for the data transfer to
 complete.
-.PP
-\f[I]fi_atomic \- Atomic\f[] : Atomic operations can perform one of
-several operations on a remote memory region.
+.RS
+.RE
+.TP
+.B \f[I]fi_atomic \- Atomic\f[]
+Atomic operations can perform one of several operations on a remote
+memory region.
 Atomic operations include well\-known functionality, such as atomic\-add
 and compare\-and\-swap, plus several other pre\-defined calls.
 Unlike other data transfer interfaces, atomic operations are aware of
 the data formatting at the target memory region.
+.RS
+.RE
 .SH LOGGING INTERFACE
 .PP
 Logging can be controlled using the FI_LOG_LEVEL, FI_LOG_PROV, and
 FI_LOG_SUBSYS environment variables.
-.PP
-\f[I]FI_LOG_LEVEL\f[] : FI_LOG_LEVEL controls the amount of logging data
-that is output.
+.TP
+.B \f[I]FI_LOG_LEVEL\f[]
+FI_LOG_LEVEL controls the amount of logging data that is output.
 The following log levels are defined.
-.IP \[bu] 2
-\f[I]Warn\f[] : Warn is the least verbose setting and is intended for
-reporting errors or warnings.
-.IP \[bu] 2
-\f[I]Trace\f[] : Trace is more verbose and is meant to include
-non\-detailed output helpful to tracing program execution.
-.IP \[bu] 2
-\f[I]Info\f[] : Info is high traffic and meant for detailed output.
-.IP \[bu] 2
-\f[I]Debug\f[] : Debug is high traffic and is likely to impact
-application performance.
+.RS
+.RE
+.TP
+.B \- \f[I]Warn\f[]
+Warn is the least verbose setting and is intended for reporting errors
+or warnings.
+.RS
+.RE
+.TP
+.B \- \f[I]Trace\f[]
+Trace is more verbose and is meant to include non\-detailed output
+helpful to tracing program execution.
+.RS
+.RE
+.TP
+.B \- \f[I]Info\f[]
+Info is high traffic and meant for detailed output.
+.RS
+.RE
+.TP
+.B \- \f[I]Debug\f[]
+Debug is high traffic and is likely to impact application performance.
 Debug output is only available if the library has been compiled with
 debugging enabled.
-.PP
-\f[I]FI_LOG_PROV\f[] : The FI_LOG_PROV environment variable enables or
-disables logging from specific providers.
+.RS
+.RE
+.TP
+.B \f[I]FI_LOG_PROV\f[]
+The FI_LOG_PROV environment variable enables or disables logging from
+specific providers.
 Providers can be enabled by listing them in a comma separated fashion.
 If the list begins with the \[aq]^\[aq] symbol, then the list will be
 negated.
 By default all providers are enabled.
+.RS
+.RE
 .PP
 Example: To enable logging from the psm and sockets provider:
 FI_LOG_PROV="psm,sockets"
 .PP
 Example: To enable logging from providers other than psm:
 FI_LOG_PROV="^psm"
-.PP
-\f[I]FI_LOG_SUBSYS\f[] : The FI_LOG_SUBSYS environment variable enables
-or disables logging at the subsystem level.
+.TP
+.B \f[I]FI_LOG_SUBSYS\f[]
+The FI_LOG_SUBSYS environment variable enables or disables logging at
+the subsystem level.
 The syntax for enabling or disabling subsystems is similar to that used
 for FI_LOG_PROV.
 The following subsystems are defined.
-.IP \[bu] 2
-\f[I]core\f[] : Provides output related to the core framework and its
-management of providers.
-.IP \[bu] 2
-\f[I]fabric\f[] : Provides output specific to interactions associated
-with the fabric object.
-.IP \[bu] 2
-\f[I]domain\f[] : Provides output specific to interactions associated
-with the domain object.
-.IP \[bu] 2
-\f[I]ep_ctrl\f[] : Provides output specific to endpoint non\-data
-transfer operations, such as CM operations.
-.IP \[bu] 2
-\f[I]ep_data\f[] : Provides output specific to endpoint data transfer
-operations.
-.IP \[bu] 2
-\f[I]av\f[] : Provides output specific to address vector operations.
-.IP \[bu] 2
-\f[I]cq\f[] : Provides output specific to completion queue operations.
-.IP \[bu] 2
-\f[I]eq\f[] : Provides output specific to event queue operations.
-.IP \[bu] 2
-\f[I]mr\f[] : Provides output specific to memory registration.
+.RS
+.RE
+.TP
+.B \- \f[I]core\f[]
+Provides output related to the core framework and its management of
+providers.
+.RS
+.RE
+.TP
+.B \- \f[I]fabric\f[]
+Provides output specific to interactions associated with the fabric
+object.
+.RS
+.RE
+.TP
+.B \- \f[I]domain\f[]
+Provides output specific to interactions associated with the domain
+object.
+.RS
+.RE
+.TP
+.B \- \f[I]ep_ctrl\f[]
+Provides output specific to endpoint non\-data transfer operations, such
+as CM operations.
+.RS
+.RE
+.TP
+.B \- \f[I]ep_data\f[]
+Provides output specific to endpoint data transfer operations.
+.RS
+.RE
+.TP
+.B \- \f[I]av\f[]
+Provides output specific to address vector operations.
+.RS
+.RE
+.TP
+.B \- \f[I]cq\f[]
+Provides output specific to completion queue operations.
+.RS
+.RE
+.TP
+.B \- \f[I]eq\f[]
+Provides output specific to event queue operations.
+.RS
+.RE
+.TP
+.B \- \f[I]mr\f[]
+Provides output specific to memory registration.
+.RS
+.RE
+.SH PROVIDER INSTALLATION AND SELECTION
+.PP
+The libfabric build scripts will install all providers that are
+supported by the installation system.
+Providers that are missing build prerequisites will be disabled.
+Installed providers will dynamically check for necessary hardware on
+library initialization and respond appropriately to application queries.
+.PP
+Users can enable or disable available providers through build
+configuration options.
+See \[aq]configure \-\-help\[aq] for details.
+In general, a specific provider can be controlled using the configure
+option \[aq]\-\-enable\-\[aq].
+For example, \[aq]\-\-enable\-udp\[aq] (or
+\[aq]\-\-enable\-udp=yes\[aq]) will add the udp provider to the build.
+To disable the provider, \[aq]\-\-enable\-udp=no\[aq] can be used.
+.PP
+Providers can also be enable or disabled at run time using the
+FI_PROVIDER environment variable.
+The FI_PROVIDER variable is set to a comma separated list of providers
+to include.
+If the list begins with the \[aq]^\[aq] symbol, then the list will be
+negated.
+.PP
+Example: To enable the udp and tcp providers only, set:
+FI_PROVIDER="udp,tcp"
+.PP
+The fi_info utility, which is included as part of the libfabric package,
+can be used to retrieve information about which providers are available
+in the system.
+Additionally, it can retrieve a list of all environment variables that
+may be used to configure libfabric and each provider.
+See \f[C]fi_info\f[](1) for more details.
 .SH NOTES
 .PP
 Because libfabric is designed to provide applications direct access to
@@ -241,18 +358,20 @@ programming to the sockets interface.
 Although limits are provider specific, the following restrictions apply
 to many providers and should be adhered to by applications desiring
 portability across providers.
-.PP
-\f[I]fork\f[] : Fabric resources are not guaranteed to be available by
-child processes.
+.TP
+.B \f[I]fork\f[]
+Fabric resources are not guaranteed to be available by child processes.
 This includes objects, such as endpoints and completion queues, as well
 as application controlled data buffers which have been assigned to the
 network.
 For example, data buffers that have been registered with a fabric domain
 may not be available in a child process because of copy on write
 restrictions.
+.RS
+.RE
 .SH SEE ALSO
 .PP
-\f[C]fi_provider\f[](7), \f[C]fi_getinfo\f[](3),
+\f[C]fi_info\f[](1), \f[C]fi_provider\f[](7), \f[C]fi_getinfo\f[](3),
 \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3), \f[C]fi_av\f[](3),
 \f[C]fi_eq\f[](3), \f[C]fi_cq\f[](3), \f[C]fi_cntr\f[](3),
 \f[C]fi_mr\f[](3)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_bgq.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_bgq.7
index 8efbd6888..33e5156a3 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_bgq.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_bgq.7
@@ -1,4 +1,7 @@
-.TH "fi_bgq" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_bgq" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_bgq \- The Blue Gene/Q Fabric Provider
@@ -17,18 +20,23 @@ via MPICH CH4.
 .PP
 The bgq provider supports most features defined for the libfabric API.
 Key features include:
-.PP
-\f[I]Endpoint types\f[] : The Blue Gene/Q hardware is connectionless and
-reliable.
+.TP
+.B \f[I]Endpoint types\f[]
+The Blue Gene/Q hardware is connectionless and reliable.
 Therefore, the bgq provider only supports the \f[I]FI_EP_RDM\f[]
 endpoint type.
-.PP
-\f[I]Capabilities\f[] : Supported capabilities include \f[I]FI_MSG\f[],
-\f[I]FI_RMA\f[], \f[I]FI_TAGGED\f[], \f[I]FI_ATOMIC\f[],
-\f[I]FI_NAMED_RX_CTX\f[], \f[I]FI_READ\f[], \f[I]FI_WRITE\f[],
-\f[I]FI_SEND\f[], \f[I]FI_RECV\f[], \f[I]FI_REMOTE_READ\f[],
-\f[I]FI_REMOTE_WRITE\f[], \f[I]FI_MULTI_RECV\f[],
-\f[I]FI_DIRECTED_RECV\f[], \f[I]FI_SOURCE\f[] and \f[I]FI_FENCE\f[].
+.RS
+.RE
+.TP
+.B \f[I]Capabilities\f[]
+Supported capabilities include \f[I]FI_MSG\f[], \f[I]FI_RMA\f[],
+\f[I]FI_TAGGED\f[], \f[I]FI_ATOMIC\f[], \f[I]FI_NAMED_RX_CTX\f[],
+\f[I]FI_READ\f[], \f[I]FI_WRITE\f[], \f[I]FI_SEND\f[], \f[I]FI_RECV\f[],
+\f[I]FI_REMOTE_READ\f[], \f[I]FI_REMOTE_WRITE\f[],
+\f[I]FI_MULTI_RECV\f[], \f[I]FI_DIRECTED_RECV\f[], \f[I]FI_SOURCE\f[]
+and \f[I]FI_FENCE\f[].
+.RS
+.RE
 .PP
 Notes on FI_DIRECTED_RECV capability: The immediate data which is sent
 within the \f[I]senddata\f[] call to support FI_DIRECTED_RECV for BGQ
@@ -37,13 +45,15 @@ source address to an exascale\-level number of ranks for tag matching on
 the recv and can be managed within the MU packet.
 Therefore the domain attribute cq_data_size is set to 4 which is the OFI
 standard minimum.
-.PP
-\f[I]Modes\f[] : The bgq provider requires \f[I]FI_CONTEXT\f[] and
-\f[I]FI_ASYNC_IOV\f[]
-.PP
-\f[I]Memory registration modes\f[] : Both FI_MR_SCALABLE and FI_MR_BASIC
-are supported, specified at configuration time with the
-"\-\-with\-bgq\-mr" configure option.
+.TP
+.B \f[I]Modes\f[]
+The bgq provider requires \f[I]FI_CONTEXT\f[] and \f[I]FI_ASYNC_IOV\f[]
+.RS
+.RE
+.TP
+.B \f[I]Memory registration modes\f[]
+Both FI_MR_SCALABLE and FI_MR_BASIC are supported, specified at
+configuration time with the "\-\-with\-bgq\-mr" configure option.
 The base address table utilized by FI_MR_SCALABLE for rdma transfers is
 completely software emulated, supporting FI_ATOMIC, FI_READ, FI_WRITE,
 FI_REMOTE_READ, and FI_REMOTE_WRITE capabilities.
@@ -52,29 +62,47 @@ other rdma transfers are still software emulated but the use of a base
 address table is no longer required as the offset is now the virtual
 address of the memory from the application and the key is the delta from
 which the physical address can be computed if necessary.
-.PP
-\f[I]Additional features\f[] : Supported additional features include
-\f[I]FABRIC_DIRECT\f[], \f[I]scalable endpoints\f[], and
-\f[I]counters\f[].
-.PP
-\f[I]Progress\f[] : Both progress modes, \f[I]FI_PROGRESS_AUTO\f[] and
+.RS
+.RE
+.TP
+.B \f[I]Additional features\f[]
+Supported additional features include \f[I]FABRIC_DIRECT\f[],
+\f[I]scalable endpoints\f[], and \f[I]counters\f[].
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+Both progress modes, \f[I]FI_PROGRESS_AUTO\f[] and
 \f[I]FI_PROGRESS_MANUAL\f[], are supported.
 The progress mode may be specified via the "\-\-with\-bgq\-progress"
 configure option.
-.PP
-\f[I]Address vector\f[] : Only the \f[I]FI_AV_MAP\f[] address vector
-format is supported.
+.RS
+.RE
+.TP
+.B \f[I]Address vector\f[]
+Only the \f[I]FI_AV_MAP\f[] address vector format is supported.
+.RS
+.RE
 .SH UNSUPPORTED FEATURES
-.PP
-\f[I]Endpoint types\f[] : Unsupported endpoint types include
-\f[I]FI_EP_DGRAM\f[] and \f[I]FI_EP_MSG\f[]
-.PP
-\f[I]Capabilities\f[] : The bgq provider does not support the
-\f[I]FI_RMA_EVENT\f[], and \f[I]FI_TRIGGER\f[] capabilities.
-.PP
-\f[I]Address vector\f[] : The bgq provider does not support the
-\f[I]FI_AV_TABLE\f[] address vector format.
+.TP
+.B \f[I]Endpoint types\f[]
+Unsupported endpoint types include \f[I]FI_EP_DGRAM\f[] and
+\f[I]FI_EP_MSG\f[]
+.RS
+.RE
+.TP
+.B \f[I]Capabilities\f[]
+The bgq provider does not support the \f[I]FI_RMA_EVENT\f[], and
+\f[I]FI_TRIGGER\f[] capabilities.
+.RS
+.RE
+.TP
+.B \f[I]Address vector\f[]
+The bgq provider does not support the \f[I]FI_AV_TABLE\f[] address
+vector format.
 Support for \f[I]FI_AV_TABLE\f[] may be added in the future.
+.RS
+.RE
 .SH LIMITATIONS
 .PP
 The bgq provider only supports \f[I]FABRIC_DIRECT\f[].
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_direct.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_direct.7
index ca9bd0c1f..d73cba49b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_direct.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_direct.7
@@ -1,4 +1,7 @@
-.TH "fi_direct" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_direct" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_direct \- Direct fabric provider access
@@ -56,16 +59,20 @@ direct providers must provide definitions for various capabilities and
 modes, if those capabilities are supported.
 The following #define values may be used by an application to test for
 provider support of supported features.
-.PP
-\f[I]FI_DIRECT_CONTEXT\f[] : The provider sets FI_CONTEXT or FI_CONTEXT2
-for fi_info:mode.
+.TP
+.B \f[I]FI_DIRECT_CONTEXT\f[]
+The provider sets FI_CONTEXT or FI_CONTEXT2 for fi_info:mode.
 See fi_getinfo for additional details.
 When FI_DIRECT_CONTEXT is defined, applications should use struct
 fi_context in their definitions, even if FI_CONTEXT2 is set.
-.PP
-\f[I]FI_DIRECT_LOCAL_MR\f[] : The provider sets FI_LOCAL_MR for
-fi_info:mode.
+.RS
+.RE
+.TP
+.B \f[I]FI_DIRECT_LOCAL_MR\f[]
+The provider sets FI_LOCAL_MR for fi_info:mode.
 See fi_getinfo for additional details.
+.RS
+.RE
 .SH SEE ALSO
 .PP
 \f[C]fi_getinfo\f[](3), \f[C]fi_endpoint\f[](3), \f[C]fi_domain\f[](3)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_gni.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_gni.7
index eea2e051b..aea1e0d8b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_gni.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_gni.7
@@ -1,4 +1,7 @@
-.TH "fi_gni" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_gni" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_gni \- The GNI Fabric Provider
@@ -28,49 +31,73 @@ Any other value will result in a return value of \-FI_EINVAL.
 .PP
 The GNI provider supports the following features defined for the
 libfabric API:
-.PP
-\f[I]Endpoint types\f[] : The provider supports the \f[I]FI_EP_RDM\f[],
-\f[I]FI_EP_DGRAM\f[], \f[I]FI_EP_MSG\f[] endpoint types, including
-scalable endpoints.
-.PP
-\f[I]Address vectors\f[] : The provider implements both the
-\f[I]FI_AV_MAP\f[] and \f[I]FI_AV_TABLE\f[] address vector types.
+.TP
+.B \f[I]Endpoint types\f[]
+The provider supports the \f[I]FI_EP_RDM\f[], \f[I]FI_EP_DGRAM\f[],
+\f[I]FI_EP_MSG\f[] endpoint types, including scalable endpoints.
+.RS
+.RE
+.TP
+.B \f[I]Address vectors\f[]
+The provider implements both the \f[I]FI_AV_MAP\f[] and
+\f[I]FI_AV_TABLE\f[] address vector types.
 FI_EVENT is unsupported.
-.PP
-\f[I]Memory registration modes\f[] : The provider implements basic and
-scalable memory registration modes.
-.PP
-\f[I]Data transfer operations\f[] : The following data transfer
-interfaces are supported for all endpoint types: \f[I]FI_ATOMIC\f[],
-\f[I]FI_MSG\f[], \f[I]FI_RMA\f[], \f[I]FI_TAGGED\f[].
+.RS
+.RE
+.TP
+.B \f[I]Memory registration modes\f[]
+The provider implements basic and scalable memory registration modes.
+.RS
+.RE
+.TP
+.B \f[I]Data transfer operations\f[]
+The following data transfer interfaces are supported for all endpoint
+types: \f[I]FI_ATOMIC\f[], \f[I]FI_MSG\f[], \f[I]FI_RMA\f[],
+\f[I]FI_TAGGED\f[].
 See DATA TRANSFER OPERATIONS below for more details.
-.PP
-\f[I]Completion events\f[] : The GNI provider supports
-\f[I]FI_CQ_FORMAT_CONTEXT\f[], \f[I]FI_CQ_FORMAT_MSG\f[],
-\f[I]FI_CQ_FORMAT_DATA\f[] and \f[I]FI_CQ_FORMAT_TAGGED\f[] with wait
-objects of type \f[I]FI_WAIT_NONE\f[], \f[I]FI_WAIT_UNSPEC\f[],
-\f[I]FI_WAIT_SET\f[].
-.PP
-\f[I]Modes\f[] : The GNI provider does not require any operation modes.
-.PP
-\f[I]Progress\f[] : For both control and data progress, the GNI provider
-supports both \f[I]FI_PROGRESS_AUTO\f[] and \f[I]FI_PROGRESS_MANUAL\f[],
-with a default set to \f[I]FI_PROGRESS_AUTO\f[].
+.RS
+.RE
+.TP
+.B \f[I]Completion events\f[]
+The GNI provider supports \f[I]FI_CQ_FORMAT_CONTEXT\f[],
+\f[I]FI_CQ_FORMAT_MSG\f[], \f[I]FI_CQ_FORMAT_DATA\f[] and
+\f[I]FI_CQ_FORMAT_TAGGED\f[] with wait objects of type
+\f[I]FI_WAIT_NONE\f[], \f[I]FI_WAIT_UNSPEC\f[], \f[I]FI_WAIT_SET\f[].
+.RS
+.RE
+.TP
+.B \f[I]Modes\f[]
+The GNI provider does not require any operation modes.
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+For both control and data progress, the GNI provider supports both
+\f[I]FI_PROGRESS_AUTO\f[] and \f[I]FI_PROGRESS_MANUAL\f[], with a
+default set to \f[I]FI_PROGRESS_AUTO\f[].
 Note that for data progress, progression is only performed when data
 transfers use the rendezvous protocol.
-.PP
-\f[I]Wait Objects\f[] : The GNI provider specifically supports wait
-object types \f[I]FI_WAIT_UNSPEC\f[], and \f[I]FI_WAIT_SET\f[].
+.RS
+.RE
+.TP
+.B \f[I]Wait Objects\f[]
+The GNI provider specifically supports wait object types
+\f[I]FI_WAIT_UNSPEC\f[], and \f[I]FI_WAIT_SET\f[].
 A wait object must be used when calling fi_cntr_wait, fi_cq_sread/from,
 fi_eq_sread/from, fi_wait.
 The GNI provider spawns an internal wait progress thread that is woken
 up when clients utilize the wait system (e.g., calling fi_wait).
-.PP
-\f[I]Additional Features\f[] : The GNI provider also supports the
-following capabilities and features: \- \f[I]FI_MULTI_RECV\f[] \-
-\f[I]FI_SOURCE\f[] \- \f[I]FI_FENCE\f[] \- \f[I]FI_RM_ENABLED\f[] \-
-\f[I]FI_RMA_EVENT\f[] \- \f[I]FI_REMOTE_CQ_DATA\f[] \-
-\f[I]FABRIC_DIRECT\f[] compilation mode \- \f[I]FI_MORE\f[] (For FI_RMA)
+.RS
+.RE
+.TP
+.B \f[I]Additional Features\f[]
+The GNI provider also supports the following capabilities and features:
+\- \f[I]FI_MULTI_RECV\f[] \- \f[I]FI_SOURCE\f[] \- \f[I]FI_FENCE\f[] \-
+\f[I]FI_RM_ENABLED\f[] \- \f[I]FI_RMA_EVENT\f[] \-
+\f[I]FI_REMOTE_CQ_DATA\f[] \- \f[I]FABRIC_DIRECT\f[] compilation mode \-
+\f[I]FI_MORE\f[] (For FI_RMA)
+.RS
+.RE
 .SH DATA TRANSFER OPERATIONS
 .SS FI_ATOMIC
 .PP
@@ -156,92 +183,145 @@ The \f[C]set_val\f[] function sets the value of a given parameter; the
 \f[C]get_val\f[] function returns the current value.
 .PP
 For \f[I]FI_GNI_FABRIC_OPS_1\f[], the currently supported values are:
-.PP
-\f[I]GNI_WAIT_THREAD_SLEEP\f[] : Time in seconds for which the progress
-thread will sleep between periods of inactivity.
-.PP
-\f[I]GNI_DEFAULT_USER_REGISTRATION_LIMIT\f[] : The number of user
-registrations that an authorization key is limited to when using the
-scalable memory mode, if not specified by the user during init.
-.PP
-\f[I]GNI_DEFAULT_PROV_REGISTRATION_LIMIT\f[] : The number of provider
-registration that an authorization key is limited to when using the
-scalable memory mode, if not specified by the user during init.
-.PP
-\f[I]GNI_WAIT_SHARED_MEMORY_TIMEOUT\f[] : The number of seconds that the
-provider should wait when attempting to open mmap\[aq]d shared memory
-files for internal mappings.
+.TP
+.B \f[I]GNI_WAIT_THREAD_SLEEP\f[]
+Time in seconds for which the progress thread will sleep between periods
+of inactivity.
+.RS
+.RE
+.TP
+.B \f[I]GNI_DEFAULT_USER_REGISTRATION_LIMIT\f[]
+The number of user registrations that an authorization key is limited to
+when using the scalable memory mode, if not specified by the user during
+init.
+.RS
+.RE
+.TP
+.B \f[I]GNI_DEFAULT_PROV_REGISTRATION_LIMIT\f[]
+The number of provider registration that an authorization key is limited
+to when using the scalable memory mode, if not specified by the user
+during init.
+.RS
+.RE
+.TP
+.B \f[I]GNI_WAIT_SHARED_MEMORY_TIMEOUT\f[]
+The number of seconds that the provider should wait when attempting to
+open mmap\[aq]d shared memory files for internal mappings.
+.RS
+.RE
 .PP
 For \f[I]FI_GNI_FABRIC_OPS_2\f[], the currently supported values are:
-.PP
-\f[I]GNIX_USER_KEY_LIMIT\f[] : The number of user registrations that an
-authorization key is limited to when using the scalable memory mode.
+.TP
+.B \f[I]GNIX_USER_KEY_LIMIT\f[]
+The number of user registrations that an authorization key is limited to
+when using the scalable memory mode.
 This may only be set prior to the first use of an authorization key in
 the initialization of a domain, endpoint, or memory registration.
-.PP
-\f[I]GNIX_PROV_KEY_LIMIT\f[] : The number of provider registrations that
-an authorization key is limited to when using the scalable memory mode.
+.RS
+.RE
+.TP
+.B \f[I]GNIX_PROV_KEY_LIMIT\f[]
+The number of provider registrations that an authorization key is
+limited to when using the scalable memory mode.
 This may only be set prior to the first use of an authorization key in
 the initialization of a domain, endpoint, or memory registration.
+.RS
+.RE
 .PP
 For \f[I]FI_GNI_DOMAIN_OPS_1\f[], the currently supported values are:
-.PP
-\f[I]GNI_MSG_RENDEZVOUS_THRESHOLD\f[] : Threshold message size at which
-a rendezvous protocol is used for \f[I]FI_MSG\f[] data transfers.
+.TP
+.B \f[I]GNI_MSG_RENDEZVOUS_THRESHOLD\f[]
+Threshold message size at which a rendezvous protocol is used for
+\f[I]FI_MSG\f[] data transfers.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_RMA_RDMA_THRESHOLD\f[] : Threshold message size at which RDMA
-is used for \f[I]FI_RMA\f[] data transfers.
-The value is of type uint32_t.
-.PP
-\f[I]GNI_CONN_TABLE_INITIAL_SIZE\f[] : Initial size of the internal
-table data structure used to manage connections.
+.RS
+.RE
+.TP
+.B \f[I]GNI_RMA_RDMA_THRESHOLD\f[]
+Threshold message size at which RDMA is used for \f[I]FI_RMA\f[] data
+transfers.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_CONN_TABLE_MAX_SIZE\f[] : Maximum size of the internal table
-data structure used to manage connections.
+.RS
+.RE
+.TP
+.B \f[I]GNI_CONN_TABLE_INITIAL_SIZE\f[]
+Initial size of the internal table data structure used to manage
+connections.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_CONN_TABLE_STEP_SIZE\f[] : Step size for increasing the size of
-the internal table data structure used to manage internal GNI
+.RS
+.RE
+.TP
+.B \f[I]GNI_CONN_TABLE_MAX_SIZE\f[]
+Maximum size of the internal table data structure used to manage
 connections.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_VC_ID_TABLE_CAPACITY\f[] : Size of the virtual channel (VC)
-table used for managing remote connections.
+.RS
+.RE
+.TP
+.B \f[I]GNI_CONN_TABLE_STEP_SIZE\f[]
+Step size for increasing the size of the internal table data structure
+used to manage internal GNI connections.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_MBOX_PAGE_SIZE\f[] : Page size for GNI SMSG mailbox
-allocations.
+.RS
+.RE
+.TP
+.B \f[I]GNI_VC_ID_TABLE_CAPACITY\f[]
+Size of the virtual channel (VC) table used for managing remote
+connections.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_MBOX_NUM_PER_SLAB\f[] : Number of GNI SMSG mailboxes per
-allocation slab.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MBOX_PAGE_SIZE\f[]
+Page size for GNI SMSG mailbox allocations.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_MBOX_MAX_CREDIT\f[] : Maximum number of credits per GNI SMSG
-mailbox.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MBOX_NUM_PER_SLAB\f[]
+Number of GNI SMSG mailboxes per allocation slab.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_MBOX_MSG_MAX_SIZE\f[] : Maximum size of GNI SMSG messages.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MBOX_MAX_CREDIT\f[]
+Maximum number of credits per GNI SMSG mailbox.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_RX_CQ_SIZE\f[] : Recommended GNI receive CQ size.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MBOX_MSG_MAX_SIZE\f[]
+Maximum size of GNI SMSG messages.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_TX_CQ_SIZE\f[] : Recommended GNI transmit CQ size.
+.RS
+.RE
+.TP
+.B \f[I]GNI_RX_CQ_SIZE\f[]
+Recommended GNI receive CQ size.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_MAX_RETRANSMITS\f[] : Maximum number of message retransmits
-before failure.
+.RS
+.RE
+.TP
+.B \f[I]GNI_TX_CQ_SIZE\f[]
+Recommended GNI transmit CQ size.
 The value is of type uint32_t.
-.PP
-\f[I]GNI_MR_CACHE_LAZY_DEREG\f[] : Enable or disable lazy deregistration
-of memory.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MAX_RETRANSMITS\f[]
+Maximum number of message retransmits before failure.
+The value is of type uint32_t.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MR_CACHE_LAZY_DEREG\f[]
+Enable or disable lazy deregistration of memory.
 The value is of type int32_t.
-.PP
-\f[I]GNI_MR_CACHE\f[] : Select the type of cache that the domain will
-use.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MR_CACHE\f[]
+Select the type of cache that the domain will use.
 Valid choices are the following: \[aq]internal\[aq], \[aq]udreg\[aq], or
 \[aq]none\[aq].
 \[aq]internal\[aq] refers to the GNI provider internal registration
@@ -249,33 +329,51 @@ cache.
 \[aq]udreg\[aq] refers to a user level dreg library based cache.
 Lastly, \[aq]none\[aq] refers to device direct registration without a
 provider cache.
-.PP
-\f[I]GNI_MR_HARD_REG_LIMIT\f[] : Maximum number of registrations.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MR_HARD_REG_LIMIT\f[]
+Maximum number of registrations.
 Applies only to the GNI provider cache.
 The value is of type int32_t (\-1 for no limit).
-.PP
-\f[I]GNI_MR_SOFT_REG_LIMIT\f[] : Soft cap on the registration limit.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MR_SOFT_REG_LIMIT\f[]
+Soft cap on the registration limit.
 Applies only to the GNI provider cache.
 The value is of type int32_t (\-1 for no limit).
-.PP
-\f[I]GNI_MR_HARD_STALE_REG_LIMIT\f[] : Maximum number of stale
-registrations to be held in cache.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MR_HARD_STALE_REG_LIMIT\f[]
+Maximum number of stale registrations to be held in cache.
 This applies to the GNI provider cache and the udreg cache.
 The value is of type int32_t (\-1 for no limit for the GNI provider
 cache and udreg cache values must be greater than 0).
-.PP
-\f[I]GNI_MR_UDREG_LIMIT\f[] : Maximum number of registrations.
+.RS
+.RE
+.TP
+.B \f[I]GNI_MR_UDREG_LIMIT\f[]
+Maximum number of registrations.
 Applies only to the udreg cache.
 The value is of type int32_t.
 The value must be greater than 0.
-.PP
-\f[I]GNI_XPMEM_ENABLE\f[] : Enable or disable use of XPMEM for on node
-messages using the GNI provider internal rendezvous protocol.
+.RS
+.RE
+.TP
+.B \f[I]GNI_XPMEM_ENABLE\f[]
+Enable or disable use of XPMEM for on node messages using the GNI
+provider internal rendezvous protocol.
 The value is of type bool.
-.PP
-\f[I]GNI_DGRAM_PROGRESS_TIMEOUT\f[] : Controls timeout value in
-milliseconds for the control progress thread.
+.RS
+.RE
+.TP
+.B \f[I]GNI_DGRAM_PROGRESS_TIMEOUT\f[]
+Controls timeout value in milliseconds for the control progress thread.
 The value is of type uint32_t.
+.RS
+.RE
 .PP
 The \f[C]flush_cache\f[] function allows the user to flush any stale
 registration cache entries from the cache.
@@ -302,11 +400,14 @@ The \f[C]native_amo\f[] function allows the user to call GNI native
 atomics that are not implemented in the libfabric API.
 The parameters for native_amo are the same as the fi_atomic function but
 adds the following parameter:
-.PP
-\f[I]enum gnix_fab_req_type req_type\f[] : The req_type\[aq]s supported
-with this call are GNIX_FAB_RQ_NAMO_AX (AND and XOR), and
-GNIX_FAB_RQ_NAMO_AX_S (AND and XOR 32 bit), GNIX_FAB_RQ_NAMO_FAX (Fetch
-AND and XOR) and GNIX_FAB_RQ_NAMO_FAX_S (Fetch AND and XOR 32 bit).
+.TP
+.B \f[I]enum gnix_fab_req_type req_type\f[]
+The req_type\[aq]s supported with this call are GNIX_FAB_RQ_NAMO_AX (AND
+and XOR), and GNIX_FAB_RQ_NAMO_AX_S (AND and XOR 32 bit),
+GNIX_FAB_RQ_NAMO_FAX (Fetch AND and XOR) and GNIX_FAB_RQ_NAMO_FAX_S
+(Fetch AND and XOR 32 bit).
+.RS
+.RE
 .SH NOTES
 .PP
 The default address format is FI_ADDR_GNI.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_hook.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_hook.7
new file mode 100644
index 000000000..1fab08471
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_hook.7
@@ -0,0 +1,79 @@
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_hook" "7" "2018\-10\-16" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
+.SH NAME
+.PP
+fi_hook \- The Hook Fabric Provider Utility
+.SH OVERVIEW
+.PP
+The hooking provider is a utility function that can intercept calls to
+any provider.
+The hook provider is always available, but has zero impact on calls
+unless enabled.
+It is useful for providing performance data on selected calls or
+debugging information.
+.SH SUPPORTED FEATURES
+.PP
+Hooking support is enabled through the FI_HOOK environment variable.
+To enable hooking, FI_HOOK must be set to the name of one or more of the
+available hooking providers.
+When multiple hooks are specified, the names must be separated by a
+semi\-colon.
+To obtain a list of hooking providers available on the current system,
+one can use the fi_info utility with the \[aq]\-\-env\[aq] command line
+option.
+Hooking providers are usually identified by \[aq]hook\[aq] appearing in
+the provider name.
+.PP
+Known hooking providers include the following:
+.TP
+.B \f[I]ofi_perf_hook\f[]
+This hooks \[aq]fast path\[aq] data operation calls.
+Performance data is captured on call entrance and exit, in order to
+provide an average of how long each call takes to complete.
+See the PERFORMANCE HOOKS section for available performance data.
+.RS
+.RE
+.SH PERFORMANCE HOOKS
+.PP
+The hook provider allows capturing inline performance data by accessing
+the CPU Performance Management Unit (PMU).
+PMU data is only available on Linux systems.
+Additionally, access to PMU data may be restricted to privileged
+(super\-user) applications.
+.PP
+Performance data is captured for critical data transfer calls: fi_msg,
+fi_rma, fi_tagged, fi_cq, and fi_cntr.
+Captured data is displayed as logged data using the FI_LOG_LEVEL trace
+level.
+Performance data is logged when the associated fabric is destroyed.
+.PP
+The environment variable FI_PERF_CNTR is used to identify which
+performance counter is tracked.
+The following counters are available:
+.TP
+.B \f[I]cpu_cycles\f[]
+Counts the number of CPU cycles each function takes to complete.
+.RS
+.RE
+.TP
+.B \f[I]cpu_instr\f[]
+Counts the number of CPU instructions each function takes to complete.
+This is the default performance counter if none is specified.
+.RS
+.RE
+.SH LIMITATIONS
+.PP
+Hooking functionality is not available for providers built using the
+FI_FABRIC_DIRECT feature.
+That is, directly linking to a provider prevents hooking.
+.PP
+The hooking provider does not work with triggered operations.
+Application that use FI_TRIGGER operations that attempt to hook calls
+will likely crash.
+.SH SEE ALSO
+.PP
+\f[C]fabric\f[](7), \f[C]fi_provider\f[](7)
+.SH AUTHORS
+OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_mlx.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_mlx.7
index e2d7cee17..d38ee44bc 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_mlx.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_mlx.7
@@ -1,4 +1,7 @@
-.TH "fi_mlx" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_mlx" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_mlx \- The MLX Fabric Provider
@@ -16,24 +19,66 @@ Supported UCP API version: 1.0
 The \f[I]mlx\f[] provider doesn\[aq]t support all the features defined
 in the libfabric API.
 Here are some of the limitations:
-.PP
-Endpoint types : Only supported type: \f[I]FI_RDM\f[]
-.PP
-Endpoint capabilities : Endpoints can support the only data transfer
-capability \f[I]FI_TAGGED\f[].
-.PP
-Modes : \f[I]FI_CONTEXT\f[] is required.
+.TP
+.B Endpoint types
+Only supported type: \f[I]FI_RDM\f[]
+.RS
+.RE
+.TP
+.B Endpoint capabilities
+Endpoints can support the only data transfer capability
+\f[I]FI_TAGGED\f[].
+.RS
+.RE
+.TP
+.B Modes
+\f[I]FI_CONTEXT\f[] is required.
 That means, all the requests that generate completions must have a valid
 pointer to type \f[I]struct fi_context\f[] passed as the operation
 context.
-.PP
-Threading : The supported mode is FI_THREAD_DOMAIN, i.e.
+.RS
+.RE
+.TP
+.B Threading
+The supported mode is FI_THREAD_DOMAIN, i.e.
 the \f[I]mlx\f[] provider is not thread safe.
-.PP
-Unsupported features : These features are unsupported: connection
-management, event queue, scalable endpoint, passive endpoint, shared
-receive context, rma, atomics.
+.RS
+.RE
+.TP
+.B Unsupported features
+These features are unsupported: connection management, event queue,
+scalable endpoint, passive endpoint, shared receive context, rma,
+atomics.
+.RS
+.RE
 .SH RUNTIME PARAMETERS
+.TP
+.B \f[I]FI_MLX_CONFIG\f[]
+The path to the MLX configuration file (default: none).
+.RS
+.RE
+.TP
+.B \f[I]FI_MLX_TINJECT_LIMIT\f[]
+Maximal tinject message size (default: 1024).
+.RS
+.RE
+.TP
+.B \f[I]FI_MLX_NS_ENABLE\f[]
+Enforce usage of name server functionality for MLX provider (default:
+disabled).
+.RS
+.RE
+.TP
+.B \f[I]FI_MLX_NS_PORT\f[]
+MLX provider\[aq]s name server port (default: 12345).
+.RS
+.RE
+.TP
+.B \f[I]FI_MLX_NS_IFACE\f[]
+IPv4 network interface for MLX provider\[aq]s name server (default:
+any).
+.RS
+.RE
 .SH SEE ALSO
 .PP
 \f[C]fabric\f[](7), \f[C]fi_provider\f[](7),
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_mrail.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_mrail.7
new file mode 100644
index 000000000..1b6e2396d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_mrail.7
@@ -0,0 +1,90 @@
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_mrail" "7" "2018\-12\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
+.SH NAME
+.PP
+fi_mrail \- The Multi\-Rail Utility Provider
+.SH OVERVIEW
+.PP
+The mrail provider (ofi_mrail) is an utility provider that layers over
+an underlying provider to enable the use of multiple network ports
+(rails).
+This increases the total available bandwidth of an underlying proivder.
+The current status of mrail provider is experimental \- not all
+libfabric features are supported and performance is not guaranteed.
+.SH REQUIREMENTS
+.SS Requirements for underlying provider
+.PP
+mrail provider requires the underlying provider to support the following
+capabilities / modes:
+.IP \[bu] 2
+Buffered receive (FI_BUFFERED_RECV)
+.IP \[bu] 2
+FI_SOURCE
+.IP \[bu] 2
+FI_AV_TABLE
+.SS Requirements for applications
+.PP
+Applications need to: * Support FI_MR_RAW MR mode bit to make use of
+FI_RMA capability.
+* Set FI_OFI_MRAIL_ADDR_STRC env variable (see RUNTIME PARAMETERS
+section below).
+.SH SUPPORTED FEATURES
+.TP
+.B \f[I]Endpoint types\f[]
+The provider supports only \f[I]FI_EP_RDM\f[].
+.RS
+.RE
+.TP
+.B \f[I]Endpoint capabilities\f[]
+The following data transfer interface is supported: \f[I]FI_MSG\f[],
+\f[I]FI_TAGGED\f[], \f[I]FI_RMA\f[].
+.RS
+.RE
+.TP
+.B # LIMITATIONS
+Limitations of the underlying provider may show up as that of mrail
+provider.
+.RS
+.RE
+mrail provider doesn\[aq]t allow pass\-through of any mode bits to the
+underlying provider.
+.RS
+.RE
+.SS Unsupported features
+.PP
+The following are the major libfabric features that are not supported.
+Any other feature not listed in "Supported features" can be assumed as
+unsupported.
+.IP \[bu] 2
+FI_ATOMIC
+.IP \[bu] 2
+Scalable endpoints
+.IP \[bu] 2
+Shared contexts
+.IP \[bu] 2
+FABRIC_DIRECT
+.IP \[bu] 2
+Multicast
+.IP \[bu] 2
+Triggered operations
+.SH FUNCTIONALITY OVERVIEW
+.PP
+For messages (FI_MSG, FI_TAGGED), the provider sends one message per
+rail in a round\-robin manner.
+Ordering is guaranteed through the use of sequence numbers.
+For RMA, the data is striped equally across all rails.
+.SH RUNTIME PARAMETERS
+.PP
+The ofi_mrail provider checks for the following environment variables.
+.TP
+.B \f[I]FI_OFI_MRAIL_ADDR_STRC\f[]
+Comma delimited list of individual rail addresses in FI_ADDR_STR format.
+.RS
+.RE
+.SH SEE ALSO
+.PP
+\f[C]fabric\f[](7), \f[C]fi_provider\f[](7), \f[C]fi_getinfo\f[](3)
+.SH AUTHORS
+OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_netdir.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_netdir.7
index a83ae3815..3785465a4 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_netdir.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_netdir.7
@@ -1,4 +1,7 @@
-.TH "fi_netdir" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_netdir" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_netdir \- The Network Direct Fabric Provider
@@ -21,75 +24,122 @@ service provider interface (SPI) for their hardware.
 .PP
 The Network Direct provider support the following features defined for
 the libfabric API:
-.PP
-\f[I]Endpoint types\f[] : The provider support the FI_EP_MSG endpoint
-types.
-.PP
-\f[I]Memory registration modes\f[] : The provider implements the
-\f[I]FI_MR_BASIC\f[] memory registration mode.
-.PP
-\f[I]Data transfer operations\f[] : The following data transfer
-interfaces are supported for the following endpoint types:
-\f[I]FI_MSG\f[], \f[I]FI_RMA\f[].
+.TP
+.B \f[I]Endpoint types\f[]
+The provider support the FI_EP_MSG endpoint types.
+.RS
+.RE
+.TP
+.B \f[I]Memory registration modes\f[]
+The provider implements the \f[I]FI_MR_BASIC\f[] memory registration
+mode.
+.RS
+.RE
+.TP
+.B \f[I]Data transfer operations\f[]
+The following data transfer interfaces are supported for the following
+endpoint types: \f[I]FI_MSG\f[], \f[I]FI_RMA\f[].
 See DATA TRANSFER OPERATIONS below for more details.
-.PP
-\f[I]Modes\f[] : The Network Direct provider requires applications to
-support the following modes: * FI_LOCAL_MR for all applications.
-.PP
-\f[I]Addressing Formats\f[] : Supported addressing formats include
-FI_SOCKADDR, FI_SOCKADDR_IN, FI_SOCKADDR_IN6
-.PP
-\f[I]Progress\f[] : The Network Direct provider supports
-FI_PROGRESS_AUTO: Asynchronous operations make forward progress
-automatically.
-.PP
-\f[I]Operation flags\f[] : The provider supports FI_INJECT,
-FI_COMPLETION, FI_TRANSMIT_COMPLETE, FI_INJECT_COMPLETE,
-FI_DELIVERY_COMPLETE, FI_SELECTIVE_COMPLETION
-.PP
-\f[I]Completion ordering\f[] : RX/TX contexts: FI_ORDER_STRICT
-.PP
-\f[I]Other supported features\f[] : Multiple input/output vector (IOV)
-is supported for FI_RMA read/write and FI_MSG receive/transmit
-operations.
+.RS
+.RE
+.TP
+.B \f[I]Modes\f[]
+The Network Direct provider requires applications to support the
+following modes: * FI_LOCAL_MR for all applications.
+.RS
+.RE
+.TP
+.B \f[I]Addressing Formats\f[]
+Supported addressing formats include FI_SOCKADDR, FI_SOCKADDR_IN,
+FI_SOCKADDR_IN6
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+The Network Direct provider supports FI_PROGRESS_AUTO: Asynchronous
+operations make forward progress automatically.
+.RS
+.RE
+.TP
+.B \f[I]Operation flags\f[]
+The provider supports FI_INJECT, FI_COMPLETION, FI_TRANSMIT_COMPLETE,
+FI_INJECT_COMPLETE, FI_DELIVERY_COMPLETE, FI_SELECTIVE_COMPLETION
+.RS
+.RE
+.TP
+.B \f[I]Completion ordering\f[]
+RX/TX contexts: FI_ORDER_STRICT
+.RS
+.RE
+.TP
+.B \f[I]Other supported features\f[]
+Multiple input/output vector (IOV) is supported for FI_RMA read/write
+and FI_MSG receive/transmit operations.
+.RS
+.RE
 .SH LIMITATIONS
 .PP
 The Network Direct is an experimental provider.
 The full support of the Network Direct provider will be added to 1.6
 release version of libfabric.
-.PP
-\f[I]Memory Regions\f[] : Only FI_MR_BASIC mode is supported.
+.TP
+.B \f[I]Memory Regions\f[]
+Only FI_MR_BASIC mode is supported.
 Adding regions via s/g list is supported only up to a s/g list size of
 1.
 No support for binding memory regions to a counter.
-.PP
-\f[I]Wait objects\f[] : Wait object and wait sets are not supported.
-.PP
-\f[I]Resource Management\f[] : Application has to make sure CQs are not
-overrun as this cannot be detected by the provider.
-.PP
-\f[I]Unsupported Endpoint types\f[] : FI_EP_DGRAM, FI_EP_RDM
-.PP
-\f[I]Other unsupported features\f[] : Scalable endpoints, FABRIC_DIRECT
-.PP
-\f[I]Unsupported features specific to MSG endpoints\f[] : FI_SOURCE,
-FI_TAGGED, FI_CLAIM, fi_ep_alias, shared TX context, operations.
+.RS
+.RE
+.TP
+.B \f[I]Wait objects\f[]
+Wait object and wait sets are not supported.
+.RS
+.RE
+.TP
+.B \f[I]Resource Management\f[]
+Application has to make sure CQs are not overrun as this cannot be
+detected by the provider.
+.RS
+.RE
+.TP
+.B \f[I]Unsupported Endpoint types\f[]
+FI_EP_DGRAM, FI_EP_RDM
+.RS
+.RE
+.TP
+.B \f[I]Other unsupported features\f[]
+Scalable endpoints, FABRIC_DIRECT
+.RS
+.RE
+.TP
+.B \f[I]Unsupported features specific to MSG endpoints\f[]
+FI_SOURCE, FI_TAGGED, FI_CLAIM, fi_ep_alias, shared TX context,
+operations.
+.RS
+.RE
 .SH RUNTIME PARAMETERS
 .PP
 The Network Direct provider checks for the following environment
 variables.
 .SS Variables specific to RDM endpoints
-.PP
-\f[I]FI_NETDIR_INLINETHR\f[] : The size of the (default: 8 Kbyte): *
-Transmitted data that can be inlined * Preposted data for the unexpected
-receive queue
-.PP
-\f[I]FI_NETDIR_PREPOSTCNT\f[] : The number of pre\-registered buffers
-between the endpoints that are not require internal ACK messages, must
-be a power of 2 (default: 8).
-.PP
-\f[I]FI_NETDIR_PREPOSTBUFCNT\f[] : The number of preposted arrays of
-buffers, must be a power of 2 (default: 1).
+.TP
+.B \f[I]FI_NETDIR_INLINETHR\f[]
+The size of the (default: 8 Kbyte): * Transmitted data that can be
+inlined * Preposted data for the unexpected receive queue
+.RS
+.RE
+.TP
+.B \f[I]FI_NETDIR_PREPOSTCNT\f[]
+The number of pre\-registered buffers between the endpoints that are not
+require internal ACK messages, must be a power of 2 (default: 8).
+.RS
+.RE
+.TP
+.B \f[I]FI_NETDIR_PREPOSTBUFCNT\f[]
+The number of preposted arrays of buffers, must be a power of 2
+(default: 1).
+.RS
+.RE
 .SS Environment variables notes
 .PP
 The fi_info utility would give the up\-to\-date information on
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_provider.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_provider.7
index 311e619f5..0a3f08b14 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_provider.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_provider.7
@@ -1,4 +1,7 @@
-.TH "fi_provider" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_provider" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_provider \- Fabric Interface Providers
@@ -16,41 +19,73 @@ referred to as fabric providers, or simply providers.
 This distribution of libfabric contains the following providers
 (although more may be available via run\-time plug\-ins):
 .SS Core providers
-.PP
-\f[I]GNI\f[] : A provider for the Aries interconnect in Cray XC(TM)
-systems utilizing the user\-space \f[I]Generic Networking Interface\f[].
+.TP
+.B \f[I]GNI\f[]
+A provider for the Aries interconnect in Cray XC(TM) systems utilizing
+the user\-space \f[I]Generic Networking Interface\f[].
 See \f[C]fi_gni\f[](7) for more information.
-.PP
-\f[I]PSM\f[] : High\-speed InfiniBand networking from Intel.
+.RS
+.RE
+.TP
+.B \f[I]PSM\f[]
+High\-speed InfiniBand networking from Intel.
 See \f[C]fi_psm\f[](7) for more information.
-.PP
-\f[I]Sockets\f[] : A general purpose provider that can be used on any
-network that supports TCP/UDP sockets.
+.RS
+.RE
+.TP
+.B \f[I]Sockets\f[]
+A general purpose provider that can be used on any network that supports
+TCP/UDP sockets.
 This provider is not intended to provide performance improvements over
 regular TCP/UDP sockets, but rather to allow developers to write, test,
 and debug application code even on platforms that do not have
 high\-speed networking.
 See \f[C]fi_sockets\f[](7) for more information.
-.PP
-\f[I]usNIC\f[] : Ultra low latency Ethernet networking over Cisco
-userspace VIC adapters.
+.RS
+.RE
+.TP
+.B \f[I]usNIC\f[]
+Ultra low latency Ethernet networking over Cisco userspace VIC adapters.
 See \f[C]fi_usnic\f[](7) for more information.
-.PP
-\f[I]Verbs\f[] : This provider uses the Linux Verbs API for network
-transport.
+.RS
+.RE
+.TP
+.B \f[I]Verbs\f[]
+This provider uses the Linux Verbs API for network transport.
 Application performance is, obviously expected to be similar to that of
 the native Linux Verbs API.
 Analogous to the Sockets provider, the Verbs provider is intended to
 enable developers to write, test, and debug application code on
 platforms that only have Linux Verbs\-based networking.
 See \f[C]fi_verbs\f[](7) for more information.
-.PP
-\f[I]Blue Gene/Q\f[] : See \f[C]fi_bgq\f[](7) for more information.
+.RS
+.RE
+.TP
+.B \f[I]Blue Gene/Q\f[]
+See \f[C]fi_bgq\f[](7) for more information.
+.RS
+.RE
 .SS Utility providers
-.PP
-\f[I]RxM\f[] : The RxM provider (ofi_rxm) is an utility provider that
-supports RDM endpoints emulated over MSG endpoints of a core provider.
+.TP
+.B \f[I]RxM\f[]
+The RxM provider (ofi_rxm) is an utility provider that supports RDM
+endpoints emulated over MSG endpoints of a core provider.
 See \f[C]fi_rxm\f[](7) for more information.
+.RS
+.RE
+.SS Special providers
+.TP
+.B \f[I]Hook\f[]
+The hook provider is a special type of provider that can layer over any
+other provider, unless FI_FABRIC_DIRECT is used.
+The hook provider is always available, but has no impact unless enabled.
+When enabled, the hook provider will intercept all calls to the
+underlying core or utility provider(s).
+The hook provider is useful for capturing performance data or providing
+debugging information, even in release builds of the library.
+See \f[C]fi_hook\f[](7) for more information.
+.RS
+.RE
 .SH CORE VERSUS UTILITY PROVIDERS
 .PP
 Core providers implement the libfabric interfaces directly over
@@ -186,26 +221,47 @@ Logging is performed using the FI_ERR, FI_LOG, and FI_DEBUG macros.
 \f[]
 .fi
 .SS ARGUMENTS
-.PP
-\f[I]prov_name\f[] : String representing the provider name.
-.PP
-\f[I]prov\f[] : Provider context structure.
-.PP
-\f[I]level\f[] : Log level associated with log statement.
-.PP
-\f[I]subsystem\f[] : Subsystem being logged from.
+.TP
+.B \f[I]prov_name\f[]
+String representing the provider name.
+.RS
+.RE
+.TP
+.B \f[I]prov\f[]
+Provider context structure.
+.RS
+.RE
+.TP
+.B \f[I]level\f[]
+Log level associated with log statement.
+.RS
+.RE
+.TP
+.B \f[I]subsystem\f[]
+Subsystem being logged from.
+.RS
+.RE
 .SS DESCRIPTION
-.PP
-\f[I]FI_ERR\f[] : Always logged.
-.PP
-\f[I]FI_LOG\f[] : Logged if the intended provider, log level, and
-subsystem parameters match the user supplied values.
-.PP
-\f[I]FI_DEBUG\f[] : Logged if configured with the \-\-enable\-debug
-flag.
+.TP
+.B \f[I]FI_ERR\f[]
+Always logged.
+.RS
+.RE
+.TP
+.B \f[I]FI_LOG\f[]
+Logged if the intended provider, log level, and subsystem parameters
+match the user supplied values.
+.RS
+.RE
+.TP
+.B \f[I]FI_DEBUG\f[]
+Logged if configured with the \-\-enable\-debug flag.
+.RS
+.RE
 .SH SEE ALSO
 .PP
-\f[C]fi_gni\f[](7), \f[C]fi_psm\f[](7), \f[C]fi_sockets\f[](7),
-\f[C]fi_usnic\f[](7), \f[C]fi_verbs\f[](7), \f[C]fi_bgq\f[](7),
+\f[C]fi_gni\f[](7), \f[C]fi_hook\f[](7), \f[C]fi_psm\f[](7),
+\f[C]fi_sockets\f[](7), \f[C]fi_usnic\f[](7), \f[C]fi_verbs\f[](7),
+\f[C]fi_bgq\f[](7),
 .SH AUTHORS
 OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_psm.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_psm.7
index 0b849aa6b..513355278 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_psm.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_psm.7
@@ -1,4 +1,7 @@
-.TH "fi_psm" "7" "2018\-02\-13" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_psm" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_psm \- The PSM Fabric Provider
@@ -23,13 +26,17 @@ exposes a PSM 1.x interface over the Intel Omni\-Path Fabric.
 The \f[I]psm\f[] provider doesn\[aq]t support all the features defined
 in the libfabric API.
 Here are some of the limitations:
-.PP
-Endpoint types : Only support non\-connection based types
-\f[I]FI_DGRAM\f[] and \f[I]FI_RDM\f[]
-.PP
-Endpoint capabilities : Endpoints can support any combination of data
-transfer capabilities \f[I]FI_TAGGED\f[], \f[I]FI_MSG\f[],
-\f[I]FI_ATOMICS\f[], and \f[I]FI_RMA\f[].
+.TP
+.B Endpoint types
+Only support non\-connection based types \f[I]FI_DGRAM\f[] and
+\f[I]FI_RDM\f[]
+.RS
+.RE
+.TP
+.B Endpoint capabilities
+Endpoints can support any combination of data transfer capabilities
+\f[I]FI_TAGGED\f[], \f[I]FI_MSG\f[], \f[I]FI_ATOMICS\f[], and
+\f[I]FI_RMA\f[].
 These capabilities can be further refined by \f[I]FI_SEND\f[],
 \f[I]FI_RECV\f[], \f[I]FI_READ\f[], \f[I]FI_WRITE\f[],
 \f[I]FI_REMOTE_READ\f[], and \f[I]FI_REMOTE_WRITE\f[] to limit the
@@ -42,12 +49,15 @@ For example it is fine to have two endpoints with \f[I]FI_TAGGED\f[] |
 \f[I]FI_RMA\f[] | \f[I]FI_ATOMICS\f[].
 But it is not allowed to have two endpoints with \f[I]FI_TAGGED\f[], or
 two endpoints with \f[I]FI_RMA\f[].
+.RS
+.RE
 .PP
 \f[I]FI_MULTI_RECV\f[] is supported for non\-tagged message queue only.
 .PP
 Other supported capabilities include \f[I]FI_TRIGGER\f[].
-.PP
-Modes : \f[I]FI_CONTEXT\f[] is required for the \f[I]FI_TAGGED\f[] and
+.TP
+.B Modes
+\f[I]FI_CONTEXT\f[] is required for the \f[I]FI_TAGGED\f[] and
 \f[I]FI_MSG\f[] capabilities.
 That means, any request belonging to these two categories that generates
 a completion must pass as the operation context a valid pointer to type
@@ -55,25 +65,33 @@ a completion must pass as the operation context a valid pointer to type
 remain untouched until the request has completed.
 If none of \f[I]FI_TAGGED\f[] and \f[I]FI_MSG\f[] is asked for, the
 \f[I]FI_CONTEXT\f[] mode is not required.
-.PP
-Progress : The \f[I]psm\f[] provider requires manual progress.
+.RS
+.RE
+.TP
+.B Progress
+The \f[I]psm\f[] provider requires manual progress.
 The application is expected to call \f[I]fi_cq_read\f[] or
 \f[I]fi_cntr_read\f[] function from time to time when no other libfabric
 function is called to ensure progress is made in a timely manner.
 The provider does support auto progress mode.
 However, the performance can be significantly impacted if the
 application purely depends on the provider to make auto progress.
-.PP
-Unsupported features : These features are unsupported: connection
-management, scalable endpoint, passive endpoint, shared receive context,
-send/inject with immediate data.
+.RS
+.RE
+.TP
+.B Unsupported features
+These features are unsupported: connection management, scalable
+endpoint, passive endpoint, shared receive context, send/inject with
+immediate data.
+.RS
+.RE
 .SH RUNTIME PARAMETERS
 .PP
 The \f[I]psm\f[] provider checks for the following environment
 variables:
-.PP
-\f[I]FI_PSM_UUID\f[] : PSM requires that each job has a unique ID
-(UUID).
+.TP
+.B \f[I]FI_PSM_UUID\f[]
+PSM requires that each job has a unique ID (UUID).
 All the processes in the same job need to use the same UUID in order to
 be able to talk to each other.
 The PSM reference manual advises to keep UUID unique to each job.
@@ -83,12 +101,15 @@ jobs with the same UUID have exited normally.
 If running into "resource busy" or "connection failure" issues with
 unknown reason, it is advisable to manually set the UUID to a value
 different from the default.
+.RS
+.RE
 .PP
 The default UUID is 0FFF0FFF\-0000\-0000\-0000\-0FFF0FFF0FFF.
-.PP
-\f[I]FI_PSM_NAME_SERVER\f[] : The \f[I]psm\f[] provider has a simple
-built\-in name server that can be used to resolve an IP address or host
-name into a transport address needed by the \f[I]fi_av_insert\f[] call.
+.TP
+.B \f[I]FI_PSM_NAME_SERVER\f[]
+The \f[I]psm\f[] provider has a simple built\-in name server that can be
+used to resolve an IP address or host name into a transport address
+needed by the \f[I]fi_av_insert\f[] call.
 The main purpose of this name server is to allow simple client\-server
 type applications (such as those in \f[I]fabtests\f[]) to be written
 purely with libfabric, without using any out\-of\-band communication
@@ -104,6 +125,8 @@ Optionally the \f[I]service\f[] parameter can be used in addition to
 \f[I]node\f[].
 Notice that the \f[I]service\f[] number is interpreted by the provider
 and is not a TCP/IP port number.
+.RS
+.RE
 .PP
 The name server is on by default.
 It can be turned off by setting the variable to 0.
@@ -112,13 +135,16 @@ created when the name server is on.
 .PP
 The provider detects OpenMPI and MPICH runs and changes the default
 setting to off.
-.PP
-\f[I]FI_PSM_TAGGED_RMA\f[] : The RMA functions are implemented on top of
-the PSM Active Message functions.
+.TP
+.B \f[I]FI_PSM_TAGGED_RMA\f[]
+The RMA functions are implemented on top of the PSM Active Message
+functions.
 The Active Message functions have limit on the size of data can be
 transferred in a single message.
 Large transfers can be divided into small chunks and be pipe\-lined.
 However, the bandwidth is sub\-optimal by doing this way.
+.RS
+.RE
 .PP
 The \f[I]psm\f[] provider use PSM tag\-matching message queue functions
 to achieve higher bandwidth for large size RMA.
@@ -127,39 +153,50 @@ RMA traffic from the regular tagged message queue.
 .PP
 The option is on by default.
 To turn it off set the variable to 0.
-.PP
-\f[I]FI_PSM_AM_MSG\f[] : The \f[I]psm\f[] provider implements the
-non\-tagged message queue over the PSM tag\-matching message queue.
+.TP
+.B \f[I]FI_PSM_AM_MSG\f[]
+The \f[I]psm\f[] provider implements the non\-tagged message queue over
+the PSM tag\-matching message queue.
 One tag bit is reserved for this purpose.
 Alternatively, the non\-tagged message queue can be implemented over
 Active Message.
 This experimental feature has slightly larger latency.
+.RS
+.RE
 .PP
 This option is off by default.
 To turn it on set the variable to 1.
-.PP
-\f[I]FI_PSM_DELAY\f[] : Time (seconds) to sleep before closing PSM
-endpoints.
+.TP
+.B \f[I]FI_PSM_DELAY\f[]
+Time (seconds) to sleep before closing PSM endpoints.
 This is a workaround for a bug in some versions of PSM library.
+.RS
+.RE
 .PP
 The default setting is 1.
-.PP
-\f[I]FI_PSM_TIMEOUT\f[] : Timeout (seconds) for gracefully closing PSM
-endpoints.
+.TP
+.B \f[I]FI_PSM_TIMEOUT\f[]
+Timeout (seconds) for gracefully closing PSM endpoints.
 A forced closing will be issued if timeout expires.
+.RS
+.RE
 .PP
 The default setting is 5.
-.PP
-\f[I]FI_PSM_PROG_INTERVAL\f[] : When auto progress is enabled (asked via
-the hints to \f[I]fi_getinfo\f[]), a progress thread is created to make
-progress calls from time to time.
+.TP
+.B \f[I]FI_PSM_PROG_INTERVAL\f[]
+When auto progress is enabled (asked via the hints to
+\f[I]fi_getinfo\f[]), a progress thread is created to make progress
+calls from time to time.
 This option set the interval (microseconds) between progress calls.
+.RS
+.RE
 .PP
 The default setting is 1 if affinity is set, or 1000 if not.
 See \f[I]FI_PSM_PROG_AFFINITY\f[].
-.PP
-\f[I]FI_PSM_PROG_AFFINITY\f[] : When set, specify the set of CPU cores
-to set the progress thread affinity to.
+.TP
+.B \f[I]FI_PSM_PROG_AFFINITY\f[]
+When set, specify the set of CPU cores to set the progress thread
+affinity to.
 The format is
 \f[C]<start>[:<end>[:<stride>]][,<start>[:<end>[:<stride>]]]*\f[], where
 each triplet \f[C]<start>:<end>:<stride>\f[] defines a block of
@@ -167,6 +204,8 @@ core_ids.
 Both \f[C]<start>\f[] and \f[C]<end>\f[] can be either the
 \f[C]core_id\f[] (when >=0) or \f[C]core_id\ \-\ num_cores\f[] (when
 <0).
+.RS
+.RE
 .PP
 By default affinity is not set.
 .SH SEE ALSO
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_psm2.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_psm2.7
index cebcb3688..7801cce90 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_psm2.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_psm2.7
@@ -1,4 +1,7 @@
-.TH "fi_psm2" "7" "2018\-02\-21" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_psm2" "7" "2018\-10\-23" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_psm2 \- The PSM2 Fabric Provider
@@ -16,17 +19,23 @@ Fabric.
 The \f[I]psm2\f[] provider doesn\[aq]t support all the features defined
 in the libfabric API.
 Here are some of the limitations:
-.PP
-Endpoint types : Only support non\-connection based types
-\f[I]FI_DGRAM\f[] and \f[I]FI_RDM\f[]
-.PP
-Endpoint capabilities : Endpoints can support any combination of data
-transfer capabilities \f[I]FI_TAGGED\f[], \f[I]FI_MSG\f[],
-\f[I]FI_ATOMICS\f[], and \f[I]FI_RMA\f[].
+.TP
+.B Endpoint types
+Only support non\-connection based types \f[I]FI_DGRAM\f[] and
+\f[I]FI_RDM\f[]
+.RS
+.RE
+.TP
+.B Endpoint capabilities
+Endpoints can support any combination of data transfer capabilities
+\f[I]FI_TAGGED\f[], \f[I]FI_MSG\f[], \f[I]FI_ATOMICS\f[], and
+\f[I]FI_RMA\f[].
 These capabilities can be further refined by \f[I]FI_SEND\f[],
 \f[I]FI_RECV\f[], \f[I]FI_READ\f[], \f[I]FI_WRITE\f[],
 \f[I]FI_REMOTE_READ\f[], and \f[I]FI_REMOTE_WRITE\f[] to limit the
 direction of operations.
+.RS
+.RE
 .PP
 \f[I]FI_MULTI_RECV\f[] is supported for non\-tagged message queue only.
 .PP
@@ -41,8 +50,9 @@ Other supported capabilities include \f[I]FI_TRIGGER\f[],
 and \f[I]FI_SOURCE_ERR\f[].
 Furthermore, \f[I]FI_NAMED_RX_CTX\f[] is supported when scalable
 endpoints are enabled.
-.PP
-Modes : \f[I]FI_CONTEXT\f[] is required for the \f[I]FI_TAGGED\f[] and
+.TP
+.B Modes
+\f[I]FI_CONTEXT\f[] is required for the \f[I]FI_TAGGED\f[] and
 \f[I]FI_MSG\f[] capabilities.
 That means, any request belonging to these two categories that generates
 a completion must pass as the operation context a valid pointer to type
@@ -50,23 +60,31 @@ a completion must pass as the operation context a valid pointer to type
 remain untouched until the request has completed.
 If none of \f[I]FI_TAGGED\f[] and \f[I]FI_MSG\f[] is asked for, the
 \f[I]FI_CONTEXT\f[] mode is not required.
-.PP
-Progress : The \f[I]psm2\f[] provider requires manual progress.
+.RS
+.RE
+.TP
+.B Progress
+The \f[I]psm2\f[] provider requires manual progress.
 The application is expected to call \f[I]fi_cq_read\f[] or
 \f[I]fi_cntr_read\f[] function from time to time when no other libfabric
 function is called to ensure progress is made in a timely manner.
 The provider does support auto progress mode.
 However, the performance can be significantly impacted if the
 application purely depends on the provider to make auto progress.
-.PP
-Scalable endpoints : Scalable endpoints support depends on the multi\-EP
-feature of the \f[I]PSM2\f[] library.
+.RS
+.RE
+.TP
+.B Scalable endpoints
+Scalable endpoints support depends on the multi\-EP feature of the
+\f[I]PSM2\f[] library.
 If the \f[I]PSM2\f[] library supports this feature, the availability is
 further controlled by an environment variable \f[I]PSM2_MULTI_EP\f[].
 The \f[I]psm2\f[] provider automatically sets this variable to 1 if it
 is not set.
 The feature can be disabled explicitly by setting \f[I]PSM2_MULTI_EP\f[]
 to 0.
+.RS
+.RE
 .PP
 When creating a scalable endpoint, the exact number of contexts
 requested should be set in the "fi_info" structure passed to the
@@ -81,24 +99,30 @@ For optimal performance, it is advised to avoid having multiple threads
 accessing the same context, either directly by posting
 send/recv/read/write request, or indirectly by polling associated
 completion queues or counters.
-.PP
-Shared Tx contexts : In order to achieve the purpose of saving PSM
-context by using shared Tx context, the endpoints bound to the shared Tx
-contexts need to be Tx only.
+.TP
+.B Shared Tx contexts
+In order to achieve the purpose of saving PSM context by using shared Tx
+context, the endpoints bound to the shared Tx contexts need to be Tx
+only.
 The reason is that Rx capability always requires a PSM context, which
 can also be automatically used for Tx.
 As the result, allocating a shared Tx context for Rx capable endpoints
 actually consumes one extra context instead of saving some.
-.PP
-Unsupported features : These features are unsupported: connection
-management, passive endpoint, and shared receive context.
+.RS
+.RE
+.TP
+.B Unsupported features
+These features are unsupported: connection management, passive endpoint,
+and shared receive context.
+.RS
+.RE
 .SH RUNTIME PARAMETERS
 .PP
 The \f[I]psm2\f[] provider checks for the following environment
 variables:
-.PP
-\f[I]FI_PSM2_UUID\f[] : PSM requires that each job has a unique ID
-(UUID).
+.TP
+.B \f[I]FI_PSM2_UUID\f[]
+PSM requires that each job has a unique ID (UUID).
 All the processes in the same job need to use the same UUID in order to
 be able to talk to each other.
 The PSM reference manual advises to keep UUID unique to each job.
@@ -108,12 +132,15 @@ jobs with the same UUID have exited normally.
 If running into "resource busy" or "connection failure" issues with
 unknown reason, it is advisable to manually set the UUID to a value
 different from the default.
+.RS
+.RE
 .PP
 The default UUID is 00FF00FF\-0000\-0000\-0000\-00FF0F0F00FF.
-.PP
-\f[I]FI_PSM2_NAME_SERVER\f[] : The \f[I]psm2\f[] provider has a simple
-built\-in name server that can be used to resolve an IP address or host
-name into a transport address needed by the \f[I]fi_av_insert\f[] call.
+.TP
+.B \f[I]FI_PSM2_NAME_SERVER\f[]
+The \f[I]psm2\f[] provider has a simple built\-in name server that can
+be used to resolve an IP address or host name into a transport address
+needed by the \f[I]fi_av_insert\f[] call.
 The main purpose of this name server is to allow simple client\-server
 type applications (such as those in \f[I]fabtests\f[]) to be written
 purely with libfabric, without using any out\-of\-band communication
@@ -129,6 +156,8 @@ Optionally the \f[I]service\f[] parameter can be used in addition to
 \f[I]node\f[].
 Notice that the \f[I]service\f[] number is interpreted by the provider
 and is not a TCP/IP port number.
+.RS
+.RE
 .PP
 The name server is on by default.
 It can be turned off by setting the variable to 0.
@@ -137,13 +166,16 @@ created when the name server is on.
 .PP
 The provider detects OpenMPI and MPICH runs and changes the default
 setting to off.
-.PP
-\f[I]FI_PSM2_TAGGED_RMA\f[] : The RMA functions are implemented on top
-of the PSM Active Message functions.
+.TP
+.B \f[I]FI_PSM2_TAGGED_RMA\f[]
+The RMA functions are implemented on top of the PSM Active Message
+functions.
 The Active Message functions have limit on the size of data can be
 transferred in a single message.
 Large transfers can be divided into small chunks and be pipe\-lined.
 However, the bandwidth is sub\-optimal by doing this way.
+.RS
+.RE
 .PP
 The \f[I]psm2\f[] provider use PSM tag\-matching message queue functions
 to achieve higher bandwidth for large size RMA.
@@ -152,29 +184,37 @@ the RMA traffic from the regular tagged message queue.
 .PP
 The option is on by default.
 To turn it off set the variable to 0.
-.PP
-\f[I]FI_PSM2_DELAY\f[] : Time (seconds) to sleep before closing PSM
-endpoints.
+.TP
+.B \f[I]FI_PSM2_DELAY\f[]
+Time (seconds) to sleep before closing PSM endpoints.
 This is a workaround for a bug in some versions of PSM library.
+.RS
+.RE
 .PP
 The default setting is 0.
-.PP
-\f[I]FI_PSM2_TIMEOUT\f[] : Timeout (seconds) for gracefully closing PSM
-endpoints.
+.TP
+.B \f[I]FI_PSM2_TIMEOUT\f[]
+Timeout (seconds) for gracefully closing PSM endpoints.
 A forced closing will be issued if timeout expires.
+.RS
+.RE
 .PP
 The default setting is 5.
-.PP
-\f[I]FI_PSM2_PROG_INTERVAL\f[] : When auto progress is enabled (asked
-via the hints to \f[I]fi_getinfo\f[]), a progress thread is created to
-make progress calls from time to time.
+.TP
+.B \f[I]FI_PSM2_PROG_INTERVAL\f[]
+When auto progress is enabled (asked via the hints to
+\f[I]fi_getinfo\f[]), a progress thread is created to make progress
+calls from time to time.
 This option set the interval (microseconds) between progress calls.
+.RS
+.RE
 .PP
 The default setting is 1 if affinity is set, or 1000 if not.
 See \f[I]FI_PSM2_PROG_AFFINITY\f[].
-.PP
-\f[I]FI_PSM2_PROG_AFFINITY\f[] : When set, specify the set of CPU cores
-to set the progress thread affinity to.
+.TP
+.B \f[I]FI_PSM2_PROG_AFFINITY\f[]
+When set, specify the set of CPU cores to set the progress thread
+affinity to.
 The format is
 \f[C]<start>[:<end>[:<stride>]][,<start>[:<end>[:<stride>]]]*\f[], where
 each triplet \f[C]<start>:<end>:<stride>\f[] defines a block of
@@ -182,52 +222,42 @@ core_ids.
 Both \f[C]<start>\f[] and \f[C]<end>\f[] can be either the
 \f[C]core_id\f[] (when >=0) or \f[C]core_id\ \-\ num_cores\f[] (when
 <0).
+.RS
+.RE
 .PP
 By default affinity is not set.
-.PP
-\f[I]FI_PSM2_INJECT_SIZE\f[] : Maximum message size allowed for
-fi_inject and fi_tinject calls.
+.TP
+.B \f[I]FI_PSM2_INJECT_SIZE\f[]
+Maximum message size allowed for fi_inject and fi_tinject calls.
 This is an experimental feature to allow some applications to override
 default inject size limitation.
 When the inject size is larger than the default value, some inject calls
 might block.
+.RS
+.RE
 .PP
 The default setting is 64.
-.PP
-\f[I]FI_PSM2_LOCK_LEVEL\f[] : When set, dictate the level of locking
-being used by the provider.
+.TP
+.B \f[I]FI_PSM2_LOCK_LEVEL\f[]
+When set, dictate the level of locking being used by the provider.
 Level 2 means all locks are enabled.
 Level 1 disables some locks and is suitable for runs that limit the
 access to each PSM2 context to a single thread.
 Level 0 disables all locks and thus is only suitable for single threaded
 runs.
+.RS
+.RE
 .PP
 To use level 0 or level 1, wait object and auto progress mode cannot be
 used because they introduce internal threads that may break the
 conditions needed for these levels.
 .PP
 The default setting is 2.
-.PP
-\f[I]FI_PSM2_LAZY_CONN\f[] : Control when connections are established
-between PSM2 endpoints that OFI endpoints are built on top of.
-When set to 0, connections are established when addresses are inserted
-into the address vector.
-This is the eager connection mode.
-When set to 1, connections are established when addresses are used the
-first time in communication.
-This is the lazy connection mode.
-.PP
-Lazy connection mode may reduce the start\-up time on large systems at
-the expense of slightly higher data path overhead.
-For applications that use multiple endpoints, lazy connection mode can
-be especially helpful with the potential of greatly reduce the time to
-set up address vectors and to close endpoints.
-.PP
-The default setting is 0.
-.PP
-\f[I]FI_PSM2_DISCONNECT\f[] : The provider has a mechanism to
-automatically send disconnection notifications to all connected peers
-before the local endpoint is closed.
+.TP
+.B \f[I]FI_PSM2_DISCONNECT\f[]
+The provider has a mechanism to automatically send disconnection
+notifications to all connected peers before the local endpoint is
+closed.
 As the response, the peers call \f[I]psm2_ep_disconnect\f[] to clean up
 the connection state at their side.
 This allows the same PSM2 epid be used by different dynamically started
@@ -236,6 +266,8 @@ This mechanism, however, introduce extra overhead to the finalization
 phase.
 For applications that never reuse epids within the same session such
 overhead is unnecessary.
+.RS
+.RE
 .PP
 This option controls whether the automatic disconnection notification
 mechanism should be enabled.
@@ -243,9 +275,9 @@ For client\-server application mentioned above, the client side should
 set this option to 1, but the server should set it to 0.
 .PP
 The default setting is 0.
-.PP
-\f[I]FI_PSM2_TAG_LAYOUT\f[] : Select how the 96\-bit PSM2 tag bits are
-organized.
+.TP
+.B \f[I]FI_PSM2_TAG_LAYOUT\f[]
+Select how the 96\-bit PSM2 tag bits are organized.
 Currently three choices are available: \f[I]tag60\f[] means 32\-4\-60
 partitioning for CQ data, internal protocol flags, and application tag.
 \f[I]tag64\f[] means 4\-28\-64 partitioning for internal protocol flags,
@@ -259,6 +291,8 @@ including \f[I]FI_REMOTE_CQ_DATA\f[] in \f[I]hints\->caps\f[], otherwise
 If \f[I]tag64\f[] is the result of automatic selection,
 \f[I]fi_getinfo\f[] also returns a second instance of the provider with
 \f[I]tag60\f[] layout.
+.RS
+.RE
 .PP
 The default setting is \f[I]auto\f[].
 .PP
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rstream.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rstream.7
new file mode 100644
index 000000000..60ec49c8d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rstream.7
@@ -0,0 +1,103 @@
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_rstream" "7" "2018\-11\-21" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
+.SH NAME
+.PP
+fi_rstream
+.SH OVERVIEW
+.PP
+The rstream provider supports stream messaging over message based RMA.
+It maps stream to message over a core RMA\-based OFI provider.
+Only Endpoints and EQs are needed for connection start\-up and
+messaging.
+Unlike other OFI providers, rstream does not support CQs or memory
+registration of any kind.
+In order to asynchronously wait for a completion (cm/msg), one can use
+fi_control on the endpoint/eq to get an fd to use in a poll call.
+For messaging completions, use FI_PEEK on send/recv after poll to see
+what type of transaction has transpired.
+.SH SUPPORTED FEATURES
+.PP
+The rstream provider currently supports \f[I]FI_MSG\f[] capabilities.
+.TP
+.B \f[I]Endpoint types\f[]
+The provider supports only endpoint type \f[I]FI_EP_SOCK_STREAM\f[].
+.RS
+.RE
+.PP
+\f[I]Endpoint capabilities\f[] : The following data transfer interface
+is supported: \f[I]fi_msg\f[].
+.TP
+.B \f[I]Modes\f[]
+The provider does not require the use of any mode bits but supports core
+providers that require FI_CONTEXT and FI_RX_CQ_DATA.
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+The rstream provider only supports \f[I]FI_PROGRESS_MANUAL\f[].
+.RS
+.RE
+.TP
+.B \f[I]Threading Model\f[]
+The provider supports FI_THREAD_SAFE
+.RS
+.RE
+.TP
+.B \f[I]Verbs\-iWarp\f[]
+The provider has added features to enable iWarp.
+To use this feature, the ep protocol IWARP must be requested in a
+getinfo call.
+.RS
+.RE
+.SH LIMITATIONS
+.PP
+The rstream provider is experimental and lacks performance validation
+and extensive testing.
+The iWarp protocol may need extra initialization work to re\-enable.
+Currently the rstream provider is used to by the rsockets\-OFI library
+as a ULP and hooks into the core provider verbs.
+It is not interoperable with the previous rsockets(v1) protocol.
+There are default settings that limit the message stream (provider
+memory region size and CQ size).
+These can be modified by fi_setopt.
+.SH SETTINGS
+.PP
+The \f[I]rstream\f[] provider settings can be modified via fi_setopt on
+the endpoint (FI_OPT_ENDPOINT) along with the following parameters:
+.TP
+.B \f[I]FI_OPT_SEND_BUF_SIZE\f[]
+Size of the send buffer.
+Default is 32KB.
+.RS
+.RE
+.TP
+.B \f[I]FI_OPT_RECV_BUF_SIZE\f[]
+Size of the recv buffer.
+Default is 32KB.
+.RS
+.RE
+.TP
+.B \f[I]FI_OPT_TX_SIZE\f[]
+Size of the send queue.
+Default is 384.
+.RS
+.RE
+.TP
+.B \f[I]FI_OPT_RX_SIZE\f[]
+Size of the recv queue.
+Default is 384.
+.RS
+.RE
+.SH OFI EXTENSIONS
+.PP
+The rstream provider has extended the current OFI API set in order to
+enable a user implemenation of Poll.
+Specifically sendmsg(FI_PEEK) is supported which replicates the behavior
+of the recvmsg(FI_PEEK) feature.
+.SH SEE ALSO
+.PP
+\f[C]fabric\f[](7), \f[C]fi_provider\f[](7), \f[C]fi_getinfo\f[](3)
+.SH AUTHORS
+OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rxd.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rxd.7
index f385c7253..d4723ec0c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rxd.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rxd.7
@@ -1,4 +1,7 @@
-.TH "fi_rxd" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_rxd" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_rxd \- The RxD (RDM over DGRAM) Utility Provider
@@ -8,24 +11,26 @@ The RxD provider is a utility provider that supports RDM endpoints
 emulated over a base DGRAM provider.
 .SH SUPPORTED FEATURES
 .PP
-The RxD provider currently supports \f[I]FI_MSG\f[], \f[I]FI_TAGGED\f[]
-and \f[I]FI_RMA\f[] capabilities.
-It requires the base DGRAM provider to support \f[I]FI_MSG\f[]
-capabilities.
-.PP
-\f[I]Endpoint types\f[] : The provider supports only endpoint type
-\f[I]FI_EP_RDM\f[].
+The RxD provider currently supports \f[I]FI_MSG\f[] capabilities.
+.TP
+.B \f[I]Endpoint types\f[]
+The provider supports only endpoint type \f[I]FI_EP_RDM\f[].
+.RS
+.RE
 .PP
 \f[I]Endpoint capabilities\f[] : The following data transfer interface
-is supported: \f[I]fi_msg\f[], \f[I]fi_tagged\f[] and \f[I]fi_rma\f[].
-.PP
-\f[I]Modes\f[] : The provider does not require the use of any mode bits.
-.PP
-\f[I]Progress\f[] : The RxD provider supports both
-\f[I]FI_PROGRESS_AUTO\f[] and \f[I]FI_PROGRESS_MANUAL\f[], with a
-default set to auto.
-However, receive side data buffers are not modified outside of
-completion processing routines.
+is supported: \f[I]fi_msg\f[].
+.TP
+.B \f[I]Modes\f[]
+The provider does not require the use of any mode bits but supports core
+DGRAM providers that require FI_CONTEXT and FI_MSG_PREFIX.
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+The RxD provider only supports \f[I]FI_PROGRESS_MANUAL\f[].
+.RS
+.RE
 .SH LIMITATIONS
 .PP
 The RxD provider has hard\-coded maximums for supported queue sizes and
@@ -40,7 +45,34 @@ The RxD provider is still under development and is not extensively
 tested.
 .SH RUNTIME PARAMETERS
 .PP
-No runtime parameters are currently defined.
+The \f[I]rxd\f[] provider checks for the following environment
+variables:
+.TP
+.B \f[I]FI_OFI_RXD_SPIN_COUNT\f[]
+Number of times to read the core provider\[aq]s CQ for a segment
+completion before trying to progress sends.
+Default is 1000.
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXD_RETRY\f[]
+Toggles retrying of packets and assumes reliability of individual
+packets and will reassemble all received packets.
+Retrying is turned on by default.
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXD_MAX_PEERS\f[]
+Maximum number of peers the provider should prepare to track.
+Default: 1024
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXD_MAX_UNACKED\f[]
+Maximum number of packets (per peer) to send at a time.
+Default: 128
+.RS
+.RE
 .SH SEE ALSO
 .PP
 \f[C]fabric\f[](7), \f[C]fi_provider\f[](7), \f[C]fi_getinfo\f[](3)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rxm.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rxm.7
index 2d7bc335a..94055936c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rxm.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_rxm.7
@@ -1,38 +1,77 @@
-.TH "fi_rxm" "7" "2018\-02\-19" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_rxm" "7" "2018\-12\-19" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_rxm \- The RxM (RDM over MSG) Utility Provider
 .SH OVERVIEW
 .PP
-The RxM provider (ofi_rxm) is an utility provider that supports RDM
-endpoint emulated over MSG endpoint of a core provider.
+The RxM provider (ofi_rxm) is an utility provider that supports
+FI_EP_RDM type endpoint emulated over FI_EP_MSG type endpoint(s) of an
+underlying core provider.
+FI_EP_RDM endpoints have a reliable unconnected messaging interface and
+RxM emulates this by hiding the connection management of underlying
+FI_EP_MSG endpoints from the user.
+Additionally, RxM can hide memory registration requirement from a core
+provider like verbs if the apps don\[aq]t support it.
 .SH REQUIREMENTS
+.SS Requirements for core provider
 .PP
 RxM provider requires the core provider to support the following
 features:
 .IP \[bu] 2
 MSG endpoints (FI_EP_MSG)
 .IP \[bu] 2
-RMA read/write (FI_RMA)
+RMA read/write (FI_RMA) \- Used for implementing rendezvous protocol for
+large messages.
 .IP \[bu] 2
-FI_OPT_CM_DATA_SIZE of at least 24 bytes
+FI_OPT_CM_DATA_SIZE of at least 48 bytes
+.SS Requirements for applications
+.PP
+Since RxM emulates RDM endpoints by hiding connection management and
+connections are established only on\-demand (when app tries to send
+data), the first several data transfer calls would return EAGAIN.
+Applications should be aware of this and retry until the operation
+succeeds.
+.PP
+If an application has chosen manual progress for data progress, it
+should also read the CQ so that the connection establishment progresses.
+Not doing so would result in a stall.
+See also the ERRORS section in fi_msg(3).
 .SH SUPPORTED FEATURES
 .PP
-The RxM provider currently supports \f[I]FI_MSG\f[], \f[I]FI_TAGGED\f[]
-and \f[I]FI_RMA\f[] capabilities.
-.PP
-\f[I]Endpoint types\f[] : The provider supports only \f[I]FI_EP_RDM\f[].
-.PP
-\f[I]Endpoint capabilities\f[] : The following data transfer interface
-is supported: \f[I]FI_MSG\f[], \f[I]FI_TAGGED\f[], \f[I]FI_RMA\f[].
-.PP
-\f[I]Progress\f[] : The RxM provider supports \f[I]FI_PROGRESS_AUTO\f[].
-.PP
-\f[I]Addressing Formats\f[] : FI_SOCKADDR, FI_SOCKADDR_IN
-.PP
-\f[I]Memory Region\f[] : FI_MR_VIRT_ADDR, FI_MR_ALLOCATED,
-FI_MR_PROV_KEY MR mode bits would be required from the app in case the
-core provider requires it.
+The RxM provider currently supports \f[I]FI_MSG\f[], \f[I]FI_TAGGED\f[],
+\f[I]FI_RMA\f[] and \f[I]FI_ATOMIC\f[] capabilities.
+.TP
+.B \f[I]Endpoint types\f[]
+The provider supports only \f[I]FI_EP_RDM\f[].
+.RS
+.RE
+.TP
+.B \f[I]Endpoint capabilities\f[]
+The following data transfer interface is supported: \f[I]FI_MSG\f[],
+\f[I]FI_TAGGED\f[], \f[I]FI_RMA\f[], \f[I]FI_ATOMIC\f[].
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+The RxM provider supports both \f[I]FI_PROGRESS_MANUAL\f[] and
+\f[I]FI_PROGRESS_AUTO\f[].
+The former is more optimal.
+.RS
+.RE
+.TP
+.B \f[I]Addressing Formats\f[]
+FI_SOCKADDR, FI_SOCKADDR_IN
+.RS
+.RE
+.TP
+.B \f[I]Memory Region\f[]
+FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY MR mode bits would be
+required from the app in case the core provider requires it.
+.RS
+.RE
 .SH LIMITATIONS
 .PP
 When using RxM provider, some limitations from the underlying MSG
@@ -45,8 +84,6 @@ RxM provider does not support the following features:
 .IP \[bu] 2
 op_flags: FI_FENCE.
 .IP \[bu] 2
-FI_ATOMIC
-.IP \[bu] 2
 Scalable endpoints
 .IP \[bu] 2
 Shared contexts
@@ -66,25 +103,105 @@ FI_ADDR_STR, FI_SYNC_ERR
 Reporting unknown source addr data as part of completions
 .IP \[bu] 2
 Triggered operations
-.SS Auto progress
+.SS Progress limitations
 .PP
 When sending large messages, an app doing an sread or waiting on the CQ
 file descriptor may not get a completion when reading the CQ after being
 woken up from the wait.
 The app has to do sread or wait on the file descriptor again.
+This is needed because RxM uses a rendezvous protocol for large message
+sends.
+An app would get woken up from waiting on CQ fd when rendezvous protocol
+request completes but it would have to wait again to get an ACK from the
+receiver indicating completion of large message transfer by remote RMA
+read.
+.SS FI_ATOMIC limitations
+.PP
+The FI_ATOMIC capability will only be listed in the fi_info if the
+fi_info hints parameter specifies FI_ATOMIC.
+If FI_ATOMIC is requested, message order FI_ORDER_RAR, FI_ORDER_RAW,
+FI_ORDER_WAR, FI_ORDER_WAW, FI_ORDER_SAR, and FI_ORDER_SAW can not be
+supported.
 .SH RUNTIME PARAMETERS
 .PP
 The ofi_rxm provider checks for the following environment variables.
-.PP
-\f[I]FI_OFI_RXM_BUFFER_SIZE\f[] : Defines the transmit buffer size /
-inject size.
+.TP
+.B \f[I]FI_OFI_RXM_BUFFER_SIZE\f[]
+Defines the transmit buffer size / inject size.
 Messages of size less than this would be transmitted via an eager
-protocol and those above would be transmitted via a rendezvous protocol.
+protocol and those above would be transmitted via a rendezvous or SAR
+(Segmentation And Reassembly) protocol.
 Transmit data would be copied up to this size (default: ~16k).
-.PP
-\f[I]FI_OFI_RXM_COMP_PER_PROGRESS\f[] : Defines the maximum number of
-MSG provider CQ entries (default: 1) that would be read per progress
-(RxM CQ read).
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXM_COMP_PER_PROGRESS\f[]
+Defines the maximum number of MSG provider CQ entries (default: 1) that
+would be read per progress (RxM CQ read).
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXM_SAR_LIMIT\f[]
+Set this environment variable to control the RxM SAR (Segmentation And
+Reassembly) protocol.
+Messages of size greater than this (default: 256 Kb) would be
+transmitted via rendezvous protocol.
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXM_USE_SRX\f[]
+Set this to 1 to use shared receive context from MSG provider.
+This reduces overall memory usage but there may be a slight increase in
+latency (default: 0).
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXM_TX_SIZE\f[]
+Defines default TX context size (default: 1024)
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXM_RX_SIZE\f[]
+Defines default RX context size (default: 1024)
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXM_MSG_TX_SIZE\f[]
+Defines FI_EP_MSG TX size that would be requested (default: 128).
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_RXM_MSG_RX_SIZE\f[]
+Defines FI_EP_MSG RX size that would be requested (default: 128).
+.RS
+.RE
+.TP
+.B \f[I]FI_UNIVERSE_SIZE\f[]
+Defines the expected number of ranks / peers an endpoint would
+communicate with (default: 256).
+.RS
+.RE
+.SH Tuning
+.SS Bandwidth
+.PP
+To optimize for bandwidth, ensure you use higher values than default for
+FI_OFI_RXM_TX_SIZE, FI_OFI_RXM_RX_SIZE, FI_OFI_RXM_MSG_TX_SIZE,
+FI_OFI_RXM_MSG_RX_SIZE subject to memory limits of the system and the tx
+and rx sizes supported by the MSG provider.
+.PP
+FI_OFI_RXM_SAR_LIMIT is another knob that can be experimented with to
+optimze for bandwidth.
+.SS Memory
+.PP
+To conserve memory, ensure FI_UNIVERSE_SIZE set to what is required.
+Similarly check that FI_OFI_RXM_TX_SIZE, FI_OFI_RXM_RX_SIZE,
+FI_OFI_RXM_MSG_TX_SIZE and FI_OFI_RXM_MSG_RX_SIZE env variables are set
+to only required values.
+.SH NOTES
+.PP
+The data transfer API may return \-FI_EAGAIN during on\-demand
+connection setup of the core provider FI_MSG_EP.
+See \f[C]fi_msg\f[](3) for a detailed description of handling FI_EAGAIN.
 .SH SEE ALSO
 .PP
 \f[C]fabric\f[](7), \f[C]fi_provider\f[](7), \f[C]fi_getinfo\f[](3)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_shm.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_shm.7
index 2d76a7bf5..61b092d4f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_shm.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_shm.7
@@ -1,4 +1,7 @@
-.TH "fi_shm" "7" "2018\-02\-13" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_shm" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_shm \- The SHM Fabric Provider
@@ -13,22 +16,30 @@ between processes on the same system.
 .PP
 This release contains an initial implementation of the SHM provider that
 offers the following support:
-.PP
-\f[I]Endpoint types\f[] : The provider supports only endpoint type
-\f[I]FI_EP_RDM\f[].
-.PP
-\f[I]Endpoint capabilities\f[] : Endpoints cna support any combinations
-of the following data transfer capabilities: \f[I]FI_MSG\f[],
-\f[I]FI_TAGGED\f[], \f[I]FI_RMA\f[], amd \f[I]FI_ATOMICS\f[].
+.TP
+.B \f[I]Endpoint types\f[]
+The provider supports only endpoint type \f[I]FI_EP_RDM\f[].
+.RS
+.RE
+.TP
+.B \f[I]Endpoint capabilities\f[]
+Endpoints cna support any combinations of the following data transfer
+capabilities: \f[I]FI_MSG\f[], \f[I]FI_TAGGED\f[], \f[I]FI_RMA\f[], amd
+\f[I]FI_ATOMICS\f[].
 These capabilities can be further defined by \f[I]FI_SEND\f[],
 \f[I]FI_RECV\f[], \f[I]FI_READ\f[], \f[I]FI_WRITE\f[],
 \f[I]FI_REMOTE_READ\f[], and \f[I]FI_REMOTE_WRITE\f[] to limit the
 direction of operations.
-.PP
-\f[I]Modes\f[] : The provider does not require the use of any mode bits.
-.PP
-\f[I]Progress\f[] : The SHM provider supports
-\f[I]FI_PROGRESS_MANUAL\f[].
+.RS
+.RE
+.TP
+.B \f[I]Modes\f[]
+The provider does not require the use of any mode bits.
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+The SHM provider supports \f[I]FI_PROGRESS_MANUAL\f[].
 Receive side data buffers are not modified outside of completion
 processing routines.
 The provider processes messages using three different methods, based on
@@ -37,10 +48,12 @@ For messages smaller than 4096 bytes, tx completions are generated
 immediately after the send.
 For larger messages, tx completions are not generated until the
 receiving side has processed the message.
-.PP
-\f[I]Address Format\f[] : The SHM provider uses the address format
-FI_ADDR_STR, which follows the general format pattern
-"[prefix]://[addr]".
+.RS
+.RE
+.TP
+.B \f[I]Address Format\f[]
+The SHM provider uses the address format FI_ADDR_STR, which follows the
+general format pattern "[prefix]://[addr]".
 The application can provide addresses through the node or hints
 parameter.
 As long as the address is in a valid FI_ADDR_STR format (contains
@@ -48,6 +61,8 @@ As long as the address is in a valid FI_ADDR_STR format (contains
 If the application input is incorrectly formatted or no input was
 provided, the SHM provider will resolve it according to the following
 SHM provider standards:
+.RS
+.RE
 .PP
 (flags & FI_SOURCE) ?
 src_addr : dest_addr = \- if (node && service) : "fi_ns://node:service"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_sockets.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_sockets.7
index f73ddc8cf..64acfd685 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_sockets.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_sockets.7
@@ -1,4 +1,7 @@
-.TH "fi_sockets" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_sockets" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_sockets \- The Sockets Fabric Provider
@@ -17,24 +20,35 @@ interfaces.
 The sockets provider supports all the features defined for the libfabric
 API.
 Key features include:
-.PP
-\f[I]Endpoint types\f[] : The provider supports all endpoint types:
-\f[I]FI_EP_MSG\f[], \f[I]FI_EP_RDM\f[], and \f[I]FI_EP_DGRAM\f[].
-.PP
-\f[I]Endpoint capabilities\f[] : The following data transfer interface
-is supported for a all endpoint types: \f[I]fi_msg\f[].
+.TP
+.B \f[I]Endpoint types\f[]
+The provider supports all endpoint types: \f[I]FI_EP_MSG\f[],
+\f[I]FI_EP_RDM\f[], and \f[I]FI_EP_DGRAM\f[].
+.RS
+.RE
+.TP
+.B \f[I]Endpoint capabilities\f[]
+The following data transfer interface is supported for a all endpoint
+types: \f[I]fi_msg\f[].
 Additionally, these interfaces are supported for reliable endpoints
 (\f[I]FI_EP_MSG\f[] and \f[I]FI_EP_RDM\f[]): \f[I]fi_tagged\f[],
 \f[I]fi_atomic\f[], and \f[I]fi_rma\f[].
-.PP
-\f[I]Modes\f[] : The sockets provider supports all operational modes
-including \f[I]FI_CONTEXT\f[] and \f[I]FI_MSG_PREFIX\f[].
-.PP
-\f[I]Progress\f[] : Sockets provider supports both
-\f[I]FI_PROGRESS_AUTO\f[] and \f[I]FI_PROGRESS_MANUAL\f[], with a
-default set to auto.
+.RS
+.RE
+.TP
+.B \f[I]Modes\f[]
+The sockets provider supports all operational modes including
+\f[I]FI_CONTEXT\f[] and \f[I]FI_MSG_PREFIX\f[].
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+Sockets provider supports both \f[I]FI_PROGRESS_AUTO\f[] and
+\f[I]FI_PROGRESS_MANUAL\f[], with a default set to auto.
 When progress is set to auto, a background thread runs to ensure that
 progress is made for asynchronous requests.
+.RS
+.RE
 .SH LIMITATIONS
 .PP
 Sockets provider attempts to emulate the entire API set, including all
@@ -49,49 +63,90 @@ Does not support FI_ADDR_STR address format.
 .SH RUNTIME PARAMETERS
 .PP
 The sockets provider checks for the following environment variables \-
-.PP
-\f[I]FI_SOCKETS_PE_WAITTIME\f[] : An integer value that specifies how
-many milliseconds to spin while waiting for progress in
-\f[I]FI_PROGRESS_AUTO\f[] mode.
-.PP
-\f[I]FI_SOCKETS_MAX_CONN_RETRY\f[] : An integer value that specifies the
-number of socket connection retries before reporting as failure.
-.PP
-\f[I]FI_SOCKETS_DEF_CONN_MAP_SZ\f[] : An integer to specify the default
-connection map size.
-.PP
-\f[I]FI_SOCKETS_DEF_AV_SZ\f[] : An integer to specify the default
-address vector size.
-.PP
-\f[I]FI_SOCKETS_DEF_CQ_SZ\f[] : An integer to specify the default
-completion queue size.
-.PP
-\f[I]FI_SOCKETS_DEF_EQ_SZ\f[] : An integer to specify the default event
-queue size.
-.PP
-\f[I]FI_SOCKETS_DGRAM_DROP_RATE\f[] : An integer value to specify the
-drop rate of dgram frame when endpoint is \f[I]FI_EP_DGRAM\f[].
+.TP
+.B \f[I]FI_SOCKETS_PE_WAITTIME\f[]
+An integer value that specifies how many milliseconds to spin while
+waiting for progress in \f[I]FI_PROGRESS_AUTO\f[] mode.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_CONN_TIMEOUT\f[]
+An integer value that specifies how many milliseconds to wait for one
+connection establishment.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_MAX_CONN_RETRY\f[]
+An integer value that specifies the number of socket connection retries
+before reporting as failure.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_DEF_CONN_MAP_SZ\f[]
+An integer to specify the default connection map size.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_DEF_AV_SZ\f[]
+An integer to specify the default address vector size.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_DEF_CQ_SZ\f[]
+An integer to specify the default completion queue size.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_DEF_EQ_SZ\f[]
+An integer to specify the default event queue size.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_DGRAM_DROP_RATE\f[]
+An integer value to specify the drop rate of dgram frame when endpoint
+is \f[I]FI_EP_DGRAM\f[].
 This is for debugging purpose only.
-.PP
-\f[I]FI_SOCKETS_PE_AFFINITY\f[] : If specified, progress thread is bound
-to the indicated range(s) of Linux virtual processor ID(s).
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_PE_AFFINITY\f[]
+If specified, progress thread is bound to the indicated range(s) of
+Linux virtual processor ID(s).
 This option is currently not supported on OS X.
 The usage is \- id_start[\-id_end[:stride]][,].
-.PP
-\f[I]FI_SOCKETS_KEEPALIVE_ENABLE\f[] : A boolean to enable the keepalive
-support.
-.PP
-\f[I]FI_SOCKETS_KEEPALIVE_TIME\f[] : An integer to specify the idle time
-in seconds before sending the first keepalive probe.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_KEEPALIVE_ENABLE\f[]
+A boolean to enable the keepalive support.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_KEEPALIVE_TIME\f[]
+An integer to specify the idle time in seconds before sending the first
+keepalive probe.
 Only relevant if \f[I]FI_SOCKETS_KEEPALIVE_ENABLE\f[] is enabled.
-.PP
-\f[I]FI_SOCKETS_KEEPALIVE_INTVL\f[] : An integer to specify the time in
-seconds between individual keepalive probes.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_KEEPALIVE_INTVL\f[]
+An integer to specify the time in seconds between individual keepalive
+probes.
 Only relevant if \f[I]FI_SOCKETS_KEEPALIVE_ENABLE\f[] is enabled.
-.PP
-\f[I]FI_SOCKETS_KEEPALIVE_PROBES\f[] : An integer to specify the maximum
-number of keepalive probes sent before dropping the connection.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_KEEPALIVE_PROBES\f[]
+An integer to specify the maximum number of keepalive probes sent before
+dropping the connection.
 Only relevant if \f[I]FI_SOCKETS_KEEPALIVE_ENABLE\f[] is enabled.
+.RS
+.RE
+.TP
+.B \f[I]FI_SOCKETS_IFACE\f[]
+The prefix or the name of the network interface (default: any)
+.RS
+.RE
 .SH LARGE SCALE JOBS
 .PP
 For large scale runs one can use these environment variables to set the
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_tcp.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_tcp.7
new file mode 100644
index 000000000..0963b3994
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_tcp.7
@@ -0,0 +1,44 @@
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_tcp" "7" "2018\-10\-29" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
+.SH NAME
+.PP
+fi_tcp \- The msg sockets Fabric Provider
+.SH OVERVIEW
+.PP
+The tcp provider can be used on any system that supports TCP sockets.
+The provider is not intended to provide performance improvements over
+regular TCP sockets, but rather to allow developers to write, test,and
+debug application code even on platforms that do not have
+high\-performance fabric hardware.
+.SH SUPPORTED FEATURES
+.PP
+The following features are supported
+.TP
+.B \f[I]Endpoint types\f[]
+\f[I]FI_EP_MSG\f[] is the only supported endpoint type.
+Reliable datagram endpoint over TCP sockets can be achieved by layering
+RxM over tcp provider.
+.RS
+.RE
+.TP
+.B \f[I]Endpoint capabilities\f[]
+The tcp provider currently supports \f[I]FI_MSG\f[], \f[I]FI_RMA\f[]
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+Currently tcp provider supports only \f[I]FI_PROGRESS_MANUAL\f[]
+.RS
+.RE
+.SH LIMITATIONS
+.PP
+tcp provider is implemented over TCP sockets to emulate libfabric API.
+Hence the performance is lower than what an application might see
+implementing to sockets directly.
+.SH SEE ALSO
+.PP
+\f[C]fabric\f[](7), \f[C]fi_provider\f[](7), \f[C]fi_getinfo\f[](3)
+.SH AUTHORS
+OpenFabrics.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_udp.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_udp.7
index 54d85276c..5da716a7b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_udp.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_udp.7
@@ -1,4 +1,7 @@
-.TH "fi_udp" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_udp" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_udp \- The UDP Fabric Provider
@@ -15,22 +18,31 @@ the implementation of libfabric features over any hardware.
 .PP
 The UDP provider supports a minimal set of features useful for sending
 and receiving datagram messages over an unreliable endpoint.
-.PP
-\f[I]Endpoint types\f[] : The provider supports only endpoint type
-\f[I]FI_EP_DGRAM\f[].
-.PP
-\f[I]Endpoint capabilities\f[] : The following data transfer interface
-is supported: \f[I]fi_msg\f[].
+.TP
+.B \f[I]Endpoint types\f[]
+The provider supports only endpoint type \f[I]FI_EP_DGRAM\f[].
+.RS
+.RE
+.TP
+.B \f[I]Endpoint capabilities\f[]
+The following data transfer interface is supported: \f[I]fi_msg\f[].
 The provider supports standard unicast datagram transfers, as well as
 multicast operations.
-.PP
-\f[I]Modes\f[] : The provider does not require the use of any mode bits.
-.PP
-\f[I]Progress\f[] : The UDP provider supports both
-\f[I]FI_PROGRESS_AUTO\f[] and \f[I]FI_PROGRESS_MANUAL\f[], with a
-default set to auto.
+.RS
+.RE
+.TP
+.B \f[I]Modes\f[]
+The provider does not require the use of any mode bits.
+.RS
+.RE
+.TP
+.B \f[I]Progress\f[]
+The UDP provider supports both \f[I]FI_PROGRESS_AUTO\f[] and
+\f[I]FI_PROGRESS_MANUAL\f[], with a default set to auto.
 However, receive side data buffers are not modified outside of
 completion processing routines.
+.RS
+.RE
 .SH LIMITATIONS
 .PP
 The UDP provider has hard\-coded maximums for supported queue sizes and
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_usnic.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_usnic.7
index 40eb9b4ce..c75126f9c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_usnic.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_usnic.7
@@ -1,4 +1,7 @@
-.TH "fi_usnic" "7" "2017\-12\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_usnic" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_usnic \- The usNIC Fabric Provider
@@ -161,13 +164,22 @@ int\ getinfo(uint32_t\ version,\ struct\ fid_fabric\ *fabric,
 \ \ \ \ \ \ \ \ struct\ fi_usnic_info\ *info);
 \f[]
 .fi
-.PP
-\f[I]version\f[] : Version of getinfo to be used
-.PP
-\f[I]fabric\f[] : Fabric descriptor
-.PP
-\f[I]info\f[] : Upon successful return, this parameter will contain
-information about the fabric.
+.TP
+.B \f[I]version\f[]
+Version of getinfo to be used
+.RS
+.RE
+.TP
+.B \f[I]fabric\f[]
+Fabric descriptor
+.RS
+.RE
+.TP
+.B \f[I]info\f[]
+Upon successful return, this parameter will contain information about
+the fabric.
+.RS
+.RE
 .IP \[bu] 2
 Version 2
 .IP
@@ -327,14 +339,23 @@ vector extension operations.
 int\ get_distance(struct\ fid_av\ *av,\ void\ *addr,\ int\ *metric);
 \f[]
 .fi
-.PP
-\f[I]av\f[] : Address vector
-.PP
-\f[I]addr\f[] : Destination address
-.PP
-\f[I]metric\f[] : On output this will contain \f[C]\-1\f[] if the
-destination host is unreachable, \f[C]0\f[] is the destination host is
-locally connected, and \f[C]1\f[] otherwise.
+.TP
+.B \f[I]av\f[]
+Address vector
+.RS
+.RE
+.TP
+.B \f[I]addr\f[]
+Destination address
+.RS
+.RE
+.TP
+.B \f[I]metric\f[]
+On output this will contain \f[C]\-1\f[] if the destination host is
+unreachable, \f[C]0\f[] is the destination host is locally connected,
+and \f[C]1\f[] otherwise.
+.RS
+.RE
 .PP
 See fi_ext_usnic.h for more details.
 .SH VERSION DIFFERENCES
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_verbs.7 b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_verbs.7
index db15d5eb6..f62db5960 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_verbs.7
+++ b/src/mpid/ch4/netmod/ofi/libfabric/man/man7/fi_verbs.7
@@ -1,4 +1,7 @@
-.TH "fi_verbs" "7" "2018\-03\-01" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.\" Automatically generated by Pandoc 1.19.2.4
+.\"
+.TH "fi_verbs" "7" "2018\-12\-19" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.hy
 .SH NAME
 .PP
 fi_verbs \- The Verbs Fabric Provider
@@ -158,84 +161,141 @@ should not be used in the forked process.
 The memory registered using fi_mr_reg has to be page aligned since
 ibv_reg_mr marks the entire page that a memory region belongs to as not
 to be re\-mapped when the process is forked (MADV_DONTFORK).
+.SS XRC Transport
+.PP
+The XRC transport is intended to be used when layered with the RXM
+provider and requires the use of shared receive contexts.
+See \f[C]fi_rxm\f[](7).
 .SH RUNTIME PARAMETERS
 .PP
 The verbs provider checks for the following environment variables.
 .SS Common variables:
-.PP
-\f[I]FI_VERBS_TX_SIZE\f[] : Default maximum tx context size (default:
-384)
-.PP
-\f[I]FI_VERBS_RX_SIZE\f[] : Default maximum rx context size (default:
-384)
-.PP
-\f[I]FI_VERBS_TX_IOV_LIMIT\f[] : Default maximum tx iov_limit (default:
-4).
+.TP
+.B \f[I]FI_VERBS_TX_SIZE\f[]
+Default maximum tx context size (default: 384)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_RX_SIZE\f[]
+Default maximum rx context size (default: 384)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_TX_IOV_LIMIT\f[]
+Default maximum tx iov_limit (default: 4).
 Note: RDM (internal \- deprecated) EP type supports only 1
-.PP
-\f[I]FI_VERBS_RX_IOV_LIMIT\f[] : Default maximum rx iov_limit (default:
-4).
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_RX_IOV_LIMIT\f[]
+Default maximum rx iov_limit (default: 4).
 Note: RDM (internal \- deprecated) EP type supports only 1
-.PP
-\f[I]FI_VERBS_INLINE_SIZE\f[] : Default maximum inline size.
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_INLINE_SIZE\f[]
+Default maximum inline size.
 Actual inject size returned in fi_info may be greater (default: 64)
-.PP
-\f[I]FI_VERBS_MIN_RNR_TIMER\f[] : Set min_rnr_timer QP attribute (0 \-
-31) (default: 12)
-.PP
-\f[I]FI_VERBS_USE_ODP\f[] : Enable On\-Demand\-Paging (ODP) experimental
-feature.
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_MIN_RNR_TIMER\f[]
+Set min_rnr_timer QP attribute (0 \- 31) (default: 12)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_USE_ODP\f[]
+Enable On\-Demand\-Paging (ODP) experimental feature.
 The feature is supported only on Mellanox OFED (default: 0)
-.PP
-\f[I]FI_VERBS_CQREAD_BUNCH_SIZE\f[] : The number of entries to be read
-from the verbs completion queue at a time (default: 8).
-.PP
-\f[I]FI_VERBS_IFACE\f[] : The prefix or the full name of the network
-interface associated with the verbs device (default: ib)
-.PP
-\f[I]FI_VERBS_MR_CACHE_ENABLE\f[] : Enable Memory Registration caching
-(default: 0)
-.PP
-\f[I]FI_VERBS_MR_MAX_CACHED_CNT\f[] : Maximum number of cache entries
-(default: 4096)
-.PP
-\f[I]FI_VERBS_MR_MAX_CACHED_SIZE\f[] : Maximum total size of cache
-entries (default: 4 GB)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_CQREAD_BUNCH_SIZE\f[]
+The number of entries to be read from the verbs completion queue at a
+time (default: 8).
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_IFACE\f[]
+The prefix or the full name of the network interface associated with the
+verbs device (default: ib)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_MR_CACHE_ENABLE\f[]
+Enable Memory Registration caching (default: 0)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_MR_MAX_CACHED_CNT\f[]
+Maximum number of cache entries (default: 4096)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_MR_MAX_CACHED_SIZE\f[]
+Maximum total size of cache entries (default: 4 GB)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_PREFER_XRC\f[]
+Prioritize XRC transport fi_info before RC transport fi_info (default:
+0, RC fi_info will be before XRC fi_info)
+.RS
+.RE
 .SS Variables specific to RDM (internal \- deprecated) endpoints
-.PP
-\f[I]FI_VERBS_RDM_BUFFER_NUM\f[] : The number of pre\-registered buffers
-for buffered operations between the endpoints, must be a power of 2
-(default: 8).
-.PP
-\f[I]FI_VERBS_RDM_BUFFER_SIZE\f[] : The maximum size of a buffered
-operation (bytes) (default: platform specific).
-.PP
-\f[I]FI_VERBS_RDM_RNDV_SEG_SIZE\f[] : The segment size for zero copy
-protocols (bytes)(default: 1073741824).
-.PP
-\f[I]FI_VERBS_RDM_THREAD_TIMEOUT\f[] : The wake up timeout of the helper
-thread (usec) (default: 100).
-.PP
-\f[I]FI_VERBS_RDM_EAGER_SEND_OPCODE\f[] : The operation code that will
-be used for eager messaging.
+.TP
+.B \f[I]FI_VERBS_RDM_BUFFER_NUM\f[]
+The number of pre\-registered buffers for buffered operations between
+the endpoints, must be a power of 2 (default: 8).
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_RDM_BUFFER_SIZE\f[]
+The maximum size of a buffered operation (bytes) (default: platform
+specific).
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_RDM_RNDV_SEG_SIZE\f[]
+The segment size for zero copy protocols (bytes)(default: 1073741824).
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_RDM_THREAD_TIMEOUT\f[]
+The wake up timeout of the helper thread (usec) (default: 100).
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_RDM_EAGER_SEND_OPCODE\f[]
+The operation code that will be used for eager messaging.
 Only IBV_WR_SEND and IBV_WR_RDMA_WRITE_WITH_IMM are supported.
 The last one is not applicable for iWarp.
 (default: IBV_WR_SEND)
-.PP
-\f[I]FI_VERBS_RDM_CM_THREAD_AFFINITY\f[] : If specified, bind the CM
-thread to the indicated range(s) of Linux virtual processor ID(s).
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_RDM_CM_THREAD_AFFINITY\f[]
+If specified, bind the CM thread to the indicated range(s) of Linux
+virtual processor ID(s).
 This option is currently not supported on OS X.
 Usage: id_start[\-id_end[:stride]][,]
+.RS
+.RE
 .SS Variables specific to DGRAM endpoints
-.PP
-\f[I]FI_VERBS_DGRAM_USE_NAME_SERVER\f[] : The option that
-enables/disables OFI Name Server thread.
+.TP
+.B \f[I]FI_VERBS_DGRAM_USE_NAME_SERVER\f[]
+The option that enables/disables OFI Name Server thread.
 The NS thread is used to resolve IP\-addresses to provider specific
 addresses (default: 1, if "OMPI_COMM_WORLD_RANK" and "PMI_RANK"
 environment variables aren\[aq]t defined)
-.PP
-\f[I]FI_VERBS_NAME_SERVER_PORT\f[] : The port on which Name Server
-thread listens incoming connections and requests (default: 5678)
+.RS
+.RE
+.TP
+.B \f[I]FI_VERBS_NAME_SERVER_PORT\f[]
+The port on which Name Server thread listens incoming connections and
+requests (default: 5678)
+.RS
+.RE
 .SS Environment variables notes
 .PP
 The fi_info utility would give the up\-to\-date information on
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/pingpong.vcxproj b/src/mpid/ch4/netmod/ofi/libfabric/pingpong.vcxproj
old mode 100644
new mode 100755
index 261624538..2e65c22b8
--- a/src/mpid/ch4/netmod/ofi/libfabric/pingpong.vcxproj
+++ b/src/mpid/ch4/netmod/ofi/libfabric/pingpong.vcxproj
@@ -30,8 +30,8 @@
     <ProjectGuid>{DBBD5F92-1E78-40ED-8D64-F958D0EF12B2}</ProjectGuid>
     <Keyword>Win32Proj</Keyword>
     <RootNamespace>pingpong</RootNamespace>
-    <WindowsTargetPlatformVersion>8.1</WindowsTargetPlatformVersion>
   </PropertyGroup>
+  <Import Project="$(SolutionDir)\Libfabric.Build.Default.props" />
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
   <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'" Label="Configuration">
     <ConfigurationType>Application</ConfigurationType>
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/fi_ext_gni.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/fi_ext_gni.h
index fc004d157..26939de34 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/fi_ext_gni.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/fi_ext_gni.h
@@ -166,8 +166,9 @@ struct fi_gni_auth_key {
 	};
 };
 
-#define GNIX_PROV_DEFAULT_AUTH_KEY NULL
-#define GNIX_PROV_DEFAULT_AUTH_KEYLEN 0
+extern uint8_t* gnix_default_auth_key;
+#define GNIX_PROV_DEFAULT_AUTH_KEY gnix_default_auth_key
+#define GNIX_PROV_DEFAULT_AUTH_KEYLEN sizeof(struct fi_gni_auth_key)
 
 #define FI_GNI_FAB_OPS_2 "fab ops 2"
 struct fi_gni_auth_key_ops_fab {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/gnix_ep.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/gnix_ep.h
index c83867940..7bad7704a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/gnix_ep.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/gnix_ep.h
@@ -405,6 +405,17 @@ int gnix_scalable_ep_bind(fid_t fid, struct fid *bfid, uint64_t flags);
  */
 int gnix_pep_bind(fid_t fid, struct fid *bfid, uint64_t flags);
 
+/**
+ * Cancels a transaction posted to an endpoint, if possible.
+ *
+ * @param[in] fid	the endpoint
+ * @param[in] context	context of the transaction to be canceled
+ *
+ * @return FI_SUCCESS	upon successfully canceling transaction
+ * @return -FI_ENONT	no entry to cancel
+ */
+ssize_t gnix_cancel(fid_t fid, void *context);
+
 DIRECT_FN int gnix_ep_atomic_valid(struct fid_ep *ep,
 				   enum fi_datatype datatype,
 				   enum fi_op op, size_t *count);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/gnix_vc.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/gnix_vc.h
index 52955dc9d..ae9055d93 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/gnix_vc.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/include/gnix_vc.h
@@ -101,6 +101,7 @@ enum gnix_vc_conn_req_type {
  *                           associated
  * @var smsg_mbox            pointer to GNI SMSG mailbox used by this VC
  *                           to exchange SMSG messages with its peer
+ * @var gnix_ep_name         cache for storing remote endpoint name
  * @var gni_ep               GNI endpoint for this VC
  * @var outstanding_fab_reqs Count of outstanding libfabric level requests
  *                           associated with this endpoint.
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_auth_key.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_auth_key.c
index 697884f32..c1e6f8c99 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_auth_key.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_auth_key.c
@@ -60,6 +60,8 @@ typedef enum gnix_global_auth_info_version {
 
 static char *gnix_default_ak_path = GNIX_DEFAULT_AK_PATH;
 
+uint8_t* gnix_default_auth_key = NULL;
+
 struct gnix_global_ptag_info {
 	gnix_bitmap_t prov;
 	gnix_bitmap_t user;
@@ -386,24 +388,20 @@ int _gnix_auth_key_insert(
 		return -FI_EINVAL;
 	}
 
-	if (auth_key_size == GNIX_PROV_DEFAULT_AUTH_KEYLEN)
-		key = 0;
-	else {
-		if (!auth_key) {
-			GNIX_INFO(FI_LOG_FABRIC, "auth key is null\n");
-			return -FI_EINVAL;
-		}
+	if (!auth_key) {
+		GNIX_INFO(FI_LOG_FABRIC, "auth key is null\n");
+		return -FI_EINVAL;
+	}
 
-		switch (gni_auth_key->type) {
-		case GNIX_AKT_RAW:
-			key = (gnix_ht_key_t) gni_auth_key->raw.protection_key;
-			break;
-		default:
-			GNIX_INFO(FI_LOG_FABRIC, "unrecognized auth key "
-				"type, type=%d\n",
-				gni_auth_key->type);
-			return -FI_EINVAL;
-		}
+	switch (gni_auth_key->type) {
+	case GNIX_AKT_RAW:
+		key = (gnix_ht_key_t) gni_auth_key->raw.protection_key;
+		break;
+	default:
+		GNIX_INFO(FI_LOG_FABRIC, "unrecognized auth key "
+			"type, type=%d\n",
+			gni_auth_key->type);
+		return -FI_EINVAL;
 	}
 
 	ret = _gnix_ht_insert(&__gnix_auth_key_ht, key, to_insert);
@@ -438,26 +436,19 @@ _gnix_auth_key_lookup(uint8_t *auth_key, size_t auth_key_size)
 	struct gnix_auth_key *ptr = NULL;
 	struct fi_gni_auth_key *gni_auth_key = NULL;
 
-	if (auth_key_size == GNIX_PROV_DEFAULT_AUTH_KEYLEN) {
-		key = 0;
-	} else {
-		if (!auth_key) {
-			GNIX_INFO(FI_LOG_FABRIC,
-				"null auth key provided, cannot find entry\n");
-			return NULL;
-		}
-
-		gni_auth_key = (struct fi_gni_auth_key *) auth_key;
-		switch (gni_auth_key->type) {
-		case GNIX_AKT_RAW:
-			key = (gnix_ht_key_t) gni_auth_key->raw.protection_key;
-			break;
-		default:
-			GNIX_INFO(FI_LOG_FABRIC, "unrecognized auth key type, "
-				"type=%d\n", gni_auth_key->type);
-			return NULL;
-		}
+	if (auth_key == NULL || auth_key_size == 0) {
+		auth_key = gnix_default_auth_key;
+	}
 
+	gni_auth_key = (struct fi_gni_auth_key *) auth_key;
+	switch (gni_auth_key->type) {
+	case GNIX_AKT_RAW:
+		key = (gnix_ht_key_t) gni_auth_key->raw.protection_key;
+		break;
+	default:
+		GNIX_INFO(FI_LOG_FABRIC, "unrecognized auth key type, "
+			"type=%d\n", gni_auth_key->type);
+		return NULL;
 	}
 
 	ptr = (struct gnix_auth_key *) _gnix_ht_lookup(
@@ -484,11 +475,18 @@ int _gnix_auth_key_subsys_init(void)
 	ret = _gnix_ht_init(&__gnix_auth_key_ht, &attr);
 	assert(ret == FI_SUCCESS);
 
+	struct fi_gni_auth_key *gni_auth_key = calloc(1, sizeof(*gni_auth_key));
+	gni_auth_key->type = GNIX_AKT_RAW;
+	gni_auth_key->raw.protection_key = 0;
+	gnix_default_auth_key = (uint8_t *) gni_auth_key;
+
 	return ret;
 }
 
 int _gnix_auth_key_subsys_fini(void)
 {
+	free(gnix_default_auth_key);
+
 	return FI_SUCCESS;
 }
 
@@ -503,10 +501,15 @@ struct gnix_auth_key *_gnix_auth_key_create(
 	uint8_t ptag;
 	uint32_t cookie;
 
-	if (auth_key_size == GNIX_PROV_DEFAULT_AUTH_KEYLEN) {
+	if (auth_key == NULL || auth_key_size == 0) {
+		auth_key = gnix_default_auth_key;
+	}
+
+	gni_auth_key = (struct fi_gni_auth_key *) auth_key;
+	if (auth_key == gnix_default_auth_key) {
 		gnixu_get_rdma_credentials(NULL, &ptag, &cookie);
+		gni_auth_key->raw.protection_key = cookie;
 	} else {
-		gni_auth_key = (struct fi_gni_auth_key *) auth_key;
 		switch (gni_auth_key->type) {
 		case GNIX_AKT_RAW:
 			cookie = gni_auth_key->raw.protection_key;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_av.c
index ea6d200f2..bbc8a55aa 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_av.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_av.c
@@ -173,7 +173,7 @@ static int table_insert(struct gnix_fid_av *av_priv, const void *addr,
 		/* check if this ep_name fits in the av context bits */
 		if (ep_name.name_type & GNIX_EPN_TYPE_SEP) {
 			if ((1 << av_priv->rx_ctx_bits) < ep_name.rx_ctx_cnt) {
-				if (flags && FI_SYNC_ERR) {
+				if (flags & FI_SYNC_ERR) {
 					entry_err[i] = -FI_EINVAL;
 					fi_addr[i] = FI_ADDR_NOTAVAIL;
 					ret = -FI_EINVAL;
@@ -196,7 +196,7 @@ static int table_insert(struct gnix_fid_av *av_priv, const void *addr,
 		if (fi_addr)
 			fi_addr[i] = index;
 
-		if (flags && FI_SYNC_ERR) {
+		if (flags & FI_SYNC_ERR) {
 			entry_err[i] = FI_SUCCESS;
 		}
 	}
@@ -335,7 +335,7 @@ static int map_insert(struct gnix_fid_av *av_priv, const void *addr,
 		/* check if this ep_name fits in the av context bits */
 		if (ep_name.name_type & GNIX_EPN_TYPE_SEP) {
 			if ((1 << av_priv->rx_ctx_bits) < ep_name.rx_ctx_cnt) {
-				if (flags && FI_SYNC_ERR) {
+				if (flags & FI_SYNC_ERR) {
 					entry_err[i] = -FI_EINVAL;
 					fi_addr[i] = FI_ADDR_NOTAVAIL;
 					ret_cnt = -FI_EINVAL;
@@ -360,7 +360,7 @@ static int map_insert(struct gnix_fid_av *av_priv, const void *addr,
 				      key,
 				      the_entry);
 
-		if (flags && FI_SYNC_ERR) {
+		if (flags & FI_SYNC_ERR) {
 			entry_err[i] = FI_SUCCESS;
 		}
 
@@ -372,7 +372,7 @@ static int map_insert(struct gnix_fid_av *av_priv, const void *addr,
 			GNIX_WARN(FI_LOG_AV,
 				  "_gnix_ht_insert failed %d\n",
 				  ret);
-			if (flags && FI_SYNC_ERR) {
+			if (flags & FI_SYNC_ERR) {
 				entry_err[i] = ret;
 				fi_addr[i] = FI_ADDR_NOTAVAIL;
 				ret_cnt = ret;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_cq.c
index bd9ddc52d..07d9565c8 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_cq.c
@@ -351,6 +351,9 @@ ssize_t _gnix_cq_add_error(struct gnix_fid_cq *cq, void *op_context,
 
 	_gnix_queue_enqueue(cq->errors, &event->item);
 
+	if (cq->wait)
+		_gnix_signal_wait_obj(cq->wait);
+
 err:
 	COND_RELEASE(cq->requires_lock, &cq->lock);
 
@@ -455,7 +458,7 @@ static ssize_t __gnix_cq_readfrom(struct fid_cq *cq, void *buf,
 		assert(event->the_entry);
 		memcpy(buf, event->the_entry, cq_priv->entry_size);
 		if (src_addr)
-			memcpy(src_addr, &event->src_addr, sizeof(fi_addr_t));
+			memcpy(&src_addr[read_count], &event->src_addr, sizeof(fi_addr_t));
 
 		_gnix_queue_enqueue_free(cq_priv->events, &event->item);
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_ep.c
index 6d8b093e9..219084ced 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_ep.c
@@ -2888,6 +2888,8 @@ DIRECT_FN STATIC ssize_t gnix_ep_cancel(fid_t fid, void *context)
 ssize_t gnix_cancel(fid_t fid, void *context)
 {
 	ssize_t ret;
+	struct gnix_fid_ep *ep;
+	struct gnix_fid_trx *trx_ep;
 
 	GNIX_TRACE(FI_LOG_EP_CTRL, "\n");
 
@@ -2896,10 +2898,14 @@ ssize_t gnix_cancel(fid_t fid, void *context)
 		ret = gnix_ep_cancel(fid, context);
 		break;
 
-	/* not supported yet */
 	case FI_CLASS_RX_CTX:
-	case FI_CLASS_SRX_CTX:
 	case FI_CLASS_TX_CTX:
+		trx_ep = container_of(fid, struct gnix_fid_trx, ep_fid);
+		ep = trx_ep->ep;
+		ret = gnix_ep_cancel(&ep->ep_fid.fid, context);
+		break;
+	/* not supported yet */
+	case FI_CLASS_SRX_CTX:
 	case FI_CLASS_STX_CTX:
 		return -FI_ENOENT;
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_fabric.c
index 77b2f4eae..9524855cc 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_fabric.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_fabric.c
@@ -722,7 +722,7 @@ static void gnix_fini(void)
 struct fi_provider gnix_prov = {
 	.name = gnix_prov_name,
 	.version = FI_VERSION(GNI_MAJOR_VERSION, GNI_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = gnix_getinfo,
 	.fabric = gnix_fabric_open,
 	.cleanup = gnix_fini
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_mbox_allocator.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_mbox_allocator.c
index 2e8b7fa5e..b9896b7b5 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_mbox_allocator.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_mbox_allocator.c
@@ -39,6 +39,7 @@
 
 #include "gnix_mbox_allocator.h"
 #include "gnix_nic.h"
+#include "fi_ext_gni.h"
 
 /**
  * Will attempt to find a directory in the hugetlbfs with the given page size.
@@ -299,6 +300,7 @@ static int __create_slab(struct gnix_mbox_alloc_handle *handle)
 	int vmdh_index = -1;
 	int flags = GNI_MEM_READWRITE;
 	struct gnix_auth_key *info;
+	struct fi_gni_auth_key key;
 
 	GNIX_TRACE(FI_LOG_EP_CTRL, "\n");
 
@@ -343,8 +345,10 @@ static int __create_slab(struct gnix_mbox_alloc_handle *handle)
 
 	COND_ACQUIRE(handle->nic_handle->requires_lock, &handle->nic_handle->lock);
 	if (handle->nic_handle->using_vmdh) {
-		info = _gnix_auth_key_lookup(GNIX_PROV_DEFAULT_AUTH_KEY,
-				GNIX_PROV_DEFAULT_AUTH_KEYLEN);
+		key.type = GNIX_AKT_RAW;
+		key.raw.protection_key = handle->nic_handle->cookie;
+
+		info = _gnix_auth_key_lookup((uint8_t *) &key, sizeof(key));
 		assert(info);
 
 		if (!handle->nic_handle->mdd_resources_set) {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_msg.c
index 80e6e9dfa..4645d589c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_msg.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_msg.c
@@ -1,6 +1,6 @@
 /*
  * Copyright (c) 2015-2017 Cray Inc. All rights reserved.
- * Copyright (c) 2015-2017 Los Alamos National Security, LLC.
+ * Copyright (c) 2015-2018 Los Alamos National Security, LLC.
  *                         All rights reserved.
  *
  * This software is available to you under a choice of one of two
@@ -400,11 +400,15 @@ static int __recv_completion_src(
 		fi_addr_t src_addr)
 {
 	ssize_t rc;
+	char *buffer;
 
 	GNIX_DBG_TRACE(FI_LOG_TRACE, "\n");
 
 	if ((req->msg.recv_flags & FI_COMPLETION) && ep->recv_cq) {
 		if (src_addr == FI_ADDR_NOTAVAIL) {
+			buffer = malloc(GNIX_CQ_MAX_ERR_DATA_SIZE);
+			memcpy(buffer, req->vc->gnix_ep_name,
+				sizeof(struct gnix_ep_name));
 			rc = _gnix_cq_add_error(ep->recv_cq,
 						req->user_context,
 						flags,
@@ -415,7 +419,7 @@ static int __recv_completion_src(
 						0,
 						FI_EADDRNOTAVAIL,
 						0,
-						req->vc->gnix_ep_name,
+						buffer,
 						sizeof(struct gnix_ep_name));
 		} else {
 			rc = _gnix_cq_add_event(ep->recv_cq,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_nic.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_nic.c
index 9a17d89f4..f23b0d251 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_nic.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_nic.c
@@ -44,6 +44,7 @@
 #include "gnix_vc.h"
 #include "gnix_mbox_allocator.h"
 #include "gnix_util.h"
+#include "fi_ext_gni.h"
 
 /*
  * TODO: make this a domain parameter
@@ -204,6 +205,7 @@ static int __nic_setup_irq_cq(struct gnix_nic *nic)
 	int vmdh_index = -1;
 	int flags = GNI_MEM_READWRITE;
 	struct gnix_auth_key *info;
+	struct fi_gni_auth_key key;
 
 	len = (size_t)sysconf(_SC_PAGESIZE);
 
@@ -224,8 +226,10 @@ static int __nic_setup_irq_cq(struct gnix_nic *nic)
 	memset(mmap_addr, 0x0, len);
 
 	if (nic->using_vmdh) {
-		info = _gnix_auth_key_lookup(GNIX_PROV_DEFAULT_AUTH_KEY,
-				GNIX_PROV_DEFAULT_AUTH_KEYLEN);
+		key.type = GNIX_AKT_RAW;
+		key.raw.protection_key = nic->cookie;
+
+		info = _gnix_auth_key_lookup((uint8_t *) &key, sizeof(key));
 		assert(info);
 
 		if (!nic->mdd_resources_set) {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_sep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_sep.c
index 1e67c3c16..d80530aae 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_sep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_sep.c
@@ -1597,7 +1597,7 @@ static struct fi_ops gnix_sep_fi_ops = {
 
 static struct fi_ops_ep gnix_sep_ops = {
 	.size = sizeof(struct fi_ops_ep),
-	.cancel = fi_no_cancel,
+	.cancel = gnix_cancel,
 	.getopt = fi_no_getopt,
 	.setopt = fi_no_setopt,
 	.tx_ctx = gnix_sep_tx_ctx,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_vc.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_vc.c
index 5c6b8d477..5dbe682dd 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_vc.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_vc.c
@@ -53,6 +53,7 @@
 #include "gnix_trigger.h"
 #include "gnix_vector.h"
 #include "gnix_xpmem.h"
+#include "gnix_cq.h"
 
 /*
  * forward declarations and local struct defs.
@@ -961,9 +962,12 @@ static int __gnix_vc_hndl_conn_req(struct gnix_cm_nic *cm_nic,
 
 				dlist_insert_tail(&vc->list, &ep->unmapped_vcs);
 
+				/*
+				 * see issue 4521 for the error_data size allocated
+				 */
 				if (vc->ep->caps & FI_SOURCE) {
 					error_data =
-						calloc(1, sizeof(*error_data));
+						calloc(1, GNIX_CQ_MAX_ERR_DATA_SIZE);
 					if (error_data == NULL) {
 						ret = -FI_ENOMEM;
 						goto err;
@@ -1506,6 +1510,7 @@ int _gnix_vc_alloc(struct gnix_fid_ep *ep_priv,
 	if (ret != FI_SUCCESS)
 		goto err;
 	vc_ptr->vc_id = remote_id;
+	vc_ptr->gnix_ep_name = NULL;
 
 	*vc = vc_ptr;
 
@@ -1637,6 +1642,11 @@ int _gnix_vc_destroy(struct gnix_vc *vc)
 
 	_gnix_free_bitmap(&vc->flags);
 
+	if (vc->gnix_ep_name != NULL) {
+		free(vc->gnix_ep_name);
+		vc->gnix_ep_name = NULL;
+	}
+
 	/*
 	 * put VC back on the freelist
 	 */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_xpmem.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_xpmem.c
index 825b67fb0..180350562 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_xpmem.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/src/gnix_xpmem.c
@@ -14,7 +14,7 @@
  *     conditions are met:
  *
  *      - Redistributions of source code must retain the above
- *        opyright notice, this list of conditions and the following
+ *        copyright notice, this list of conditions and the following
  *        disclaimer.
  *
  *      - Redistributions in binary form must reproduce the above
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/test/allocator.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/test/allocator.c
index 6b30b73a1..7776bb068 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/test/allocator.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/test/allocator.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2015-2017 Los Alamos National Security, LLC. All rights reserved.
+ * Copyright (c) 2015-2018 Los Alamos National Security, LLC. All rights reserved.
  * Copyright (c) 2015-2017 Cray Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
@@ -128,9 +128,14 @@ static ptrdiff_t abs_value(ptrdiff_t x)
 	return x * ((x > 0) - (x < 0));
 }
 
+#ifndef __aarch64__
 /*
  * Open /proc/self/maps and count the number of times the hugetlbfs
  * string is present. Return value is the count;
+ *
+ * TODO: this approach doesn't work on Cray ARM systems.  Large
+ *       page regions don't show being backed by files in 
+ *       /var/lib/hugetlbfs.  Need to fix with something better.
  */
 static int verify_hugepages(void)
 {
@@ -162,6 +167,7 @@ static int verify_hugepages(void)
 
 	return ret;
 }
+#endif
 
 /*
  * Open an allocator with the given parameters and immediately close it. Verify
@@ -185,13 +191,17 @@ static void open_close_allocator(enum gnix_page_size page_size,
 		return;
 	}
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_create failed5.");
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 2 + ALLOCD_WITH_NIC,
 			 "memory not found in /proc/self/maps.");
+#endif
 
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_destroy failed.");
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 			 "memory not released in /proc/self/maps.");
+#endif
 }
 
 
@@ -264,8 +274,10 @@ static inline void __alloc_mbox(void)
 	 *value is 4 because the provider has internally already opened
 	 * an mbox allocator and 2 rdma slabs at this point.
 	 */
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 2 + ALLOCD_WITH_NIC,
 		  "memory not found in /proc/self/maps.");
+#endif
 
 	ret = _gnix_mbox_alloc(allocator, &mail_box);
 	cr_expect_eq(ret, FI_SUCCESS, "_gnix_mbox_alloc failed.");
@@ -307,8 +319,11 @@ static inline void __alloc_mbox(void)
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_destroy failed.");
 
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 		     "memory not released in /proc/self/maps.");
+#endif
+
 }
 
 Test(mbox_creation_basic, alloc_mbox)
@@ -338,8 +353,10 @@ static inline void __page_size_fail(void)
 	 *value is 3 because the provider has internally already opened
 	 * an mbox allocator and two other slabs at this point.
 	 */
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 		     "Huge page open, but shouldn't be");
+#endif
 
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, -FI_EINVAL,
@@ -369,8 +386,10 @@ static inline void __mbox_size_fail(void)
 		     "Creating allocator with zero mbox size succeeded.");
 
 	cr_assert_eq(allocator, NULL);
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 		     "Huge page open, but shouldn't be");
+#endif
 
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, -FI_EINVAL,
@@ -399,8 +418,10 @@ static inline void __mpmmap_size_fail(void)
 	cr_assert_eq(ret, -FI_EINVAL,
 		  "Creating allocator with zero mailboxes per mmap succeeded.");
 	cr_assert_eq(allocator, NULL);
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 		     "Huge page open, but shouldn't be");
+#endif
 
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, -FI_EINVAL,
@@ -428,8 +449,10 @@ static inline void __null_allocator_fail(void)
 					  1000, 100, NULL);
 	cr_assert_eq(ret, -FI_EINVAL,
 		     "Creating allocator with null allocator succeeded.");
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 		     "Huge page open, but shouldn't be");
+#endif
 
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, -FI_EINVAL,
@@ -461,8 +484,10 @@ static inline void __multi_allocation(void)
 	ret = _gnix_mbox_allocator_create(ep_priv->nic, NULL, GNIX_PAGE_4MB,
 					  mbox_size, array_size, &allocator);
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_create failed2.");
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 2 + ALLOCD_WITH_NIC,
 		     "memory not found in /proc/self/maps.");
+#endif
 
 	/*
 	 * Create an array of mailboxes of size array_size.
@@ -501,8 +526,10 @@ static inline void __multi_allocation(void)
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_destroy failed.");
 
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 		     "memory not released in /proc/self/maps.");
+#endif
 }
 
 Test(mbox_creation_basic, multi_allocation)
@@ -527,8 +554,10 @@ static inline void __check_errors(void)
 	ret = _gnix_mbox_allocator_create(ep_priv->nic, NULL, GNIX_PAGE_4MB,
 					  1000, 12000, &allocator);
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_create failed3");
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 2 + ALLOCD_WITH_NIC,
 		     "memory not found in /proc/self/maps.");
+#endif
 
 	ret = _gnix_mbox_alloc(allocator, &mail_box);
 	cr_expect_eq(ret, FI_SUCCESS, "_gnix_mbox_alloc failed.");
@@ -565,8 +594,10 @@ static inline void __check_errors(void)
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_destroy failed.");
 
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 		     "memory not released in /proc/self/maps.");
+#endif
 }
 
 Test(mbox_creation_basic, check_errors)
@@ -598,8 +629,10 @@ static inline void __two_slabs(void)
 	ret = _gnix_mbox_allocator_create(ep_priv->nic, NULL, GNIX_PAGE_4MB,
 					  mbox_size, mpmmap, &allocator);
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_create failed4.");
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 2 + ALLOCD_WITH_NIC,
 		     "memory not found in /proc/self/maps.");
+#endif
 
 	/*
 	 * Should use previously allocated slab
@@ -633,8 +666,10 @@ static inline void __two_slabs(void)
 	ret = _gnix_mbox_allocator_destroy(allocator);
 	cr_assert_eq(ret, FI_SUCCESS, "_gnix_mbox_allocator_destroy failed.");
 
+#ifndef __aarch64__
 	cr_expect_eq(verify_hugepages(), 1 + ALLOCD_WITH_NIC,
 		     "memory not released in /proc/self/maps.");
+#endif
 }
 
 Test(mbox_creation_basic, two_slabs)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/test/sep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/test/sep.c
index 05e01c7f2..630024281 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/test/sep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/gni/test/sep.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2015-2017 Los Alamos National Security, LLC.
+ * Copyright (c) 2015-2018 Los Alamos National Security, LLC.
  *                         All rights reserved.
  * Copyright (c) 2015-2017 Cray Inc. All rights reserved.
  *
@@ -1368,7 +1368,8 @@ void sep_read(int index, int len)
 	}
 
 	cr_assert_eq(ret, 1);
-	sep_check_tcqe(&cqe, (void *)READ_CTX, FI_RMA | FI_READ, 0, tx_ep[0][index]);
+	sep_check_tcqe(&cqe, (void *)READ_CTX, FI_RMA | FI_READ, 0,
+			tx_ep[0][index]);
 
 	r[0] = 1;
 	sep_check_cntrs(w, r, w_e, r_e, false);
@@ -2146,6 +2147,68 @@ void sep_invalid_fetch_atomic(enum fi_datatype dt, enum fi_op op)
 	}
 }
 
+static void cancel_sep_send_sep(int index)
+{
+	ssize_t ret, len = 16;
+	struct fi_cq_err_entry buf;
+
+	sep_init_data(source, len, 0xab + index);
+	sep_init_data(target, len, 0);
+
+	ret = fi_send(tx_ep[0][index], source, len, loc_mr[0],
+		      rx_addr[index], target);
+	cr_assert(ret == 0, "fi_send failed err:%ld", ret);
+
+	ret = fi_cancel(&tx_ep[0][index]->fid, target);
+	fprintf(stderr, "ret = %d %s\n", ret, fi_strerror(-ret));
+	cr_assert(ret == FI_SUCCESS, "fi_cancel failed");
+
+	/* check for event */
+	ret = fi_cq_readerr(tx_cq[0][index], &buf, FI_SEND);
+	cr_assert(ret == 1, "did not find one error event");
+
+	cr_assert(buf.buf == (void *) source, "buffer mismatch");
+	cr_assert(buf.err == FI_ECANCELED, "error code mismatch");
+	cr_assert(buf.prov_errno == FI_ECANCELED, "prov error code mismatch");
+	cr_assert(buf.len == len, "length mismatch");
+}
+
+static void cancel_sep_recv_sep(int index)
+{
+	ssize_t ret, len = 16;
+	struct fi_cq_err_entry buf;
+
+	sep_init_data(source, len, 0xab + index);
+	sep_init_data(target, len, 0);
+
+	ret = fi_recv(rx_ep[1][index], target, len, rem_mr[0],
+		      FI_ADDR_UNSPEC, source);
+	cr_assert(ret == 0, "fi_recv failed err:%ld", ret);
+
+	ret = fi_cancel(&rx_ep[1][index]->fid, source);
+	cr_assert(ret == FI_SUCCESS, "fi_cancel failed");
+
+	/* check for event */
+	ret = fi_cq_readerr(rx_cq[1][index], &buf, FI_RECV);
+	cr_assert(ret == 1, "did not find one error event");
+
+	cr_assert(buf.buf == (void *) target, "buffer mismatch");
+	cr_assert(buf.err == FI_ECANCELED, "error code mismatch");
+	cr_assert(buf.prov_errno == FI_ECANCELED, "prov error code mismatch");
+	cr_assert(buf.len == len, "length mismatch");
+}
+
+static void cancel_sep_no_event(int index)
+{
+	ssize_t ret;
+
+	ret = fi_cancel(&tx_ep[0][index]->fid, NULL);
+	cr_assert(ret == -FI_ENOENT, "fi_cancel failed");
+
+	ret = fi_cancel(&rx_ep[0][index]->fid, NULL);
+	cr_assert(ret == -FI_ENOENT, "fi_cancel failed");
+}
+
 void run_tests(void)
 {
 	int i, j;
@@ -2363,6 +2426,27 @@ void run_tests(void)
 			sep_invalid_fetch_atomic(j, i);
 		}
 	}
+
+}
+
+void run_cancel_tests(void)
+{
+	int i;
+
+	cr_log_info("cancel send test\n");
+	for (i = 0; i < ctx_cnt; i++) {
+		cancel_sep_send_sep(i);
+	}
+
+	cr_log_info("cancel recv test\n");
+	for (i = 0; i < ctx_cnt; i++) {
+		cancel_sep_recv_sep(i);
+	}
+
+	cr_log_info("cancel no event test\n");
+	for (i = 0; i < ctx_cnt; i++) {
+		cancel_sep_no_event(i);
+	}
 }
 
 TestSuite(scalablea,
@@ -2434,24 +2518,48 @@ Test(scalablem_basic, all)
 	run_tests();
 }
 
+Test(scalablem_basic, cancel)
+{
+	cr_log_info(BLUE "sep:basic:FI_AV_MAP cancel tests:\n" COLOR_RESET);
+	run_cancel_tests();
+}
+
 Test(scalablet_basic, all)
 {
 	cr_log_info(BLUE "sep:basic:FI_AV_TABLE tests:\n" COLOR_RESET);
 	run_tests();
 }
 
+Test(scalablet_basic, cancel)
+{
+	cr_log_info(BLUE "sep:basic:FI_AV_TABLE cancel tests:\n" COLOR_RESET);
+	run_cancel_tests();
+}
+
 Test(scalablem_scalable, all)
 {
 	cr_log_info(BLUE "sep:scalable:FI_AV_MAP tests:\n" COLOR_RESET);
 	run_tests();
 }
 
+Test(scalablem_scalable, cancel)
+{
+	cr_log_info(BLUE "sep:scalable:FI_AV_MAP cancel tests:\n" COLOR_RESET);
+	run_cancel_tests();
+}
+
 Test(scalablet_scalable, all)
 {
 	cr_log_info(BLUE "sep:scalable:FI_AV_TABLE tests:\n" COLOR_RESET);
 	run_tests();
 }
 
+Test(scalablet_scalable, cancel)
+{
+	cr_log_info(BLUE "sep:scalable:FI_AV_TABLE cancel tests:\n" COLOR_RESET);
+	run_cancel_tests();
+}
+
 #define INSERT_ADDR_COUNT (NUMCONTEXTS + 6)
 
 /* test for inserting an ep_name that doesn't fit in the AV */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/Makefile.include
new file mode 100644
index 000000000..89ce70148
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/Makefile.include
@@ -0,0 +1,2 @@
+src_libfabric_la_CPPFLAGS +=	-I$(top_srcdir)/prov/hook/include
+src_libfabric_la_SOURCES  +=    prov/hook/include/hook_prov.h
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/include/hook_prov.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/include/hook_prov.h
new file mode 100644
index 000000000..a70ae7ce2
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/include/hook_prov.h
@@ -0,0 +1,26 @@
+#ifndef HOOK_PROV_H
+#define HOOK_PROV_H
+
+#include <ofi.h>
+#include "ofi_hook.h"
+
+int hook_bind(struct fid *fid, struct fid *bfid, uint64_t flags);
+int hook_control(struct fid *fid, int command, void *arg);
+int hook_ops_open(struct fid *fid, const char *name,
+			 uint64_t flags, void **ops, void *context);
+int hook_close(struct fid *fid);
+
+#if HAVE_PERF
+#include "hook_perf.h"
+#else
+#define perf_msg_ops hook_msg_ops
+#define perf_rma_ops hook_rma_ops
+#define perf_tagged_ops hook_tagged_ops
+#define perf_cntr_ops hook_cntr_ops
+#define perf_cq_ops hook_cq_ops
+
+#define hook_perf_create hook_fabric_create
+#define hook_perf_destroy hook_fabric_destroy
+
+#endif /* HAVE_PERF */
+#endif /* HOOK_PROV_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/Makefile.include
new file mode 100644
index 000000000..65e58b9bc
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/Makefile.include
@@ -0,0 +1,13 @@
+if HAVE_PERF
+_perfhook_files = \
+	prov/hook/perf/src/hook_perf.c
+
+_perfhook_headers = \
+	prov/hook/perf/include/hook_perf.h
+
+
+src_libfabric_la_SOURCES  +=	$(_perfhook_files) \
+				$(_perfhook_headers)
+src_libfabric_la_CPPFLAGS +=	-I$(top_srcdir)/prov/hook/perf/include
+src_libfabric_la_LIBADD	  +=	$(perfhook_shm_LIBS)
+endif HAVE_PERF
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/configure.m4 b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/configure.m4
new file mode 100644
index 000000000..82befb010
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/configure.m4
@@ -0,0 +1,21 @@
+dnl Configury specific to the libfabrics perf hooking provider
+
+dnl Called to configure this provider
+dnl
+dnl Arguments:
+dnl
+dnl $1: action if configured successfully
+dnl $2: action if not configured successfully
+dnl
+
+AC_DEFUN([FI_PERF_CONFIGURE],[
+    # Determine if we can support the perf hooking provider
+    perf_happy=0
+    AS_IF([test x"$enable_perf" != x"no"], [perf_happy=1])
+    AS_IF([test x"$perf_dl" == x"1"], [
+	perf_happy=0
+	AC_MSG_ERROR([perf provider cannot be compiled as DL])
+    ])
+    AS_IF([test $perf_happy -eq 1], [$1], [$2])
+
+])
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/include/hook_perf.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/include/hook_perf.h
new file mode 100644
index 000000000..56625a8c9
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/include/hook_perf.h
@@ -0,0 +1,105 @@
+/*
+ * Copyright (c) 2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL); Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _HOOK_PERF_H_
+#define _HOOK_PERF_H_
+
+#include "ofi_hook.h"
+#include "ofi.h"
+#include "ofi_perf.h"
+
+
+struct perf_fabric {
+	struct hook_fabric fabric_hook;
+	struct ofi_perfset perf_set;
+};
+
+int perf_hook_destroy(struct fid *fabric);
+
+
+#define HOOK_FOREACH(DECL)		\
+	DECL(perf_recv),		\
+	DECL(perf_recvv),		\
+	DECL(perf_recvmsg),		\
+	DECL(perf_send),		\
+	DECL(perf_sendv),		\
+	DECL(perf_sendmsg),		\
+	DECL(perf_inject),		\
+	DECL(perf_senddata),		\
+	DECL(perf_injectdata),		\
+	DECL(perf_read),		\
+	DECL(perf_readv),		\
+	DECL(perf_readmsg),		\
+	DECL(perf_write),		\
+	DECL(perf_writev),		\
+	DECL(perf_writemsg),		\
+	DECL(perf_inject_write),	\
+	DECL(perf_writedata),		\
+	DECL(perf_inject_writedata),	\
+	DECL(perf_trecv),		\
+	DECL(perf_trecvv),		\
+	DECL(perf_trecvmsg),		\
+	DECL(perf_tsend),		\
+	DECL(perf_tsendv),		\
+	DECL(perf_tsendmsg),		\
+	DECL(perf_tinject),		\
+	DECL(perf_tsenddata),		\
+	DECL(perf_tinjectdata),		\
+	DECL(perf_cq_read),		\
+	DECL(perf_cq_readfrom),		\
+	DECL(perf_cq_readerr),		\
+	DECL(perf_cq_sread),		\
+	DECL(perf_cq_sreadfrom),	\
+	DECL(perf_cq_signal),		\
+	DECL(perf_cntr_read),		\
+	DECL(perf_cntr_readerr),	\
+	DECL(perf_cntr_add),		\
+	DECL(perf_cntr_set),		\
+	DECL(perf_cntr_wait),		\
+	DECL(perf_cntr_adderr),		\
+	DECL(perf_cntr_seterr),		\
+	DECL(perf_size)
+
+enum perf_counters {
+	HOOK_FOREACH(OFI_ENUM_VAL)
+};
+
+extern const char *perf_counters_str[];
+
+extern struct fi_ops_msg perf_msg_ops;
+extern struct fi_ops_rma perf_rma_ops;
+extern struct fi_ops_tagged perf_tagged_ops;
+extern struct fi_ops_cq perf_cq_ops;
+extern struct fi_ops_cntr perf_cntr_ops;
+
+
+#endif /* _HOOK_PERF_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/src/hook_perf.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/src/hook_perf.c
new file mode 100644
index 000000000..154f16393
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/perf/src/hook_perf.c
@@ -0,0 +1,904 @@
+/*
+ * Copyright (c) 2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "ofi_perf.h"
+#include "ofi_prov.h"
+#include "hook_prov.h"
+
+
+const char *perf_counters_str[] = {
+	HOOK_FOREACH(OFI_STR)
+};
+
+
+static inline struct ofi_perfset *perf_set(struct hook_ep *ep)
+{
+	return &container_of(ep->domain->fabric, struct perf_fabric,
+			     fabric_hook)->perf_set;
+}
+
+static inline struct ofi_perfset *perf_set_cq(struct hook_cq *cq)
+{
+	return &container_of(cq->domain->fabric, struct perf_fabric,
+			     fabric_hook)->perf_set;
+}
+
+static inline struct ofi_perfset *perf_set_cntr(struct hook_cntr *cntr)
+{
+	return &container_of(cntr->domain->fabric, struct perf_fabric,
+			     fabric_hook)->perf_set;
+}
+
+/*
+static ssize_t
+perf_atomic_write(struct fid_ep *ep,
+		  const void *buf, size_t count, void *desc,
+		  fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		  enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_atomic(myep->hep, buf, count, desc, dest_addr,
+			addr, key, datatype, op, context);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_writev(struct fid_ep *ep,
+		   const struct fi_ioc *iov, void **desc, size_t count,
+		   fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		   enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_atomicv(myep->hep, iov, desc, count, dest_addr,
+			 addr, key, datatype, op, context);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_writemsg(struct fid_ep *ep,
+		     const struct fi_msg_atomic *msg, uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_atomicmsg(myep->hep, msg, flags);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_inject(struct fid_ep *ep, const void *buf, size_t count,
+		   fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		   enum fi_datatype datatype, enum fi_op op)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_inject_atomic(myep->hep, buf, count, dest_addr,
+			       addr, key, datatype, op);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_readwrite(struct fid_ep *ep,
+		      const void *buf, size_t count, void *desc,
+		      void *result, void *result_desc,
+		      fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		      enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_fetch_atomic(myep->hep, buf, count, desc,
+			      result, result_desc, dest_addr,
+			      addr, key, datatype, op, context);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_readwritev(struct fid_ep *ep,
+		       const struct fi_ioc *iov, void **desc, size_t count,
+		       struct fi_ioc *resultv, void **result_desc,
+		       size_t result_count, fi_addr_t dest_addr,
+		       uint64_t addr, uint64_t key, enum fi_datatype datatype,
+		       enum fi_op op, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_fetch_atomicv(myep->hep, iov, desc, count,
+			       resultv, result_desc, result_count,
+			       dest_addr, addr, key, datatype, op, context);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_readwritemsg(struct fid_ep *ep, const struct fi_msg_atomic *msg,
+			 struct fi_ioc *resultv, void **result_desc,
+			 size_t result_count, uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_fetch_atomicmsg(myep->hep, msg, resultv, result_desc,
+				 result_count, flags);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_compwrite(struct fid_ep *ep,
+		      const void *buf, size_t count, void *desc,
+		      const void *compare, void *compare_desc,
+		      void *result, void *result_desc,
+		      fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		      enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_compare_atomic(myep->hep, buf, count, desc,
+				compare, compare_desc, result, result_desc,
+				dest_addr, addr, key, datatype, op, context);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_compwritev(struct fid_ep *ep,
+		       const struct fi_ioc *iov, void **desc, size_t count,
+		       const struct fi_ioc *comparev, void **compare_desc,
+		       size_t compare_count, struct fi_ioc *resultv,
+		       void **result_desc, size_t result_count,
+		       fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		       enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_compare_atomicv(myep->hep, iov, desc, count,
+				 comparev, compare_desc, compare_count,
+				 resultv, result_desc, result_count, dest_addr,
+				 addr, key, datatype, op, context);
+	return ret;
+}
+
+static ssize_t
+perf_atomic_compwritemsg(struct fid_ep *ep,
+			 const struct fi_msg_atomic *msg,
+			 const struct fi_ioc *comparev, void **compare_desc,
+			 size_t compare_count, struct fi_ioc *resultv,
+			 void **result_desc, size_t result_count,
+			 uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_compare_atomicmsg(myep->hep, msg,
+				   comparev, compare_desc, compare_count,
+				   resultv, result_desc, result_count, flags);
+	return ret;
+}
+
+static int
+perf_atomic_writevalid(struct fid_ep *ep, enum fi_datatype datatype,
+		       enum fi_op op, size_t *count)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_atomicvalid(myep->hep, datatype, op, count);
+	return ret;
+}
+
+static int
+perf_atomic_readwritevalid(struct fid_ep *ep, enum fi_datatype datatype,
+			   enum fi_op op, size_t *count)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_fetch_atomicvalid(myep->hep, datatype, op, count);
+	return ret;
+}
+
+static int
+perf_atomic_compwritevalid(struct fid_ep *ep, enum fi_datatype datatype,
+			   enum fi_op op, size_t *count)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ret = fi_compare_atomicvalid(myep->hep, datatype, op, count);
+	return ret;
+}
+
+struct fi_ops_atomic perf_atomic_ops = {
+	.size = sizeof(struct fi_ops_atomic),
+	.write = perf_atomic_write,
+	.writev = perf_atomic_writev,
+	.writemsg = perf_atomic_writemsg,
+	.inject = perf_atomic_inject,
+	.readwrite = perf_atomic_readwrite,
+	.readwritev = perf_atomic_readwritev,
+	.readwritemsg = perf_atomic_readwritemsg,
+	.compwrite = perf_atomic_compwrite,
+	.compwritev = perf_atomic_compwritev,
+	.compwritemsg = perf_atomic_compwritemsg,
+	.writevalid = perf_atomic_writevalid,
+	.readwritevalid = perf_atomic_readwritevalid,
+	.compwritevalid = perf_atomic_compwritevalid,
+};
+*/
+
+
+static ssize_t
+perf_msg_recv(struct fid_ep *ep, void *buf, size_t len, void *desc,
+	      fi_addr_t src_addr, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_recv);
+	ret = fi_recv(myep->hep, buf, len, desc, src_addr, context);
+	ofi_perfset_end(perf_set(myep), perf_recv);
+	return ret;
+}
+
+static ssize_t
+perf_msg_recvv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+	       size_t count, fi_addr_t src_addr, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_recvv);
+	ret = fi_recvv(myep->hep, iov, desc, count, src_addr, context);
+	ofi_perfset_end(perf_set(myep), perf_recvv);
+	return ret;
+}
+
+static ssize_t
+perf_msg_recvmsg(struct fid_ep *ep, const struct fi_msg *msg, uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_recvmsg);
+	ret = fi_recvmsg(myep->hep, msg, flags);
+	ofi_perfset_end(perf_set(myep), perf_recvmsg);
+	return ret;
+}
+
+static ssize_t
+perf_msg_send(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+	      fi_addr_t dest_addr, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_send);
+	ret = fi_send(myep->hep, buf, len, desc, dest_addr, context);
+	ofi_perfset_end(perf_set(myep), perf_send);
+	return ret;
+}
+
+static ssize_t
+perf_msg_sendv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+	       size_t count, fi_addr_t dest_addr, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_sendv);
+	ret = fi_sendv(myep->hep, iov, desc, count, dest_addr, context);
+	ofi_perfset_end(perf_set(myep), perf_sendv);
+	return ret;
+}
+
+static ssize_t
+perf_msg_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
+		 uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_sendmsg);
+	ret = fi_sendmsg(myep->hep, msg, flags);
+	ofi_perfset_end(perf_set(myep), perf_sendmsg);
+	return ret;
+}
+
+static ssize_t
+perf_msg_inject(struct fid_ep *ep, const void *buf, size_t len,
+		fi_addr_t dest_addr)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_inject);
+	ret = fi_inject(myep->hep, buf, len, dest_addr);
+	ofi_perfset_end(perf_set(myep), perf_inject);
+	return ret;
+}
+
+static ssize_t
+perf_msg_senddata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		  uint64_t data, fi_addr_t dest_addr, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_senddata);
+	ret = fi_senddata(myep->hep, buf, len, desc, data, dest_addr, context);
+	ofi_perfset_end(perf_set(myep), perf_senddata);
+	return ret;
+}
+
+static ssize_t
+perf_msg_injectdata(struct fid_ep *ep, const void *buf, size_t len,
+		    uint64_t data, fi_addr_t dest_addr)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_injectdata);
+	ret = fi_injectdata(myep->hep, buf, len, data, dest_addr);
+	ofi_perfset_end(perf_set(myep), perf_injectdata);
+	return ret;
+}
+
+struct fi_ops_msg perf_msg_ops = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = perf_msg_recv,
+	.recvv = perf_msg_recvv,
+	.recvmsg = perf_msg_recvmsg,
+	.send = perf_msg_send,
+	.sendv = perf_msg_sendv,
+	.sendmsg = perf_msg_sendmsg,
+	.inject = perf_msg_inject,
+	.senddata = perf_msg_senddata,
+	.injectdata = perf_msg_injectdata,
+};
+
+
+static ssize_t
+perf_rma_read(struct fid_ep *ep, void *buf, size_t len, void *desc,
+	      fi_addr_t src_addr, uint64_t addr, uint64_t key, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_read);
+	ret = fi_read(myep->hep, buf, len, desc, src_addr, addr, key, context);
+	ofi_perfset_end(perf_set(myep), perf_read);
+	return ret;
+}
+
+static ssize_t
+perf_rma_readv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+	       size_t count, fi_addr_t src_addr, uint64_t addr, uint64_t key,
+	       void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_readv);
+	ret = fi_readv(myep->hep, iov, desc, count, src_addr,
+		       addr, key, context);
+	ofi_perfset_end(perf_set(myep), perf_readv);
+	return ret;
+}
+
+static ssize_t
+perf_rma_readmsg(struct fid_ep *ep, const struct fi_msg_rma *msg,
+		 uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_readmsg);
+	ret = fi_readmsg(myep->hep, msg, flags);
+	ofi_perfset_end(perf_set(myep), perf_readmsg);
+	return ret;
+}
+
+static ssize_t
+perf_rma_write(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+	       fi_addr_t dest_addr, uint64_t addr, uint64_t key, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_write);
+	ret = fi_write(myep->hep, buf, len, desc, dest_addr,
+		       addr, key, context);
+	ofi_perfset_end(perf_set(myep), perf_write);
+	return ret;
+}
+
+static ssize_t
+perf_rma_writev(struct fid_ep *ep, const struct iovec *iov, void **desc,
+		size_t count, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_writev);
+	ret = fi_writev(myep->hep, iov, desc, count, dest_addr,
+			addr, key, context);
+	ofi_perfset_end(perf_set(myep), perf_writev);
+	return ret;
+}
+
+static ssize_t
+perf_rma_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg,
+		  uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_writemsg);
+	ret = fi_writemsg(myep->hep, msg, flags);
+	ofi_perfset_end(perf_set(myep), perf_writemsg);
+	return ret;
+}
+
+static ssize_t
+perf_rma_inject(struct fid_ep *ep, const void *buf, size_t len,
+		fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_inject_write);
+	ret = fi_inject_write(myep->hep, buf, len, dest_addr, addr, key);
+	ofi_perfset_end(perf_set(myep), perf_inject_write);
+	return ret;
+}
+
+static ssize_t
+perf_rma_writedata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		   uint64_t data, fi_addr_t dest_addr, uint64_t addr,
+		   uint64_t key, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_writedata);
+	ret = fi_writedata(myep->hep, buf, len, desc, data,
+			   dest_addr, addr, key, context);
+	ofi_perfset_end(perf_set(myep), perf_writedata);
+	return ret;
+}
+
+static ssize_t
+perf_rma_injectdata(struct fid_ep *ep, const void *buf, size_t len,
+		    uint64_t data, fi_addr_t dest_addr, uint64_t addr,
+		    uint64_t key)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_inject_writedata);
+	ret = fi_inject_writedata(myep->hep, buf, len, data, dest_addr,
+				  addr, key);
+	ofi_perfset_end(perf_set(myep), perf_inject_writedata);
+	return ret;
+}
+
+struct fi_ops_rma perf_rma_ops = {
+	.size = sizeof(struct fi_ops_rma),
+	.read = perf_rma_read,
+	.readv = perf_rma_readv,
+	.readmsg = perf_rma_readmsg,
+	.write = perf_rma_write,
+	.writev = perf_rma_writev,
+	.writemsg = perf_rma_writemsg,
+	.inject = perf_rma_inject,
+	.writedata = perf_rma_writedata,
+	.injectdata = perf_rma_injectdata,
+};
+
+
+static ssize_t
+perf_tagged_recv(struct fid_ep *ep, void *buf, size_t len, void *desc,
+		 fi_addr_t src_addr, uint64_t tag, uint64_t ignore,
+		 void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_trecv);
+	ret = fi_trecv(myep->hep, buf, len, desc, src_addr,
+		       tag, ignore, context);
+	ofi_perfset_end(perf_set(myep), perf_trecv);
+	return ret;
+}
+
+static ssize_t
+perf_tagged_recvv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+		  size_t count, fi_addr_t src_addr, uint64_t tag,
+		  uint64_t ignore, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_trecvv);
+	ret = fi_trecvv(myep->hep, iov, desc, count, src_addr,
+			tag, ignore, context);
+	ofi_perfset_end(perf_set(myep), perf_trecvv);
+	return ret;
+}
+
+static ssize_t
+perf_tagged_recvmsg(struct fid_ep *ep, const struct fi_msg_tagged *msg,
+		    uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_trecvmsg);
+	ret = fi_trecvmsg(myep->hep, msg, flags);
+	ofi_perfset_end(perf_set(myep), perf_trecvmsg);
+	return ret;
+}
+
+static ssize_t
+perf_tagged_send(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		 fi_addr_t dest_addr, uint64_t tag, void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_tsend);
+	ret = fi_tsend(myep->hep, buf, len, desc, dest_addr, tag, context);
+	ofi_perfset_end(perf_set(myep), perf_tsend);
+	return ret;
+}
+
+static ssize_t
+perf_tagged_sendv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+		  size_t count, fi_addr_t dest_addr, uint64_t tag,
+		  void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_tsendv);
+	ret = fi_tsendv(myep->hep, iov, desc, count, dest_addr, tag, context);
+	ofi_perfset_end(perf_set(myep), perf_tsendv);
+	return ret;
+}
+
+static ssize_t
+perf_tagged_sendmsg(struct fid_ep *ep, const struct fi_msg_tagged *msg,
+		    uint64_t flags)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_tsendmsg);
+	ret = fi_tsendmsg(myep->hep, msg, flags);
+	ofi_perfset_end(perf_set(myep), perf_tsendmsg);
+	return ret;
+}
+
+static ssize_t
+perf_tagged_inject(struct fid_ep *ep, const void *buf, size_t len,
+		   fi_addr_t dest_addr, uint64_t tag)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_tinject);
+	ret = fi_tinject(myep->hep, buf, len, dest_addr, tag);
+	ofi_perfset_end(perf_set(myep), perf_tinject);
+	return ret;
+}
+
+static ssize_t
+perf_tagged_senddata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		     uint64_t data, fi_addr_t dest_addr, uint64_t tag,
+		     void *context)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_tsenddata);
+	ret = fi_tsenddata(myep->hep, buf, len, desc, data,
+			   dest_addr, tag, context);
+	ofi_perfset_end(perf_set(myep), perf_tsenddata);
+	return ret;
+}
+
+static ssize_t
+perf_tagged_injectdata(struct fid_ep *ep, const void *buf, size_t len,
+		       uint64_t data, fi_addr_t dest_addr, uint64_t tag)
+{
+	struct hook_ep *myep = container_of(ep, struct hook_ep, ep);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set(myep), perf_tinjectdata);
+	ret = fi_tinjectdata(myep->hep, buf, len, data, dest_addr, tag);
+	ofi_perfset_end(perf_set(myep), perf_tinjectdata);
+	return ret;
+}
+
+struct fi_ops_tagged perf_tagged_ops = {
+	.size = sizeof(struct fi_ops_tagged),
+	.recv = perf_tagged_recv,
+	.recvv = perf_tagged_recvv,
+	.recvmsg = perf_tagged_recvmsg,
+	.send = perf_tagged_send,
+	.sendv = perf_tagged_sendv,
+	.sendmsg = perf_tagged_sendmsg,
+	.inject = perf_tagged_inject,
+	.senddata = perf_tagged_senddata,
+	.injectdata = perf_tagged_injectdata,
+};
+
+
+static ssize_t perf_cq_read_op(struct fid_cq *cq, void *buf, size_t count)
+{
+	struct hook_cq *mycq = container_of(cq, struct hook_cq, cq);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set_cq(mycq), perf_cq_read);
+	ret = fi_cq_read(mycq->hcq, buf, count);
+	ofi_perfset_end(perf_set_cq(mycq), perf_cq_read);
+	return ret;
+}
+
+static ssize_t
+perf_cq_readerr_op(struct fid_cq *cq, struct fi_cq_err_entry *buf, uint64_t flags)
+{
+	struct hook_cq *mycq = container_of(cq, struct hook_cq, cq);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set_cq(mycq), perf_cq_readerr);
+	ret = fi_cq_readerr(mycq->hcq, buf, flags);
+	ofi_perfset_end(perf_set_cq(mycq), perf_cq_readerr);
+	return ret;
+}
+
+static ssize_t
+perf_cq_readfrom_op(struct fid_cq *cq, void *buf, size_t count, fi_addr_t *src_addr)
+{
+	struct hook_cq *mycq = container_of(cq, struct hook_cq, cq);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set_cq(mycq), perf_cq_readfrom);
+	ret = fi_cq_readfrom(mycq->hcq, buf, count, src_addr);
+	ofi_perfset_end(perf_set_cq(mycq), perf_cq_readfrom);
+	return ret;
+}
+
+static ssize_t
+perf_cq_sread_op(struct fid_cq *cq, void *buf, size_t count,
+	      const void *cond, int timeout)
+{
+	struct hook_cq *mycq = container_of(cq, struct hook_cq, cq);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set_cq(mycq), perf_cq_sread);
+	ret = fi_cq_sread(mycq->hcq, buf, count, cond, timeout);
+	ofi_perfset_end(perf_set_cq(mycq), perf_cq_sread);
+	return ret;
+}
+
+static ssize_t
+perf_cq_sreadfrom_op(struct fid_cq *cq, void *buf, size_t count,
+		  fi_addr_t *src_addr, const void *cond, int timeout)
+{
+	struct hook_cq *mycq = container_of(cq, struct hook_cq, cq);
+	ssize_t ret;
+
+	ofi_perfset_start(perf_set_cq(mycq), perf_cq_sreadfrom);
+	ret = fi_cq_sreadfrom(mycq->hcq, buf, count, src_addr, cond, timeout);
+	ofi_perfset_end(perf_set_cq(mycq), perf_cq_sreadfrom);
+	return ret;
+}
+
+static int perf_cq_signal_op(struct fid_cq *cq)
+{
+	struct hook_cq *mycq = container_of(cq, struct hook_cq, cq);
+	int ret;
+
+	ofi_perfset_start(perf_set_cq(mycq), perf_cq_signal);
+	ret = fi_cq_signal(mycq->hcq);
+	ofi_perfset_end(perf_set_cq(mycq), perf_cq_signal);
+	return ret;
+}
+
+struct fi_ops_cq perf_cq_ops = {
+	.size = sizeof(struct fi_ops_cq),
+	.read = perf_cq_read_op,
+	.readfrom = perf_cq_readfrom_op,
+	.readerr = perf_cq_readerr_op,
+	.sread = perf_cq_sread_op,
+	.sreadfrom = perf_cq_sreadfrom_op,
+	.signal = perf_cq_signal_op,
+	.strerror = hook_cq_strerror,
+};
+
+
+static uint64_t perf_cntr_read_op(struct fid_cntr *cntr)
+{
+	struct hook_cntr *mycntr = container_of(cntr, struct hook_cntr, cntr);
+	uint64_t ret;
+
+	ofi_perfset_start(perf_set_cntr(mycntr), perf_cntr_read);
+	ret = fi_cntr_read(mycntr->hcntr);
+	ofi_perfset_end(perf_set_cntr(mycntr), perf_cntr_read);
+	return ret;
+}
+
+static uint64_t perf_cntr_readerr_op(struct fid_cntr *cntr)
+{
+	struct hook_cntr *mycntr = container_of(cntr, struct hook_cntr, cntr);
+	uint64_t ret;
+
+	ofi_perfset_start(perf_set_cntr(mycntr), perf_cntr_readerr);
+	ret = fi_cntr_readerr(mycntr->hcntr);
+	ofi_perfset_end(perf_set_cntr(mycntr), perf_cntr_readerr);
+	return ret;
+}
+
+static int perf_cntr_add_op(struct fid_cntr *cntr, uint64_t value)
+{
+	struct hook_cntr *mycntr = container_of(cntr, struct hook_cntr, cntr);
+	int ret;
+
+	ofi_perfset_start(perf_set_cntr(mycntr), perf_cntr_add);
+	ret = fi_cntr_add(mycntr->hcntr, value);
+	ofi_perfset_end(perf_set_cntr(mycntr), perf_cntr_add);
+	return ret;
+}
+
+static int perf_cntr_set_op(struct fid_cntr *cntr, uint64_t value)
+{
+	struct hook_cntr *mycntr = container_of(cntr, struct hook_cntr, cntr);
+	int ret;
+
+	ofi_perfset_start(perf_set_cntr(mycntr), perf_cntr_set);
+	ret = fi_cntr_set(mycntr->hcntr, value);
+	ofi_perfset_end(perf_set_cntr(mycntr), perf_cntr_set);
+	return ret;
+}
+
+static int perf_cntr_wait_op(struct fid_cntr *cntr, uint64_t threshold, int timeout)
+{
+	struct hook_cntr *mycntr = container_of(cntr, struct hook_cntr, cntr);
+	int ret;
+
+	ofi_perfset_start(perf_set_cntr(mycntr), perf_cntr_wait);
+	ret = fi_cntr_wait(mycntr->hcntr, threshold, timeout);
+	ofi_perfset_end(perf_set_cntr(mycntr), perf_cntr_wait);
+	return ret;
+}
+
+static int perf_cntr_adderr_op(struct fid_cntr *cntr, uint64_t value)
+{
+	struct hook_cntr *mycntr = container_of(cntr, struct hook_cntr, cntr);
+	int ret;
+
+	ofi_perfset_start(perf_set_cntr(mycntr), perf_cntr_adderr);
+	ret = fi_cntr_adderr(mycntr->hcntr, value);
+	ofi_perfset_end(perf_set_cntr(mycntr), perf_cntr_adderr);
+	return ret;
+}
+
+static int perf_cntr_seterr_op(struct fid_cntr *cntr, uint64_t value)
+{
+	struct hook_cntr *mycntr = container_of(cntr, struct hook_cntr, cntr);
+	int ret;
+
+	ofi_perfset_start(perf_set_cntr(mycntr), perf_cntr_seterr);
+	ret = fi_cntr_seterr(mycntr->hcntr, value);
+	ofi_perfset_end(perf_set_cntr(mycntr), perf_cntr_seterr);
+	return ret;
+}
+
+struct fi_ops_cntr perf_cntr_ops = {
+	.size = sizeof(struct fi_ops_cntr),
+	.read = perf_cntr_read_op,
+	.readerr = perf_cntr_readerr_op,
+	.add = perf_cntr_add_op,
+	.set = perf_cntr_set_op,
+	.wait = perf_cntr_wait_op,
+	.adderr = perf_cntr_adderr_op,
+	.seterr = perf_cntr_seterr_op,
+};
+
+
+static struct fi_ops perf_fabric_fid_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = perf_hook_destroy,
+	.bind = hook_bind,
+	.control = hook_control,
+	.ops_open = hook_ops_open,
+};
+
+int perf_hook_destroy(struct fid *fid)
+{
+	struct perf_fabric *fab;
+
+	fab = container_of(fid, struct perf_fabric, fabric_hook);
+	ofi_perfset_log(&fab->perf_set, perf_counters_str);
+	ofi_perfset_close(&fab->perf_set);
+	hook_close(fid);
+
+	return FI_SUCCESS;
+}
+
+static int perf_hook_fabric(struct fi_fabric_attr *attr,
+			    struct fid_fabric **fabric, void *context)
+{
+	struct fi_provider *hprov = context;
+	struct perf_fabric *fab;
+	int ret;
+
+	FI_TRACE(hprov, FI_LOG_FABRIC, "Installing perf hook\n");
+	fab = calloc(1, sizeof *fab);
+	if (!fab)
+		return -FI_ENOMEM;
+
+	ret = ofi_perfset_create(hprov, &fab->perf_set, perf_size,
+				 perf_domain, perf_cntr, perf_flags);
+	if (ret) {
+		free(fab);
+		return ret;
+	}
+
+	hook_fabric_init(&fab->fabric_hook, HOOK_PERF, attr->fabric, hprov,
+			 &perf_fabric_fid_ops);
+	*fabric = &fab->fabric_hook.fabric;
+	return 0;
+}
+
+struct fi_provider perf_hook_prov = {
+	.version = FI_VERSION(1,0),
+	/* We're a pass-through provider, so the fi_version is always the latest */
+	.fi_version = FI_VERSION(FI_MAJOR_VERSION, FI_MINOR_VERSION),
+	.name = "ofi_perf_hook",
+	.getinfo = NULL,
+	.fabric = perf_hook_fabric,
+	.cleanup = NULL,
+};
+
+PERF_HOOK_INI
+{
+	return &perf_hook_prov;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook.c
index 3c097d623..05015d9f8 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook.c
@@ -33,7 +33,15 @@
 #include <stdlib.h>
 #include <pthread.h>
 #include <stdio.h>
-#include "hook.h"
+#include <ofi.h>
+#include <shared/ofi_str.h>
+
+#include "ofi_hook.h"
+#include "ofi_prov.h"
+
+
+static char **hooks;
+static size_t hook_cnt;
 
 
 struct fid *hook_to_hfid(const struct fid *fid)
@@ -80,12 +88,17 @@ struct fid *hook_to_hfid(const struct fid *fid)
 		return &(container_of(fid, struct hook_mr, mr.fid)->
 			 hmr->fid);
 	default:
-		assert(0);
 		return NULL;
 	}
 }
 
-static int hook_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
+struct fid_wait *hook_to_hwait(const struct fid_wait *wait)
+{
+	return container_of(wait, struct hook_wait, wait)->hwait;
+}
+
+
+int hook_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 {
 	struct fid *hfid, *hbfid;
 
@@ -97,7 +110,7 @@ static int hook_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 	return hfid->ops->bind(hfid, hbfid, flags);
 }
 
-static int hook_control(struct fid *fid, int command, void *arg)
+int hook_control(struct fid *fid, int command, void *arg)
 {
 	struct fid *hfid;
 
@@ -108,7 +121,7 @@ static int hook_control(struct fid *fid, int command, void *arg)
 	return hfid->ops->control(hfid, command, arg);
 }
 
-static int hook_ops_open(struct fid *fid, const char *name,
+int hook_ops_open(struct fid *fid, const char *name,
 			 uint64_t flags, void **ops, void *context)
 {
 	struct fid *hfid;
@@ -120,7 +133,7 @@ static int hook_ops_open(struct fid *fid, const char *name,
 	return hfid->ops->ops_open(hfid, name, flags, ops, context);
 }
 
-static int hook_close(struct fid *fid)
+int hook_close(struct fid *fid)
 {
 	struct fid *hfid;
 	int ret;
@@ -135,6 +148,7 @@ static int hook_close(struct fid *fid)
 	return ret;
 }
 
+
 struct fi_ops hook_fid_ops = {
 	.size = sizeof(struct fi_ops),
 	.close = hook_close,
@@ -143,6 +157,14 @@ struct fi_ops hook_fid_ops = {
 	.ops_open = hook_ops_open,
 };
 
+static struct fi_ops hook_fabric_fid_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = hook_close,
+	.bind = hook_bind,
+	.control = hook_control,
+	.ops_open = hook_ops_open,
+};
+
 static struct fi_ops_fabric hook_fabric_ops = {
 	.size = sizeof(struct fi_ops_fabric),
 	.domain = hook_domain,
@@ -152,22 +174,104 @@ static struct fi_ops_fabric hook_fabric_ops = {
 	.trywait = hook_trywait,
 };
 
-int hook_fabric(struct fid_fabric *hfabric, struct fid_fabric **fabric)
+void hook_fabric_init(struct hook_fabric *fabric, enum ofi_hook_class hclass,
+		      struct fid_fabric *hfabric, struct fi_provider *hprov,
+		      struct fi_ops *f_ops)
 {
+	fabric->hclass = hclass;
+	fabric->hfabric = hfabric;
+	fabric->prov = hprov;
+	fabric->fabric.fid.fclass = FI_CLASS_FABRIC;
+	fabric->fabric.fid.context = hfabric->fid.context;
+	fabric->fabric.fid.ops = f_ops;
+	fabric->fabric.api_version = hfabric->api_version;
+	fabric->fabric.ops = &hook_fabric_ops;
+
+	hfabric->fid.context = fabric;
+}
+
+static int noop_hook_fabric(struct fi_fabric_attr *attr,
+			    struct fid_fabric **fabric, void *context)
+{
+	struct fi_provider *hprov = context;
 	struct hook_fabric *fab;
 
+	FI_TRACE(hprov, FI_LOG_FABRIC, "Installing noop hook\n");
 	fab = calloc(1, sizeof *fab);
 	if (!fab)
 		return -FI_ENOMEM;
 
-	fab->fabric.fid.fclass = FI_CLASS_FABRIC;
-	fab->fabric.fid.context = hfabric->fid.context;
-	fab->fabric.fid.ops = &hook_fid_ops;
-	fab->fabric.api_version = hfabric->api_version;
-	fab->fabric.ops = &hook_fabric_ops;
-
-	hfabric->fid.context = fab;
+	hook_fabric_init(fab, HOOK_NOOP, attr->fabric, hprov,
+			 &hook_fabric_fid_ops);
 	*fabric = &fab->fabric;
-
 	return 0;
 }
+
+struct fi_provider noop_hook_prov = {
+	.version = FI_VERSION(1,0),
+	/* We're a pass-through provider, so the fi_version is always the latest */
+	.fi_version = FI_VERSION(FI_MAJOR_VERSION, FI_MINOR_VERSION),
+	.name = "ofi_noop_hook",
+	.getinfo = NULL,
+	.fabric = noop_hook_fabric,
+	.cleanup = NULL,
+};
+
+NOOP_HOOK_INI
+{
+	return &noop_hook_prov;
+}
+
+/*
+ * Call the fabric() interface of the hooking provider.  We pass in the
+ * fabric being hooked via the fabric attributes and the corresponding
+ * fi_provider structure as the context.
+ */
+void ofi_hook_install(struct fid_fabric *hfabric, struct fid_fabric **fabric,
+		      struct fi_provider *prov)
+{
+	struct fi_provider *hook_prov;
+	struct fi_fabric_attr attr;
+	int i, ret;
+
+	*fabric = hfabric;
+	if (!hook_cnt || !hooks)
+		return;
+
+	memset(&attr, 0, sizeof attr);
+
+	for (i = 0; i < hook_cnt; i++) {
+		hook_prov = ofi_get_hook(hooks[i]);
+		if (!hook_prov)
+			continue;
+
+		attr.fabric = hfabric;
+		ret = hook_prov->fabric(&attr, fabric, prov);
+		if (ret)
+			continue;
+
+		hfabric = *fabric;
+	}
+}
+
+void ofi_hook_init(void)
+{
+	char *param_val = NULL;
+
+	fi_param_define(NULL, "hook", FI_PARAM_STRING,
+			"Intercept calls to underlying provider and apply "
+			"the specified functionality to them.  Hook option: "
+			"perf (gather performance data)");
+	fi_param_get_str(NULL, "hook", &param_val);
+
+	if (!param_val)
+		return;
+
+	hooks = ofi_split_and_alloc(param_val, ";", &hook_cnt);
+}
+
+void ofi_hook_fini(void)
+{
+	if (hooks)
+		ofi_free_string_array(hooks);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_av.c
index ddde2735f..c57df17ea 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_av.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_av.c
@@ -31,7 +31,7 @@
  */
 
 #include <stdlib.h>
-#include "hook.h"
+#include "ofi_hook.h"
 
 
 static int
@@ -112,6 +112,7 @@ int hook_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 	if (!myav)
 		return -FI_ENOMEM;
 
+	myav->domain = dom;
 	myav->av.fid.fclass = FI_CLASS_AV;
 	myav->av.fid.context = context;
 	myav->av.fid.ops = &hook_fid_ops;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cm.c
index 071f9a430..124ef38bf 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cm.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cm.c
@@ -30,7 +30,7 @@
  * SOFTWARE.
  */
 
-#include "hook.h"
+#include "ofi_hook.h"
 
 
 static int hook_setname(fid_t fid, void *addr, size_t addrlen)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cntr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cntr.c
index 3d7a9f98d..781bc9489 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cntr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cntr.c
@@ -31,7 +31,7 @@
  */
 
 #include <stdlib.h>
-#include "hook.h"
+#include "hook_prov.h"
 
 
 static uint64_t hook_cntr_read(struct fid_cntr *cntr)
@@ -99,18 +99,32 @@ int hook_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
 {
 	struct hook_domain *dom = container_of(domain, struct hook_domain, domain);
 	struct hook_cntr *mycntr;
+	struct fi_cntr_attr hattr;
 	int ret;
 
 	mycntr = calloc(1, sizeof *mycntr);
 	if (!mycntr)
 		return -FI_ENOMEM;
 
+	mycntr->domain = dom;
 	mycntr->cntr.fid.fclass = FI_CLASS_CNTR;
 	mycntr->cntr.fid.context = context;
 	mycntr->cntr.fid.ops = &hook_fid_ops;
-	mycntr->cntr.ops = &hook_cntr_ops;
 
-	ret = fi_cntr_open(dom->hdomain, attr, &mycntr->hcntr,
+	switch (dom->fabric->hclass) {
+	case HOOK_PERF:
+		mycntr->cntr.ops = &perf_cntr_ops;
+		break;
+	default:
+		mycntr->cntr.ops = &hook_cntr_ops;
+		break;
+	}
+
+	hattr = *attr;
+	if (attr->wait_obj == FI_WAIT_SET)
+		hattr.wait_set = hook_to_hwait(attr->wait_set);
+
+	ret = fi_cntr_open(dom->hdomain, &hattr, &mycntr->hcntr,
 			   &mycntr->cntr.fid);
 	if (ret)
 		free(mycntr);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cq.c
index a23c722f7..fb3bb83bc 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_cq.c
@@ -31,7 +31,7 @@
  */
 
 #include <stdlib.h>
-#include "hook.h"
+#include "hook_prov.h"
 
 
 static ssize_t hook_cq_read(struct fid_cq *cq, void *buf, size_t count)
@@ -82,7 +82,7 @@ static int hook_cq_signal(struct fid_cq *cq)
 	return fi_cq_signal(mycq->hcq);
 }
 
-static const char *
+const char *
 hook_cq_strerror(struct fid_cq *cq, int prov_errno,
 		 const void *err_data, char *buf, size_t len)
 {
@@ -107,18 +107,32 @@ int hook_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
 {
 	struct hook_domain *dom = container_of(domain, struct hook_domain, domain);
 	struct hook_cq *mycq;
+	struct fi_cq_attr hattr;
 	int ret;
 
 	mycq = calloc(1, sizeof *mycq);
 	if (!mycq)
 		return -FI_ENOMEM;
 
+	mycq->domain = dom;
 	mycq->cq.fid.fclass = FI_CLASS_CQ;
 	mycq->cq.fid.context = context;
 	mycq->cq.fid.ops = &hook_fid_ops;
-	mycq->cq.ops = &hook_cq_ops;
 
-	ret = fi_cq_open(dom->hdomain, attr, &mycq->hcq, &mycq->cq.fid);
+	switch (dom->fabric->hclass) {
+	case HOOK_PERF:
+		mycq->cq.ops = &perf_cq_ops;
+		break;
+	default:
+		mycq->cq.ops = &hook_cq_ops;
+		break;
+	}
+
+	hattr = *attr;
+	if (attr->wait_obj == FI_WAIT_SET)
+		hattr.wait_set = hook_to_hwait(attr->wait_set);
+
+	ret = fi_cq_open(dom->hdomain, &hattr, &mycq->hcq, &mycq->cq.fid);
 	if (ret)
 		free(mycq);
 	else
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_domain.c
index e4519a6da..04706665a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_domain.c
@@ -32,7 +32,7 @@
 
 #include <stdlib.h>
 #include <sys/uio.h>
-#include "hook.h"
+#include "ofi_hook.h"
 
 
 static int hook_mr_regattr(struct fid *fid, const struct fi_mr_attr *attr,
@@ -46,6 +46,7 @@ static int hook_mr_regattr(struct fid *fid, const struct fi_mr_attr *attr,
 	if (!mymr)
 		return -FI_ENOMEM;
 
+	mymr->domain = dom;
 	mymr->mr.fid.fclass = FI_CLASS_MR;
 	mymr->mr.fid.context = attr->context;
 	mymr->mr.fid.ops = &hook_fid_ops;
@@ -135,6 +136,7 @@ int hook_domain(struct fid_fabric *fabric, struct fi_info *info,
 	if (!dom)
 		return -FI_ENOMEM;
 
+	dom->fabric = fab;
 	dom->domain.fid.fclass = FI_CLASS_DOMAIN;
 	dom->domain.fid.context = context;
 	dom->domain.fid.ops = &hook_fid_ops;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_ep.c
index 8916cb5ad..655a1b42b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_ep.c
@@ -32,7 +32,7 @@
 
 #include <stdlib.h>
 #include <ofi_enosys.h>
-#include "hook.h"
+#include "hook_prov.h"
 
 
 static int hook_open_tx_ctx(struct fid_ep *sep, int index,
@@ -86,16 +86,27 @@ static struct fi_ops_ep hook_ep_ops = {
 };
 
 
-static void hook_setup_ep(struct fid_ep *ep, int fclass, void *context)
+static void hook_setup_ep(enum ofi_hook_class hclass, struct fid_ep *ep,
+			  int fclass, void *context)
 {
 	ep->fid.fclass = fclass;
 	ep->fid.context = context;
 	ep->fid.ops = &hook_fid_ops;
 	ep->ops = &hook_ep_ops;
 	ep->cm = &hook_cm_ops;
-	ep->msg = &hook_msg_ops;
-	ep->rma = &hook_rma_ops;
-	ep->tagged = &hook_tagged_ops;
+
+	switch (hclass) {
+	case HOOK_PERF:
+		ep->msg = &perf_msg_ops;
+		ep->rma = &perf_rma_ops;
+		ep->tagged = &perf_tagged_ops;
+		break;
+	default:
+		ep->msg = &hook_msg_ops;
+		ep->rma = &hook_rma_ops;
+		ep->tagged = &hook_tagged_ops;
+		break;
+	}
 	ep->atomic = &hook_atomic_ops;
 }
 
@@ -110,7 +121,8 @@ int hook_scalable_ep(struct fid_domain *domain, struct fi_info *info,
 	if (!mysep)
 		return -FI_ENOMEM;
 
-	hook_setup_ep(&mysep->ep, FI_CLASS_SEP, context);
+	mysep->domain = dom;
+	hook_setup_ep(dom->fabric->hclass, &mysep->ep, FI_CLASS_SEP, context);
 	ret = fi_scalable_ep(dom->hdomain, info, &mysep->hep, &mysep->ep.fid);
 	if (ret)
 		free(mysep);
@@ -132,6 +144,7 @@ int hook_stx_ctx(struct fid_domain *domain,
 	if (!mystx)
 		return -FI_ENOMEM;
 
+	mystx->domain = dom;
 	mystx->stx.fid.fclass = FI_CLASS_STX_CTX;
 	mystx->stx.fid.context = context;
 	mystx->stx.fid.ops = &hook_fid_ops;
@@ -157,7 +170,8 @@ int hook_srx_ctx(struct fid_domain *domain, struct fi_rx_attr *attr,
 	if (!srx)
 		return -FI_ENOMEM;
 
-	hook_setup_ep(&srx->ep, FI_CLASS_SRX_CTX, context);
+	srx->domain = dom;
+	hook_setup_ep(dom->fabric->hclass, &srx->ep, FI_CLASS_SRX_CTX, context);
 	ret = fi_srx_context(dom->hdomain, attr, &srx->hep, &srx->ep.fid);
 	if (ret)
 		free(srx);
@@ -179,7 +193,9 @@ static int hook_open_tx_ctx(struct fid_ep *sep, int index,
 	if (!mytx)
 		return -FI_ENOMEM;
 
-	hook_setup_ep(&mytx->ep, FI_CLASS_TX_CTX, context);
+	mytx->domain = mysep->domain;
+	hook_setup_ep(mysep->domain->fabric->hclass, &mytx->ep,
+		      FI_CLASS_TX_CTX, context);
 	ret = fi_tx_context(mysep->hep, index, attr, &mytx->hep, &mytx->ep.fid);
 	if (ret)
 		free(mytx);
@@ -201,7 +217,9 @@ static int hook_open_rx_ctx(struct fid_ep *sep, int index,
 	if (!myrx)
 		return -FI_ENOMEM;
 
-	hook_setup_ep(&myrx->ep, FI_CLASS_RX_CTX, context);
+	myrx->domain = mysep->domain;
+	hook_setup_ep(mysep->domain->fabric->hclass, &myrx->ep,
+		      FI_CLASS_RX_CTX, context);
 	ret = fi_rx_context(mysep->hep, index, attr, &myrx->hep, &myrx->ep.fid);
 	if (ret)
 		free(myrx);
@@ -222,6 +240,7 @@ int hook_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
 	if (!mypep)
 		return -FI_ENOMEM;
 
+	mypep->fabric = fab;
 	mypep->pep.fid.fclass = FI_CLASS_PEP;
 	mypep->pep.fid.context = context;
 	mypep->pep.fid.ops = &hook_fid_ops;
@@ -242,18 +261,27 @@ int hook_endpoint(struct fid_domain *domain, struct fi_info *info,
 {
 	struct hook_domain *dom = container_of(domain, struct hook_domain, domain);
 	struct hook_ep *myep;
+	struct fid *saved_fid;
 	int ret;
 
 	myep = calloc(1, sizeof *myep);
 	if (!myep)
 		return -FI_ENOMEM;
 
-	hook_setup_ep(&myep->ep, FI_CLASS_EP, context);
+	saved_fid = info->handle;
+	if (saved_fid) {
+		info->handle = hook_to_hfid(info->handle);
+		if (!info->handle)
+			info->handle = saved_fid;
+	}
+	myep->domain = dom;
+	hook_setup_ep(dom->fabric->hclass, &myep->ep, FI_CLASS_EP, context);
 	ret = fi_endpoint(dom->hdomain, info, &myep->hep, &myep->ep.fid);
 	if (ret)
 		free(myep);
 	else
 		*ep = &myep->ep;
 
+	info->handle = saved_fid;
 	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_eq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_eq.c
index 33460c10d..8391099e1 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_eq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_eq.c
@@ -31,12 +31,12 @@
  */
 
 #include <stdlib.h>
-#include "hook.h"
+#include "ofi_hook.h"
 
 
 static int hook_eq_std_event(uint32_t event)
 {
-	return event <= FI_JOIN_COMPLETE;
+	return (event > FI_NOTIFY) && (event <= FI_JOIN_COMPLETE);
 }
 
 /*
@@ -121,18 +121,24 @@ int hook_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
 {
 	struct hook_fabric *fab = container_of(fabric, struct hook_fabric, fabric);
 	struct hook_eq *myeq;
+	struct fi_eq_attr hattr;
 	int ret;
 
 	myeq = calloc(1, sizeof *myeq);
 	if (!myeq)
 		return -FI_ENOMEM;
 
+	myeq->fabric = fab;
 	myeq->eq.fid.fclass = FI_CLASS_EQ;
 	myeq->eq.fid.context = context;
 	myeq->eq.fid.ops = &hook_fid_ops;
 	myeq->eq.ops = &hook_eq_ops;
 
-	ret = fi_eq_open(fab->hfabric, attr, &myeq->heq, &myeq->eq.fid);
+	hattr = *attr;
+	if (attr->wait_obj == FI_WAIT_SET)
+		hattr.wait_set = hook_to_hwait(attr->wait_set);
+
+	ret = fi_eq_open(fab->hfabric, &hattr, &myeq->heq, &myeq->eq.fid);
 	if (ret)
 		free(myeq);
 	else
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_wait.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_wait.c
index e2287e1d5..31e8fa47e 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_wait.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_wait.c
@@ -31,7 +31,7 @@
  */
 
 #include <stdlib.h>
-#include "hook.h"
+#include "ofi_hook.h"
 
 
 static int hook_do_poll(struct fid_poll *pollset, void **context, int count)
@@ -83,6 +83,7 @@ int hook_poll_open(struct fid_domain *domain, struct fi_poll_attr *attr,
 	if (!poll)
 		return -FI_ENOMEM;
 
+	poll->domain = dom;
 	poll->poll.fid.fclass = FI_CLASS_POLL;
 	poll->poll.fid.ops = &hook_fid_ops;
 	poll->poll.ops = &hook_poll_ops;
@@ -139,6 +140,7 @@ int hook_wait_open(struct fid_fabric *fabric, struct fi_wait_attr *attr,
 	if (!wait)
 		return -FI_ENOMEM;
 
+	wait->fabric = fab;
 	wait->wait.fid.fclass = FI_CLASS_WAIT;
 	wait->wait.fid.ops = &hook_fid_ops;
 	wait->wait.ops = &hook_wait_ops;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_xfer.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_xfer.c
index 9f846cdb7..9c00754eb 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_xfer.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/hook/src/hook_xfer.c
@@ -30,7 +30,7 @@
  * SOFTWARE.
  */
 
-#include "hook.h"
+#include "ofi_hook.h"
 
 
 static ssize_t
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_av.c
index 89ebb80d7..bb9e944c1 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_av.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_av.c
@@ -118,7 +118,7 @@ static int mlx_av_insert(
 {
 	struct mlx_av *av;
 	struct mlx_ep *ep;
-	int i;
+	size_t i;
 	ucs_status_t status = UCS_OK;
 	int added = 0;
 
@@ -129,35 +129,34 @@ static int mlx_av_insert(
 		return -FI_ENOEQ;
 	}
 
-	for ( i = 0; i < count ; ++i) {
-		ucp_ep_params_t ep_params = {};
+	for (i = 0; i < count ; ++i) {
+		ucp_ep_params_t ep_params = { 0 };
 
 		if (mlx_descriptor.use_ns) {
 			if (mlx_av_resolve_if_addr(
 				(struct sockaddr*)
-				  (&(((struct sockaddr_in*)addr)[i])),
-				(char**)&ep_params.address) != FI_SUCCESS)
+				  (&(((struct sockaddr_in *) addr)[i])),
+				(char**) &ep_params.address) != FI_SUCCESS)
 				break;
 		} else {
 			ep_params.address = (const ucp_address_t *)
-				(&(((const char *)addr)[i * FI_MLX_MAX_NAME_LEN]));
+				(&(((const char *) addr)[i * av->addr_len]));
 		}
 
 		ep_params.field_mask = UCP_EP_PARAM_FIELD_REMOTE_ADDRESS;
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"Try to insert address #%d, offset=%d (size=%ld)"
+		FI_WARN(&mlx_prov, FI_LOG_CORE,
+			"Try to insert address #%zd, offset=%zd (size=%zd)"
 			" fi_addr=%p \naddr = %s\n",
-			i, i * FI_MLX_MAX_NAME_LEN, count,
-			fi_addr, &(((const char *)addr)[i * FI_MLX_MAX_NAME_LEN]));
+			i, i * av->addr_len, count,
+			fi_addr, &(((const char *) addr)[i * av->addr_len]));
 
-		status = ucp_ep_create( ep->worker,
-					&ep_params,
-					(ucp_ep_h *)(&(fi_addr[i])));
+		status = ucp_ep_create(ep->worker, &ep_params,
+				       (ucp_ep_h *)(&(fi_addr[i])));
 		if (mlx_descriptor.use_ns) {
-			free((void*)ep_params.address);
+			free((void *) ep_params.address);
 		}
 		if (status == UCS_OK) {
-			FI_WARN( &mlx_prov, FI_LOG_CORE, "address inserted\n");
+			FI_WARN(&mlx_prov, FI_LOG_CORE, "address inserted\n");
 			added++;
 		} else {
 			if (av->eq) {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_callbacks.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_callbacks.c
index 9f0dc318e..ab1abc990 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_callbacks.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_callbacks.c
@@ -45,7 +45,7 @@ void mlx_send_callback(void *request,
 	struct util_cq *cq;
 	struct mlx_request *mlx_req = request;
 	struct fi_cq_tagged_entry *t_entry;
-	struct util_cq_err_entry *err;
+	struct util_cq_oflow_err_entry *err;
 
 	cq = mlx_req->cq;
 
@@ -62,18 +62,18 @@ void mlx_send_callback(void *request,
 
 	if (status != UCS_OK){
 		t_entry->flags |= UTIL_FLAG_ERROR;
-		err = calloc(1, sizeof(struct util_cq_err_entry));
+		err = calloc(1, sizeof(struct util_cq_oflow_err_entry));
 		if (!err) {
 			FI_WARN(&mlx_prov, FI_LOG_CQ,
 				"out of memory, cannot report CQ error\n");
 			goto fn;
 		}
 
-		err->err_entry = (mlx_req->completion.error);
-		err->err_entry.prov_errno = (int)status;
-		err->err_entry.err = MLX_TRANSLATE_ERRCODE(status);
-		err->err_entry.olen = 0;
-		slist_insert_tail(&err->list_entry, &cq->err_list);
+		err->comp = (mlx_req->completion.error);
+		err->comp.prov_errno = (int)status;
+		err->comp.err = MLX_TRANSLATE_ERRCODE(status);
+		err->comp.olen = 0;
+		slist_insert_tail(&err->list_entry, &cq->oflow_err_list);
 	}
 fn:
 	mlx_req->type = MLX_FI_REQ_UNINITIALIZED;
@@ -133,10 +133,10 @@ void mlx_recv_callback(void *request,
 		*t_entry = (mlx_req->completion.tagged);
 
 		if (status != UCS_OK) {
-			struct util_cq_err_entry* err;
+			struct util_cq_oflow_err_entry *err;
 			t_entry->flags |= UTIL_FLAG_ERROR;
 
-			err = calloc(1, sizeof(struct util_cq_err_entry));
+			err = calloc(1, sizeof(struct util_cq_oflow_err_entry));
 			if (!err) {
 				FI_WARN(&mlx_prov, FI_LOG_CQ,
 					"out of memory, cannot report CQ error\n");
@@ -144,8 +144,8 @@ void mlx_recv_callback(void *request,
 				goto fn;
 			}
 
-			err->err_entry = (mlx_req->completion.error);
-			slist_insert_tail(&err->list_entry, &cq->err_list);
+			err->comp = (mlx_req->completion.error);
+			slist_insert_tail(&err->list_entry, &cq->oflow_err_list);
 		}
 
 		if (cq->src){
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_cm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_cm.c
index 47b5c1482..c0b7668fa 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_cm.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_cm.c
@@ -89,11 +89,14 @@ static int mlx_cm_getname_ai_format(
 			size_t *addrlen)
 {
 	int ofi_status = FI_SUCCESS;
-	struct mlx_ep* ep;
-	ep = container_of(fid, struct mlx_ep, ep.ep_fid.fid);
+	struct mlx_ep* ep = container_of(fid, struct mlx_ep, ep.ep_fid.fid);
+
 	if (ep->addr) {
 		if (ep->addr_len > *addrlen) {
 			ofi_status = -FI_ETOOSMALL;
+			FI_WARN(&mlx_prov, FI_LOG_EP_CTRL,
+				"addrlen expected: %"PRIu64", got: %"PRIu64"\n",
+				ep->addr_len, *addrlen);
 		} else {
 			memcpy(addr, ep->addr, ep->addr_len);
 		}
@@ -101,32 +104,35 @@ static int mlx_cm_getname_ai_format(
 	} else {
 		char *hostname = mlx_descriptor.localhost;
 		int service = (((getpid() & 0xFFFF)));
-		struct addrinfo hints;
+		struct addrinfo hints = {
+			.ai_family = AF_INET,
+			.ai_socktype = SOCK_STREAM,
+			.ai_protocol = IPPROTO_TCP,
+		};
 		struct addrinfo *res;
 
-		memset(&hints, 0, sizeof(hints));
-		hints.ai_flags = 0;
-		hints.ai_family = AF_INET;
-		hints.ai_socktype = SOCK_STREAM;
-		hints.ai_protocol = IPPROTO_TCP;
-		hints.ai_addrlen = 0;
-		hints.ai_addr = NULL;
-		hints.ai_canonname = NULL;
-		hints.ai_next = NULL;
-
-		if(getaddrinfo(hostname, NULL, &hints, &res) != 0) {
-			FI_WARN( &mlx_prov, FI_LOG_CORE,
-					"Unable to resolve hostname:%s\n",hostname);
+		if (getaddrinfo(hostname, NULL, &hints, &res) != 0) {
+			FI_WARN(&mlx_prov, FI_LOG_CORE,
+				"Unable to resolve hostname:%s\n", hostname);
+			return -FI_EAVAIL;
 		}
 		FI_INFO(&mlx_prov, FI_LOG_CORE,
-			"Loaded IPv4 address: [%"PRIu64"]%s:%d\n",
-			res->ai_addrlen, hostname, service);
+			"Loaded IPv4 address: [%jd]%s:%d\n",
+			(intmax_t) res->ai_addrlen, hostname, service);
 
-		memcpy(addr,res->ai_addr,res->ai_addrlen);
-		((struct sockaddr_in*)addr)->sin_port = htons((short)service);
-		freeaddrinfo(res);
+		if (res->ai_addrlen > *addrlen) {
+			ofi_status = -FI_ETOOSMALL;
+			FI_WARN(&mlx_prov, FI_LOG_EP_CTRL,
+				"addrlen expected: %jd, got: %"PRIu64"\n",
+				(intmax_t) res->ai_addrlen, *addrlen);
+		} else {
+			memcpy(addr, res->ai_addr, res->ai_addrlen);
+			((struct sockaddr_in *)addr)->sin_port = htons((short)service);
+		}
 
-		*addrlen = sizeof(struct sockaddr);
+		*addrlen = res->ai_addrlen;
+
+		freeaddrinfo(res);
 	}
 
 	return ofi_status;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_fabric.c
index 527ceb320..f443da750 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_fabric.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_fabric.c
@@ -85,7 +85,7 @@ static char* mlx_local_host_resolve()
 	char *iface = NULL;
 	char *result = NULL;
 
-	status = fi_param_get( &mlx_prov, "mlx_ns_iface",
+	status = fi_param_get( &mlx_prov, "ns_iface",
 		&iface);
 	if (!status) {
 		iface = NULL;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_init.c
index dd6cb5c55..fbbe14a78 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_init.c
@@ -79,7 +79,7 @@ struct fi_domain_attr mlx_domain_attrs = {
 	.data_progress = FI_PROGRESS_MANUAL,
 	.resource_mgmt = FI_RM_DISABLED,
 	.av_type = FI_AV_UNSPEC,
-	.mr_mode = OFI_MR_BASIC_MAP,
+	.mr_mode = OFI_MR_BASIC_MAP | FI_MR_BASIC,
 	.mr_key_size = -1, /*Should be setup after init*/
 	.tx_ctx_cnt = 1,
 	.rx_ctx_cnt = 1,
@@ -166,26 +166,26 @@ static int mlx_getinfo (
 	mlx_descriptor.config = NULL;
 
 	status = fi_param_get( &mlx_prov,
-				"mlx_tinject_limit",
+				"tinject_limit",
 				&inject_thresh);
 	if (!status)
 		inject_thresh = FI_MLX_DEFAULT_INJECT_SIZE;
 
 	FI_INFO( &mlx_prov, FI_LOG_CORE,
-		"used inlect size = %d \n", inject_thresh);
+		"used inject size = %d \n", inject_thresh);
 
-	status = fi_param_get( &mlx_prov, "mlx_config", &configfile_name);
+	status = fi_param_get( &mlx_prov, "config", &configfile_name);
 	if (!status) {
 		configfile_name = NULL;
 	}
 
 	/* NS is disabled by default */
-	status = fi_param_get( &mlx_prov, "mlx_ns_enable",
+	status = fi_param_get( &mlx_prov, "ns_enable",
 			&mlx_descriptor.use_ns);
 	if (!status) {
 		mlx_descriptor.use_ns = 0;
 	}
-	status = fi_param_get( &mlx_prov, "mlx_ns_port",
+	status = fi_param_get( &mlx_prov, "ns_port",
 			&mlx_descriptor.ns_port);
 	if (!status) {
 		mlx_descriptor.ns_port = FI_MLX_DEFAULT_NS_PORT;
@@ -260,7 +260,7 @@ void mlx_cleanup(void)
 struct fi_provider mlx_prov = {
 	.name = FI_MLX_FABRIC_NAME,
 	.version = FI_MLX_VERSION,
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = mlx_getinfo,
 	.fabric = mlx_fabric_open,
 	.cleanup = mlx_cleanup,
@@ -271,23 +271,23 @@ MLX_INI
 {
 	mlx_init_errcodes();
 	fi_param_define( &mlx_prov,
-			"mlx_config", FI_PARAM_STRING,
+			"config", FI_PARAM_STRING,
 			"MLX configuration file name");
 
 	fi_param_define(&mlx_prov,
-			"mlx_tinject_limit", FI_PARAM_INT,
+			"tinject_limit", FI_PARAM_INT,
 			"Maximal tinject message size");
 
 	fi_param_define(&mlx_prov,
-			"mlx_ns_port", FI_PARAM_INT,
+			"ns_port", FI_PARAM_INT,
 			"MLX Name server port");
 
 	fi_param_define(&mlx_prov,
-			"mlx_ns_enable",FI_PARAM_BOOL,
+			"ns_enable",FI_PARAM_BOOL,
 			"Enforce usage of name server for MLX provider");
 
 	fi_param_define(&mlx_prov,
-			"mlx_ns_iface",FI_PARAM_STRING,
+			"ns_iface",FI_PARAM_STRING,
 			"Specify IPv4 network interface for MLX provider's name server'");
 	return &mlx_prov;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_tagged.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_tagged.c
index e0d54d40b..afb3f090a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_tagged.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mlx/src/mlx_tagged.c
@@ -98,19 +98,19 @@ static ssize_t mlx_tagged_recvmsg(
 	*t_entry = (req->completion.tagged);
 
 	if (req->type == MLX_FI_REQ_UNEXPECTED_ERR) {
-		struct util_cq_err_entry* err;
+		struct util_cq_oflow_err_entry* err;
 		req->completion.error.olen -= req->completion.tagged.len;
 		t_entry->flags |= UTIL_FLAG_ERROR;
 
-		err = calloc(1, sizeof(struct util_cq_err_entry));
+		err = calloc(1, sizeof(struct util_cq_oflow_err_entry));
 		if (!err) {
 			FI_WARN(&mlx_prov, FI_LOG_CQ,
 				"out of memory, cannot report CQ error\n");
 			fastlock_release(&cq->cq_lock);
 			return -FI_ENOMEM;
 		}
-		err->err_entry = (req->completion.error);
-		slist_insert_tail(&err->list_entry, &cq->err_list);
+		err->comp = (req->completion.error);
+		slist_insert_tail(&err->list_entry, &cq->oflow_err_list);
 	}
 
 	ofi_cirque_commit(cq->cirq);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/Makefile.include
new file mode 100644
index 000000000..f993fa941
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/Makefile.include
@@ -0,0 +1,28 @@
+if HAVE_MRAIL
+_mrail_files = \
+	prov/mrail/src/mrail_init.c	\
+	prov/mrail/src/mrail_attr.c	\
+	prov/mrail/src/mrail_fabric.c	\
+	prov/mrail/src/mrail_domain.c	\
+	prov/mrail/src/mrail_cq.c	\
+	prov/mrail/src/mrail_ep.c	\
+	prov/mrail/src/mrail_av.c	\
+	prov/mrail/src/mrail_rma.c	\
+	prov/mrail/src/mrail.h
+
+if HAVE_MRAIL_DL
+pkglib_LTLIBRARIES += libmrail-fi.la
+libmrail_fi_la_SOURCES = $(_mrail_files) $(common_srcs)
+libmrail_fi_la_LIBADD = $(linkback) $(mrail_shm_LIBS)
+libmrail_fi_la_LDFLAGS = -module -avoid-version -shared -export-dynamic
+libmrail_fi_la_DEPENDENCIES = $(linkback)
+else !HAVE_MRAIL_DL
+src_libfabric_la_SOURCES += $(_mrail_files)
+src_libfabric_la_LIBADD += $(mrail_shm_LIBS)
+endif !HAVE_MRAIL_DL
+
+prov_install_man_pages += man/man7/fi_mrail.7
+
+endif HAVE_MRAIL
+
+prov_dist_man_pages += man/man7/fi_mrail.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/configure.m4 b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/configure.m4
new file mode 100644
index 000000000..a5f7c1ad8
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/configure.m4
@@ -0,0 +1,15 @@
+dnl Configury specific to the libfabric mrail provider
+
+dnl Called to configure this provider
+dnl
+dnl Arguments:
+dnl
+dnl $1: action if configured successfully
+dnl $2: action if not configured successfully
+dnl
+AC_DEFUN([FI_MRAIL_CONFIGURE],[
+       # Determine if we can support the mrail provider
+       mrail_h_happy=0
+       AS_IF([test x"$enable_mrail" != x"no"], [mrail_h_happy=1])
+       AS_IF([test $mrail_h_happy -eq 1], [$1], [$2])
+])
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/TODO b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/TODO
new file mode 100644
index 000000000..ec6f16658
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/TODO
@@ -0,0 +1,28 @@
+TODO:
+-----
+
+Feature / issue				Status
+----------------------------------------------------
+CQ					in-progress
+AV					in-progress
+EP					in-progress
+small msgs (un-ordered)			in-progress
+support for multiple layering		-
+(above is needed for multi-rail
+ over ofi_rxm provider)
+OFI_MULTI_RAIL env var			-
+fi_dupinfo issue			-
+App mode bit to make it aware		-
+of list of rails in fi_info
+addressing:				-
+	- FI_ADDR_STRV
+	- primary/failover
+small msg ordering:			-
+	- bounce buffers
+large msg support:			-
+	- use FI_VARIABLE_MSG
+Memory registration			-
+RMA					-
+rail failure handling			-
+rail selection / striping algorithm	-
+Atomics					-
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail.h
new file mode 100644
index 000000000..851bf86e0
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail.h
@@ -0,0 +1,363 @@
+/*
+ * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#if HAVE_CONFIG_H
+#  include <config.h>
+#endif /* HAVE_CONFIG_H */
+
+#include <string.h>
+
+#include <rdma/fabric.h>
+#include <rdma/fi_atomic.h>
+#include <rdma/fi_cm.h>
+#include <rdma/fi_domain.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_eq.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_tagged.h>
+#include "rdma/providers/fi_log.h"
+
+#include <ofi.h>
+#include <ofi_util.h>
+#include <ofi_iov.h>
+#include <ofi_list.h>
+#include <ofi_proto.h>
+#include <ofi_prov.h>
+#include <ofi_enosys.h>
+
+#define MRAIL_MAJOR_VERSION 1
+#define MRAIL_MINOR_VERSION 0
+
+#define MRAIL_MAX_INFO 100
+
+#define MRAIL_PASSTHRU_MODES 	(0ULL)
+#define MRAIL_PASSTHRU_MR_MODES	(OFI_MR_BASIC_MAP)
+
+#define MRAIL_RAIL_CQ_FORMAT	FI_CQ_FORMAT_TAGGED
+
+extern struct fi_info mrail_info;
+extern struct fi_provider mrail_prov;
+extern struct util_prov mrail_util_prov;
+extern struct fi_fabric_attr mrail_fabric_attr;
+
+extern struct fi_info *mrail_info_vec[MRAIL_MAX_INFO];
+extern size_t mrail_num_info;
+
+extern struct fi_ops_rma mrail_ops_rma;
+
+struct mrail_match_attr {
+	fi_addr_t addr;
+	uint64_t tag;
+};
+
+struct mrail_unexp_msg_entry {
+	struct dlist_entry 	entry;
+	fi_addr_t 		addr;
+	uint64_t 		tag;
+	void			*context;
+	char			data[];		/* completion entry */
+};
+
+struct mrail_recv_queue;
+
+typedef struct mrail_unexp_msg_entry *
+(*mrail_get_unexp_msg_entry_func)(struct mrail_recv_queue *recv_queue, void *context);
+
+struct mrail_recv_queue {
+	struct fi_provider 		*prov;
+	struct dlist_entry 		recv_list;
+	struct dlist_entry 		unexp_msg_list;
+	dlist_func_t 			*match_recv;
+	dlist_func_t 			*match_unexp;
+	mrail_get_unexp_msg_entry_func	get_unexp_msg_entry;
+};
+
+struct mrail_recv *
+mrail_match_recv_handle_unexp(struct mrail_recv_queue *recv_queue, uint64_t tag,
+			      uint64_t addr, char *data, size_t len, void *context);
+
+/* mrail protocol */
+#define MRAIL_HDR_VERSION 1
+
+struct mrail_hdr {
+	uint8_t		version;
+	uint8_t		op;
+	uint8_t		padding[2];
+	uint32_t	seq;
+	uint64_t 	tag;
+};
+
+struct mrail_tx_buf {
+	/* context should stay at top and would get overwritten on
+	 * util buf release */
+	void			*context;
+	struct mrail_ep		*ep;
+	/* flags would be used for both operation flags (FI_COMPLETION)
+	 * and completion flags (FI_MSG, FI_TAGGED, etc) */
+	uint64_t		flags;
+	struct mrail_hdr	hdr;
+};
+
+struct mrail_pkt {
+	struct mrail_hdr	hdr;
+	char 			data[];
+};
+
+/* TX & RX processing */
+
+#define MRAIL_IOV_LIMIT	5
+
+struct mrail_rx_buf {
+	struct fid_ep		*rail_ep;
+	struct mrail_pkt	pkt;
+};
+
+struct mrail_recv {
+	struct iovec 		iov[MRAIL_IOV_LIMIT];
+	void 			*desc[MRAIL_IOV_LIMIT];
+	uint8_t 		count;
+	void 			*context;
+	uint64_t 		flags;
+	uint64_t 		comp_flags;
+	struct mrail_hdr	hdr;
+	struct mrail_ep		*ep;
+	struct dlist_entry 	entry;
+	fi_addr_t 		addr;
+	uint64_t 		tag;
+	uint64_t 		ignore;
+};
+DECLARE_FREESTACK(struct mrail_recv, mrail_recv_fs);
+
+int mrail_cq_process_buf_recv(struct fi_cq_tagged_entry *comp,
+			      struct mrail_recv *recv);
+
+struct mrail_fabric {
+	struct util_fabric util_fabric;
+	struct fi_info *info;
+	struct fid_fabric **fabrics;
+	size_t num_fabrics;
+};
+
+struct mrail_domain {
+	struct util_domain util_domain;
+	struct fi_info *info;
+	struct fid_domain **domains;
+	size_t num_domains;
+	size_t addrlen;
+};
+
+struct mrail_av {
+	struct util_av util_av;
+	struct fid_av **avs;
+	size_t *rail_addrlen;
+	size_t num_avs;
+};
+
+struct mrail_peer_info {
+	struct slist	ooo_recv_queue;
+	fi_addr_t	addr;
+	uint32_t	seq_no;
+	uint32_t	expected_seq_no;
+};
+
+struct mrail_ooo_recv {
+	struct slist_entry 		entry;
+	struct fi_cq_tagged_entry 	comp;
+	uint32_t 			seq_no;
+};
+
+typedef int (*mrail_cq_process_comp_func_t)(struct fi_cq_tagged_entry *comp,
+					    fi_addr_t src_addr);
+struct mrail_cq {
+	struct util_cq 			util_cq;
+	struct fid_cq 			**cqs;
+	size_t 				num_cqs;
+	mrail_cq_process_comp_func_t	process_comp;
+};
+
+struct mrail_ep {
+	struct util_ep		util_ep;
+	struct fi_info		*info;
+	struct {
+		struct fid_ep 		*ep;
+		struct fi_info		*info;
+	}			*rails;
+	size_t			num_eps;
+	ofi_atomic32_t		tx_rail;
+	ofi_atomic32_t		rx_rail;
+
+	struct mrail_recv_fs	*recv_fs;
+	struct mrail_recv_queue recv_queue;
+	struct mrail_recv_queue trecv_queue;
+
+	struct util_buf_pool	*req_pool;
+	struct util_buf_pool 	*ooo_recv_pool;
+	struct util_buf_pool 	*tx_buf_pool;
+	struct slist		deferred_reqs;
+};
+
+struct mrail_addr_key {
+	uint64_t base_addr;
+	uint64_t key;
+};
+
+struct mrail_mr {
+	struct fid_mr mr_fid;
+	size_t num_mrs;
+	struct {
+		uint64_t base_addr;
+		struct fid_mr *mr;
+	} rails[];
+};
+
+int mrail_get_core_info(uint32_t version, const char *node, const char *service,
+			uint64_t flags, const struct fi_info *hints,
+			struct fi_info **core_info);
+int mrail_fabric_open(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
+		       void *context);
+int mrail_domain_open(struct fid_fabric *fabric, struct fi_info *info,
+		       struct fid_domain **domain, void *context);
+int mrail_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
+		   struct fid_cq **cq_fid, void *context);
+int mrail_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+		   struct fid_av **av_fid, void *context);
+int mrail_ep_open(struct fid_domain *domain, struct fi_info *info,
+		   struct fid_ep **ep_fid, void *context);
+
+static inline struct mrail_recv *
+mrail_pop_recv(struct mrail_ep *mrail_ep)
+{
+	struct mrail_recv *recv;
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	recv = freestack_isempty(mrail_ep->recv_fs) ? NULL :
+		freestack_pop(mrail_ep->recv_fs);
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+	return recv;
+}
+
+static inline void
+mrail_push_recv(struct mrail_recv *recv)
+{
+	ofi_ep_lock_acquire(&recv->ep->util_ep);
+	freestack_push(recv->ep->recv_fs, recv);
+	ofi_ep_lock_release(&recv->ep->util_ep);
+}
+
+static inline struct fi_info *mrail_get_info_cached(char *name)
+{
+	struct fi_info *info;
+	size_t i;
+
+	for (i = 0; i < mrail_num_info; i++) {
+		info = mrail_info_vec[i];
+		if (!strcmp(info->fabric_attr->name, name))
+			return info;
+	}
+
+	FI_WARN(&mrail_prov, FI_LOG_CORE, "Unable to find matching "
+		"fi_info in mrail_info_vec for given fabric name\n");
+	return NULL;
+}
+
+static inline int mrail_close_fids(struct fid **fids, size_t count)
+{
+	int ret, retv = 0;
+	size_t i;
+
+	for (i = 0; i < count; i++) {
+		if (fids[i]) {
+			ret = fi_close(fids[i]);
+			if (ret)
+				retv = ret;
+		}
+	}
+	return retv;
+}
+
+static inline size_t mrail_get_tx_rail(struct mrail_ep *mrail_ep)
+{
+	return (ofi_atomic_inc32(&mrail_ep->tx_rail) - 1) % mrail_ep->num_eps;
+}
+
+struct mrail_subreq {
+	struct fi_context context;
+	struct mrail_req *parent;
+	void *descs[MRAIL_IOV_LIMIT];
+	struct iovec iov[MRAIL_IOV_LIMIT];
+	struct fi_rma_iov rma_iov[MRAIL_IOV_LIMIT];
+	size_t iov_count;
+	size_t rma_iov_count;
+};
+
+struct mrail_req {
+	struct slist_entry entry;
+	uint64_t flags;
+	uint64_t data;
+	struct mrail_ep *mrail_ep;
+	struct mrail_peer_info *peer_info;
+	struct fi_cq_tagged_entry comp;
+	ofi_atomic32_t expected_subcomps;
+	int op_type;
+	int pending_subreq;
+	struct mrail_subreq subreqs[];
+};
+
+static inline
+struct mrail_req *mrail_alloc_req(struct mrail_ep *mrail_ep)
+{
+	struct mrail_req *req;
+
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	req = util_buf_alloc(mrail_ep->req_pool);
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+
+	return req;
+}
+
+static inline
+void mrail_free_req(struct mrail_ep *mrail_ep, struct mrail_req *req)
+{
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	util_buf_release(mrail_ep->req_pool, req);
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+}
+
+void mrail_progress_deferred_reqs(struct mrail_ep *mrail_ep);
+
+void mrail_poll_cq(struct util_cq *cq);
+
+static inline void mrail_cntr_incerr(struct util_cntr *cntr)
+{
+       if (cntr) {
+               cntr->cntr_fid.ops->adderr(&cntr->cntr_fid, 1);
+       }
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_attr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_attr.c
new file mode 100644
index 000000000..7786b379b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_attr.c
@@ -0,0 +1,106 @@
+/*
+ * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "mrail.h"
+
+struct fi_tx_attr mrail_tx_attr = {
+	.caps 		= ~0x0ULL,
+	.msg_order 	= ~0x0ULL,
+	.comp_order 	= ~0x0ULL,
+	.inject_size 	= SIZE_MAX,
+	.size 		= SIZE_MAX,
+	.iov_limit 	= MRAIL_IOV_LIMIT,
+	.rma_iov_limit 	= SIZE_MAX,
+};
+
+struct fi_rx_attr mrail_rx_attr = {
+	.caps 			= ~0x0ULL,
+	.msg_order 		= ~0x0ULL,
+	.comp_order 		= ~0x0ULL,
+	.total_buffered_recv 	= SIZE_MAX,
+	.size 			= SIZE_MAX,
+	.iov_limit		= SIZE_MAX,
+};
+
+struct fi_ep_attr mrail_ep_attr = {
+	.type 			= FI_EP_UNSPEC,
+	.protocol 		= FI_PROTO_MRAIL,
+	.protocol_version 	= 1,
+	.max_msg_size 		= SIZE_MAX,
+	.msg_prefix_size	= SIZE_MAX,
+	.max_order_raw_size 	= SIZE_MAX,
+	.max_order_war_size 	= SIZE_MAX,
+	.max_order_waw_size 	= SIZE_MAX,
+	.tx_ctx_cnt 		= SIZE_MAX,
+	.rx_ctx_cnt 		= SIZE_MAX,
+	.auth_key_size		= SIZE_MAX,
+};
+
+struct fi_domain_attr mrail_domain_attr = {
+	.name			= "ofi_mrail_domain",
+	.threading 		= FI_THREAD_SAFE,
+	.control_progress 	= FI_PROGRESS_AUTO,
+	.data_progress 		= FI_PROGRESS_AUTO,
+	.resource_mgmt 		= FI_RM_ENABLED,
+	.av_type 		= FI_AV_UNSPEC,
+	.mr_mode 		= FI_MR_BASIC | FI_MR_SCALABLE | FI_MR_RAW,
+	.mr_key_size		= SIZE_MAX,
+	.cq_data_size 		= SIZE_MAX,
+	.cq_cnt 		= SIZE_MAX,
+	.ep_cnt 		= SIZE_MAX,
+	.tx_ctx_cnt 		= SIZE_MAX,
+	.rx_ctx_cnt 		= SIZE_MAX,
+	.max_ep_tx_ctx 		= SIZE_MAX,
+	.max_ep_rx_ctx 		= SIZE_MAX,
+	.max_ep_stx_ctx 	= SIZE_MAX,
+	.max_ep_srx_ctx 	= SIZE_MAX,
+	.cntr_cnt 		= SIZE_MAX,
+	.mr_iov_limit 		= SIZE_MAX,
+	.caps			= ~0x0ULL,
+	.auth_key_size		= SIZE_MAX,
+	.max_err_data		= SIZE_MAX,
+	.mr_cnt			= SIZE_MAX,
+};
+
+struct fi_fabric_attr mrail_fabric_attr = {
+	.prov_version = FI_VERSION(MRAIL_MAJOR_VERSION, MRAIL_MINOR_VERSION),
+	.name = "ofi_mrail_fabric",
+};
+
+struct fi_info mrail_info = {
+	.caps = ~0x0ULL,
+	.tx_attr = &mrail_tx_attr,
+	.rx_attr = &mrail_rx_attr,
+	.ep_attr = &mrail_ep_attr,
+	.domain_attr = &mrail_domain_attr,
+	.fabric_attr = &mrail_fabric_attr
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_av.c
new file mode 100644
index 000000000..d55a5dbb9
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_av.c
@@ -0,0 +1,204 @@
+#include "mrail.h"
+
+static int mrail_av_close(struct fid *fid)
+{
+	struct mrail_av *mrail_av = container_of(fid, struct mrail_av,
+						 util_av.av_fid);
+	int ret, retv = 0;
+
+	ret = mrail_close_fids((struct fid **)mrail_av->avs, mrail_av->num_avs);
+	if (ret)
+		retv = ret;
+	free(mrail_av->avs);
+	free(mrail_av->rail_addrlen);
+
+	ret = ofi_av_close(&mrail_av->util_av);
+	if (ret)
+		retv = ret;
+
+	free(mrail_av);
+	return retv;
+}
+
+static int mrail_av_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
+{
+	return ofi_av_bind(fid, bfid, flags);
+}
+
+static const char *mrail_av_straddr(struct fid_av *av, const void *addr,
+				  char *buf, size_t *len)
+{
+	return NULL;
+}
+
+static int mrail_av_insertsvc(struct fid_av *av, const char *node,
+			   const char *service, fi_addr_t *fi_addr,
+			   uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+static int mrail_av_insertsym(struct fid_av *av_fid, const char *node, size_t nodecnt,
+			   const char *service, size_t svccnt, fi_addr_t *fi_addr,
+			   uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+static int mrail_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr,
+			 size_t *addrlen)
+{
+	return -FI_ENOSYS;
+
+}
+
+static int mrail_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr, size_t count,
+			uint64_t flags)
+{
+	return -FI_ENOSYS;
+}
+
+static int mrail_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
+			fi_addr_t *fi_addr, uint64_t flags, void *context)
+{
+	struct mrail_domain *mrail_domain;
+	struct mrail_av *mrail_av;
+	struct mrail_peer_info *peer_info;
+	size_t i, j, offset, num_inserted = 0;
+	fi_addr_t index;
+	int ret;
+
+	mrail_av = container_of(av_fid, struct mrail_av, util_av.av_fid);
+	mrail_domain = container_of(mrail_av->util_av.domain, struct mrail_domain,
+				    util_domain);
+
+	/* TODO if it's more optimal to insert multiple addresses at once
+	 * convert ADDR1: ADDR1_RAIL1:ADDR1_RAIL2
+	 *         ADDR2: ADDR2_RAIL1:ADDR2_RAIL2
+	 * 	   to
+	 *         ADDR1: ADDR1_RAIL1:ADDR2_RAIL1
+	 *         ADDR2: ADDR1_RAIL2:ADDR2_RAIL2
+	*/
+
+	peer_info = calloc(1, mrail_av->util_av.addrlen);
+	if (!peer_info)
+		return -FI_ENOMEM;
+	slist_init(&peer_info->ooo_recv_queue);
+
+	for (i = 0; i < count; i++) {
+		offset = i * mrail_domain->addrlen;
+		for (j = 0; j < mrail_av->num_avs; j++) {
+			ofi_straddr_dbg(&mrail_prov, FI_LOG_EP_CTRL,
+					"addr", addr);
+			ret = fi_av_insert(mrail_av->avs[j],
+					   (char *)addr + offset, 1,
+					   NULL, flags, NULL);
+			if (ret != 1) {
+				free(peer_info);
+				return ret;
+			}
+			offset += mrail_av->rail_addrlen[j];
+		}
+		ret = ofi_av_insert_addr(&mrail_av->util_av, peer_info,
+					 &index);
+		if (fi_addr) {
+			if (ret) {
+				FI_WARN(&mrail_prov, FI_LOG_AV, \
+					"Unable to get rail fi_addr\n");
+				peer_info->addr = FI_ADDR_NOTAVAIL;
+			} else {
+				peer_info->addr = index;
+				num_inserted++;
+			}
+			fi_addr[i] = peer_info->addr;
+		}
+	}
+
+	free(peer_info);
+	return num_inserted;
+}
+
+static struct fi_ops_av mrail_av_ops = {
+	.size = sizeof(struct fi_ops_av),
+	.insert = mrail_av_insert,
+	.insertsvc = mrail_av_insertsvc,
+	.insertsym = mrail_av_insertsym,
+	.remove = mrail_av_remove,
+	.lookup = mrail_av_lookup,
+	.straddr = mrail_av_straddr,
+};
+
+static struct fi_ops mrail_av_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = mrail_av_close,
+	.bind = mrail_av_bind,
+	.control = fi_no_control,
+	.ops_open = fi_no_ops_open,
+};
+
+int mrail_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+		   struct fid_av **av_fid, void *context)
+{
+	struct mrail_av *mrail_av;
+	struct mrail_domain *mrail_domain;
+	struct fi_av_attr rail_attr;
+	struct util_av_attr util_attr;
+	struct fi_info *fi;
+	size_t i;
+	int ret;
+
+	mrail_domain = container_of(domain_fid, struct mrail_domain,
+				    util_domain.domain_fid);
+	mrail_av = calloc(1, sizeof(*mrail_av));
+	if (!mrail_av)
+		return -FI_ENOMEM;
+
+	mrail_av->num_avs = mrail_domain->num_domains;
+
+	util_attr.addrlen = sizeof(struct mrail_peer_info);
+	/* We just need a table to store the mapping */
+	util_attr.flags = 0;
+
+	if (attr->type == FI_AV_UNSPEC)
+		attr->type = FI_AV_TABLE;
+
+	ret = ofi_av_init(&mrail_domain->util_domain, attr, &util_attr,
+			 &mrail_av->util_av, context);
+	if (ret) {
+		free(mrail_av);
+		return ret;
+	}
+
+	mrail_av->avs = calloc(mrail_av->num_avs, sizeof(*mrail_av->avs));
+	if (!mrail_av->avs) {
+		ret = -FI_ENOMEM;
+		goto err;
+	}
+
+	mrail_av->rail_addrlen = calloc(mrail_av->num_avs,
+					sizeof(*mrail_av->rail_addrlen));
+	if (!mrail_av->rail_addrlen) {
+		ret = -FI_ENOMEM;
+		goto err;
+	}
+
+	rail_attr = *attr;
+	rail_attr.type = FI_AV_TABLE;
+	for (i = 0, fi = mrail_domain->info->next; i < mrail_av->num_avs;
+	     i++, fi = fi->next) {
+		ret = fi_av_open(mrail_domain->domains[i], &rail_attr,
+				 &mrail_av->avs[i], context);
+		if (ret)
+			goto err;
+		mrail_av->rail_addrlen[i] = fi->src_addrlen;
+	}
+
+	mrail_av->util_av.av_fid.fid.ops = &mrail_av_fi_ops;
+	mrail_av->util_av.av_fid.ops = &mrail_av_ops;
+	*av_fid = &mrail_av->util_av.av_fid;
+
+	return 0;
+err:
+	mrail_av_close(&mrail_av->util_av.av_fid.fid);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_cq.c
new file mode 100644
index 000000000..4e03f81a4
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_cq.c
@@ -0,0 +1,498 @@
+/*
+ * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *	- Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *	- Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <ofi_iov.h>
+
+#include "mrail.h"
+
+int mrail_cq_write_recv_comp(struct mrail_ep *mrail_ep, struct mrail_hdr *hdr,
+			     struct fi_cq_tagged_entry *comp,
+			     struct mrail_recv *recv)
+{
+	FI_DBG(&mrail_prov, FI_LOG_CQ, "finish recv: length: %zu "
+	       "tag: 0x%" PRIx64 "\n", comp->len - sizeof(struct mrail_pkt),
+	       hdr->tag);
+	ofi_ep_rx_cntr_inc(&mrail_ep->util_ep);
+	if (!(recv->flags & FI_COMPLETION))
+		return 0;
+	return ofi_cq_write(mrail_ep->util_ep.rx_cq, recv->context,
+			   recv->comp_flags |
+			   (comp->flags & FI_REMOTE_CQ_DATA),
+			   comp->len - sizeof(struct mrail_pkt),
+			   NULL, comp->data, hdr->tag);
+}
+
+int mrail_cq_process_buf_recv(struct fi_cq_tagged_entry *comp,
+			      struct mrail_recv *recv)
+{
+	struct fi_recv_context *recv_ctx = comp->op_context;
+	struct fi_msg msg = {
+		.context = recv_ctx,
+	};
+	struct mrail_ep *mrail_ep;
+	struct mrail_pkt *mrail_pkt;
+	size_t size, len;
+	int ret, retv = 0;
+
+	if (comp->flags & FI_MORE) {
+		msg.msg_iov	= recv->iov;
+		msg.iov_count	= recv->count;
+		msg.addr	= recv->addr;
+
+		recv_ctx->context = recv;
+
+		ret = fi_recvmsg(recv_ctx->ep, &msg, FI_CLAIM);
+		if (ret) {
+			FI_WARN(&mrail_prov, FI_LOG_CQ,
+				"Unable to claim buffered recv\n");
+			assert(0);
+			// TODO write cq error entry
+		}
+		return ret;
+	}
+
+	mrail_ep = recv_ctx->ep->fid.context;
+	mrail_pkt = (struct mrail_pkt *)comp->buf;
+
+	len = comp->len - sizeof(*mrail_pkt);
+
+	size = ofi_copy_to_iov(&recv->iov[1], recv->count - 1, 0,
+			       mrail_pkt->data, len);
+
+	if (size < len) {
+		FI_WARN(&mrail_prov, FI_LOG_CQ, "Message truncated recv buf "
+			"size: %zu message length: %zu\n", size, len);
+		ret = ofi_cq_write_error_trunc(
+			mrail_ep->util_ep.rx_cq, recv->context,
+			recv->comp_flags | (comp->flags & FI_REMOTE_CQ_DATA),
+			0, NULL, comp->data, mrail_pkt->hdr.tag, comp->len - size);
+		if (ret) {
+			FI_WARN(&mrail_prov, FI_LOG_CQ,
+				"Unable to write truncation error to util cq\n");
+			retv = ret;
+		}
+		mrail_cntr_incerr(mrail_ep->util_ep.rx_cntr);
+		goto out;
+	}
+	ret = mrail_cq_write_recv_comp(mrail_ep, &mrail_pkt->hdr, comp, recv);
+	if (ret)
+		retv = ret;
+out:
+	ret = fi_recvmsg(recv_ctx->ep, &msg, FI_DISCARD);
+	if (ret) {
+		FI_WARN(&mrail_prov, FI_LOG_CQ,
+			"Unable to discard buffered recv\n");
+		retv = ret;
+	}
+	mrail_push_recv(recv);
+	return retv;
+}
+
+/* Should only be called while holding the EP's lock */
+static struct mrail_recv *mrail_match_recv(struct mrail_ep *mrail_ep,
+					   struct fi_cq_tagged_entry *comp,
+					   int src_addr)
+{
+	struct mrail_hdr *hdr = comp->buf;
+	struct mrail_recv *recv;
+
+	if (hdr->op == ofi_op_msg) {
+		FI_DBG(&mrail_prov, FI_LOG_CQ, "Got MSG op\n");
+		recv = mrail_match_recv_handle_unexp(&mrail_ep->recv_queue, 0,
+						     src_addr, (char *)comp,
+						     sizeof(*comp), NULL);
+	} else {
+		assert(hdr->op == ofi_op_tagged);
+		FI_DBG(&mrail_prov, FI_LOG_CQ, "Got TAGGED op with tag: 0x%"
+		       PRIx64 "\n", hdr->tag);
+		recv = mrail_match_recv_handle_unexp(&mrail_ep->trecv_queue,
+						     hdr->tag, src_addr,
+						     (char *)comp,
+						     sizeof(*comp), NULL);
+	}
+
+	return recv;
+}
+
+static
+struct mrail_ooo_recv *mrail_get_next_recv(struct mrail_peer_info *peer_info)
+{
+	struct slist *queue = &peer_info->ooo_recv_queue;
+	struct mrail_ooo_recv *ooo_recv;
+
+	if (!slist_empty(queue)) {
+		ooo_recv = container_of(queue->head, struct mrail_ooo_recv,
+				entry);
+		if (ooo_recv->seq_no == peer_info->expected_seq_no) {
+			slist_remove_head(queue);
+			peer_info->expected_seq_no++;
+			return ooo_recv;
+		}
+	}
+	return NULL;
+}
+
+static int mrail_process_ooo_recvs(struct mrail_ep *mrail_ep,
+				   struct mrail_peer_info *peer_info)
+{
+	struct mrail_ooo_recv *ooo_recv;
+	struct mrail_recv *recv;
+	int ret;
+
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	ooo_recv = mrail_get_next_recv(peer_info);
+	while (ooo_recv) {
+		FI_DBG(&mrail_prov, FI_LOG_CQ, "found ooo_recv seq=%d\n",
+				ooo_recv->seq_no);
+		/* Requesting FI_AV_TABLE from the underlying provider allows
+		 * us to use peer_info->addr as an int here. */
+		recv = mrail_match_recv(mrail_ep, &ooo_recv->comp,
+				(int) peer_info->addr);
+		ofi_ep_lock_release(&mrail_ep->util_ep);
+
+		if (recv) {
+			ret = mrail_cq_process_buf_recv(&ooo_recv->comp, recv);
+			if (ret)
+				return ret;
+		}
+
+		ofi_ep_lock_acquire(&mrail_ep->util_ep);
+		util_buf_release(mrail_ep->ooo_recv_pool, ooo_recv);
+		ooo_recv = mrail_get_next_recv(peer_info);
+	}
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+	return 0;
+}
+
+static int mrail_ooo_recv_before(struct slist_entry *item, const void *arg)
+{
+	struct mrail_ooo_recv *ooo_recv;
+	struct mrail_ooo_recv *new_recv;
+
+	ooo_recv = container_of(item, struct mrail_ooo_recv, entry);
+	new_recv = container_of(arg, struct mrail_ooo_recv, entry);
+	return (new_recv->seq_no < ooo_recv->seq_no);
+}
+
+/* Should only be called while holding the EP's lock */
+static void mrail_save_ooo_recv(struct mrail_ep *mrail_ep,
+				struct mrail_peer_info *peer_info,
+				uint32_t seq_no,
+				struct fi_cq_tagged_entry *comp)
+{
+	struct slist *queue = &peer_info->ooo_recv_queue;
+	struct mrail_ooo_recv *ooo_recv;
+
+	ooo_recv = util_buf_alloc(mrail_ep->ooo_recv_pool);
+	if (!ooo_recv) {
+		FI_WARN(&mrail_prov, FI_LOG_CQ, "Cannot allocate ooo_recv\n");
+		assert(0);
+	}
+	ooo_recv->seq_no = seq_no;
+	memcpy(&ooo_recv->comp, comp, sizeof(*comp));
+
+	slist_insert_before_first_match(queue, mrail_ooo_recv_before,
+					&ooo_recv->entry);
+
+	FI_DBG(&mrail_prov, FI_LOG_CQ, "saved ooo_recv seq=%d\n", seq_no);
+}
+
+static int mrail_handle_recv_completion(struct fi_cq_tagged_entry *comp,
+					fi_addr_t src_addr)
+{
+	struct fi_recv_context *recv_ctx;
+	struct mrail_peer_info *peer_info;
+	struct mrail_ep *mrail_ep;
+	struct mrail_recv *recv;
+	struct mrail_hdr *hdr;
+	uint32_t seq_no;
+	int ret;
+
+	if (comp->flags & FI_CLAIM) {
+		/* This message has already been processed and claimed.
+		 * See mrail_cq_process_buf_recv().
+		 */
+		recv = comp->op_context;
+		assert(recv->hdr.version == MRAIL_HDR_VERSION);
+		ret =  mrail_cq_write_recv_comp(recv->ep, &recv->hdr, comp,
+						recv);
+		mrail_push_recv(recv);
+		goto exit;
+	}
+
+	recv_ctx = comp->op_context;
+	mrail_ep = recv_ctx->ep->fid.context;
+	hdr = comp->buf;
+
+	// TODO make rxm send buffered recv amount of data for large message
+	assert(hdr->version == MRAIL_HDR_VERSION);
+
+	seq_no = ntohl(hdr->seq);
+	peer_info = ofi_av_get_addr(mrail_ep->util_ep.av, (int) src_addr);
+	FI_DBG(&mrail_prov, FI_LOG_CQ,
+			"ep=%p peer=%d received seq=%d, expected=%d\n",
+			mrail_ep, (int)peer_info->addr, seq_no,
+			peer_info->expected_seq_no);
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	if (seq_no == peer_info->expected_seq_no) {
+		/* This message was received in order */
+		peer_info->expected_seq_no++;
+		/* Requesting FI_AV_TABLE from the underlying provider allows
+		 * us to use src_addr as an int here. */
+		recv = mrail_match_recv(mrail_ep, comp, (int) src_addr);
+		ofi_ep_lock_release(&mrail_ep->util_ep);
+
+		if (recv) {
+			ret = mrail_cq_process_buf_recv(comp, recv);
+			if (ret)
+				goto exit;
+		}
+
+		/* Process any next-in-order message that had already arrived */
+		ret = mrail_process_ooo_recvs(mrail_ep, peer_info);
+	} else {
+		/* This message was received early.
+		 * Save it into the out-of-order recv queue.
+		 */
+		mrail_save_ooo_recv(mrail_ep, peer_info, seq_no, comp);
+		ofi_ep_lock_release(&mrail_ep->util_ep);
+		ret = 0;
+	}
+exit:
+	return ret;
+}
+
+static int mrail_cq_close(fid_t fid)
+{
+	struct mrail_cq *mrail_cq = container_of(fid, struct mrail_cq, util_cq.cq_fid.fid);
+	int ret, retv = 0;
+
+	ret = mrail_close_fids((struct fid **)mrail_cq->cqs,
+			       mrail_cq->num_cqs);
+	if (ret)
+		retv = ret;
+	free(mrail_cq->cqs);
+
+	ret = ofi_cq_cleanup(&mrail_cq->util_cq);
+	if (ret)
+		retv = ret;
+
+	free(mrail_cq);
+	return retv;
+}
+
+static struct fi_ops mrail_cq_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = mrail_cq_close,
+	.bind = fi_no_bind,
+	.control = fi_no_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static struct fi_ops_cq mrail_cq_ops = {
+	.size = sizeof(struct fi_ops_cq),
+	.read = ofi_cq_read,
+	.readfrom = ofi_cq_readfrom,
+	.readerr = ofi_cq_readerr,
+	.sread = ofi_cq_sread,
+	.sreadfrom = ofi_cq_sreadfrom,
+	.signal = ofi_cq_signal,
+	// TODO define cq strerror, may need to pass rail index
+	// in err_data
+	.strerror = fi_no_cq_strerror,
+};
+
+static void mrail_handle_rma_completion(struct util_cq *cq,
+		struct fi_cq_tagged_entry *comp)
+{
+	int ret;
+	struct mrail_req *req;
+	struct mrail_subreq *subreq;
+
+	subreq = comp->op_context;
+	req = subreq->parent;
+
+	if (ofi_atomic_dec32(&req->expected_subcomps) == 0) {
+		ret = ofi_cq_write(cq, req->comp.op_context, req->comp.flags,
+				req->comp.len, req->comp.buf, req->comp.data,
+				req->comp.tag);
+		if (ret) {
+			FI_WARN(&mrail_prov, FI_LOG_CQ,
+				"Cannot write to util cq\n");
+			/* This should not happen unless totally out of memory,
+			 * in which case there is nothing we can do.  */
+			assert(0);
+		}
+
+		if (comp->flags & FI_WRITE)
+			ofi_ep_wr_cntr_inc(&req->mrail_ep->util_ep);
+		else
+			ofi_ep_rd_cntr_inc(&req->mrail_ep->util_ep);
+
+		mrail_free_req(req->mrail_ep, req);
+	}
+}
+
+void mrail_poll_cq(struct util_cq *cq)
+{
+	struct mrail_cq *mrail_cq;
+	struct mrail_tx_buf *tx_buf;
+	struct fi_cq_tagged_entry comp;
+	fi_addr_t src_addr;
+	size_t i;
+	int ret;
+
+	mrail_cq = container_of(cq, struct mrail_cq, util_cq);
+
+	for (i = 0; i < mrail_cq->num_cqs; i++) {
+		ret = fi_cq_readfrom(mrail_cq->cqs[i], &comp, 1, &src_addr);
+		if (ret == -FI_EAGAIN || !ret)
+			continue;
+		if (ret < 0) {
+			FI_WARN(&mrail_prov, FI_LOG_CQ,
+				"Unable to read rail completion: %s\n",
+				fi_strerror(-ret));
+			goto err1;
+		}
+		// TODO handle variable length message
+		if (comp.flags & FI_RECV) {
+			ret = mrail_cq->process_comp(&comp, src_addr);
+			if (ret)
+				goto err1;
+		} else if (comp.flags & (FI_READ | FI_WRITE)) {
+			mrail_handle_rma_completion(cq, &comp);
+		} else if (comp.flags & FI_SEND) {
+			tx_buf = comp.op_context;
+
+			ofi_ep_tx_cntr_inc(&tx_buf->ep->util_ep);
+
+			if (tx_buf->flags & FI_COMPLETION) {
+				ret = ofi_cq_write(cq, tx_buf->context,
+						   (tx_buf->flags &
+						    (FI_TAGGED | FI_MSG)) |
+						   FI_SEND, 0, NULL, 0, 0);
+				if (ret) {
+					FI_WARN(&mrail_prov, FI_LOG_CQ,
+						"Unable to write to util cq\n");
+					goto err2;
+				}
+			}
+			ofi_ep_lock_acquire(&tx_buf->ep->util_ep);
+			util_buf_release(tx_buf->ep->tx_buf_pool, tx_buf);
+			ofi_ep_lock_release(&tx_buf->ep->util_ep);
+		} else {
+			/* We currently cannot support FI_REMOTE_READ and
+			 * FI_REMOTE_WRITE because RMA operations are split
+			 * across all rails. We would need to introduce some
+			 * sort of protocol to keep track of remotely-initiated
+			 * RMA operations. */
+			assert(comp.flags & (FI_REMOTE_READ | FI_REMOTE_WRITE));
+			FI_WARN(&mrail_prov, FI_LOG_CQ,
+				"Unsupported completion flag\n");
+		}
+	}
+
+	return;
+
+err2:
+	ofi_ep_lock_acquire(&tx_buf->ep->util_ep);
+	util_buf_release(tx_buf->ep->tx_buf_pool, tx_buf);
+	ofi_ep_lock_release(&tx_buf->ep->util_ep);
+err1:
+	// TODO write error to cq
+	assert(0);
+}
+
+static void mrail_cq_progress(struct util_cq *cq)
+{
+	mrail_poll_cq(cq);
+
+	/* Progress the bound EPs */
+	ofi_cq_progress(cq);
+}
+
+int mrail_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
+		   struct fid_cq **cq_fid, void *context)
+{
+	struct mrail_domain *mrail_domain;
+	struct mrail_cq *mrail_cq;
+	struct fi_cq_attr rail_cq_attr = {
+		.wait_obj = FI_WAIT_NONE,
+		.format = MRAIL_RAIL_CQ_FORMAT,
+		.size = attr->size,
+	};
+	size_t i;
+	int ret;
+
+	mrail_cq = calloc(1, sizeof(*mrail_cq));
+	if (!mrail_cq)
+		return -FI_ENOMEM;
+
+	ret = ofi_cq_init(&mrail_prov, domain, attr, &mrail_cq->util_cq,
+			  &mrail_cq_progress, context);
+	if (ret) {
+		free(mrail_cq);
+		return ret;
+	}
+
+	mrail_domain = container_of(domain, struct mrail_domain,
+				    util_domain.domain_fid);
+
+	mrail_cq->cqs = calloc(mrail_domain->num_domains,
+			       sizeof(*mrail_cq->cqs));
+	if (!mrail_cq->cqs)
+		goto err;
+
+	mrail_cq->num_cqs = mrail_domain->num_domains;
+
+	for (i = 0; i < mrail_cq->num_cqs; i++) {
+		ret = fi_cq_open(mrail_domain->domains[i], &rail_cq_attr,
+				 &mrail_cq->cqs[i], NULL);
+		if (ret) {
+			FI_WARN(&mrail_prov, FI_LOG_EP_CTRL,
+				"Unable to open rail CQ\n");
+			goto err;
+		}
+	}
+
+	// TODO add regular process comp when FI_BUFFERED_RECV not set
+	mrail_cq->process_comp = mrail_handle_recv_completion;
+
+	*cq_fid = &mrail_cq->util_cq.cq_fid;
+	(*cq_fid)->fid.ops = &mrail_cq_fi_ops;
+	(*cq_fid)->ops = &mrail_cq_ops;
+
+	return 0;
+err:
+	mrail_cq_close(&mrail_cq->util_cq.cq_fid.fid);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_domain.c
new file mode 100644
index 000000000..1b73f1cee
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_domain.c
@@ -0,0 +1,311 @@
+/*
+ * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "mrail.h"
+
+static int mrail_domain_close(fid_t fid)
+{
+	struct mrail_domain *mrail_domain =
+		container_of(fid, struct mrail_domain, util_domain.domain_fid.fid);
+	int ret, retv = 0;
+
+	ret = mrail_close_fids((struct fid **)mrail_domain->domains,
+			       mrail_domain->num_domains);
+	if (ret)
+		retv = ret;
+	free(mrail_domain->domains);
+
+	ret = ofi_domain_close(&mrail_domain->util_domain);
+	if (ret)
+		retv = ret;
+
+	free(mrail_domain);
+	return retv;
+}
+
+static int mrail_domain_map_raw(struct mrail_domain *mrail_domain,
+                                struct fi_mr_map_raw *map)
+{
+	struct mrail_addr_key *mr_map;
+
+	/* Copy the raw key and use a pointer as the new key. */
+
+	mr_map = calloc(1, map->key_size);
+	if (!mr_map) {
+		return -FI_ENOMEM;
+	}
+
+	memcpy(mr_map, map->raw_key, map->key_size);
+
+	*(map->key) = (uint64_t)mr_map;
+
+	return 0;
+}
+
+static int mrail_domain_unmap_key(struct mrail_addr_key **mr_map)
+{
+	assert(mr_map);
+	free(*mr_map);
+	return 0;
+}
+
+static int mrail_domain_control(struct fid *fid, int command, void *arg)
+{
+	struct mrail_domain *mrail_domain = container_of(fid,
+			struct mrail_domain, util_domain.domain_fid.fid);
+
+	switch(command) {
+	case FI_MAP_RAW_MR:
+		return mrail_domain_map_raw(mrail_domain, arg);
+	case FI_UNMAP_KEY:
+		return mrail_domain_unmap_key(arg);
+	}
+	return -FI_EINVAL;
+}
+
+static struct fi_ops mrail_domain_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = mrail_domain_close,
+	.bind = fi_no_bind,
+	.control = mrail_domain_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static int mrail_mr_close(fid_t fid)
+{
+	uint32_t i;
+	struct mrail_mr *mrail_mr = container_of(fid, struct mrail_mr,
+			mr_fid.fid);
+
+	for (i = 0; i < mrail_mr->num_mrs; ++i) {
+		fi_close(&mrail_mr->rails[i].mr->fid);
+	}
+	return 0;
+}
+
+static int mrail_mr_raw_attr(struct mrail_mr *mrail_mr,
+                             struct fi_mr_raw_attr *attr)
+{
+	uint32_t num_rails;
+	uint32_t i;
+	struct mrail_addr_key *rail;
+	size_t required_key_size;
+
+	num_rails = mrail_mr->num_mrs;
+
+	required_key_size = num_rails * sizeof(struct mrail_addr_key);
+
+	if (*(attr->key_size) < required_key_size) {
+		*(attr->key_size) = required_key_size;
+		return -FI_ETOOSMALL;
+	}
+
+	/* The raw key is the concatenation of one "struct mrail_addr_key" per
+	 * rail. */
+	for (i = 0, rail = (struct mrail_addr_key*)attr->raw_key; i < num_rails;
+			++i, ++rail) {
+		rail->base_addr = mrail_mr->rails[i].base_addr;
+		rail->key	= fi_mr_key(mrail_mr->rails[i].mr);
+	}
+
+	*(attr->key_size) = required_key_size;
+	*(attr->base_addr) = 0;
+
+	return 0;
+}
+
+static int mrail_mr_control(struct fid *fid, int command, void *arg)
+{
+	struct mrail_mr *mrail_mr = container_of(fid, struct mrail_mr,
+			mr_fid.fid);
+
+	switch(command) {
+	case FI_GET_RAW_MR:
+		return mrail_mr_raw_attr(mrail_mr, arg);
+	}
+	return -FI_EINVAL;
+}
+
+static struct fi_ops mrail_mr_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = mrail_mr_close,
+	.bind = fi_no_bind,
+	.control = mrail_mr_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static int mrail_mr_reg(struct fid *domain_fid, const void *buf, size_t len,
+			 uint64_t access, uint64_t offset, uint64_t requested_key,
+			 uint64_t flags, struct fid_mr **mr, void *context)
+{
+	struct mrail_domain *mrail_domain = container_of(domain_fid,
+			struct mrail_domain, util_domain.domain_fid.fid);
+	size_t num_rails = mrail_domain->num_domains;
+	struct mrail_mr *mrail_mr;
+	struct fi_info *fi;
+	uint32_t rail;
+	int ret = 0;
+
+	mrail_mr = calloc(1, sizeof(*mrail_mr) +
+			num_rails * sizeof(*mrail_mr->rails));
+	if (!mrail_mr) {
+		return -FI_ENOMEM;
+	}
+
+	for (rail = 0, fi = mrail_domain->info->next;
+			rail < mrail_domain->num_domains;
+			++rail, fi = fi->next) {
+		ret = fi_mr_reg(mrail_domain->domains[rail], buf, len, access,
+				offset, requested_key, flags,
+				&mrail_mr->rails[rail].mr, context);
+		if (ret) {
+			FI_WARN(&mrail_prov, FI_LOG_DOMAIN,
+				"Unable to register memory, rail %" PRIu32 "\n",
+				rail);
+			goto err1;
+		}
+		mrail_mr->rails[rail].base_addr =
+			(fi->domain_attr->mr_mode & FI_MR_VIRT_ADDR ?
+			 (uint64_t)buf : 0);
+	}
+
+	mrail_mr->mr_fid.fid.fclass = FI_CLASS_MR;
+	mrail_mr->mr_fid.fid.context = context;
+	mrail_mr->mr_fid.fid.ops = &mrail_mr_ops;
+	mrail_mr->mr_fid.mem_desc = mrail_mr;
+	mrail_mr->mr_fid.key = FI_KEY_NOTAVAIL;
+	mrail_mr->num_mrs = mrail_domain->num_domains;
+	*mr = &mrail_mr->mr_fid;
+
+	return 0;
+err1:
+	for (; rail != 0; --rail) {
+		fi_close(&mrail_mr->rails[rail].mr->fid);
+	}
+	free(mrail_mr);
+	return ret;
+}
+
+static struct fi_ops_mr mrail_domain_mr_ops = {
+	.size = sizeof(struct fi_ops_mr),
+	.reg = mrail_mr_reg,
+	.regv = fi_no_mr_regv,
+	.regattr = fi_no_mr_regattr,
+};
+
+int mrail_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
+		struct fid_cntr **cntr_fid, void *context)
+{
+	int ret;
+	struct util_cntr *cntr;
+
+	cntr = calloc(1, sizeof(*cntr));
+	if (!cntr)
+		return -FI_ENOMEM;
+
+	ret = ofi_cntr_init(&mrail_prov, domain, attr, cntr,
+			&ofi_cntr_progress, context);
+	if (ret)
+		goto error;
+
+	*cntr_fid = &cntr->cntr_fid;
+	return FI_SUCCESS;
+
+error:
+	free(cntr);
+	return ret;
+}
+
+static struct fi_ops_domain mrail_domain_ops = {
+	.size = sizeof(struct fi_ops_domain),
+	.av_open = mrail_av_open,
+	.cq_open = mrail_cq_open,
+	.endpoint = mrail_ep_open,
+	.scalable_ep = fi_no_scalable_ep,
+	.cntr_open = mrail_cntr_open,
+	.poll_open = fi_no_poll_open,
+	.stx_ctx = fi_no_stx_context,
+	.srx_ctx = fi_no_srx_context,
+	.query_atomic = fi_no_query_atomic,
+};
+
+int mrail_domain_open(struct fid_fabric *fabric, struct fi_info *info,
+		      struct fid_domain **domain, void *context)
+{
+	struct mrail_fabric *mrail_fabric =
+		container_of(fabric, struct mrail_fabric, util_fabric.fabric_fid);
+	struct mrail_domain *mrail_domain;
+	struct fi_info *fi;
+	size_t i;
+	int ret;
+
+	assert(!strcmp(mrail_fabric->info->fabric_attr->name, info->fabric_attr->name));
+
+	mrail_domain = calloc(1, sizeof(*mrail_domain));
+	if (!mrail_domain)
+		return -FI_ENOMEM;
+
+	ret = ofi_domain_init(fabric, info, &mrail_domain->util_domain, context);
+	if (ret) {
+		free(mrail_domain);
+		return ret;
+	}
+
+	mrail_domain->info = mrail_fabric->info;
+	mrail_domain->num_domains = mrail_fabric->num_fabrics;
+
+	mrail_domain->domains = calloc(mrail_domain->num_domains,
+				       sizeof(*mrail_domain->domains));
+	if (!mrail_domain->domains) {
+		ret = -FI_ENOMEM;
+		goto err;
+	}
+
+	for (i = 0, fi = mrail_domain->info->next; fi; fi = fi->next, i++) {
+		ret = fi_domain(mrail_fabric->fabrics[i], fi,
+				&mrail_domain->domains[i], context);
+		if (ret)
+			goto err;
+
+		mrail_domain->addrlen += fi->src_addrlen;
+	}
+
+	*domain = &mrail_domain->util_domain.domain_fid;
+	(*domain)->fid.ops = &mrail_domain_fi_ops;
+	(*domain)->mr = &mrail_domain_mr_ops;
+	(*domain)->ops = &mrail_domain_ops;
+
+	return 0;
+err:
+	mrail_domain_close(&mrail_domain->util_domain.domain_fid.fid);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_ep.c
new file mode 100644
index 000000000..eae9da40b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_ep.c
@@ -0,0 +1,960 @@
+/*
+ * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <ofi_iov.h>
+
+#include "mrail.h"
+
+#define MRAIL_HDR_INITIALIZER(op_type, tag_val)		\
+{							\
+	.version 	= MRAIL_HDR_VERSION,		\
+	.op		= op_type,			\
+	.tag		= tag_val,			\
+}
+
+#define MRAIL_HDR_INITIALIZER_MSG MRAIL_HDR_INITIALIZER(ofi_op_msg, 0)
+
+#define MRAIL_HDR_INITIALIZER_TAGGED(tag) \
+	MRAIL_HDR_INITIALIZER(ofi_op_tagged, tag)
+
+#define mrail_util_ep(ep_fid) \
+	container_of(ep_fid, struct util_ep, ep_fid.fid)
+
+#define mrail_comp_flag(ep_fid) \
+	(mrail_util_ep(ep_fid)->tx_op_flags & FI_COMPLETION)
+
+#define mrail_inject_flags(ep_fid) \
+	((mrail_util_ep(ep_fid)->tx_op_flags & ~FI_COMPLETION) | FI_INJECT)
+
+static int mrail_match_recv_any(struct dlist_entry *item, const void *arg)
+{
+	OFI_UNUSED(item);
+	OFI_UNUSED(arg);
+	return 1;
+}
+
+static int mrail_match_recv_addr(struct dlist_entry *item, const void *arg)
+{
+	struct mrail_match_attr *match_attr = (struct mrail_match_attr *)arg;
+	struct mrail_recv *recv =
+		container_of(item, struct mrail_recv, entry);
+
+	return ofi_match_addr(recv->addr, match_attr->addr);
+}
+
+static int mrail_match_recv_tag(struct dlist_entry *item, const void *arg)
+{
+	struct mrail_match_attr *match_attr = (struct mrail_match_attr *)arg;
+	struct mrail_recv *recv =
+		container_of(item, struct mrail_recv, entry);
+
+	return ofi_match_tag(recv->tag, recv->ignore, match_attr->tag);
+}
+
+static int mrail_match_recv_addr_tag(struct dlist_entry *item, const void *arg)
+{
+	struct mrail_match_attr *match_attr = (struct mrail_match_attr *)arg;
+	struct mrail_recv *recv =
+		container_of(item, struct mrail_recv, entry);
+
+	return ofi_match_addr(recv->addr, match_attr->addr) &&
+		ofi_match_tag(recv->tag, recv->ignore, match_attr->tag);
+}
+
+static int mrail_match_unexp_any(struct dlist_entry *item, const void *arg)
+{
+	OFI_UNUSED(item);
+	OFI_UNUSED(arg);
+	return 1;
+}
+
+static int mrail_match_unexp_addr(struct dlist_entry *item, const void *arg)
+{
+	struct mrail_recv *recv = (struct mrail_recv *)arg;
+	struct mrail_unexp_msg_entry *unexp_msg_entry =
+		container_of(item, struct mrail_unexp_msg_entry, entry);
+
+	return ofi_match_addr(unexp_msg_entry->addr, recv->addr);
+}
+
+static int mrail_match_unexp_tag(struct dlist_entry *item, const void *arg)
+{
+	struct mrail_recv *recv = (struct mrail_recv *)arg;
+	struct mrail_unexp_msg_entry *unexp_msg_entry =
+		container_of(item, struct mrail_unexp_msg_entry, entry);
+
+	return ofi_match_tag(recv->tag, recv->ignore, unexp_msg_entry->tag);
+}
+
+static int mrail_match_unexp_addr_tag(struct dlist_entry *item, const void *arg)
+{
+	struct mrail_recv *recv = (struct mrail_recv *)arg;
+	struct mrail_unexp_msg_entry *unexp_msg_entry =
+		container_of(item, struct mrail_unexp_msg_entry, entry);
+
+	return ofi_match_addr(recv->addr, unexp_msg_entry->addr) &&
+		ofi_match_tag(recv->tag, recv->ignore, unexp_msg_entry->tag);
+}
+
+int mrail_reprocess_directed_recvs(struct mrail_recv_queue *recv_queue)
+{
+	// TODO
+	return -FI_ENOSYS;
+}
+
+struct mrail_recv *
+mrail_match_recv_handle_unexp(struct mrail_recv_queue *recv_queue, uint64_t tag,
+			      uint64_t addr, char *data, size_t len, void *context)
+{
+	struct dlist_entry *entry;
+	struct mrail_unexp_msg_entry *unexp_msg_entry;
+	struct mrail_match_attr match_attr = {
+		.tag	= tag,
+		.addr	= addr,
+	};
+
+	entry = dlist_remove_first_match(&recv_queue->recv_list,
+					 recv_queue->match_recv, &match_attr);
+	if (OFI_UNLIKELY(!entry)) {
+		unexp_msg_entry = recv_queue->get_unexp_msg_entry(recv_queue,
+								  context);
+		if (!unexp_msg_entry) {
+			FI_WARN(recv_queue->prov, FI_LOG_CQ,
+				"Unable to get unexp_msg_entry!");
+			assert(0);
+			return NULL;
+		}
+
+		unexp_msg_entry->addr		= addr;
+		unexp_msg_entry->tag		= tag;
+		unexp_msg_entry->context	= context;
+		memcpy(unexp_msg_entry->data, data, len);
+
+		FI_DBG(recv_queue->prov, FI_LOG_CQ, "No matching recv found for"
+		       " incoming msg with addr: 0x%" PRIx64 " tag: 0x%" PRIx64
+		       "\n", unexp_msg_entry->addr, unexp_msg_entry->tag);
+
+		FI_DBG(recv_queue->prov, FI_LOG_CQ, "Enqueueing unexp_msg_entry to "
+		       "unexpected msg list\n");
+
+		dlist_insert_tail(&unexp_msg_entry->entry,
+				  &recv_queue->unexp_msg_list);
+		return NULL;
+	}
+	return container_of(entry, struct mrail_recv, entry);
+}
+
+static void mrail_init_recv(struct mrail_recv *recv, void *arg)
+{
+	recv->ep		= arg;
+	recv->iov[0].iov_base 	= &recv->hdr;
+	recv->iov[0].iov_len 	= sizeof(recv->hdr);
+	recv->comp_flags	= FI_RECV;
+}
+
+#define mrail_recv_assert(recv)						\
+({									\
+	assert(recv->ep == mrail_ep);					\
+	assert(recv->iov[0].iov_base == &recv->hdr);			\
+	assert(recv->iov[0].iov_len == sizeof(recv->hdr));		\
+	assert(recv->comp_flags & FI_RECV);				\
+	assert(recv->count <= mrail_ep->info->rx_attr->iov_limit + 1);	\
+})
+
+static void mrail_recv_queue_init(struct fi_provider *prov,
+				  struct mrail_recv_queue *recv_queue,
+				  dlist_func_t match_recv,
+				  dlist_func_t match_unexp,
+				  mrail_get_unexp_msg_entry_func get_unexp_msg_entry)
+{
+	recv_queue->prov = prov;
+	dlist_init(&recv_queue->recv_list);
+	dlist_init(&recv_queue->unexp_msg_list);
+	recv_queue->match_recv = match_recv;
+	recv_queue->match_unexp = match_unexp;
+	recv_queue->get_unexp_msg_entry = get_unexp_msg_entry;
+}
+
+// TODO go for separate recv functions (recvmsg, recvv, etc) to be optimal
+static ssize_t
+mrail_recv_common(struct mrail_ep *mrail_ep, struct mrail_recv_queue *recv_queue,
+		  struct iovec *iov, size_t count, void *context,
+		  fi_addr_t src_addr, uint64_t tag, uint64_t ignore,
+		  uint64_t flags, uint64_t comp_flags)
+{
+	struct mrail_recv *recv;
+	struct mrail_unexp_msg_entry *unexp_msg_entry;
+
+	recv = mrail_pop_recv(mrail_ep);
+	if (!recv)
+		return -FI_EAGAIN;
+
+	recv->count 		= count + 1;
+	recv->context 		= context;
+	recv->flags 		= flags;
+	recv->comp_flags 	|= comp_flags;
+	recv->addr	 	= src_addr;
+	recv->tag 		= tag;
+	recv->ignore 		= ignore;
+
+	memcpy(&recv->iov[1], iov, sizeof(*iov) * count);
+
+	FI_DBG(&mrail_prov, FI_LOG_EP_DATA, "Posting recv of length: %zu "
+	       "src_addr: 0x%" PRIx64 " tag: 0x%" PRIx64 " ignore: 0x%" PRIx64
+	       "\n", ofi_total_iov_len(iov, count), recv->addr,
+	       recv->tag, recv->ignore);
+
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	unexp_msg_entry = container_of(dlist_remove_first_match(
+						&recv_queue->unexp_msg_list,
+						recv_queue->match_unexp,
+						recv),
+				       struct mrail_unexp_msg_entry,
+				       entry);
+	if (!unexp_msg_entry) {
+		dlist_insert_tail(&recv->entry, &recv_queue->recv_list);
+		ofi_ep_lock_release(&mrail_ep->util_ep);
+		return 0;
+	}
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+
+	FI_DBG(recv_queue->prov, FI_LOG_EP_DATA, "Match for posted recv"
+	       " with addr: 0x%" PRIx64 ", tag: 0x%" PRIx64 " ignore: "
+	       "0x%" PRIx64 " found in unexpected msg queue\n",
+	       recv->addr, recv->tag, recv->ignore);
+
+	return mrail_cq_process_buf_recv((struct fi_cq_tagged_entry *)
+					 unexp_msg_entry->data, recv);
+}
+
+static ssize_t mrail_recv(struct fid_ep *ep_fid, void *buf, size_t len,
+			  void *desc, fi_addr_t src_addr, void *context)
+{
+	struct mrail_ep *mrail_ep = container_of(ep_fid, struct mrail_ep,
+					     util_ep.ep_fid.fid);
+	struct iovec iov = {
+		.iov_base	= buf,
+		.iov_len	= len,
+	};
+	return mrail_recv_common(mrail_ep, &mrail_ep->recv_queue, &iov,
+				 1, context, src_addr, 0, 0,
+				 mrail_ep->util_ep.rx_op_flags, FI_MSG);
+}
+
+static ssize_t mrail_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+		uint64_t flags)
+{
+	struct mrail_ep *mrail_ep = container_of(ep_fid, struct mrail_ep,
+					     util_ep.ep_fid.fid);
+
+	return mrail_recv_common(mrail_ep, &mrail_ep->recv_queue,
+				 (struct iovec *)msg->msg_iov, msg->iov_count,
+				 msg->context, msg->addr, 0, 0, flags, FI_MSG);
+}
+
+static ssize_t mrail_trecv(struct fid_ep *ep_fid, void *buf, size_t len,
+			    void *desc, fi_addr_t src_addr, uint64_t tag,
+			    uint64_t ignore, void *context)
+{
+	struct mrail_ep *mrail_ep = container_of(ep_fid, struct mrail_ep,
+					     util_ep.ep_fid.fid);
+	struct iovec iov = {
+		.iov_base	= buf,
+		.iov_len	= len,
+	};
+	return mrail_recv_common(mrail_ep, &mrail_ep->trecv_queue, &iov,
+				 1, context, src_addr, tag, ignore,
+				 mrail_ep->util_ep.rx_op_flags, FI_TAGGED);
+}
+
+static ssize_t mrail_trecvmsg(struct fid_ep *ep_fid,
+				const struct fi_msg_tagged *msg,
+				uint64_t flags)
+{
+	struct mrail_ep *mrail_ep = container_of(ep_fid, struct mrail_ep,
+					     util_ep.ep_fid.fid);
+
+	return mrail_recv_common(mrail_ep, &mrail_ep->trecv_queue,
+				 (struct iovec *)msg->msg_iov, msg->iov_count,
+				 msg->context, msg->addr, msg->tag,
+				 msg->ignore,
+				 (mrail_ep->util_ep.rx_op_flags | flags),
+				 FI_TAGGED);
+}
+
+static void mrail_copy_iov_hdr(struct mrail_hdr *hdr, struct iovec *iov_dest,
+			       const struct iovec *iov_src, size_t count)
+{
+	iov_dest[0].iov_base = hdr;
+	iov_dest[0].iov_len = sizeof(*hdr);
+	memcpy(&iov_dest[1], iov_src, sizeof(*iov_src) * count);
+}
+
+static struct mrail_tx_buf *mrail_get_tx_buf(struct mrail_ep *mrail_ep,
+					     void *context, uint32_t seq,
+					     uint8_t op, uint64_t flags)
+{
+	struct mrail_tx_buf *tx_buf = util_buf_alloc(mrail_ep->tx_buf_pool);
+	if (OFI_UNLIKELY(!tx_buf))
+		return NULL;
+
+	assert(tx_buf->ep == mrail_ep);
+	assert(tx_buf->hdr.version == MRAIL_HDR_VERSION);
+
+	tx_buf->context		= context;
+	tx_buf->flags		= flags;
+	tx_buf->hdr.op		= op;
+	tx_buf->hdr.seq		= htonl(seq);
+	return tx_buf;
+}
+
+static ssize_t
+mrail_send_common(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		  size_t count, size_t len, fi_addr_t dest_addr, uint64_t data,
+		  void *context, uint64_t flags)
+{
+	struct mrail_ep *mrail_ep = container_of(ep_fid, struct mrail_ep,
+						 util_ep.ep_fid.fid);
+	struct mrail_peer_info *peer_info;
+	struct iovec *iov_dest = alloca(sizeof(*iov_dest) * (count + 1));
+	struct mrail_tx_buf *tx_buf;
+	uint32_t i = mrail_get_tx_rail(mrail_ep);
+	struct fi_msg msg;
+	ssize_t ret;
+
+	peer_info = ofi_av_get_addr(mrail_ep->util_ep.av, (int) dest_addr);
+
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+
+	tx_buf = mrail_get_tx_buf(mrail_ep, context, peer_info->seq_no++,
+				  ofi_op_msg, flags | FI_MSG);
+	if (OFI_UNLIKELY(!tx_buf)) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+	mrail_copy_iov_hdr(&tx_buf->hdr, iov_dest, iov, count);
+
+	msg.msg_iov 	= iov_dest;
+	msg.desc    	= desc;
+	msg.iov_count	= count + 1;
+	msg.addr	= dest_addr;
+	msg.context	= tx_buf;
+	msg.data	= data;
+
+	if (len < mrail_ep->rails[i].info->tx_attr->inject_size)
+		flags |= FI_INJECT;
+
+	FI_DBG(&mrail_prov, FI_LOG_EP_DATA, "Posting send of length: %" PRIu64
+	       " dest_addr: 0x%" PRIx64 "  seq: %d on rail: %d\n",
+	       len, dest_addr, peer_info->seq_no - 1, i);
+
+	ret = fi_sendmsg(mrail_ep->rails[i].ep, &msg, flags);
+	if (ret) {
+		FI_WARN(&mrail_prov, FI_LOG_EP_DATA,
+			"Unable to fi_sendmsg on rail: %" PRIu32 "\n", i);
+		goto err2;
+	} else if (!(flags & FI_COMPLETION)) {
+		ofi_ep_tx_cntr_inc(&mrail_ep->util_ep);
+	}
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+	return ret;
+err2:
+	util_buf_release(mrail_ep->tx_buf_pool, tx_buf);
+err1:
+	peer_info->seq_no--;
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+	return ret;
+}
+
+static ssize_t
+mrail_tsend_common(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		   size_t count, size_t len, fi_addr_t dest_addr, uint64_t tag,
+		   uint64_t data, void *context, uint64_t flags)
+{
+	struct mrail_ep *mrail_ep = container_of(ep_fid, struct mrail_ep,
+						 util_ep.ep_fid.fid);
+	struct mrail_peer_info *peer_info;
+	struct iovec *iov_dest = alloca(sizeof(*iov_dest) * (count + 1));
+	struct mrail_tx_buf *tx_buf;
+	uint32_t i = mrail_get_tx_rail(mrail_ep);
+	struct fi_msg msg;
+	ssize_t ret;
+
+	peer_info = ofi_av_get_addr(mrail_ep->util_ep.av, (int) dest_addr);
+
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+
+	tx_buf = mrail_get_tx_buf(mrail_ep, context, peer_info->seq_no++,
+				  ofi_op_tagged, flags | FI_TAGGED);
+	if (OFI_UNLIKELY(!tx_buf)) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+	tx_buf->hdr.tag = tag;
+	mrail_copy_iov_hdr(&tx_buf->hdr, iov_dest, iov, count);
+
+	msg.msg_iov 	= iov_dest;
+	msg.desc    	= desc;
+	msg.iov_count	= count + 1;
+	msg.addr	= dest_addr;
+	msg.context	= tx_buf;
+	msg.data	= data;
+
+	if (len < mrail_ep->rails[i].info->tx_attr->inject_size)
+		flags |= FI_INJECT;
+
+	FI_DBG(&mrail_prov, FI_LOG_EP_DATA, "Posting tsend of length: %" PRIu64
+	       " dest_addr: 0x%" PRIx64 " tag: 0x%" PRIx64 " seq: %d"
+	       " on rail: %d\n", len, dest_addr, tag, peer_info->seq_no - 1, i);
+
+	ret = fi_sendmsg(mrail_ep->rails[i].ep, &msg, flags);
+	if (ret) {
+		FI_WARN(&mrail_prov, FI_LOG_EP_DATA,
+			"Unable to fi_sendmsg on rail: %" PRIu32 "\n", i);
+		goto err2;
+	} else if (!(flags & FI_COMPLETION)) {
+		ofi_ep_tx_cntr_inc(&mrail_ep->util_ep);
+	}
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+	return ret;
+err2:
+	util_buf_release(mrail_ep->tx_buf_pool, tx_buf);
+err1:
+	peer_info->seq_no--;
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+	return ret;
+}
+
+static ssize_t mrail_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+			     uint64_t flags)
+{
+	return mrail_send_common(ep_fid, msg->msg_iov, msg->desc, msg->iov_count,
+				 ofi_total_iov_len(msg->msg_iov, msg->iov_count),
+				 msg->addr, msg->data, msg->context,
+				 flags | mrail_comp_flag(ep_fid));
+}
+
+static ssize_t mrail_send(struct fid_ep *ep_fid, const void *buf, size_t len,
+			  void *desc, fi_addr_t dest_addr, void *context)
+{
+	struct iovec iov = {
+		.iov_base 	= (void *)buf,
+		.iov_len 	= len,
+	};
+	return mrail_send_common(ep_fid, &iov, &desc, 1, len, dest_addr, 0,
+				 context, mrail_comp_flag(ep_fid));
+}
+
+static ssize_t mrail_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
+			    fi_addr_t dest_addr)
+{
+	struct iovec iov = {
+		.iov_base 	= (void *)buf,
+		.iov_len 	= len,
+	};
+	return mrail_send_common(ep_fid, &iov, NULL, 1, len, dest_addr, 0,
+				 NULL, mrail_inject_flags(ep_fid));
+}
+
+static ssize_t mrail_injectdata(struct fid_ep *ep_fid, const void *buf,
+				size_t len, uint64_t data, fi_addr_t dest_addr)
+{
+	struct iovec iov = {
+		.iov_base 	= (void *)buf,
+		.iov_len 	= len,
+	};
+	return mrail_send_common(ep_fid, &iov, NULL, 1, len, dest_addr, data,
+				 NULL, (mrail_inject_flags(ep_fid) |
+					FI_REMOTE_CQ_DATA));
+}
+
+static ssize_t
+mrail_tsendmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *msg,
+	       uint64_t flags)
+{
+	return mrail_tsend_common(ep_fid, msg->msg_iov, msg->desc, msg->iov_count,
+				  ofi_total_iov_len(msg->msg_iov, msg->iov_count),
+				  msg->addr, msg->tag, msg->data, msg->context,
+				  flags | mrail_comp_flag(ep_fid));
+}
+
+static ssize_t mrail_tsend(struct fid_ep *ep_fid, const void *buf, size_t len,
+			   void *desc, fi_addr_t dest_addr, uint64_t tag,
+			   void *context)
+{
+	struct iovec iov = {
+		.iov_base 	= (void *)buf,
+		.iov_len 	= len,
+	};
+	return mrail_tsend_common(ep_fid, &iov, &desc, 1, len, dest_addr, tag,
+				  0, context, mrail_comp_flag(ep_fid));
+}
+
+static ssize_t mrail_tsenddata(struct fid_ep *ep_fid, const void *buf, size_t len,
+			       void *desc, uint64_t data, fi_addr_t dest_addr,
+			       uint64_t tag, void *context)
+{
+	struct iovec iov = {
+		.iov_base 	= (void *)buf,
+		.iov_len 	= len,
+	};
+	return mrail_tsend_common(ep_fid, &iov, &desc, 1, len, dest_addr, tag,
+				  data, context, (mrail_comp_flag(ep_fid) |
+						  FI_REMOTE_CQ_DATA));
+}
+
+static ssize_t mrail_tinject(struct fid_ep *ep_fid, const void *buf, size_t len,
+			     fi_addr_t dest_addr, uint64_t tag)
+{
+	struct iovec iov = {
+		.iov_base 	= (void *)buf,
+		.iov_len 	= len,
+	};
+	return mrail_tsend_common(ep_fid, &iov, NULL, 1, len, dest_addr, tag,
+				  0, NULL, mrail_inject_flags(ep_fid));
+}
+
+static ssize_t mrail_tinjectdata(struct fid_ep *ep_fid, const void *buf,
+				 size_t len, uint64_t data, fi_addr_t dest_addr,
+				 uint64_t tag)
+{
+	struct iovec iov = {
+		.iov_base 	= (void *)buf,
+		.iov_len 	= len,
+	};
+	return mrail_tsend_common(ep_fid, &iov, NULL, 1, len, dest_addr, tag,
+				  data, NULL, (mrail_inject_flags(ep_fid) |
+					       FI_REMOTE_CQ_DATA));
+}
+
+static struct mrail_unexp_msg_entry *
+mrail_get_unexp_msg_entry(struct mrail_recv_queue *recv_queue, void *context)
+{
+	// TODO use buf pool
+	// context would be mrail_ep from which u can get the buf pool
+	struct mrail_unexp_msg_entry *unexp_msg_entry =
+		malloc(sizeof(*unexp_msg_entry) + sizeof(struct fi_cq_tagged_entry));
+	return unexp_msg_entry;
+}
+
+static int mrail_getname(fid_t fid, void *addr, size_t *addrlen)
+{
+	struct mrail_ep *mrail_ep =
+		container_of(fid, struct mrail_ep, util_ep.ep_fid.fid);
+	struct mrail_domain *mrail_domain =
+		container_of(mrail_ep->util_ep.domain, struct mrail_domain,
+			     util_domain);
+	size_t i, offset = 0, rail_addrlen;
+	int ret;
+
+	if (*addrlen < mrail_domain->addrlen)
+		return -FI_ETOOSMALL;
+
+	for (i = 0; i < mrail_ep->num_eps; i++) {
+		rail_addrlen = *addrlen - offset;
+		ret = fi_getname(&mrail_ep->rails[i].ep->fid,
+				 (char *)addr + offset, &rail_addrlen);
+		if (ret) {
+			FI_WARN(&mrail_prov, FI_LOG_EP_CTRL,
+				"Unable to get name for rail: %zd\n", i);
+			return ret;
+		}
+		offset += rail_addrlen;
+	}
+	return 0;
+}
+
+
+static void mrail_tx_buf_init(void *pool_ctx, void *buf)
+{
+	struct mrail_ep *mrail_ep = pool_ctx;
+	struct mrail_tx_buf *tx_buf = buf;
+
+	tx_buf->ep		= mrail_ep;
+	tx_buf->hdr.version	= MRAIL_HDR_VERSION;
+}
+
+static void mrail_ep_free_bufs(struct mrail_ep *mrail_ep)
+{
+	if (mrail_ep->req_pool)
+		util_buf_pool_destroy(mrail_ep->req_pool);
+
+	if (mrail_ep->ooo_recv_pool)
+		util_buf_pool_destroy(mrail_ep->ooo_recv_pool);
+
+	if (mrail_ep->tx_buf_pool)
+		util_buf_pool_destroy(mrail_ep->tx_buf_pool);
+
+	if (mrail_ep->recv_fs)
+		mrail_recv_fs_free(mrail_ep->recv_fs);
+}
+
+static int mrail_ep_alloc_bufs(struct mrail_ep *mrail_ep)
+{
+	struct util_buf_attr attr = {
+		.size		= sizeof(struct mrail_tx_buf),
+		.alignment	= sizeof(void *),
+		.max_cnt	= 0,
+		.chunk_cnt	= 64,
+		.alloc_hndlr	= NULL,
+		.free_hndlr	= NULL,
+		.init		= mrail_tx_buf_init,
+		.ctx		= mrail_ep,
+	};
+	size_t buf_size, rxq_total_size = 0;
+	struct fi_info *fi;
+	int ret;
+
+	for (fi = mrail_ep->info->next; fi; fi = fi->next)
+		rxq_total_size += fi->rx_attr->size;
+
+	mrail_ep->recv_fs = mrail_recv_fs_create(rxq_total_size, mrail_init_recv,
+						 mrail_ep);
+	if (!mrail_ep->recv_fs)
+		return -FI_ENOMEM;
+
+	ret = util_buf_pool_create(&mrail_ep->ooo_recv_pool,
+				   sizeof(struct mrail_ooo_recv),
+				   sizeof(void *), 0, 64);
+	if (!mrail_ep->ooo_recv_pool)
+		goto err;
+
+	ret = util_buf_pool_create_attr(&attr, &mrail_ep->tx_buf_pool);
+	if (!mrail_ep->tx_buf_pool)
+		goto err;
+
+	buf_size = (sizeof(struct mrail_req) +
+		    (mrail_ep->num_eps * sizeof(struct mrail_subreq)));
+
+	ret = util_buf_pool_create(&mrail_ep->req_pool, buf_size,
+				   sizeof(void *), 0, 64);
+	if (ret)
+		goto err;
+	return 0;
+err:
+	mrail_ep_free_bufs(mrail_ep);
+	return ret;
+}
+
+static int mrail_ep_close(fid_t fid)
+{
+	struct mrail_ep *mrail_ep =
+		container_of(fid, struct mrail_ep, util_ep.ep_fid.fid);
+	int ret, retv = 0;
+	size_t i;
+
+	mrail_ep_free_bufs(mrail_ep);
+
+	for (i = 0; i < mrail_ep->num_eps; i++) {
+		ret = fi_close(&mrail_ep->rails[i].ep->fid);
+		if (ret)
+			retv = ret;
+	}
+	free(mrail_ep->rails);
+
+	ret = ofi_endpoint_close(&mrail_ep->util_ep);
+	if (ret)
+		retv = ret;
+	free(mrail_ep);
+	return retv;
+}
+
+static int mrail_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
+{
+	struct mrail_ep *mrail_ep =
+		container_of(ep_fid, struct mrail_ep, util_ep.ep_fid.fid);
+	struct mrail_cq *mrail_cq;
+	struct mrail_av *mrail_av;
+	struct util_cntr *cntr;
+	int ret = 0;
+	size_t i;
+
+	switch (bfid->fclass) {
+	case FI_CLASS_AV:
+		mrail_av = container_of(bfid, struct mrail_av,
+					util_av.av_fid.fid);
+		ret = ofi_ep_bind_av(&mrail_ep->util_ep, &mrail_av->util_av);
+		if (ret)
+			return ret;
+		for (i = 0; i < mrail_ep->num_eps; i++) {
+			ret = fi_ep_bind(mrail_ep->rails[i].ep,
+					 &mrail_av->avs[i]->fid, flags);
+			if (ret)
+				return ret;
+		}
+		break;
+	case FI_CLASS_CQ:
+		mrail_cq = container_of(bfid, struct mrail_cq,
+					util_cq.cq_fid.fid);
+
+		ret = ofi_ep_bind_cq(&mrail_ep->util_ep, &mrail_cq->util_cq,
+				     flags);
+		if (ret)
+			return ret;
+		for (i = 0; i < mrail_ep->num_eps; i++) {
+			ret = fi_ep_bind(mrail_ep->rails[i].ep,
+					 &mrail_cq->cqs[i]->fid, flags);
+			if (ret)
+				return ret;
+		}
+		break;
+	case FI_CLASS_CNTR:
+		cntr = container_of(bfid, struct util_cntr, cntr_fid.fid);
+
+		ret = ofi_ep_bind_cntr(&mrail_ep->util_ep, cntr, flags);
+		if (ret)
+			return ret;
+		break;
+	case FI_CLASS_EQ:
+		ret = -FI_ENOSYS;
+		break;
+	default:
+		FI_WARN(&mrail_prov, FI_LOG_EP_CTRL, "invalid fid class\n");
+		ret = -FI_EINVAL;
+		break;
+	}
+	return ret;
+}
+
+static int mrail_ep_ctrl(struct fid *fid, int command, void *arg)
+{
+	struct mrail_ep *mrail_ep;
+	size_t i, buf_recv_min = sizeof(struct mrail_hdr);
+	int ret;
+
+	mrail_ep = container_of(fid, struct mrail_ep, util_ep.ep_fid.fid);
+
+	switch (command) {
+	case FI_ENABLE:
+		if (!mrail_ep->util_ep.rx_cq || !mrail_ep->util_ep.tx_cq)
+			return -FI_ENOCQ;
+		if (!mrail_ep->util_ep.av)
+			return -FI_ENOAV;
+		for (i = 0; i < mrail_ep->num_eps; i++) {
+			ret = fi_setopt(&mrail_ep->rails[i].ep->fid,
+					FI_OPT_ENDPOINT, FI_OPT_BUFFERED_MIN,
+					&buf_recv_min, sizeof(buf_recv_min));
+			if (ret)
+				return ret;
+
+			ret = fi_enable(mrail_ep->rails[i].ep);
+			if (ret)
+				return ret;
+		}
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+	return 0;
+}
+
+static struct fi_ops mrail_ep_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = mrail_ep_close,
+	.bind = mrail_ep_bind,
+	.control = mrail_ep_ctrl,
+	.ops_open = fi_no_ops_open,
+};
+
+static int mrail_ep_setopt(fid_t fid, int level, int optname,
+		const void *optval, size_t optlen)
+{
+	struct mrail_ep *mrail_ep;
+	size_t i;
+	int ret = 0;
+
+	mrail_ep = container_of(fid, struct mrail_ep, util_ep.ep_fid.fid);
+
+	for (i = 0; i < mrail_ep->num_eps; i++) {
+		ret = fi_setopt(&mrail_ep->rails[i].ep->fid, level, optname,
+				optval, optlen);
+		if (ret)
+			return ret;
+	}
+
+	return ret;
+}
+
+static struct fi_ops_ep mrail_ops_ep = {
+	.size = sizeof(struct fi_ops_ep),
+	.cancel = fi_no_cancel,
+	.getopt = fi_no_getopt,
+	.setopt = mrail_ep_setopt,
+	.tx_ctx = fi_no_tx_ctx,
+	.rx_ctx = fi_no_rx_ctx,
+	.rx_size_left = fi_no_rx_size_left,
+	.tx_size_left = fi_no_tx_size_left,
+};
+
+static struct fi_ops_cm mrail_ops_cm = {
+	.size = sizeof(struct fi_ops_cm),
+	.setname = fi_no_setname,
+	.getname = mrail_getname,
+	.getpeer = fi_no_getpeer,
+	.connect = fi_no_connect,
+	.listen = fi_no_listen,
+	.accept = fi_no_accept,
+	.reject = fi_no_reject,
+	.shutdown = fi_no_shutdown,
+	.join = fi_no_join,
+};
+
+static struct fi_ops_msg mrail_ops_msg = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = mrail_recv,
+	.recvv = fi_no_msg_recvv,
+	.recvmsg = mrail_recvmsg,
+	.send = mrail_send,
+	.sendv = fi_no_msg_sendv,
+	.sendmsg = mrail_sendmsg,
+	.inject = mrail_inject,
+	.senddata = fi_no_msg_senddata,
+	.injectdata = mrail_injectdata,
+};
+
+struct fi_ops_tagged mrail_ops_tagged = {
+	.size = sizeof(struct fi_ops_tagged),
+	.recv = mrail_trecv,
+	.recvv = fi_no_tagged_recvv,
+	.recvmsg = mrail_trecvmsg,
+	.send = mrail_tsend,
+	.sendv = fi_no_tagged_sendv,
+	.sendmsg = mrail_tsendmsg,
+	.inject = mrail_tinject,
+	.senddata = mrail_tsenddata,
+	.injectdata = mrail_tinjectdata,
+};
+
+void mrail_ep_progress(struct util_ep *ep)
+{
+	struct mrail_ep *mrail_ep;
+	mrail_ep = container_of(ep, struct mrail_ep, util_ep);
+	mrail_progress_deferred_reqs(mrail_ep);
+}
+
+int mrail_ep_open(struct fid_domain *domain_fid, struct fi_info *info,
+		  struct fid_ep **ep_fid, void *context)
+{
+	struct mrail_domain *mrail_domain =
+		container_of(domain_fid, struct mrail_domain,
+			     util_domain.domain_fid);
+	struct mrail_ep *mrail_ep;
+	struct fi_info *fi;
+	size_t i;
+	int ret;
+
+	if (strcmp(mrail_domain->info->domain_attr->name,
+		    info->domain_attr->name)) {
+		FI_WARN(&mrail_prov, FI_LOG_EP_CTRL, "info domain name: %s "
+			"doesn't match fid_domain name: %s!\n",
+			info->domain_attr->name,
+			mrail_domain->info->domain_attr->name);
+		return -FI_EINVAL;
+	}
+
+	mrail_ep = calloc(1, sizeof(*mrail_ep));
+	if (!mrail_ep)
+		return -FI_ENOMEM;
+
+	// TODO detect changes b/w mrail_domain->info and info arg
+	// this may be difficult and we may not support such changes
+	mrail_ep->info = mrail_domain->info;
+	mrail_ep->num_eps = mrail_domain->num_domains;
+
+	ret = ofi_endpoint_init(domain_fid, &mrail_util_prov, info, &mrail_ep->util_ep,
+				context, &mrail_ep_progress);
+	if (ret) {
+		goto free_ep;
+	}
+
+	mrail_ep->rails = calloc(mrail_ep->num_eps, sizeof(*mrail_ep->rails));
+	if (!mrail_ep->rails) {
+		ret = -FI_ENOMEM;
+		goto err;
+	}
+
+	for (i = 0, fi = mrail_ep->info->next; fi; fi = fi->next, i++) {
+		fi->tx_attr->op_flags &= ~FI_COMPLETION;
+		ret = fi_endpoint(mrail_domain->domains[i], fi,
+				  &mrail_ep->rails[i].ep, mrail_ep);
+		if (ret) {
+			FI_WARN(&mrail_prov, FI_LOG_EP_CTRL,
+				"Unable to open EP\n");
+			goto err;
+		}
+		mrail_ep->rails[i].info = fi;
+	}
+
+	ret = mrail_ep_alloc_bufs(mrail_ep);
+	if (ret)
+		goto err;
+
+	slist_init(&mrail_ep->deferred_reqs);
+
+	if (mrail_ep->info->caps & FI_DIRECTED_RECV) {
+		mrail_recv_queue_init(&mrail_prov, &mrail_ep->recv_queue,
+				      mrail_match_recv_addr,
+				      mrail_match_unexp_addr,
+				      mrail_get_unexp_msg_entry);
+		mrail_recv_queue_init(&mrail_prov, &mrail_ep->trecv_queue,
+				      mrail_match_recv_addr_tag,
+				      mrail_match_unexp_addr_tag,
+				      mrail_get_unexp_msg_entry);
+	} else {
+		mrail_recv_queue_init(&mrail_prov, &mrail_ep->recv_queue,
+				      mrail_match_recv_any,
+				      mrail_match_unexp_any,
+				      mrail_get_unexp_msg_entry);
+		mrail_recv_queue_init(&mrail_prov, &mrail_ep->trecv_queue,
+				      mrail_match_recv_tag,
+				      mrail_match_unexp_tag,
+				      mrail_get_unexp_msg_entry);
+	}
+
+	ofi_atomic_initialize32(&mrail_ep->tx_rail, 0);
+	ofi_atomic_initialize32(&mrail_ep->rx_rail, 0);
+
+	*ep_fid = &mrail_ep->util_ep.ep_fid;
+	(*ep_fid)->fid.ops = &mrail_ep_fi_ops;
+	(*ep_fid)->ops = &mrail_ops_ep;
+	(*ep_fid)->cm = &mrail_ops_cm;
+	(*ep_fid)->msg = &mrail_ops_msg;
+	(*ep_fid)->tagged = &mrail_ops_tagged;
+	(*ep_fid)->rma = &mrail_ops_rma;
+
+	return 0;
+err:
+	mrail_ep_close(&mrail_ep->util_ep.ep_fid.fid);
+free_ep:
+	free(mrail_ep);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_fabric.c
new file mode 100644
index 000000000..14eb7d33d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_fabric.c
@@ -0,0 +1,122 @@
+/*
+ * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "mrail.h"
+
+static int mrail_fabric_close(fid_t fid)
+{
+	struct mrail_fabric *mrail_fabric =
+		container_of(fid, struct mrail_fabric, util_fabric.fabric_fid.fid);
+	int ret, retv = 0;
+
+	ret = mrail_close_fids((struct fid **)mrail_fabric->fabrics,
+			       mrail_fabric->num_fabrics);
+	if (ret)
+		retv = ret;
+
+	free(mrail_fabric->fabrics);
+
+	ret = ofi_fabric_close(&mrail_fabric->util_fabric);
+	if (ret)
+		retv = ret;
+
+	free(mrail_fabric);
+	return retv;
+}
+
+static struct fi_ops mrail_fabric_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = mrail_fabric_close,
+	.bind = fi_no_bind,
+	.control = fi_no_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static struct fi_ops_fabric mrail_fabric_ops = {
+	.size = sizeof(struct fi_ops_fabric),
+	.domain = mrail_domain_open,
+	.passive_ep = fi_no_passive_ep,
+	.eq_open = ofi_eq_create,
+	.wait_open = ofi_wait_fd_open,
+	.trywait = ofi_trywait
+};
+
+int mrail_fabric_open(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
+		      void *context)
+{
+	struct fi_info *fi;
+	struct mrail_fabric *mrail_fabric;
+	size_t i;
+	int ret;
+
+	mrail_fabric = calloc(1, sizeof(*mrail_fabric));
+	if (!mrail_fabric)
+		return -FI_ENOMEM;
+
+	mrail_fabric->info = mrail_get_info_cached(attr->name);
+	if (!mrail_fabric->info) {
+		free(mrail_fabric);
+		return -FI_EINVAL;
+	}
+
+	ret = ofi_fabric_init(&mrail_prov, &mrail_fabric_attr, attr,
+			      &mrail_fabric->util_fabric, context);
+	if (ret) {
+		free(mrail_fabric);
+		return ret;
+	}
+
+	for (fi = mrail_fabric->info->next; fi; fi = fi->next)
+		mrail_fabric->num_fabrics++;
+
+	mrail_fabric->fabrics = calloc(mrail_fabric->num_fabrics,
+				       sizeof(*mrail_fabric->fabrics));
+	if (!mrail_fabric->fabrics) {
+		ret = -FI_ENOMEM;
+		goto err;
+	}
+
+	for (i = 0, fi = mrail_fabric->info->next; fi; fi = fi->next, i++) {
+		ret = fi_fabric(fi->fabric_attr, &mrail_fabric->fabrics[i], context);
+		if (ret)
+			goto err;
+	}
+
+	*fabric 		= &mrail_fabric->util_fabric.fabric_fid;
+	(*fabric)->fid.ops 	= &mrail_fabric_fi_ops;
+	(*fabric)->ops 		= &mrail_fabric_ops;
+
+	return 0;
+err:
+	mrail_fabric_close(&mrail_fabric->util_fabric.fabric_fid.fid);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_init.c
new file mode 100644
index 000000000..eaec9647c
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_init.c
@@ -0,0 +1,363 @@
+/*
+ * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *	- Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *	- Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <shared/ofi_str.h>
+
+#include "mrail.h"
+
+static char **mrail_addr_strv = NULL;
+/* Not thread safe */
+struct fi_info *mrail_info_vec[MRAIL_MAX_INFO] = {0};
+size_t mrail_num_info = 0;
+
+static inline char **mrail_split_addr_strc(const char *addr_strc)
+{
+	char **addr_strv = ofi_split_and_alloc(addr_strc, ",", NULL);
+	if (!addr_strv) {
+		FI_WARN(&mrail_prov, FI_LOG_CORE,
+			"Unable to split a FI_ADDR_STRV string\n");
+		return NULL;
+	}
+	return addr_strv;
+}
+
+static int mrail_parse_env_vars(void)
+{
+	char *addr_strc;
+	int ret;
+
+	fi_param_define(&mrail_prov, "addr_strc", FI_PARAM_STRING, "List of rail"
+			" addresses of format FI_ADDR_STR delimited by comma");
+	ret = fi_param_get_str(&mrail_prov, "addr_strc", &addr_strc);
+	if (ret) {
+		FI_WARN(&mrail_prov, FI_LOG_CORE, "Unable to read "
+			"OFI_MRAIL_ADDR_STRC env variable\n");
+		return ret;
+	}
+	mrail_addr_strv = mrail_split_addr_strc(addr_strc);
+	if (!mrail_addr_strv)
+		return -FI_ENOMEM;
+	return 0;
+}
+
+int mrail_get_core_info(uint32_t version, const char *node, const char *service,
+			uint64_t flags, const struct fi_info *hints,
+			struct fi_info **core_info)
+{
+	struct fi_info *core_hints, *info, *fi = NULL;
+	size_t i;
+	int ret = 0;
+
+	if (!mrail_addr_strv) {
+		FI_WARN(&mrail_prov, FI_LOG_FABRIC,
+			"OFI_MRAIL_ADDR_STRC env variable not set!\n");
+		return -FI_ENODATA;
+	}
+
+	core_hints = fi_dupinfo(hints);
+	if (!core_hints)
+		return -FI_ENOMEM;
+
+	if (!hints) {
+		core_hints->mode = MRAIL_PASSTHRU_MODES;
+		assert(core_hints->domain_attr);
+		core_hints->domain_attr->mr_mode = MRAIL_PASSTHRU_MR_MODES;
+	} else {
+		if (hints->tx_attr) {
+			if (hints->tx_attr->iov_limit)
+				core_hints->tx_attr->iov_limit =
+					hints->tx_attr->iov_limit + 1;
+			if (hints->rx_attr->iov_limit)
+				core_hints->rx_attr->iov_limit =
+					hints->rx_attr->iov_limit + 1;
+			core_hints->tx_attr->op_flags &= ~FI_COMPLETION;
+		}
+	}
+
+	core_hints->mode |= FI_BUFFERED_RECV;
+	core_hints->caps |= FI_SOURCE;
+
+	if (!core_hints->fabric_attr) {
+		core_hints->fabric_attr = calloc(1, sizeof(*core_hints->fabric_attr));
+		if (!core_hints->fabric_attr) {
+			ret = -FI_ENOMEM;
+			goto out;
+		}
+	}
+
+	if (!core_hints->domain_attr) {
+		core_hints->domain_attr = calloc(1, sizeof(*core_hints->domain_attr));
+		if (!core_hints->domain_attr) {
+			ret = -FI_ENOMEM;
+			goto out;
+		}
+	}
+	core_hints->domain_attr->av_type = FI_AV_TABLE;
+
+	ret = ofi_exclude_prov_name(&core_hints->fabric_attr->prov_name,
+				    mrail_prov.name);
+	if (ret)
+		goto out;
+
+	for (i = 0; mrail_addr_strv[i]; i++) {
+		free(core_hints->src_addr);
+		ret = ofi_str_toaddr(mrail_addr_strv[i],
+				     &core_hints->addr_format,
+				     &core_hints->src_addr,
+				     &core_hints->src_addrlen);
+		if (ret) {
+			FI_WARN(&mrail_prov, FI_LOG_FABRIC,
+				"Unable to convert FI_ADDR_STR to device "
+				"specific address\n");
+			goto err;
+		}
+
+		FI_DBG(&mrail_prov, FI_LOG_CORE,
+		       "--- Begin fi_getinfo for rail: %zd ---\n", i);
+
+		ret = fi_getinfo(version, NULL, NULL, 0, core_hints, &info);
+
+		FI_DBG(&mrail_prov, FI_LOG_CORE,
+		       "--- End fi_getinfo for rail: %zd ---\n", i);
+		if (ret)
+			goto err;
+
+		if (!fi)
+			*core_info = info;
+		else
+			fi->next = info;
+		fi = info;
+
+		/* We only want the first fi_info entry per rail */
+		if (info->next) {
+			fi_freeinfo(info->next);
+			info->next = NULL;
+		}
+
+	}
+	goto out;
+err:
+	if (fi)
+		fi_freeinfo(*core_info);
+out:
+	fi_freeinfo(core_hints);
+	return ret;
+}
+
+static struct fi_info *mrail_dupinfo(const struct fi_info *info)
+{
+	struct fi_info *dup, *fi, *head = NULL;
+
+	while (info) {
+		if (!(dup = fi_dupinfo(info)))
+			goto err;
+		if (!head)
+			head = fi = dup;
+		else
+			fi->next = dup;
+		fi = dup;
+		info = info->next;
+	}
+	return head;
+err:
+	fi_freeinfo(head);
+	return NULL;
+}
+
+static void mrail_adjust_info(struct fi_info *info, const struct fi_info *hints)
+{
+	info->mode &= ~FI_BUFFERED_RECV;
+
+	if (!hints)
+		return;
+
+	if (hints->domain_attr) {
+		if (hints->domain_attr->av_type)
+			info->domain_attr->av_type = hints->domain_attr->av_type;
+	}
+
+	if (hints->tx_attr) {
+		if (hints->tx_attr->op_flags & FI_COMPLETION)
+			info->tx_attr->op_flags |= FI_COMPLETION;
+	}
+}
+
+static struct fi_info *mrail_get_prefix_info(struct fi_info *core_info)
+{
+	struct fi_info *fi;
+	uint32_t num_rails;
+
+	for (fi = core_info, num_rails = 0; fi; fi = fi->next, ++num_rails)
+		;
+
+	fi = fi_dupinfo(core_info);
+	if (!fi)
+		return NULL;
+
+	free(fi->fabric_attr->name);
+	free(fi->domain_attr->name);
+
+	fi->fabric_attr->name = NULL;
+	fi->domain_attr->name = NULL;
+
+	fi->fabric_attr->name = strdup(mrail_info.fabric_attr->name);
+	if (!fi->fabric_attr->name)
+		goto err;
+
+	fi->domain_attr->name = strdup(mrail_info.domain_attr->name);
+	if (!fi->domain_attr->name)
+		goto err;
+
+	fi->ep_attr->protocol		= mrail_info.ep_attr->protocol;
+	fi->ep_attr->protocol_version	= mrail_info.ep_attr->protocol_version;
+	fi->fabric_attr->prov_version	= FI_VERSION(MRAIL_MAJOR_VERSION,
+						     MRAIL_MINOR_VERSION);
+	fi->domain_attr->mr_key_size	= (num_rails *
+					   sizeof(struct mrail_addr_key));
+	fi->domain_attr->mr_mode	|= FI_MR_RAW;
+
+	/* Account for one iovec buffer used for mrail header */
+	assert(fi->tx_attr->iov_limit);
+	fi->tx_attr->iov_limit--;
+
+	/* Claiming messages larger than FI_OPT_BUFFERED_LIMIT would consume
+	 * a scatter/gather entry for mrail_hdr */
+	fi->rx_attr->iov_limit--;
+
+	if (fi->tx_attr->inject_size < sizeof(struct mrail_hdr))
+		fi->tx_attr->inject_size = 0;
+	else
+		fi->tx_attr->inject_size -= sizeof(struct mrail_hdr);
+	return fi;
+err:
+	fi_freeinfo(fi);
+	return NULL;
+}
+
+static int mrail_check_modes(const struct fi_info *hints)
+{
+	if (!hints)
+		return 0;
+
+	if (hints->mode & ~MRAIL_PASSTHRU_MODES) {
+		FI_INFO(&mrail_prov, FI_LOG_CORE,
+			"Unable to pass through given modes: %s\n",
+			fi_tostr(&hints->mode, FI_TYPE_MODE));
+		return -FI_ENODATA;
+	}
+
+	if (hints->domain_attr &&
+	    (hints->domain_attr->mr_mode & ~MRAIL_PASSTHRU_MR_MODES)) {
+		FI_INFO(&mrail_prov, FI_LOG_CORE,
+			"Unable to pass through given MR modes: %s\n",
+			fi_tostr(&hints->domain_attr->mr_mode, FI_TYPE_MR_MODE));
+		return -FI_ENODATA;
+	}
+	return 0;
+}
+
+static int mrail_getinfo(uint32_t version, const char *node, const char *service,
+			 uint64_t flags, const struct fi_info *hints,
+			 struct fi_info **info)
+{
+	struct fi_info *fi;
+	int ret;
+
+	if (mrail_num_info >= MRAIL_MAX_INFO) {
+		FI_WARN(&mrail_prov, FI_LOG_CORE,
+			"Max mrail_num_info reached\n");
+		assert(0);
+		return -FI_ENODATA;
+	}
+
+	ret = mrail_check_modes(hints);
+	if (ret)
+		return ret;
+
+	ret = mrail_get_core_info(version, node, service, flags, hints, info);
+	if (ret)
+		return ret;
+
+	fi = mrail_get_prefix_info(*info);
+	if (!fi) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+
+	mrail_adjust_info(fi, hints);
+
+	// TODO set src_addr to FI_ADDR_STRC address
+	fi->next = *info;
+	*info = fi;
+
+	mrail_info_vec[mrail_num_info] = mrail_dupinfo(*info);
+	if (!mrail_info_vec[mrail_num_info])
+		goto err2;
+
+	mrail_num_info++;
+
+	return 0;
+err2:
+	fi_freeinfo(fi);
+err1:
+	fi_freeinfo(*info);
+	return ret;
+}
+
+static void mrail_fini(void)
+{
+	size_t i;
+	for (i = 0; i < mrail_num_info; i++)
+		fi_freeinfo(mrail_info_vec[i]);
+}
+
+struct fi_provider mrail_prov = {
+	.name = OFI_UTIL_PREFIX "mrail",
+	.version = FI_VERSION(MRAIL_MAJOR_VERSION, MRAIL_MINOR_VERSION),
+	.fi_version = FI_VERSION(1, 7),
+	.getinfo = mrail_getinfo,
+	.fabric = mrail_fabric_open,
+	.cleanup = mrail_fini
+};
+
+struct util_prov mrail_util_prov = {
+	.prov = &mrail_prov,
+	.info = &mrail_info,
+	.flags = 0,
+};
+
+MRAIL_INI
+{
+	mrail_parse_env_vars();
+	return &mrail_prov;
+}
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_rma.c
new file mode 100644
index 000000000..4685a8c17
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/mrail/src/mrail_rma.c
@@ -0,0 +1,421 @@
+/*
+ * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "mrail.h"
+
+static void mrail_subreq_to_rail(struct mrail_subreq *subreq, uint32_t rail,
+		struct iovec *out_iovs, void **out_descs,
+		struct fi_rma_iov *out_rma_iovs)
+{
+	const struct mrail_mr *mrail_mr;
+	struct mrail_addr_key *mr_map;
+	size_t i;
+
+	for (i = 0; i < subreq->iov_count; ++i) {
+		mrail_mr = subreq->descs[i];
+		//TODO: add base address from mrail_mr
+		out_iovs[i].iov_len	= subreq->iov[i].iov_len;
+		out_iovs[i].iov_base 	=
+			(void*)((uintptr_t)subreq->iov[i].iov_base);
+
+		out_descs[i] = (mrail_mr ?
+				fi_mr_desc(mrail_mr->rails[rail].mr) : NULL);
+	}
+
+	for (i = 0; i < subreq->rma_iov_count; ++i) {
+		mr_map = (struct mrail_addr_key *)subreq->rma_iov[i].key;
+		//TODO: add base address from mrail_addr_key
+		out_rma_iovs[i].addr 	= subreq->rma_iov[i].addr;
+		out_rma_iovs[i].len	= subreq->rma_iov[i].len;
+		out_rma_iovs[i].key	= mr_map[rail].key;
+	}
+}
+
+static ssize_t mrail_post_subreq(uint32_t rail,
+		struct mrail_subreq *subreq)
+{
+	ssize_t ret;
+	struct iovec rail_iov[MRAIL_IOV_LIMIT];
+	void *rail_descs[MRAIL_IOV_LIMIT];
+	struct fi_rma_iov rail_rma_iov[MRAIL_IOV_LIMIT];
+	struct fi_msg_rma msg;
+
+	struct mrail_req *req = subreq->parent;
+	struct mrail_ep *mrail_ep = req->mrail_ep;
+
+	uint64_t flags = req->flags;
+
+	mrail_subreq_to_rail(subreq, rail, rail_iov, rail_descs, rail_rma_iov);
+
+	msg.msg_iov		= rail_iov;
+	msg.desc		= rail_descs;
+	msg.iov_count		= subreq->iov_count;
+	msg.addr		= req->peer_info->addr;
+	msg.rma_iov		= rail_rma_iov;
+	msg.rma_iov_count	= subreq->rma_iov_count;
+	msg.context		= &subreq->context;
+
+	if (req->op_type == FI_READ) {
+		ret = fi_readmsg(mrail_ep->rails[rail].ep, &msg, flags);
+	} else {
+		/* Immediate data is sent with the last subreq only */
+		if (flags & FI_REMOTE_CQ_DATA) {
+			if (req->pending_subreq > 0) {
+				flags &= ~FI_REMOTE_CQ_DATA;
+			} else {
+				msg.data = req->data;
+			}
+		}
+		ret = fi_writemsg(mrail_ep->rails[rail].ep, &msg, flags);
+	}
+
+	return ret;
+}
+
+static ssize_t mrail_post_req(struct mrail_req *req)
+{
+	size_t i;
+	uint32_t rail;
+	ssize_t ret = 0;
+
+	while (req->pending_subreq >= 0) {
+		/* Try all rails before giving up */
+		for (i = 0; i < req->mrail_ep->num_eps; ++i) {
+			rail = mrail_get_tx_rail(req->mrail_ep);
+
+			ret = mrail_post_subreq(rail,
+					&req->subreqs[req->pending_subreq]);
+			if (ret != -FI_EAGAIN) {
+				break;
+			} else {
+				/* One of the rails is busy. Try progressing. */
+				mrail_poll_cq(req->mrail_ep->util_ep.tx_cq);
+			}
+		}
+
+		if (ret != 0) {
+			if (ret == -FI_EAGAIN) {
+				break;
+			}
+			/* TODO: Handle errors besides FI_EAGAIN */
+			assert(0);
+		}
+		req->pending_subreq--;
+	}
+
+	return ret;
+}
+
+static inline
+struct mrail_req *mrail_dequeue_deferred_req(struct mrail_ep *mrail_ep)
+{
+	struct mrail_req *req;
+
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	slist_remove_head_container(&mrail_ep->deferred_reqs, struct mrail_req,
+			req, entry);
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+
+	return req;
+}
+
+static inline void mrail_requeue_deferred_req(struct mrail_ep *mrail_ep,
+		struct mrail_req *req)
+{
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	slist_insert_head(&req->entry, &mrail_ep->deferred_reqs);
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+}
+
+static inline void mrail_queue_deferred_req(struct mrail_ep *mrail_ep,
+		struct mrail_req *req)
+{
+	ofi_ep_lock_acquire(&mrail_ep->util_ep);
+	slist_insert_tail(&req->entry, &mrail_ep->deferred_reqs);
+	ofi_ep_lock_release(&mrail_ep->util_ep);
+}
+
+void mrail_progress_deferred_reqs(struct mrail_ep *mrail_ep)
+{
+	struct mrail_req *req;
+	ssize_t ret;
+
+	req = mrail_dequeue_deferred_req(mrail_ep);
+	while (req) {
+		ret = mrail_post_req(req);
+		if (ret) {
+			mrail_requeue_deferred_req(mrail_ep, req);
+			break;
+		}
+		req = mrail_dequeue_deferred_req(mrail_ep);
+	}
+}
+
+static ssize_t mrail_prepare_rma_subreqs(struct mrail_ep *mrail_ep,
+		const struct fi_msg_rma *msg, struct mrail_req *req)
+{
+	ssize_t ret;
+	struct mrail_subreq *subreq;
+	size_t subreq_count;
+	size_t total_len;
+	size_t chunk_len;
+	size_t subreq_len;
+	size_t iov_index;
+	size_t iov_offset;
+	size_t rma_iov_index;
+	size_t rma_iov_offset;
+	int i;
+
+	/* For now, stripe across all rails.
+	 * This could be determined by a dynamic scheduler instead.
+	 */
+	subreq_count = mrail_ep->num_eps;
+
+	total_len = ofi_total_iov_len(msg->msg_iov, msg->iov_count); 
+	chunk_len = total_len / subreq_count;
+
+	/* The first chunk is the longest */
+	subreq_len =  chunk_len + (total_len % subreq_count);
+	iov_index = 0;
+	iov_offset = 0;
+	rma_iov_index = 0;
+	rma_iov_offset = 0;
+
+	/* The array is filled in reverse order -- i.e. first subreq at
+	 * last position in the array. Filling the array in this order saves
+	 * us from having to use two variables, to track the total number of
+	 * subreqs, and to know which one to try posting next.
+	 * Instead, a single variable (req->pending_subreq) is used to keep
+	 * track of which subreq to post next, starting at the end of the
+	 * array.
+	 */
+	for (i = (subreq_count - 1); i >= 0; --i) {
+		subreq = &req->subreqs[i];
+
+		subreq->parent = req;
+
+		ret = ofi_copy_iov_desc(subreq->iov, subreq->descs,
+				&subreq->iov_count,
+				(struct iovec *)msg->msg_iov, msg->desc,
+				msg->iov_count, &iov_index, &iov_offset,
+				subreq_len);
+		if (ret) {
+			goto out;
+		}
+
+		ret = ofi_copy_rma_iov(subreq->rma_iov, &subreq->rma_iov_count,
+				(struct fi_rma_iov *)msg->rma_iov,
+				msg->rma_iov_count, &rma_iov_index,
+				&rma_iov_offset, subreq_len);
+		if (ret) {
+			goto out;
+		}
+
+		/* All the other chunks have the same length */
+		subreq_len = chunk_len;
+	}
+
+	ofi_atomic_initialize32(&req->expected_subcomps, subreq_count);
+
+	/* pending_subreq is the index of the next subreq to post.
+	 * The array was filled in reverse order in mrail_prepare_rma_subreqs()
+	 */
+	req->pending_subreq	= subreq_count - 1;
+
+out:
+	return ret;
+}
+
+static ssize_t mrail_init_rma_req(struct mrail_ep *mrail_ep,
+		struct mrail_req *req, const struct fi_msg_rma *msg,
+		uint64_t flags, int op_type)
+{
+	ssize_t ret;
+
+	req->op_type		= op_type;
+	req->flags		= flags;
+	req->data		= msg->data;
+	req->mrail_ep		= mrail_ep;
+	req->peer_info		= ofi_av_get_addr(mrail_ep->util_ep.av,
+						 (int) msg->addr);
+	req->comp.op_context	= msg->context;
+	req->comp.flags		= flags;
+
+	ret = mrail_prepare_rma_subreqs(mrail_ep, msg, req);
+	if (ret) {
+		FI_WARN(&mrail_prov, FI_LOG_EP_DATA,
+			"Unable to prepare rma subreqs: %s\n",
+			fi_strerror(-ret));
+	}
+	return ret;
+}
+
+static ssize_t mrail_ep_post_rma(struct fid_ep *ep_fid,
+		const struct fi_msg_rma *msg, uint64_t flags, int op_type)
+{
+	ssize_t ret;
+	struct mrail_ep *mrail_ep;
+	struct mrail_req *req;
+
+	mrail_ep = container_of(ep_fid, struct mrail_ep, util_ep.ep_fid.fid);
+
+	req = mrail_alloc_req(mrail_ep);
+	if (!req) {
+		return -FI_ENOMEM;
+	}
+
+	ret = mrail_init_rma_req(mrail_ep, req, msg, flags, op_type);
+	if (ret) {
+		mrail_free_req(mrail_ep, req);
+		return ret;
+	}
+
+	mrail_queue_deferred_req(mrail_ep, req);
+
+	/* Initiate progress here. See mrail_ep_progress() for any remaining
+	 * reqs.
+	 */
+	mrail_progress_deferred_reqs(mrail_ep);
+
+	return 0;
+}
+
+static ssize_t mrail_ep_readmsg(struct fid_ep *ep_fid,
+		const struct fi_msg_rma *msg, uint64_t flags)
+{
+	return mrail_ep_post_rma(ep_fid, msg, flags, FI_READ);
+}
+
+/* TODO: separate the different operations to optimize performance */
+static ssize_t mrail_ep_read(struct fid_ep *ep_fid, void *buf, size_t len,
+		void *desc, fi_addr_t src_addr, uint64_t addr,
+		uint64_t key, void *context)
+{
+	struct mrail_ep *mrail_ep;
+	struct iovec iovec = {
+		.iov_base = (void*)buf,
+		.iov_len = len
+	};
+	struct fi_rma_iov rma_iov= {
+		.addr = addr,
+		.len = len,
+		.key = key
+	};
+	struct fi_msg_rma msg = {
+		.msg_iov = &iovec,
+		.desc = &desc,
+		.iov_count = 1,
+		.addr = src_addr,
+		.rma_iov = &rma_iov,
+		.rma_iov_count = 1,
+		.context = context,
+		.data = 0
+	};
+
+	mrail_ep = container_of(ep_fid, struct mrail_ep, util_ep.ep_fid.fid);
+
+	return mrail_ep_readmsg(ep_fid, &msg, mrail_ep->util_ep.tx_op_flags);
+}
+
+static ssize_t mrail_ep_writemsg(struct fid_ep *ep_fid,
+		const struct fi_msg_rma *msg, uint64_t flags)
+{
+	return mrail_ep_post_rma(ep_fid, msg, flags, FI_WRITE);
+}
+
+static ssize_t mrail_ep_write(struct fid_ep *ep_fid, const void *buf,
+		size_t len, void *desc, fi_addr_t dest_addr, uint64_t addr,
+		uint64_t key, void *context)
+{
+	struct mrail_ep *mrail_ep;
+	struct iovec iovec = {
+		.iov_base = (void*)buf,
+		.iov_len = len
+	};
+	struct fi_rma_iov rma_iov= {
+		.addr = addr,
+		.len = len,
+		.key = key
+	};
+	struct fi_msg_rma msg = {
+		.msg_iov = &iovec,
+		.desc = &desc,
+		.iov_count = 1,
+		.addr = dest_addr,
+		.rma_iov = &rma_iov,
+		.rma_iov_count = 1,
+		.context = context,
+		.data = 0
+	};
+
+	mrail_ep = container_of(ep_fid, struct mrail_ep, util_ep.ep_fid.fid);
+
+	return mrail_ep_writemsg(ep_fid, &msg, mrail_ep->util_ep.tx_op_flags);
+}
+
+static ssize_t mrail_ep_inject_write(struct fid_ep *ep_fid, const void *buf,
+		size_t len, fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	struct mrail_ep *mrail_ep;
+	struct mrail_addr_key *mr_map;
+	uint32_t rail;
+	ssize_t ret;
+
+	mrail_ep = container_of(ep_fid, struct mrail_ep, util_ep.ep_fid.fid);
+	mr_map = (struct mrail_addr_key *) key;
+
+	rail = mrail_get_tx_rail(mrail_ep);
+	ret = fi_inject_write(mrail_ep->rails[rail].ep, buf, len,
+			      dest_addr, addr, mr_map[rail].key);
+	if (ret) {
+		FI_WARN(&mrail_prov, FI_LOG_EP_DATA,
+			"Unable to post inject write on rail: %" PRIu32 "\n",
+			rail);
+		return ret;
+	}
+	ofi_ep_wr_cntr_inc(&mrail_ep->util_ep);
+
+	return 0;
+}
+
+struct fi_ops_rma mrail_ops_rma = {
+	.size = sizeof (struct fi_ops_rma),
+	.read = mrail_ep_read,
+	.readv = fi_no_rma_readv,
+	.readmsg = mrail_ep_readmsg,
+	.write = mrail_ep_write,
+	.writev = fi_no_rma_writev,
+	.writemsg = mrail_ep_writemsg,
+	.inject = mrail_ep_inject_write,
+	.writedata = fi_no_rma_writedata,
+	.injectdata = fi_no_rma_injectdata,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/NetDirect/README.NetworkDirect b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/NetDirect/README.NetworkDirect
index 06472ed4e..a6d113a24 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/NetDirect/README.NetworkDirect
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/NetDirect/README.NetworkDirect
@@ -1,6 +1,12 @@
-Network Direct SDK/DDK may be downloaded from:
+Network Direct SDK/DDK may be obtained as a nuget package (preferred) from:
+
+https://www.nuget.org/packages/NetworkDirect
+
+or downloaded from:
+
 https://www.microsoft.com/en-us/download/details.aspx?id=36043
 on page press Download button and select NetworkDirect_DDK.zip.
+
 Extract header files from downloaded
 NetworkDirect_DDK.zip:\NetDirect\include\ file into this directory,
 or add path to NetDirect headers into VS include paths
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir.h
index f0c4d47d0..7b17e4ca9 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir.h
@@ -49,23 +49,26 @@ extern "C" {
 #endif /* __cplusplus */
 
 #define OFI_ND_MAJOR_VERSION 1
-#define OFI_ND_MINOR_VERSION 5
+#define OFI_ND_MINOR_VERSION 0
 
 #define ND_MSG_IOV_LIMIT		(256)
 #define ND_MSG_INTERNAL_IOV_LIMIT	(512)
 #define ND_EP_MAX_CM_DATA_SIZE		(256)
 #define OFI_ND_MAX_MR_CNT		(1 << 16)
 
-#define OFI_ND_PRIMARY_CAPS					\
-	FI_MSG | FI_RMA | FI_SEND | FI_RECV |			\
-	FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE
-#define OFI_ND_CAPS OFI_ND_PRIMARY_CAPS
+#define OFI_ND_DOMAIN_CAPS	(FI_LOCAL_COMM | FI_REMOTE_COMM)
 
-#define OFI_ND_TX_OP_FLAGS					\
-	FI_INJECT | FI_COMPLETION | FI_TRANSMIT_COMPLETE |	\
-	FI_INJECT_COMPLETE | FI_DELIVERY_COMPLETE |		\
-	FI_SELECTIVE_COMPLETION
+#define OFI_ND_EP_CAPS	(FI_MSG | FI_RMA |			\
+			 FI_SEND | FI_RECV |			\
+			 FI_READ | FI_WRITE |			\
+			 FI_REMOTE_READ | FI_REMOTE_WRITE)
 
+#define OFI_ND_TX_OP_FLAGS	(FI_INJECT | FI_COMPLETION | FI_TRANSMIT_COMPLETE |	\
+				 FI_INJECT_COMPLETE | FI_DELIVERY_COMPLETE |		\
+				 FI_SELECTIVE_COMPLETION)
+
+#define OFI_ND_MSG_ORDER (FI_ORDER_RAR | FI_ORDER_RAW | FI_ORDER_RAS | \
+			FI_ORDER_WAW | FI_ORDER_WAS | FI_ORDER_SAW | FI_ORDER_SAS )
 
 extern struct gl_data {
 	int	inline_thr;
@@ -157,6 +160,25 @@ static inline size_t unique(void *base, size_t num, size_t width,
 	return n;
 }
 
+#define H2F(x) ofi_nd_hresult_2_fierror(x)
+
+static inline int ofi_nd_hresult_2_fierror(HRESULT hr)
+{
+	switch (hr) {
+	case S_OK:
+	case ND_PENDING:
+		return FI_SUCCESS;
+	case ND_BUFFER_OVERFLOW:
+		return -FI_EOVERFLOW;
+	case ND_CONNECTION_REFUSED:
+		return -FI_ECONNREFUSED;
+	case ND_TIMEOUT:
+		return -FI_ETIMEDOUT;
+	default:
+		return -FI_EOTHER;
+	}
+}
+
 #define OFI_ND_TIMEOUT_INIT(timeout)				\
 	uint64_t sfinish = ((timeout) >= 0) ?			\
 		(fi_gettime_ms() + (timeout) * 10000) : -1;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_cntr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_cntr.c
index 5c7f80e06..cd3a19781 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_cntr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_cntr.c
@@ -34,7 +34,6 @@
 
 #include "netdir.h"
 #include "netdir_ov.h"
-#include "netdir_err.h"
 #include "netdir_iface.h"
 
 #include "rdma/fabric.h"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_cq.c
index 945787dc6..e69ff4de7 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_cq.c
@@ -34,7 +34,6 @@
 
 #include "netdir.h"
 #include "netdir_cq.h"
-#include "netdir_err.h"
 #include "netdir_iface.h"
 #include "netdir_unexp.h"
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_domain.c
index e9d5b4b8a..590e1aad4 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_domain.c
@@ -37,7 +37,6 @@
 
 #include "netdir.h"
 #include "netdir_ov.h"
-#include "netdir_err.h"
 #include "netdir_log.h"
 #include "netdir_util.h"
 #include "netdir_iface.h"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep.c
index 72729c4a6..f183078af 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep.c
@@ -37,7 +37,6 @@
 
 #include "netdir.h"
 #include "netdir_ov.h"
-#include "netdir_err.h"
 #include "netdir_log.h"
 #include "netdir_util.h"
 #include "netdir_iface.h"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_msg.c
index 05851d0e6..3427dbe1d 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_msg.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_msg.c
@@ -38,7 +38,6 @@
 #include "netdir.h"
 #include "netdir_ov.h"
 #include "netdir_cq.h"
-#include "netdir_err.h"
 #include "netdir_log.h"
 #include "netdir_iface.h"
 #include "netdir_unexp.h"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_rma.c
index 09ff39b69..4bc1058f8 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_rma.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_rma.c
@@ -35,7 +35,6 @@
 #include "netdir.h"
 #include "netdir_ov.h"
 #include "netdir_cq.h"
-#include "netdir_err.h"
 #include "netdir_log.h"
 #include "netdir_iface.h"
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_srx.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_srx.c
index c5cbbfd10..19d19a6d6 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_srx.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ep_srx.c
@@ -35,7 +35,6 @@
 #include "netdir.h"
 #include "netdir_ov.h"
 #include "netdir_cq.h"
-#include "netdir_err.h"
 #include "netdir_log.h"
 #include "netdir_iface.h"
 #include "netdir_unexp.h"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_eq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_eq.c
index 129aa96a8..9deeef24a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_eq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_eq.c
@@ -34,7 +34,6 @@
 
 #include "netdir.h"
 #include "netdir_ov.h"
-#include "netdir_err.h"
 #include "netdir_log.h"
 #include "netdir_iface.h"
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_init.c
index 5da3f5a48..509b3504f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_init.c
@@ -43,6 +43,23 @@
 
 #include "netdir_queue.h"
 
+const char ofi_nd_prov_name[] = "netdir";
+
+struct fi_provider ofi_nd_prov = {
+	.name = ofi_nd_prov_name,
+	.version = FI_VERSION(OFI_ND_MAJOR_VERSION, OFI_ND_MINOR_VERSION),
+	.fi_version = FI_VERSION(1, 7),
+	.getinfo = ofi_nd_getinfo,
+	.fabric = ofi_nd_fabric,
+	.cleanup = ofi_nd_fini
+};
+
+struct util_prov ofi_nd_util_prov = {
+	.prov = &ofi_nd_prov,
+	.info = 0,
+	.flags = UTIL_RX_SHARED_CTX,
+};
+
 struct gl_data gl_data = {
 	/* 8 KByte */
 	.inline_thr = 8192,
@@ -59,8 +76,7 @@ int ofi_nd_getinfo(uint32_t version, const char *node, const char *service,
 	if (ofi_nd_util_prov.info) {
 		return util_getinfo(&ofi_nd_util_prov, version, node, service, flags,
 				    hints, info);
-	}
-	else {
+	} else {
 		*info = NULL;
 		return -FI_EINVAL;
 	}
@@ -93,6 +109,7 @@ static int ofi_nd_adapter_cb(const ND2_ADAPTER_INFO *adapter, const char *name)
 	info->tx_attr->iov_limit = ND_MSG_IOV_LIMIT;
 	info->tx_attr->rma_iov_limit = ND_MSG_IOV_LIMIT;
 	info->tx_attr->op_flags = OFI_ND_TX_OP_FLAGS;
+	info->tx_attr->msg_order = OFI_ND_MSG_ORDER;
 
 	info->rx_attr->caps = FI_MSG | FI_RECV;
 	info->rx_attr->comp_order = FI_ORDER_STRICT;
@@ -101,12 +118,14 @@ static int ofi_nd_adapter_cb(const ND2_ADAPTER_INFO *adapter, const char *name)
 	/* TODO: if optimization will be needed, we can use adapter->MaxInitiatorSge,
 	 * and use ND SGE to recv iovecs */
 	info->rx_attr->iov_limit = ND_MSG_IOV_LIMIT;
+	info->rx_attr->msg_order = OFI_ND_MSG_ORDER;
 
 	info->ep_attr->type = FI_EP_MSG;
 	info->ep_attr->protocol = FI_PROTO_NETWORKDIRECT;
 	info->ep_attr->protocol_version = 0;
 	info->ep_attr->max_msg_size = (size_t)adapter->MaxTransferLength;
 
+	info->domain_attr->caps = OFI_ND_DOMAIN_CAPS;
 	info->domain_attr->name = strdup(name);
 	info->domain_attr->threading = FI_THREAD_SAFE;
 	info->domain_attr->control_progress = FI_PROGRESS_AUTO;
@@ -121,13 +140,12 @@ static int ofi_nd_adapter_cb(const ND2_ADAPTER_INFO *adapter, const char *name)
 	info->fabric_attr->name = strdup(ofi_nd_prov_name);
 	info->fabric_attr->prov_version = FI_VERSION(OFI_ND_MAJOR_VERSION, OFI_ND_MINOR_VERSION);
 
-	info->caps = OFI_ND_CAPS;
+	info->caps = OFI_ND_EP_CAPS | OFI_ND_DOMAIN_CAPS;
 	info->addr_format = FI_SOCKADDR;
 
 	if (!ofi_nd_util_prov.info) {
 		ofi_nd_util_prov.info = info;
-	}
-	else {
+	} else {
 		struct fi_info *finfo = (struct fi_info *) ofi_nd_util_prov.info;
 
 		while (finfo->next)
@@ -151,9 +169,6 @@ NETDIR_INI
 		"Count of Entries in Array of Preposted Buffers: number of set of buffer "
 		"in each entry array of buffers to be preposted per EP");
 
-	//fi_param_define(&ofi_nd_prov, "presize", FI_PARAM_INT,
-	//	"Pre-post vector size, number of elements in pre-post vector");
-
 	ofi_nd_startup(ofi_nd_adapter_cb);
 	return &ofi_nd_prov;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_log.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_log.h
index 32a662c65..a56ef419f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_log.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_log.h
@@ -72,19 +72,19 @@ extern struct fi_provider ofi_nd_prov;
 */
 static inline char *ofi_nd_strerror(DWORD err, HMODULE module)
 {
-	static char *message = 0;
+	static char *message = NULL;
+	size_t size;
 
 	/* if message is allocated - free it */
 	if (message)
 		LocalFree(message);
 
-	size_t size = FormatMessageA(
-		FORMAT_MESSAGE_ALLOCATE_BUFFER |
-		FORMAT_MESSAGE_FROM_SYSTEM |
-		FORMAT_MESSAGE_IGNORE_INSERTS |
-		(module ? FORMAT_MESSAGE_FROM_HMODULE : 0),
-		module, err, MAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT),
-		(LPSTR)&message, 0, NULL);
+	size = FormatMessageA(FORMAT_MESSAGE_ALLOCATE_BUFFER |
+			      FORMAT_MESSAGE_FROM_SYSTEM |
+			      FORMAT_MESSAGE_IGNORE_INSERTS |
+			      (module ? FORMAT_MESSAGE_FROM_HMODULE : 0),
+			      module, err, MAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT),
+			      (LPSTR)&message, 0, NULL);
 
 	return size ? message : (char*)"";
 }
@@ -122,8 +122,7 @@ ofi_nd_get_last_error_str(HRESULT hr, char *errmsg, SIZE_T max_msg_len)
 #define ND_FLUSHED 0x10000L	/* undocumented ND error code */
 #define ND_DISCONNECTED 0xc000020C 
 
-static char *
-ofi_nd_error_str(HRESULT hr)
+static char *ofi_nd_error_str(HRESULT hr)
 {
 	static char lerr[128];
 	char *err_str = NULL;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_mr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_mr.c
index 1aa5eab06..a35aa14f5 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_mr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_mr.c
@@ -35,7 +35,6 @@
 #include "netdir.h"
 
 #include "netdir_ov.h"
-#include "netdir_err.h"
 #include "netdir_iface.h"
 
 #include "ofi.h"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ndinit.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ndinit.c
index 47679fae7..a9b8dfdd6 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ndinit.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_ndinit.c
@@ -41,7 +41,6 @@
 
 #include "netdir.h"
 #include "netdir_log.h"
-#include "netdir_err.h"
 
 #ifndef ofi_sizeofaddr
 #define ofi_sizeofaddr(address)			\
@@ -203,13 +202,8 @@ static inline wchar_t *ofi_nd_get_provider_path(const WSAPROTOCOL_INFOW *proto)
 {
 	assert(proto);
 
-	int len;
-	int lenex;
-	int err;
-	int res;
-
-	wchar_t *prov;
-	wchar_t *provex;
+	int len, lenex, err, res;
+	wchar_t *prov, *provex;
 
 	res = WSCGetProviderPath((GUID*)&proto->ProviderId, NULL, &len, &err);
 	if (err != WSAEFAULT || !len)
@@ -268,6 +262,7 @@ static inline struct module_t *ofi_nd_search_module(const wchar_t* path)
 {
 	size_t i;
 	size_t j;
+
 	for (i = 0; i < ofi_nd_infra.providers.count; i++) {
 		if (path && ofi_nd_file_exists(path) &&
 		    !ofi_nd_is_directory(path)) {
@@ -283,15 +278,20 @@ static inline struct module_t *ofi_nd_search_module(const wchar_t* path)
 
 static inline struct module_t *ofi_nd_create_module(const wchar_t* path)
 {
+	struct module_t *module;
+	HMODULE hmodule;
+	can_unload_now_t unload;
+	get_class_object_t getclass;
+
 	assert(ofi_nd_infra.providers.modules);
 
-	struct module_t *module = ofi_nd_search_module(path);
+	module = ofi_nd_search_module(path);
 	if (module)
 		return module;
 
 	/* ok, this is not duplicate. try to
 	load it and get class factory*/
-	HMODULE hmodule = LoadLibraryW(path);
+	hmodule = LoadLibraryW(path);
 	if (!hmodule) {
 		ND_LOG_WARN(FI_LOG_CORE,
 			   "ofi_nd_create_module: provider : %S, failed to load: %s\n",
@@ -299,8 +299,8 @@ static inline struct module_t *ofi_nd_create_module(const wchar_t* path)
 		return NULL;
 	}
 
-	can_unload_now_t unload = (can_unload_now_t)GetProcAddress(hmodule, "DllCanUnloadNow");
-	get_class_object_t getclass = (get_class_object_t)GetProcAddress(hmodule, "DllGetClassObject");
+	unload = (can_unload_now_t)GetProcAddress(hmodule, "DllCanUnloadNow");
+	getclass = (get_class_object_t)GetProcAddress(hmodule, "DllGetClassObject");
 	if (!unload || !getclass) {
 		ND_LOG_WARN(FI_LOG_CORE,
 			   "ofi_nd_create_module: provider: %S, failed to import interface\n",
@@ -325,31 +325,36 @@ fn_noiface:
 
 static inline HRESULT ofi_nd_create_factory(const WSAPROTOCOL_INFOW* proto)
 {
+	wchar_t *path;
+	struct module_t *module;
+	IClassFactory* factory;
+	HRESULT hr;
+	struct factory_t *ftr;
+
 	assert(proto);
 	assert(ofi_nd_is_valid_proto(proto));
 	assert(ofi_nd_infra.class_factories.factory);
 
-	wchar_t *path = ofi_nd_get_provider_path(proto);
+	path = ofi_nd_get_provider_path(proto);
 	if (path)
 		ND_LOG_INFO(FI_LOG_CORE,
-			   "ofi_nd_create_factory: provider " FI_ND_GUID_FORMAT " path: %S \n",
-			   FI_ND_GUID_ARG(proto->ProviderId), path);
+			    "ofi_nd_create_factory: provider " FI_ND_GUID_FORMAT " path: %S \n",
+			    FI_ND_GUID_ARG(proto->ProviderId), path);
 	else /* can't get provider path. just return */
 		return S_OK;
 
-	struct module_t *module = ofi_nd_create_module(path);
+	module = ofi_nd_create_module(path);
 	free(path);
 	if (!module)
-		return S_OK;;
+		return S_OK;
 
 	assert(module->get_class_object);
-	IClassFactory* factory;
-	HRESULT hr = module->get_class_object(&proto->ProviderId, &IID_IClassFactory,
-					      (void**)&factory);
+	hr = module->get_class_object(&proto->ProviderId, &IID_IClassFactory,
+				      (void**)&factory);
 	if (FAILED(hr))
 		return hr;
 
-	struct factory_t *ftr = &ofi_nd_infra.class_factories.factory[ofi_nd_infra.class_factories.count];
+	ftr = &ofi_nd_infra.class_factories.factory[ofi_nd_infra.class_factories.count];
 	ofi_nd_infra.class_factories.count++;
 	ftr->class_factory = factory;
 	ftr->module = module;
@@ -364,21 +369,21 @@ static int ofi_nd_adapter_cmp(const void *adapter1, const void *adapter2)
 			       &((struct adapter_t*)adapter2)->address);
 }
 
-static HRESULT ofi_nd_create_adapter()
+static HRESULT ofi_nd_create_adapter(void)
 {
 	size_t addr_count = 0;
 	HRESULT hr;
 
 	for (size_t i = 0; i < ofi_nd_infra.class_factories.count; i++) {
 		struct factory_t *factory = &ofi_nd_infra.class_factories.factory[i];
+		ULONG listsize = 0;
+
 		assert(factory->class_factory);
 
 		hr = factory->class_factory->lpVtbl->CreateInstance(factory->class_factory,
 			NULL, &IID_IND2Provider, (void**)&factory->provider);
 		if (FAILED(hr))
 			return hr;
-
-		ULONG listsize = 0;
 		hr = factory->provider->lpVtbl->QueryAddressList(factory->provider, NULL, &listsize);
 		if (hr != ND_BUFFER_OVERFLOW)
 			return hr;
@@ -438,14 +443,17 @@ static HRESULT ofi_nd_create_adapter()
 	for (size_t i = 0; i < ofi_nd_infra.adapters.count; i++) {
 		struct adapter_t *adapter = &ofi_nd_infra.adapters.adapter[i];
 		struct factory_t *factory = adapter->factory;
+		wchar_t *saddr;
+		DWORD addrlen = 0;
+		UINT64 id;
+		int res;
+
 		assert(factory);
 		assert(factory->provider);
 
 		assert(adapter->address.addr.sa_family == AF_INET ||
 		       adapter->address.addr.sa_family == AF_INET6);
 
-		UINT64 id;
-
 		hr = factory->provider->lpVtbl->ResolveAddress(factory->provider,
 			&adapter->address.addr,
 			ofi_sizeofaddr(&adapter->address.addr), &id);
@@ -471,17 +479,12 @@ static HRESULT ofi_nd_create_adapter()
 				return hr;
 			adapter->info = *info;
 			free(info);
-		}
-		else if (FAILED(hr)) {
+		} else if (FAILED(hr)) {
 			return hr;
 		}
 
 		/* generate adapter's name */
-		wchar_t *saddr;
-
-		DWORD addrlen = 0;
-
-		int res = WSAAddressToStringW(&adapter->address.addr,
+		res = WSAAddressToStringW(&adapter->address.addr,
 					     ofi_sizeofaddr(&adapter->address.addr),
 					     NULL, NULL, &addrlen);
 		if (res == SOCKET_ERROR && WSAGetLastError() == WSAEFAULT && addrlen) {
@@ -507,27 +510,22 @@ static HRESULT ofi_nd_init(ofi_nd_adapter_cb_t cb)
 {
 	DWORD proto_len = 0;
 	HRESULT hr = ND_INTERNAL_ERROR;
-	int i;
-	int protonum;
-	size_t j;
+	int i, protonum, err;
+	size_t j, prov_count = 0;
 	WSAPROTOCOL_INFOW *proto = 0;
 
-	size_t prov_count = 0;
-
-	int err;
-
-	memset(&ofi_nd_infra, 0, sizeof(*(&ofi_nd_infra)));
+	memset(&ofi_nd_infra, 0, sizeof(ofi_nd_infra));
 
 	int ret = WSCEnumProtocols(NULL, NULL, &proto_len, &err);
 	if (ret != SOCKET_ERROR || err != WSAENOBUFS) {
 		hr = ND_NO_MEMORY;
-		goto fn_failed;
+		goto fn_exit;
 	}
 
 	proto = (WSAPROTOCOL_INFOW*)(malloc(proto_len));
 	if (!proto) {
 		hr = ND_NO_MEMORY;
-		goto fn_failed;
+		goto fn_exit;
 	}
 
 	protonum = WSCEnumProtocols(NULL, proto, &proto_len, &err);
@@ -540,9 +538,7 @@ static HRESULT ofi_nd_init(ofi_nd_adapter_cb_t cb)
 	   as maximum of existing providers and class factories */
 	for (i = 0; i < protonum; i++) {
 		if (ofi_nd_is_valid_proto(&proto[i]))
-		{
 			prov_count++;
-		}
 	}
 
 	if (!prov_count) {
@@ -555,9 +551,8 @@ static HRESULT ofi_nd_init(ofi_nd_adapter_cb_t cb)
 		goto fn_protofail;
 
 	for (i = 0; i < protonum; i++) {
-		if (ofi_nd_is_valid_proto(&proto[i])) {
+		if (ofi_nd_is_valid_proto(&proto[i]))
 			ofi_nd_create_factory(&proto[i]);
-		}
 	}
 
 	free(proto);
@@ -565,7 +560,6 @@ static HRESULT ofi_nd_init(ofi_nd_adapter_cb_t cb)
 	/* ok, factories are created, now list all available addresses, try to
 	   create adapters & collect adapter's info */
 	hr = ofi_nd_create_adapter();
-
 	if (FAILED(hr))
 		return hr;
 
@@ -577,18 +571,21 @@ static HRESULT ofi_nd_init(ofi_nd_adapter_cb_t cb)
 		cb(&ofi_nd_infra.adapters.adapter[j].info,
 		   ofi_nd_infra.adapters.adapter[j].name);
 
-fn_exit:
 	return hr;
-
 fn_protofail:
 	free(proto);
-fn_failed:
-	goto fn_exit;
+fn_exit:
+	return hr;
 }
 
+/* we don't need here exclusive execution because this function
+ * is called from OFI init routine which is single thread */
 HRESULT ofi_nd_startup(ofi_nd_adapter_cb_t cb)
-{ /* we don't need here exclusive execution because this function
-     is called from OFI init routine which is single thread */
+{ 
+	WSADATA data;
+	HRESULT hr;
+	int ret;
+
 	assert(cb);
 
 	if (ofi_nd_startup_done)
@@ -596,22 +593,20 @@ HRESULT ofi_nd_startup(ofi_nd_adapter_cb_t cb)
 
 	ND_LOG_INFO(FI_LOG_CORE, "ofi_nd_startup: starting initialization\n");
 
-	WSADATA data;
-
-	int ret = WSAStartup(MAKEWORD(2, 2), &data);
+	ret = WSAStartup(MAKEWORD(2, 2), &data);
 	if (ret)
 		return HRESULT_FROM_WIN32(ret);
 
 	ND_LOG_DEBUG(FI_LOG_CORE, "ofi_nd_startup: WSAStartup complete\n");
 
-	HRESULT hr = ofi_nd_init(cb);
+	hr = ofi_nd_init(cb);
 
 	ofi_nd_startup_done = 1;
 
 	return hr;
 }
 
-HRESULT ofi_nd_shutdown()
+HRESULT ofi_nd_shutdown(void)
 {
 	if (!ofi_nd_startup_done)
 		return S_OK;
@@ -619,25 +614,29 @@ HRESULT ofi_nd_shutdown()
 	ND_LOG_INFO(FI_LOG_CORE, "ofi_nd_shutdown: shutdown WSA\n");
 
 	ofi_nd_free_infra();
-
-	int ret = WSACleanup();
-
 	ofi_nd_startup_done = 0;
-	return HRESULT_FROM_WIN32(ret);
+
+	return HRESULT_FROM_WIN32(WSACleanup());
 }
 
 int ofi_nd_lookup_adapter(const char *name, IND2Adapter **adapter, struct sockaddr** addr)
 {
+	size_t i;
+
 	assert(name);
 	assert(adapter);
 
 	if (!ofi_nd_startup_done)
 		return -FI_EOPBADSTATE;
 
-	size_t i;
 	for (i = 0; i < ofi_nd_infra.adapters.count; i++) {
 		struct adapter_t *ada = &ofi_nd_infra.adapters.adapter[i];
 		if (ada->name && !strcmp(ada->name, name)) {
+			HRESULT hr;
+			UINT64 adapter_id;
+			IClassFactory* factory = NULL;
+			IND2Provider *provider = NULL;
+
 			/* ok, we found good adapter. try to initialize it */
 			if (ada->adapter) {
 				*adapter = ada->adapter;
@@ -650,8 +649,7 @@ int ofi_nd_lookup_adapter(const char *name, IND2Adapter **adapter, struct sockad
 			assert(ada->factory->module);
 			assert(ada->factory->module->get_class_object);
 
-			IClassFactory* factory = NULL;
-			HRESULT hr = ada->factory->module->get_class_object(
+			hr = ada->factory->module->get_class_object(
 				&ada->factory->protocol.ProviderId,
 				&IID_IClassFactory,
 				(void**)&factory);
@@ -659,26 +657,24 @@ int ofi_nd_lookup_adapter(const char *name, IND2Adapter **adapter, struct sockad
 				return H2F(hr);
 			assert(factory);
 
-			IND2Provider *provider = NULL;
-			hr = factory->lpVtbl->CreateInstance(factory, NULL, &IID_IND2Provider,
-				(void**)&provider);
+			hr = factory->lpVtbl->CreateInstance(factory, NULL,
+							     &IID_IND2Provider,
+							     (void**)&provider);
 			factory->lpVtbl->Release(factory);
 			if (FAILED(hr))
 				return H2F(hr);
 			assert(provider);
 
-			UINT64 adapter_id;
-
 			hr = provider->lpVtbl->ResolveAddress(provider, &ada->address.addr,
-				ofi_sizeofaddr(&ada->address.addr),
-				&adapter_id);
+							      ofi_sizeofaddr(&ada->address.addr),
+							      &adapter_id);
 			if (FAILED(hr)) {
 				provider->lpVtbl->Release(provider);
 				return H2F(hr);
 			}
 
 			hr = provider->lpVtbl->OpenAdapter(provider, &IID_IND2Adapter, adapter_id,
-				(void**)&ada->adapter);
+							   (void**)&ada->adapter);
 			provider->lpVtbl->Release(provider);
 			if (FAILED(hr))
 				return H2F(hr);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_pep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_pep.c
index 98442867b..188984fed 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_pep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_pep.c
@@ -43,7 +43,6 @@
 #include "ofi_util.h"
 
 #include "netdir_ov.h"
-#include "netdir_err.h"
 #include "netdir_log.h"
 #include "netdir_iface.h"
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_unexp.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_unexp.c
index 506199a1e..c74e42fc3 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_unexp.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/netdir/src/netdir_unexp.c
@@ -40,7 +40,6 @@
 #include "netdir.h"
 #include "netdir_cq.h"
 #include "netdir_log.h"
-#include "netdir_err.h"
 #include "netdir_util.h"
 #include "netdir_queue.h"
 #include "netdir_iface.h"
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx.h
index 3485e3f59..9c761b4da 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx.h
@@ -76,7 +76,7 @@ extern struct fi_provider psmx_prov;
 
 extern int psmx_am_compat_mode;
 
-#define PSMX_VERSION	(FI_VERSION(1, 6))
+#define PSMX_VERSION	(FI_VERSION(1, 7))
 
 #define PSMX_OP_FLAGS	(FI_INJECT | FI_MULTI_RECV | FI_COMPLETION | \
 			 FI_TRIGGER | FI_INJECT_COMPLETE | \
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx_init.c
index daa3465b8..3e0a89e70 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx_init.c
@@ -53,7 +53,7 @@ struct psmx_env psmx_env = {
 
 static void psmx_init_env(void)
 {
-	if (getenv("OMPI_COMM_WORLD_RANK") || getenv("PMI_RANK"))
+	if (getenv("OMPI_COMM_WORLD_RANK") || getenv("PMI_RANK") || getenv("PMIX_RANK"))
 		psmx_env.name_server = 0;
 
 	fi_param_get_bool(&psmx_prov, "name_server", &psmx_env.name_server);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx_wait.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx_wait.c
index 470ce8d72..7e48c66c2 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx_wait.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm/src/psmx_wait.c
@@ -1,9 +1,9 @@
 /*
  * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
  *
- * This software is waitailable to you under a choice of one of two
+ * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, waitailable from the file
+ * General Public License (GPL) Version 2, available from the file
  * COPYING in the main directory of this source tree, or the
  * BSD license below:
  *
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/Makefile.include
index 167fa3485..7e4783ceb 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/Makefile.include
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/Makefile.include
@@ -28,130 +28,69 @@ _psm2_files += \
 
 _psm2_nodist_files = \
 	prov/psm2/src/psm2/psm_am.c \
-	prov/psm2/src/psm2/psm2_am.h \
-	prov/psm2/src/psm2/psm_am_internal.h \
 	prov/psm2/src/psm2/psm.c \
-	prov/psm2/src/psm2/psm2.h \
 	prov/psm2/src/psm2/psm_context.c \
-	prov/psm2/src/psm2/psm_context.h \
 	prov/psm2/src/psm2/psm_diags.c \
 	prov/psm2/src/psm2/psm_ep.c \
-	prov/psm2/src/psm2/psm_ep.h \
 	prov/psm2/src/psm2/psm_ep_connect.c \
 	prov/psm2/src/psm2/psm_error.c \
-	prov/psm2/src/psm2/psm_error.h \
-	prov/psm2/src/psm2/psm_help.h \
-	prov/psm2/src/psm2/psm_lock.h \
-	prov/psm2/src/psm2/psm_log.h \
 	prov/psm2/src/psm2/psm_memcpy.c \
 	prov/psm2/src/psm2/psm_mock.c \
 	prov/psm2/src/psm2/psm_mpool.c \
-	prov/psm2/src/psm2/psm_mpool.h \
 	prov/psm2/src/psm2/psm_mq.c \
-	prov/psm2/src/psm2/psm2_mq.h \
-	prov/psm2/src/psm2/psm_mq_internal.h \
 	prov/psm2/src/psm2/psm_mq_recv.c \
 	prov/psm2/src/psm2/psm_mq_utils.c \
 	prov/psm2/src/psm2/psm_perf.c \
-	prov/psm2/src/psm2/psm_perf.h \
 	prov/psm2/src/psm2/psm_stats.c \
-	prov/psm2/src/psm2/psm_stats.h \
 	prov/psm2/src/psm2/psm_sysbuf.c \
-	prov/psm2/src/psm2/psm_sysbuf.h \
 	prov/psm2/src/psm2/psm_timer.c \
-	prov/psm2/src/psm2/psm_timer.h \
-	prov/psm2/src/psm2/psm_user.h \
 	prov/psm2/src/psm2/psm_utils.c \
-	prov/psm2/src/psm2/psm_utils.h \
-	prov/psm2/src/psm2/ptl.h \
 	prov/psm2/src/psm2/psmi_wrappers.c \
-	prov/psm2/src/psm2/psmi_wrappers.h \
+	prov/psm2/src/psm2/psm2_hal.c \
 	prov/psm2/src/psm2/ptl_am/am_cuda_memhandle_cache.c \
-	prov/psm2/src/psm2/ptl_am/am_cuda_memhandle_cache.h \
 	prov/psm2/src/psm2/ptl_am/am_reqrep.c \
 	prov/psm2/src/psm2/ptl_am/am_reqrep_shmem.c \
 	prov/psm2/src/psm2/ptl_am/cmarwu.c \
-	prov/psm2/src/psm2/ptl_am/cmarw.h \
-	prov/psm2/src/psm2/ptl_am/psm_am_internal.h \
 	prov/psm2/src/psm2/ptl_am/ptl.c \
-	prov/psm2/src/psm2/ptl_am/ptl_fwd.h \
 	prov/psm2/src/psm2/ptl_ips/ips_crc32.c \
 	prov/psm2/src/psm2/ptl_ips/ips_epstate.c \
-	prov/psm2/src/psm2/ptl_ips/ips_epstate.h \
-	prov/psm2/src/psm2/ptl_ips/ipserror.c \
-	prov/psm2/src/psm2/ptl_ips/ipserror.h \
-	prov/psm2/src/psm2/ptl_ips/ips_expected_proto.h \
 	prov/psm2/src/psm2/ptl_ips/ips_opp_path_rec.c \
 	prov/psm2/src/psm2/ptl_ips/ips_path_rec.c \
-	prov/psm2/src/psm2/ptl_ips/ips_path_rec.h \
 	prov/psm2/src/psm2/ptl_ips/ips_proto.c \
-	prov/psm2/src/psm2/ptl_ips/ips_proto.h \
 	prov/psm2/src/psm2/ptl_ips/ips_proto_am.c \
-	prov/psm2/src/psm2/ptl_ips/ips_proto_am.h \
 	prov/psm2/src/psm2/ptl_ips/ips_proto_connect.c \
 	prov/psm2/src/psm2/ptl_ips/ips_proto_dump.c \
 	prov/psm2/src/psm2/ptl_ips/ips_proto_expected.c \
-	prov/psm2/src/psm2/ptl_ips/ips_proto_header.h \
-	prov/psm2/src/psm2/ptl_ips/ips_proto_help.h \
-	prov/psm2/src/psm2/ptl_ips/ips_proto_internal.h \
 	prov/psm2/src/psm2/ptl_ips/ips_proto_mq.c \
-	prov/psm2/src/psm2/ptl_ips/ips_proto_params.h \
 	prov/psm2/src/psm2/ptl_ips/ips_proto_recv.c \
 	prov/psm2/src/psm2/ptl_ips/ips_recvhdrq.c \
-	prov/psm2/src/psm2/ptl_ips/ips_recvhdrq.h \
 	prov/psm2/src/psm2/ptl_ips/ips_recvq.c \
-	prov/psm2/src/psm2/ptl_ips/ips_recvq.h \
 	prov/psm2/src/psm2/ptl_ips/ips_scb.c \
-	prov/psm2/src/psm2/ptl_ips/ips_scb.h \
-	prov/psm2/src/psm2/ptl_ips/ips_spio.c \
-	prov/psm2/src/psm2/ptl_ips/ips_spio.h \
-	prov/psm2/src/psm2/ptl_ips/ips_stats.h \
-	prov/psm2/src/psm2/ptl_ips/ips_subcontext.c \
-	prov/psm2/src/psm2/ptl_ips/ips_subcontext.h \
 	prov/psm2/src/psm2/ptl_ips/ips_tid.c \
-	prov/psm2/src/psm2/ptl_ips/ips_tid.h \
 	prov/psm2/src/psm2/ptl_ips/ips_tidcache.c \
-	prov/psm2/src/psm2/ptl_ips/ips_tidcache.h \
 	prov/psm2/src/psm2/ptl_ips/ips_tidflow.c \
-	prov/psm2/src/psm2/ptl_ips/ips_tidflow.h \
 	prov/psm2/src/psm2/ptl_ips/ips_writehdrq.c \
-	prov/psm2/src/psm2/ptl_ips/ips_writehdrq.h \
 	prov/psm2/src/psm2/ptl_ips/ptl.c \
-	prov/psm2/src/psm2/ptl_ips/ptl_fwd.h \
-	prov/psm2/src/psm2/ptl_ips/ptl_ips.h \
 	prov/psm2/src/psm2/ptl_ips/ptl_rcvthread.c \
 	prov/psm2/src/psm2/ptl_self/ptl.c \
-	prov/psm2/src/psm2/ptl_self/ptl_fwd.h \
 	prov/psm2/src/psm2/libuuid/psm_uuid.c \
-	prov/psm2/src/psm2/libuuid/psm_uuid.h \
 	prov/psm2/src/psm2/libuuid/parse.c \
 	prov/psm2/src/psm2/libuuid/pack.c \
 	prov/psm2/src/psm2/libuuid/unpack.c \
 	prov/psm2/src/psm2/libuuid/unparse.c \
 	prov/psm2/src/psm2/opa/opa_debug.c \
 	prov/psm2/src/psm2/opa/opa_dwordcpy-@psm2_ARCH@.c \
-	prov/psm2/src/psm2/opa/opa_i2cflash.c \
-	prov/psm2/src/psm2/opa/opa_proto.c \
 	prov/psm2/src/psm2/opa/opa_service.c \
 	prov/psm2/src/psm2/opa/opa_sysfs.c \
 	prov/psm2/src/psm2/opa/opa_syslog.c \
 	prov/psm2/src/psm2/opa/opa_time.c \
 	prov/psm2/src/psm2/opa/opa_utils.c \
-	prov/psm2/src/psm2/include/hfi1_deprecated.h \
-	prov/psm2/src/psm2/include/opa_byteorder.h \
-	prov/psm2/src/psm2/include/opa_common.h \
-	prov/psm2/src/psm2/include/opa_debug.h \
-	prov/psm2/src/psm2/include/opa_intf.h \
-	prov/psm2/src/psm2/include/opa_queue.h \
-	prov/psm2/src/psm2/include/opa_revision.h \
-	prov/psm2/src/psm2/include/opa_service.h \
-	prov/psm2/src/psm2/include/opa_udebug.h \
-	prov/psm2/src/psm2/include/opa_user.h \
-	prov/psm2/src/psm2/include/psm2_mock_testing.h \
-	prov/psm2/src/psm2/include/rbtree.h \
-	prov/psm2/src/psm2/include/linux-@psm2_ARCH@/bit_ops.h \
-	prov/psm2/src/psm2/include/linux-@psm2_ARCH@/sysdep.h \
-	prov/psm2/src/psm2/mpspawn/mpspawn_stats.h
+	prov/psm2/src/psm2/psm_hal_gen1/psm_hal_gen1.c \
+	prov/psm2/src/psm2/psm_hal_gen1/opa_i2cflash_gen1.c \
+	prov/psm2/src/psm2/psm_hal_gen1/opa_proto_gen1.c \
+	prov/psm2/src/psm2/psm_hal_gen1/opa_service_gen1.c \
+	prov/psm2/src/psm2/psm_hal_gen1/opa_utils_gen1.c \
+	prov/psm2/src/psm2/psm_hal_gen1/psm_gdrcpy.c
 
 if HAVE_PSM2_X86_64
 _psm2_nodist_files += \
@@ -166,8 +105,10 @@ _psm2_cppflags = \
 	-I$(top_srcdir)/prov/psm2/src/psm2/ptl_ips \
 	-I$(top_srcdir)/prov/psm2/src/psm2/ptl_am \
 	-I$(top_srcdir)/prov/psm2/src/psm2/ptl_self \
+	-I$(top_srcdir)/prov/psm2/src/psm2/psm_hal_gen1 \
 	-DNVALGRIND
 
+
 endif HAVE_PSM2_SRC
 
 if HAVE_PSM2_DL
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/configure.m4 b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/configure.m4
index db0d927f3..844919d23 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/configure.m4
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/configure.m4
@@ -18,6 +18,9 @@ AC_DEFUN([FI_PSM2_CONFIGURE],[
 	 AC_DEFINE_UNQUOTED([HAVE_PSM2_SRC], $have_psm2_src, [PSM2 source is built-in])
 	 psm2_happy=0
 	 have_psm2_am_register_handlers_2=1
+	 have_psm2_mq_fp_msg=1
+	 have_psm2_mq_req_user=1
+	 have_psm2_info_query=1
 	 AS_IF([test x"$enable_psm2" != x"no"],
 	       [AS_IF([test x$have_psm2_src = x0],
 		      [
@@ -25,7 +28,7 @@ AC_DEFUN([FI_PSM2_CONFIGURE],[
 			FI_CHECK_PACKAGE([psm2],
 					 [psm2.h],
 					 [psm2],
-					 [psm2_am_register_handlers_2],
+					 [psm2_info_query],
 					 [],
 					 [$psm2_PREFIX],
 					 [$psm2_LIBDIR],
@@ -33,12 +36,54 @@ AC_DEFUN([FI_PSM2_CONFIGURE],[
 					 [psm2_happy=0])
 			AS_IF([test x$psm2_happy = x0],
 			      [
-				$as_echo "$as_me: recheck psm2 with reduced feature set."
+				$as_echo "$as_me: recheck psm2 without psm2_info_query."
+				have_psm2_info_query=0
+				FI_CHECK_PACKAGE([psm2],
+						 [psm2.h],
+						 [psm2],
+						 [psm2_mq_ipeek_dequeue_multi],
+						 [],
+						 [$psm2_PREFIX],
+						 [$psm2_LIBDIR],
+						 [psm2_happy=1],
+						 [psm2_happy=0])
+			      ])
+			AS_IF([test x$psm2_happy = x0],
+			      [
+				$as_echo "$as_me: recheck psm2 without psm2_mq_ipeek_dequeue_multi."
+				have_psm2_mq_req_user=0
+				FI_CHECK_PACKAGE([psm2],
+						 [psm2.h],
+						 [psm2],
+						 [psm2_mq_fp_msg],
+						 [],
+						 [$psm2_PREFIX],
+						 [$psm2_LIBDIR],
+						 [psm2_happy=1],
+						 [psm2_happy=0])
+			      ])
+			AS_IF([test x$psm2_happy = x0],
+			      [
+				$as_echo "$as_me: recheck psm2 without psm2_mq_fp_msg."
+				have_psm2_mq_fp_msg=0
+				FI_CHECK_PACKAGE([psm2],
+						 [psm2.h],
+						 [psm2],
+						 [psm2_am_register_handlers_2],
+						 [],
+						 [$psm2_PREFIX],
+						 [$psm2_LIBDIR],
+						 [psm2_happy=1],
+						 [psm2_happy=0])
+			      ])
+			AS_IF([test x$psm2_happy = x0],
+			      [
+				$as_echo "$as_me: recheck psm2 without psm2_am_register_handlers_2."
 				have_psm2_am_register_handlers_2=0
 				FI_CHECK_PACKAGE([psm2],
 						 [psm2.h],
 						 [psm2],
-						 [psm2_ep_epid_lookup2],
+						 [psm2_ep_disconnect2],
 						 [],
 						 [$psm2_PREFIX],
 						 [$psm2_LIBDIR],
@@ -48,8 +93,11 @@ AC_DEFUN([FI_PSM2_CONFIGURE],[
 		      ],
 		      [
 			dnl build with PSM2 source code included
-			psm2_CPPFLAGS="-msse4.2"
 			psm2_happy=1
+			have_psm2_mq_req_user=1
+			AS_IF([test $cc_basename = icc],
+			      [psm2_CPPFLAGS="-march=core-avx2"],
+			      [psm2_CPPFLAGS="-mavx2"])
 			AC_COMPILE_IFELSE([AC_LANG_PROGRAM(
 						[[#include <rdma/hfi/hfi1_user.h>]],
 						[[
@@ -76,30 +124,43 @@ AC_DEFUN([FI_PSM2_CONFIGURE],[
 							psm2_happy=0
 						])])
 			AS_IF([test x$psm2_happy = x1],
-			      AS_IF([test -f $with_psm2_src/libpsm2.spec.in],
-				    [AS_IF([grep -q psm2_am_register_handlers_2 $with_psm2_src/psm2_am.h],
-					   [
-						$as_echo "$as_me: creating links for PSM2 source code."
-						mkdir -p $srcdir/prov/psm2/src/psm2
-						cp -srf $with_psm2_src/* $srcdir/prov/psm2/src/psm2/
-						ln -sf ../include/rbtree.h $srcdir/prov/psm2/src/psm2/ptl_ips/
-						ln -sf ../include/rbtree.h $srcdir/prov/psm2/src/psm2/ptl_am/
-					   ],
-					   [
-						$as_echo "$as_me: PSM2 source under <$with_psm2_src> is too old."
-						psm2_happy=0
-					   ])
-				   ],
-				   [
-					$as_echo "$as_me: no PSM2 source under <$with_psm2_src>."
+			      [AS_IF([test -f $with_psm2_src/psm_hal_gen1/opa_common_gen1.h],
+				     [
+					$as_echo "$as_me: creating links for PSM2 source code."
+					mkdir -p $srcdir/prov/psm2/src/psm2
+					cp -srf $with_psm2_src/* $srcdir/prov/psm2/src/psm2/
+					ln -sf ../include/rbtree.h $srcdir/prov/psm2/src/psm2/ptl_ips/
+					ln -sf ../include/rbtree.h $srcdir/prov/psm2/src/psm2/ptl_am/
+
+					hal_decl_file=$srcdir/prov/psm2/src/psm2/psm2_hal_inlines_d.h
+					hal_impl_file=$srcdir/prov/psm2/src/psm2/psm2_hal_inlines_i.h
+					$as_echo "#define PSMI_HAL_INST_CNT 1" >$hal_decl_file
+					$as_echo "#define PSMI_HAL_INLINE inline" >>$hal_decl_file
+					$as_echo "#define PSMI_HAL_CAT_INL_SYM(KERNEL) hfp_gen1_##KERNEL" >>$hal_decl_file
+					$as_echo "#include \"psm2_hal_inline_t.h\"" >>$hal_decl_file
+					$as_echo "#include \"psm_hal_gen1/psm_hal_inline_i.h\"" >$hal_impl_file
+				     ],
+				     [
+					$as_echo "$as_me: PSM2 source under <$with_psm2_src> is missing or too old."
+					$as_echo "$as_me: Please get the latest source from https://github.com/intel/opa-psm2."
 					psm2_happy=0
-				   ]))
+				     ])
+			      ])
 		      ])
 	       ])
 	 AS_IF([test $psm2_happy -eq 1], [$1], [$2])
 	 AC_DEFINE_UNQUOTED([HAVE_PSM2_AM_REGISTER_HANDLERS_2],
 			    $have_psm2_am_register_handlers_2,
 			    [psm2_am_register_handlers_2 function is present])
+	 AC_DEFINE_UNQUOTED([HAVE_PSM2_MQ_FP_MSG],
+			    $have_psm2_mq_fp_msg,
+			    [psm2_mq_fp_msg function is present])
+	 AC_DEFINE_UNQUOTED([HAVE_PSM2_MQ_REQ_USER],
+			    $have_psm2_mq_req_user,
+			    [psm2_mq_ipeek_dequeue_multi function is present])
+	 AC_DEFINE_UNQUOTED([HAVE_PSM2_INFO_QUERY],
+			    $have_psm2_info_query,
+			    [psm2_info_query function is present])
 ])
 
 AC_ARG_WITH([psm2-src],
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct.h
new file mode 100644
index 000000000..620edace5
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct.h
@@ -0,0 +1,42 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2015-2016 Los Alamos National Security, LLC.
+ *                         All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_H
+#define FI_DIRECT_H
+
+/*
+ * use default definitions
+ */
+
+#endif /* FI_DIRECT_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_atomic.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_atomic.h
new file mode 100644
index 000000000..6bbd6847f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_atomic.h
@@ -0,0 +1,269 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_ATOMIC_H
+#define FI_DIRECT_ATOMIC_H
+
+#define FABRIC_DIRECT_ATOMIC
+
+ssize_t psmx2_atomic_write(
+		struct fid_ep *ep,
+		const void *buf, size_t count, void *desc,
+		fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op, void *context);
+
+ssize_t psmx2_atomic_writev(
+		struct fid_ep *ep,
+		const struct fi_ioc *iov, void **desc, size_t count,
+		fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op, void *context);
+
+ssize_t psmx2_atomic_writemsg(
+		struct fid_ep *ep,
+		const struct fi_msg_atomic *msg, uint64_t flags);
+
+ssize_t psmx2_atomic_inject(
+		struct fid_ep *ep, const void *buf, size_t count,
+		fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op);
+
+ssize_t psmx2_atomic_readwrite(
+		struct fid_ep *ep,
+		const void *buf, size_t count, void *desc,
+		void *result, void *result_desc,
+		fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op, void *context);
+
+ssize_t psmx2_atomic_readwritev(
+		struct fid_ep *ep,
+		const struct fi_ioc *iov, void **desc, size_t count,
+		struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op, void *context);
+
+ssize_t psmx2_atomic_readwritemsg(
+		struct fid_ep *ep,
+		const struct fi_msg_atomic *msg,
+		struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		uint64_t flags);
+
+ssize_t psmx2_atomic_comparewrite(
+		struct fid_ep *ep,
+		const void *buf, size_t count, void *desc,
+		const void *compare, void *compare_desc,
+		void *result, void *result_desc,
+		fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op, void *context);
+
+ssize_t psmx2_atomic_compareweitev(
+		struct fid_ep *ep,
+		const struct fi_ioc *iov, void **desc, size_t count,
+		const struct fi_ioc *comparev, void **compare_desc, size_t compare_count,
+		struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op, void *context);
+
+ssize_t psmx2_atomic_comparewritemsg(
+		struct fid_ep *ep,
+		const struct fi_msg_atomic *msg,
+		const struct fi_ioc *comparev, void **compare_desc, size_t compare_count,
+		struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		uint64_t flags);
+
+int psmx2_atomic_writevalid(
+		struct fid_ep *ep,
+		enum fi_datatype datatype, enum fi_op op, size_t *count);
+
+int psmx2_atomic_readwritevalid(
+		struct fid_ep *ep,
+		enum fi_datatype datatype, enum fi_op op, size_t *count);
+
+int psmx2_atomic_comparewritevalid(
+		struct fid_ep *ep,
+		enum fi_datatype datatype, enum fi_op op, size_t *count);
+
+int psmx2_query_atomic(
+		struct fid_domain *domain,
+		enum fi_datatype datatype, enum fi_op op,
+		struct fi_atomic_attr *attr, uint64_t flags);
+
+
+static inline ssize_t
+fi_atomic(struct fid_ep *ep,
+	  const void *buf, size_t count, void *desc,
+	  fi_addr_t dest_addr,
+	  uint64_t addr, uint64_t key,
+	  enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	return psmx2_atomic_write(ep, buf, count, desc, dest_addr, addr, key,
+			datatype, op, context);
+}
+
+static inline ssize_t
+fi_atomicv(struct fid_ep *ep,
+	   const struct fi_ioc *iov, void **desc, size_t count,
+	   fi_addr_t dest_addr,
+	   uint64_t addr, uint64_t key,
+	   enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	return psmx2_atomic_writev(ep, iov, desc, count, dest_addr, addr, key,
+			datatype, op, context);
+}
+
+static inline ssize_t
+fi_atomicmsg(struct fid_ep *ep,
+	     const struct fi_msg_atomic *msg, uint64_t flags)
+{
+	return psmx2_atomic_writemsg(ep, msg, flags);
+}
+
+static inline ssize_t
+fi_inject_atomic(struct fid_ep *ep, const void *buf, size_t count,
+		 fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		 enum fi_datatype datatype, enum fi_op op)
+{
+	return psmx2_atomic_inject(ep, buf, count, dest_addr, addr,
+			key, datatype, op);
+}
+
+static inline ssize_t
+fi_fetch_atomic(struct fid_ep *ep,
+		const void *buf, size_t count, void *desc,
+		void *result, void *result_desc,
+		fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	return psmx2_atomic_readwrite(ep, buf, count, desc, result, result_desc,
+			dest_addr, addr, key, datatype, op, context);
+}
+
+static inline ssize_t
+fi_fetch_atomicv(struct fid_ep *ep,
+		 const struct fi_ioc *iov, void **desc, size_t count,
+		 struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		 fi_addr_t dest_addr,
+		 uint64_t addr, uint64_t key,
+		 enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	return psmx2_atomic_readwritev(ep, iov, desc, count,
+			resultv, result_desc, result_count,
+			dest_addr, addr, key, datatype, op, context);
+}
+
+static inline ssize_t
+fi_fetch_atomicmsg(struct fid_ep *ep,
+		   const struct fi_msg_atomic *msg,
+		   struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		   uint64_t flags)
+{
+	return psmx2_atomic_readwritemsg(ep, msg, resultv, result_desc,
+			result_count, flags);
+}
+
+static inline ssize_t
+fi_compare_atomic(struct fid_ep *ep,
+		  const void *buf, size_t count, void *desc,
+		  const void *compare, void *compare_desc,
+		  void *result, void *result_desc,
+		  fi_addr_t dest_addr,
+		  uint64_t addr, uint64_t key,
+		  enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	return psmx2_atomic_compwrite(ep, buf, count, desc,
+			compare, compare_desc, result, result_desc,
+			dest_addr, addr, key, datatype, op, context);
+}
+
+static inline ssize_t
+fi_compare_atomicv(struct fid_ep *ep,
+		   const struct fi_ioc *iov, void **desc, size_t count,
+		   const struct fi_ioc *comparev, void **compare_desc, size_t compare_count,
+		   struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		   fi_addr_t dest_addr,
+		   uint64_t addr, uint64_t key,
+		   enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	return psmx2_atomic_compwritev(ep, iov, desc, count,
+			comparev, compare_desc, compare_count,
+			resultv, result_desc, result_count,
+			dest_addr, addr, key, datatype, op, context);
+}
+
+static inline ssize_t
+fi_compare_atomicmsg(struct fid_ep *ep,
+		     const struct fi_msg_atomic *msg,
+		     const struct fi_ioc *comparev, void **compare_desc, size_t compare_count,
+		     struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		     uint64_t flags)
+{
+	return psmx2_atomic_compwritemsg(ep, msg,
+			comparev, compare_desc, compare_count,
+			resultv, result_desc, result_count, flags);
+}
+
+static inline int
+fi_atomicvalid(struct fid_ep *ep,
+	       enum fi_datatype datatype, enum fi_op op, size_t *count)
+{
+	return psmx2_atomic_writevalid(ep, datatype, op, count);
+}
+
+static inline int
+fi_fetch_atomicvalid(struct fid_ep *ep,
+		     enum fi_datatype datatype, enum fi_op op, size_t *count)
+{
+	return psmx2_atomic_readwritevalid(ep, datatype, op, count);
+}
+
+static inline int
+fi_compare_atomicvalid(struct fid_ep *ep,
+		       enum fi_datatype datatype, enum fi_op op, size_t *count)
+{
+	return psmx2_atomic_compwritevalid(ep, datatype, op, count);
+}
+
+static inline int
+fi_query_atomic(struct fid_domain *domain,
+		enum fi_datatype datatype, enum fi_op op,
+		struct fi_atomic_attr *attr, uint64_t flags)
+{
+	return psmx2_query_atomic(domain, datatype, op, attr, flags);
+}
+
+#endif /* FI_DIRECT_ATOMIC_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_atomic_def.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_atomic_def.h
new file mode 100644
index 000000000..c8a5d3ede
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_atomic_def.h
@@ -0,0 +1,40 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_ATOMIC_DEF_H
+#define FI_DIRECT_ATOMIC_DEF_H
+
+/*
+ * use the default definitions
+ */
+
+#endif /* FI_DIRECT_ATOMIC_DEF_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_cm.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_cm.h
new file mode 100644
index 000000000..a337c5d53
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_cm.h
@@ -0,0 +1,97 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_CM_H
+#define FI_DIRECT_CM_H
+
+#define FABRIC_DIRECT_CM
+
+int psmx2_cm_getname(fid_t fid, void *addr, size_t *addrlen);
+
+
+static inline int fi_setname(fid_t fid, void *addr, size_t addrlen)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int fi_getname(fid_t fid, void *addr, size_t *addrlen)
+{
+	return psmx2_cm_getname(fid, addr, addrlen);
+}
+
+static inline int fi_getpeer(struct fid_ep *ep, void *addr, size_t *addrlen)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int fi_listen(struct fid_pep *pep)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_connect(struct fid_ep *ep, const void *addr,
+	   const void *param, size_t paramlen)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_accept(struct fid_ep *ep, const void *param, size_t paramlen)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_reject(struct fid_pep *pep, fid_t handle,
+	  const void *param, size_t paramlen)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int fi_shutdown(struct fid_ep *ep, uint64_t flags)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int fi_join(struct fid_ep *ep, const void *addr, uint64_t flags,
+			  struct fid_mc **mc, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+static inline fi_addr_t fi_mc_addr(struct fid_mc *mc)
+{
+	return -FI_ENOSYS;
+}
+
+#endif /* FI_DIRECT_CM_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_domain.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_domain.h
new file mode 100644
index 000000000..6d5b7247d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_domain.h
@@ -0,0 +1,266 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_DOMAIN_H
+#define FI_DIRECT_DOMAIN_H
+
+#define FABRIC_DIRECT_DOMAIN
+
+int psmx2_domain_open(
+		struct fid_fabric *fabric, struct fi_info *info,
+		struct fid_domain **domain, void *context);
+
+int psmx2_cq_open(
+		struct fid_domain *domain, struct fi_cq_attr *attr,
+		struct fid_cq **cq, void *context);
+
+int psmx2_cntr_open(
+		struct fid_domain *domain, struct fi_cntr_attr *attr,
+		struct fid_cntr **cntr, void *context);
+
+int psmx2_wait_open(
+		struct fid_fabric *fabric, struct fi_wait_attr *attr,
+		struct fid_wait **waitset);
+
+int psmx2_mr_reg(
+		struct fid *fid, const void *buf, size_t len,
+		uint64_t access, uint64_t offset, uint64_t requested_key,
+		uint64_t flags, struct fid_mr **mr, void *context);
+
+int psmx2_mr_regv(
+		struct fid *fid, const struct iovec *iov,
+		size_t count, uint64_t access,
+		uint64_t offset, uint64_t requested_key,
+		uint64_t flags, struct fid_mr **mr, void *context);
+
+int psmx2_mr_regattr(
+		struct fid *fid, const struct fi_mr_attr *attr,
+		uint64_t flags, struct fid_mr **mr);
+
+int psmx2_mr_bind(struct fid *fid, struct fid *bfid, uint64_t flags);
+
+int psmx2_av_open(
+		struct fid_domain *domain, struct fi_av_attr *attr,
+		struct fid_av **av, void *context);
+
+int psmx2_av_bind(struct fid *fid, struct fid *bfid, uint64_t flags);
+
+int psmx2_av_insert(
+		struct fid_av *av, const void *addr, size_t count,
+		fi_addr_t *fi_addr, uint64_t flags, void *context);
+
+int psmx2_av_remove(
+		struct fid_av *av, fi_addr_t *fi_addr, size_t count,
+		uint64_t flags);
+
+int psmx2_av_lookup(
+		struct fid_av *av, fi_addr_t fi_addr, void *addr,
+		size_t *addrlen);
+
+const char *psmx2_av_straddr(
+		struct fid_av *av, const void *addr, char *buf, size_t *len);
+
+
+static inline int
+fi_domain(struct fid_fabric *fabric, struct fi_info *info,
+	   struct fid_domain **domain, void *context)
+{
+	return psmx2_domain_open(fabric, info, domain, context);
+}
+
+static inline int
+fi_domain_bind(struct fid_domain *domain, struct fid *fid, uint64_t flags)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
+	   struct fid_cq **cq, void *context)
+{
+	return psmx2_cq_open(domain, attr, cq, context);
+}
+
+static inline int
+fi_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
+	      struct fid_cntr **cntr, void *context)
+{
+	return psmx2_cntr_open(domain, attr, cntr, context);
+}
+
+static inline int
+fi_wait_open(struct fid_fabric *fabric, struct fi_wait_attr *attr,
+	     struct fid_wait **waitset)
+{
+	return psmx2_wait_open(fabric, attr, waitset);
+}
+
+static inline int
+fi_poll_open(struct fid_domain *domain, struct fi_poll_attr *attr,
+	     struct fid_poll **pollset)
+{
+	return domain->ops->poll_open(domain, attr, pollset);
+}
+
+static inline int
+fi_mr_reg(struct fid_domain *domain, const void *buf, size_t len,
+	  uint64_t access, uint64_t offset, uint64_t requested_key,
+	  uint64_t flags, struct fid_mr **mr, void *context)
+{
+	return psmx2_mr_reg(&domain->fid, buf, len, access, offset,
+			       requested_key, flags, mr, context);
+}
+
+static inline int
+fi_mr_regv(struct fid_domain *domain, const struct iovec *iov,
+			size_t count, uint64_t access,
+			uint64_t offset, uint64_t requested_key,
+			uint64_t flags, struct fid_mr **mr, void *context)
+{
+	return psmx2_mr_regv(&domain->fid, iov, count, access,
+			offset, requested_key, flags, mr, context);
+}
+
+static inline int
+fi_mr_regattr(struct fid_domain *domain, const struct fi_mr_attr *attr,
+			uint64_t flags, struct fid_mr **mr)
+{
+	return psmx2_mr_regattr(&domain->fid, attr, flags, mr);
+}
+
+static inline void *fi_mr_desc(struct fid_mr *mr)
+{
+	return mr->mem_desc;
+}
+
+static inline uint64_t fi_mr_key(struct fid_mr *mr)
+{
+	return mr->key;
+}
+
+static inline int
+fi_mr_raw_attr(struct fid_mr *mr, uint64_t *base_addr,
+	       uint8_t *raw_key, size_t *key_size, uint64_t flags)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_mr_map_raw(struct fid_domain *domain, uint64_t base_addr,
+	      uint8_t *raw_key, size_t key_size, uint64_t *key, uint64_t flags)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_mr_unmap_key(struct fid_domain *domain, uint64_t key)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int fi_mr_bind(struct fid_mr *mr, struct fid *bfid, uint64_t flags)
+{
+	return psmx2_mr_bind(&mr->fid, bfid, flags);
+}
+
+static inline int
+fi_mr_refresh(struct fid_mr *mr, const struct iovec *iov, size_t count,
+	      uint64_t flags)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int fi_mr_enable(struct fid_mr *mr)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
+	   struct fid_av **av, void *context)
+{
+	return psmx2_av_open(domain, attr, av, context);
+}
+
+static inline int
+fi_av_bind(struct fid_av *av, struct fid *fid, uint64_t flags)
+{
+	return psmx2_av_bind(&av->fid, fid, flags);
+}
+
+static inline int
+fi_av_insert(struct fid_av *av, const void *addr, size_t count,
+	     fi_addr_t *fi_addr, uint64_t flags, void *context)
+{
+	return psmx2_av_insert(av, addr, count, fi_addr, flags, context);
+}
+
+static inline int
+fi_av_insertsvc(struct fid_av *av, const char *node, const char *service,
+		fi_addr_t *fi_addr, uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_av_insertsym(struct fid_av *av, const char *node, size_t nodecnt,
+		const char *service, size_t svccnt,
+		fi_addr_t *fi_addr, uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_av_remove(struct fid_av *av, fi_addr_t *fi_addr, size_t count, uint64_t flags)
+{
+	return psmx2_av_remove(av, fi_addr, count, flags);
+}
+
+static inline int
+fi_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr, size_t *addrlen)
+{
+        return psmx2_av_lookup(av, fi_addr, addr, addrlen);
+}
+
+static inline const char *
+fi_av_straddr(struct fid_av *av, const void *addr, char *buf, size_t *len)
+{
+	return psmx2_av_straddr(av, addr, buf, len);
+}
+
+static inline fi_addr_t
+fi_rx_addr(fi_addr_t fi_addr, int rx_index, int rx_ctx_bits)
+{
+	return (fi_addr_t) (((uint64_t) rx_index << (64 - rx_ctx_bits)) | fi_addr);
+}
+
+#endif /* FI_DIRECT_DOMAIN_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_endpoint.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_endpoint.h
new file mode 100644
index 000000000..943e8368f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_endpoint.h
@@ -0,0 +1,282 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_ENDPOINT_H
+#define FI_DIRECT_ENDPOINT_H
+
+#define FABRIC_DIRECT_ENDPOINT
+
+int psmx2_ep_open(
+		struct fid_domain *domain, struct fi_info *info,
+		struct fid_ep **ep, void *context);
+
+int psmx2_sep_open(
+		struct fid_domain *domain, struct fi_info *info,
+		struct fid_ep **sep, void *context);
+
+int psmx2_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags);
+
+int psmx2_sep_bind(struct fid *fid, struct fid *bfid, uint64_t flags);
+
+int psmx2_ep_control(fid_t fid, int command, void *arg);
+
+ssize_t psmx2_ep_cancel(fid_t fid, void *context);
+
+int psmx2_ep_setopt(
+		fid_t fid, int level, int optname, const void *optval,
+		size_t optlen);
+
+int psmx2_ep_getopt(
+		fid_t fid, int level, int optname, void *optval,
+		size_t *optlen);
+
+int psmx2_tx_context(
+		struct fid_ep *ep, int index, struct fi_tx_attr *attr,
+		struct fid_ep **tx_ep, void *context);
+
+int psmx2_rx_context(
+		struct fid_ep *ep, int index, struct fi_rx_attr *attr,
+		struct fid_ep **rx_ep, void *context);
+
+ssize_t psmx2_rx_size_left(struct fid_ep *ep);
+
+ssize_t psmx2_tx_size_left(struct fid_ep *ep);
+
+int psmx2_stx_ctx(
+		struct fid_domain *domain, struct fi_tx_attr *attr,
+		struct fid_stx **stx, void *context);
+
+ssize_t psmx2_recv(
+		struct fid_ep *ep, void *buf, size_t len, void *desc,
+		fi_addr_t src_addr, void *context);
+
+ssize_t psmx2_recvv(
+		struct fid_ep *ep, const struct iovec *iov, void **desc,
+		size_t count, fi_addr_t src_addr, void *context);
+
+ssize_t psmx2_recvmsg(
+		struct fid_ep *ep, const struct fi_msg *msg, uint64_t flags);
+
+ssize_t psmx2_send(
+		struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		fi_addr_t dest_addr, void *context);
+
+ssize_t psmx2_sendv(
+		struct fid_ep *ep, const struct iovec *iov, void **desc,
+		size_t count, fi_addr_t dest_addr, void *context);
+
+ssize_t psmx2_sendmsg(struct fid_ep *ep, const struct fi_msg *msg, uint64_t flags);
+
+ssize_t psmx2_inject(
+		struct fid_ep *ep, const void *buf, size_t len, fi_addr_t dest_addr);
+
+ssize_t psmx2_senddata(
+		struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		uint64_t data, fi_addr_t dest_addr, void *context);
+
+ssize_t psmx2_injectdata(
+		struct fid_ep *ep, const void *buf, size_t len,
+		uint64_t data, fi_addr_t dest_addr);
+
+
+static inline int
+fi_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
+	     struct fid_pep **pep, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int
+fi_endpoint(struct fid_domain *domain, struct fi_info *info,
+	    struct fid_ep **ep, void *context)
+{
+	return psmx2_ep_open(domain, info, ep, context);
+}
+
+static inline int
+fi_scalable_ep(struct fid_domain *domain, struct fi_info *info,
+	    struct fid_ep **sep, void *context)
+{
+	return psmx2_sep_open(domain, info, sep, context);
+}
+
+static inline int fi_ep_bind(struct fid_ep *ep, struct fid *bfid, uint64_t flags)
+{
+	return psmx2_ep_bind(&ep->fid, bfid, flags);
+}
+
+static inline int fi_pep_bind(struct fid_pep *pep, struct fid *bfid, uint64_t flags)
+{
+	return -FI_ENOSYS;
+}
+
+static inline int fi_scalable_ep_bind(struct fid_ep *sep, struct fid *bfid, uint64_t flags)
+{
+	return psmx2_sep_bind(&sep->fid, bfid, flags);
+}
+
+static inline int fi_enable(struct fid_ep *ep)
+{
+	return psmx2_ep_control(&ep->fid, FI_ENABLE, NULL);
+}
+
+static inline ssize_t fi_cancel(fid_t fid, void *context)
+{
+	return psmx2_ep_cancel(fid, context);
+}
+
+static inline int
+fi_setopt(fid_t fid, int level, int optname,
+	  const void *optval, size_t optlen)
+{
+	return psmx2_ep_setopt(fid, level, optname, optval, optlen);
+}
+
+static inline int
+fi_getopt(fid_t fid, int level, int optname,
+	  void *optval, size_t *optlen)
+{
+	return psmx2_ep_getopt(fid, level, optname, optval, optlen);
+}
+
+static inline int fi_ep_alias(struct fid_ep *ep, struct fid_ep **alias_ep,
+			      uint64_t flags)
+{
+	int ret;
+	struct fid *fid;
+	ret = fi_alias(&ep->fid, &fid, flags);
+	if (!ret)
+		*alias_ep = container_of(fid, struct fid_ep, fid);
+	return ret;
+}
+
+static inline int
+fi_tx_context(struct fid_ep *ep, int index, struct fi_tx_attr *attr,
+	      struct fid_ep **tx_ep, void *context)
+{
+	return psmx2_tx_ctx(ep, index, attr, tx_ep, context);
+}
+
+static inline int
+fi_rx_context(struct fid_ep *ep, int index, struct fi_rx_attr *attr,
+	      struct fid_ep **rx_ep, void *context)
+{
+	return psmx2_rx_ctx(ep, index, attr, rx_ep, context);
+}
+
+static inline FI_DEPRECATED_FUNC ssize_t
+fi_rx_size_left(struct fid_ep *ep)
+{
+	return psmx2_rx_size_left(ep);
+}
+
+static inline FI_DEPRECATED_FUNC ssize_t
+fi_tx_size_left(struct fid_ep *ep)
+{
+	return psmx2_tx_size_left(ep);
+}
+
+static inline int
+fi_stx_context(struct fid_domain *domain, struct fi_tx_attr *attr,
+	       struct fid_stx **stx, void *context)
+{
+	return psmx2_stx_ctx(domain, attr, stx, context);
+}
+
+static inline int
+fi_srx_context(struct fid_domain *domain, struct fi_rx_attr *attr,
+	       struct fid_ep **rx_ep, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+static inline ssize_t
+fi_recv(struct fid_ep *ep, void *buf, size_t len, void *desc, fi_addr_t src_addr,
+	void *context)
+{
+	return psmx2_recv(ep, buf, len, desc, src_addr, context);
+}
+
+static inline ssize_t
+fi_recvv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+	 size_t count, fi_addr_t src_addr, void *context)
+{
+	return psmx2_recvv(ep, iov, desc, count, src_addr, context);
+}
+
+static inline ssize_t
+fi_recvmsg(struct fid_ep *ep, const struct fi_msg *msg, uint64_t flags)
+{
+	return psmx2_recvmsg(ep, msg, flags);
+}
+
+static inline ssize_t
+fi_send(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+	fi_addr_t dest_addr, void *context)
+{
+	return psmx2_send(ep, buf, len, desc, dest_addr, context);
+}
+
+static inline ssize_t
+fi_sendv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+	 size_t count, fi_addr_t dest_addr, void *context)
+{
+	return psmx2_sendv(ep, iov, desc, count, dest_addr, context);
+}
+
+static inline ssize_t
+fi_sendmsg(struct fid_ep *ep, const struct fi_msg *msg, uint64_t flags)
+{
+	return psmx2_sendmsg(ep, msg, flags);
+}
+
+static inline ssize_t
+fi_inject(struct fid_ep *ep, const void *buf, size_t len, fi_addr_t dest_addr)
+{
+	return psmx2_inject(ep, buf, len, dest_addr);
+}
+
+static inline ssize_t
+fi_senddata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+	      uint64_t data, fi_addr_t dest_addr, void *context)
+{
+	return psmx2_senddata(ep, buf, len, desc, data, dest_addr, context);
+}
+
+static inline ssize_t
+fi_injectdata(struct fid_ep *ep, const void *buf, size_t len,
+		uint64_t data, fi_addr_t dest_addr)
+{
+	return psmx2_injectdata(ep, buf, len, data, dest_addr);
+}
+
+#endif /* FI_DIRECT_ENDPOINT */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_eq.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_eq.h
new file mode 100644
index 000000000..c3c43358a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_eq.h
@@ -0,0 +1,230 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_EQ_H
+#define FI_DIRECT_EQ_H
+
+#define FABRIC_DIRECT_EQ
+
+int psmx2_wait_trywait(struct fid_fabric *fabric, struct fid **fids, int count);
+
+int psmx2_wait_wait(struct fid_wait *waitset, int timeout);
+
+ssize_t psmx2_cq_read(struct fid_cq *cq, void *buf, size_t count);
+
+ssize_t psmx2_cq_readfrom(
+		struct fid_cq *cq, void *buf, size_t count,
+		fi_addr_t *src_addr);
+
+ssize_t psmx2_cq_readerr(
+		struct fid_cq *cq, struct fi_cq_err_entry *buf,
+		uint64_t flags);
+
+ssize_t psmx2_cq_sread(
+		struct fid_cq *cq, void *buf, size_t count,
+		const void *cond, int timeout);
+
+ssize_t psmx2_cq_sreadfrom(
+		struct fid_cq *cq, void *buf, size_t count,
+		fi_addr_t *src_addr, const void *cond, int timeout);
+
+int psmx2_cq_signal(struct fid_cq *cq);
+
+const char *psmx2_cq_strerror(
+		struct fid_cq *cq, int prov_errno,
+		const void *err_data, char *buf, size_t len);
+
+uint64_t psmx2_cntr_read(struct fid_cntr *cntr);
+uint64_t psmx2_cntr_readerr(struct fid_cntr *cntr);
+int psmx2_cntr_add(struct fid_cntr *cntr, uint64_t value);
+int psmx2_cntr_adderr(struct fid_cntr *cntr, uint64_t value);
+int psmx2_cntr_set(struct fid_cntr *cntr, uint64_t value);
+int psmx2_cntr_seterr(struct fid_cntr *cntr, uint64_t value);
+int psmx2_cntr_wait(struct fid_cntr *cntr, uint64_t threshold, int timeout);
+
+
+static inline int
+fi_trywait(struct fid_fabric *fabric, struct fid **fids, int count)
+{
+	return psmx2_wait_trywait(fabric, fids, count);
+}
+
+static inline int
+fi_wait(struct fid_wait *waitset, int timeout)
+{
+	return psmx2_wait_wait(waitset, timeout);
+}
+
+/*
+ * pollset and eq use util functions
+ */
+
+static inline int
+fi_poll(struct fid_poll *pollset, void **context, int count)
+{
+	return pollset->ops->poll(pollset, context, count);
+}
+
+static inline int
+fi_poll_add(struct fid_poll *pollset, struct fid *event_fid, uint64_t flags)
+{
+	return pollset->ops->poll_add(pollset, event_fid, flags);
+}
+
+static inline int
+fi_poll_del(struct fid_poll *pollset, struct fid *event_fid, uint64_t flags)
+{
+	return pollset->ops->poll_del(pollset, event_fid, flags);
+}
+
+static inline int
+fi_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
+	   struct fid_eq **eq, void *context)
+{
+	return fabric->ops->eq_open(fabric, attr, eq, context);
+}
+
+static inline ssize_t
+fi_eq_read(struct fid_eq *eq, uint32_t *event, void *buf,
+	   size_t len, uint64_t flags)
+{
+	return eq->ops->read(eq, event, buf, len, flags);
+}
+
+static inline ssize_t
+fi_eq_readerr(struct fid_eq *eq, struct fi_eq_err_entry *buf, uint64_t flags)
+{
+	return eq->ops->readerr(eq, buf, flags);
+}
+
+static inline ssize_t
+fi_eq_write(struct fid_eq *eq, uint32_t event, const void *buf,
+	    size_t len, uint64_t flags)
+{
+	return eq->ops->write(eq, event, buf, len, flags);
+}
+
+static inline ssize_t
+fi_eq_sread(struct fid_eq *eq, uint32_t *event, void *buf, size_t len,
+	    int timeout, uint64_t flags)
+{
+	return eq->ops->sread(eq, event, buf, len, timeout, flags);
+}
+
+static inline const char *
+fi_eq_strerror(struct fid_eq *eq, int prov_errno, const void *err_data,
+	       char *buf, size_t len)
+{
+	return eq->ops->strerror(eq, prov_errno, err_data, buf, len);
+}
+
+
+static inline ssize_t fi_cq_read(struct fid_cq *cq, void *buf, size_t count)
+{
+	return psmx2_cq_read(cq, buf, count);
+}
+
+static inline ssize_t
+fi_cq_readfrom(struct fid_cq *cq, void *buf, size_t count, fi_addr_t *src_addr)
+{
+	return psmx2_cq_readfrom(cq, buf, count, src_addr);
+}
+
+static inline ssize_t
+fi_cq_readerr(struct fid_cq *cq, struct fi_cq_err_entry *buf, uint64_t flags)
+{
+	return psmx2_cq_readerr(cq, buf, flags);
+}
+
+static inline ssize_t
+fi_cq_sread(struct fid_cq *cq, void *buf, size_t count, const void *cond, int timeout)
+{
+	return psmx2_cq_sread(cq, buf, count, cond, timeout);
+}
+
+static inline ssize_t
+fi_cq_sreadfrom(struct fid_cq *cq, void *buf, size_t count,
+		fi_addr_t *src_addr, const void *cond, int timeout)
+{
+	return psmx2_cq_sreadfrom(cq, buf, count, src_addr, cond, timeout);
+}
+
+static inline int fi_cq_signal(struct fid_cq *cq)
+{
+	return psmx2_cq_signal(cq);
+}
+
+static inline const char *
+fi_cq_strerror(struct fid_cq *cq, int prov_errno, const void *err_data,
+	       char *buf, size_t len)
+{
+	return psmx2_cq_strerror(cq, prov_errno, err_data, buf, len);
+}
+
+
+static inline uint64_t fi_cntr_read(struct fid_cntr *cntr)
+{
+	return psmx2_cntr_read(cntr);
+}
+
+static inline uint64_t fi_cntr_readerr(struct fid_cntr *cntr)
+{
+	return psmx2_cntr_readerr(cntr);
+}
+
+static inline int fi_cntr_add(struct fid_cntr *cntr, uint64_t value)
+{
+	return psmx2_cntr_add(cntr, value);
+}
+
+static inline int fi_cntr_adderr(struct fid_cntr *cntr, uint64_t value)
+{
+	return psmx2_cntr_adderr(cntr, value);
+}
+
+static inline int fi_cntr_set(struct fid_cntr *cntr, uint64_t value)
+{
+	return psmx2_cntr_set(cntr, value);
+}
+
+static inline int fi_cntr_seterr(struct fid_cntr *cntr, uint64_t value)
+{
+	return psmx2_cntr_seterr(cntr, value);
+}
+
+static inline int
+fi_cntr_wait(struct fid_cntr *cntr, uint64_t threshold, int timeout)
+{
+	return psmx2_cntr_wait(cntr, threshold, timeout);
+}
+
+#endif /* FI_DIRECT_EQ_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_rma.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_rma.h
new file mode 100644
index 000000000..543b2ac36
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_rma.h
@@ -0,0 +1,144 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_RMA_H
+#define FI_DIRECT_RMA_H
+
+#define FABRIC_DIRECT_RMA
+
+ssize_t psmx2_read(
+		struct fid_ep *ep, void *buf, size_t len, void *desc,
+		fi_addr_t src_addr, uint64_t addr, uint64_t key,
+		void *context);
+
+ssize_t psmx2_readv(
+		struct fid_ep *ep, const struct iovec *iov, void **desc,
+		size_t count, fi_addr_t src_addr, uint64_t addr, uint64_t key,
+		void *context);
+
+ssize_t psmx2_readmsg(
+		struct fid_ep *ep, const struct fi_msg_rma *msg,
+		uint64_t flags);
+
+ssize_t psmx2_write(
+		struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		fi_addr_t dest_addr, uint64_t addr, uint64_t key, void *context);
+
+ssize_t psmx2_writev(
+		struct fid_ep *ep, const struct iovec *iov, void **desc,
+		size_t count, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		void *context);
+
+ssize_t psmx2_writemsg(
+		struct fid_ep *ep, const struct fi_msg_rma *msg,
+		uint64_t flags);
+
+ssize_t psmx2_inject_write(
+		struct fid_ep *ep, const void *buf, size_t len,
+		fi_addr_t dest_addr, uint64_t addr, uint64_t key);
+
+ssize_t psmx2_writedata(
+		struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		uint64_t data, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		void *context);
+
+ssize_t psmx2_inject_writedata(
+		struct fid_ep *ep, const void *buf, size_t len,
+		uint64_t data, fi_addr_t dest_addr, uint64_t addr, uint64_t key);
+
+
+static inline ssize_t
+fi_read(struct fid_ep *ep, void *buf, size_t len, void *desc,
+	fi_addr_t src_addr, uint64_t addr, uint64_t key, void *context)
+{
+	return psmx2_read(ep, buf, len, desc, src_addr, addr, key, context);
+}
+
+static inline ssize_t
+fi_readv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+	 size_t count, fi_addr_t src_addr, uint64_t addr, uint64_t key,
+	 void *context)
+{
+	return psmx2_readv(ep, iov, desc, count, src_addr, addr, key, context);
+}
+
+static inline ssize_t
+fi_readmsg(struct fid_ep *ep, const struct fi_msg_rma *msg, uint64_t flags)
+{
+	return psmx2_readmsg(ep, msg, flags);
+}
+
+static inline ssize_t
+fi_write(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+	 fi_addr_t dest_addr, uint64_t addr, uint64_t key, void *context)
+{
+	return psmx2_write(ep, buf, len, desc, dest_addr, addr, key, context);
+}
+
+static inline ssize_t
+fi_writev(struct fid_ep *ep, const struct iovec *iov, void **desc,
+	 size_t count, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+	 void *context)
+{
+	return psmx2_writev(ep, iov, desc, count, dest_addr, addr, key, context);
+}
+
+static inline ssize_t
+fi_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg, uint64_t flags)
+{
+	return psmx2_writemsg(ep, msg, flags);
+}
+
+static inline ssize_t
+fi_inject_write(struct fid_ep *ep, const void *buf, size_t len,
+		fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	return psmx2_inject_write(ep, buf, len, dest_addr, addr, key);
+}
+
+static inline ssize_t
+fi_writedata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+	       uint64_t data, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+	       void *context)
+{
+	return psmx2_writedata(ep, buf, len, desc,data, dest_addr,
+				  addr, key, context);
+}
+
+static inline ssize_t
+fi_inject_writedata(struct fid_ep *ep, const void *buf, size_t len,
+		uint64_t data, fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	return psmx2_inject_writedata(ep, buf, len, data, dest_addr, addr, key);
+}
+
+#endif /* FI_DIRECT_RMA_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_tagged.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_tagged.h
new file mode 100644
index 000000000..f77d7a396
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_tagged.h
@@ -0,0 +1,40 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_TAGGED_H
+#define FI_DIRECT_TAGGED_H
+
+/*
+ * use defaults bacause function pointers are needed for specialization
+ */
+
+#endif /* FI_DIRECT_TAGGED_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_trigger.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_trigger.h
new file mode 100644
index 000000000..10f795614
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/include/rdma/fi_direct_trigger.h
@@ -0,0 +1,40 @@
+/*
+ * Copyright (c) 2016-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef FI_DIRECT_TRIGGER_H
+#define FI_DIRECT_TRIGGER_H
+
+/*
+ * use default definitions
+ */
+
+#endif /* FI_DIRECT_TRIGGER_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/provider_FABRIC_1.0.map b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/provider_FABRIC_1.0.map
new file mode 100644
index 000000000..f26516aad
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/provider_FABRIC_1.0.map
@@ -0,0 +1,81 @@
+/*
+ * Included from "libfabric.map" at the top level directory.
+ * Used for fabric direct build only.
+ */
+		psmx2_atomic_write;
+		psmx2_atomic_writev;
+		psmx2_atomic_writemsg;
+		psmx2_atomic_inject;
+		psmx2_atomic_readwrite;
+		psmx2_atomic_readwritev;
+		psmx2_atomic_readwritemsg;
+		psmx2_atomic_compwrite;
+		psmx2_atomic_compwritev;
+		psmx2_atomic_compwritemsg;
+		psmx2_atomic_writevalid;
+		psmx2_atomic_readwritevalid;
+		psmx2_atomic_compwritevalid;
+		psmx2_query_atomic;
+		psmx2_cm_getname;
+		psmx2_domain_open;
+		psmx2_cq_open;
+		psmx2_cntr_open;
+		psmx2_wait_open;
+		psmx2_mr_reg;
+		psmx2_mr_regv;
+		psmx2_mr_regattr;
+		psmx2_mr_bind;
+		psmx2_av_open;
+		psmx2_av_bind;
+		psmx2_av_insert;
+		psmx2_av_remove;
+		psmx2_av_lookup;
+		psmx2_av_straddr;
+		psmx2_ep_open;
+		psmx2_sep_open;
+		psmx2_ep_bind;
+		psmx2_sep_bind;
+		psmx2_ep_control;
+		psmx2_ep_cancel;
+		psmx2_ep_getopt;
+		psmx2_ep_setopt;
+		psmx2_tx_context;
+		psmx2_rx_context;
+		psmx2_rx_size_left;
+		psmx2_tx_size_left;
+		psmx2_stx_ctx;
+		psmx2_recv;
+		psmx2_recvv;
+		psmx2_recvmsg;
+		psmx2_send;
+		psmx2_sendv;
+		psmx2_sendmsg;
+		psmx2_inject;
+		psmx2_senddata;
+		psmx2_injectdata;
+		psmx2_wait_trywait;
+		psmx2_wait_wait;
+		psmx2_cq_read;
+		psmx2_cq_readfrom;
+		psmx2_cq_readerr;
+		psmx2_cq_sread;
+		psmx2_cq_sreadfrom;
+		psmx2_cq_signal;
+		psmx2_cq_strerror;
+		psmx2_cntr_read;
+		psmx2_cntr_readerr;
+		psmx2_cntr_add;
+		psmx2_cntr_adderr;
+		psmx2_cntr_set;
+		psmx2_cntr_seterr;
+		psmx2_cntr_wait;
+		psmx2_read;
+		psmx2_readv;
+		psmx2_readmsg;
+		psmx2_write;
+		psmx2_writev;
+		psmx2_writemsg;
+		psmx2_inject_write;
+		psmx2_writedata;
+		psmx2_inject_writedata;
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2.h
index 3d824f16a..36b5c7e4b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2.h
@@ -73,9 +73,17 @@ extern "C" {
 #include "rbtree.h"
 #include "version.h"
 
+#ifdef FABRIC_DIRECT_ENABLED
+#define DIRECT_FN __attribute__((visibility ("default")))
+#define STATIC
+#else
+#define DIRECT_FN
+#define STATIC static
+#endif
+
 extern struct fi_provider psmx2_prov;
 
-#define PSMX2_VERSION	(FI_VERSION(1, 6))
+#define PSMX2_VERSION	(FI_VERSION(1, 7))
 
 #define PSMX2_OP_FLAGS	(FI_INJECT | FI_MULTI_RECV | FI_COMPLETION | \
 			 FI_TRIGGER | FI_INJECT_COMPLETE | \
@@ -88,7 +96,7 @@ extern struct fi_provider psmx2_prov;
 
 #define PSMX2_SEC_CAPS	(FI_MULTI_RECV | FI_SOURCE | FI_RMA_EVENT | \
 			 FI_TRIGGER | FI_LOCAL_COMM | FI_REMOTE_COMM | \
-			 FI_SOURCE_ERR)
+			 FI_SOURCE_ERR | FI_SHARED_AV)
 
 #define PSMX2_CAPS	(PSMX2_PRI_CAPS | PSMX2_SEC_CAPS | FI_REMOTE_CQ_DATA)
 
@@ -267,34 +275,12 @@ static inline uint64_t psmx2_get_tag64(psm2_mq_tag_t *tag96)
 #define PSMX2_GET_FLAGS(tag96)	((tag96).tag[PSMX2_FLAGS_IDX] & PSMX2_FLAGS_MASK)
 #define PSMX2_GET_CQDATA(tag96)	((tag96).tag2 & PSMX2_DATA_MASK)
 
-/*
- * Canonical virtual address on X86_64 only uses 48 bits and the higher 16 bits
- * are sign extensions. We can put some extra information into the 16 bits.
- *
- * Here is the layout:  AA-B-C-DDDDDDDDDDDD
- *
- * C == 0xE: scalable endpoint, AAB is context index, DDDDDDDDDDDD is the address
- * C != 0xE: regular endpoint, AA is 0, BCDDDDDDDDDDDD is epaddr
- */
-#define PSMX2_EP_MASK			(0x00FFFFFFFFFFFFFFUL)
-#define PSMX2_SIGN_MASK  		(0x0080000000000000UL)
-#define PSMX2_SIGN_EXT			(0xFF00000000000000UL)
-
-#define PSMX2_EP_TO_ADDR(ep)		((uint64_t)ep & PSMX2_EP_MASK)
-#define PSMX2_ADDR_TO_EP(addr)		((psm2_epaddr_t) \
-						((addr & PSMX2_SIGN_MASK) ? \
-						 (addr | PSMX2_SIGN_EXT) : \
-						 (addr & PSMX2_EP_MASK)))
-
-#define PSMX2_MAX_RX_CTX_BITS		(12)
-#define PSMX2_SEP_ADDR_FLAG		(0x000E000000000000UL)
-#define PSMX2_SEP_ADDR_MASK		(0x000F000000000000UL)
-#define PSMX2_SEP_CTXT_MASK		(0xFFF0000000000000UL)
-#define PSMX2_SEP_IDX_MASK		(0x0000FFFFFFFFFFFFUL)
-#define PSMX2_SEP_ADDR_TEST(addr)	(((addr) & PSMX2_SEP_ADDR_MASK) == PSMX2_SEP_ADDR_FLAG)
-#define PSMX2_SEP_ADDR_CTXT(addr, ctxt_bits) \
-					(((addr) & PSMX2_SEP_CTXT_MASK) >> (64-(ctxt_bits)))
-#define PSMX2_SEP_ADDR_IDX(addr)	((addr) & PSMX2_SEP_IDX_MASK)
+#define PSMX2_MAX_RX_CTX_BITS	(12)
+#define PSMX2_ADDR_IDX_MASK	(0x000FFFFFFFFFFFFFUL)
+#define PSMX2_ADDR_CTXT_MASK	(0xFFF0000000000000UL)
+#define PSMX2_ADDR_IDX(addr)	((addr) & PSMX2_ADDR_IDX_MASK)
+#define PSMX2_ADDR_CTXT(addr, ctxt_bits) \
+				(((addr) & PSMX2_ADDR_CTXT_MASK) >> (64-(ctxt_bits)))
 
 /* Bits 60 .. 63 of the flag are provider specific */
 #define PSMX2_NO_COMPLETION	(1ULL << 60)
@@ -332,6 +318,15 @@ union psmx2_pi {
 #define PSMX2_CTXT_USER(fi_context)	((fi_context)->internal[2])
 #define PSMX2_CTXT_EP(fi_context)	((fi_context)->internal[3])
 
+/*
+ * Use per-protocol versioning to avoid unnecessary version checking. Only perform
+ * version checking when the current version is greater than zero.
+ */
+#define PSMX2_AM_RMA_VERSION		0
+#define PSMX2_AM_ATOMIC_VERSION		0
+#define PSMX2_AM_SEP_VERSION		1
+#define PSMX2_AM_TRX_CTXT_VERSION	0
+
 #define PSMX2_AM_RMA_HANDLER		0
 #define PSMX2_AM_ATOMIC_HANDLER		1
 #define PSMX2_AM_SEP_HANDLER		2
@@ -339,14 +334,18 @@ union psmx2_pi {
 
 #define PSMX2_AM_OP_MASK	0x000000FF
 #define PSMX2_AM_FLAG_MASK	0xFF000000
+#define PSMX2_AM_VER_MASK	0x00FF0000
+#define PSMX2_AM_VER_SHIFT	16
 #define PSMX2_AM_EOM		0x40000000
 #define PSMX2_AM_DATA		0x20000000
 #define PSMX2_AM_FORCE_ACK	0x10000000
 
-#define PSMX2_AM_SET_OP(u32w0,op)	do {u32w0 &= ~PSMX2_AM_OP_MASK; u32w0 |= op;} while (0)
-#define PSMX2_AM_SET_FLAG(u32w0,flag)	do {u32w0 &= ~PSMX2_AM_FLAG_MASK; u32w0 |= flag;} while (0)
-#define PSMX2_AM_GET_OP(u32w0)		(u32w0 & PSMX2_AM_OP_MASK)
-#define PSMX2_AM_GET_FLAG(u32w0)	(u32w0 & PSMX2_AM_FLAG_MASK)
+#define PSMX2_AM_SET_OP(u32w0,op)	do {(u32w0) &= ~PSMX2_AM_OP_MASK; (u32w0) |= (op);} while (0)
+#define PSMX2_AM_SET_FLAG(u32w0,flag)	do {(u32w0) &= ~PSMX2_AM_FLAG_MASK; (u32w0) |= (flag);} while (0)
+#define PSMX2_AM_SET_VER(u32w0,ver)	do {(u32w0) &= ~PSMX2_AM_VER_MASK; (u32w0) |= (ver << PSMX2_AM_VER_SHIFT);} while (0)
+#define PSMX2_AM_GET_OP(u32w0)		((u32w0) & PSMX2_AM_OP_MASK)
+#define PSMX2_AM_GET_FLAG(u32w0)	((u32w0) & PSMX2_AM_FLAG_MASK)
+#define PSMX2_AM_GET_VER(u32w0)		(((u32w0) & PSMX2_AM_VER_MASK) >> PSMX2_AM_VER_SHIFT)
 
 enum {
 	PSMX2_AM_REQ_WRITE = 1,
@@ -405,17 +404,17 @@ struct psmx2_am_request {
 			int	datatype;
 		} atomic;
 	};
-	uint64_t cq_flags;
-	struct fi_context fi_context;
-	struct psmx2_fid_ep *ep;
-	int no_event;
-	int error;
-	struct slist_entry list_entry;
+	uint64_t		cq_flags;
+	struct fi_context	fi_context;
+	struct psmx2_fid_ep	*ep;
+	int			no_event;
+	int			error;
+	struct slist_entry	list_entry;
 	union {
-		struct iovec *iov;	/* for readv */
-		struct fi_ioc *ioc;	/* for atomic read */
+		struct iovec	*iov;	/* for readv */
+		struct fi_ioc	*ioc;	/* for atomic read */
 	};
-	void *tmpbuf;
+	void			*tmpbuf;
 };
 
 #define PSMX2_IOV_PROTO_PACK	0
@@ -425,40 +424,40 @@ struct psmx2_am_request {
 #define PSMX2_IOV_MAX_COUNT	(PSMX2_IOV_BUF_SIZE / sizeof(uint32_t) - 3)
 
 struct psmx2_iov_info {
-	uint32_t seq_num;
-	uint32_t total_len;
-	uint32_t count;
-	uint32_t len[PSMX2_IOV_MAX_COUNT];
+	uint32_t	seq_num;
+	uint32_t	total_len;
+	uint32_t	count;
+	uint32_t	len[PSMX2_IOV_MAX_COUNT];
 };
 
 struct psmx2_sendv_request {
-	struct fi_context fi_context;
-	struct fi_context fi_context_iov;
-	PSMX2_STATUS_DECL(status);
-	void *user_context;
-	int iov_protocol;
-	int no_completion;
-	int comp_flag;
-	uint32_t iov_done;
+	struct fi_context	fi_context;
+	struct fi_context	fi_context_iov;
+	void			*user_context;
+	int			iov_protocol;
+	int			no_completion;
+	int			comp_flag;
+	uint32_t		iov_done;
+	psm2_mq_tag_t		tag;
 	union {
-		struct psmx2_iov_info iov_info;
-		char buf[PSMX2_IOV_BUF_SIZE];
+		struct psmx2_iov_info	iov_info;
+		char			buf[PSMX2_IOV_BUF_SIZE];
 	};
 };
 
 struct psmx2_sendv_reply {
-	struct fi_context fi_context;
-	int no_completion;
-	int multi_recv;
-	psm2_mq_tag_t tag;
-	uint8_t *buf;
-	void *user_context;
-	size_t iov_done;
-	size_t bytes_received;
-	size_t msg_length;
-	int error_code;
-	int comp_flag;
-	struct psmx2_iov_info iov_info;
+	struct fi_context	fi_context;
+	int			no_completion;
+	int			multi_recv;
+	psm2_mq_tag_t		tag;
+	uint8_t			*buf;
+	void			*user_context;
+	size_t			iov_done;
+	size_t			bytes_received;
+	size_t			msg_length;
+	int			error_code;
+	int			comp_flag;
+	struct psmx2_iov_info	iov_info;
 };
 
 struct psmx2_req_queue {
@@ -506,8 +505,10 @@ struct psmx2_trx_ctxt {
 	struct psmx2_fid_domain	*domain;
 	struct psmx2_fid_ep	*ep;
 
+#if !HAVE_PSM2_MQ_FP_MSG
 	/* incoming req queue for AM based RMA request. */
 	struct psmx2_req_queue	rma_queue;
+#endif
 
 	/* triggered operations that are ready to be processed */
 	struct psmx2_req_queue	trigger_queue;
@@ -525,9 +526,19 @@ struct psmx2_trx_ctxt {
 	struct dlist_entry	peer_list;
 	fastlock_t		peer_lock;
 
+	/* number of pathes this tx/rx context can be polled. this include
+	 * CQs and counters, as well as domain->trx_ctxt_list.
+	 */
+	ofi_atomic32_t		poll_refcnt;
+	int			poll_active;
+
 	struct dlist_entry	entry;
 };
 
+typedef void	(*psmx2_lock_fn_t) (fastlock_t *lock, int lock_level);
+typedef int	(*psmx2_trylock_fn_t) (fastlock_t *lock, int lock_level);
+typedef void	(*psmx2_unlock_fn_t) (fastlock_t *lock, int lock_level);
+
 struct psmx2_fid_domain {
 	struct util_domain	util_domain;
 	struct psmx2_fid_fabric	*fabric;
@@ -554,6 +565,32 @@ struct psmx2_fid_domain {
 	uint32_t		max_atomic_size;
 
 	struct dlist_entry	entry;
+
+	/* Lock/Unlock function pointers set based on FI_THREAD model */
+	psmx2_lock_fn_t		av_lock_fn;
+	psmx2_unlock_fn_t	av_unlock_fn;
+	psmx2_lock_fn_t		am_req_pool_lock_fn;
+	psmx2_unlock_fn_t	am_req_pool_unlock_fn;
+	psmx2_lock_fn_t		trx_ctxt_lock_fn;
+	psmx2_unlock_fn_t	trx_ctxt_unlock_fn;
+	psmx2_lock_fn_t		rma_queue_lock_fn;
+	psmx2_unlock_fn_t	rma_queue_unlock_fn;
+	psmx2_lock_fn_t		trigger_queue_lock_fn;
+	psmx2_unlock_fn_t	trigger_queue_unlock_fn;
+	psmx2_lock_fn_t		peer_lock_fn;
+	psmx2_unlock_fn_t	peer_unlock_fn;
+	psmx2_lock_fn_t		sep_lock_fn;
+	psmx2_unlock_fn_t	sep_unlock_fn;
+	psmx2_lock_fn_t		trigger_lock_fn;
+	psmx2_unlock_fn_t	trigger_unlock_fn;
+	psmx2_lock_fn_t		cq_lock_fn;
+	psmx2_unlock_fn_t	cq_unlock_fn;
+	psmx2_lock_fn_t		mr_lock_fn;
+	psmx2_unlock_fn_t	mr_unlock_fn;
+	psmx2_lock_fn_t		context_lock_fn;
+	psmx2_unlock_fn_t	context_unlock_fn;
+	psmx2_trylock_fn_t	poll_trylock_fn;
+	psmx2_unlock_fn_t	poll_unlock_fn;
 };
 
 #define PSMX2_EP_REGULAR	0
@@ -579,6 +616,13 @@ struct psmx2_ep_name {
 
 #define PSMX2_MAX_STRING_NAME_LEN	64	/* "fi_addr_psmx2://<uint64_t>:<uint64_t>"  */
 
+struct psmx2_status_data {
+	struct psmx2_fid_cq	*poll_cq;
+	struct psmx2_trx_ctxt	*trx_ctxt;
+	fi_addr_t		*src_addr;
+	void			*event_buffer;
+};
+
 struct psmx2_cq_event {
 	union {
 		struct fi_cq_entry		context;
@@ -587,11 +631,11 @@ struct psmx2_cq_event {
 		struct fi_cq_tagged_entry	tagged;
 		struct fi_cq_err_entry		err;
 	} cqe;
-	int error;
-	int source_is_valid;
-	fi_addr_t source;
-	struct psmx2_fid_av *source_av;
-	struct slist_entry list_entry;
+	int			error;
+	int			source_is_valid;
+	psm2_epaddr_t		source;
+	struct psmx2_fid_av	*source_av;
+	struct slist_entry	list_entry;
 };
 
 #define PSMX2_ERR_DATA_SIZE		64	/* large enough to hold a string address */
@@ -640,14 +684,30 @@ struct psmx2_fid_cntr {
 	fastlock_t		trigger_lock;
 };
 
-struct psmx2_av_peer {
+#define PSMX2_AV_DEFAULT_SIZE	64
+
+#define PSMX2_AV_TABLE_SIZE(count, shared) \
+		(sizeof(struct psmx2_av_hdr) + \
+		 ((shared) ? (count) * sizeof(fi_addr_t) : 0) + \
+		 (count) * sizeof(struct psmx2_av_addr))
+
+struct psmx2_av_hdr {
+	uint64_t		size;
+	uint64_t		last;
+};
+
+struct psmx2_av_addr {
+	psm2_epid_t		epid;
 	uint8_t			type;
 	uint8_t			sep_id;
-	int			sep_ctxt_cnt;
-	psm2_epid_t		*sep_ctxt_epids;
 };
 
-struct psmx2_av_table {
+struct psmx2_av_sep {
+	int			ctxt_cnt;
+	psm2_epid_t		*epids;
+};
+
+struct psmx2_av_conn {
 	struct psmx2_trx_ctxt	*trx_ctxt;
 	psm2_epaddr_t		*epaddrs;
 	psm2_epaddr_t		**sepaddrs;
@@ -657,18 +717,20 @@ struct psmx2_fid_av {
 	struct fid_av		av;
 	struct psmx2_fid_domain	*domain;
 	struct fid_eq		*eq;
-	int			type;
 	int			addr_format;
 	int			rx_ctx_bits;
 	int			max_trx_ctxt;
+	int			shared;
 	uint64_t		flags;
 	size_t			addrlen;
 	size_t			count;
-	size_t			last;
 	fastlock_t		lock;
-	psm2_epid_t		*epids;	 /* one entry per peer */
-	struct psmx2_av_peer	*peers;  /* one entry per peer */
-	struct psmx2_av_table	tables[];/* one entry per context */
+	struct util_shm		shm;
+	struct psmx2_av_hdr	*hdr;	/* shared AV header */
+	fi_addr_t		*map;	/* shared AV address mapping */
+	struct psmx2_av_addr	*table;	/* shared AV address table */
+	struct psmx2_av_sep	*sep_info;
+	struct psmx2_av_conn	conn_info[];
 };
 
 struct psmx2_fid_ep {
@@ -754,45 +816,36 @@ struct psmx2_epaddr_context {
 };
 
 struct psmx2_env {
-	int name_server;
-	int tagged_rma;
-	char *uuid;
-	int delay;
-	int timeout;
-	int prog_interval;
-	char *prog_affinity;
-	int multi_ep;
-	int max_trx_ctxt;
-	int free_trx_ctxt;
-	int num_devunits;
-	int inject_size;
-	int lock_level;
-	int lazy_conn;
-	int disconnect;
+	int	name_server;
+	int	tagged_rma;
+	char	*uuid;
+	int	delay;
+	int	timeout;
+	int	prog_interval;
+	char	*prog_affinity;
+	int	multi_ep;
+	int	max_trx_ctxt;
+	int	free_trx_ctxt;
+	int	num_devunits;
+	int	inject_size;
+	int	lock_level;
+	int	disconnect;
 #if (PSMX2_TAG_LAYOUT == PSMX2_TAG_LAYOUT_RUNTIME)
-	char *tag_layout;
+	char	*tag_layout;
 #endif
 };
 
 extern struct fi_ops_mr		psmx2_mr_ops;
 extern struct fi_ops_cm		psmx2_cm_ops;
 extern struct fi_ops_tagged	psmx2_tagged_ops;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_flag_av_map_directed;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_flag_av_table_directed;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_event_av_map_directed;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_event_av_table_directed;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_send_event_av_map_directed;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_send_event_av_table_directed;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_recv_event_av_map_directed;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_recv_event_av_table_directed;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_flag_av_map_undirected;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_flag_av_table_undirected;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_event_av_map_undirected;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_event_av_table_undirected;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_send_event_av_map_undirected;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_send_event_av_table_undirected;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_recv_event_av_map_undirected;
-extern struct fi_ops_tagged	psmx2_tagged_ops_no_recv_event_av_table_undirected;
+extern struct fi_ops_tagged	psmx2_tagged_ops_no_flag_directed;
+extern struct fi_ops_tagged	psmx2_tagged_ops_no_event_directed;
+extern struct fi_ops_tagged	psmx2_tagged_ops_no_send_event_directed;
+extern struct fi_ops_tagged	psmx2_tagged_ops_no_recv_event_directed;
+extern struct fi_ops_tagged	psmx2_tagged_ops_no_flag_undirected;
+extern struct fi_ops_tagged	psmx2_tagged_ops_no_event_undirected;
+extern struct fi_ops_tagged	psmx2_tagged_ops_no_send_event_undirected;
+extern struct fi_ops_tagged	psmx2_tagged_ops_no_recv_event_undirected;
 extern struct fi_ops_msg	psmx2_msg_ops;
 extern struct fi_ops_msg	psmx2_msg2_ops;
 extern struct fi_ops_rma	psmx2_rma_ops;
@@ -826,6 +879,33 @@ static inline void psmx2_unlock(fastlock_t *lock, int lock_level)
 		fastlock_release(lock);
 }
 
+/* Specialized lock functions used based on FI_THREAD model */
+
+static inline void psmx2_lock_disabled(fastlock_t *lock, int lock_level)
+{
+	return;
+}
+
+static inline int psmx2_trylock_disabled(fastlock_t *lock, int lock_level)
+{
+	return 0;
+}
+
+static inline void psmx2_lock_enabled(fastlock_t *lock, int lock_level)
+{
+	fastlock_acquire(lock);
+}
+
+static inline void psmx2_unlock_enabled(fastlock_t *lock, int lock_level)
+{
+	fastlock_release(lock);
+}
+
+static inline int psmx2_trylock_enabled(fastlock_t *lock, int lock_level)
+{
+	return fastlock_tryacquire(lock);
+}
+
 int	psmx2_init_prov_info(const struct fi_info *hints, struct fi_info **info);
 void	psmx2_update_prov_info(struct fi_info *info,
 			       struct psmx2_ep_name *src_addr,
@@ -924,43 +1004,13 @@ int	psmx2_cq_poll_mq(struct psmx2_fid_cq *cq, struct psmx2_trx_ctxt *trx_ctxt,
 int	psmx2_epid_to_epaddr(struct psmx2_trx_ctxt *trx_ctxt,
 			     psm2_epid_t epid, psm2_epaddr_t *epaddr);
 
-int	psmx2_av_add_trx_ctxt(struct psmx2_fid_av *av, struct psmx2_trx_ctxt *trx_ctxt,
-			      int connect_now);
-
-psm2_epaddr_t psmx2_av_translate_sep(struct psmx2_fid_av *av,
-				     struct psmx2_trx_ctxt *trx_ctxt, fi_addr_t addr);
+int	psmx2_av_add_trx_ctxt(struct psmx2_fid_av *av, struct psmx2_trx_ctxt *trx_ctxt);
 
 void	psmx2_av_remove_conn(struct psmx2_fid_av *av, struct psmx2_trx_ctxt *trx_ctxt,
 			     psm2_epaddr_t epaddr);
 
-static inline int psmx2_av_check_table_idx(struct psmx2_fid_av *av,
-					   struct psmx2_trx_ctxt *trx_ctxt,
-					   size_t idx)
-{
-	int err = 0;
-
-	psmx2_lock(&av->lock, 1);
-
-	if (OFI_UNLIKELY(idx >= av->last)) {
-		FI_WARN(&psmx2_prov, FI_LOG_AV,
-			"error: av index %ld out of range(max: %ld).\n", idx, av->last);
-		err = -FI_EINVAL;
-		goto out;
-	}
-
-	if (!av->tables[trx_ctxt->id].epaddrs[idx]) {
-		err = psmx2_epid_to_epaddr(trx_ctxt, av->epids[idx],
-					   &av->tables[trx_ctxt->id].epaddrs[idx]);
-		if (err)
-			FI_WARN(&psmx2_prov, FI_LOG_AV,
-				"fatal error: unable to translate epid %lx to epaddr.\n",
-				av->epids[idx]);
-	}
-
-out:
-	psmx2_unlock(&av->lock, 1);
-	return err;
-}
+psm2_epaddr_t psmx2_av_translate_addr(struct psmx2_fid_av *av,
+				      struct psmx2_trx_ctxt *trx_ctxt, fi_addr_t addr);
 
 void	psmx2_am_global_init(void);
 void	psmx2_am_global_fini(void);
@@ -992,9 +1042,9 @@ struct psmx2_am_request *psmx2_am_request_alloc(struct psmx2_trx_ctxt *trx_ctxt)
 {
 	struct psmx2_am_request *req;
 
-	psmx2_lock(&trx_ctxt->am_req_pool_lock, 2);
+	trx_ctxt->domain->am_req_pool_lock_fn(&trx_ctxt->am_req_pool_lock, 0);
 	req = util_buf_alloc(trx_ctxt->am_req_pool);
-	psmx2_unlock(&trx_ctxt->am_req_pool_lock, 2);
+	trx_ctxt->domain->am_req_pool_unlock_fn(&trx_ctxt->am_req_pool_lock, 0);
 
 	if (req)
 		memset(req, 0, sizeof(*req));
@@ -1005,9 +1055,9 @@ struct psmx2_am_request *psmx2_am_request_alloc(struct psmx2_trx_ctxt *trx_ctxt)
 static inline void psmx2_am_request_free(struct psmx2_trx_ctxt *trx_ctxt,
 					 struct psmx2_am_request *req)
 {
-	psmx2_lock(&trx_ctxt->am_req_pool_lock, 2);
+	trx_ctxt->domain->am_req_pool_lock_fn(&trx_ctxt->am_req_pool_lock, 0);
 	util_buf_release(trx_ctxt->am_req_pool, req);
-	psmx2_unlock(&trx_ctxt->am_req_pool_lock, 2);
+	trx_ctxt->domain->am_req_pool_unlock_fn(&trx_ctxt->am_req_pool_lock, 0);
 }
 
 struct	psmx2_fid_mr *psmx2_mr_get(struct psmx2_fid_domain *domain, uint64_t key);
@@ -1031,24 +1081,21 @@ static inline void psmx2_cntr_inc(struct psmx2_fid_cntr *cntr, int error)
 		cntr->wait->signal(cntr->wait);
 }
 
-fi_addr_t psmx2_av_translate_source(struct psmx2_fid_av *av, fi_addr_t source);
+fi_addr_t psmx2_av_translate_source(struct psmx2_fid_av *av, psm2_epaddr_t source);
 
-static inline void psmx2_get_source_name(fi_addr_t source, struct psmx2_ep_name *name)
+static inline void psmx2_get_source_name(psm2_epaddr_t source, struct psmx2_ep_name *name)
 {
-	psm2_epaddr_t epaddr = PSMX2_ADDR_TO_EP(source);
-
 	memset(name, 0, sizeof(*name));
-	psm2_epaddr_to_epid(epaddr, &name->epid);
+	psm2_epaddr_to_epid(source, &name->epid);
 	name->type = PSMX2_EP_REGULAR;
 }
 
-static inline void psmx2_get_source_string_name(fi_addr_t source, char *name, size_t *len)
+static inline void psmx2_get_source_string_name(psm2_epaddr_t source, char *name, size_t *len)
 {
 	struct psmx2_ep_name ep_name;
-	psm2_epaddr_t epaddr = PSMX2_ADDR_TO_EP(source);
 
 	memset(&ep_name, 0, sizeof(ep_name));
-	psm2_epaddr_to_epid(epaddr, &ep_name.epid);
+	psm2_epaddr_to_epid(source, &ep_name.epid);
 	ep_name.type = PSMX2_EP_REGULAR;
 
 	ofi_straddr(name, len, FI_ADDR_PSMX2, &ep_name);
@@ -1056,8 +1103,12 @@ static inline void psmx2_get_source_string_name(fi_addr_t source, char *name, si
 
 static inline void psmx2_progress(struct psmx2_trx_ctxt *trx_ctxt)
 {
-	if (trx_ctxt) {
+	if (trx_ctxt && trx_ctxt->poll_active) {
+#if HAVE_PSM2_MQ_REQ_USER
+		psmx2_cq_poll_mq(NULL, trx_ctxt, NULL, 1, NULL);
+#else
 		psmx2_cq_poll_mq(NULL, trx_ctxt, NULL, 0, NULL);
+#endif
 		if (trx_ctxt->am_progress)
 			psmx2_am_progress(trx_ctxt);
 	}
@@ -1068,12 +1119,12 @@ static inline void psmx2_progress_all(struct psmx2_fid_domain *domain)
 	struct dlist_entry *item;
 	struct psmx2_trx_ctxt *trx_ctxt;
 
-	psmx2_lock(&domain->trx_ctxt_lock, 1);
+	domain->trx_ctxt_lock_fn(&domain->trx_ctxt_lock, 1);
 	dlist_foreach(&domain->trx_ctxt_list, item) {
 		trx_ctxt = container_of(item, struct psmx2_trx_ctxt, entry);
 		psmx2_progress(trx_ctxt);
 	}
-	psmx2_unlock(&domain->trx_ctxt_lock, 1);
+	domain->trx_ctxt_unlock_fn(&domain->trx_ctxt_lock, 1);
 }
 
 /*
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_am.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_am.c
index 5e4e28d61..e1180e428 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_am.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_am.c
@@ -71,30 +71,32 @@ int psmx2_am_handler_count = 0;
 int psmx2_am_progress(struct psmx2_trx_ctxt *trx_ctxt)
 {
 	struct slist_entry *item;
-	struct psmx2_am_request *req;
 	struct psmx2_trigger *trigger;
 
+#if !HAVE_PSM2_MQ_FP_MSG
+	struct psmx2_am_request *req;
 	if (psmx2_env.tagged_rma) {
-		psmx2_lock(&trx_ctxt->rma_queue.lock, 2);
+		trx_ctxt->domain->rma_queue_lock_fn(&trx_ctxt->rma_queue.lock, 2);
 		while (!slist_empty(&trx_ctxt->rma_queue.list)) {
 			item = slist_remove_head(&trx_ctxt->rma_queue.list);
 			req = container_of(item, struct psmx2_am_request, list_entry);
-			psmx2_unlock(&trx_ctxt->rma_queue.lock, 2);
+			trx_ctxt->domain->rma_queue_unlock_fn(&trx_ctxt->rma_queue.lock, 2);
 			psmx2_am_process_rma(trx_ctxt, req);
-			psmx2_lock(&trx_ctxt->rma_queue.lock, 2);
+			trx_ctxt->domain->rma_queue_lock_fn(&trx_ctxt->rma_queue.lock, 2);
 		}
-		psmx2_unlock(&trx_ctxt->rma_queue.lock, 2);
+		trx_ctxt->domain->rma_queue_unlock_fn(&trx_ctxt->rma_queue.lock, 2);
 	}
+#endif
 
-	psmx2_lock(&trx_ctxt->trigger_queue.lock, 2);
+	trx_ctxt->domain->trigger_queue_lock_fn(&trx_ctxt->trigger_queue.lock, 2);
 	while (!slist_empty(&trx_ctxt->trigger_queue.list)) {
 		item = slist_remove_head(&trx_ctxt->trigger_queue.list);
 		trigger = container_of(item, struct psmx2_trigger, list_entry);
-		psmx2_unlock(&trx_ctxt->trigger_queue.lock, 2);
+		trx_ctxt->domain->trigger_queue_unlock_fn(&trx_ctxt->trigger_queue.lock, 2);
 		psmx2_process_trigger(trx_ctxt, trigger);
-		psmx2_lock(&trx_ctxt->trigger_queue.lock, 2);
+		trx_ctxt->domain->trigger_queue_lock_fn(&trx_ctxt->trigger_queue.lock, 2);
 	}
-	psmx2_unlock(&trx_ctxt->trigger_queue.lock, 2);
+	trx_ctxt->domain->trigger_queue_unlock_fn(&trx_ctxt->trigger_queue.lock, 2);
 
 	return 0;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_atomic.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_atomic.c
index d0ea0cbbf..6c2875936 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_atomic.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_atomic.c
@@ -808,8 +808,6 @@ ssize_t psmx2_atomic_write_generic(struct fid_ep *ep,
 	psm2_epaddr_t psm2_epaddr;
 	int am_flags = PSM2_AM_FLAG_ASYNC;
 	int chunk_size, len;
-	size_t idx;
-	int err;
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 
@@ -824,18 +822,9 @@ ssize_t psmx2_atomic_write_generic(struct fid_ep *ep,
 	assert((int)op >= 0 && (int)op < FI_ATOMIC_OP_LAST);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else  if (av && av->type == FI_AV_TABLE) {
-		idx = dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(dest_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid)
@@ -908,7 +897,6 @@ ssize_t psmx2_atomic_writev_generic(struct fid_ep *ep,
 	psm2_epaddr_t psm2_epaddr;
 	int am_flags = PSM2_AM_FLAG_ASYNC;
 	int chunk_size;
-	size_t idx;
 	size_t len;
 	uint8_t *buf;
 	int err;
@@ -930,18 +918,9 @@ ssize_t psmx2_atomic_writev_generic(struct fid_ep *ep,
 		count--;
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(dest_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	len = psmx2_ioc_size(iov, count, datatype);
 
@@ -1010,7 +989,8 @@ ssize_t psmx2_atomic_writev_generic(struct fid_ep *ep,
 	return 0;
 }
 
-static ssize_t psmx2_atomic_write(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_write(struct fid_ep *ep,
 				  const void *buf,
 				  size_t count, void *desc,
 				  fi_addr_t dest_addr,
@@ -1026,7 +1006,8 @@ static ssize_t psmx2_atomic_write(struct fid_ep *ep,
 					  ep_priv->tx_flags);
 }
 
-static ssize_t psmx2_atomic_writemsg(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_writemsg(struct fid_ep *ep,
 				const struct fi_msg_atomic *msg,
 				uint64_t flags)
 {
@@ -1052,7 +1033,8 @@ static ssize_t psmx2_atomic_writemsg(struct fid_ep *ep,
 					  msg->op, msg->context, flags);
 }
 
-static ssize_t psmx2_atomic_writev(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_writev(struct fid_ep *ep,
 				   const struct fi_ioc *iov,
 				   void **desc, size_t count,
 				   fi_addr_t dest_addr,
@@ -1079,7 +1061,8 @@ static ssize_t psmx2_atomic_writev(struct fid_ep *ep,
 					  ep_priv->tx_flags);
 }
 
-static ssize_t psmx2_atomic_inject(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_inject(struct fid_ep *ep,
 				   const void *buf,
 				   size_t count, /*void *desc,*/
 				   fi_addr_t dest_addr,
@@ -1114,8 +1097,6 @@ ssize_t psmx2_atomic_readwrite_generic(struct fid_ep *ep,
 	psm2_epaddr_t psm2_epaddr;
 	int am_flags = PSM2_AM_FLAG_ASYNC;
 	int chunk_size, len;
-	size_t idx;
-	int err;
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 
@@ -1132,18 +1113,9 @@ ssize_t psmx2_atomic_readwrite_generic(struct fid_ep *ep,
 	assert((int)op >= 0 && (int)op < FI_ATOMIC_OP_LAST);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(dest_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid)
@@ -1223,7 +1195,6 @@ ssize_t psmx2_atomic_readwritev_generic(struct fid_ep *ep,
 	psm2_epaddr_t psm2_epaddr;
 	int am_flags = PSM2_AM_FLAG_ASYNC;
 	int chunk_size;
-	size_t idx;
 	size_t len, result_len, iov_size;
 	uint8_t *buf, *result;
 	void *desc0, *result_desc0;
@@ -1269,18 +1240,9 @@ ssize_t psmx2_atomic_readwritev_generic(struct fid_ep *ep,
 	assert(result_len >= len);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(dest_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid) {
@@ -1386,7 +1348,8 @@ ssize_t psmx2_atomic_readwritev_generic(struct fid_ep *ep,
 	return 0;
 }
 
-static ssize_t psmx2_atomic_readwrite(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_readwrite(struct fid_ep *ep,
 				      const void *buf,
 				      size_t count, void *desc,
 				      void *result, void *result_desc,
@@ -1404,7 +1367,8 @@ static ssize_t psmx2_atomic_readwrite(struct fid_ep *ep,
 					      context, ep_priv->tx_flags);
 }
 
-static ssize_t psmx2_atomic_readwritemsg(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_readwritemsg(struct fid_ep *ep,
 					 const struct fi_msg_atomic *msg,
 					 struct fi_ioc *resultv,
 					 void **result_desc,
@@ -1450,7 +1414,8 @@ static ssize_t psmx2_atomic_readwritemsg(struct fid_ep *ep,
 					      msg->op, msg->context, flags);
 }
 
-static ssize_t psmx2_atomic_readwritev(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_readwritev(struct fid_ep *ep,
 				       const struct fi_ioc *iov,
 				       void **desc, size_t count,
 				       struct fi_ioc *resultv,
@@ -1511,8 +1476,6 @@ ssize_t psmx2_atomic_compwrite_generic(struct fid_ep *ep,
 	psm2_epaddr_t psm2_epaddr;
 	int am_flags = PSM2_AM_FLAG_ASYNC;
 	int chunk_size, len;
-	size_t idx;
-	int err;
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 
@@ -1530,18 +1493,9 @@ ssize_t psmx2_atomic_compwrite_generic(struct fid_ep *ep,
 	assert((int)op >= 0 && (int)op < FI_ATOMIC_OP_LAST);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(dest_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid)
@@ -1625,8 +1579,7 @@ ssize_t psmx2_atomic_compwritev_generic(struct fid_ep *ep,
 	psm2_epaddr_t psm2_epaddr;
 	int am_flags = PSM2_AM_FLAG_ASYNC;
 	int chunk_size;
-	size_t idx;
-	size_t len, compare_len, result_len, iov_size;
+	size_t len, iov_size;
 	uint8_t *buf, *compare, *result;
 	void *desc0, *compare_desc0, *result_desc0;
 	int err;
@@ -1664,25 +1617,14 @@ ssize_t psmx2_atomic_compwritev_generic(struct fid_ep *ep,
 		result_count--;
 
 	len = psmx2_ioc_size(iov, count, datatype);
-	compare_len = psmx2_ioc_size(comparev, compare_count, datatype);
-	result_len = psmx2_ioc_size(resultv, result_count, datatype);
 
-	assert(compare_len >= len);
-	assert(result_len >= len);
+	assert(psmx2_ioc_size(comparev, compare_count, datatype) >= len);
+	assert(psmx2_ioc_size(resultv, result_count, datatype) >= len);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(dest_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid) {
@@ -1810,7 +1752,8 @@ ssize_t psmx2_atomic_compwritev_generic(struct fid_ep *ep,
 	return 0;
 }
 
-static ssize_t psmx2_atomic_compwrite(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_compwrite(struct fid_ep *ep,
 				      const void *buf,
 				      size_t count, void *desc,
 				      const void *compare, void *compare_desc,
@@ -1830,7 +1773,8 @@ static ssize_t psmx2_atomic_compwrite(struct fid_ep *ep,
 					      datatype, op, context, ep_priv->tx_flags);
 }
 
-static ssize_t psmx2_atomic_compwritemsg(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_compwritemsg(struct fid_ep *ep,
 					 const struct fi_msg_atomic *msg,
 					 const struct fi_ioc *comparev,
 					 void **compare_desc,
@@ -1871,7 +1815,8 @@ static ssize_t psmx2_atomic_compwritemsg(struct fid_ep *ep,
 					      msg->op, msg->context, flags);
 }
 
-static ssize_t psmx2_atomic_compwritev(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_atomic_compwritev(struct fid_ep *ep,
 				       const struct fi_ioc *iov,
 				       void **desc, size_t count,
 				       const struct fi_ioc *comparev,
@@ -2021,7 +1966,8 @@ static int psmx2_atomic_compwritevalid_internal(size_t chunk_size,
 	return 0;
 }
 
-static int psmx2_atomic_writevalid(struct fid_ep *ep,
+DIRECT_FN
+STATIC int psmx2_atomic_writevalid(struct fid_ep *ep,
 				   enum fi_datatype datatype,
 				   enum fi_op op, size_t *count)
 {
@@ -2033,7 +1979,8 @@ static int psmx2_atomic_writevalid(struct fid_ep *ep,
 	return psmx2_atomic_writevalid_internal(chunk_size, datatype, op, count);
 }
 
-static int psmx2_atomic_readwritevalid(struct fid_ep *ep,
+DIRECT_FN
+STATIC int psmx2_atomic_readwritevalid(struct fid_ep *ep,
 				       enum fi_datatype datatype,
 				       enum fi_op op, size_t *count)
 {
@@ -2045,7 +1992,8 @@ static int psmx2_atomic_readwritevalid(struct fid_ep *ep,
 	return psmx2_atomic_readwritevalid_internal(chunk_size, datatype, op, count);
 }
 
-static int psmx2_atomic_compwritevalid(struct fid_ep *ep,
+DIRECT_FN
+STATIC int psmx2_atomic_compwritevalid(struct fid_ep *ep,
 				       enum fi_datatype datatype,
 				       enum fi_op op, size_t *count)
 {
@@ -2057,6 +2005,7 @@ static int psmx2_atomic_compwritevalid(struct fid_ep *ep,
 	return psmx2_atomic_compwritevalid_internal(chunk_size, datatype, op, count);
 }
 
+DIRECT_FN
 int psmx2_query_atomic(struct fid_domain *domain, enum fi_datatype datatype,
 		       enum fi_op op, struct fi_atomic_attr *attr, uint64_t flags)
 {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_av.c
index 4999bba23..cbcf5efdc 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_av.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_av.c
@@ -35,29 +35,21 @@
 /*
  * SEP address query protocol:
  *
- * SEQ Query REQ:
- *	args[0].u32w0	cmd
+ * SEP Query REQ:
+ *	args[0].u32w0	cmd, version
  *	args[0].u32w1	id
- *	args[1].u64	req
- *	args[2].u64	av_idx
+ *	args[1].u64	sep_info
+ *	args[2].u64	status
  *
  * SEP Query REP:
- *	args[0].u32w0	cmd
+ *	args[0].u32w0	cmd, version
  *	args[0].u32w1	error
- *	args[1].u64	req
- *	args[2].u64	av_idx
+ *	args[1].u64	sep_info
+ *	args[2].u64	status
  *	args[3].u64	n
- *	data		epaddrs
+ *	data		epids
  */
 
-struct psmx2_sep_query {
-	struct psmx2_fid_av	*av;
-	void 			*context;
-	psm2_error_t		*errors;
-	ofi_atomic32_t		error_count;
-	ofi_atomic32_t		pending;
-};
-
 static int psmx2_am_sep_match(struct dlist_entry *entry, const void *arg)
 {
 	struct psmx2_fid_sep *sep;
@@ -75,15 +67,15 @@ int psmx2_am_sep_handler(psm2_am_token_t token, psm2_amarg_t *args,
 			 int nargs, void *src, uint32_t len, void *hctx)
 {
 	struct psmx2_fid_domain *domain;
-	psm2_amarg_t rep_args[8];
+	psm2_amarg_t rep_args[4];
 	int op_error = 0;
 	int err = 0;
-	int cmd;
+	int cmd, version;
 	int n, i, j;
 	uint8_t sep_id;
 	struct psmx2_fid_sep *sep;
-	struct psmx2_sep_query *req;
-	struct psmx2_fid_av *av;
+	struct psmx2_av_sep *sep_info;
+	ofi_atomic32_t *status;
 	psm2_epid_t *epids;
 	psm2_epid_t *buf = NULL;
 	int buflen;
@@ -91,12 +83,20 @@ int psmx2_am_sep_handler(psm2_am_token_t token, psm2_amarg_t *args,
 	struct psmx2_trx_ctxt *trx_ctxt = hctx;
 
 	cmd = PSMX2_AM_GET_OP(args[0].u32w0);
+	version = PSMX2_AM_GET_VER(args[0].u32w0);
+	if (version != PSMX2_AM_SEP_VERSION) {
+		FI_WARN(&psmx2_prov, FI_LOG_AV,
+			"AM SEP protocol version mismatch: request %d handler %d\n",
+			version, PSMX2_AM_SEP_VERSION);
+		return -FI_EINVAL;
+	}
+
 	domain = trx_ctxt->domain;
 
 	switch (cmd) {
 	case PSMX2_AM_REQ_SEP_QUERY:
 		sep_id = args[0].u32w1;
-		psmx2_lock(&domain->sep_lock, 1);
+		domain->sep_lock_fn(&domain->sep_lock, 1);
 		entry = dlist_find_first_match(&domain->sep_list, psmx2_am_sep_match,
 					       (void *)(uintptr_t)sep_id);
 		if (!entry) {
@@ -110,7 +110,7 @@ int psmx2_am_sep_handler(psm2_am_token_t token, psm2_amarg_t *args,
 			if (n) {
 				buf = malloc(buflen);
 				if (!buf) {
-					op_error = -FI_ENOMEM;
+					op_error = PSM2_NO_MEMORY;
 					buflen = 0;
 					n = 0;
 				}
@@ -118,9 +118,10 @@ int psmx2_am_sep_handler(psm2_am_token_t token, psm2_amarg_t *args,
 					buf[i] = sep->ctxts[i].trx_ctxt->psm2_epid;
 			}
 		}
-		psmx2_unlock(&domain->sep_lock, 1);
+		domain->sep_unlock_fn(&domain->sep_lock, 1);
 
 		rep_args[0].u32w0 = PSMX2_AM_REP_SEP_QUERY;
+		PSMX2_AM_SET_VER(rep_args[0].u32w0, PSMX2_AM_SEP_VERSION);
 		rep_args[0].u32w1 = op_error;
 		rep_args[1].u64 = args[1].u64;
 		rep_args[2].u64 = args[2].u64;
@@ -132,31 +133,28 @@ int psmx2_am_sep_handler(psm2_am_token_t token, psm2_amarg_t *args,
 
 	case PSMX2_AM_REP_SEP_QUERY:
 		op_error = args[0].u32w1;
-		req = (void *)(uintptr_t)args[1].u64;
-		av = req->av;
-		i = args[2].u64;
+		sep_info = (struct psmx2_av_sep *)(uintptr_t)args[1].u64;
+		status = (void *)(uintptr_t)args[2].u64;
 		if (op_error) {
-			ofi_atomic_inc32(&req->error_count);
-			req->errors[i] = op_error;
+			ofi_atomic_set32(status, psmx2_errno(op_error));
 		} else {
 			n = args[3].u64;
 			epids = malloc(n * sizeof(psm2_epid_t));
 			if (!epids) {
-				ofi_atomic_inc32(&req->error_count);
-				req->errors[i] = PSM2_NO_MEMORY;
+				ofi_atomic_set32(status, -FI_ENOMEM);
 			} else {
 				for (j=0; j<n; j++)
 					epids[j] = ((psm2_epid_t *)src)[j];
 				/*
 				 * the sender of the SEP query request should
 				 * have acquired the lock and is waiting for
-				 * the response. see psmx2_av_connect_trx_ctxt.
+				 * the response. see psmx2_av_query_sep().
 				 */
-				av->peers[i].sep_ctxt_cnt = n;
-				av->peers[i].sep_ctxt_epids = epids;
+				sep_info->ctxt_cnt = n;
+				sep_info->epids = epids;
+				ofi_atomic_set32(status, 0);
 			}
 		}
-		ofi_atomic_dec32(&req->pending);
 		break;
 
 	default:
@@ -210,9 +208,9 @@ static void psmx2_set_epaddr_context(struct psmx2_trx_ctxt *trx_ctxt,
 	context->epaddr = epaddr;
 	psm2_epaddr_setctxt(epaddr, context);
 
-	psmx2_lock(&trx_ctxt->peer_lock, 2);
+	trx_ctxt->domain->peer_lock_fn(&trx_ctxt->peer_lock, 2);
 	dlist_insert_before(&context->entry, &trx_ctxt->peer_list);
-	psmx2_unlock(&trx_ctxt->peer_lock, 2);
+	trx_ctxt->domain->peer_unlock_fn(&trx_ctxt->peer_lock, 2);
 }
 
 int psmx2_epid_to_epaddr(struct psmx2_trx_ctxt *trx_ctxt,
@@ -234,16 +232,15 @@ int psmx2_epid_to_epaddr(struct psmx2_trx_ctxt *trx_ctxt,
 
 	err = psm2_ep_connect(trx_ctxt->psm2_ep, 1, &epid, NULL, &errors,
 			      epaddr, psmx2_conn_timeout(1));
-	if (err != PSM2_OK) {
-		FI_WARN(&psmx2_prov, FI_LOG_AV,
-			"psm2_ep_connect retured error %s, remote epid=%lx.\n",
-			psm2_error_get_string(err), epid);
-		return psmx2_errno(err);
+	if (err == PSM2_OK || err == PSM2_EPID_ALREADY_CONNECTED) {
+		psmx2_set_epaddr_context(trx_ctxt, epid, *epaddr);
+		return 0;
 	}
 
-	psmx2_set_epaddr_context(trx_ctxt,epid,*epaddr);
-
-	return 0;
+	FI_WARN(&psmx2_prov, FI_LOG_AV,
+		"psm2_ep_connect retured error %s, remote epid=%lx.\n",
+		psm2_error_get_string(err), epid);
+	return psmx2_errno(err);
 }
 
 /*
@@ -251,52 +248,67 @@ int psmx2_epid_to_epaddr(struct psmx2_trx_ctxt *trx_ctxt,
  */
 static int psmx2_av_check_space(struct psmx2_fid_av *av, size_t count)
 {
-	psm2_epid_t *new_epids;
 	psm2_epaddr_t *new_epaddrs;
 	psm2_epaddr_t **new_sepaddrs;
-	struct psmx2_av_peer *new_peers;
+	struct psmx2_av_hdr *new_hdr;
+	struct psmx2_av_sep *new_sep_info;
 	size_t new_count;
+	size_t old_table_size, new_table_size;
 	int i;
 
 	new_count = av->count;
-	while (new_count < av->last + count)
-		new_count = new_count * 2 + 1;
+	while (new_count < av->hdr->last + count)
+		new_count = new_count * 2;
 
-	if ((new_count <= av->count) && av->epids)
+	if ((new_count <= av->count) && av->table)
 		return 0;
 
-	new_epids = realloc(av->epids, new_count * sizeof(*new_epids));
-	if (!new_epids)
-		return -FI_ENOMEM;
-	av->epids = new_epids;
+	old_table_size = PSMX2_AV_TABLE_SIZE(av->count, av->shared);
+	new_table_size = PSMX2_AV_TABLE_SIZE(new_count, av->shared);
+	if (av->shared) {
+		new_hdr = mremap(av->hdr, old_table_size, new_table_size, 0);
+		if (new_hdr == MAP_FAILED)
+			return -FI_ENOMEM;
+		av->hdr = new_hdr;
+		av->map = (fi_addr_t *)(av->hdr + 1);
+		av->table = (struct psmx2_av_addr *)(av->map + new_count);
+		for (i = 0; i < new_count; i++)
+			av->map[i] = i;
+	} else {
+		new_hdr = realloc(av->hdr, new_table_size);
+		if (!new_hdr)
+			return -FI_ENOMEM;
+		av->hdr = new_hdr;
+		av->table = (struct psmx2_av_addr *)(av->hdr + 1);
+	}
 
-	new_peers = realloc(av->peers, new_count * sizeof(*new_peers));
-	if (!new_peers)
+	new_sep_info = realloc(av->sep_info, new_count * sizeof(*new_sep_info));
+	if (!new_sep_info)
 		return -FI_ENOMEM;
-	av->peers = new_peers;
+	av->sep_info = new_sep_info;
 
 	for (i = 0; i < av->max_trx_ctxt; i++) {
-		if (!av->tables[i].trx_ctxt)
+		if (!av->conn_info[i].trx_ctxt)
 			continue;
 
-		new_epaddrs = realloc(av->tables[i].epaddrs,
+		new_epaddrs = realloc(av->conn_info[i].epaddrs,
 				      new_count * sizeof(*new_epaddrs));
 		if (!new_epaddrs)
 			return -FI_ENOMEM;
-		memset(new_epaddrs + av->last, 0,
-		       (new_count - av->last)  * sizeof(*new_epaddrs));
-		av->tables[i].epaddrs = new_epaddrs;
+		memset(new_epaddrs + av->hdr->last, 0,
+		       (new_count - av->hdr->last)  * sizeof(*new_epaddrs));
+		av->conn_info[i].epaddrs = new_epaddrs;
 
-		new_sepaddrs = realloc(av->tables[i].sepaddrs,
+		new_sepaddrs = realloc(av->conn_info[i].sepaddrs,
 				       new_count * sizeof(*new_sepaddrs));
 		if (!new_sepaddrs)
 			return -FI_ENOMEM;
-		memset(new_sepaddrs + av->last, 0,
-		       (new_count - av->last)  * sizeof(*new_sepaddrs));
-		av->tables[i].sepaddrs = new_sepaddrs;
+		memset(new_sepaddrs + av->hdr->last, 0,
+		       (new_count - av->hdr->last)  * sizeof(*new_sepaddrs));
+		av->conn_info[i].sepaddrs = new_sepaddrs;
 	}
 
-	av->count = new_count;
+	av->count = av->hdr->size = new_count;
 	return 0;
 }
 
@@ -326,195 +338,53 @@ static void psmx2_av_post_completion(struct psmx2_fid_av *av, void *context,
 /*
  * Must be called with av->lock held
  */
-static int psmx2_av_connect_trx_ctxt(struct psmx2_fid_av *av,
-				     int trx_ctxt_id,
-				     size_t av_idx_start,
-				     size_t count,
-				     psm2_error_t *errors)
+static int psmx2_av_query_sep(struct psmx2_fid_av *av,
+			      struct psmx2_trx_ctxt *trx_ctxt,
+			      size_t idx)
 {
-	struct psmx2_trx_ctxt *trx_ctxt;
-	struct psmx2_sep_query *req;
-	struct psmx2_av_peer *peers;
-	struct psmx2_epaddr_context *epaddr_context;
-	psm2_epconn_t epconn;
-	psm2_ep_t ep;
-	psm2_epid_t *epids;
-	psm2_epaddr_t *epaddrs;
-	psm2_epaddr_t **sepaddrs;
+	ofi_atomic32_t status; /* 1: pending, 0: succ, <0: error */
 	psm2_amarg_t args[3];
-	int *mask;
-	int error_count = 0;
-	int to_connect = 0;
-	int sep_count = 0;
-	int i;
-
-	trx_ctxt = av->tables[trx_ctxt_id].trx_ctxt;
-	ep = trx_ctxt->psm2_ep;
-	epids = av->epids + av_idx_start;
-	epaddrs = av->tables[trx_ctxt_id].epaddrs + av_idx_start;
-	sepaddrs = av->tables[trx_ctxt_id].sepaddrs + av_idx_start;
-	peers = av->peers + av_idx_start;
-
-	/* set up mask to avoid duplicated connection */
-
-	mask = calloc(count, sizeof(*mask));
-	if (!mask) {
-		for (i = 0; i < count; i++)
-			errors[i] = PSM2_NO_MEMORY;
-		error_count += count;
-		return error_count;
-	}
+	int error;
 
-	for (i = 0; i < count; i++) {
-		errors[i] = PSM2_OK;
-
-		if (psm2_ep_epid_lookup2(ep, epids[i], &epconn) == PSM2_OK) {
-			epaddr_context = psm2_epaddr_getctxt(epconn.addr);
-			if (epaddr_context && epaddr_context->epid == epids[i])
-				epaddrs[i] = epconn.addr;
-			else
-				mask[i] = 1;
-		} else {
-			mask[i] = 1;
-		}
-
-		if (peers[i].type == PSMX2_EP_SCALABLE)
-			sep_count++;
-
-		if (mask[i]) {
-			if (peers[i].type == PSMX2_EP_SCALABLE) {
-				if (peers[i].sep_ctxt_epids)
-					mask[i] = 0;
-				 else
-					to_connect++;
-			} else if (psmx2_env.lazy_conn) {
-				epaddrs[i] = NULL;
-				mask[i] = 0;
-			} else {
-				to_connect++;
-			}
-		}
+	if (!av->conn_info[trx_ctxt->id].epaddrs[idx]) {
+		psmx2_epid_to_epaddr(trx_ctxt, av->table[idx].epid,
+				     &av->conn_info[trx_ctxt->id].epaddrs[idx]);
+		assert(av->conn_info[trx_ctxt->id].epaddrs[idx]);
 	}
 
-	if (to_connect)
-		psm2_ep_connect(ep, count, epids, mask, errors, epaddrs,
-				psmx2_conn_timeout(count));
-
-	/* check the connection results */
-
-	for (i = 0; i < count; i++) {
-		if (!mask[i]) {
-			errors[i] = PSM2_OK;
-			continue;
-		}
-
-		if (errors[i] == PSM2_OK ||
-		    errors[i] == PSM2_EPID_ALREADY_CONNECTED) {
-			psmx2_set_epaddr_context(trx_ctxt, epids[i], epaddrs[i]);
-			errors[i] = PSM2_OK;
-		} else {
-			/* If duplicated addrs are passed to psm2_ep_connect(),
-			 * all but one will fail with error "Endpoint could not
-			 * be reached". This should be treated the same as
-			 * "Endpoint already connected".
-			 */
-			if (psm2_ep_epid_lookup2(ep, epids[i], &epconn) == PSM2_OK) {
-				epaddr_context = psm2_epaddr_getctxt(epconn.addr);
-				if (epaddr_context &&
-				    epaddr_context->epid == epids[i]) {
-					epaddrs[i] = epconn.addr;
-					errors[i] = PSM2_OK;
-					continue;
-				}
-			}
-
-			FI_WARN(&psmx2_prov, FI_LOG_AV,
-				"%d: psm2_ep_connect (%lx --> %lx): %s\n",
-				i, trx_ctxt->psm2_epid, epids[i],
-				psm2_error_get_string(errors[i]));
-			epaddrs[i] = NULL;
-			error_count++;
-		}
-	}
-
-	free(mask);
-
-	if (sep_count) {
+	psmx2_am_init(trx_ctxt); /* check AM handler installation */
 
-		/* query SEP information */
+	ofi_atomic_initialize32(&status, 1);
 
-		psmx2_am_init(trx_ctxt); /* check AM handler installation */
+	args[0].u32w0 = PSMX2_AM_REQ_SEP_QUERY;
+	PSMX2_AM_SET_VER(args[0].u32w0, PSMX2_AM_SEP_VERSION);
+	args[0].u32w1 = av->table[idx].sep_id;
+	args[1].u64 = (uint64_t)(uintptr_t)&av->sep_info[idx];
+	args[2].u64 = (uint64_t)(uintptr_t)&status;
+	psm2_am_request_short(av->conn_info[trx_ctxt->id].epaddrs[idx],
+			      PSMX2_AM_SEP_HANDLER, args, 3, NULL,
+			      0, 0, NULL, NULL);
 
-		req = malloc(sizeof *req);
-		if (req) {
-			req->av = av;
-			req->errors = errors;
-			ofi_atomic_initialize32(&req->error_count, 0);
-			ofi_atomic_initialize32(&req->pending, 0);
-		}
-
-		for (i = 0; i < count; i++) {
-			if (peers[i].type != PSMX2_EP_SCALABLE ||
-			    peers[i].sep_ctxt_epids ||
-			    errors[i] != PSM2_OK)
-				continue;
-
-			if (!req) {
-				errors[i] = PSM2_NO_MEMORY;
-				error_count++;
-				continue;
-			}
-
-			ofi_atomic_inc32(&req->pending);
-			args[0].u32w0 = PSMX2_AM_REQ_SEP_QUERY;
-			args[0].u32w1 = peers[i].sep_id;
-			args[1].u64 = (uint64_t)(uintptr_t)req;
-			args[2].u64 = av_idx_start + i;
-			psm2_am_request_short(epaddrs[i], PSMX2_AM_SEP_HANDLER,
-					      args, 3, NULL, 0, 0, NULL, NULL);
-		}
-
-		/*
-		 * make it synchronous for now to:
-		 * (1) ensure the array "req->errors" is valid;
-		 * (2) simplify the logic of generating the final completion.
-		 */
-
-		if (req) {
-			/*
-			 * make sure AM is progressed promptly. don't call
-			 * psmx2_progress() which may call functions that
-			 * need to access the address vector.
-			 */
-			while (ofi_atomic_get32(&req->pending))
-				psm2_poll(trx_ctxt->psm2_ep);
-
-			error_count += ofi_atomic_get32(&req->error_count);
-			free(req);
-		}
-	}
-
-	/* alloate context specific epaddrs for SEP */
+	/*
+	 * make sure AM is progressed promptly. don't call
+	 * psmx2_progress() which may call functions that
+	 * need to access the address vector.
+	 */
+	while (ofi_atomic_get32(&status) == 1)
+		psm2_poll(trx_ctxt->psm2_ep);
 
-	for (i = 0; i < count; i++) {
-		if (peers[i].type == PSMX2_EP_SCALABLE &&
-		    peers[i].sep_ctxt_epids && !sepaddrs[i])
-			sepaddrs[i] = calloc(peers[i].sep_ctxt_cnt,
-					     sizeof(*sepaddrs[i]));
-	}
+	error = (int)(int32_t)ofi_atomic_get32(&status);
 
-	return error_count;
+	return error;
 }
 
 int psmx2_av_add_trx_ctxt(struct psmx2_fid_av *av,
-			  struct psmx2_trx_ctxt *trx_ctxt,
-			  int connect_now)
+			  struct psmx2_trx_ctxt *trx_ctxt)
 {
-	psm2_error_t *errors;
 	int id = trx_ctxt->id;
 	int err = 0;
 
-	psmx2_lock(&av->lock, 1);
+	av->domain->av_lock_fn(&av->lock, 1);
 
 	if (id >= av->max_trx_ctxt) {
 		FI_WARN(&psmx2_prov, FI_LOG_AV,
@@ -524,8 +394,8 @@ int psmx2_av_add_trx_ctxt(struct psmx2_fid_av *av,
 		goto out;
 	}
 
-	if (av->tables[id].trx_ctxt) {
-		if (av->tables[id].trx_ctxt == trx_ctxt) {
+	if (av->conn_info[id].trx_ctxt) {
+		if (av->conn_info[id].trx_ctxt == trx_ctxt) {
 			FI_INFO(&psmx2_prov, FI_LOG_AV,
 				"trx_ctxt(%p) with id(%d) already added.\n",
 				trx_ctxt, id);
@@ -539,36 +409,29 @@ int psmx2_av_add_trx_ctxt(struct psmx2_fid_av *av,
 		}
 	}
 
-	av->tables[id].epaddrs = (psm2_epaddr_t *) calloc(av->count,
+	av->conn_info[id].epaddrs = (psm2_epaddr_t *) calloc(av->count,
 							  sizeof(psm2_epaddr_t));
-	if (!av->tables[id].epaddrs) {
+	if (!av->conn_info[id].epaddrs) {
 		err = -FI_ENOMEM;
 		goto out;
 	}
 
-	av->tables[id].sepaddrs = (psm2_epaddr_t **)calloc(av->count,
+	av->conn_info[id].sepaddrs = (psm2_epaddr_t **)calloc(av->count,
 							   sizeof(psm2_epaddr_t *));
-	if (!av->tables[id].sepaddrs) {
+	if (!av->conn_info[id].sepaddrs) {
 		err = -FI_ENOMEM;
 		goto out;
 	}
 
-	av->tables[id].trx_ctxt = trx_ctxt;
-
-	if (connect_now) {
-		errors = calloc(av->count, sizeof(*errors));
-		if (errors) {
-			psmx2_av_connect_trx_ctxt(av, id, 0, av->last, errors);
-			free(errors);
-		}
-	}
+	av->conn_info[id].trx_ctxt = trx_ctxt;
 
 out:
-	psmx2_unlock(&av->lock, 1);
+	av->domain->av_unlock_fn(&av->lock, 1);
 	return err;
 }
 
-static int psmx2_av_insert(struct fid_av *av, const void *addr,
+DIRECT_FN
+STATIC int psmx2_av_insert(struct fid_av *av, const void *addr,
 			   size_t count, fi_addr_t *fi_addr,
 			   uint64_t flags, void *context)
 {
@@ -579,19 +442,23 @@ static int psmx2_av_insert(struct fid_av *av, const void *addr,
 	psm2_error_t *errors = NULL;
 	int error_count = 0;
 	int i, idx, ret;
-	int sep_count = 0;
 
 	assert(addr || !count);
 
 	av_priv = container_of(av, struct psmx2_fid_av, av);
 
-	psmx2_lock(&av_priv->lock, 1);
+	av_priv->domain->av_lock_fn(&av_priv->lock, 1);
 
 	if ((av_priv->flags & FI_EVENT) && !av_priv->eq) {
 		ret = -FI_ENOEQ;
 		goto out;
 	}
 
+	if (av_priv->flags & FI_READ) {
+		ret = -FI_EINVAL;
+		goto out;
+	}
+
 	if (psmx2_av_check_space(av_priv, count)) {
 		ret = -FI_ENOMEM;
 		goto out;
@@ -605,62 +472,37 @@ static int psmx2_av_insert(struct fid_av *av, const void *addr,
 
 	/* save the peer address information */
 	for (i = 0; i < count; i++) {
-		idx = av_priv->last + i;
+		idx = av_priv->hdr->last + i;
 		if (av_priv->addr_format == FI_ADDR_STR) {
 			ep_name = psmx2_string_to_ep_name(string_names[i]);
 			if (!ep_name) {
 				ret = -FI_EINVAL;
 				goto out;
 			}
-			av_priv->epids[idx] = ep_name->epid;
-			av_priv->peers[idx].type = ep_name->type;
-			av_priv->peers[idx].sep_id = ep_name->sep_id;
+			av_priv->table[idx].type = ep_name->type;
+			av_priv->table[idx].epid = ep_name->epid;
+			av_priv->table[idx].sep_id = ep_name->sep_id;
 			free(ep_name);
 		} else {
-			av_priv->epids[idx] = names[i].epid;
-			av_priv->peers[idx].type = names[i].type;
-			av_priv->peers[idx].sep_id = names[i].sep_id;
-		}
-		av_priv->peers[idx].sep_ctxt_cnt = 1;
-		av_priv->peers[idx].sep_ctxt_epids = NULL;
-		if (av_priv->peers[idx].type == PSMX2_EP_SCALABLE)
-			sep_count++;
-	}
-
-	/*
-	 * try to establish connection when:
-	 *  (1) there are Tx/Rx context(s) bound to the AV; and
-	 *  (2) the connection is desired right now
-	 */
-	if (sep_count || !psmx2_env.lazy_conn) {
-		for (i = 0; i < av_priv->max_trx_ctxt; i++) {
-			if (!av_priv->tables[i].trx_ctxt)
-				continue;
-
-			error_count = psmx2_av_connect_trx_ctxt(av_priv, i,
-								av_priv->last,
-								count, errors);
-
-			if (error_count || psmx2_env.lazy_conn)
-				break;
+			av_priv->table[idx].type = names[i].type;
+			av_priv->table[idx].epid = names[i].epid;
+			av_priv->table[idx].sep_id = names[i].sep_id;
 		}
+		av_priv->sep_info[idx].ctxt_cnt = 1;
+		av_priv->sep_info[idx].epids = NULL;
 	}
 
 	if (fi_addr) {
 		for (i = 0; i < count; i++) {
-			idx = av_priv->last + i;
+			idx = av_priv->hdr->last + i;
 			if (errors[i] != PSM2_OK)
 				fi_addr[i] = FI_ADDR_NOTAVAIL;
-			else if (av_priv->peers[idx].type == PSMX2_EP_SCALABLE)
-				fi_addr[i] = idx | PSMX2_SEP_ADDR_FLAG;
-			else if (av_priv->type == FI_AV_TABLE)
-				fi_addr[i] = idx;
 			else
-				fi_addr[i] = PSMX2_EP_TO_ADDR(av_priv->tables[0].epaddrs[idx]);
+				fi_addr[i] = idx;
 		}
 	}
 
-	av_priv->last += count;
+	av_priv->hdr->last += count;
 
 	if (av_priv->flags & FI_EVENT) {
 		if (error_count) {
@@ -680,23 +522,106 @@ static int psmx2_av_insert(struct fid_av *av, const void *addr,
 
 out:
 	free(errors);
-	psmx2_unlock(&av_priv->lock, 1);
+	av_priv->domain->av_unlock_fn(&av_priv->lock, 1);
 	return ret;
 }
 
-static int psmx2_av_remove(struct fid_av *av, fi_addr_t *fi_addr, size_t count,
+
+static int psmx2_av_disconnect_addr(int trx_ctxt_id, psm2_epid_t epid,
+				    psm2_epaddr_t epaddr)
+{
+	struct psmx2_epaddr_context *epaddr_context;
+	psm2_error_t errors;
+	int err;
+
+	if (!epaddr)
+		return 0;
+
+	FI_INFO(&psmx2_prov, FI_LOG_AV,
+		"trx_ctxt_id %d epid %lx epaddr %p\n", trx_ctxt_id, epid, epaddr);
+
+	epaddr_context = psm2_epaddr_getctxt(epaddr);
+	if (!epaddr_context)
+		return -FI_EINVAL;
+
+	if (trx_ctxt_id != epaddr_context->trx_ctxt->id)
+		return -FI_EINVAL;
+
+	if (epid != epaddr_context->epid)
+		return -FI_EINVAL;
+
+	err = psm2_ep_disconnect2(epaddr_context->trx_ctxt->psm2_ep, 1, &epaddr,
+				  NULL, &errors, PSM2_EP_DISCONNECT_FORCE, 0);
+
+	return psmx2_errno(err);
+}
+
+DIRECT_FN
+STATIC int psmx2_av_remove(struct fid_av *av, fi_addr_t *fi_addr, size_t count,
 			   uint64_t flags)
 {
+	struct psmx2_fid_av *av_priv;
+	int idx, i, j, k;
+	int err;
+
+	av_priv = container_of(av, struct psmx2_fid_av, av);
+
+	av_priv->domain->av_lock_fn(&av_priv->lock, 1);
+
+	for (i = 0; i < count; i++) {
+		idx = PSMX2_ADDR_IDX(fi_addr[i]);
+		if (idx >= av_priv->hdr->last) {
+			FI_WARN(&psmx2_prov, FI_LOG_AV,
+				"AV index out of range: fi_addr %lx idx %d last %ld\n",
+				fi_addr[i], idx, av_priv->hdr->last);
+			continue;
+		}
+
+		if (av_priv->table[idx].type == PSMX2_EP_REGULAR) {
+			for (j = 0; j < av_priv->max_trx_ctxt; j++) {
+				if (!av_priv->conn_info[j].trx_ctxt)
+					continue;
+
+				err = psmx2_av_disconnect_addr(
+						j, av_priv->table[idx].epid,
+						av_priv->conn_info[j].epaddrs[idx]);
+				if (!err)
+					av_priv->conn_info[j].epaddrs[idx] = NULL;
+			}
+		} else {
+			if (!av_priv->sep_info[idx].epids)
+				continue;
+
+			for (j = 0; j < av_priv->max_trx_ctxt; j++) {
+				if (!av_priv->conn_info[j].trx_ctxt)
+					continue;
+
+				if (!av_priv->conn_info[j].sepaddrs[idx])
+					continue;
+
+				for (k = 0; k < av_priv->sep_info[idx].ctxt_cnt; k++) {
+					err = psmx2_av_disconnect_addr(
+							j, av_priv->sep_info[idx].epids[k],
+							av_priv->conn_info[j].sepaddrs[idx][k]);
+					if (!err)
+						av_priv->conn_info[j].sepaddrs[idx][k] = NULL;
+				}
+			}
+		}
+	}
+
+	av_priv->domain->av_unlock_fn(&av_priv->lock, 1);
+
 	return 0;
 }
 
-static int psmx2_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr,
+DIRECT_FN
+STATIC int psmx2_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr,
 			   size_t *addrlen)
 {
 	struct psmx2_fid_av *av_priv;
-	struct psmx2_epaddr_context *context;
 	struct psmx2_ep_name name;
-	int idx;
+	int idx = PSMX2_ADDR_IDX(fi_addr);
 	int err = 0;
 
 	assert(addr);
@@ -706,31 +631,17 @@ static int psmx2_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr,
 
 	memset(&name, 0, sizeof(name));
 
-	psmx2_lock(&av_priv->lock, 1);
+	av_priv->domain->av_lock_fn(&av_priv->lock, 1);
 
-	if (PSMX2_SEP_ADDR_TEST(fi_addr)) {
-		idx = PSMX2_SEP_ADDR_IDX(fi_addr);
-		if (idx >= av_priv->last) {
-			err = -FI_EINVAL;
-			goto out;
-		}
-		name.type = PSMX2_EP_SCALABLE;
-		name.epid = av_priv->epids[idx];
-		name.sep_id = av_priv->peers[idx].sep_id;
-	} else if (av_priv->type == FI_AV_TABLE) {
-		idx = (int)(int64_t)fi_addr;
-		if (idx >= av_priv->last) {
-			err = -FI_EINVAL;
-			goto out;
-		}
-		name.type = PSMX2_EP_REGULAR;
-		name.epid = av_priv->epids[idx];
-	} else {
-		context = psm2_epaddr_getctxt(PSMX2_ADDR_TO_EP(fi_addr));
-		name.type = PSMX2_EP_REGULAR;
-		name.epid = context->epid;
+	if (idx >= av_priv->hdr->last) {
+		err = -FI_EINVAL;
+		goto out;
 	}
 
+	name.type = av_priv->table[idx].type;
+	name.epid = av_priv->table[idx].epid;
+	name.sep_id = av_priv->table[idx].sep_id;
+
 	if (av_priv->addr_format == FI_ADDR_STR) {
 		ofi_straddr(addr, addrlen, FI_ADDR_PSMX2, &name);
 	} else {
@@ -739,75 +650,90 @@ static int psmx2_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr,
 	}
 
 out:
-	psmx2_unlock(&av_priv->lock, 1);
+	av_priv->domain->av_unlock_fn(&av_priv->lock, 1);
 	return err;
 }
 
-psm2_epaddr_t psmx2_av_translate_sep(struct psmx2_fid_av *av,
-				     struct psmx2_trx_ctxt *trx_ctxt,
-				     fi_addr_t addr)
+psm2_epaddr_t psmx2_av_translate_addr(struct psmx2_fid_av *av,
+				      struct psmx2_trx_ctxt *trx_ctxt,
+				      fi_addr_t addr)
 {
-	int idx = PSMX2_SEP_ADDR_IDX(addr);
-	int ctxt = PSMX2_SEP_ADDR_CTXT(addr, av->rx_ctx_bits);
-	psm2_epaddr_t epaddr = NULL;
-	psm2_error_t errors;
-	int err;
-
-	psmx2_lock(&av->lock, 1);
+	psm2_epaddr_t epaddr;
+	size_t idx = PSMX2_ADDR_IDX(addr);
+	int ctxt;
+	int err = 0;
 
-	if (av->peers[idx].type != PSMX2_EP_SCALABLE ||
-	    ctxt >= av->peers[idx].sep_ctxt_cnt)
-		goto out;
+	av->domain->av_lock_fn(&av->lock, 1);
+	assert(idx < av->hdr->last);
 
-	/* this can be NULL when lazy connection is enabled */
-	if (!av->tables[trx_ctxt->id].sepaddrs[idx]) {
-		psmx2_av_connect_trx_ctxt(av, trx_ctxt->id, idx, 1, &errors);
-		assert(av->tables[trx_ctxt->id].sepaddrs[idx]);
-	}
+	if (av->table[idx].type == PSMX2_EP_SCALABLE) {
+		if (!av->sep_info[idx].epids) {
+			psmx2_av_query_sep(av, trx_ctxt, idx);
+			assert(av->sep_info[idx].epids);
+		}
 
-	if (!av->tables[trx_ctxt->id].sepaddrs[idx][ctxt]) {
-		err = psmx2_epid_to_epaddr(trx_ctxt,
-					   av->peers[idx].sep_ctxt_epids[ctxt],
-					   &epaddr);
-		if (err) {
-			FI_WARN(&psmx2_prov, FI_LOG_AV,
-				"fatal error: unable to translate epid %lx to epaddr.\n",
-				av->peers[idx].sep_ctxt_epids[ctxt]);
-			goto out;
+		if (!av->conn_info[trx_ctxt->id].sepaddrs[idx]) {
+			av->conn_info[trx_ctxt->id].sepaddrs[idx] =
+				calloc(av->sep_info[idx].ctxt_cnt, sizeof(psm2_epaddr_t));
+			assert(av->conn_info[trx_ctxt->id].sepaddrs[idx]);
 		}
 
-		av->tables[trx_ctxt->id].sepaddrs[idx][ctxt] = epaddr;
-	}
+		ctxt = PSMX2_ADDR_CTXT(addr, av->rx_ctx_bits);
+		assert(ctxt < av->sep_info[idx].ctxt_cnt);
 
-	epaddr = av->tables[trx_ctxt->id].sepaddrs[idx][ctxt];
+		if (!av->conn_info[trx_ctxt->id].sepaddrs[idx][ctxt]) {
+			err = psmx2_epid_to_epaddr(trx_ctxt,
+						   av->sep_info[idx].epids[ctxt],
+						   &av->conn_info[trx_ctxt->id].sepaddrs[idx][ctxt]);
+			assert(!err);
+		}
+		epaddr = av->conn_info[trx_ctxt->id].sepaddrs[idx][ctxt];
+	} else {
+		if (!av->conn_info[trx_ctxt->id].epaddrs[idx]) {
+			err = psmx2_epid_to_epaddr(trx_ctxt, av->table[idx].epid,
+						   &av->conn_info[trx_ctxt->id].epaddrs[idx]);
+			assert(!err);
+		}
+		epaddr = av->conn_info[trx_ctxt->id].epaddrs[idx];
+	}
 
-out:
-	psmx2_unlock(&av->lock, 1);
+#ifdef NDEBUG
+	(void) err;
+#endif
+	av->domain->av_unlock_fn(&av->lock, 1);
 	return epaddr;
 }
 
-fi_addr_t psmx2_av_translate_source(struct psmx2_fid_av *av, fi_addr_t source)
+fi_addr_t psmx2_av_translate_source(struct psmx2_fid_av *av, psm2_epaddr_t source)
 {
-	psm2_epaddr_t epaddr;
 	psm2_epid_t epid;
 	fi_addr_t ret = FI_ADDR_NOTAVAIL;
 	int i, j, found = 0;
 
-	epaddr = PSMX2_ADDR_TO_EP(source);
-	psm2_epaddr_to_epid(epaddr, &epid);
+	psm2_epaddr_to_epid(source, &epid);
 
-	psmx2_lock(&av->lock, 1);
+	av->domain->av_lock_fn(&av->lock, 1);
 
-	for (i = av->last - 1; i >= 0 && !found; i--) {
-		if (av->peers[i].type == PSMX2_EP_REGULAR) {
-			if (av->epids[i] == epid) {
-				ret = (av->type == FI_AV_MAP) ?
-				      source : (fi_addr_t)i;
+	for (i = av->hdr->last - 1; i >= 0 && !found; i--) {
+		if (av->table[i].type == PSMX2_EP_REGULAR) {
+			if (av->table[i].epid == epid) {
+				ret = (fi_addr_t)i;
 				found = 1;
 			}
 		} else {
-			for (j=0; j<av->peers[i].sep_ctxt_cnt; j++) {
-				if (av->peers[i].sep_ctxt_epids[j] == epid) {
+			if (!av->sep_info[i].epids) {
+				for (j = 0; j < av->max_trx_ctxt; j++) {
+					if (av->conn_info[j].trx_ctxt)
+						break;
+				}
+				if (j >= av->max_trx_ctxt)
+					continue;
+				psmx2_av_query_sep(av, av->conn_info[j].trx_ctxt, i);
+				if (!av->sep_info[i].epids)
+					continue;
+			}
+			for (j=0; j<av->sep_info[i].ctxt_cnt; j++) {
+				if (av->sep_info[i].epids[j] == epid) {
 					ret = fi_rx_addr((fi_addr_t)i, j,
 							 av->rx_ctx_bits);
 					found = 1;
@@ -817,7 +743,7 @@ fi_addr_t psmx2_av_translate_source(struct psmx2_fid_av *av, fi_addr_t source)
 		}
 	}
 
-	psmx2_unlock(&av->lock, 1);
+	av->domain->av_unlock_fn(&av->lock, 1);
 	return ret;
 }
 
@@ -830,27 +756,30 @@ void psmx2_av_remove_conn(struct psmx2_fid_av *av,
 
 	psm2_epaddr_to_epid(epaddr, &epid);
 
-	psmx2_lock(&av->lock, 1);
+	av->domain->av_lock_fn(&av->lock, 1);
 
-	for (i = 0; i < av->last; i++) {
-		if (av->peers[i].type == PSMX2_EP_REGULAR) {
-			if (av->epids[i] == epid &&
-			    av->tables[trx_ctxt->id].epaddrs[i] == epaddr)
-				av->tables[trx_ctxt->id].epaddrs[i] = NULL;
+	for (i = 0; i < av->hdr->last; i++) {
+		if (av->table[i].type == PSMX2_EP_REGULAR) {
+			if (av->table[i].epid == epid &&
+			    av->conn_info[trx_ctxt->id].epaddrs[i] == epaddr)
+				av->conn_info[trx_ctxt->id].epaddrs[i] = NULL;
 		} else {
-			for (j=0; j<av->peers[i].sep_ctxt_cnt; j++) {
-				if (av->peers[i].sep_ctxt_epids[j] == epid &&
-				    av->tables[trx_ctxt->id].sepaddrs[i] &&
-				    av->tables[trx_ctxt->id].sepaddrs[i][j] == epaddr)
-					    av->tables[trx_ctxt->id].sepaddrs[i][j] = NULL;
+			if (!av->sep_info[i].epids)
+				continue;
+			for (j=0; j<av->sep_info[i].ctxt_cnt; j++) {
+				if (av->sep_info[i].epids[j] == epid &&
+				    av->conn_info[trx_ctxt->id].sepaddrs[i] &&
+				    av->conn_info[trx_ctxt->id].sepaddrs[i][j] == epaddr)
+					    av->conn_info[trx_ctxt->id].sepaddrs[i][j] = NULL;
 			}
 		}
 	}
 
-	psmx2_unlock(&av->lock, 1);
+	av->domain->av_unlock_fn(&av->lock, 1);
 }
 
-static const char *psmx2_av_straddr(struct fid_av *av, const void *addr,
+DIRECT_FN
+STATIC const char *psmx2_av_straddr(struct fid_av *av, const void *addr,
 				    char *buf, size_t *len)
 {
 	return ofi_straddr(buf, len, FI_ADDR_PSMX2, addr);
@@ -860,27 +789,36 @@ static int psmx2_av_close(fid_t fid)
 {
 	struct psmx2_fid_av *av;
 	int i, j;
+	int err;
 
 	av = container_of(fid, struct psmx2_fid_av, av.fid);
 	psmx2_domain_release(av->domain);
 	fastlock_destroy(&av->lock);
 	for (i = 0; i < av->max_trx_ctxt; i++) {
-		if (!av->tables[i].trx_ctxt)
+		if (!av->conn_info[i].trx_ctxt)
 			continue;
-		free(av->tables[i].epaddrs);
-		if (av->tables[i].sepaddrs) {
-			for (j = 0; j < av->last; j++)
-				free(av->tables[i].sepaddrs[j]);
+		free(av->conn_info[i].epaddrs);
+		if (av->conn_info[i].sepaddrs) {
+			for (j = 0; j < av->hdr->last; j++)
+				free(av->conn_info[i].sepaddrs[j]);
 		}
-		free(av->tables[i].sepaddrs);
+		free(av->conn_info[i].sepaddrs);
+	}
+	if (av->shared) {
+		err = ofi_shm_unmap(&av->shm);
+		if (err)
+			FI_INFO(&psmx2_prov, FI_LOG_AV,
+				"Failed to unmap shared AV: %s.\n",
+				strerror(ofi_syserr()));
+	} else {
+		free(av->hdr);
 	}
-	free(av->peers);
-	free(av->epids);
 	free(av);
 	return 0;
 }
 
-static int psmx2_av_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
+DIRECT_FN
+STATIC int psmx2_av_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 {
 	struct psmx2_fid_av *av;
 
@@ -918,66 +856,35 @@ static struct fi_ops_av psmx2_av_ops = {
 	.straddr = psmx2_av_straddr,
 };
 
+DIRECT_FN
 int psmx2_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 		  struct fid_av **av, void *context)
 {
 	struct psmx2_fid_domain *domain_priv;
 	struct psmx2_fid_av *av_priv;
-	int type;
-	size_t count = 64;
+	size_t count = PSMX2_AV_DEFAULT_SIZE;
 	uint64_t flags = 0;
+	int shared = 0;
 	int rx_ctx_bits = PSMX2_MAX_RX_CTX_BITS;
+	size_t conn_size;
 	size_t table_size;
+	int err;
+	int i;
 
 	domain_priv = container_of(domain, struct psmx2_fid_domain,
 				   util_domain.domain_fid);
 
-	if (psmx2_env.lazy_conn || psmx2_env.max_trx_ctxt > 1)
-		type = FI_AV_TABLE;
-	else
-		type = FI_AV_MAP;
-
 	if (attr) {
-		switch (attr->type) {
-		case FI_AV_UNSPEC:
-			break;
-
-		case FI_AV_MAP:
-			if (psmx2_env.lazy_conn) {
-				FI_INFO(&psmx2_prov, FI_LOG_AV,
-					"Lazy connection is enabled, force FI_AV_TABLE\n");
-				break;
-			}
-			if (psmx2_env.max_trx_ctxt > 1) {
-				FI_INFO(&psmx2_prov, FI_LOG_AV,
-					"Multi-EP is enabled, force FI_AV_TABLE\n");
-				break;
-			}
-			/* fall through */
-		case FI_AV_TABLE:
-			type = attr->type;
-			break;
-		default:
-			FI_INFO(&psmx2_prov, FI_LOG_AV,
-				"attr->type=%d, supported=%d %d\n",
-				attr->type, FI_AV_MAP, FI_AV_TABLE);
-			return -FI_EINVAL;
-		}
+		if (attr->count)
+			count = attr->count;
 
-		count = attr->count;
-		flags = attr->flags;
+		if (attr->name)
+			shared = 1;
 
-		if (flags & (FI_READ | FI_SYMMETRIC)) {
-			FI_INFO(&psmx2_prov, FI_LOG_AV,
-				"attr->flags=%"PRIu64", supported=%llu\n",
-				attr->flags, FI_EVENT);
-			return -FI_ENOSYS;
-		}
-
-		if (attr->name) {
+		flags = attr->flags;
+		if (flags & FI_SYMMETRIC) {
 			FI_INFO(&psmx2_prov, FI_LOG_AV,
-				"attr->name=%s, named AV is not supported\n",
-				attr->name);
+				"FI_SYMMETRIC flags is no supported\n");
 			return -FI_ENOSYS;
 		}
 
@@ -991,17 +898,60 @@ int psmx2_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 		rx_ctx_bits = attr->rx_ctx_bits;
 	}
 
-	table_size = psmx2_env.max_trx_ctxt * sizeof(struct psmx2_av_table);
-	av_priv = (struct psmx2_fid_av *) calloc(1, sizeof(*av_priv) + table_size);
+	conn_size = psmx2_env.max_trx_ctxt * sizeof(struct psmx2_av_conn);
+	av_priv = (struct psmx2_fid_av *) calloc(1, sizeof(*av_priv) + conn_size);
 	if (!av_priv)
 		return -FI_ENOMEM;
 
+	av_priv->sep_info = calloc(count, sizeof(struct psmx2_av_sep));
+	if (!av_priv->sep_info) {
+		err = -FI_ENOMEM;
+		goto errout_free;
+	}
+
+	table_size = PSMX2_AV_TABLE_SIZE(count, shared);
+	if (attr && attr->name) {
+		err = ofi_shm_map(&av_priv->shm, attr->name, table_size,
+				  flags & FI_READ, (void**)&av_priv->hdr);
+		if (err || av_priv->hdr == MAP_FAILED) {
+			FI_WARN(&psmx2_prov, FI_LOG_AV,
+				"failed to map shared AV: %s\n", attr->name);
+			err = -FI_EINVAL;
+			goto errout_free;
+		}
+
+		if (flags & FI_READ) {
+			if (av_priv->hdr->size != count) {
+				FI_WARN(&psmx2_prov, FI_LOG_AV,
+					"AV size doesn't match: shared %ld, asking %ld\n",
+					av_priv->hdr->size, count);
+				err = -FI_EINVAL;
+				goto errout_free;
+			}
+		} else {
+			av_priv->hdr->size = count;
+			av_priv->hdr->last = 0;
+		}
+		av_priv->shared = 1;
+		av_priv->map = (fi_addr_t *)(av_priv->hdr + 1);
+		av_priv->table = (struct psmx2_av_addr *)(av_priv->map + count);
+		for (i = 0; i < count; i++)
+			av_priv->map[i] = i;
+	} else {
+		av_priv->hdr = calloc(1, table_size);
+		if (!av_priv->hdr) {
+			err = -FI_ENOMEM;
+			goto errout_free;
+		}
+		av_priv->hdr->size = count;
+		av_priv->table = (struct psmx2_av_addr *)(av_priv->hdr + 1);
+	}
+
 	fastlock_init(&av_priv->lock);
 
 	psmx2_domain_acquire(domain_priv);
 
 	av_priv->domain = domain_priv;
-	av_priv->type = type;
 	av_priv->addrlen = sizeof(psm2_epaddr_t);
 	av_priv->count = count;
 	av_priv->flags = flags;
@@ -1015,12 +965,17 @@ int psmx2_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 	av_priv->av.ops = &psmx2_av_ops;
 
 	*av = &av_priv->av;
-	if (attr)
-		attr->type = type;
-
-	FI_INFO(&psmx2_prov, FI_LOG_AV,
-		"type = %s\n", fi_tostr(&type, FI_TYPE_AV_TYPE));
+	if (attr) {
+		attr->type = FI_AV_TABLE;
+		if (shared)
+			attr->map_addr = av_priv->map;
+	}
 
 	return 0;
+
+errout_free:
+	free(av_priv->sep_info);
+	free(av_priv);
+	return err;
 }
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cm.c
index dba162439..239506e7a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cm.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cm.c
@@ -32,7 +32,8 @@
 
 #include "psmx2.h"
 
-static int psmx2_cm_getname(fid_t fid, void *addr, size_t *addrlen)
+DIRECT_FN
+STATIC int psmx2_cm_getname(fid_t fid, void *addr, size_t *addrlen)
 {
 	struct psmx2_fid_ep *ep;
 	struct psmx2_fid_sep *sep;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cntr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cntr.c
index cc9d07d7e..f176630a4 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cntr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cntr.c
@@ -42,7 +42,7 @@ void psmx2_cntr_check_trigger(struct psmx2_fid_cntr *cntr)
 	if (!cntr->trigger)
 		return;
 
-	psmx2_lock(&cntr->trigger_lock, 2);
+	cntr->domain->trigger_lock_fn(&cntr->trigger_lock, 2);
 
 	trigger = cntr->trigger;
 	while (trigger) {
@@ -65,10 +65,10 @@ void psmx2_cntr_check_trigger(struct psmx2_fid_cntr *cntr)
 		}
 
 		if (trx_ctxt->am_initialized) {
-			psmx2_lock(&trx_ctxt->trigger_queue.lock, 2);
+			cntr->domain->trigger_queue_lock_fn(&trx_ctxt->trigger_queue.lock, 2);
 			slist_insert_tail(&trigger->list_entry,
 					  &trx_ctxt->trigger_queue.list);
-			psmx2_unlock(&trx_ctxt->trigger_queue.lock, 2);
+			cntr->domain->trigger_queue_unlock_fn(&trx_ctxt->trigger_queue.lock, 2);
 		} else {
 			psmx2_process_trigger(trx_ctxt, trigger);
 		}
@@ -76,7 +76,7 @@ void psmx2_cntr_check_trigger(struct psmx2_fid_cntr *cntr)
 		trigger = cntr->trigger;
 	}
 
-	psmx2_unlock(&cntr->trigger_lock, 2);
+	cntr->domain->trigger_unlock_fn(&cntr->trigger_lock, 2);
 }
 
 void psmx2_cntr_add_trigger(struct psmx2_fid_cntr *cntr,
@@ -84,7 +84,7 @@ void psmx2_cntr_add_trigger(struct psmx2_fid_cntr *cntr,
 {
 	struct psmx2_trigger *p, *q;
 
-	psmx2_lock(&cntr->trigger_lock, 2);
+	cntr->domain->trigger_lock_fn(&cntr->trigger_lock, 2);
 
 	q = NULL;
 	p = cntr->trigger;
@@ -98,12 +98,13 @@ void psmx2_cntr_add_trigger(struct psmx2_fid_cntr *cntr,
 		cntr->trigger = trigger;
 	trigger->next = p;
 
-	psmx2_unlock(&cntr->trigger_lock, 2);
+	cntr->domain->trigger_unlock_fn(&cntr->trigger_lock, 2);
 
 	psmx2_cntr_check_trigger(cntr);
 }
 
-static uint64_t psmx2_cntr_read(struct fid_cntr *cntr)
+DIRECT_FN
+STATIC uint64_t psmx2_cntr_read(struct fid_cntr *cntr)
 {
 	struct psmx2_fid_cntr *cntr_priv;
 	struct psmx2_poll_ctxt *poll_ctxt;
@@ -126,7 +127,8 @@ static uint64_t psmx2_cntr_read(struct fid_cntr *cntr)
 	return ofi_atomic_get64(&cntr_priv->counter);
 }
 
-static uint64_t psmx2_cntr_readerr(struct fid_cntr *cntr)
+DIRECT_FN
+STATIC uint64_t psmx2_cntr_readerr(struct fid_cntr *cntr)
 {
 	struct psmx2_fid_cntr *cntr_priv;
 
@@ -136,7 +138,8 @@ static uint64_t psmx2_cntr_readerr(struct fid_cntr *cntr)
 	return ofi_atomic_get64(&cntr_priv->error_counter);
 }
 
-static int psmx2_cntr_add(struct fid_cntr *cntr, uint64_t value)
+DIRECT_FN
+STATIC int psmx2_cntr_add(struct fid_cntr *cntr, uint64_t value)
 {
 	struct psmx2_fid_cntr *cntr_priv;
 
@@ -151,7 +154,8 @@ static int psmx2_cntr_add(struct fid_cntr *cntr, uint64_t value)
 	return 0;
 }
 
-static int psmx2_cntr_set(struct fid_cntr *cntr, uint64_t value)
+DIRECT_FN
+STATIC int psmx2_cntr_set(struct fid_cntr *cntr, uint64_t value)
 {
 	struct psmx2_fid_cntr *cntr_priv;
 
@@ -166,7 +170,8 @@ static int psmx2_cntr_set(struct fid_cntr *cntr, uint64_t value)
 	return 0;
 }
 
-static int psmx2_cntr_adderr(struct fid_cntr *cntr, uint64_t value)
+DIRECT_FN
+STATIC int psmx2_cntr_adderr(struct fid_cntr *cntr, uint64_t value)
 {
 	struct psmx2_fid_cntr *cntr_priv;
 
@@ -182,7 +187,8 @@ static int psmx2_cntr_adderr(struct fid_cntr *cntr, uint64_t value)
 	return 0;
 }
 
-static int psmx2_cntr_seterr(struct fid_cntr *cntr, uint64_t value)
+DIRECT_FN
+STATIC int psmx2_cntr_seterr(struct fid_cntr *cntr, uint64_t value)
 {
 	struct psmx2_fid_cntr *cntr_priv;
 
@@ -198,7 +204,8 @@ static int psmx2_cntr_seterr(struct fid_cntr *cntr, uint64_t value)
 	return 0;
 }
 
-static int psmx2_cntr_wait(struct fid_cntr *cntr, uint64_t threshold, int timeout)
+DIRECT_FN
+STATIC int psmx2_cntr_wait(struct fid_cntr *cntr, uint64_t threshold, int timeout)
 {
 	struct psmx2_fid_cntr *cntr_priv;
 	struct psmx2_poll_ctxt *poll_ctxt;
@@ -269,6 +276,8 @@ static int psmx2_cntr_close(fid_t fid)
 	while (!slist_empty(&cntr->poll_list)) {
 		entry = slist_remove_head(&cntr->poll_list);
 		item = container_of(entry, struct psmx2_poll_ctxt, list_entry);
+		if (!ofi_atomic_dec32(&item->trx_ctxt->poll_refcnt))
+			free(item->trx_ctxt);
 		free(item);
 	}
 
@@ -335,6 +344,7 @@ static struct fi_ops_cntr psmx2_cntr_ops = {
 	.seterr = psmx2_cntr_seterr,
 };
 
+DIRECT_FN
 int psmx2_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
 			struct fid_cntr **cntr, void *context)
 {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cq.c
index 4f1356f16..f3d877b98 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_cq.c
@@ -35,10 +35,10 @@
 void psmx2_cq_enqueue_event(struct psmx2_fid_cq *cq,
 			    struct psmx2_cq_event *event)
 {
-	psmx2_lock(&cq->lock, 2);
+	cq->domain->cq_lock_fn(&cq->lock, 2);
 	slist_insert_tail(&event->list_entry, &cq->event_queue);
 	cq->event_count++;
-	psmx2_unlock(&cq->lock, 2);
+	cq->domain->cq_unlock_fn(&cq->lock, 2);
 
 	if (cq->wait)
 		cq->wait->signal(cq->wait);
@@ -48,14 +48,14 @@ static struct psmx2_cq_event *psmx2_cq_dequeue_event(struct psmx2_fid_cq *cq)
 {
 	struct slist_entry *entry;
 
-	psmx2_lock(&cq->lock, 2);
+	cq->domain->cq_lock_fn(&cq->lock, 2);
 	if (slist_empty(&cq->event_queue)) {
-		psmx2_unlock(&cq->lock, 2);
+		cq->domain->cq_unlock_fn(&cq->lock, 2);
 		return NULL;
 	}
 	entry = slist_remove_head(&cq->event_queue);
 	cq->event_count--;
-	psmx2_unlock(&cq->lock, 2);
+	cq->domain->cq_unlock_fn(&cq->lock, 2);
 
 	return container_of(entry, struct psmx2_cq_event, list_entry);
 }
@@ -64,15 +64,15 @@ static struct psmx2_cq_event *psmx2_cq_alloc_event(struct psmx2_fid_cq *cq)
 {
 	struct psmx2_cq_event *event;
 
-	psmx2_lock(&cq->lock, 2);
+	cq->domain->cq_lock_fn(&cq->lock, 2);
 	if (!slist_empty(&cq->free_list)) {
 		event = container_of(slist_remove_head(&cq->free_list),
 				     struct psmx2_cq_event, list_entry);
-		psmx2_unlock(&cq->lock, 2);
+		cq->domain->cq_unlock_fn(&cq->lock, 2);
 		return event;
 	}
 
-	psmx2_unlock(&cq->lock, 2);
+	cq->domain->cq_unlock_fn(&cq->lock, 2);
 	event = calloc(1, sizeof(*event));
 	if (!event)
 		FI_WARN(&psmx2_prov, FI_LOG_CQ, "out of memory.\n");
@@ -85,9 +85,9 @@ static void psmx2_cq_free_event(struct psmx2_fid_cq *cq,
 {
 	memset(event, 0, sizeof(*event));
 
-	psmx2_lock(&cq->lock, 2);
+	cq->domain->cq_lock_fn(&cq->lock, 2);
 	slist_insert_tail(&event->list_entry, &cq->free_list);
-	psmx2_unlock(&cq->lock, 2);
+	cq->domain->cq_unlock_fn(&cq->lock, 2);
 }
 
 struct psmx2_cq_event *psmx2_cq_create_event(struct psmx2_fid_cq *cq,
@@ -152,6 +152,690 @@ out:
 	return event;
 }
 
+static uint64_t psmx2_comp_flags[PSMX2_MAX_CONTEXT_TYPE] = {
+	[PSMX2_NOCOMP_SEND_CONTEXT]	= FI_SEND | FI_MSG,
+	[PSMX2_NOCOMP_RECV_CONTEXT]	= FI_RECV | FI_MSG,
+	[PSMX2_NOCOMP_TSEND_CONTEXT]	= FI_SEND | FI_TAGGED,
+	[PSMX2_NOCOMP_TRECV_CONTEXT]	= FI_RECV | FI_TAGGED,
+	[PSMX2_NOCOMP_WRITE_CONTEXT]	= FI_WRITE | FI_RMA,
+	[PSMX2_NOCOMP_READ_CONTEXT]	= FI_READ | FI_RMA,
+	[PSMX2_SEND_CONTEXT]		= FI_SEND | FI_MSG,
+	[PSMX2_RECV_CONTEXT]		= FI_RECV | FI_MSG,
+	[PSMX2_MULTI_RECV_CONTEXT]	= FI_RECV | FI_MSG,
+	[PSMX2_TSEND_CONTEXT]		= FI_SEND | FI_TAGGED,
+	[PSMX2_TRECV_CONTEXT]		= FI_RECV | FI_TAGGED,
+	[PSMX2_WRITE_CONTEXT]		= FI_WRITE | FI_RMA,
+	[PSMX2_READ_CONTEXT]		= FI_READ | FI_RMA,
+	[PSMX2_REMOTE_WRITE_CONTEXT]	= FI_REMOTE_WRITE | FI_RMA,
+	[PSMX2_REMOTE_READ_CONTEXT]	= FI_REMOTE_READ | FI_RMA,
+	[PSMX2_SENDV_CONTEXT]		= FI_SEND,
+	[PSMX2_IOV_SEND_CONTEXT]	= FI_SEND,
+	[PSMX2_IOV_RECV_CONTEXT]	= FI_RECV,
+};
+
+
+#if HAVE_PSM2_MQ_REQ_USER
+
+/*
+ * Translate "status" into completion event. A few factors determine where to
+ * save the event.
+ *
+ * If:
+ *
+ * (1) the CQE is for the CQ being polled; and
+ * (2) event buffer is supplied (event_in != NULL); and
+ * (3) the CQE is not an error entry,
+ *
+ * then the event is written to the event buffer directly. Otherwise a CQE is
+ * allocated on the corresponding CQ.
+ *
+ * The function doesn't use PSMX2_STATUS_CONTEXT(status) because the context
+ * field could refer to an allocated descriptor that may have already been
+ * freed. All the information that are dependent on the field are obtained
+ * in advance and passed in as separate parameters ("op_context", "buf",
+ * "flags", "data", and "is_recv").
+ *
+ * The flag "event_saved" is set to indicate to the caller that the event
+ * was saved to the user's provided buffer, otherwise the event was an error
+ * or the event has been saved to the comp_cq slist.
+ */
+
+__attribute__((always_inline))
+static inline int psmx2_cq_any_complete(struct psmx2_fid_cq *poll_cq,
+					struct psmx2_fid_cq *comp_cq,
+					struct psmx2_fid_av *av,
+					PSMX2_STATUS_TYPE *status,
+					void *op_context,
+					void *buf,
+					uint64_t flags,
+					uint64_t data,
+					struct psmx2_cq_event *event_in,
+					int *event_saved,
+					fi_addr_t *src_addr,
+					int is_recv)
+{
+	struct psmx2_cq_event *event = event_in;
+
+	*event_saved = 1;
+
+	if (OFI_UNLIKELY(PSMX2_STATUS_ERROR(status))) {
+		*event_saved = 0;
+		event = psmx2_cq_alloc_event(comp_cq);
+		if (!event)
+			return -FI_ENOMEM;
+
+		event->error = 1;
+		event->cqe.err.op_context = op_context;
+		event->cqe.err.flags = flags;
+		event->cqe.err.err = -psmx2_errno(PSMX2_STATUS_ERROR(status));
+		event->cqe.err.prov_errno = PSMX2_STATUS_ERROR(status);
+		event->cqe.err.tag = PSMX2_GET_TAG64(PSMX2_STATUS_TAG(status));
+		event->cqe.err.olen = PSMX2_STATUS_SNDLEN(status) - PSMX2_STATUS_RCVLEN(status);
+		event->cqe.err.data = data;
+
+		psmx2_cq_enqueue_event(comp_cq, event);
+		return 0;
+	}
+
+	if (OFI_UNLIKELY(poll_cq != comp_cq || !event)) {
+		*event_saved = 0;
+		event = psmx2_cq_alloc_event(comp_cq);
+		if (!event)
+			return -FI_ENOMEM;
+
+		event->error = 0;
+	}
+
+	if (is_recv) {
+		psm2_epaddr_t source = PSMX2_STATUS_PEER(status);
+
+		if (event == event_in) {
+			if (src_addr) {
+				src_addr[0] = psmx2_av_translate_source(av, source);
+				if (src_addr[0] == FI_ADDR_NOTAVAIL) {
+					*event_saved = 0;
+					event = psmx2_cq_alloc_event(comp_cq);
+					if (!event)
+						return -FI_ENOMEM;
+
+					event->cqe = event_in->cqe;
+					event->cqe.err.err = FI_EADDRNOTAVAIL;
+					event->cqe.err.err_data = &comp_cq->error_data;
+					event->error = !!event->cqe.err.err;
+					if (av->addr_format == FI_ADDR_STR) {
+						event->cqe.err.err_data_size = PSMX2_ERR_DATA_SIZE;
+						psmx2_get_source_string_name(source, (void *)&comp_cq->error_data,
+										 &event->cqe.err.err_data_size);
+					} else {
+						psmx2_get_source_name(source, (void *)&comp_cq->error_data);
+						event->cqe.err.err_data_size = sizeof(struct psmx2_ep_name);
+					}
+				}
+			}
+		} else {
+			event->source_is_valid = 1;
+			event->source = source;
+			event->source_av = av;
+		}
+	}
+
+	switch (comp_cq->format) {
+	case FI_CQ_FORMAT_CONTEXT:
+		event->cqe.context.op_context = op_context;
+		break;
+
+	case FI_CQ_FORMAT_MSG:
+		event->cqe.msg.op_context = op_context;
+		event->cqe.msg.flags = flags;
+		event->cqe.msg.len = PSMX2_STATUS_RCVLEN(status);
+		break;
+
+	case FI_CQ_FORMAT_DATA:
+		event->cqe.data.op_context = op_context;
+		event->cqe.data.buf = buf;
+		event->cqe.data.flags = flags;
+		event->cqe.data.len = PSMX2_STATUS_RCVLEN(status);
+		event->cqe.data.data = data;
+		break;
+
+	case FI_CQ_FORMAT_TAGGED:
+		event->cqe.tagged.op_context = op_context;
+		event->cqe.tagged.buf = buf;
+		event->cqe.tagged.flags = flags;
+		event->cqe.tagged.len = PSMX2_STATUS_RCVLEN(status);
+		event->cqe.tagged.data = data;
+		event->cqe.tagged.tag = PSMX2_GET_TAG64(PSMX2_STATUS_TAG(status));
+		break;
+
+	default:
+		FI_WARN(&psmx2_prov, FI_LOG_CQ,
+			"unsupported CQ format %d\n", comp_cq->format);
+		if (event != event_in)
+			psmx2_cq_free_event(comp_cq, event);
+		return -FI_EINVAL;
+	}
+
+	if (OFI_UNLIKELY(event != event_in))
+		psmx2_cq_enqueue_event(comp_cq, event);
+
+	return 0;
+}
+
+static inline int psmx2_cq_tx_complete(struct psmx2_fid_cq *poll_cq,
+				       struct psmx2_fid_cq *comp_cq,
+				       struct psmx2_fid_av *av,
+				       PSMX2_STATUS_TYPE *status,
+				       void *op_context,
+				       void *buf,
+				       uint64_t flags,
+				       uint64_t data,
+				       struct psmx2_cq_event *event_in,
+				       int *event_saved)
+{
+	return psmx2_cq_any_complete(poll_cq, comp_cq, av, status,
+				     op_context, buf, flags, data,
+				     event_in, event_saved, NULL, 0);
+}
+
+static inline int psmx2_cq_rx_complete(struct psmx2_fid_cq *poll_cq,
+				       struct psmx2_fid_cq *comp_cq,
+				       struct psmx2_fid_av *av,
+				       PSMX2_STATUS_TYPE *status,
+				       void *op_context,
+				       void *buf,
+				       uint64_t flags,
+				       uint64_t data,
+				       struct psmx2_cq_event *event_in,
+				       fi_addr_t *src_addr,
+				       int *event_saved)
+{
+	return psmx2_cq_any_complete(poll_cq, comp_cq, av, status,
+				     op_context, buf, flags, data,
+				     event_in, event_saved, src_addr, 1);
+}
+
+int
+psmx2_mq_status_copy(struct psm2_mq_req_user *req, void *status_array, int entry_index)
+{
+	struct fi_context *fi_context;
+	struct psmx2_fid_ep *ep;
+	struct psmx2_fid_mr *mr;
+	struct psmx2_am_request *am_req;
+	struct psmx2_multi_recv *multi_recv_req;
+	struct psmx2_sendv_request *sendv_req;
+	struct psmx2_sendv_reply *sendv_rep;
+	psm2_mq_req_t psm2_req;
+	size_t len_remaining;
+	void *op_context;
+	void *buf;
+	uint64_t flags;
+	uint64_t data;
+	int err;
+	int context_type;
+	int event_saved = 0;
+	void *entry = NULL;
+
+	struct psmx2_status_data *status_data = status_array;
+
+	if (OFI_LIKELY(status_data->event_buffer && status_data->poll_cq))
+		entry = (uint8_t *)status_data->event_buffer +
+				(entry_index * status_data->poll_cq->entry_size);
+
+	fi_context = PSMX2_STATUS_CONTEXT(req);
+
+	if (OFI_UNLIKELY(!fi_context))
+		return 0;
+
+	context_type = (int)PSMX2_CTXT_TYPE(fi_context);
+	flags = psmx2_comp_flags[context_type];
+	ep = PSMX2_CTXT_EP(fi_context);
+
+	switch (context_type) {
+	case PSMX2_SEND_CONTEXT:
+	case PSMX2_TSEND_CONTEXT:
+		if (ep->send_cq) {
+			op_context = fi_context;
+			buf = PSMX2_CTXT_USER(fi_context);
+			err = psmx2_cq_tx_complete(
+					status_data->poll_cq, ep->send_cq, ep->av,
+					req, op_context, buf, flags, 0,
+					entry, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->send_cntr)
+			psmx2_cntr_inc(ep->send_cntr, PSMX2_STATUS_ERROR(req));
+
+		/* Bi-directional send/recv performance tweak for KNL */
+		if (event_saved && PSMX2_STATUS_SNDLEN(req) > 16384)
+			event_saved++;
+		break;
+
+	case PSMX2_NOCOMP_SEND_CONTEXT:
+	case PSMX2_NOCOMP_TSEND_CONTEXT:
+		if (OFI_UNLIKELY(ep->send_cq && PSMX2_STATUS_ERROR(req))) {
+			err = psmx2_cq_tx_complete(
+					status_data->poll_cq, ep->send_cq, ep->av,
+					req, NULL, NULL, flags, 0,
+					entry, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->send_cntr)
+			psmx2_cntr_inc(ep->send_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_RECV_CONTEXT:
+		if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req))) &&
+				  !psmx2_handle_sendv_req(ep, req, 0))) {
+			return 0;
+		}
+		if (ep->recv_cq) {
+			op_context = fi_context;
+			buf = PSMX2_CTXT_USER(fi_context);
+			data = 0;
+			if (PSMX2_HAS_IMM(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req)))) {
+				flags |= FI_REMOTE_CQ_DATA;
+				data = PSMX2_GET_CQDATA(PSMX2_STATUS_TAG(req));
+			}
+			err = psmx2_cq_rx_complete(
+					status_data->poll_cq, ep->recv_cq, ep->av,
+					req, op_context, buf, flags, data,
+					entry, status_data->src_addr, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->recv_cntr)
+			psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_TRECV_CONTEXT:
+		if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req))) &&
+				 !psmx2_handle_sendv_req(ep, req, 0))) {
+			return 0;
+		}
+		if (ep->recv_cq) {
+			op_context = fi_context;
+			buf = PSMX2_CTXT_USER(fi_context);
+			data = 0;
+			if (PSMX2_HAS_IMM(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req)))) {
+				flags |= FI_REMOTE_CQ_DATA;
+				data = PSMX2_GET_CQDATA(PSMX2_STATUS_TAG(req));
+			}
+			err = psmx2_cq_rx_complete(
+					status_data->poll_cq, ep->recv_cq, ep->av,
+					req, op_context, buf, flags, data,
+					entry, status_data->src_addr, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->recv_cntr)
+			psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_NOCOMP_RECV_CONTEXT:
+		if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req))) &&
+				 !psmx2_handle_sendv_req(ep, req, 0))) {
+			PSMX2_EP_PUT_OP_CONTEXT(ep, fi_context);
+			return 0;
+		}
+		PSMX2_EP_PUT_OP_CONTEXT(ep, fi_context);
+		if (OFI_UNLIKELY(ep->recv_cq && PSMX2_STATUS_ERROR(req))) {
+			data = 0;
+			if (PSMX2_HAS_IMM(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req)))) {
+				flags |= FI_REMOTE_CQ_DATA;
+				data = PSMX2_GET_CQDATA(PSMX2_STATUS_TAG(req));
+			}
+			err = psmx2_cq_rx_complete(
+					status_data->poll_cq, ep->recv_cq, ep->av,
+					req, NULL, NULL, flags, data,
+					entry, status_data->src_addr, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->recv_cntr)
+			psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_NOCOMP_TRECV_CONTEXT:
+		if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req))) &&
+				 !psmx2_handle_sendv_req(ep, req, 0))) {
+			PSMX2_EP_PUT_OP_CONTEXT(ep, fi_context);
+			return 0;
+		}
+		PSMX2_EP_PUT_OP_CONTEXT(ep, fi_context);
+		if (OFI_UNLIKELY(ep->recv_cq && PSMX2_STATUS_ERROR(req))) {
+			err = psmx2_cq_rx_complete(
+					status_data->poll_cq, ep->recv_cq, ep->av,
+					req, NULL, NULL, flags, 0,
+					entry, status_data->src_addr, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->recv_cntr)
+			psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_WRITE_CONTEXT:
+		am_req = container_of(fi_context, struct psmx2_am_request,
+					  fi_context);
+		op_context = PSMX2_CTXT_USER(fi_context);
+		free(am_req->tmpbuf);
+		psmx2_am_request_free(status_data->trx_ctxt, am_req);
+		if (ep->send_cq) {
+			err = psmx2_cq_tx_complete(
+					status_data->poll_cq, ep->send_cq, ep->av,
+					req, op_context, NULL, flags, 0,
+					entry, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->write_cntr)
+			psmx2_cntr_inc(ep->write_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_NOCOMP_WRITE_CONTEXT:
+		am_req = container_of(fi_context, struct psmx2_am_request,
+					  fi_context);
+		op_context = PSMX2_CTXT_USER(fi_context);
+		free(am_req->tmpbuf);
+		psmx2_am_request_free(status_data->trx_ctxt, am_req);
+		if (OFI_UNLIKELY(ep->send_cq && PSMX2_STATUS_ERROR(req))) {
+			err = psmx2_cq_tx_complete(
+					status_data->poll_cq, ep->send_cq, ep->av,
+					req, op_context, NULL, flags, 0,
+					entry, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->write_cntr)
+			psmx2_cntr_inc(ep->write_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_READ_CONTEXT:
+		am_req = container_of(fi_context, struct psmx2_am_request,
+					  fi_context);
+		if (OFI_UNLIKELY(am_req->op == PSMX2_AM_REQ_READV)) {
+			am_req->read.len_read += PSMX2_STATUS_RCVLEN(req);
+			if (am_req->read.len_read < am_req->read.len) {
+				FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
+					"readv: long protocol finishes early\n");
+				if (PSMX2_STATUS_ERROR(req))
+					am_req->error = psmx2_errno(PSMX2_STATUS_ERROR(req));
+				/* Request to be freed in AM handler */
+				return 0;
+			}
+		}
+		op_context = PSMX2_CTXT_USER(fi_context);
+		free(am_req->tmpbuf);
+		psmx2_am_request_free(status_data->trx_ctxt, am_req);
+		if (ep->send_cq) {
+			err = psmx2_cq_tx_complete(
+					status_data->poll_cq, ep->send_cq, ep->av,
+					req, op_context, NULL, flags, 0,
+					entry, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->read_cntr)
+			psmx2_cntr_inc(ep->read_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_NOCOMP_READ_CONTEXT:
+		am_req = container_of(fi_context, struct psmx2_am_request,
+					  fi_context);
+		if (OFI_UNLIKELY(am_req->op == PSMX2_AM_REQ_READV)) {
+			am_req->read.len_read += PSMX2_STATUS_RCVLEN(req);
+			if (am_req->read.len_read < am_req->read.len) {
+				FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
+					"readv: long protocol finishes early\n");
+				if (PSMX2_STATUS_ERROR(req))
+					am_req->error = psmx2_errno(PSMX2_STATUS_ERROR(req));
+				/* Request to be freed in AM handler */
+				return 0;
+			}
+		}
+		op_context = PSMX2_CTXT_USER(fi_context);
+		free(am_req->tmpbuf);
+		psmx2_am_request_free(status_data->trx_ctxt, am_req);
+		if (OFI_UNLIKELY(ep->send_cq && PSMX2_STATUS_ERROR(req))) {
+			err = psmx2_cq_tx_complete(
+					status_data->poll_cq, ep->send_cq, ep->av,
+					req, op_context, NULL, flags, 0,
+					entry, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->read_cntr)
+			psmx2_cntr_inc(ep->read_cntr, PSMX2_STATUS_ERROR(req));
+		break;
+
+	case PSMX2_MULTI_RECV_CONTEXT:
+		if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req))) &&
+			!psmx2_handle_sendv_req(ep, req, 1))) {
+			return 0;
+		}
+		multi_recv_req = PSMX2_CTXT_USER(fi_context);
+		if (ep->recv_cq) {
+			op_context = fi_context;
+			buf = multi_recv_req->buf + multi_recv_req->offset;
+			data = 0;
+			if (PSMX2_HAS_IMM(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(req)))) {
+				flags |= FI_REMOTE_CQ_DATA;
+				data = PSMX2_GET_CQDATA(PSMX2_STATUS_TAG(req));
+			}
+			if (multi_recv_req->offset + PSMX2_STATUS_RCVLEN(req) +
+				multi_recv_req->min_buf_size > multi_recv_req->len)
+				flags |= FI_MULTI_RECV;	/* buffer used up */
+			err = psmx2_cq_rx_complete(
+					status_data->poll_cq, ep->recv_cq, ep->av,
+					req, op_context, buf, flags, data,
+					entry, status_data->src_addr, &event_saved);
+			if (OFI_UNLIKELY(err))
+				return err;
+		}
+		if (ep->recv_cntr)
+			psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(req));
+
+		/* repost multi-recv buffer */
+		multi_recv_req->offset += PSMX2_STATUS_RCVLEN(req);
+		len_remaining = multi_recv_req->len - multi_recv_req->offset;
+		if (len_remaining >= multi_recv_req->min_buf_size) {
+			if (len_remaining > PSMX2_MAX_MSG_SIZE)
+				len_remaining = PSMX2_MAX_MSG_SIZE;
+			err = psm2_mq_irecv2(ep->rx->psm2_mq,
+						 multi_recv_req->src_addr, &multi_recv_req->tag,
+						 &multi_recv_req->tagsel, multi_recv_req->flag,
+						 multi_recv_req->buf + multi_recv_req->offset,
+						 len_remaining,
+						 (void *)fi_context, &psm2_req);
+			if (OFI_UNLIKELY(err != PSM2_OK))
+				return psmx2_errno(err);
+			PSMX2_CTXT_REQ(fi_context) = psm2_req;
+		} else {
+			free(multi_recv_req);
+		}
+		break;
+
+	case PSMX2_REMOTE_WRITE_CONTEXT:
+		am_req = container_of(fi_context, struct psmx2_am_request, fi_context);
+		if (am_req->op & PSMX2_AM_FORCE_ACK) {
+			am_req->error = psmx2_errno(PSMX2_STATUS_ERROR(req));
+			psmx2_am_ack_rma(am_req);
+		}
+
+		if (am_req->ep->recv_cq && (am_req->cq_flags & FI_REMOTE_CQ_DATA)) {
+			flags |= FI_REMOTE_CQ_DATA;
+			err = psmx2_cq_rx_complete(
+					status_data->poll_cq, am_req->ep->recv_cq, am_req->ep->av,
+					req, NULL, NULL, flags, am_req->write.data,
+					entry, status_data->src_addr, &event_saved);
+			if (OFI_UNLIKELY(err)) {
+				psmx2_am_request_free(status_data->trx_ctxt, am_req);
+				return err;
+			}
+		}
+
+		if (am_req->ep->caps & FI_RMA_EVENT) {
+			if (am_req->ep->remote_write_cntr)
+				psmx2_cntr_inc(am_req->ep->remote_write_cntr, 0);
+
+			mr = PSMX2_CTXT_USER(fi_context);
+			if (mr->cntr && mr->cntr != am_req->ep->remote_write_cntr)
+				psmx2_cntr_inc(mr->cntr, 0);
+		}
+
+		/* NOTE: am_req->tmpbuf is unused here */
+		psmx2_am_request_free(status_data->trx_ctxt, am_req);
+		break;
+
+	case PSMX2_REMOTE_READ_CONTEXT:
+		am_req = container_of(fi_context, struct psmx2_am_request, fi_context);
+		if (am_req->ep->caps & FI_RMA_EVENT) {
+			if (am_req->ep->remote_read_cntr)
+				psmx2_cntr_inc(am_req->ep->remote_read_cntr, 0);
+		}
+
+		/* NOTE: am_req->tmpbuf is unused here */
+		psmx2_am_request_free(status_data->trx_ctxt, am_req);
+		break;
+
+	case PSMX2_SENDV_CONTEXT:
+		sendv_req = PSMX2_CTXT_USER(fi_context);
+		sendv_req->iov_done++;
+		if (sendv_req->iov_protocol == PSMX2_IOV_PROTO_MULTI &&
+			sendv_req->iov_done < sendv_req->iov_info.count + 1) {
+			sendv_req->tag = PSMX2_STATUS_TAG(req);
+			return 0;
+		}
+		if (ep->send_cq && !sendv_req->no_completion) {
+			op_context = sendv_req->user_context;
+			flags |= sendv_req->comp_flag;
+			err = psmx2_cq_tx_complete(
+					status_data->poll_cq, ep->send_cq, ep->av,
+					req, op_context, NULL, flags, 0,
+					entry, &event_saved);
+			if (OFI_UNLIKELY(err)) {
+				free(sendv_req);
+				return err;
+			}
+		}
+		if (ep->send_cntr)
+			psmx2_cntr_inc(ep->send_cntr, PSMX2_STATUS_ERROR(req));
+		free(sendv_req);
+		break;
+
+	case PSMX2_IOV_SEND_CONTEXT:
+		sendv_req = PSMX2_CTXT_USER(fi_context);
+		sendv_req->iov_done++;
+		if (sendv_req->iov_done < sendv_req->iov_info.count + 1)
+			return 0;
+		PSMX2_STATUS_TAG(req) = sendv_req->tag;
+		if (ep->send_cq && !sendv_req->no_completion) {
+			op_context = sendv_req->user_context;
+			flags |= sendv_req->comp_flag;
+			err = psmx2_cq_tx_complete(
+					status_data->poll_cq, ep->send_cq, ep->av,
+					req, op_context, NULL, flags, 0,
+					entry, &event_saved);
+			if (OFI_UNLIKELY(err)) {
+				free(sendv_req);
+				return err;
+			}
+		}
+		if (ep->send_cntr)
+			psmx2_cntr_inc(ep->send_cntr, PSMX2_STATUS_ERROR(req));
+		free(sendv_req);
+		break;
+
+	case PSMX2_IOV_RECV_CONTEXT:
+		sendv_rep = PSMX2_CTXT_USER(fi_context);
+		sendv_rep->iov_done++;
+		sendv_rep->msg_length += PSMX2_STATUS_SNDLEN(req);
+		sendv_rep->bytes_received += PSMX2_STATUS_RCVLEN(req);
+		if (PSMX2_STATUS_ERROR(req) != PSM2_OK)
+			sendv_rep->error_code = PSMX2_STATUS_ERROR(req);
+		if (sendv_rep->iov_done < sendv_rep->iov_info.count)
+			return 0;
+
+		PSMX2_STATUS_TAG(req) = sendv_rep->tag;
+		PSMX2_STATUS_RCVLEN(req) = sendv_rep->bytes_received;
+		PSMX2_STATUS_SNDLEN(req) = sendv_rep->msg_length;
+		PSMX2_STATUS_ERROR(req) = sendv_rep->error_code;
+
+		if (ep->recv_cq && !sendv_rep->no_completion) {
+			op_context = sendv_rep->user_context;
+			buf = sendv_rep->buf;
+			flags |= sendv_rep->comp_flag;
+			err = psmx2_cq_rx_complete(
+					status_data->poll_cq, ep->recv_cq, ep->av,
+					req, op_context, buf, flags, 0,
+					entry, status_data->src_addr, &event_saved);
+			if (OFI_UNLIKELY(err)) {
+				free(sendv_rep);
+				return err;
+			}
+		}
+		if (ep->recv_cntr)
+			psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(req));
+
+		if (sendv_rep->multi_recv) {
+			/* repost the multi-recv buffer */
+			fi_context = sendv_rep->user_context;
+			multi_recv_req = PSMX2_CTXT_USER(fi_context);
+			multi_recv_req->offset += PSMX2_STATUS_RCVLEN(req);
+			len_remaining = multi_recv_req->len - multi_recv_req->offset;
+			if (len_remaining >= multi_recv_req->min_buf_size) {
+				if (len_remaining > PSMX2_MAX_MSG_SIZE)
+					len_remaining = PSMX2_MAX_MSG_SIZE;
+				err = psm2_mq_irecv2(ep->rx->psm2_mq,
+							 multi_recv_req->src_addr, &multi_recv_req->tag,
+							 &multi_recv_req->tagsel, multi_recv_req->flag,
+							 multi_recv_req->buf + multi_recv_req->offset,
+							 len_remaining,
+							 (void *)fi_context, &psm2_req);
+				if (OFI_UNLIKELY(err != PSM2_OK)) {
+					free(sendv_rep);
+					return psmx2_errno(err);
+				}
+				PSMX2_CTXT_REQ(fi_context) = psm2_req;
+			} else {
+				free(multi_recv_req);
+			}
+		}
+
+		free(sendv_rep);
+		break;
+	}
+
+	return event_saved;
+}
+
+int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
+		     struct psmx2_trx_ctxt *trx_ctxt,
+		     struct psmx2_cq_event *event_in,
+		     int count, fi_addr_t *src_addr)
+{
+	struct psmx2_status_data status_data;
+
+	/* psm2_mq_ipeek_dequeue_multi needs non-zero count to make progress */
+	if (!count) {
+		event_in = NULL;
+		count = 1;
+	}
+
+	status_data.poll_cq = cq;
+	status_data.event_buffer = event_in;
+	status_data.src_addr = src_addr;
+	status_data.trx_ctxt = trx_ctxt;
+
+	psm2_mq_ipeek_dequeue_multi(trx_ctxt->psm2_mq, &status_data,
+			psmx2_mq_status_copy, &count);
+	return count;
+}
+
+#else /* !HAVE_PSM2_MQ_REQ_USER */
+
 /*
  * Translate "status" into completion event. A few factors determine where to
  * save the event.
@@ -270,7 +954,7 @@ static inline int psmx2_cq_any_complete(struct psmx2_fid_cq *poll_cq,
 	}
 
 	if (is_recv) {
-		fi_addr_t source = PSMX2_EP_TO_ADDR(PSMX2_STATUS_PEER(status));
+		psm2_epaddr_t source = PSMX2_STATUS_PEER(status);
 
 		if (event == event_in) {
 			if (src_addr) {
@@ -353,33 +1037,12 @@ static inline int psmx2_cq_rx_complete(struct psmx2_fid_cq *poll_cq,
 				     read_more, src_addr, 1);
 }
 
-static uint64_t psmx2_comp_flags[PSMX2_MAX_CONTEXT_TYPE] = {
-	[PSMX2_NOCOMP_SEND_CONTEXT]	= FI_SEND | FI_MSG,
-	[PSMX2_NOCOMP_RECV_CONTEXT]	= FI_RECV | FI_MSG,
-	[PSMX2_NOCOMP_TSEND_CONTEXT]	= FI_SEND | FI_TAGGED,
-	[PSMX2_NOCOMP_TRECV_CONTEXT]	= FI_RECV | FI_TAGGED,
-	[PSMX2_NOCOMP_WRITE_CONTEXT]	= FI_WRITE | FI_RMA,
-	[PSMX2_NOCOMP_READ_CONTEXT]	= FI_READ | FI_RMA,
-	[PSMX2_SEND_CONTEXT]		= FI_SEND | FI_MSG,
-	[PSMX2_RECV_CONTEXT]		= FI_RECV | FI_MSG,
-	[PSMX2_MULTI_RECV_CONTEXT]	= FI_RECV | FI_MSG,
-	[PSMX2_TSEND_CONTEXT]		= FI_SEND | FI_TAGGED,
-	[PSMX2_TRECV_CONTEXT]		= FI_RECV | FI_TAGGED,
-	[PSMX2_WRITE_CONTEXT]		= FI_WRITE | FI_RMA,
-	[PSMX2_READ_CONTEXT]		= FI_READ | FI_RMA,
-	[PSMX2_REMOTE_WRITE_CONTEXT]	= FI_REMOTE_WRITE | FI_RMA,
-	[PSMX2_REMOTE_READ_CONTEXT]	= FI_REMOTE_READ | FI_RMA,
-	[PSMX2_SENDV_CONTEXT]		= FI_SEND,
-	[PSMX2_IOV_SEND_CONTEXT]	= FI_SEND,
-	[PSMX2_IOV_RECV_CONTEXT]	= FI_RECV,
-};
-
 int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 		     struct psmx2_trx_ctxt *trx_ctxt,
 		     struct psmx2_cq_event *event_in,
 		     int count, fi_addr_t *src_addr)
 {
-	PSMX2_STATUS_DECL(status);
+	psm2_mq_status2_t status_priv, *status = &status_priv;
 	struct fi_context *fi_context;
 	struct psmx2_fid_ep *ep;
 	struct psmx2_fid_mr *mr;
@@ -398,16 +1061,25 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 	int err;
 	int context_type;
 
-	PSMX2_STATUS_INIT(status);
-
 	while (read_more) {
 
-		PSMX2_POLL_COMPLETION(trx_ctxt, status, err);
+		/*
+		 * psm2_mq_test2 is called immediately after psm2_mq_ipeek with a lock held to
+		 * prevent psm2_mq_ipeek from returning the same request multiple times under
+		 * different threads.
+		 */
+		if (trx_ctxt->domain->poll_trylock_fn(&trx_ctxt->poll_lock, 2)) {
+			err = PSM2_MQ_NO_COMPLETIONS;
+		} else {
+			err = psm2_mq_ipeek(trx_ctxt->psm2_mq, &psm2_req, NULL);
+			if (err == PSM2_OK)
+				psm2_mq_test2(&psm2_req, status);
+			trx_ctxt->domain->poll_unlock_fn(&trx_ctxt->poll_lock, 2);
+		}
 
 		if (err == PSM2_OK) {
 			fi_context = PSMX2_STATUS_CONTEXT(status);
 			if (OFI_UNLIKELY(!fi_context)) {
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				continue;
 			}
 
@@ -426,10 +1098,8 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, 0,
 							event_in, count, &read_count,
 							&read_more);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->send_cntr)
 					psmx2_cntr_inc(ep->send_cntr, PSMX2_STATUS_ERROR(status));
@@ -438,7 +1108,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 				if (PSMX2_STATUS_SNDLEN(status) > 16384)
 					read_more = 0;
 
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_NOCOMP_SEND_CONTEXT:
@@ -452,22 +1121,17 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, 0,
 							event_in, count, &read_count,
 							&read_more);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->send_cntr)
 					psmx2_cntr_inc(ep->send_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_RECV_CONTEXT:
 				if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(status))) &&
-						  !psmx2_handle_sendv_req(ep, status, 0))) {
-					PSMX2_FREE_COMPLETION(trx_ctxt, status);
+						  !psmx2_handle_sendv_req(ep, status, 0)))
 					continue;
-				}
 				if (ep->recv_cq) {
 					op_context = fi_context;
 					buf = PSMX2_CTXT_USER(fi_context);
@@ -483,22 +1147,17 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, data,
 							event_in, count, &read_count,
 							&read_more, src_addr);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->recv_cntr)
 					psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_TRECV_CONTEXT:
 				if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(status))) &&
-						 !psmx2_handle_sendv_req(ep, status, 0))) {
-					PSMX2_FREE_COMPLETION(trx_ctxt, status);
+						 !psmx2_handle_sendv_req(ep, status, 0)))
 					continue;
-				}
 				if (ep->recv_cq) {
 					op_context = fi_context;
 					buf = PSMX2_CTXT_USER(fi_context);
@@ -514,21 +1173,17 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, data,
 							event_in, count, &read_count,
 							&read_more, src_addr);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->recv_cntr)
 					psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_NOCOMP_RECV_CONTEXT:
 				if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(status))) &&
 						 !psmx2_handle_sendv_req(ep, status, 0))) {
 					PSMX2_EP_PUT_OP_CONTEXT(ep, fi_context);
-					PSMX2_FREE_COMPLETION(trx_ctxt, status);
 					continue;
 				}
 				PSMX2_EP_PUT_OP_CONTEXT(ep, fi_context);
@@ -547,21 +1202,17 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, data,
 							event_in, count, &read_count,
 							&read_more, src_addr);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->recv_cntr)
 					psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_NOCOMP_TRECV_CONTEXT:
 				if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(status))) &&
 						 !psmx2_handle_sendv_req(ep, status, 0))) {
 					PSMX2_EP_PUT_OP_CONTEXT(ep, fi_context);
-					PSMX2_FREE_COMPLETION(trx_ctxt, status);
 					continue;
 				}
 				PSMX2_EP_PUT_OP_CONTEXT(ep, fi_context);
@@ -574,14 +1225,11 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, 0,
 							event_in, count, &read_count,
 							&read_more, src_addr);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->recv_cntr)
 					psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_WRITE_CONTEXT:
@@ -598,14 +1246,11 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, 0,
 							event_in, count, &read_count,
 							&read_more);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->write_cntr)
 					psmx2_cntr_inc(ep->write_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_NOCOMP_WRITE_CONTEXT:
@@ -622,14 +1267,11 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, 0,
 							event_in, count, &read_count,
 							&read_more);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->write_cntr)
 					psmx2_cntr_inc(ep->write_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_READ_CONTEXT:
@@ -643,7 +1285,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 						if (PSMX2_STATUS_ERROR(status))
 							am_req->error = psmx2_errno(PSMX2_STATUS_ERROR(status));
 						/* Request to be freed in AM handler */
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
 						continue;
 					}
 				}
@@ -658,14 +1299,11 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, 0,
 							event_in, count, &read_count,
 							&read_more);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->read_cntr)
 					psmx2_cntr_inc(ep->read_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_NOCOMP_READ_CONTEXT:
@@ -679,7 +1317,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 						if (PSMX2_STATUS_ERROR(status))
 							am_req->error = psmx2_errno(PSMX2_STATUS_ERROR(status));
 						/* Request to be freed in AM handler */
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
 						continue;
 					}
 				}
@@ -694,22 +1331,17 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, 0,
 							event_in, count, &read_count,
 							&read_more);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->read_cntr)
 					psmx2_cntr_inc(ep->read_cntr, PSMX2_STATUS_ERROR(status));
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_MULTI_RECV_CONTEXT:
 				if (OFI_UNLIKELY(PSMX2_IS_IOV_HEADER(PSMX2_GET_FLAGS(PSMX2_STATUS_TAG(status))) &&
-				    !psmx2_handle_sendv_req(ep, status, 1))) {
-					PSMX2_FREE_COMPLETION(trx_ctxt, status);
+				    !psmx2_handle_sendv_req(ep, status, 1)))
 					continue;
-				}
 				multi_recv_req = PSMX2_CTXT_USER(fi_context);
 				if (ep->recv_cq) {
 					op_context = fi_context;
@@ -729,10 +1361,8 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							status, op_context, buf, flags, data,
 							event_in, count, &read_count,
 							&read_more, src_addr);
-					if (err) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err)
 						return err;
-					}
 				}
 				if (ep->recv_cntr)
 					psmx2_cntr_inc(ep->recv_cntr, PSMX2_STATUS_ERROR(status));
@@ -749,15 +1379,12 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							     multi_recv_req->buf + multi_recv_req->offset,
 							     len_remaining,
 							     (void *)fi_context, &psm2_req);
-					if (err != PSM2_OK) {
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
+					if (err != PSM2_OK)
 						return psmx2_errno(err);
-					}
 					PSMX2_CTXT_REQ(fi_context) = psm2_req;
 				} else {
 					free(multi_recv_req);
 				}
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_REMOTE_WRITE_CONTEXT:
@@ -778,7 +1405,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							&read_more, src_addr);
 					if (err) {
 						psmx2_am_request_free(trx_ctxt, am_req);
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
 						return err;
 					}
 				}
@@ -794,7 +1420,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 
 				/* NOTE: am_req->tmpbuf is unused here */
 				psmx2_am_request_free(trx_ctxt, am_req);
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_REMOTE_READ_CONTEXT:
@@ -806,7 +1431,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 
 				/* NOTE: am_req->tmpbuf is unused here */
 				psmx2_am_request_free(trx_ctxt, am_req);
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_SENDV_CONTEXT:
@@ -814,7 +1438,7 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 				sendv_req->iov_done++;
 				if (sendv_req->iov_protocol == PSMX2_IOV_PROTO_MULTI &&
 				    sendv_req->iov_done < sendv_req->iov_info.count + 1) {
-					PSMX2_STATUS_SAVE(status, sendv_req->status);
+					sendv_req->tag = PSMX2_STATUS_TAG(status);
 					continue;
 				}
 				if (ep->send_cq && !sendv_req->no_completion) {
@@ -829,23 +1453,20 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							&read_more);
 					if (err) {
 						free(sendv_req);
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
 						return err;
 					}
 				}
 				if (ep->send_cntr)
 					psmx2_cntr_inc(ep->send_cntr, PSMX2_STATUS_ERROR(status));
 				free(sendv_req);
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 
 			case PSMX2_IOV_SEND_CONTEXT:
 				sendv_req = PSMX2_CTXT_USER(fi_context);
 				sendv_req->iov_done++;
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				if (sendv_req->iov_done < sendv_req->iov_info.count + 1)
 					continue;
-				status = sendv_req->status;
+				PSMX2_STATUS_TAG(status) = sendv_req->tag;
 				if (ep->send_cq && !sendv_req->no_completion) {
 					op_context = sendv_req->user_context;
 					buf = NULL;
@@ -858,15 +1479,12 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							&read_more);
 					if (err) {
 						free(sendv_req);
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
 						return err;
 					}
 				}
 				if (ep->send_cntr)
 					psmx2_cntr_inc(ep->send_cntr, PSMX2_STATUS_ERROR(status));
 				free(sendv_req);
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
-				PSMX2_STATUS_INIT(status);
 				break;
 
 			case PSMX2_IOV_RECV_CONTEXT:
@@ -876,10 +1494,8 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 				sendv_rep->bytes_received += PSMX2_STATUS_RCVLEN(status);
 				if (PSMX2_STATUS_ERROR(status) != PSM2_OK)
 					sendv_rep->error_code = PSMX2_STATUS_ERROR(status);
-				if (sendv_rep->iov_done < sendv_rep->iov_info.count) {
-					PSMX2_FREE_COMPLETION(trx_ctxt, status);
+				if (sendv_rep->iov_done < sendv_rep->iov_info.count)
 					continue;
-				}
 
 				PSMX2_STATUS_TAG(status) = sendv_rep->tag;
 				PSMX2_STATUS_RCVLEN(status) = sendv_rep->bytes_received;
@@ -898,7 +1514,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 							&read_more, src_addr);
 					if (err) {
 						free(sendv_rep);
-						PSMX2_FREE_COMPLETION(trx_ctxt, status);
 						return err;
 					}
 				}
@@ -922,7 +1537,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 								     (void *)fi_context, &psm2_req);
 						if (err != PSM2_OK) {
 							free(sendv_rep);
-							PSMX2_FREE_COMPLETION(trx_ctxt, status);
 							return psmx2_errno(err);
 						}
 						PSMX2_CTXT_REQ(fi_context) = psm2_req;
@@ -932,7 +1546,6 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 				}
 
 				free(sendv_rep);
-				PSMX2_FREE_COMPLETION(trx_ctxt, status);
 				break;
 			}
 		} else if (err == PSM2_MQ_NO_COMPLETIONS) {
@@ -944,8 +1557,10 @@ int psmx2_cq_poll_mq(struct psmx2_fid_cq *cq,
 
 	return read_count;
 }
+#endif /* !HAVE_PSM2_MQ_REQ_USER */
 
-static ssize_t psmx2_cq_readfrom(struct fid_cq *cq, void *buf, size_t count,
+DIRECT_FN
+STATIC ssize_t psmx2_cq_readfrom(struct fid_cq *cq, void *buf, size_t count,
 				 fi_addr_t *src_addr)
 {
 	struct psmx2_fid_cq *cq_priv;
@@ -963,6 +1578,10 @@ static ssize_t psmx2_cq_readfrom(struct fid_cq *cq, void *buf, size_t count,
 		slist_foreach(&cq_priv->poll_list, item, prev) {
 			poll_ctxt = container_of(item, struct psmx2_poll_ctxt,
 						 list_entry);
+
+			if (OFI_UNLIKELY(!poll_ctxt->trx_ctxt->poll_active))
+				continue;
+
 			ret = psmx2_cq_poll_mq(cq_priv, poll_ctxt->trx_ctxt,
 					       (struct psmx2_cq_event *)buf,
 					       count, src_addr);
@@ -976,13 +1595,16 @@ static ssize_t psmx2_cq_readfrom(struct fid_cq *cq, void *buf, size_t count,
 		}
 	}
 
-	if (cq_priv->pending_error)
+	if (OFI_UNLIKELY(cq_priv->pending_error != NULL))
 		return -FI_EAVAIL;
 
 	assert(buf || !count);
 
 	read_count = 0;
 	for (i = 0; i < count; i++) {
+		if (slist_empty(&cq_priv->event_queue))
+			break;
+
 		event = psmx2_cq_dequeue_event(cq_priv);
 		if (event) {
 			if (!event->error) {
@@ -1040,12 +1662,14 @@ static ssize_t psmx2_cq_readfrom(struct fid_cq *cq, void *buf, size_t count,
 	return read_count;
 }
 
-static ssize_t psmx2_cq_read(struct fid_cq *cq, void *buf, size_t count)
+DIRECT_FN
+STATIC ssize_t psmx2_cq_read(struct fid_cq *cq, void *buf, size_t count)
 {
 	return psmx2_cq_readfrom(cq, buf, count, NULL);
 }
 
-static ssize_t psmx2_cq_readerr(struct fid_cq *cq, struct fi_cq_err_entry *buf,
+DIRECT_FN
+STATIC ssize_t psmx2_cq_readerr(struct fid_cq *cq, struct fi_cq_err_entry *buf,
 				uint64_t flags)
 {
 	struct psmx2_fid_cq *cq_priv;
@@ -1054,7 +1678,7 @@ static ssize_t psmx2_cq_readerr(struct fid_cq *cq, struct fi_cq_err_entry *buf,
 
 	cq_priv = container_of(cq, struct psmx2_fid_cq, cq);
 
-	psmx2_lock(&cq_priv->lock, 2);
+	cq_priv->domain->cq_lock_fn(&cq_priv->lock, 2);
 	if (cq_priv->pending_error) {
 		api_version = cq_priv->domain->fabric->util_fabric.
 			      fabric_fid.api_version;
@@ -1067,12 +1691,13 @@ static ssize_t psmx2_cq_readerr(struct fid_cq *cq, struct fi_cq_err_entry *buf,
 		psmx2_unlock(&cq_priv->lock, 2);
 		return 1;
 	}
-	psmx2_unlock(&cq_priv->lock, 2);
+	cq_priv->domain->cq_unlock_fn(&cq_priv->lock, 2);
 
 	return -FI_EAGAIN;
 }
 
-static ssize_t psmx2_cq_sreadfrom(struct fid_cq *cq, void *buf, size_t count,
+DIRECT_FN
+STATIC ssize_t psmx2_cq_sreadfrom(struct fid_cq *cq, void *buf, size_t count,
 				  fi_addr_t *src_addr, const void *cond,
 				  int timeout)
 {
@@ -1106,6 +1731,10 @@ static ssize_t psmx2_cq_sreadfrom(struct fid_cq *cq, void *buf, size_t count,
 					poll_ctxt = container_of(item,
 								 struct psmx2_poll_ctxt,
 								 list_entry);
+
+					if (OFI_UNLIKELY(!poll_ctxt->trx_ctxt->poll_active))
+						continue;
+
 					sth_happened =
 						psmx2_cq_poll_mq(cq_priv,
 								 poll_ctxt->trx_ctxt,
@@ -1141,13 +1770,15 @@ static ssize_t psmx2_cq_sreadfrom(struct fid_cq *cq, void *buf, size_t count,
 	return psmx2_cq_readfrom(cq, buf, count, src_addr);
 }
 
-static ssize_t psmx2_cq_sread(struct fid_cq *cq, void *buf, size_t count,
+DIRECT_FN
+STATIC ssize_t psmx2_cq_sread(struct fid_cq *cq, void *buf, size_t count,
 			      const void *cond, int timeout)
 {
 	return psmx2_cq_sreadfrom(cq, buf, count, NULL, cond, timeout);
 }
 
-static int psmx2_cq_signal(struct fid_cq *cq)
+DIRECT_FN
+STATIC int psmx2_cq_signal(struct fid_cq *cq)
 {
 	struct psmx2_fid_cq *cq_priv;
 	cq_priv = container_of(cq, struct psmx2_fid_cq, cq);
@@ -1159,7 +1790,8 @@ static int psmx2_cq_signal(struct fid_cq *cq)
 	return 0;
 }
 
-static const char *psmx2_cq_strerror(struct fid_cq *cq, int prov_errno, const void *prov_data,
+DIRECT_FN
+STATIC const char *psmx2_cq_strerror(struct fid_cq *cq, int prov_errno, const void *prov_data,
 				     char *buf, size_t len)
 {
 	return psm2_error_get_string(prov_errno);
@@ -1177,6 +1809,8 @@ static int psmx2_cq_close(fid_t fid)
 	while (!slist_empty(&cq->poll_list)) {
 		entry = slist_remove_head(&cq->poll_list);
 		poll_item = container_of(entry, struct psmx2_poll_ctxt, list_entry);
+		if (!ofi_atomic_dec32(&poll_item->trx_ctxt->poll_refcnt))
+			free(poll_item->trx_ctxt);
 		free(poll_item);
 	}
 
@@ -1241,6 +1875,7 @@ static struct fi_ops_cq psmx2_cq_ops = {
 	.strerror = psmx2_cq_strerror,
 };
 
+DIRECT_FN
 int psmx2_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
 		 struct fid_cq **cq, void *context)
 {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_domain.c
index 2f760c6c9..741e79dc9 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_domain.c
@@ -203,7 +203,8 @@ static int psmx2_domain_close(fid_t fid)
 	return 0;
 }
 
-static int psmx2_domain_control(fid_t fid, int command, void *arg)
+DIRECT_FN
+STATIC int psmx2_domain_control(fid_t fid, int command, void *arg)
 {
 	struct fi_mr_map_raw *map;
 
@@ -292,6 +293,7 @@ err_out:
 	return err;
 }
 
+DIRECT_FN
 int psmx2_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 		      struct fid_domain **domain, void *context)
 {
@@ -299,7 +301,7 @@ int psmx2_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 	struct psmx2_fid_domain *domain_priv;
 	struct psmx2_ep_name *src_addr = info->src_addr;
 	int mr_mode = (info->domain_attr->mr_mode & FI_MR_BASIC) ? FI_MR_BASIC : 0;
-	int err;
+	int err, tmp;
 
 	FI_INFO(&psmx2_prov, FI_LOG_DOMAIN, "\n");
 
@@ -337,6 +339,108 @@ int psmx2_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 	if (info->addr_format == FI_ADDR_STR)
 		src_addr = psmx2_string_to_ep_name(info->src_addr);
 
+	/* Use generic lock/unlock functions by default */
+	domain_priv->av_lock_fn = psmx2_lock;
+	domain_priv->am_req_pool_lock_fn = psmx2_lock;
+	domain_priv->trx_ctxt_lock_fn = psmx2_lock;
+	domain_priv->rma_queue_lock_fn = psmx2_lock;
+	domain_priv->trigger_queue_lock_fn = psmx2_lock;
+	domain_priv->peer_lock_fn = psmx2_lock;
+	domain_priv->sep_lock_fn = psmx2_lock;
+	domain_priv->trigger_lock_fn = psmx2_lock;
+	domain_priv->cq_lock_fn = psmx2_lock;
+	domain_priv->mr_lock_fn = psmx2_lock;
+	domain_priv->context_lock_fn = psmx2_lock;
+	domain_priv->poll_trylock_fn = psmx2_trylock;
+
+	domain_priv->av_unlock_fn = psmx2_unlock;
+	domain_priv->am_req_pool_unlock_fn = psmx2_unlock;
+	domain_priv->trx_ctxt_unlock_fn = psmx2_unlock;
+	domain_priv->rma_queue_unlock_fn = psmx2_unlock;
+	domain_priv->trigger_queue_unlock_fn = psmx2_unlock;
+	domain_priv->peer_unlock_fn = psmx2_unlock;
+	domain_priv->sep_unlock_fn = psmx2_unlock;
+	domain_priv->trigger_unlock_fn = psmx2_unlock;
+	domain_priv->cq_unlock_fn = psmx2_unlock;
+	domain_priv->mr_unlock_fn = psmx2_unlock;
+	domain_priv->context_unlock_fn = psmx2_unlock;
+	domain_priv->poll_unlock_fn = psmx2_unlock;
+
+	/* If lock_level env is unset, then set locks based off threading model*/
+	err = fi_param_get_bool(&psmx2_prov, "lock_level", &tmp);
+	if (err < 0) {
+		switch (info->domain_attr->threading) {
+		case FI_THREAD_DOMAIN:
+			/* Disable locks not required when serializing access to a domain */
+			domain_priv->av_lock_fn = psmx2_lock_disabled;
+			domain_priv->trx_ctxt_lock_fn = psmx2_lock_disabled;
+			domain_priv->trigger_queue_lock_fn = psmx2_lock_disabled;
+			domain_priv->peer_lock_fn = psmx2_lock_disabled;
+			domain_priv->sep_lock_fn = psmx2_lock_disabled;
+			domain_priv->trigger_lock_fn = psmx2_lock_disabled;
+			domain_priv->cq_lock_fn = psmx2_lock_disabled;
+			domain_priv->mr_lock_fn = psmx2_lock_disabled;
+			domain_priv->context_lock_fn = psmx2_lock_disabled;
+			domain_priv->poll_trylock_fn = psmx2_trylock_disabled;
+
+			domain_priv->av_unlock_fn = psmx2_lock_disabled;
+			domain_priv->trx_ctxt_unlock_fn = psmx2_lock_disabled;
+			domain_priv->trigger_queue_unlock_fn = psmx2_lock_disabled;
+			domain_priv->peer_unlock_fn = psmx2_lock_disabled;
+			domain_priv->sep_unlock_fn = psmx2_lock_disabled;
+			domain_priv->trigger_unlock_fn = psmx2_lock_disabled;
+			domain_priv->cq_unlock_fn = psmx2_lock_disabled;
+			domain_priv->mr_unlock_fn = psmx2_lock_disabled;
+			domain_priv->context_unlock_fn = psmx2_lock_disabled;
+			domain_priv->poll_unlock_fn = psmx2_lock_disabled;
+
+			/*
+			 * If FI_RMA or FI_ATOMIC caps are enabled, then locks are
+			 * required for the CQ, am_req_poll, & rma_queue
+			 * due to the PSM2 Recv thread.
+			 * NOTE: am_req_poll & rma_queue are only used when FI_RMA
+			 * and FI_ATOMIC capabilities are enabled.
+			 */
+			if ((info->caps & FI_RMA) || (info->caps & FI_ATOMIC)) {
+				domain_priv->cq_lock_fn = psmx2_lock_enabled;
+				domain_priv->am_req_pool_lock_fn = psmx2_lock_enabled;
+				domain_priv->rma_queue_lock_fn = psmx2_lock_enabled;
+				domain_priv->cq_unlock_fn = psmx2_unlock_enabled;
+				domain_priv->am_req_pool_unlock_fn = psmx2_unlock_enabled;
+				domain_priv->rma_queue_unlock_fn = psmx2_unlock_enabled;
+			}
+			break;
+		default:
+			/* Otherwise, enable all locks */
+			domain_priv->av_lock_fn = psmx2_lock_enabled;
+			domain_priv->am_req_pool_lock_fn = psmx2_lock_enabled;
+			domain_priv->trx_ctxt_lock_fn = psmx2_lock_enabled;
+			domain_priv->rma_queue_lock_fn = psmx2_lock_enabled;
+			domain_priv->trigger_queue_lock_fn = psmx2_lock_enabled;
+			domain_priv->peer_lock_fn = psmx2_lock_enabled;
+			domain_priv->sep_lock_fn = psmx2_lock_enabled;
+			domain_priv->trigger_lock_fn = psmx2_lock_enabled;
+			domain_priv->cq_lock_fn = psmx2_lock_enabled;
+			domain_priv->mr_lock_fn = psmx2_lock_enabled;
+			domain_priv->context_lock_fn = psmx2_lock_enabled;
+			domain_priv->poll_trylock_fn = psmx2_trylock_enabled;
+
+			domain_priv->av_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->am_req_pool_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->trx_ctxt_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->rma_queue_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->trigger_queue_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->peer_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->sep_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->trigger_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->cq_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->mr_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->context_unlock_fn = psmx2_unlock_enabled;
+			domain_priv->poll_unlock_fn = psmx2_unlock_enabled;
+			break;
+		}
+	}
+
 	err = psmx2_domain_init(domain_priv, src_addr);
 	if (info->addr_format == FI_ADDR_STR)
 		free(src_addr);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_ep.c
index 6141301a9..088510937 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_ep.c
@@ -52,61 +52,37 @@ static void psmx2_ep_optimize_ops(struct psmx2_fid_ep *ep)
 
 			if (ep->caps & FI_DIRECTED_RECV) {
 				if (!send_completion && !recv_completion) {
-					if (ep->av && ep->av->type == FI_AV_TABLE)
-						ep->ep.tagged = &psmx2_tagged_ops_no_event_av_table_directed;
-					else
-						ep->ep.tagged = &psmx2_tagged_ops_no_event_av_map_directed;
+					ep->ep.tagged = &psmx2_tagged_ops_no_event_directed;
 					FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
 						"tagged ops optimized for op_flags=0 and event suppression and directed receive\n");
 				} else if (!send_completion) {
-					if (ep->av && ep->av->type == FI_AV_TABLE)
-						ep->ep.tagged = &psmx2_tagged_ops_no_send_event_av_table_directed;
-					else
-						ep->ep.tagged = &psmx2_tagged_ops_no_send_event_av_map_directed;
+					ep->ep.tagged = &psmx2_tagged_ops_no_send_event_directed;
 					FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
 						"tagged ops optimized for op_flags=0 and send event suppression and directed receive\n");
 				} else if (!recv_completion) {
-					if (ep->av && ep->av->type == FI_AV_TABLE)
-						ep->ep.tagged = &psmx2_tagged_ops_no_recv_event_av_table_directed;
-					else
-						ep->ep.tagged = &psmx2_tagged_ops_no_recv_event_av_map_directed;
+					ep->ep.tagged = &psmx2_tagged_ops_no_recv_event_directed;
 					FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
 						"tagged ops optimized for op_flags=0 and recv event suppression and directed receive\n");
 				} else {
-					if (ep->av && ep->av->type == FI_AV_TABLE)
-						ep->ep.tagged = &psmx2_tagged_ops_no_flag_av_table_directed;
-					else
-						ep->ep.tagged = &psmx2_tagged_ops_no_flag_av_map_directed;
+					ep->ep.tagged = &psmx2_tagged_ops_no_flag_directed;
 					FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
 						"tagged ops optimized for op_flags=0 and directed receive\n");
 				}
 			} else {
 				if (!send_completion && !recv_completion) {
-					if (ep->av && ep->av->type == FI_AV_TABLE)
-						ep->ep.tagged = &psmx2_tagged_ops_no_event_av_table_undirected;
-					else
-						ep->ep.tagged = &psmx2_tagged_ops_no_event_av_map_undirected;
+					ep->ep.tagged = &psmx2_tagged_ops_no_event_undirected;
 					FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
 						"tagged ops optimized for op_flags=0 and event suppression\n");
 				} else if (!send_completion) {
-					if (ep->av && ep->av->type == FI_AV_TABLE)
-						ep->ep.tagged = &psmx2_tagged_ops_no_send_event_av_table_undirected;
-					else
-						ep->ep.tagged = &psmx2_tagged_ops_no_send_event_av_map_undirected;
+					ep->ep.tagged = &psmx2_tagged_ops_no_send_event_undirected;
 					FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
 						"tagged ops optimized for op_flags=0 and send event suppression\n");
 				} else if (!recv_completion) {
-					if (ep->av && ep->av->type == FI_AV_TABLE)
-						ep->ep.tagged = &psmx2_tagged_ops_no_recv_event_av_table_undirected;
-					else
-						ep->ep.tagged = &psmx2_tagged_ops_no_recv_event_av_map_undirected;
+					ep->ep.tagged = &psmx2_tagged_ops_no_recv_event_undirected;
 					FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
 						"tagged ops optimized for op_flags=0 and recv event suppression\n");
 				} else {
-					if (ep->av && ep->av->type == FI_AV_TABLE)
-						ep->ep.tagged = &psmx2_tagged_ops_no_flag_av_table_undirected;
-					else
-						ep->ep.tagged = &psmx2_tagged_ops_no_flag_av_map_undirected;
+					ep->ep.tagged = &psmx2_tagged_ops_no_flag_undirected;
 					FI_INFO(&psmx2_prov, FI_LOG_EP_DATA,
 						"tagged ops optimized for op_flags=0\n");
 				}
@@ -116,7 +92,8 @@ static void psmx2_ep_optimize_ops(struct psmx2_fid_ep *ep)
 	}
 }
 
-static ssize_t psmx2_ep_cancel(fid_t fid, void *context)
+DIRECT_FN
+STATIC ssize_t psmx2_ep_cancel(fid_t fid, void *context)
 {
 	struct psmx2_fid_ep *ep;
 	psm2_mq_status2_t status;
@@ -165,7 +142,8 @@ static ssize_t psmx2_ep_cancel(fid_t fid, void *context)
 	return psmx2_errno(err);
 }
 
-static int psmx2_ep_getopt(fid_t fid, int level, int optname,
+DIRECT_FN
+STATIC int psmx2_ep_getopt(fid_t fid, int level, int optname,
 			   void *optval, size_t *optlen)
 {
 	struct psmx2_fid_ep *ep;
@@ -188,7 +166,8 @@ static int psmx2_ep_getopt(fid_t fid, int level, int optname,
 	return 0;
 }
 
-static int psmx2_ep_setopt(fid_t fid, int level, int optname,
+DIRECT_FN
+STATIC int psmx2_ep_setopt(fid_t fid, int level, int optname,
 			   const void *optval, size_t optlen)
 {
 	struct psmx2_fid_ep *ep;
@@ -275,12 +254,14 @@ static int psmx2_add_poll_ctxt(struct slist *list, struct psmx2_trx_ctxt *trx_ct
 	if (!item)
 		return -FI_ENOMEM;
 
+	ofi_atomic_inc32(&trx_ctxt->poll_refcnt);
 	item->trx_ctxt = trx_ctxt;
 	slist_insert_tail(&item->list_entry, list);
 	return 0;
 }
 
-static int psmx2_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
+DIRECT_FN
+STATIC int psmx2_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 {
 	struct psmx2_fid_ep *ep;
 	struct psmx2_fid_av *av;
@@ -357,9 +338,9 @@ static int psmx2_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 		ep->av = av;
 		psmx2_ep_optimize_ops(ep);
 		if (ep->tx)
-			psmx2_av_add_trx_ctxt(av, ep->tx, !psmx2_env.lazy_conn);
+			psmx2_av_add_trx_ctxt(av, ep->tx);
 		if (ep->rx && ep->rx != ep->tx)
-			psmx2_av_add_trx_ctxt(av, ep->rx, !psmx2_env.lazy_conn);
+			psmx2_av_add_trx_ctxt(av, ep->rx);
 		break;
 
 	case FI_CLASS_MR:
@@ -381,7 +362,11 @@ static int psmx2_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 		err = psmx2_domain_enable_ep(ep->domain, ep);
 		if (err)
 			return err;
+#if HAVE_PSM2_MQ_FP_MSG
+		if (ep->caps & FI_TRIGGER)
+#else
 		if (ep->caps & (FI_RMA | FI_TRIGGER))
+#endif
 			stx->tx->am_progress = 1;
 		ofi_atomic_inc32(&stx->ref);
 		break;
@@ -425,7 +410,8 @@ static inline int psmx2_ep_get_flags(struct psmx2_fid_ep *ep, uint64_t *flags)
 	return 0;
 }
 
-static int psmx2_ep_control(fid_t fid, int command, void *arg)
+DIRECT_FN
+STATIC int psmx2_ep_control(fid_t fid, int command, void *arg)
 {
 	struct fi_alias *alias;
 	struct psmx2_fid_ep *ep, *new_ep;
@@ -477,7 +463,8 @@ static int psmx2_ep_control(fid_t fid, int command, void *arg)
 	return 0;
 }
 
-static ssize_t psmx2_rx_size_left(struct fid_ep *ep)
+DIRECT_FN
+STATIC ssize_t psmx2_rx_size_left(struct fid_ep *ep)
 {
 	struct psmx2_fid_ep *ep_priv;
 
@@ -488,7 +475,8 @@ static ssize_t psmx2_rx_size_left(struct fid_ep *ep)
 		return -FI_EOPBADSTATE;
 }
 
-static ssize_t psmx2_tx_size_left(struct fid_ep *ep)
+DIRECT_FN
+STATIC ssize_t psmx2_tx_size_left(struct fid_ep *ep)
 {
 	struct psmx2_fid_ep *ep_priv;
 
@@ -604,8 +592,11 @@ int psmx2_ep_open_internal(struct psmx2_fid_domain *domain_priv,
 	psmx2_ep_optimize_ops(ep_priv);
 
 	PSMX2_EP_INIT_OP_CONTEXT(ep_priv);
-
+#if HAVE_PSM2_MQ_FP_MSG
+	if ((ep_cap & FI_TRIGGER) && trx_ctxt)
+#else
 	if ((ep_cap & (FI_RMA | FI_TRIGGER)) && trx_ctxt)
+#endif
 		trx_ctxt->am_progress = 1;
 
 	*ep_out = ep_priv;
@@ -618,6 +609,7 @@ errout:
 	return err;
 }
 
+DIRECT_FN
 int psmx2_ep_open(struct fid_domain *domain, struct fi_info *info,
 		  struct fid_ep **ep, void *context)
 {
@@ -741,6 +733,7 @@ static struct fi_ops_ep psmx2_stx_ops = {
 	.tx_size_left = fi_no_tx_size_left,
 };
 
+DIRECT_FN
 int psmx2_stx_ctx(struct fid_domain *domain, struct fi_tx_attr *attr,
 		  struct fid_stx **stx, void *context)
 {
@@ -819,9 +812,9 @@ static int psmx2_sep_close(fid_t fid)
 			psmx2_ep_close_internal(sep->ctxts[i].ep);
 	}
 
-	psmx2_lock(&sep->domain->sep_lock, 1);
+	sep->domain->sep_lock_fn(&sep->domain->sep_lock, 1);
 	dlist_remove(&sep->entry);
-	psmx2_unlock(&sep->domain->sep_lock, 1);
+	sep->domain->sep_unlock_fn(&sep->domain->sep_lock, 1);
 
 	psmx2_domain_release(sep->domain);
 	free(sep);
@@ -846,7 +839,8 @@ static int psmx2_sep_control(fid_t fid, int command, void *arg)
 	return 0;
 }
 
-static int psmx2_sep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
+DIRECT_FN
+STATIC int psmx2_sep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 {
 	struct psmx2_fid_sep *sep;
 	int i, err = 0;
@@ -862,7 +856,8 @@ static int psmx2_sep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 	return err;
 }
 
-static int psmx2_tx_context(struct fid_ep *ep, int index, struct fi_tx_attr *attr,
+DIRECT_FN
+STATIC int psmx2_tx_context(struct fid_ep *ep, int index, struct fi_tx_attr *attr,
 			    struct fid_ep **tx_ep, void *context)
 {
 	struct psmx2_fid_sep *sep;
@@ -875,7 +870,8 @@ static int psmx2_tx_context(struct fid_ep *ep, int index, struct fi_tx_attr *att
 	return 0;
 }
 
-static int psmx2_rx_context(struct fid_ep *ep, int index, struct fi_rx_attr *attr,
+DIRECT_FN
+STATIC int psmx2_rx_context(struct fid_ep *ep, int index, struct fi_rx_attr *attr,
 			    struct fid_ep **rx_ep, void *context)
 {
 	struct psmx2_fid_sep *sep;
@@ -927,6 +923,7 @@ static struct fi_ops_ep psmx2_sep_ops = {
 	.tx_size_left = fi_no_tx_size_left,
 };
 
+DIRECT_FN
 int psmx2_sep_open(struct fid_domain *domain, struct fi_info *info,
 		   struct fid_ep **sep, void *context)
 {
@@ -1031,9 +1028,9 @@ int psmx2_sep_open(struct fid_domain *domain, struct fi_info *info,
 
 	sep_priv->id = ofi_atomic_inc32(&domain_priv->sep_cnt);
 
-	psmx2_lock(&domain_priv->sep_lock, 1);
+	domain_priv->sep_lock_fn(&domain_priv->sep_lock, 1);
 	dlist_insert_before(&sep_priv->entry, &domain_priv->sep_list);
-	psmx2_unlock(&domain_priv->sep_lock, 1);
+	domain_priv->sep_unlock_fn(&domain_priv->sep_lock, 1);
 
 	ep_name.epid = sep_priv->ctxts[0].trx_ctxt->psm2_epid;
 	ep_name.sep_id = sep_priv->id;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_init.c
index 3fa705dc5..d7c064f48 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_init.c
@@ -30,8 +30,8 @@
  * SOFTWARE.
  */
 
-#include "psmx2.h"
 #include "ofi_prov.h"
+#include "psmx2.h"
 #include <glob.h>
 #include <dlfcn.h>
 
@@ -53,7 +53,6 @@ struct psmx2_env psmx2_env = {
 	.num_devunits	= 1,
 	.inject_size	= 64,
 	.lock_level	= 2,
-	.lazy_conn	= 0,
 	.disconnect	= 0,
 #if (PSMX2_TAG_LAYOUT == PSMX2_TAG_LAYOUT_RUNTIME)
 	.tag_layout	= "auto",
@@ -70,7 +69,7 @@ int	 psmx2_tag_layout_locked = 0;
 
 static void psmx2_init_env(void)
 {
-	if (getenv("OMPI_COMM_WORLD_RANK") || getenv("PMI_RANK"))
+	if (getenv("OMPI_COMM_WORLD_RANK") || getenv("PMI_RANK") || getenv("PMIX_RANK"))
 		psmx2_env.name_server = 0;
 
 	fi_param_get_bool(&psmx2_prov, "name_server", &psmx2_env.name_server);
@@ -82,7 +81,6 @@ static void psmx2_init_env(void)
 	fi_param_get_str(&psmx2_prov, "prog_affinity", &psmx2_env.prog_affinity);
 	fi_param_get_int(&psmx2_prov, "inject_size", &psmx2_env.inject_size);
 	fi_param_get_bool(&psmx2_prov, "lock_level", &psmx2_env.lock_level);
-	fi_param_get_bool(&psmx2_prov, "lazy_conn", &psmx2_env.lazy_conn);
 	fi_param_get_bool(&psmx2_prov, "disconnect", &psmx2_env.disconnect);
 #if (PSMX2_TAG_LAYOUT == PSMX2_TAG_LAYOUT_RUNTIME)
 	fi_param_get_str(&psmx2_prov, "tag_layout", &psmx2_env.tag_layout);
@@ -188,6 +186,7 @@ static int psmx2_init_lib(void)
 {
 	int major, minor;
 	int ret = 0, err;
+	glob_t glob_buf;
 
 	if (psmx2_lib_initialized)
 		return 0;
@@ -197,6 +196,24 @@ static int psmx2_init_lib(void)
 	if (psmx2_lib_initialized)
 		goto out;
 
+	/*
+	* psm2_init() may wait for 15 seconds before return
+	* when /dev/hfi[0-9]_0 is not present. Check the existence of any hfi
+	* device interface first to avoid this delay. Note that the devices
+	* don't necessarily appear consecutively so we need to check all
+	* possible device names before returning "no device found" error.
+	* This also means if "/dev/hfi[0-9]_0" doesn't exist but other devices
+	* exist, we are still going to see the delay; but that's a rare case.
+	*/
+	if ((glob("/dev/hfi[0-9]_[0-9]", 0, NULL, &glob_buf) != 0) &&
+		(glob("/dev/hfi[0-9]_[0-9][0-9]", GLOB_APPEND, NULL, &glob_buf) != 0)) {
+		FI_INFO(&psmx2_prov, FI_LOG_CORE,
+			"no hfi device is found.\n");
+		ret = -FI_ENODEV;
+		goto out;
+	}
+	globfree(&glob_buf);
+
 	/* turn on multi-ep feature, but don't overwrite existing setting */
 	setenv("PSM2_MULTI_EP", "1", 0);
 
@@ -230,6 +247,7 @@ out:
 	return ret;
 }
 
+#if !HAVE_PSM2_INFO_QUERY
 #define PSMX2_SYSFS_PATH "/sys/class/infiniband/hfi1"
 static int psmx2_read_sysfs_int(int unit, char *entry)
 {
@@ -252,6 +270,7 @@ static int psmx2_unit_active(int unit)
 {
 	return (4 == psmx2_read_sysfs_int(unit, "ports/1/state"));
 }
+#endif
 
 #define PSMX2_MAX_UNITS	4
 static int psmx2_active_units[PSMX2_MAX_UNITS];
@@ -266,6 +285,13 @@ static void psmx2_update_hfi_info(void)
 	int multirail = 0;
 	char *s;
 
+#if HAVE_PSM2_INFO_QUERY
+	int unit_active;
+	int ret;
+	int tmp_cnt;
+	psm2_info_query_arg_t args[1];
+#endif
+
 	assert(psmx2_env.num_devunits <= PSMX2_MAX_UNITS);
 
 	s = getenv("HFI_UNIT");
@@ -278,6 +304,50 @@ static void psmx2_update_hfi_info(void)
 
 	psmx2_num_active_units = 0;
 	for (i = 0; i < psmx2_env.num_devunits; i++) {
+#if HAVE_PSM2_INFO_QUERY
+		args[0].unit = i;
+		ret = psm2_info_query(PSM2_INFO_QUERY_UNIT_STATUS, &unit_active, 1, args);
+		if (ret != PSM2_OK) {
+			FI_WARN(&psmx2_prov, FI_LOG_CORE,
+				"Failed to check active state of HFI unit %d\n",
+				i);
+			continue;
+		}
+
+		if (!unit_active) {
+			FI_WARN(&psmx2_prov, FI_LOG_CORE,
+				"HFI unit %d STATE = INACTIVE\n",
+				i);
+			continue;
+		}
+
+		if (hfi_unit >=0 && i != hfi_unit) {
+			FI_INFO(&psmx2_prov, FI_LOG_CORE,
+				"hfi %d skipped: HFI_UNIT=%d\n",
+				i, hfi_unit);
+			continue;
+		}
+
+		if (PSM2_OK != psm2_info_query(PSM2_INFO_QUERY_NUM_FREE_CONTEXTS,
+						&tmp_cnt, 1, args) || (tmp_cnt < 0))
+		{
+			FI_WARN(&psmx2_prov, FI_LOG_CORE,
+				"Failed to read number of free contexts from HFI unit %d\n",
+				i);
+			continue;
+		}
+		nfreectxts += tmp_cnt;
+
+		if (PSM2_OK != psm2_info_query(PSM2_INFO_QUERY_NUM_CONTEXTS,
+						&tmp_cnt, 1, args) || (tmp_cnt < 0))
+		{
+			FI_WARN(&psmx2_prov, FI_LOG_CORE,
+				"Failed to read number of contexts from HFI unit %d\n",
+				i);
+			continue;
+		}
+		nctxts += tmp_cnt;
+#else
 		if (!psmx2_unit_active(i)) {
 			FI_INFO(&psmx2_prov, FI_LOG_CORE,
 				"hfi %d skipped: inactive\n", i);
@@ -293,6 +363,7 @@ static void psmx2_update_hfi_info(void)
 
 		nctxts += psmx2_read_sysfs_int(i, "nctxts");
 		nfreectxts += psmx2_read_sysfs_int(i, "nfreectxts");
+#endif
 		psmx2_active_units[psmx2_num_active_units++] = i;
 
 		if (multirail)
@@ -335,7 +406,6 @@ static int psmx2_getinfo(uint32_t api_version, const char *node,
 	size_t len;
 	void *addr;
 	uint32_t fmt;
-	glob_t glob_buf;
 	uint32_t cnt = 0;
 
 	FI_INFO(&psmx2_prov, FI_LOG_CORE,"\n");
@@ -346,24 +416,12 @@ static int psmx2_getinfo(uint32_t api_version, const char *node,
 	if (psmx2_init_lib())
 		goto err_out;
 
-	/*
-	 * psm2_ep_num_devunits() may wait for 15 seconds before return
-	 * when /dev/hfi1_0 is not present. Check the existence of any hfi1
-	 * device interface first to avoid this delay. Note that the devices
-	 * don't necessarily appear consecutively so we need to check all
-	 * possible device names before returning "no device found" error.
-	 * This also means if "/dev/hfi1_0" doesn't exist but other devices
-	 * exist, we are still going to see the delay; but that's a rare case.
-	 */
-	if ((glob("/dev/hfi1_[0-9]", 0, NULL, &glob_buf) != 0) &&
-	    (glob("/dev/hfi1_[0-9][0-9]", GLOB_APPEND, NULL, &glob_buf) != 0)) {
-		FI_INFO(&psmx2_prov, FI_LOG_CORE,
-			"no hfi1 device is found.\n");
-		goto err_out;
-	}
-	globfree(&glob_buf);
-
-	if (psm2_ep_num_devunits(&cnt) || !cnt) {
+#if HAVE_PSM2_INFO_QUERY
+	if (psm2_info_query(PSM2_INFO_QUERY_NUM_UNITS, &cnt, 0, NULL) || !cnt)
+#else
+	if (psm2_ep_num_devunits(&cnt) || !cnt)
+#endif
+	{
 		FI_INFO(&psmx2_prov, FI_LOG_CORE,
 			"no PSM2 device is found.\n");
 		goto err_out;
@@ -496,7 +554,7 @@ static void psmx2_fini(void)
 struct fi_provider psmx2_prov = {
 	.name = PSMX2_PROV_NAME,
 	.version = PSMX2_VERSION,
-	.fi_version = PSMX2_VERSION,
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = psmx2_getinfo,
 	.fabric = psmx2_fabric,
 	.cleanup = psmx2_fini
@@ -506,8 +564,9 @@ PROVIDER_INI
 {
 	FI_INFO(&psmx2_prov, FI_LOG_CORE, "build options: HAVE_PSM2_SRC=%d, "
 			"HAVE_PSM2_AM_REGISTER_HANDLERS_2=%d, "
+			"HAVE_PSM2_MQ_FP_MSG=%d, "
 			"PSMX2_USE_REQ_CONTEXT=%d\n", HAVE_PSM2_SRC,
-			HAVE_PSM2_AM_REGISTER_HANDLERS_2, PSMX2_USE_REQ_CONTEXT);
+			HAVE_PSM2_AM_REGISTER_HANDLERS_2, HAVE_PSM2_MQ_FP_MSG, PSMX2_USE_REQ_CONTEXT);
 
 	fi_param_define(&psmx2_prov, "name_server", FI_PARAM_BOOL,
 			"Whether to turn on the name server or not "
@@ -545,9 +604,6 @@ PROVIDER_INI
 	fi_param_define(&psmx2_prov, "lock_level", FI_PARAM_INT,
 			"How internal locking is used. 0 means no locking. (default: 2).");
 
-	fi_param_define(&psmx2_prov, "lazy_conn", FI_PARAM_BOOL,
-			"Whether to use lazy connection or not (default: no).");
-
 	fi_param_define(&psmx2_prov, "disconnect", FI_PARAM_BOOL,
 			"Whether to issue disconnect request when process ends (default: no).");
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_mr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_mr.c
index 278b42eb8..750721a39 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_mr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_mr.c
@@ -38,14 +38,14 @@ struct psmx2_fid_mr *psmx2_mr_get(struct psmx2_fid_domain *domain,
 	RbtIterator it;
 	struct psmx2_fid_mr *mr = NULL;
 
-	psmx2_lock(&domain->mr_lock, 1);
+	domain->mr_lock_fn(&domain->mr_lock, 1);
 	it = rbtFind(domain->mr_map, (void *)key);
 	if (!it)
 		goto exit;
 
 	rbtKeyValue(domain->mr_map, it, (void **)&key, (void **)&mr);
 exit:
-	psmx2_unlock(&domain->mr_lock, 1);
+	domain->mr_unlock_fn(&domain->mr_lock, 1);
 	return mr;
 }
 
@@ -54,11 +54,11 @@ static inline void psmx2_mr_release_key(struct psmx2_fid_domain *domain,
 {
 	RbtIterator it;
 
-	psmx2_lock(&domain->mr_lock, 1);
+	domain->mr_lock_fn(&domain->mr_lock, 1);
 	it = rbtFind(domain->mr_map, (void *)key);
 	if (it)
 		rbtErase(domain->mr_map, it);
-	psmx2_unlock(&domain->mr_lock, 1);
+	domain->mr_unlock_fn(&domain->mr_lock, 1);
 }
 
 static int psmx2_mr_reserve_key(struct psmx2_fid_domain *domain,
@@ -71,7 +71,7 @@ static int psmx2_mr_reserve_key(struct psmx2_fid_domain *domain,
 	int try_count;
 	int err = -FI_ENOKEY;
 
-	psmx2_lock(&domain->mr_lock, 1);
+	domain->mr_lock_fn(&domain->mr_lock, 1);
 
 	if (domain->mr_mode == FI_MR_BASIC) {
 		key = domain->mr_reserved_key;
@@ -93,7 +93,7 @@ static int psmx2_mr_reserve_key(struct psmx2_fid_domain *domain,
 		}
 	}
 
-	psmx2_unlock(&domain->mr_lock, 1);
+	domain->mr_unlock_fn(&domain->mr_lock, 1);
 
 	return err;
 }
@@ -132,7 +132,8 @@ static int psmx2_mr_close(fid_t fid)
 	return 0;
 }
 
-static int psmx2_mr_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
+DIRECT_FN
+STATIC int psmx2_mr_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 {
 	struct psmx2_fid_mr *mr;
 	struct psmx2_fid_ep *ep;
@@ -170,7 +171,8 @@ static int psmx2_mr_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 	return 0;
 }
 
-static int psmx2_mr_control(fid_t fid, int command, void *arg)
+DIRECT_FN
+STATIC int psmx2_mr_control(fid_t fid, int command, void *arg)
 {
 	struct psmx2_fid_mr *mr;
 	struct fi_mr_raw_attr *attr;
@@ -272,7 +274,8 @@ static void psmx2_mr_normalize_iov(struct iovec *iov, size_t *count)
 	*count = i;
 }
 
-static int psmx2_mr_reg(struct fid *fid, const void *buf, size_t len,
+DIRECT_FN
+STATIC int psmx2_mr_reg(struct fid *fid, const void *buf, size_t len,
 			uint64_t access, uint64_t offset, uint64_t requested_key,
 			uint64_t flags, struct fid_mr **mr, void *context)
 {
@@ -318,7 +321,8 @@ static int psmx2_mr_reg(struct fid *fid, const void *buf, size_t len,
 	return 0;
 }
 
-static int psmx2_mr_regv(struct fid *fid,
+DIRECT_FN
+STATIC int psmx2_mr_regv(struct fid *fid,
 			 const struct iovec *iov, size_t count,
 			 uint64_t access, uint64_t offset,
 			 uint64_t requested_key, uint64_t flags,
@@ -372,7 +376,8 @@ static int psmx2_mr_regv(struct fid *fid,
 	return 0;
 }
 
-static int psmx2_mr_regattr(struct fid *fid, const struct fi_mr_attr *attr,
+DIRECT_FN
+STATIC int psmx2_mr_regattr(struct fid *fid, const struct fi_mr_attr *attr,
 			uint64_t flags, struct fid_mr **mr)
 {
 	struct fid_domain *domain;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_msg.c
index 4e3383785..bd50f479b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_msg.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_msg.c
@@ -44,7 +44,6 @@ ssize_t psmx2_recv_generic(struct fid_ep *ep, void *buf, size_t len,
 	psm2_mq_tag_t psm2_tag, psm2_tagsel;
 	struct fi_context *fi_context;
 	int recv_flag = 0;
-	size_t idx;
 	int err;
 	int enable_completion;
 
@@ -56,17 +55,8 @@ ssize_t psmx2_recv_generic(struct fid_ep *ep, void *buf, size_t len,
 
 	if ((ep_priv->caps & FI_DIRECTED_RECV) && src_addr != FI_ADDR_UNSPEC) {
 		av = ep_priv->av;
-		if (av && PSMX2_SEP_ADDR_TEST(src_addr)) {
-			psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->rx, src_addr);
-		} else if (av && av->type == FI_AV_TABLE) {
-			idx = (size_t)src_addr;
-			if ((err = psmx2_av_check_table_idx(av, ep_priv->rx, idx)))
-				return err;
-
-			psm2_epaddr = av->tables[ep_priv->rx->id].epaddrs[idx];
-		} else {
-			psm2_epaddr = PSMX2_ADDR_TO_EP(src_addr);
-		}
+		assert(av);
+		psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->rx, src_addr);
 	} else {
 		psm2_epaddr = 0;
 	}
@@ -136,7 +126,8 @@ ssize_t psmx2_recv_generic(struct fid_ep *ep, void *buf, size_t len,
 	return 0;
 }
 
-static ssize_t psmx2_recv(struct fid_ep *ep, void *buf, size_t len,
+DIRECT_FN
+STATIC ssize_t psmx2_recv(struct fid_ep *ep, void *buf, size_t len,
 			  void *desc, fi_addr_t src_addr, void *context)
 {
 	struct psmx2_fid_ep *ep_priv;
@@ -147,7 +138,8 @@ static ssize_t psmx2_recv(struct fid_ep *ep, void *buf, size_t len,
 				  ep_priv->rx_flags);
 }
 
-static ssize_t psmx2_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
+DIRECT_FN
+STATIC ssize_t psmx2_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
 			     uint64_t flags)
 {
 	void *buf;
@@ -170,7 +162,8 @@ static ssize_t psmx2_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
 				  msg->addr, msg->context, flags);
 }
 
-static ssize_t psmx2_recvv(struct fid_ep *ep, const struct iovec *iov,
+DIRECT_FN
+STATIC ssize_t psmx2_recvv(struct fid_ep *ep, const struct iovec *iov,
 			   void **desc, size_t count, fi_addr_t src_addr,
 			   void *context)
 {
@@ -204,7 +197,6 @@ ssize_t psmx2_send_generic(struct fid_ep *ep, const void *buf, size_t len,
 	struct fi_context * fi_context;
 	int send_flag = 0;
 	int err;
-	size_t idx;
 	int no_completion = 0;
 	struct psmx2_cq_event *event;
 	int have_data = (flags & FI_REMOTE_CQ_DATA) > 0;
@@ -216,17 +208,8 @@ ssize_t psmx2_send_generic(struct fid_ep *ep, const void *buf, size_t len,
 						context, flags, data);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = (size_t)dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else  {
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	PSMX2_SET_TAG(psm2_tag, 0, data, PSMX2_TYPE_MSG | PSMX2_IMM_BIT_SET(have_data));
 
@@ -301,7 +284,6 @@ ssize_t psmx2_sendv_generic(struct fid_ep *ep, const struct iovec *iov,
 	struct fi_context * fi_context;
 	int send_flag = 0;
 	int err;
-	size_t idx;
 	int no_completion = 0;
 	struct psmx2_cq_event *event;
 	size_t real_count;
@@ -337,8 +319,6 @@ ssize_t psmx2_sendv_generic(struct fid_ep *ep, const struct iovec *iov,
 	if (!req)
 		return -FI_ENOMEM;
 
-	PSMX2_STATUS_INIT(req->status);
-
 	if (total_len <= PSMX2_IOV_BUF_SIZE) {
 		req->iov_protocol = PSMX2_IOV_PROTO_PACK;
 		p = req->buf;
@@ -370,19 +350,8 @@ ssize_t psmx2_sendv_generic(struct fid_ep *ep, const struct iovec *iov,
 	}
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = (size_t)dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx))) {
-			free(req);
-			return err;
-		}
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else  {
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	if (flags & FI_REMOTE_CQ_DATA)
 		msg_flags |= PSMX2_IMM_BIT;
@@ -564,7 +533,8 @@ int psmx2_handle_sendv_req(struct psmx2_fid_ep *ep,
 	return 0;
 }
 
-static ssize_t psmx2_send(struct fid_ep *ep, const void *buf, size_t len,
+DIRECT_FN
+STATIC ssize_t psmx2_send(struct fid_ep *ep, const void *buf, size_t len,
 			  void *desc, fi_addr_t dest_addr, void *context)
 {
 	struct psmx2_fid_ep *ep_priv;
@@ -575,7 +545,8 @@ static ssize_t psmx2_send(struct fid_ep *ep, const void *buf, size_t len,
 				  ep_priv->tx_flags, 0);
 }
 
-static ssize_t psmx2_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
+DIRECT_FN
+STATIC ssize_t psmx2_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
 			     uint64_t flags)
 {
 	void *buf;
@@ -604,7 +575,8 @@ static ssize_t psmx2_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
 				  msg->data);
 }
 
-static ssize_t psmx2_sendv(struct fid_ep *ep, const struct iovec *iov,
+DIRECT_FN
+STATIC ssize_t psmx2_sendv(struct fid_ep *ep, const struct iovec *iov,
 			   void **desc, size_t count, fi_addr_t dest_addr,
 			   void *context)
 {
@@ -632,7 +604,8 @@ static ssize_t psmx2_sendv(struct fid_ep *ep, const struct iovec *iov,
 			  dest_addr, context);
 }
 
-static ssize_t psmx2_inject(struct fid_ep *ep, const void *buf, size_t len,
+DIRECT_FN
+STATIC ssize_t psmx2_inject(struct fid_ep *ep, const void *buf, size_t len,
 			    fi_addr_t dest_addr)
 {
 	struct psmx2_fid_ep *ep_priv;
@@ -644,7 +617,8 @@ static ssize_t psmx2_inject(struct fid_ep *ep, const void *buf, size_t len,
 				  0);
 }
 
-static ssize_t psmx2_senddata(struct fid_ep *ep, const void *buf, size_t len,
+DIRECT_FN
+STATIC ssize_t psmx2_senddata(struct fid_ep *ep, const void *buf, size_t len,
 			      void *desc, uint64_t data, fi_addr_t dest_addr,
 			      void *context)
 {
@@ -656,7 +630,8 @@ static ssize_t psmx2_senddata(struct fid_ep *ep, const void *buf, size_t len,
 				  ep_priv->tx_flags | FI_REMOTE_CQ_DATA, data);
 }
 
-static ssize_t psmx2_injectdata(struct fid_ep *ep, const void *buf, size_t len,
+DIRECT_FN
+STATIC ssize_t psmx2_injectdata(struct fid_ep *ep, const void *buf, size_t len,
 				uint64_t data, fi_addr_t dest_addr)
 {
 	struct psmx2_fid_ep *ep_priv;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_rma.c
index 0e80fcd7f..8e6a0540d 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_rma.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_rma.c
@@ -33,13 +33,15 @@
 #include "psmx2.h"
 #include "psmx2_trigger.h"
 
+#if !HAVE_PSM2_MQ_FP_MSG
 static inline void psmx2_am_enqueue_rma(struct psmx2_trx_ctxt *trx_ctxt,
 					struct psmx2_am_request *req)
 {
-	psmx2_lock(&trx_ctxt->rma_queue.lock, 2);
+	trx_ctxt->domain->rma_queue_lock_fn(&trx_ctxt->rma_queue.lock, 2);
 	slist_insert_tail(&req->list_entry, &trx_ctxt->rma_queue.list);
-	psmx2_unlock(&trx_ctxt->rma_queue.lock, 2);
+	trx_ctxt->domain->rma_queue_unlock_fn(&trx_ctxt->rma_queue.lock, 2);
 }
+#endif
 
 static inline void psmx2_iov_copy(struct iovec *iov, size_t count,
 				  size_t offset, const void *src,
@@ -116,6 +118,11 @@ int psmx2_am_rma_handler(psm2_am_token_t token, psm2_amarg_t *args,
 	psm2_epaddr_t epaddr;
 	struct psmx2_trx_ctxt *rx;
 
+#if HAVE_PSM2_MQ_FP_MSG
+	psm2_mq_req_t psm2_req;
+	psm2_mq_tag_t psm2_tag, psm2_tagsel;
+#endif
+
 	psm2_am_get_source(token, &epaddr);
 	cmd = PSMX2_AM_GET_OP(args[0].u32w0);
 	eom = args[0].u32w0 & PSMX2_AM_EOM;
@@ -210,7 +217,28 @@ int psmx2_am_rma_handler(psm2_am_token_t token, psm2_amarg_t *args,
 					(has_data ? FI_REMOTE_CQ_DATA : 0),
 			PSMX2_CTXT_TYPE(&req->fi_context) = PSMX2_REMOTE_WRITE_CONTEXT;
 			PSMX2_CTXT_USER(&req->fi_context) = mr;
+#if HAVE_PSM2_MQ_FP_MSG
+			PSMX2_SET_TAG(psm2_tag, (uint64_t)req->write.context, 0,
+					PSMX2_RMA_TYPE_WRITE);
+			PSMX2_SET_MASK(psm2_tagsel, PSMX2_MATCH_ALL, PSMX2_RMA_TYPE_MASK);
+			op_error = psm2_mq_fp_msg(rx->psm2_ep, rx->psm2_mq,
+						 (psm2_epaddr_t)epaddr,
+						 &psm2_tag, &psm2_tagsel, 0,
+						 (void *)rma_addr, rma_len,
+						 (void *)&req->fi_context, PSM2_MQ_IRECV_FP, &psm2_req);
+			if (op_error) {
+				rep_args[0].u32w0 = PSMX2_AM_REP_WRITE | eom;
+				rep_args[0].u32w1 = op_error;
+				rep_args[1].u64 = args[1].u64;
+				err = psm2_am_reply_short(token, PSMX2_AM_RMA_HANDLER,
+							  rep_args, 2, NULL, 0, 0,
+							  NULL, NULL );
+				psmx2_am_request_free(rx, req);
+				break;
+			}
+#else
 			psmx2_am_enqueue_rma(rx, req);
+#endif
 		}
 		break;
 
@@ -282,7 +310,28 @@ int psmx2_am_rma_handler(psm2_am_token_t token, psm2_amarg_t *args,
 			req->read.peer_addr = (void *)epaddr;
 			PSMX2_CTXT_TYPE(&req->fi_context) = PSMX2_REMOTE_READ_CONTEXT;
 			PSMX2_CTXT_USER(&req->fi_context) = mr;
+#if HAVE_PSM2_MQ_FP_MSG
+			PSMX2_SET_TAG(psm2_tag, (uint64_t)req->read.context, 0,
+			PSMX2_RMA_TYPE_READ);
+			op_error = psm2_mq_fp_msg(rx->psm2_ep, rx->psm2_mq,
+				  (psm2_epaddr_t)req->read.peer_addr,
+				 &psm2_tag, 0, 0,
+				 (void *)req->read.addr, req->read.len,
+				 (void *)&req->fi_context, PSM2_MQ_ISEND_FP, &psm2_req);
+			if (op_error) {
+				rep_args[0].u32w0 = PSMX2_AM_REP_READ | eom;
+				rep_args[0].u32w1 = op_error;
+				rep_args[1].u64 = args[1].u64;
+				rep_args[2].u64 = 0;
+				err = psm2_am_reply_short(token, PSMX2_AM_RMA_HANDLER,
+						rep_args, 3, NULL, 0, 0,
+						NULL, NULL );
+				psmx2_am_request_free(rx, req);
+				break;
+			}
+#else
 			psmx2_am_enqueue_rma(rx, req);
+#endif
 		}
 		break;
 
@@ -541,6 +590,7 @@ void psmx2_am_ack_rma(struct psmx2_am_request *req)
 			      PSM2_AM_FLAG_NOREPLY, NULL, NULL);
 }
 
+#if !HAVE_PSM2_MQ_FP_MSG
 int psmx2_am_process_rma(struct psmx2_trx_ctxt *trx_ctxt,
 			 struct psmx2_am_request *req)
 {
@@ -569,6 +619,7 @@ int psmx2_am_process_rma(struct psmx2_trx_ctxt *trx_ctxt,
 
 	return psmx2_errno(err);
 }
+#endif
 
 ssize_t psmx2_read_generic(struct fid_ep *ep, void *buf, size_t len,
 			   void *desc, fi_addr_t src_addr,
@@ -585,8 +636,6 @@ ssize_t psmx2_read_generic(struct fid_ep *ep, void *buf, size_t len,
 	psm2_epaddr_t psm2_epaddr;
 	psm2_mq_req_t psm2_req;
 	psm2_mq_tag_t psm2_tag, psm2_tagsel;
-	size_t idx;
-	int err;
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 
@@ -597,18 +646,8 @@ ssize_t psmx2_read_generic(struct fid_ep *ep, void *buf, size_t len,
 	assert(buf);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(src_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, src_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = src_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(src_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(src_addr);
-	}
+	assert(av);
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, src_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid)
@@ -699,11 +738,9 @@ ssize_t psmx2_readv_generic(struct fid_ep *ep, const struct iovec *iov,
 	psm2_epaddr_t psm2_epaddr;
 	psm2_mq_req_t psm2_req;
 	psm2_mq_tag_t psm2_tag, psm2_tagsel;
-	size_t idx;
 	size_t total_len, long_len = 0, short_len;
 	void *long_buf = NULL;
 	int i;
-	int err;
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 
@@ -712,18 +749,8 @@ ssize_t psmx2_readv_generic(struct fid_ep *ep, const struct iovec *iov,
 						 addr, key, context, flags);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(src_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, src_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = src_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(src_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(src_addr);
-	}
+	assert(av);
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, src_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid)
@@ -829,7 +856,8 @@ ssize_t psmx2_readv_generic(struct fid_ep *ep, const struct iovec *iov,
 	return 0;
 }
 
-static ssize_t psmx2_read(struct fid_ep *ep, void *buf, size_t len,
+DIRECT_FN
+STATIC ssize_t psmx2_read(struct fid_ep *ep, void *buf, size_t len,
 			  void *desc, fi_addr_t src_addr,
 			  uint64_t addr, uint64_t key, void *context)
 {
@@ -841,7 +869,8 @@ static ssize_t psmx2_read(struct fid_ep *ep, void *buf, size_t len,
 				  key, context, ep_priv->tx_flags);
 }
 
-static ssize_t psmx2_readmsg(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_readmsg(struct fid_ep *ep,
 			     const struct fi_msg_rma *msg,
 			     uint64_t flags)
 {
@@ -867,7 +896,8 @@ static ssize_t psmx2_readmsg(struct fid_ep *ep,
 				  flags);
 }
 
-static ssize_t psmx2_readv(struct fid_ep *ep, const struct iovec *iov,
+DIRECT_FN
+STATIC ssize_t psmx2_readv(struct fid_ep *ep, const struct iovec *iov,
 			   void **desc, size_t count, fi_addr_t src_addr,
 			   uint64_t addr, uint64_t key, void *context)
 {
@@ -903,10 +933,8 @@ ssize_t psmx2_write_generic(struct fid_ep *ep, const void *buf, size_t len,
 	psm2_epaddr_t psm2_epaddr;
 	psm2_mq_req_t psm2_req;
 	psm2_mq_tag_t psm2_tag;
-	size_t idx;
 	void *psm2_context;
 	int no_event;
-	int err;
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 
@@ -918,18 +946,8 @@ ssize_t psmx2_write_generic(struct fid_ep *ep, const void *buf, size_t len,
 	assert(buf);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(dest_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid)
@@ -1060,13 +1078,11 @@ ssize_t psmx2_writev_generic(struct fid_ep *ep, const struct iovec *iov,
 	psm2_epaddr_t psm2_epaddr;
 	psm2_mq_req_t psm2_req;
 	psm2_mq_tag_t psm2_tag;
-	size_t idx;
 	void *psm2_context;
 	int no_event;
 	size_t total_len, len, len_sent;
 	uint8_t *buf, *p;
 	int i;
-	int err;
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 
@@ -1076,18 +1092,8 @@ ssize_t psmx2_writev_generic(struct fid_ep *ep, const struct iovec *iov,
 						  context, flags, data);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else if (av && av->type == FI_AV_TABLE) {
-		idx = dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		assert(dest_addr);
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	epaddr_context = psm2_epaddr_getctxt((void *)psm2_epaddr);
 	if (epaddr_context->epid == ep_priv->tx->psm2_epid)
@@ -1265,7 +1271,8 @@ ssize_t psmx2_writev_generic(struct fid_ep *ep, const struct iovec *iov,
 	return 0;
 }
 
-static ssize_t psmx2_write(struct fid_ep *ep, const void *buf, size_t len,
+DIRECT_FN
+STATIC ssize_t psmx2_write(struct fid_ep *ep, const void *buf, size_t len,
 			   void *desc, fi_addr_t dest_addr, uint64_t addr,
 			   uint64_t key, void *context)
 {
@@ -1277,7 +1284,8 @@ static ssize_t psmx2_write(struct fid_ep *ep, const void *buf, size_t len,
 				   key, context, ep_priv->tx_flags, 0);
 }
 
-static ssize_t psmx2_writemsg(struct fid_ep *ep,
+DIRECT_FN
+STATIC ssize_t psmx2_writemsg(struct fid_ep *ep,
 			      const struct fi_msg_rma *msg,
 			      uint64_t flags)
 {
@@ -1301,7 +1309,8 @@ static ssize_t psmx2_writemsg(struct fid_ep *ep,
 				   msg->context, flags, msg->data);
 }
 
-static ssize_t psmx2_writev(struct fid_ep *ep, const struct iovec *iov,
+DIRECT_FN
+STATIC ssize_t psmx2_writev(struct fid_ep *ep, const struct iovec *iov,
 			    void **desc, size_t count, fi_addr_t dest_addr,
 			    uint64_t addr, uint64_t key, void *context)
 {
@@ -1321,8 +1330,9 @@ static ssize_t psmx2_writev(struct fid_ep *ep, const struct iovec *iov,
 				   context, ep_priv->tx_flags, 0);
 }
 
-static ssize_t psmx2_inject(struct fid_ep *ep, const void *buf, size_t len,
-			    fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+DIRECT_FN
+STATIC ssize_t psmx2_inject_write(struct fid_ep *ep, const void *buf, size_t len,
+			          fi_addr_t dest_addr, uint64_t addr, uint64_t key)
 {
 	struct psmx2_fid_ep *ep_priv;
 
@@ -1333,7 +1343,8 @@ static ssize_t psmx2_inject(struct fid_ep *ep, const void *buf, size_t len,
 				   0);
 }
 
-static ssize_t psmx2_writedata(struct fid_ep *ep, const void *buf, size_t len,
+DIRECT_FN
+STATIC ssize_t psmx2_writedata(struct fid_ep *ep, const void *buf, size_t len,
 			       void *desc, uint64_t data, fi_addr_t dest_addr,
 			       uint64_t addr, uint64_t key, void *context)
 {
@@ -1346,9 +1357,10 @@ static ssize_t psmx2_writedata(struct fid_ep *ep, const void *buf, size_t len,
 				   data);
 }
 
-static ssize_t psmx2_injectdata(struct fid_ep *ep, const void *buf, size_t len,
-				uint64_t data, fi_addr_t dest_addr, uint64_t addr,
-				uint64_t key)
+DIRECT_FN
+STATIC ssize_t psmx2_inject_writedata(struct fid_ep *ep, const void *buf, size_t len,
+				      uint64_t data, fi_addr_t dest_addr, uint64_t addr,
+				      uint64_t key)
 {
 	struct psmx2_fid_ep *ep_priv;
 
@@ -1367,8 +1379,8 @@ struct fi_ops_rma psmx2_rma_ops = {
 	.write = psmx2_write,
 	.writev = psmx2_writev,
 	.writemsg = psmx2_writemsg,
-	.inject = psmx2_inject,
+	.inject = psmx2_inject_write,
 	.writedata = psmx2_writedata,
-	.injectdata = psmx2_injectdata,
+	.injectdata = psmx2_inject_writedata,
 };
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_tagged.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_tagged.c
index ded4ddbf1..dee42c4f6 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_tagged.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_tagged.c
@@ -46,7 +46,6 @@ static ssize_t psmx2_tagged_peek_generic(struct fid_ep *ep,
 	psm2_mq_req_t req;
 	psm2_mq_status2_t psm2_status;
 	psm2_mq_tag_t psm2_tag, psm2_tagsel;
-	size_t idx;
 	uint64_t data;
 	int err;
 
@@ -54,17 +53,8 @@ static ssize_t psmx2_tagged_peek_generic(struct fid_ep *ep,
 
 	if ((ep_priv->caps & FI_DIRECTED_RECV) && src_addr != FI_ADDR_UNSPEC) {
 		av = ep_priv->av;
-		if (av && PSMX2_SEP_ADDR_TEST(src_addr)) {
-			psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->rx, src_addr);
-		} else if (av && av->type == FI_AV_TABLE) {
-			idx = (size_t)src_addr;
-			if ((err = psmx2_av_check_table_idx(av, ep_priv->rx, idx)))
-				return err;
-
-			psm2_epaddr = av->tables[ep_priv->rx->id].epaddrs[idx];
-		} else {
-			psm2_epaddr = PSMX2_ADDR_TO_EP(src_addr);
-		}
+		assert(av);
+		psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->rx, src_addr);
 	} else {
 		psm2_epaddr = 0;
 	}
@@ -115,7 +105,7 @@ static ssize_t psmx2_tagged_peek_generic(struct fid_ep *ep,
 				return -FI_ENOMEM;
 
 			event->source_is_valid = 1;
-			event->source = PSMX2_EP_TO_ADDR(psm2_status.msg_peer);
+			event->source = psm2_status.msg_peer;
 			event->source_av = ep_priv->av;
 			psmx2_cq_enqueue_event(ep_priv->recv_cq, event);
 		}
@@ -159,7 +149,6 @@ ssize_t psmx2_tagged_recv_generic(struct fid_ep *ep, void *buf,
 	psm2_mq_req_t psm2_req;
 	psm2_mq_tag_t psm2_tag, psm2_tagsel;
 	struct fi_context *fi_context;
-	size_t idx;
 	int err;
 	int enable_completion;
 
@@ -208,7 +197,7 @@ ssize_t psmx2_tagged_recv_generic(struct fid_ep *ep, void *buf,
 					return -FI_ENOMEM;
 
 				event->source_is_valid = 1;
-				event->source = PSMX2_EP_TO_ADDR(psm2_status.msg_peer);
+				event->source = psm2_status.msg_peer;
 				event->source_av = ep_priv->av;
 				psmx2_cq_enqueue_event(ep_priv->recv_cq, event);
 			}
@@ -255,17 +244,8 @@ ssize_t psmx2_tagged_recv_generic(struct fid_ep *ep, void *buf,
 
 	if ((ep_priv->caps & FI_DIRECTED_RECV) && src_addr != FI_ADDR_UNSPEC) {
 		av = ep_priv->av;
-		if (av && PSMX2_SEP_ADDR_TEST(src_addr)) {
-			psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->rx, src_addr);
-		} else if (av && av->type == FI_AV_TABLE) {
-			idx = (size_t)src_addr;
-			if ((err = psmx2_av_check_table_idx(av, ep_priv->rx, idx)))
-				return err;
-
-			psm2_epaddr = av->tables[ep_priv->rx->id].epaddrs[idx];
-		} else {
-			psm2_epaddr = PSMX2_ADDR_TO_EP(src_addr);
-		}
+		assert(av);
+		psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->rx, src_addr);
 	} else {
 		psm2_epaddr = 0;
 	}
@@ -302,7 +282,6 @@ psmx2_tagged_recv_specialized(struct fid_ep *ep, void *buf, size_t len,
 			      uint64_t tag, uint64_t ignore,
 			      void *context,
 			      int enable_completion,
-			      enum fi_av_type av_type,
 			      int directed_receive)
 {
 	struct psmx2_fid_ep *ep_priv;
@@ -311,7 +290,6 @@ psmx2_tagged_recv_specialized(struct fid_ep *ep, void *buf, size_t len,
 	psm2_mq_req_t psm2_req;
 	psm2_mq_tag_t psm2_tag, psm2_tagsel;
 	struct fi_context *fi_context;
-	size_t idx;
 	int err;
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
@@ -334,24 +312,8 @@ psmx2_tagged_recv_specialized(struct fid_ep *ep, void *buf, size_t len,
 
 	if (directed_receive && src_addr != FI_ADDR_UNSPEC) {
 		av = ep_priv->av;
-		if (av_type == FI_AV_MAP) {
-			if (av && PSMX2_SEP_ADDR_TEST(src_addr)) {
-				psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->rx, src_addr);
-			} else {
-				psm2_epaddr = PSMX2_ADDR_TO_EP(src_addr);
-			}
-		} else { /* FI_AV_TABLE */
-			assert(av != NULL);
-			if (PSMX2_SEP_ADDR_TEST(src_addr)) {
-				psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->rx, src_addr);
-			} else {
-				idx = (size_t)src_addr;
-				if ((err = psmx2_av_check_table_idx(av, ep_priv->rx, idx)))
-					return err;
-
-				psm2_epaddr = av->tables[ep_priv->rx->id].epaddrs[idx];
-			}
-		}
+		assert(av);
+		psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->rx, src_addr);
 	} else {
 		psm2_epaddr = 0;
 	}
@@ -381,96 +343,50 @@ psmx2_tagged_recv_specialized(struct fid_ep *ep, void *buf, size_t len,
 	return 0;
 }
 
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_AV_MAP, FI_DIRECTED_RECEIVE not set */
-static ssize_t
-psmx2_tagged_recv_no_flag_av_map_undirected(struct fid_ep *ep, void *buf, size_t len,
-					    void *desc, fi_addr_t src_addr,
-					    uint64_t tag, uint64_t ignore,
-					    void *context)
-{
-	return psmx2_tagged_recv_specialized(ep, buf, len, desc,
-			src_addr, tag, ignore, context, 1, FI_AV_MAP, 0);
-}
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_AV_TABLE, FI_DIRECTED_RECEIVE not set */
-static ssize_t
-psmx2_tagged_recv_no_flag_av_table_undirected(struct fid_ep *ep, void *buf, size_t len,
-					      void *desc, fi_addr_t src_addr,
-					      uint64_t tag, uint64_t ignore,
-					      void *context)
-{
-	return psmx2_tagged_recv_specialized(ep, buf, len, desc,
-			src_addr, tag, ignore, context, 1, FI_AV_TABLE, 0);
-}
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_AV_MAP, FI_DIRECTED_RECEIVE not set */
-static ssize_t
-psmx2_tagged_recv_no_event_av_map_undirected(struct fid_ep *ep, void *buf, size_t len,
-					     void *desc, fi_addr_t src_addr,
-					     uint64_t tag, uint64_t ignore,
-					     void *context)
-{
-	return psmx2_tagged_recv_specialized(ep, buf, len, desc,
-			src_addr, tag, ignore, context, 0, FI_AV_MAP, 0);
-}
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_AV_TABLE, FI_DIRECTED_RECEIVE not set */
-static ssize_t
-psmx2_tagged_recv_no_event_av_table_undirected(struct fid_ep *ep, void *buf, size_t len,
-					       void *desc, fi_addr_t src_addr,
-					       uint64_t tag, uint64_t ignore,
-					       void *context)
-{
-	return psmx2_tagged_recv_specialized(ep, buf, len, desc,
-			src_addr, tag, ignore, context, 0, FI_AV_TABLE, 0);
-}
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_AV_MAP, FI_DIRECTED_RECEIVE set */
+/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_DIRECTED_RECEIVE not set */
 static ssize_t
-psmx2_tagged_recv_no_flag_av_map_directed(struct fid_ep *ep, void *buf, size_t len,
-					  void *desc, fi_addr_t src_addr,
-					  uint64_t tag, uint64_t ignore,
-					  void *context)
+psmx2_tagged_recv_no_flag_undirected(struct fid_ep *ep, void *buf, size_t len,
+				     void *desc, fi_addr_t src_addr,
+				     uint64_t tag, uint64_t ignore,
+				     void *context)
 {
-	return psmx2_tagged_recv_specialized(ep, buf, len, desc,
-			src_addr, tag, ignore, context, 1, FI_AV_MAP, 1);
+	return psmx2_tagged_recv_specialized(ep, buf, len, desc, src_addr,
+					     tag, ignore, context, 1, 0);
 }
 
-/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_AV_TABLE, FI_DIRECTED_RECEIVE set */
+/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_DIRECTED_RECEIVE not set */
 static ssize_t
-psmx2_tagged_recv_no_flag_av_table_directed(struct fid_ep *ep, void *buf, size_t len,
-					    void *desc, fi_addr_t src_addr,
-					    uint64_t tag, uint64_t ignore,
-					    void *context)
+psmx2_tagged_recv_no_event_undirected(struct fid_ep *ep, void *buf, size_t len,
+				      void *desc, fi_addr_t src_addr,
+				      uint64_t tag, uint64_t ignore,
+				      void *context)
 {
-	return psmx2_tagged_recv_specialized(ep, buf, len, desc,
-			src_addr, tag, ignore, context, 1, FI_AV_TABLE, 1);
+	return psmx2_tagged_recv_specialized(ep, buf, len, desc, src_addr,
+					     tag, ignore, context, 0, 0);
 }
 
-/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_AV_MAP, FI_DIRECTED_RECEIVE set */
+/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_DIRECTED_RECEIVE set */
 static ssize_t
-psmx2_tagged_recv_no_event_av_map_directed(struct fid_ep *ep, void *buf, size_t len,
-					   void *desc, fi_addr_t src_addr,
-					   uint64_t tag, uint64_t ignore,
-					   void *context)
+psmx2_tagged_recv_no_flag_directed(struct fid_ep *ep, void *buf, size_t len,
+				   void *desc, fi_addr_t src_addr,
+				   uint64_t tag, uint64_t ignore,
+				   void *context)
 {
-	return psmx2_tagged_recv_specialized(ep, buf, len, desc,
-			src_addr, tag, ignore, context, 0, FI_AV_MAP, 1);
+	return psmx2_tagged_recv_specialized(ep, buf, len, desc, src_addr,
+					     tag, ignore, context, 1, 1);
 }
 
-/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_AV_TABLE, FI_DIRECTED_RECEIVE set */
+/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_DIRECTED_RECEIVE set */
 static ssize_t
-psmx2_tagged_recv_no_event_av_table_directed(struct fid_ep *ep, void *buf, size_t len,
-					     void *desc, fi_addr_t src_addr,
-					     uint64_t tag, uint64_t ignore,
-					     void *context)
+psmx2_tagged_recv_no_event_directed(struct fid_ep *ep, void *buf, size_t len,
+				    void *desc, fi_addr_t src_addr,
+				    uint64_t tag, uint64_t ignore,
+				    void *context)
 {
-	return psmx2_tagged_recv_specialized(ep, buf, len, desc,
-			src_addr, tag, ignore, context, 0, FI_AV_TABLE, 1);
+	return psmx2_tagged_recv_specialized(ep, buf, len, desc, src_addr,
+					     tag, ignore, context, 0, 1);
 }
 
-
 static ssize_t psmx2_tagged_recv(struct fid_ep *ep, void *buf, size_t len,
 				 void *desc, fi_addr_t src_addr, uint64_t tag,
 				 uint64_t ignore, void *context)
@@ -533,16 +449,10 @@ psmx2_tagged_recvv##suffix(struct fid_ep *ep, const struct iovec *iov,	\
 }
 
 PSMX2_TAGGED_RECVV_FUNC()
-PSMX2_TAGGED_RECVV_FUNC(_no_flag_av_map_directed)
-PSMX2_TAGGED_RECVV_FUNC(_no_flag_av_table_directed)
-PSMX2_TAGGED_RECVV_FUNC(_no_event_av_map_directed)
-PSMX2_TAGGED_RECVV_FUNC(_no_event_av_table_directed)
-PSMX2_TAGGED_RECVV_FUNC(_no_flag_av_map_undirected)
-PSMX2_TAGGED_RECVV_FUNC(_no_flag_av_table_undirected)
-PSMX2_TAGGED_RECVV_FUNC(_no_event_av_map_undirected)
-PSMX2_TAGGED_RECVV_FUNC(_no_event_av_table_undirected)
-
-
+PSMX2_TAGGED_RECVV_FUNC(_no_flag_directed)
+PSMX2_TAGGED_RECVV_FUNC(_no_event_directed)
+PSMX2_TAGGED_RECVV_FUNC(_no_flag_undirected)
+PSMX2_TAGGED_RECVV_FUNC(_no_event_undirected)
 
 ssize_t psmx2_tagged_send_generic(struct fid_ep *ep,
 				  const void *buf, size_t len,
@@ -556,7 +466,6 @@ ssize_t psmx2_tagged_send_generic(struct fid_ep *ep,
 	psm2_mq_req_t psm2_req;
 	psm2_mq_tag_t psm2_tag;
 	struct fi_context *fi_context;
-	size_t idx;
 	int err;
 	int no_completion = 0;
 	struct psmx2_cq_event *event;
@@ -572,17 +481,8 @@ ssize_t psmx2_tagged_send_generic(struct fid_ep *ep,
 						 flags, data);
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else  if (av && av->type == FI_AV_TABLE) {
-		idx = (size_t)dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-			return err;
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else {
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	PSMX2_SET_TAG(psm2_tag, tag, (uint32_t)data,
 		      PSMX2_TYPE_TAGGED | PSMX2_IMM_BIT_SET(have_data));
@@ -651,7 +551,6 @@ psmx2_tagged_send_specialized(struct fid_ep *ep, const void *buf,
 			      fi_addr_t dest_addr, uint64_t tag,
 			      void *context,
 			      int enable_completion,
-			      enum fi_av_type av_type,
 			      int has_data, uint64_t data)
 {
 	struct psmx2_fid_ep *ep_priv;
@@ -660,30 +559,15 @@ psmx2_tagged_send_specialized(struct fid_ep *ep, const void *buf,
 	psm2_mq_req_t psm2_req;
 	psm2_mq_tag_t psm2_tag;
 	struct fi_context *fi_context;
-	size_t idx;
 	int err;
 
 	assert((tag & ~PSMX2_TAG_MASK) == 0);
 
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 	av = ep_priv->av;
+	assert(av);
 
-	if (av_type == FI_AV_MAP) {
-		if (av && PSMX2_SEP_ADDR_TEST(dest_addr))
-			psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-		else
-			psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	} else { /* FI_AV_TABLE */
-		if (PSMX2_SEP_ADDR_TEST(dest_addr)) {
-			psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-		} else {
-			idx = (size_t)dest_addr;
-			if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-				return err;
-
-			psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-		}
-	}
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	if (has_data)
 		PSMX2_SET_TAG(psm2_tag, tag, data, PSMX2_TYPE_TAGGED | PSMX2_IMM_BIT);
@@ -712,107 +596,56 @@ psmx2_tagged_send_specialized(struct fid_ep *ep, const void *buf,
 	return 0;
 }
 
-/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_AV_MAP */
-static ssize_t
-psmx2_tagged_send_no_flag_av_map(struct fid_ep *ep, const void *buf,
-				 size_t len, void *desc,
-				 fi_addr_t dest_addr, uint64_t tag,
-				 void *context)
-{
-	return psmx2_tagged_send_specialized(ep, buf, len, desc, dest_addr,
-					     tag, context, 1, FI_AV_MAP, 0, 0);
-}
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_AV_TABLE */
+/* op_flags=0, FI_SELECTIVE_COMPLETION not set */
 static ssize_t
-psmx2_tagged_send_no_flag_av_table(struct fid_ep *ep, const void *buf,
-				   size_t len, void *desc,
-				   fi_addr_t dest_addr, uint64_t tag,
-				   void *context)
-{
-	return psmx2_tagged_send_specialized(ep, buf, len, desc, dest_addr, tag,
-					     context, 1, FI_AV_TABLE, 0, 0);
-}
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_AV_MAP */
-static ssize_t
-psmx2_tagged_send_no_event_av_map(struct fid_ep *ep, const void *buf,
-				  size_t len, void *desc,
-				  fi_addr_t dest_addr, uint64_t tag,
-				  void *context)
-{
-	return psmx2_tagged_send_specialized(ep, buf, len, desc, dest_addr, tag,
-					     context, 0, FI_AV_MAP, 0, 0);
-}
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_AV_TABLE */
-static ssize_t
-psmx2_tagged_send_no_event_av_table(struct fid_ep *ep, const void *buf,
-				    size_t len, void *desc,
-				    fi_addr_t dest_addr, uint64_t tag,
-				    void *context)
-{
-	return psmx2_tagged_send_specialized(ep, buf, len, desc, dest_addr, tag,
-					     context, 0, FI_AV_TABLE, 0, 0);
-}
-
-/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_AV_MAP */
-static ssize_t
-psmx2_tagged_senddata_no_flag_av_map(struct fid_ep *ep, const void *buf,
-				     size_t len, void *desc, uint64_t data,
-				     fi_addr_t dest_addr, uint64_t tag,
-				     void *context)
+psmx2_tagged_send_no_flag(struct fid_ep *ep, const void *buf, size_t len,
+			  void *desc, fi_addr_t dest_addr, uint64_t tag,
+			  void *context)
 {
 	return psmx2_tagged_send_specialized(ep, buf, len, desc, dest_addr, tag,
-					     context, 1, FI_AV_MAP, 1, data);
+					     context, 1, 0, 0);
 }
 
-/* op_flags=0, FI_SELECTIVE_COMPLETION not set, FI_AV_TABLE */
+/* op_flags=0, FI_SELECTIVE_COMPLETION set */
 static ssize_t
-psmx2_tagged_senddata_no_flag_av_table(struct fid_ep *ep, const void *buf,
-				       size_t len, void *desc, uint64_t data,
-				       fi_addr_t dest_addr, uint64_t tag,
-				       void *context)
+psmx2_tagged_send_no_event(struct fid_ep *ep, const void *buf, size_t len,
+			   void *desc, fi_addr_t dest_addr, uint64_t tag,
+			   void *context)
 {
 	return psmx2_tagged_send_specialized(ep, buf, len, desc, dest_addr, tag,
-					     context, 1, FI_AV_TABLE, 1, data);
+					     context, 0, 0, 0);
 }
 
-/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_AV_MAP */
+/* op_flags=0, FI_SELECTIVE_COMPLETION not set */
 static ssize_t
-psmx2_tagged_senddata_no_event_av_map(struct fid_ep *ep, const void *buf,
-				      size_t len, void *desc, uint64_t data,
-				      fi_addr_t dest_addr, uint64_t tag,
-				      void *context)
+psmx2_tagged_senddata_no_flag(struct fid_ep *ep, const void *buf, size_t len,
+			      void *desc, uint64_t data, fi_addr_t dest_addr,
+			      uint64_t tag, void *context)
 {
 	return psmx2_tagged_send_specialized(ep, buf, len, desc, dest_addr, tag,
-					     context, 0, FI_AV_MAP, 1, data);
+					     context, 1, 1, data);
 }
 
-/* op_flags=0, FI_SELECTIVE_COMPLETION set, FI_AV_TABLE */
+/* op_flags=0, FI_SELECTIVE_COMPLETION set */
 static ssize_t
-psmx2_tagged_senddata_no_event_av_table(struct fid_ep *ep, const void *buf,
-					size_t len, void *desc, uint64_t data,
-					fi_addr_t dest_addr, uint64_t tag,
-					void *context)
+psmx2_tagged_senddata_no_event(struct fid_ep *ep, const void *buf, size_t len,
+			       void *desc, uint64_t data, fi_addr_t dest_addr,
+			       uint64_t tag, void *context)
 {
 	return psmx2_tagged_send_specialized(ep, buf, len, desc, dest_addr, tag,
-					     context, 0, FI_AV_TABLE, 1, data);
+					     context, 0, 1, data);
 }
 
-/* op_flags=0, FI_AV_MAP */
 __attribute__((always_inline))
 static inline ssize_t
 psmx2_tagged_inject_specialized(struct fid_ep *ep, const void *buf,
 				size_t len, fi_addr_t dest_addr,
-				uint64_t tag, enum fi_av_type av_type,
-				int has_data, uint64_t data)
+				uint64_t tag, int has_data, uint64_t data)
 {
 	struct psmx2_fid_ep *ep_priv;
 	struct psmx2_fid_av *av;
 	psm2_epaddr_t psm2_epaddr;
 	psm2_mq_tag_t psm2_tag;
-	size_t idx;
 	int err;
 
 	assert((tag & ~PSMX2_TAG_MASK) == 0);
@@ -823,23 +656,9 @@ psmx2_tagged_inject_specialized(struct fid_ep *ep, const void *buf,
 	ep_priv = container_of(ep, struct psmx2_fid_ep, ep);
 
 	av = ep_priv->av;
+	assert(av);
 
-	if (av_type == FI_AV_MAP) {
-		if (av && PSMX2_SEP_ADDR_TEST(dest_addr))
-			psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-		else
-			psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	} else { /* FI_AV_TABLE */
-		if (PSMX2_SEP_ADDR_TEST(dest_addr)) {
-			psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-		} else {
-			idx = (size_t)dest_addr;
-			if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx)))
-				return err;
-
-			psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-		}
-	}
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	if (has_data)
 		PSMX2_SET_TAG(psm2_tag, tag, data, PSMX2_TYPE_TAGGED | PSMX2_IMM_BIT);
@@ -858,44 +677,22 @@ psmx2_tagged_inject_specialized(struct fid_ep *ep, const void *buf,
 	return 0;
 }
 
-/* op_flags=0, FI_AV_MAP */
-static ssize_t
-psmx2_tagged_inject_no_flag_av_map(struct fid_ep *ep, const void *buf,
-				   size_t len, fi_addr_t dest_addr,
-				   uint64_t tag)
-{
-	return psmx2_tagged_inject_specialized(ep, buf, len, dest_addr, tag,
-					       FI_AV_MAP, 0, 0);
-}
-
-/* op_flags=0, FI_AV_TABLE */
-static ssize_t
-psmx2_tagged_inject_no_flag_av_table(struct fid_ep *ep, const void *buf,
-				     size_t len, fi_addr_t dest_addr,
-				     uint64_t tag)
-{
-	return psmx2_tagged_inject_specialized(ep, buf, len, dest_addr, tag,
-					       FI_AV_TABLE, 0, 0);
-}
-
-/* op_flags=0, FI_AV_MAP */
+/* op_flags=0 */
 static ssize_t
-psmx2_tagged_injectdata_no_flag_av_map(struct fid_ep *ep, const void *buf,
-				       size_t len, uint64_t data,
-				       fi_addr_t dest_addr, uint64_t tag)
+psmx2_tagged_inject_no_flag(struct fid_ep *ep, const void *buf, size_t len,
+			    fi_addr_t dest_addr, uint64_t tag)
 {
 	return psmx2_tagged_inject_specialized(ep, buf, len, dest_addr, tag,
-					       FI_AV_MAP, 1, data);
+					       0, 0);
 }
 
-/* op_flags=0, FI_AV_TABLE */
+/* op_flags=0 */
 static ssize_t
-psmx2_tagged_injectdata_no_flag_av_table(struct fid_ep *ep, const void *buf,
-					 size_t len, uint64_t data,
-					 fi_addr_t dest_addr, uint64_t tag)
+psmx2_tagged_injectdata_no_flag(struct fid_ep *ep, const void *buf, size_t len,
+				uint64_t data, fi_addr_t dest_addr, uint64_t tag)
 {
 	return psmx2_tagged_inject_specialized(ep, buf, len, dest_addr, tag,
-					       FI_AV_TABLE, 1, data);
+					       1, data);
 }
 
 ssize_t psmx2_tagged_sendv_generic(struct fid_ep *ep,
@@ -912,7 +709,6 @@ ssize_t psmx2_tagged_sendv_generic(struct fid_ep *ep,
 	struct fi_context * fi_context;
 	int send_flag = 0;
 	int err;
-	size_t idx;
 	int no_completion = 0;
 	struct psmx2_cq_event *event;
 	size_t real_count;
@@ -952,8 +748,6 @@ ssize_t psmx2_tagged_sendv_generic(struct fid_ep *ep,
 	if (!req)
 		return -FI_ENOMEM;
 
-	PSMX2_STATUS_INIT(req->status);
-
 	if (total_len <= PSMX2_IOV_BUF_SIZE) {
 		req->iov_protocol = PSMX2_IOV_PROTO_PACK;
 		p = req->buf;
@@ -985,19 +779,8 @@ ssize_t psmx2_tagged_sendv_generic(struct fid_ep *ep,
 	}
 
 	av = ep_priv->av;
-	if (av && PSMX2_SEP_ADDR_TEST(dest_addr)) {
-		psm2_epaddr = psmx2_av_translate_sep(av, ep_priv->tx, dest_addr);
-	} else  if (av && av->type == FI_AV_TABLE) {
-		idx = (size_t)dest_addr;
-		if ((err = psmx2_av_check_table_idx(av, ep_priv->tx, idx))) {
-			free(req);
-			return err;
-		}
-
-		psm2_epaddr = av->tables[ep_priv->tx->id].epaddrs[idx];
-	} else  {
-		psm2_epaddr = PSMX2_ADDR_TO_EP(dest_addr);
-	}
+	assert(av);
+	psm2_epaddr = psmx2_av_translate_addr(av, ep_priv->tx, dest_addr);
 
 	PSMX2_SET_TAG(psm2_tag, tag, (uint32_t)data,
 		      msg_flags | PSMX2_IMM_BIT_SET(have_data));
@@ -1173,10 +956,8 @@ psmx2_tagged_sendv##suffix(struct fid_ep *ep, const struct iovec *iov,	\
 }
 
 PSMX2_TAGGED_SENDV_FUNC()
-PSMX2_TAGGED_SENDV_FUNC(_no_flag_av_map)
-PSMX2_TAGGED_SENDV_FUNC(_no_flag_av_table)
-PSMX2_TAGGED_SENDV_FUNC(_no_event_av_map)
-PSMX2_TAGGED_SENDV_FUNC(_no_event_av_table)
+PSMX2_TAGGED_SENDV_FUNC(_no_flag)
+PSMX2_TAGGED_SENDV_FUNC(_no_event)
 
 static ssize_t psmx2_tagged_inject(struct fid_ep *ep,
 				   const void *buf, size_t len,
@@ -1222,20 +1003,12 @@ struct fi_ops_tagged psmx2_tagged_ops##suffix = {	\
 };
 
 PSMX2_TAGGED_OPS(,,,)
-PSMX2_TAGGED_OPS(_no_flag_av_map_directed, _no_flag_av_map, _no_flag_av_map_directed, _no_flag_av_map)
-PSMX2_TAGGED_OPS(_no_flag_av_table_directed, _no_flag_av_table, _no_flag_av_table_directed, _no_flag_av_table)
-PSMX2_TAGGED_OPS(_no_event_av_map_directed, _no_event_av_map, _no_event_av_map_directed, _no_flag_av_map)
-PSMX2_TAGGED_OPS(_no_event_av_table_directed, _no_event_av_table, _no_event_av_table_directed, _no_flag_av_table)
-PSMX2_TAGGED_OPS(_no_send_event_av_map_directed, _no_event_av_map, _no_flag_av_map_directed, _no_flag_av_map)
-PSMX2_TAGGED_OPS(_no_send_event_av_table_directed, _no_event_av_table, _no_flag_av_table_directed, _no_flag_av_table)
-PSMX2_TAGGED_OPS(_no_recv_event_av_map_directed, _no_flag_av_map, _no_event_av_map_directed, _no_flag_av_map)
-PSMX2_TAGGED_OPS(_no_recv_event_av_table_directed, _no_flag_av_table, _no_event_av_table_directed, _no_flag_av_table)
-PSMX2_TAGGED_OPS(_no_flag_av_map_undirected, _no_flag_av_map, _no_flag_av_map_undirected, _no_flag_av_map)
-PSMX2_TAGGED_OPS(_no_flag_av_table_undirected, _no_flag_av_table, _no_flag_av_table_undirected, _no_flag_av_table)
-PSMX2_TAGGED_OPS(_no_event_av_map_undirected, _no_event_av_map, _no_event_av_map_undirected, _no_flag_av_map)
-PSMX2_TAGGED_OPS(_no_event_av_table_undirected, _no_event_av_table, _no_event_av_table_undirected, _no_flag_av_table)
-PSMX2_TAGGED_OPS(_no_send_event_av_map_undirected, _no_event_av_map, _no_flag_av_map_undirected, _no_flag_av_map)
-PSMX2_TAGGED_OPS(_no_send_event_av_table_undirected, _no_event_av_table, _no_flag_av_table_undirected, _no_flag_av_table)
-PSMX2_TAGGED_OPS(_no_recv_event_av_map_undirected, _no_flag_av_map, _no_event_av_map_undirected, _no_flag_av_map)
-PSMX2_TAGGED_OPS(_no_recv_event_av_table_undirected, _no_flag_av_table, _no_event_av_table_undirected, _no_flag_av_table)
+PSMX2_TAGGED_OPS(_no_flag_directed, _no_flag, _no_flag_directed, _no_flag)
+PSMX2_TAGGED_OPS(_no_event_directed, _no_event, _no_event_directed, _no_flag)
+PSMX2_TAGGED_OPS(_no_send_event_directed, _no_event, _no_flag_directed, _no_flag)
+PSMX2_TAGGED_OPS(_no_recv_event_directed, _no_flag, _no_event_directed, _no_flag)
+PSMX2_TAGGED_OPS(_no_flag_undirected, _no_flag, _no_flag_undirected, _no_flag)
+PSMX2_TAGGED_OPS(_no_event_undirected, _no_event, _no_event_undirected, _no_flag)
+PSMX2_TAGGED_OPS(_no_send_event_undirected, _no_event, _no_flag_undirected, _no_flag)
+PSMX2_TAGGED_OPS(_no_recv_event_undirected, _no_flag, _no_event_undirected, _no_flag)
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_trx_ctxt.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_trx_ctxt.c
index 709ced94f..d4f2b8f87 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_trx_ctxt.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_trx_ctxt.c
@@ -96,10 +96,10 @@ int psmx2_am_trx_ctxt_handler(psm2_am_token_t token, psm2_amarg_t *args,
 		 */
 		disconn = malloc(sizeof(*disconn));
 		if (disconn) {
-			psmx2_lock(&trx_ctxt->peer_lock, 2);
+			trx_ctxt->domain->peer_lock_fn(&trx_ctxt->peer_lock, 2);
 			dlist_remove_first_match(&trx_ctxt->peer_list,
 						 psmx2_peer_match, epaddr);
-			psmx2_unlock(&trx_ctxt->peer_lock, 2);
+			trx_ctxt->domain->peer_unlock_fn(&trx_ctxt->peer_lock, 2);
 			if (trx_ctxt->ep && trx_ctxt->ep->av)
 				psmx2_av_remove_conn(trx_ctxt->ep->av, trx_ctxt, epaddr);
 			disconn->ep = trx_ctxt->psm2_ep;
@@ -129,12 +129,12 @@ void psmx2_trx_ctxt_disconnect_peers(struct psmx2_trx_ctxt *trx_ctxt)
 
 	/* use local peer_list to avoid entering AM handler while holding the lock */
 	dlist_init(&peer_list);
-	psmx2_lock(&trx_ctxt->peer_lock, 2);
+	trx_ctxt->domain->peer_lock_fn(&trx_ctxt->peer_lock, 2);
 	dlist_foreach_safe(&trx_ctxt->peer_list, item, tmp) {
 		dlist_remove(item);
 		dlist_insert_before(item, &peer_list);
 	}
-	psmx2_unlock(&trx_ctxt->peer_lock, 2);
+	trx_ctxt->domain->peer_unlock_fn(&trx_ctxt->peer_lock, 2);
 
 	dlist_foreach_safe(&peer_list, item, tmp) {
 		peer = container_of(item, struct psmx2_epaddr_context, entry);
@@ -176,9 +176,12 @@ void psmx2_trx_ctxt_free(struct psmx2_trx_ctxt *trx_ctxt, int usage_flags)
 	FI_INFO(&psmx2_prov, FI_LOG_CORE, "epid: %016lx (%s)\n",
 		trx_ctxt->psm2_epid, psmx2_usage_flags_to_string(old_flags));
 
-	psmx2_lock(&trx_ctxt->domain->trx_ctxt_lock, 1);
+	trx_ctxt->am_progress = 0;
+	trx_ctxt->poll_active = 0;
+
+	trx_ctxt->domain->trx_ctxt_lock_fn(&trx_ctxt->domain->trx_ctxt_lock, 1);
 	dlist_remove(&trx_ctxt->entry);
-	psmx2_unlock(&trx_ctxt->domain->trx_ctxt_lock, 1);
+	trx_ctxt->domain->trx_ctxt_unlock_fn(&trx_ctxt->domain->trx_ctxt_lock, 1);
 
 	if (psmx2_env.disconnect)
 		psmx2_trx_ctxt_disconnect_peers(trx_ctxt);
@@ -213,7 +216,9 @@ void psmx2_trx_ctxt_free(struct psmx2_trx_ctxt *trx_ctxt, int usage_flags)
 	fastlock_destroy(&trx_ctxt->am_req_pool_lock);
 	fastlock_destroy(&trx_ctxt->poll_lock);
 	fastlock_destroy(&trx_ctxt->peer_lock);
-	free(trx_ctxt);
+
+	if (!ofi_atomic_dec32(&trx_ctxt->poll_refcnt))
+		free(trx_ctxt);
 }
 
 struct psmx2_trx_ctxt *psmx2_trx_ctxt_alloc(struct psmx2_fid_domain *domain,
@@ -231,12 +236,12 @@ struct psmx2_trx_ctxt *psmx2_trx_ctxt_alloc(struct psmx2_fid_domain *domain,
 
 	/* Check existing allocations first if only Tx or Rx is needed */
 	if (compatible_flags) {
-		psmx2_lock(&domain->trx_ctxt_lock, 1);
+		domain->trx_ctxt_lock_fn(&domain->trx_ctxt_lock, 1);
 		dlist_foreach(&domain->trx_ctxt_list, item) {
 			trx_ctxt = container_of(item, struct psmx2_trx_ctxt, entry);
 			if (compatible_flags == trx_ctxt->usage_flags) {
 				trx_ctxt->usage_flags |= asked_flags;
-				psmx2_unlock(&domain->trx_ctxt_lock, 1);
+				domain->trx_ctxt_unlock_fn(&domain->trx_ctxt_lock, 1);
 				FI_INFO(&psmx2_prov, FI_LOG_CORE,
 					"use existing context. epid: %016lx "
 					"(%s -> tx+rx).\n", trx_ctxt->psm2_epid,
@@ -244,7 +249,7 @@ struct psmx2_trx_ctxt *psmx2_trx_ctxt_alloc(struct psmx2_fid_domain *domain,
 				return trx_ctxt;
 			}
 		}
-		psmx2_unlock(&domain->trx_ctxt_lock, 1);
+		domain->trx_ctxt_unlock_fn(&domain->trx_ctxt_lock, 1);
 	}
 
 	if (psmx2_trx_ctxt_cnt >= psmx2_env.max_trx_ctxt) {
@@ -323,21 +328,25 @@ struct psmx2_trx_ctxt *psmx2_trx_ctxt_alloc(struct psmx2_fid_domain *domain,
 		goto err_out_close_ep;
 	}
 
+#if !HAVE_PSM2_MQ_FP_MSG
+	fastlock_init(&trx_ctxt->rma_queue.lock);
+	slist_init(&trx_ctxt->rma_queue.list);
+#endif
 	fastlock_init(&trx_ctxt->peer_lock);
 	fastlock_init(&trx_ctxt->poll_lock);
 	fastlock_init(&trx_ctxt->am_req_pool_lock);
-	fastlock_init(&trx_ctxt->rma_queue.lock);
 	fastlock_init(&trx_ctxt->trigger_queue.lock);
 	dlist_init(&trx_ctxt->peer_list);
-	slist_init(&trx_ctxt->rma_queue.list);
 	slist_init(&trx_ctxt->trigger_queue.list);
 	trx_ctxt->id = psmx2_trx_ctxt_cnt++;
 	trx_ctxt->domain = domain;
 	trx_ctxt->usage_flags = asked_flags;
+	trx_ctxt->poll_active = 1;
+	ofi_atomic_initialize32(&trx_ctxt->poll_refcnt, 1); /* take one ref for domain->trx_ctxt_list */
 
-	psmx2_lock(&domain->trx_ctxt_lock, 1);
+	domain->trx_ctxt_lock_fn(&domain->trx_ctxt_lock, 1);
 	dlist_insert_before(&trx_ctxt->entry, &domain->trx_ctxt_list);
-	psmx2_unlock(&domain->trx_ctxt_lock, 1);
+	domain->trx_ctxt_unlock_fn(&domain->trx_ctxt_lock, 1);
 
 	return trx_ctxt;
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_wait.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_wait.c
index 6798ac0cc..bd2a6d1bc 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_wait.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/psmx2_wait.c
@@ -1,9 +1,9 @@
 /*
  * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
  *
- * This software is waitailable to you under a choice of one of two
+ * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, waitailable from the file
+ * General Public License (GPL) Version 2, available from the file
  * COPYING in the main directory of this source tree, or the
  * BSD license below:
  *
@@ -140,7 +140,8 @@ static void psmx2_wait_stop_progress(void)
 static struct fi_ops_wait *psmx2_wait_ops_save;
 static struct fi_ops_wait psmx2_wait_ops;
 
-static int psmx2_wait_wait(struct fid_wait *wait, int timeout)
+DIRECT_FN
+STATIC int psmx2_wait_wait(struct fid_wait *wait, int timeout)
 {
 	struct util_wait *wait_priv;
 	struct psmx2_fid_fabric *fabric;
@@ -158,6 +159,7 @@ static int psmx2_wait_wait(struct fid_wait *wait, int timeout)
 	return err;
 }
 
+DIRECT_FN
 int psmx2_wait_open(struct fid_fabric *fabric, struct fi_wait_attr *attr,
 		   struct fid_wait **waitset)
 {
@@ -177,6 +179,7 @@ int psmx2_wait_open(struct fid_fabric *fabric, struct fi_wait_attr *attr,
 	return 0;
 }
 
+DIRECT_FN
 int psmx2_wait_trywait(struct fid_fabric *fabric, struct fid **fids, int count)
 {
 	struct psmx2_fid_cq *cq_priv;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/version.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/version.h
index a91ab9f2a..52e921986 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/version.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/psm2/src/version.h
@@ -40,8 +40,6 @@
 #ifdef VALGRIND_MAKE_MEM_DEFINED
 #undef VALGRIND_MAKE_MEM_DEFINED
 #endif
-#define PSM_IS_TEST /* keep plain malloc/realloc/calloc/memalign/free/strdup */
-#include "psm2/psm_mq_internal.h"
 #else
 #include <psm2.h>
 #include <psm2_mq.h>
@@ -55,16 +53,19 @@
 #define PSMX2_DEFAULT_UUID	"00FF00FF-0000-0000-0000-00FF00FF00FF"
 #define PROVIDER_INI		PSM2_INI
 
-#if HAVE_PSM2_SRC
+/* Temporarily disable the use of psm2_mq_fp_msg due to instability */
+#ifdef HAVE_PSM2_MQ_FP_MSG
+#undef HAVE_PSM2_MQ_FP_MSG
+#endif
+#define HAVE_PSM2_MQ_FP_MSG	0
+
+#if HAVE_PSM2_MQ_REQ_USER
 
 #ifndef PSMX2_USE_REQ_CONTEXT
 #define PSMX2_USE_REQ_CONTEXT	1
 #endif
 
-#define PSMX2_STATUS_TYPE	struct psm2_mq_req
-#define PSMX2_STATUS_DECL(s)	struct psm2_mq_req *s
-#define PSMX2_STATUS_INIT(s)
-#define PSMX2_STATUS_SAVE(s,t)	do { t = s; } while (0)
+#define PSMX2_STATUS_TYPE	struct psm2_mq_req_user
 #define PSMX2_STATUS_ERROR(s)	((s)->error_code)
 #define PSMX2_STATUS_TAG(s)	((s)->tag)
 #define PSMX2_STATUS_RCVLEN(s)	((s)->recv_msglen)
@@ -72,15 +73,7 @@
 #define PSMX2_STATUS_PEER(s)	((s)->peer)
 #define PSMX2_STATUS_CONTEXT(s)	((s)->context)
 
-#define PSMX2_POLL_COMPLETION(trx_ctxt, status, err) \
-	do { \
-		(err) = psm2_mq_ipeek_dequeue((trx_ctxt)->psm2_mq, &(status)); \
-	} while (0)
-
-#define PSMX2_FREE_COMPLETION(trx_ctxt, status) \
-	psm2_mq_req_free((trx_ctxt)->psm2_mq, status)
-
-#else /* !HAVE_PSM2_SRC */
+#else /* !HAVE_PSM2_MQ_REQ_USER */
 
 #ifdef PSMX2_USE_REQ_CONTEXT
 #undef PSMX2_USE_REQ_CONTEXT
@@ -88,9 +81,6 @@
 #define PSMX2_USE_REQ_CONTEXT	0
 
 #define PSMX2_STATUS_TYPE	psm2_mq_status2_t
-#define PSMX2_STATUS_DECL(s)	psm2_mq_status2_t s##_priv, *s
-#define PSMX2_STATUS_INIT(s)	do { s = &s##_priv; } while (0)
-#define PSMX2_STATUS_SAVE(s,t)	do { *(t) = *(s); } while (0)
 #define PSMX2_STATUS_ERROR(s)	((s)->error_code)
 #define PSMX2_STATUS_TAG(s)	((s)->msg_tag)
 #define PSMX2_STATUS_RCVLEN(s)	((s)->nbytes)
@@ -98,27 +88,7 @@
 #define PSMX2_STATUS_PEER(s)	((s)->msg_peer)
 #define PSMX2_STATUS_CONTEXT(s)	((s)->context)
 
-/*
- * psm2_mq_test2 is called immediately after psm2_mq_ipeek with a lock held to
- * prevent psm2_mq_ipeek from returning the same request multiple times under
- * different threads.
- */
-#define PSMX2_POLL_COMPLETION(trx_ctxt, status, err) \
-	do { \
-		if (psmx2_trylock(&(trx_ctxt)->poll_lock, 2)) { \
-			(err) = PSM2_MQ_NO_COMPLETIONS; \
-		} else { \
-			psm2_mq_req_t psm2_req; \
-			(err) = psm2_mq_ipeek((trx_ctxt)->psm2_mq, &psm2_req, NULL); \
-			if ((err) == PSM2_OK) \
-				psm2_mq_test2(&psm2_req, (status)); \
-			psmx2_unlock(&(trx_ctxt)->poll_lock, 2); \
-		} \
-	} while(0)
-
-#define PSMX2_FREE_COMPLETION(trx_ctxt, status)
-
-#endif /* HAVE_PSM2_SRC */
+#endif /* !HAVE_PSM2_MQ_REQ_USER */
 
 /*
  * Provide backward compatibility for older PSM2 libraries that lack the
@@ -134,10 +104,10 @@ typedef int (*psm2_am_handler_2_fn_t) (
 			psm2_amarg_t *args, int nargs,
 			void *src, uint32_t len, void *hctx);
 
-extern psm2_am_handler_fn_t psmx2_am_handlers[];
-extern psm2_am_handler_2_fn_t psmx2_am_handlers_2[];
-extern void *psmx2_am_handler_ctxts[];
-extern int psmx2_am_handler_count;
+extern psm2_am_handler_fn_t	psmx2_am_handlers[];
+extern psm2_am_handler_2_fn_t	psmx2_am_handlers_2[];
+extern void			*psmx2_am_handler_ctxts[];
+extern int			psmx2_am_handler_count;
 
 static inline
 psm2_error_t psm2_am_register_handlers_2(
@@ -166,10 +136,10 @@ psm2_error_t psm2_am_register_handlers_2(
 #endif /* !HAVE_PSM2_AM_REGISTER_HANDLERS_2 */
 
 /*
- * Use reserved space within psm2_mq_req for fi_context instead of
+ * Use reserved space within psm2_mq_req_user for fi_context instead of
  * allocating from a internal queue.
  *
- * Only work when compiled with PSM2 source. Can be turned off by
+ * Only work with PSM2 that has psm2_mq_req_user defined. Can be turned off by
  * passing "-DPSMX2_USE_REQ_CONTEXT=0" to the compiler.
  */
 
@@ -194,14 +164,15 @@ psm2_error_t psm2_am_register_handlers_2(
 
 #define PSMX2_REQ_GET_OP_CONTEXT(req, ctx) \
 	do { \
-		(ctx) = (req)->context = (req)->user_reserved; \
+		struct psm2_mq_req_user *req_user = (void *)(req); \
+		(ctx) = req_user->context = req_user->user_reserved; \
 	} while (0)
 
 #else /* !PSMX2_USE_REQ_CONTEXT */
 
 struct psmx2_context {
-        struct fi_context fi_context;
-        struct slist_entry list_entry;
+        struct fi_context	fi_context;
+        struct slist_entry	list_entry;
 };
 
 #define PSMX2_EP_DECL_OP_CONTEXT \
@@ -239,15 +210,15 @@ struct psmx2_context {
 #define PSMX2_EP_GET_OP_CONTEXT(ep, ctx) \
 	do { \
 		struct psmx2_context *context; \
-		psmx2_lock(&(ep)->context_lock, 2); \
+		ep->domain->context_lock_fn(&(ep)->context_lock, 2); \
 		if (!slist_empty(&(ep)->free_context_list)) { \
 			context = container_of(slist_remove_head(&(ep)->free_context_list), \
 					       struct psmx2_context, list_entry); \
-			psmx2_unlock(&(ep)->context_lock, 2); \
+			ep->domain->context_unlock_fn(&(ep)->context_lock, 2); \
 			(ctx) = &context->fi_context; \
 			break; \
 		} \
-		psmx2_unlock(&(ep)->context_lock, 2); \
+		ep->domain->context_unlock_fn(&(ep)->context_lock, 2); \
 		context = malloc(sizeof(*context)); \
 		if (!context) { \
 			FI_WARN(&psmx2_prov, FI_LOG_EP_DATA, "out of memory.\n"); \
@@ -261,12 +232,12 @@ struct psmx2_context {
 		struct psmx2_context *context; \
 		context = container_of((ctx), struct psmx2_context, fi_context); \
 		context->list_entry.next = NULL; \
-		psmx2_lock(&(ep)->context_lock, 2); \
+		ep->domain->context_lock_fn(&(ep)->context_lock, 2); \
 		slist_insert_tail(&context->list_entry, &(ep)->free_context_list); \
-		psmx2_unlock(&(ep)->context_lock, 2); \
+		ep->domain->context_unlock_fn(&(ep)->context_lock, 2); \
 	} while (0)
 
-#endif /* PSMX2_USE_REQ_CONTEXT */
+#endif /* !PSMX2_USE_REQ_CONTEXT */
 
 #endif
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/Makefile.include
new file mode 100644
index 000000000..6eac7c0d5
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/Makefile.include
@@ -0,0 +1,28 @@
+if HAVE_RSTREAM
+_rstream_files = \
+	prov/rstream/src/rstream_domain.c	\
+	prov/rstream/src/rstream_fabric.c	\
+	prov/rstream/src/rstream_attr.c	\
+	prov/rstream/src/rstream_init.c	\
+	prov/rstream/src/rstream_cm.c	\
+	prov/rstream/src/rstream_msg.c	\
+	prov/rstream/src/rstream_eq.c	\
+	prov/rstream/src/rstream_ep.c   \
+	prov/rstream/src/rstream.h
+
+if HAVE_RSTREAM_DL
+pkglib_LTLIBRARIES += librstream-fi.la
+librstream_fi_la_SOURCES = $(_rstream_files) $(common_srcs)
+librstream_fi_la_LIBADD = $(linkback) $(rstream_LIBS)
+librstream_fi_la_LDFLAGS = -module -avoid-version -shared -export-dynamic
+librstream_fi_la_DEPENDENCIES = $(linkback)
+else !HAVE_RSTREAM_DL
+src_libfabric_la_SOURCES += $(_rstream_files)
+src_libfabric_la_LIBADD += $(rstream_LIBS)
+endif !HAVE_RSTREAM_DL
+
+prov_install_man_pages += man/man7/fi_rstream.7
+
+endif HAVE_RSTREAM
+
+prov_dist_man_pages += man/man7/fi_rstream.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/configure.m4 b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/configure.m4
new file mode 100644
index 000000000..2543f472b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/configure.m4
@@ -0,0 +1,15 @@
+dnl Configury specific to the libfabric rstream provider
+
+dnl Called to configure this provider
+dnl
+dnl Arguments:
+dnl
+dnl $1: action if configured successfully
+dnl $2: action if not configured successfully
+dnl
+AC_DEFUN([FI_RSTREAM_CONFIGURE],[
+	# Determine if we can support the rxd provider
+	rstream_h_happy=0
+	AS_IF([test x"$enable_rstream" != x"no"], [rstream_h_happy=1])
+        AS_IF([test $rstream_h_happy -eq 1], [$1], [$2])
+])
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream.h
new file mode 100644
index 000000000..ddbc1fd5b
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream.h
@@ -0,0 +1,232 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _RSTREAM_H_
+#define _RSTREAM_H_
+
+#if HAVE_CONFIG_H
+#  include <config.h>
+#endif /* HAVE_CONFIG_H */
+
+#include <string.h>
+
+#include <rdma/fabric.h>
+#include <rdma/fi_atomic.h>
+#include <rdma/fi_cm.h>
+#include <rdma/fi_domain.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_eq.h>
+#include <rdma/fi_rma.h>
+#include <rdma/fi_tagged.h>
+#include "rdma/providers/fi_log.h"
+
+#include <ofi.h>
+#include <ofi_util.h>
+#include <ofi_proto.h>
+#include <ofi_prov.h>
+#include <ofi_enosys.h>
+
+
+#define RSTREAM_CAPS (FI_MSG | FI_SEND | FI_RECV | FI_LOCAL_COMM | FI_REMOTE_COMM)
+#define RSTREAM_DEFAULT_QP_SIZE 384
+#define RSTREAM_MAX_CTRL 2
+#define RSTREAM_MR_BITS 15
+#define RSTREAM_DEFAULT_MR_SEG_SIZE (1 << RSTREAM_MR_BITS)
+
+#define RSTREAM_MAX_POLL_TIME 10
+
+#define RSTREAM_MAX_MR_BITS 20
+#define RSTREAM_MR_MAX (1ULL << RSTREAM_MAX_MR_BITS)
+#define RSTREAM_MR_LEN_MASK (RSTREAM_MR_MAX - 1)
+#define RSTREAM_CREDIT_OFFSET RSTREAM_MAX_MR_BITS
+#define RSTREAM_CREDIT_BITS 9
+#define RSTREAM_CREDITS_MAX (1ULL << RSTREAM_CREDIT_BITS)
+#define RSTREAM_CREDIT_MASK ((RSTREAM_CREDITS_MAX - 1) << RSTREAM_CREDIT_OFFSET)
+#define RSTREAM_RSOCKETV2 2
+
+/*iWARP, have to also track msg len [msglen, target_credits, target_mr_len]*/
+#define RSTREAM_USING_IWARP (rstream_info.ep_attr->protocol == FI_PROTO_IWARP)
+#define RSTREAM_IWARP_DATA_SIZE sizeof(uint32_t)
+
+#define RSTREAM_IWARP_MSG_BIT (1ULL << 31)
+#define RSTREAM_IWARP_MSG_BIT_MASK (RSTREAM_IWARP_MSG_BIT - 1)
+#define RSTREAM_IWARP_IMM_MSG_LEN (1ULL << RSTREAM_MAX_MR_BITS) /* max transmission size */
+
+extern struct fi_info rstream_info;
+extern struct fi_provider rstream_prov;
+extern struct util_prov rstream_util_prov;
+extern struct fi_fabric_attr rstream_fabric_attr;
+
+/* util structs ~ user layer fds */
+
+struct rstream_fabric {
+	struct util_fabric util_fabric;
+	struct fid_fabric *msg_fabric;
+};
+
+struct rstream_domain {
+	struct util_domain util_domain;
+	struct fid_domain *msg_domain;
+};
+
+enum rstream_msg_type {
+	RSTREAM_CTRL_MSG,
+	RSTREAM_RX_MSG_COMP,
+	RSTREAM_TX_MSG_COMP,
+	RSTREAM_MSG_UNKNOWN
+};
+
+struct rstream_mr_seg {
+	void *data_start;
+	uint32_t size;
+	uint32_t avail_size;
+	uint64_t start_offset;
+	uint64_t end_offset;
+};
+
+struct rstream_lmr_data {
+	void *base_addr;
+	void *ldesc;
+	uint64_t rkey;
+	struct fid_mr *mr;
+	struct rstream_mr_seg tx;
+	struct rstream_mr_seg rx;
+	uint64_t recv_buffer_offset;
+};
+
+struct rstream_rmr_data {
+	struct rstream_mr_seg mr;
+	uint64_t rkey;
+};
+
+struct rstream_cm_data {
+	uint64_t base_addr;
+	uint64_t rkey;
+	uint32_t rmr_size;
+	uint16_t max_rx_credits;
+	uint8_t version;
+	uint8_t reserved;
+};
+
+struct rstream_ctx_data {
+	struct fi_context ctx;
+	size_t len;
+};
+
+DECLARE_FREESTACK(struct rstream_ctx_data, rstream_tx_ctx_fs);
+
+struct rstream_tx_ctx {
+	struct rstream_ctx_data *tx_ctxs;
+	uint32_t num_in_use;
+	uint32_t free_index;
+	uint32_t front;
+};
+
+struct rstream_window {
+	uint16_t max_tx_credits;
+	uint16_t tx_credits;
+	uint16_t ctrl_credits;
+	uint16_t max_target_rx_credits;
+	uint16_t target_rx_credits;
+	uint16_t max_rx_credits;
+};
+
+struct rstream_cq_data {
+	uint32_t total_len;
+	uint16_t num_completions;
+};
+
+struct rstream_ep {
+	struct util_ep util_ep;
+	struct fid_ep *ep_fd;
+	struct fid_domain *msg_domain;
+	struct rstream_lmr_data local_mr;
+	struct rstream_rmr_data remote_data;
+	struct fid_cq *cq;
+	struct rstream_window qp_win;
+	struct fi_context *rx_ctxs;
+	uint32_t rx_ctx_index;
+	struct rstream_tx_ctx_fs *tx_ctxs;
+	struct rstream_cq_data rx_cq_data;
+	fastlock_t send_lock;
+	fastlock_t recv_lock;
+	/* must take send/recv lock before cq_lock */
+	fastlock_t cq_lock;
+};
+
+struct rstream_pep {
+	struct util_pep util_pep;
+	struct fid_pep	*pep_fd;
+};
+
+struct rstream_eq {
+	struct util_eq util_eq;
+	struct fid_eq *eq_fd;
+	uint32_t cm_data_len;
+	struct fi_eq_cm_entry *cm_entry;
+	uint32_t prev_cm_state;
+	RbtHandle ep_map;
+};
+
+struct rstream_timer {
+	struct timeval start;
+	struct timeval end;
+	uint32_t poll_time;
+};
+
+extern ssize_t rstream_post_cq_data_recv(struct rstream_ep *ep,
+	const struct fi_cq_data_entry *cq_entry);
+
+extern int rstream_info_to_rstream(uint32_t version, const struct fi_info *core_info,
+	struct fi_info *info);
+extern int rstream_info_to_core(uint32_t version, const struct fi_info *rstream_info,
+	struct fi_info *core_info);
+extern void rstream_set_info(struct fi_info *info);
+extern struct fi_ops_cm rstream_ops_cm;
+extern struct fi_ops_cm rstream_ops_pep_cm;
+extern struct fi_ops_msg rstream_ops_msg;
+extern int rstream_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
+	struct fid_pep **pep, void *context);
+extern void rstream_process_cm_event(struct rstream_ep *ep, void *cm_data);
+
+int rstream_fabric_open(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
+	void *context);
+int rstream_domain_open(struct fid_fabric *fabric, struct fi_info *info,
+	struct fid_domain **domain, void *context);
+int rstream_ep_open(struct fid_domain *domain, struct fi_info *info,
+	struct fid_ep **ep_fid, void *context);
+int rstream_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
+	struct fid_eq **eq, void *context);
+int rstream_info_to_core(uint32_t version, const struct fi_info *rstream_info,
+	struct fi_info *core_info);
+
+#endif /* _RSTREAM_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_attr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_attr.c
new file mode 100644
index 000000000..40a5d962e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_attr.c
@@ -0,0 +1,96 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rstream.h"
+
+
+struct fi_tx_attr rstream_tx_attr = {
+	.caps = RSTREAM_CAPS,
+	.msg_order = FI_ORDER_SAS,
+	.size = RSTREAM_DEFAULT_QP_SIZE,
+};
+
+struct fi_rx_attr rstream_rx_attr = {
+	.caps = RSTREAM_CAPS,
+	.msg_order = FI_ORDER_SAS,
+	.size = RSTREAM_DEFAULT_QP_SIZE,
+};
+
+struct fi_ep_attr rstream_ep_attr = {
+	.type = FI_EP_SOCK_STREAM,
+	.protocol = FI_PROTO_RSTREAM,
+	.protocol_version = 1,
+	.tx_ctx_cnt = 1,
+	.rx_ctx_cnt = 1,
+};
+
+struct fi_domain_attr rstream_domain_attr = {
+	.caps = FI_LOCAL_COMM | FI_REMOTE_COMM,
+	.threading = FI_THREAD_SAFE,
+	.control_progress = FI_PROGRESS_AUTO,
+	.data_progress = FI_PROGRESS_MANUAL,
+	.resource_mgmt = FI_RM_ENABLED,
+	.av_type = FI_AV_UNSPEC,
+	/* for the ofi mr_check  */
+	.mr_mode = 0,
+	.tx_ctx_cnt = 1,
+	.rx_ctx_cnt = 1,
+	.max_ep_tx_ctx = 1,
+	.mr_iov_limit = 1,
+};
+
+struct fi_fabric_attr rstream_fabric_attr = {
+	.prov_version = FI_VERSION(1, 7),
+};
+
+struct fi_info rstream_info = {
+	.caps = RSTREAM_CAPS,
+	.addr_format = FI_SOCKADDR,
+	.tx_attr = &rstream_tx_attr,
+	.rx_attr = &rstream_rx_attr,
+	.ep_attr = &rstream_ep_attr,
+	.domain_attr = &rstream_domain_attr,
+	.fabric_attr = &rstream_fabric_attr
+};
+
+/* settings post CONNREQ for users */
+void rstream_set_info(struct fi_info *info)
+{
+	info->caps = RSTREAM_CAPS;
+	info->mode = 0;
+	info->ep_attr->type = FI_EP_SOCK_STREAM;
+	info->ep_attr->protocol = rstream_info.ep_attr->protocol;
+	info->domain_attr->mr_mode = 0;
+	info->domain_attr->mr_cnt = 0;
+	*info->rx_attr = rstream_rx_attr;
+	*info->tx_attr = rstream_tx_attr;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_cm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_cm.c
new file mode 100644
index 000000000..97635a05f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_cm.c
@@ -0,0 +1,188 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rstream.h"
+
+
+static void rstream_format_data(struct rstream_cm_data *cm,
+	const struct rstream_ep *ep)
+{
+	assert(cm && ep->local_mr.rx.data_start);
+
+	cm->version = RSTREAM_RSOCKETV2;
+	cm->max_rx_credits = htons(ep->qp_win.max_rx_credits);
+	cm->base_addr = htonll((uintptr_t)ep->local_mr.rx.data_start);
+	cm->rkey = htonll(ep->local_mr.rkey);
+	cm->rmr_size = htonl(ep->local_mr.rx.size);
+}
+
+static int rstream_setname(fid_t fid, void *addr, size_t addrlen)
+{
+	fid_t rstream_fid;
+	struct rstream_pep *rstream_pep;
+	struct rstream_ep *rstream_ep;
+
+	if (fid->fclass == FI_CLASS_PEP) {
+		rstream_pep = container_of(fid, struct rstream_pep,
+			util_pep.pep_fid);
+		rstream_fid = &rstream_pep->pep_fd->fid;
+	} else if (fid->fclass == FI_CLASS_EP) {
+		rstream_ep = container_of(fid, struct rstream_ep,
+			util_ep.ep_fid);
+		rstream_fid = &rstream_ep->ep_fd->fid;
+	} else {
+		return -FI_ENOSYS;
+	}
+
+	return fi_setname(rstream_fid, addr, addrlen);
+}
+
+static int rstream_getname(fid_t fid, void *addr, size_t *addrlen)
+{
+	fid_t rstream_fid;
+	struct rstream_pep *rstream_pep;
+	struct rstream_ep *rstream_ep;
+
+	if (fid->fclass == FI_CLASS_PEP) {
+		rstream_pep = container_of(fid, struct rstream_pep,
+			util_pep.pep_fid);
+		rstream_fid = &rstream_pep->pep_fd->fid;
+	} else if (fid->fclass == FI_CLASS_EP) {
+		rstream_ep = container_of(fid, struct rstream_ep,
+			util_ep.ep_fid);
+		rstream_fid = &rstream_ep->ep_fd->fid;
+	} else {
+		return -FI_ENOSYS;
+	}
+
+	return fi_getname(rstream_fid, addr, addrlen);
+}
+
+static int rstream_getpeer(struct fid_ep *ep, void *addr, size_t *addrlen)
+{
+	struct rstream_ep *rstream_ep =
+		container_of(ep, struct rstream_ep, util_ep.ep_fid);
+
+	return fi_getpeer(rstream_ep->ep_fd, addr, addrlen);
+}
+
+static int rstream_check_cm_size(struct rstream_ep *ep)
+{
+	int ret;
+	size_t cm_max_size = 0, opt_size = sizeof(size_t);
+
+	ret = fi_getopt(&ep->ep_fd->fid, FI_OPT_ENDPOINT, FI_OPT_CM_DATA_SIZE,
+		&cm_max_size, &opt_size);
+	if (ret < 0)
+		return ret;
+	if (cm_max_size < sizeof(struct rstream_cm_data))
+		return -FI_ETOOSMALL;
+	return ret;
+}
+
+static int rstream_connect(struct fid_ep *ep, const void *addr,
+	const void *param, size_t paramlen)
+{
+	struct rstream_ep *rstream_ep =
+		container_of(ep, struct rstream_ep, util_ep.ep_fid);
+	struct rstream_cm_data cm_data;
+
+	if (param || paramlen > 0 || rstream_check_cm_size(rstream_ep) != 0)
+		return -FI_ENOSYS;
+
+	rstream_format_data(&cm_data, rstream_ep);
+
+	return fi_connect(rstream_ep->ep_fd, addr, &cm_data, sizeof(cm_data));
+}
+
+static int rstream_listen(struct fid_pep *pep)
+{
+	struct rstream_pep *rstream_pep = container_of(pep,
+		struct rstream_pep, util_pep.pep_fid);
+
+	return fi_listen(rstream_pep->pep_fd);
+}
+
+static int rstream_accept(struct fid_ep *ep, const void *param,
+	size_t paramlen)
+{
+	struct rstream_cm_data cm_data;
+	struct rstream_ep *rstream_ep =
+		container_of(ep, struct rstream_ep, util_ep.ep_fid);
+
+	if (param || paramlen > 0 || rstream_check_cm_size(rstream_ep) != 0)
+		return -FI_ENOSYS;
+
+	rstream_format_data(&cm_data, rstream_ep);
+
+	return fi_accept(rstream_ep->ep_fd, &cm_data, sizeof(cm_data));
+}
+
+static int rstream_reject(struct fid_pep *pep, fid_t handle,
+	const void *param, size_t paramlen)
+{
+	return -FI_ENOSYS;
+}
+
+static int rstream_shutdown(struct fid_ep *ep, uint64_t flags)
+{
+	struct rstream_ep *rstream_ep =
+		container_of(ep, struct rstream_ep, util_ep.ep_fid);
+
+	return fi_shutdown(rstream_ep->ep_fd, flags);
+}
+
+struct fi_ops_cm rstream_ops_pep_cm = {
+	.size = sizeof(struct fi_ops_cm),
+	.setname = rstream_setname,
+	.getname = rstream_getname,
+	.getpeer = fi_no_getpeer,
+	.connect = fi_no_connect,
+	.listen = rstream_listen,
+	.accept = fi_no_accept,
+	.reject = rstream_reject,
+	.shutdown = rstream_shutdown,
+	.join = fi_no_join,
+};
+
+struct fi_ops_cm rstream_ops_cm = {
+	.size = sizeof(struct fi_ops_cm),
+	.setname = fi_no_setname,
+	.getname = fi_no_getname,
+	.getpeer = rstream_getpeer,
+	.connect = rstream_connect,
+	.listen = fi_no_listen,
+	.accept = rstream_accept,
+	.reject = fi_no_reject,
+	.shutdown = rstream_shutdown,
+	.join = fi_no_join,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_domain.c
new file mode 100644
index 000000000..17978aff1
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_domain.c
@@ -0,0 +1,125 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rstream.h"
+
+
+static int rstream_domain_close(fid_t fid)
+{
+	struct rstream_domain *rstream_domain =
+		container_of(fid, struct rstream_domain,
+		util_domain.domain_fid.fid);
+	int ret;
+
+	ret = fi_close(&rstream_domain->msg_domain->fid);
+	if (ret)
+		return ret;
+
+	ret = ofi_domain_close(&rstream_domain->util_domain);
+	if (ret)
+		return ret;
+
+	free(rstream_domain);
+
+	return 0;
+}
+
+static struct fi_ops_mr rstream_domain_mr_ops = {
+	.size = sizeof(struct fi_ops_mr),
+	.reg = fi_no_mr_reg,
+	.regv = fi_no_mr_regv,
+	.regattr = fi_no_mr_regattr,
+};
+
+static struct fi_ops rstream_domain_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = rstream_domain_close,
+	.bind = fi_no_bind,
+	.control = fi_no_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static struct fi_ops_domain rstream_domain_ops = {
+	.size = sizeof(struct fi_ops_domain),
+	.av_open = fi_no_av_open,
+	.cq_open = fi_no_cq_open,
+	.endpoint = rstream_ep_open,
+	.scalable_ep = fi_no_scalable_ep,
+	.cntr_open = fi_no_cntr_open,
+	.poll_open = fi_no_poll_open,
+	.stx_ctx = fi_no_stx_context,
+	.srx_ctx = fi_no_srx_context,
+	.query_atomic = fi_no_query_atomic,
+};
+
+int rstream_domain_open(struct fid_fabric *fabric, struct fi_info *info,
+			   struct fid_domain **domain, void *context)
+{
+	struct rstream_domain *rstream_domain;
+	struct rstream_fabric *rstream_fabric;
+	int ret;
+	struct fi_info *cinfo = NULL;
+
+	rstream_domain = calloc(1, sizeof(*rstream_domain));
+	if (!rstream_domain)
+		return -FI_ENOMEM;
+
+	rstream_fabric = container_of(fabric, struct rstream_fabric,
+		util_fabric.fabric_fid);
+
+	ret = ofi_get_core_info(FI_VERSION(1, 7), NULL, NULL, 0,
+		&rstream_util_prov, info, rstream_info_to_core, &cinfo);
+	if (ret)
+		goto err1;
+
+	ret = fi_domain(rstream_fabric->msg_fabric, cinfo,
+		&rstream_domain->msg_domain, context);
+	if (ret)
+		goto err1;
+
+	ret = ofi_domain_init(fabric, info, &rstream_domain->util_domain,
+		context);
+	if (ret)
+		goto err1;
+
+	*domain = &rstream_domain->util_domain.domain_fid;
+	(*domain)->fid.ops = &rstream_domain_fi_ops;
+	(*domain)->mr = &rstream_domain_mr_ops;
+	(*domain)->ops = &rstream_domain_ops;
+
+	return 0;
+err1:
+	if (cinfo)
+		fi_freeinfo(cinfo);
+	free(rstream_domain);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_ep.c
new file mode 100644
index 000000000..0979b244f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_ep.c
@@ -0,0 +1,420 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rstream.h"
+
+
+static int rstream_ep_close(fid_t fid)
+{
+	int ret;
+	struct rstream_ep *rstream_ep =
+		container_of(fid, struct rstream_ep, util_ep.ep_fid.fid);
+
+	ret = fi_close(&rstream_ep->local_mr.mr->fid);
+	if (ret)
+		return ret;
+	free(rstream_ep->local_mr.base_addr);
+
+	ret = fi_close(&rstream_ep->ep_fd->fid);
+	if (ret)
+		return ret;
+
+	ret = fi_close(&rstream_ep->cq->fid);
+	if (ret)
+		return ret;
+
+	ofi_endpoint_close(&rstream_ep->util_ep);
+
+	rstream_tx_ctx_fs_free(rstream_ep->tx_ctxs);
+
+	fastlock_destroy(&rstream_ep->send_lock);
+	fastlock_destroy(&rstream_ep->recv_lock);
+	fastlock_destroy(&rstream_ep->cq_lock);
+	free(rstream_ep->rx_ctxs);
+	free(rstream_ep);
+	return 0;
+}
+
+static int rstream_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
+{
+	int ret;
+	struct rstream_ep *rstream_ep =
+		container_of(ep_fid, struct rstream_ep, util_ep.ep_fid.fid);
+	struct rstream_eq *rstream_eq = NULL;
+
+	switch (bfid->fclass) {
+	case FI_CLASS_EQ:
+		rstream_eq = container_of(bfid, struct rstream_eq,
+			util_eq.eq_fid.fid);
+		ret = fi_ep_bind(rstream_ep->ep_fd, &rstream_eq->eq_fd->fid,
+			flags);
+		rbtInsert(rstream_eq->ep_map, &rstream_ep->ep_fd->fid,
+			rstream_ep);
+		break;
+	default:
+		FI_WARN(&rstream_prov, FI_LOG_EP_CTRL, "invalid fid class\n");
+		ret = -FI_EINVAL;
+		break;
+	}
+	return ret;
+}
+
+static int rstream_reg_mrs(struct fid_domain *domain,
+	struct rstream_lmr_data *lmr)
+{
+	int ret;
+	uint64_t rx_meta_data_offset = 0;
+	uint32_t full_mr_size = lmr->tx.size + lmr->rx.size;
+
+	if (RSTREAM_USING_IWARP)
+		rx_meta_data_offset = RSTREAM_IWARP_DATA_SIZE * lmr->rx.size;
+
+	full_mr_size = full_mr_size + rx_meta_data_offset;
+	lmr->base_addr = malloc(full_mr_size);
+
+	ret = fi_mr_reg(domain, lmr->base_addr, full_mr_size,
+		FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE,
+		0, 0, 0, &lmr->mr, NULL);
+	if (ret)
+		return ret;
+
+	lmr->ldesc = fi_mr_desc(lmr->mr);
+	lmr->rkey = fi_mr_key(lmr->mr);
+	lmr->tx.data_start = (char *)lmr->base_addr;
+	lmr->tx.avail_size = lmr->tx.size;
+	lmr->rx.data_start = (char *)lmr->tx.data_start +
+		lmr->tx.size + rx_meta_data_offset;
+
+	return ret;
+}
+
+static int rstream_cq_init(struct fid_domain *domain, struct rstream_ep *rep)
+{
+	int ret;
+	struct fi_cq_attr attr;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.format = FI_CQ_FORMAT_DATA;
+	attr.wait_obj = FI_WAIT_FD;
+	attr.size = rep->qp_win.max_rx_credits + rep->qp_win.max_tx_credits;
+
+	ret = fi_cq_open(domain, &attr, &rep->cq, NULL);
+	if (ret)
+		return ret;
+
+	ret = fi_ep_bind(rep->ep_fd, &rep->cq->fid, FI_TRANSMIT | FI_RECV);
+	if (ret)
+		return ret;
+
+	rep->qp_win.tx_credits =
+		rep->qp_win.max_tx_credits - RSTREAM_MAX_CTRL;
+
+	return ret;
+}
+
+static int rstream_ep_ctrl(struct fid *fid, int command, void *arg)
+{
+	struct rstream_ep *rstream_ep;
+	int ret = 0;
+	rstream_ep = container_of(fid, struct rstream_ep, util_ep.ep_fid.fid);
+
+	switch (command) {
+	case FI_ENABLE:
+		ret = rstream_reg_mrs(rstream_ep->msg_domain,
+			&rstream_ep->local_mr);
+		if (ret)
+			goto err1;
+		ret = rstream_cq_init(rstream_ep->msg_domain, rstream_ep);
+		if (ret)
+			goto err1;
+		ret = fi_enable(rstream_ep->ep_fd);
+		break;
+	case FI_GETWAIT:
+		ret = fi_control(&rstream_ep->cq->fid, FI_GETWAIT, arg);
+		if (ret)
+			return ret;
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+
+	return ret;
+
+err1:
+	if (rstream_ep->local_mr.base_addr)
+		free(rstream_ep->local_mr.base_addr);
+	if (rstream_ep->local_mr.mr)
+		fi_close(&rstream_ep->local_mr.mr->fid);
+
+	return ret;
+}
+
+static struct fi_ops rstream_ep_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = rstream_ep_close,
+	.bind = rstream_ep_bind,
+	.control = rstream_ep_ctrl,
+	.ops_open = fi_no_ops_open,
+};
+
+static int rstream_ep_setopt(fid_t fid, int level, int optname,
+	const void *optval, size_t optlen)
+{
+	struct rstream_ep *rstream_ep =
+		container_of(fid, struct rstream_ep, util_ep.ep_fid.fid);
+
+	if (level != FI_OPT_ENDPOINT)
+		return -FI_ENOPROTOOPT;
+
+	if (optname == FI_OPT_SEND_BUF_SIZE) {
+		if(sizeof(rstream_ep->local_mr.tx.size) != optlen)
+			return -FI_EINVAL;
+		rstream_ep->local_mr.tx.size = *((uint32_t *)optval);
+	} else if (optname == FI_OPT_RECV_BUF_SIZE) {
+		if(sizeof(rstream_ep->local_mr.rx.size) != optlen)
+			return -FI_EINVAL;
+		rstream_ep->local_mr.rx.size = *((uint32_t *)optval);
+	} else if (optname == FI_OPT_TX_SIZE) {
+		if(sizeof(rstream_ep->qp_win.max_tx_credits) != optlen)
+			return -FI_EINVAL;
+		rstream_ep->qp_win.max_tx_credits = *((uint16_t *)optval);
+	} else if (optname == FI_OPT_RX_SIZE) {
+		if(sizeof(rstream_ep->qp_win.max_rx_credits) != optlen)
+			return -FI_EINVAL;
+		rstream_ep->qp_win.max_rx_credits = *((uint16_t *)optval);
+	} else {
+		return -FI_ENOPROTOOPT;
+	}
+
+	return 0;
+}
+
+static struct fi_ops_ep rstream_ops_ep = {
+	.size = sizeof(struct fi_ops_ep),
+	.cancel = fi_no_cancel,
+	.getopt = fi_no_getopt,
+	.setopt = rstream_ep_setopt,
+	.tx_ctx = fi_no_tx_ctx,
+	.rx_ctx = fi_no_rx_ctx,
+	.rx_size_left = fi_no_rx_size_left,
+	.tx_size_left = fi_no_tx_size_left,
+};
+
+int rstream_ep_open(struct fid_domain *domain, struct fi_info *info,
+		   struct fid_ep **ep_fid, void *context)
+{
+	struct rstream_ep *rstream_ep;
+	struct rstream_domain *rstream_domain;
+	struct rstream_pep *rstream_pep = NULL;
+	int ret;
+
+	rstream_domain = container_of(domain, struct rstream_domain,
+		util_domain.domain_fid);
+
+	rstream_ep = calloc(1, sizeof(*rstream_ep));
+	if (!rstream_ep)
+		return -FI_ENOMEM;
+
+	/* manual progress */
+	ret = ofi_endpoint_init(domain, &rstream_util_prov, info,
+		&rstream_ep->util_ep, context, NULL);
+	if (ret)
+		goto err1;
+
+	rstream_info_to_core(FI_VERSION(1, 7), NULL, info);
+
+	if (info->handle && info->handle->fclass == FI_CLASS_PEP) {
+		rstream_pep = container_of(info->handle,
+			struct rstream_pep, util_pep.pep_fid);
+		info->handle = &rstream_pep->pep_fd->fid;
+	}
+
+	ret = fi_endpoint(rstream_domain->msg_domain, info,
+		&rstream_ep->ep_fd, NULL);
+	if (ret)
+		goto err1;
+
+	if (rstream_pep)
+		free(rstream_pep);
+
+	rstream_ep->msg_domain = rstream_domain->msg_domain;
+	rstream_ep->local_mr.tx.size = RSTREAM_DEFAULT_MR_SEG_SIZE;
+	rstream_ep->local_mr.rx.size = RSTREAM_DEFAULT_MR_SEG_SIZE;
+
+	rstream_ep->qp_win.max_tx_credits = rstream_info.tx_attr->size;
+	rstream_ep->qp_win.ctrl_credits = RSTREAM_MAX_CTRL;
+	rstream_ep->qp_win.max_rx_credits = rstream_info.rx_attr->size;
+
+	rstream_ep->tx_ctxs =
+		rstream_tx_ctx_fs_create(rstream_ep->qp_win.max_tx_credits,
+			NULL, NULL);
+
+	assert(rstream_ep->tx_ctxs);
+	rstream_ep->rx_ctxs = (struct fi_context *)
+		calloc(rstream_ep->qp_win.max_rx_credits,
+		sizeof(*rstream_ep->rx_ctxs));
+	assert(rstream_ep->rx_ctxs);
+
+	*ep_fid = &rstream_ep->util_ep.ep_fid;
+	(*ep_fid)->fid.ops = &rstream_ep_fi_ops;
+	(*ep_fid)->ops = &rstream_ops_ep;
+	(*ep_fid)->cm = &rstream_ops_cm;
+	(*ep_fid)->msg = &rstream_ops_msg;
+	fastlock_init(&rstream_ep->send_lock);
+	fastlock_init(&rstream_ep->recv_lock);
+	fastlock_init(&rstream_ep->cq_lock);
+	return 0;
+
+err1:
+	free(rstream_ep);
+	return ret;
+}
+
+static int rstream_pep_bind(struct fid *pep_fid, struct fid *bfid,
+	uint64_t flags)
+{
+	struct rstream_pep *rstream_pep = container_of(pep_fid,
+		struct rstream_pep, util_pep.pep_fid);
+	struct rstream_eq *rstream_eq = NULL;
+	int ret;
+
+	switch (bfid->fclass) {
+	case FI_CLASS_EQ:
+		rstream_eq = container_of(bfid, struct rstream_eq,
+			util_eq.eq_fid.fid);
+		ret = fi_pep_bind(rstream_pep->pep_fd, &rstream_eq->eq_fd->fid,
+			flags);
+		break;
+	default:
+		FI_WARN(&rstream_prov, FI_LOG_EP_CTRL, "invalid fid class\n");
+		ret = -FI_EINVAL;
+		break;
+	}
+	return ret;
+}
+
+static int rstream_pep_ctrl(struct fid *fid, int command, void *arg)
+{
+	struct rstream_pep *rstream_pep;
+	int ret = 0;
+
+	switch (fid->fclass) {
+	case FI_CLASS_PEP:
+		if (command != FI_BACKLOG)
+			return -FI_EINVAL;
+		rstream_pep = container_of(fid, struct rstream_pep,
+			util_pep.pep_fid.fid);
+		ret = fi_control(&rstream_pep->pep_fd->fid, command, arg);
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+
+	return ret;
+}
+
+static int rstream_pep_close(fid_t fid)
+{
+	struct rstream_pep *rstream_pep =
+		container_of(fid, struct rstream_pep, util_pep.pep_fid.fid);
+	int ret;
+
+	ret = fi_close(&rstream_pep->pep_fd->fid);
+	if (ret)
+		return ret;
+
+	ofi_pep_close(&rstream_pep->util_pep);
+	free(rstream_pep);
+
+	return ret;
+}
+
+static struct fi_ops rstream_pep_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = rstream_pep_close,
+	.bind = rstream_pep_bind,
+	.control = rstream_pep_ctrl,
+	.ops_open = fi_no_ops_open,
+};
+
+int rstream_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
+	struct fid_pep **pep, void *context)
+{
+	int ret;
+	struct rstream_fabric *rstream_fabric = container_of(fabric,
+		struct rstream_fabric, util_fabric.fabric_fid);
+	struct rstream_pep *rstream_pep;
+
+	rstream_pep = calloc(1, sizeof(*rstream_pep));
+	if (!rstream_pep)
+		return -FI_ENOMEM;
+
+	rstream_info_to_core(FI_VERSION(1, 7), NULL, info);
+
+	ret = fi_passive_ep(rstream_fabric->msg_fabric, info,
+		&rstream_pep->pep_fd, NULL);
+	if (ret)
+		goto err1;
+
+	*pep = &rstream_pep->util_pep.pep_fid;
+	(*pep)->fid.fclass = FI_CLASS_PEP;
+	(*pep)->fid.ops = &rstream_pep_fi_ops;
+	(*pep)->ops = &rstream_ops_ep;
+	(*pep)->cm = &rstream_ops_pep_cm;
+
+	return 0;
+
+err1:
+	free(rstream_pep);
+	return ret;
+}
+
+void rstream_process_cm_event(struct rstream_ep *ep, void *cm_data)
+{
+	assert(ep && cm_data);
+
+	int i;
+	struct rstream_cm_data *rcv_data = (struct rstream_cm_data *)cm_data;
+
+	assert(rcv_data->version == RSTREAM_RSOCKETV2);
+
+	ep->qp_win.target_rx_credits = ntohs(rcv_data->max_rx_credits);
+	ep->qp_win.max_target_rx_credits = ep->qp_win.target_rx_credits;
+	ep->remote_data.rkey = ntohll(rcv_data->rkey);
+	ep->remote_data.mr.data_start = (void *)ntohll(rcv_data->base_addr);
+	ep->remote_data.mr.size = ntohl(rcv_data->rmr_size);
+	ep->remote_data.mr.avail_size = ep->remote_data.mr.size;
+
+	for(i = 0; i < ep->qp_win.max_rx_credits; i++) {
+		rstream_post_cq_data_recv(ep, NULL);
+	}
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_eq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_eq.c
new file mode 100644
index 000000000..8aee31452
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_eq.c
@@ -0,0 +1,234 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rstream.h"
+
+static int rstream_eq_events(uint32_t *event, struct fi_eq_cm_entry *cm_entry,
+	struct fi_eq_cm_entry *usr_cm_entry, struct rstream_eq *rstream_eq)
+{
+	int ret = 0;
+
+	if (*event == FI_CONNREQ) {
+	/* have to store to transfer to ep during FI_CONNECT */
+		if (cm_entry->info) {
+			usr_cm_entry->info = cm_entry->info;
+			rstream_set_info(usr_cm_entry->info);
+		}
+	} else if (*event == FI_CONNECTED) {
+		struct rstream_ep *rstream_ep = NULL;
+		void *itr = rbtFind(rstream_eq->ep_map, cm_entry->fid);
+		assert(itr);
+		rbtKeyValue(rstream_eq->ep_map, itr,
+			(void **) &cm_entry->fid, (void **) &rstream_ep);
+		rstream_process_cm_event(rstream_ep, cm_entry->data);
+		usr_cm_entry->fid = &rstream_ep->util_ep.ep_fid.fid;
+	} else {
+		ret = -FI_ENODATA;
+	}
+	rstream_eq->prev_cm_state = *event;
+	return ret;
+}
+
+static ssize_t rstream_read(struct fid_eq *eq, uint32_t *event,
+	void *buf, size_t len, uint64_t flags)
+{
+	uint32_t rlen = sizeof(struct fi_eq_cm_entry);
+	assert(len == rlen && event);
+	struct fi_eq_cm_entry *usr_cm_entry = (struct fi_eq_cm_entry *) buf;
+	ssize_t ret;
+	struct fi_eq_cm_entry *cm_entry = NULL;
+
+	struct rstream_eq *rstream_eq = container_of(eq,
+		struct rstream_eq, util_eq.eq_fid);
+
+	cm_entry = rstream_eq->cm_entry;
+	assert(cm_entry);
+
+	if (rstream_eq->prev_cm_state != FI_CONNREQ) {
+		rlen = rlen + rstream_eq->cm_data_len;
+	}
+
+	ret = fi_eq_read(rstream_eq->eq_fd, event, cm_entry, rlen, flags);
+	if (ret == rlen) {
+		ret = rstream_eq_events(event, cm_entry, usr_cm_entry, rstream_eq);
+		if (ret)
+			return ret;
+	} else {
+		return ret;
+	}
+
+	return len;
+}
+
+static ssize_t rstream_readerr(struct fid_eq *eq, struct fi_eq_err_entry *buf,
+	uint64_t flags)
+{
+	struct rstream_eq *rstream_eq = container_of(eq,
+		struct rstream_eq, util_eq.eq_fid);
+
+	return fi_eq_readerr(rstream_eq->eq_fd, buf, flags);
+}
+
+static ssize_t rstream_sread(struct fid_eq *eq, uint32_t *event,
+	void *buf, size_t len, int timeout, uint64_t flags)
+{
+	uint32_t rlen = sizeof(struct fi_eq_cm_entry);
+	assert(len == rlen && event);
+	struct fi_eq_cm_entry *usr_cm_entry = (struct fi_eq_cm_entry *) buf;
+	ssize_t ret;
+	struct fi_eq_cm_entry *cm_entry = NULL;
+
+	struct rstream_eq *rstream_eq = container_of(eq,
+		struct rstream_eq, util_eq.eq_fid);
+
+	cm_entry = rstream_eq->cm_entry;
+	assert(cm_entry);
+
+	if (rstream_eq->prev_cm_state != FI_CONNREQ) {
+		rlen = rlen + rstream_eq->cm_data_len;
+	}
+
+	ret = fi_eq_sread(rstream_eq->eq_fd, event, cm_entry, rlen, timeout,
+		flags);
+	if (ret == rlen) {
+		ret = rstream_eq_events(event, cm_entry, usr_cm_entry, rstream_eq);
+		if (ret)
+			return ret;
+	} else {
+		return ret;
+	}
+
+	return len;
+}
+
+static const char *rstream_strerror(struct fid_eq *eq, int prov_errno,
+	const void *err_data, char *buf, size_t len)
+{
+	struct rstream_eq *rstream_eq = container_of(eq, struct rstream_eq,
+		util_eq.eq_fid);
+
+	return fi_eq_strerror(rstream_eq->eq_fd, prov_errno, err_data, buf, len);
+}
+
+static int rstream_eq_control(fid_t fid, int command, void *arg)
+{
+	struct rstream_eq *rstream_eq = container_of(fid, struct rstream_eq,
+		util_eq.eq_fid.fid);
+	int ret;
+
+	switch (command) {
+	case FI_GETWAIT:
+		ret = fi_control(&rstream_eq->eq_fd->fid, FI_GETWAIT, arg);
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+	return ret;
+}
+
+static int rstream_eq_close(fid_t fid)
+{
+	struct rstream_eq *rstream_eq =
+		container_of(fid, struct rstream_eq, util_eq.eq_fid.fid);
+	int ret;
+
+	ret = fi_close(&rstream_eq->eq_fd->fid);
+	if (ret)
+		return ret;
+
+	free(rstream_eq->cm_entry);
+	free(rstream_eq);
+	return ret;
+}
+
+static struct fi_ops_eq rstream_ops_eq = {
+	.size = sizeof(struct fi_ops_eq),
+	.read = rstream_read,
+	.readerr = rstream_readerr,
+	.write = fi_no_eq_write,
+	.sread = rstream_sread,
+	.strerror = rstream_strerror,
+};
+
+static struct fi_ops rstream_fid_ops_eq = {
+	.size = sizeof(struct fi_ops),
+	.close = rstream_eq_close,
+	.bind = fi_no_bind,
+	.control = rstream_eq_control,
+	.ops_open = fi_no_ops_open,
+};
+
+/* assumes uint64_t keys */
+static int compare_mr_keys(void *key1, void *key2)
+{
+	uint64_t k1 = *((uint64_t *) key1);
+	uint64_t k2 = *((uint64_t *) key2);
+
+	return (k1 < k2) ? -1 : (k1 > k2);
+}
+
+int rstream_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
+	struct fid_eq **eq, void *context)
+{
+	struct rstream_fabric *rstream_fabric = NULL;
+	struct rstream_eq *rstream_eq;
+	int ret;
+
+	rstream_eq = calloc(1, sizeof(*rstream_eq));
+	if (!rstream_eq)
+		return -FI_ENOMEM;
+
+	rstream_fabric = container_of(fabric, struct rstream_fabric,
+		util_fabric.fabric_fid);
+
+	ret = fi_eq_open(rstream_fabric->msg_fabric, attr, &rstream_eq->eq_fd,
+		NULL);
+	if (ret)
+		goto err1;
+
+	(*eq) = &rstream_eq->util_eq.eq_fid;
+	(*eq)->fid.fclass = FI_CLASS_EQ;
+	(*eq)->fid.context = context;
+	(*eq)->ops = &rstream_ops_eq;
+	(*eq)->fid.ops = &rstream_fid_ops_eq;
+	rstream_eq->cm_data_len = sizeof(struct rstream_cm_data);
+	rstream_eq->cm_entry = calloc(1, sizeof(struct fi_eq_cm_entry) +
+		rstream_eq->cm_data_len);
+	rstream_eq->ep_map = rbtNew(compare_mr_keys);
+	rstream_eq->prev_cm_state = FI_NOTIFY;
+
+	return ret;
+err1:
+	free(rstream_eq);
+
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_fabric.c
new file mode 100644
index 000000000..632ae6cd8
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_fabric.c
@@ -0,0 +1,144 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rstream.h"
+
+
+static int rstream_fabric_close(fid_t fid)
+{
+	struct rstream_fabric *rstream_fabric =
+		container_of(fid, struct rstream_fabric,
+		util_fabric.fabric_fid.fid);
+	int ret;
+
+	ret = fi_close(&rstream_fabric->msg_fabric->fid);
+	if (ret)
+		return ret;
+
+	ret = ofi_fabric_close(&rstream_fabric->util_fabric);
+	if (ret)
+		return ret;
+
+	free(rstream_fabric);
+	return 0;
+}
+
+static int rstream_control(struct fid *fid, int command, void *arg)
+{
+	return -FI_ENOSYS;
+}
+
+int rstream_trywait(struct fid_fabric *fabric, struct fid **fids, int count)
+{
+	int ret;
+	struct rstream_ep *rstream_ep;
+	struct rstream_fabric *rstream_fabric;
+	int num_fids = 1;
+	struct fid *rstream_fids[num_fids];
+
+	if (count != num_fids)
+		return -FI_ENOSYS;
+
+	if (fids[0]->fclass == FI_CLASS_EP) {
+		rstream_ep = container_of(fids[0], struct rstream_ep,
+			util_ep.ep_fid.fid);
+		rstream_fabric = container_of(fabric, struct rstream_fabric,
+			util_fabric.fabric_fid);
+		rstream_fids[0] = &rstream_ep->cq->fid;
+		ret = fi_trywait(rstream_fabric->msg_fabric, rstream_fids,
+			num_fids);
+		return ret;
+	}
+
+	return -FI_EINVAL;
+}
+
+static struct fi_ops rstream_fabric_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = rstream_fabric_close,
+	.bind = fi_no_bind,
+	.control = rstream_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static struct fi_ops_fabric rstream_fabric_ops = {
+	.size = sizeof(struct fi_ops_fabric),
+	.domain = rstream_domain_open,
+	.passive_ep = rstream_passive_ep,
+	.eq_open = rstream_eq_open,
+	.wait_open = fi_no_wait_open,
+	.trywait = rstream_trywait
+};
+
+int rstream_fabric_open(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
+			   void *context)
+{
+	struct rstream_fabric *rstream_fabric;
+	int ret;
+	struct fi_info *info = NULL;
+
+	rstream_fabric = calloc(1, sizeof(*rstream_fabric));
+	if (!rstream_fabric)
+		return -FI_ENOMEM;
+
+	ret = ofi_fabric_init(&rstream_prov, &rstream_fabric_attr, attr,
+			&rstream_fabric->util_fabric, context);
+	if (ret)
+		goto err1;
+
+	ret = ofi_get_core_info_fabric(&rstream_prov, attr, &info);
+	if (ret) {
+		FI_WARN(&rstream_prov, FI_LOG_FABRIC, "core info failed\n");
+		ret = -FI_EINVAL;
+		goto err1;
+	}
+
+	ret = fi_fabric(info->fabric_attr, &rstream_fabric->msg_fabric, context);
+	if (ret) {
+		FI_WARN(&rstream_prov, FI_LOG_FABRIC, "fi_fabric failed\n");
+		ret = -FI_EINVAL;
+		goto err1;
+	}
+
+	*fabric = &rstream_fabric->util_fabric.fabric_fid;
+	(*fabric)->fid.ops = &rstream_fabric_fi_ops;
+	(*fabric)->ops = &rstream_fabric_ops;
+
+	fi_freeinfo(info);
+	return 0;
+err1:
+	free(rstream_fabric);
+	if (info)
+		fi_freeinfo(info);
+
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_init.c
new file mode 100644
index 000000000..08cfe59d3
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_init.c
@@ -0,0 +1,181 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rstream.h"
+#include <sys/types.h>
+#include <sys/socket.h>
+#include <netdb.h>
+
+
+static void rstream_iwarp_settings(struct fi_info *core_info)
+{
+	core_info->ep_attr->max_msg_size = 2147483647;
+	core_info->domain_attr->cq_data_size = 0;
+	core_info->domain_attr->mr_cnt = 2289662;
+	core_info->mode = FI_CONTEXT;
+}
+
+static void rstream_default_settings(struct fi_info *core_info)
+{
+	core_info->mode = FI_RX_CQ_DATA | FI_CONTEXT;
+	core_info->rx_attr->mode = FI_RX_CQ_DATA;
+}
+
+int rstream_info_to_core(uint32_t version, const struct fi_info *irstream_info,
+	struct fi_info *core_info)
+{
+	core_info->ep_attr->type = FI_EP_MSG;
+	core_info->ep_attr->protocol = FI_PROTO_UNSPEC;
+	core_info->caps = FI_RMA | FI_MSG;
+	core_info->domain_attr->caps = FI_LOCAL_COMM | FI_REMOTE_COMM;
+	core_info->domain_attr->mr_mode = FI_MR_LOCAL | OFI_MR_BASIC_MAP;
+	core_info->tx_attr->op_flags = FI_COMPLETION;
+	core_info->rx_attr->op_flags = FI_COMPLETION;
+	core_info->fabric_attr->api_version =  FI_VERSION(1, 7);
+	core_info->fabric_attr->prov_version = FI_VERSION(1, 0);
+	(RSTREAM_USING_IWARP) ? rstream_iwarp_settings(core_info):
+		rstream_default_settings(core_info);
+
+	return 0;
+}
+
+static void update_rstream_info(const struct fi_info *core_info)
+{
+	rstream_info.tx_attr->iov_limit = core_info->tx_attr->iov_limit;
+	rstream_info.rx_attr->iov_limit = core_info->rx_attr->iov_limit;
+	rstream_info.tx_attr->size = core_info->tx_attr->size;
+	rstream_info.rx_attr->size = core_info->rx_attr->size;
+	rstream_info.domain_attr->max_ep_rx_ctx =
+		core_info->domain_attr->max_ep_rx_ctx;
+	rstream_info.domain_attr->max_ep_srx_ctx =
+		core_info->domain_attr->max_ep_srx_ctx;
+	rstream_info.ep_attr->max_msg_size =
+		core_info->ep_attr->max_msg_size;
+	rstream_info.rx_attr->iov_limit = core_info->rx_attr->iov_limit;
+	rstream_info.domain_attr->cq_data_size =
+		core_info->domain_attr->cq_data_size;
+	rstream_info.domain_attr->cq_cnt = core_info->domain_attr->cq_cnt;
+	rstream_info.domain_attr->ep_cnt = core_info->domain_attr->ep_cnt;
+	rstream_info.domain_attr->max_err_data =
+		core_info->domain_attr->max_err_data;
+}
+
+int rstream_info_to_rstream(uint32_t version, const struct fi_info *core_info,
+	struct fi_info *info)
+{
+	info->caps = RSTREAM_CAPS;
+	info->mode = 0;
+
+	*info->tx_attr = *rstream_info.tx_attr;
+	*info->rx_attr = *rstream_info.rx_attr;
+	*info->domain_attr = *rstream_info.domain_attr;
+	*info->ep_attr = *rstream_info.ep_attr;
+	info->fabric_attr->api_version = FI_VERSION(1, 7);
+	info->fabric_attr->prov_version = FI_VERSION(1, 0);
+	update_rstream_info(core_info);
+
+	return 0;
+}
+
+static int rstream_getinfo(uint32_t version, const char *node,
+	const char *service, uint64_t flags, const struct fi_info *hints,
+	struct fi_info **info)
+{
+	struct fi_info *cur;
+	struct addrinfo *ai;
+	uint16_t port_save = 0;
+	int ret;
+
+	if (!info)
+		return -FI_EINVAL;
+
+	if (hints && hints->ep_attr->protocol == FI_PROTO_IWARP) {
+		rstream_info.ep_attr->protocol = FI_PROTO_IWARP;
+		rstream_info.tx_attr->iov_limit = 3;
+		rstream_info.rx_attr->iov_limit = 3;
+		rstream_info.domain_attr->max_ep_srx_ctx = 0;
+	}
+
+	/* Avoid getting wild card address from MSG provider */
+	if (ofi_is_wildcard_listen_addr(node, service, flags, hints)) {
+		if (service) {
+			ret = getaddrinfo(NULL, service, NULL, &ai);
+			if (ret) {
+				FI_WARN(&rstream_prov, FI_LOG_CORE,
+					"Unable to getaddrinfo\n");
+				return ret;
+			}
+			port_save = ofi_addr_get_port(ai->ai_addr);
+			freeaddrinfo(ai);
+			service = NULL;
+		}
+	}
+
+	ret = ofix_getinfo(version, node, service, flags, &rstream_util_prov,
+		hints, rstream_info_to_core, rstream_info_to_rstream, info);
+	if (ret)
+		return ret;
+
+	if (port_save) {
+		for (cur = *info; cur; cur = cur->next) {
+			assert(cur->src_addr);
+			ofi_addr_set_port(cur->src_addr, port_save);
+		}
+	}
+
+	return ret;
+}
+
+static void rstream_fini(void)
+{
+	/* yawn */
+}
+
+struct fi_provider rstream_prov = {
+	.name = OFI_UTIL_PREFIX "rstream",
+	.version = FI_VERSION(1 ,0),
+	.fi_version = FI_VERSION(1, 7),
+	.getinfo = rstream_getinfo,
+	.fabric = rstream_fabric_open,
+	.cleanup = rstream_fini
+};
+
+struct util_prov rstream_util_prov = {
+	.prov = &rstream_prov,
+	.info = &rstream_info,
+	.flags = 0,
+};
+
+RSTREAM_INI
+{
+	return &rstream_prov;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_msg.c
new file mode 100644
index 000000000..9b5451c2e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rstream/src/rstream_msg.c
@@ -0,0 +1,742 @@
+/*
+ * Copyright (c) 2017-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rstream.h"
+#include <math.h>
+#include <sys/time.h>
+
+
+ssize_t rstream_process_cq(struct rstream_ep *ep, enum rstream_msg_type type);
+
+static uint32_t rstream_cq_data_get_len(uint32_t cq_data)
+{
+	return (cq_data & RSTREAM_MR_LEN_MASK);
+}
+
+static uint32_t rstream_cq_data_set(struct rstream_cq_data cq_data)
+{
+	uint32_t credits = cq_data.num_completions;
+
+	assert(cq_data.num_completions < RSTREAM_CREDITS_MAX);
+	assert(cq_data.total_len < RSTREAM_MR_MAX);
+
+	credits = credits << RSTREAM_CREDIT_OFFSET;
+	return credits | cq_data.total_len;
+}
+
+static uint16_t rstream_cq_data_get_credits(uint32_t cq_data)
+{
+	uint32_t credits = cq_data & RSTREAM_CREDIT_MASK;
+
+	credits = (credits >> RSTREAM_CREDIT_OFFSET);
+	assert(credits < RSTREAM_CREDITS_MAX);
+
+	return credits;
+}
+
+static uint32_t rstream_iwarp_cq_data_is_msg(uint32_t cq_data) {
+	return cq_data & RSTREAM_IWARP_MSG_BIT;
+}
+
+
+static uint32_t rstream_iwarp_cq_data_set_msg_len(uint32_t msg_len)
+{
+	assert(msg_len < RSTREAM_IWARP_IMM_MSG_LEN);
+
+	uint32_t cq_data = msg_len;
+
+	return cq_data | RSTREAM_IWARP_MSG_BIT;
+}
+
+static uint32_t rstream_iwarp_cq_data_get_msg_len(uint32_t cq_data)
+{
+	uint32_t msg_len = cq_data & RSTREAM_IWARP_MSG_BIT_MASK;
+
+	assert(msg_len < RSTREAM_IWARP_IMM_MSG_LEN);
+
+	return msg_len;
+}
+
+static char *rstream_get_next_recv_buffer(struct rstream_ep *ep)
+{
+	char *base_ptr = (char *)ep->local_mr.tx.data_start +
+		ep->local_mr.tx.size;
+	uint64_t *offset = &ep->local_mr.recv_buffer_offset;
+	const uint32_t full_size = RSTREAM_IWARP_DATA_SIZE *
+		ep->qp_win.max_rx_credits;
+	char *buffer = base_ptr + *offset;
+
+	assert((void *)buffer < ep->local_mr.rx.data_start);
+	*offset = (*offset + RSTREAM_IWARP_DATA_SIZE) % full_size;
+
+	return buffer;
+}
+
+/*assuming rx_ctxs are always fully used */
+static struct fi_context *rstream_get_rx_ctx(struct rstream_ep *ep)
+{
+	struct fi_context *ctx;
+
+	if (ep->rx_ctx_index == ep->qp_win.max_rx_credits)
+		return NULL;
+
+	ctx = &ep->rx_ctxs[ep->rx_ctx_index];
+	ep->rx_ctx_index = ep->rx_ctx_index + 1;
+
+	return ctx;
+}
+
+static struct fi_context *rstream_get_tx_ctx(struct rstream_ep *ep, int len)
+{
+	struct rstream_tx_ctx_fs *fs = ep->tx_ctxs;
+	struct rstream_ctx_data *rtn_ctx = freestack_pop(fs);
+
+	if (!rtn_ctx)
+		return NULL;
+
+	rtn_ctx->len = len;
+	return &rtn_ctx->ctx;
+}
+
+static int rstream_return_tx_ctx(struct fi_context *ctx_ptr,
+	struct rstream_ep *ep)
+{
+	int len;
+	struct rstream_tx_ctx_fs *fs = ep->tx_ctxs;
+
+	struct rstream_ctx_data *ctx_data = (struct rstream_ctx_data *)ctx_ptr;
+	len = ctx_data->len;
+	freestack_push(fs, ctx_data);
+
+	return len;
+}
+
+static ssize_t rstream_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
+	fi_addr_t dest_addr)
+{
+	return -FI_ENOSYS;
+}
+
+static ssize_t rstream_print_cq_error(struct fid_cq *cq)
+{
+	ssize_t ret;
+	struct fi_cq_err_entry cq_entry = {0};
+	const char *errmsg;
+
+	ret = fi_cq_readerr(cq, &cq_entry, 0);
+	if (cq_entry.err == FI_ENOMSG) {
+		ret = FI_ENOMSG;
+		return ret;
+	}
+
+	errmsg = fi_cq_strerror(cq, cq_entry.prov_errno,
+		cq_entry.err_data, NULL, 0);
+	fprintf(stderr, "CQ error msg: %s\n", errmsg);
+
+	return ret;
+}
+
+static void rstream_update_tx_credits(struct rstream_ep *ep,
+	uint16_t num_completions)
+{
+	assert(num_completions == 1);
+
+	if(ep->qp_win.ctrl_credits < RSTREAM_MAX_CTRL)
+		ep->qp_win.ctrl_credits++;
+	else
+		ep->qp_win.tx_credits++;
+
+	assert(ep->qp_win.tx_credits <= ep->qp_win.max_tx_credits);
+}
+
+static int rstream_timer_completed(struct rstream_timer *timer)
+{
+	if (!timer->poll_time)
+		gettimeofday(&timer->start, NULL);
+
+	gettimeofday(&timer->end, NULL);
+	timer->poll_time = (timer->end.tv_sec - timer->start.tv_sec) * 1000000 +
+		(timer->end.tv_usec - timer->start.tv_usec);
+
+	return (timer->poll_time > RSTREAM_MAX_POLL_TIME);
+}
+
+static int rstream_tx_mr_full(struct rstream_ep *ep)
+{
+	return !(ep->local_mr.tx.avail_size);
+}
+
+static int rstream_target_mr_full(struct rstream_ep *ep)
+{
+	return !(ep->remote_data.mr.avail_size);
+}
+
+static int rstream_tx_full(struct rstream_ep *ep)
+{
+	return (ep->qp_win.tx_credits == 0);
+}
+
+static int rstream_target_rx_full(struct rstream_ep *ep)
+{
+	return ((ep->qp_win.target_rx_credits - RSTREAM_MAX_CTRL) == 0);
+}
+
+static uint32_t rstream_calc_contig_len(struct rstream_mr_seg *mr)
+{
+	if (!mr->avail_size) {
+		assert(mr->start_offset == mr->end_offset);
+		return 0;
+	} else if (mr->start_offset < mr->end_offset) {
+		return (mr->end_offset - mr->start_offset);
+	} else {
+		return (mr->size - mr->start_offset);
+	}
+}
+
+static uint32_t rstream_alloc_contig_len_available(struct rstream_mr_seg *mr,
+	char **data_addr, uint32_t req_len)
+{
+	uint32_t len_available = rstream_calc_contig_len(mr);
+	uint32_t len;
+
+	*data_addr = (char *)mr->data_start;
+	assert(len_available <= mr->avail_size);
+
+	if (!len_available)
+		return 0;
+
+	*data_addr = *data_addr + mr->start_offset;
+	len = (len_available <	req_len) ? len_available : req_len;
+	assert(mr->avail_size >= len);
+	mr->avail_size = mr->avail_size - len;
+	mr->start_offset = (mr->start_offset + len) % mr->size;
+
+	return len;
+}
+
+static void rstream_free_contig_len(struct rstream_mr_seg *mr, uint32_t len)
+{
+	assert((mr->avail_size + len) <= mr->size);
+	mr->avail_size = mr->avail_size + len;
+	mr->end_offset = (mr->end_offset + len) % mr->size;
+}
+
+static ssize_t rstream_send_ctrl_msg(struct rstream_ep *ep, uint32_t cq_data)
+{
+	ssize_t ret = 0;
+	struct fi_msg msg;
+
+	if (!ep->qp_win.ctrl_credits || (ep->qp_win.target_rx_credits == 0)) {
+		ret = -FI_EAGAIN;
+		goto out;
+	}
+
+	if (RSTREAM_USING_IWARP) {
+		ret = fi_inject(ep->ep_fd, &cq_data, RSTREAM_IWARP_DATA_SIZE, 0);
+		if (ret != 0)
+			goto out;
+	} else {
+		msg.msg_iov = NULL;
+		msg.desc = NULL;
+		msg.iov_count = 0;
+		msg.context = rstream_get_tx_ctx(ep, 0);
+		msg.data = cq_data;
+
+		ret = fi_sendmsg(ep->ep_fd, &msg, FI_REMOTE_CQ_DATA);
+		if (ret != 0)
+			goto out;
+
+		if (ep->qp_win.tx_credits > 0)
+			ep->qp_win.tx_credits--;
+		else
+			ep->qp_win.ctrl_credits--;
+	}
+
+	assert(ep->qp_win.target_rx_credits > 0);
+	ep->qp_win.target_rx_credits--;
+
+out:
+	return ret;
+}
+
+/* accumulate data in tx_cq exhaustion case */
+static ssize_t rstream_update_target(struct rstream_ep *ep,
+	uint16_t num_completions, uint32_t len)
+{
+	uint32_t cq_data;
+	ssize_t ret = 0;
+
+	ep->rx_cq_data.num_completions =
+		ep->rx_cq_data.num_completions + num_completions;
+	ep->rx_cq_data.total_len = ep->rx_cq_data.total_len + len;
+
+	if ((ep->rx_cq_data.num_completions >= ep->qp_win.max_rx_credits / 2) ||
+		(ep->rx_cq_data.total_len >= ep->local_mr.rx.size / 2)) {
+
+		cq_data = rstream_cq_data_set(ep->rx_cq_data);
+
+		ret = rstream_send_ctrl_msg(ep, cq_data);
+		if (ret == 0) {
+			FI_DBG(&rstream_prov, FI_LOG_EP_CTRL,
+				"ctrl msg update %u = completions %u = len \n",
+				ep->rx_cq_data.num_completions,
+				ep->rx_cq_data.total_len);
+			ep->rx_cq_data.num_completions = 0;
+			ep->rx_cq_data.total_len = 0;
+		}
+	}
+
+	return ret;
+}
+
+ssize_t rstream_process_rx_cq_data(struct rstream_ep *ep,
+	const struct fi_cq_data_entry *cq_entry)
+{
+	uint16_t recvd_credits;
+	uint32_t recvd_len;
+
+	if (cq_entry->data != 0) {
+		recvd_credits = rstream_cq_data_get_credits(cq_entry->data);
+		recvd_len = rstream_cq_data_get_len(cq_entry->data);
+
+		ep->qp_win.target_rx_credits += recvd_credits;
+		assert(ep->qp_win.target_rx_credits <=
+			ep->qp_win.max_target_rx_credits);
+
+		rstream_free_contig_len(&ep->remote_data.mr, recvd_len);
+		FI_DBG(&rstream_prov, FI_LOG_EP_CTRL,
+			"recvd: ctrl msg %u = completions %u = len \n",
+			recvd_credits, recvd_len);
+	} else {
+		rstream_free_contig_len(&ep->local_mr.rx, cq_entry->len);
+	}
+
+	return rstream_post_cq_data_recv(ep, cq_entry);
+}
+
+static void format_iwarp_cq_data(struct rstream_ep *ep,
+	struct fi_cq_data_entry *cq_entry)
+{
+	uint32_t cq_data;
+
+	cq_entry->buf = rstream_get_next_recv_buffer(ep);
+	cq_data = *((uint32_t *)cq_entry->buf);
+
+	if(rstream_iwarp_cq_data_is_msg(cq_data)) {
+		cq_entry->data = 0;
+		cq_entry->len = rstream_iwarp_cq_data_get_msg_len(cq_data);
+	} else {
+		cq_entry->data = cq_data;
+		cq_entry->len = 0;
+	}
+}
+
+static enum rstream_msg_type rstream_cqe_msg_type(struct rstream_ep *ep,
+	struct fi_cq_data_entry *cq_entry)
+{
+	enum rstream_msg_type type = RSTREAM_MSG_UNKNOWN;
+
+	if (cq_entry->flags & FI_REMOTE_WRITE || cq_entry->flags & FI_RECV ||
+		cq_entry->flags & FI_REMOTE_CQ_DATA) {
+		if (RSTREAM_USING_IWARP)
+			format_iwarp_cq_data(ep, cq_entry);
+
+		if (cq_entry->data) {
+			type = RSTREAM_CTRL_MSG;
+		} else {
+			type = RSTREAM_RX_MSG_COMP;
+		}
+	} else if (cq_entry->flags & FI_WRITE || cq_entry->flags & FI_SEND) {
+		type = RSTREAM_TX_MSG_COMP;
+	}
+
+	return type;
+}
+
+static ssize_t rstream_check_cq(struct rstream_ep *ep,
+	struct fi_cq_data_entry *completion_entry)
+{
+	const int max_num = 1;
+	ssize_t ret;
+
+	ret = fi_cq_read(ep->cq, completion_entry, max_num);
+	if (ret < 0 && ret != -FI_EAGAIN) {
+		if (ret == -FI_EAVAIL) {
+			ret = rstream_print_cq_error(ep->cq);
+			fprintf(stderr, "error from %s:%d\n", __FILE__, __LINE__);
+			return ret;
+		}
+	}
+	assert(ret == -FI_EAGAIN || ret == max_num);
+
+	return ret;
+}
+
+ssize_t rstream_process_cq(struct rstream_ep *ep, enum rstream_msg_type type)
+{
+	struct fi_cq_data_entry cq_entry;
+	ssize_t ret, data_ret;
+	ssize_t found_msg_type = 0;
+	uint16_t rx_completions = 0;
+	struct rstream_timer timer = {.poll_time = 0};
+	enum rstream_msg_type comp_type;
+	int len;
+
+	fastlock_acquire(&ep->cq_lock);
+	do {
+		ret = rstream_check_cq(ep, &cq_entry);
+		if (ret == 1) {
+			comp_type = rstream_cqe_msg_type(ep, &cq_entry);
+
+			if (comp_type == type)
+				found_msg_type++;
+
+			if (comp_type == RSTREAM_CTRL_MSG ||
+				comp_type == RSTREAM_RX_MSG_COMP) {
+				data_ret = rstream_process_rx_cq_data(ep, &cq_entry);
+				if (data_ret) {
+					fprintf(stderr, "error from %s:%d\n",
+						__FILE__, __LINE__);
+					ret = data_ret;
+					goto out;
+				}
+				rx_completions++;
+			} else if (comp_type == RSTREAM_TX_MSG_COMP) {
+				len = rstream_return_tx_ctx(cq_entry.op_context, ep);
+				rstream_update_tx_credits(ep, ret);
+				rstream_free_contig_len(&ep->local_mr.tx, len);
+			} else {
+				ret = -FI_ENOMSG;
+				goto out;
+			}
+		} else if (ret != -FI_EAGAIN) {
+			goto out;
+		}
+	} while ((ret == -FI_EAGAIN && !rstream_timer_completed(&timer) &&
+		!found_msg_type) || (found_msg_type && ret > 0));
+
+	ret = rstream_update_target(ep, rx_completions, 0);
+	fastlock_release(&ep->cq_lock);
+	if (ret)
+		return ret;
+
+	if (found_msg_type)
+		return found_msg_type;
+	else
+		return -FI_EAGAIN;
+out:
+	fastlock_release(&ep->cq_lock);
+	return ret;
+}
+
+static uint32_t get_send_addrs_and_len(struct rstream_ep *ep, char **tx_addr,
+	char **dest_addr, uint32_t requested_len)
+{
+	uint32_t available_len = 0;
+
+	requested_len = MIN(MIN(requested_len,
+		rstream_calc_contig_len(&ep->local_mr.tx)),
+		rstream_calc_contig_len(&ep->remote_data.mr));
+	if (requested_len == 0)
+		return available_len;
+
+	available_len = rstream_alloc_contig_len_available(&ep->local_mr.tx,
+		tx_addr, requested_len);
+	available_len = rstream_alloc_contig_len_available(&ep->remote_data.mr,
+		dest_addr, requested_len);
+
+	return available_len;
+}
+
+static ssize_t rstream_can_send(struct rstream_ep *ep)
+{
+	ssize_t ret;
+
+	if (rstream_tx_mr_full(ep) || rstream_target_mr_full(ep) ||
+		rstream_target_rx_full(ep)) {
+		ret = rstream_process_cq(ep, RSTREAM_CTRL_MSG);
+		if (ret < 0)
+			return ret;
+	}
+
+	if (rstream_tx_full(ep)) {
+		ret = rstream_process_cq(ep, RSTREAM_TX_MSG_COMP);
+		if (ret < 0)
+			return ret;
+	}
+
+	return 0;
+}
+
+static ssize_t rstream_send(struct fid_ep *ep_fid, const void *buf, size_t len,
+	void *desc, fi_addr_t dest_addr, void *context)
+{
+	struct rstream_ep *ep = container_of(ep_fid, struct rstream_ep,
+		util_ep.ep_fid);
+	uint32_t cq_data = 0;
+	ssize_t ret;
+	char *tx_addr = NULL;
+	char *remote_addr = NULL;
+	size_t sent_len = 0;
+	uint32_t curr_avail_len = len;
+	void *ctx;
+
+	fastlock_acquire(&ep->send_lock);
+	do {
+		ret = rstream_can_send(ep);
+		if (ret < 0) {
+			if (ret < 0 && ret != -FI_EAGAIN) {
+				goto err;
+			} else {
+				fastlock_release(&ep->send_lock);
+				return ((sent_len) ? sent_len : ret);
+			}
+		}
+
+		curr_avail_len = get_send_addrs_and_len(ep, &tx_addr,
+			&remote_addr, curr_avail_len);
+		if (curr_avail_len == 0)
+			break;
+
+		memcpy(tx_addr, ((char *)buf + sent_len), curr_avail_len);
+		sent_len = sent_len + curr_avail_len;
+		ctx = rstream_get_tx_ctx(ep, curr_avail_len);
+
+		if (RSTREAM_USING_IWARP) {
+			ret = fi_write(ep->ep_fd, tx_addr, curr_avail_len,
+				ep->local_mr.ldesc, 0, (uint64_t)remote_addr,
+				ep->remote_data.rkey, ctx);
+			ret = rstream_send_ctrl_msg(ep,
+				rstream_iwarp_cq_data_set_msg_len(curr_avail_len));
+		} else {
+			ret = fi_writedata(ep->ep_fd, tx_addr, curr_avail_len,
+				ep->local_mr.ldesc, cq_data, 0, (uint64_t)remote_addr,
+				ep->remote_data.rkey, ctx);
+		}
+		if (ret != 0) {
+			FI_DBG(&rstream_prov, FI_LOG_EP_DATA,
+				"error: fi_write failed: %zd", ret);
+			goto err;
+		}
+		curr_avail_len = len - sent_len;
+
+		if (!RSTREAM_USING_IWARP)
+			ep->qp_win.target_rx_credits--;
+
+		ep->qp_win.tx_credits--;
+
+	} while(curr_avail_len); /* circle buffer rollover requires two loops */
+
+	fastlock_release(&ep->send_lock);
+	return sent_len;
+
+err:
+	fastlock_release(&ep->send_lock);
+	return ret;
+}
+
+static ssize_t rstream_sendv(struct fid_ep *ep_fid, const struct iovec *iov,
+	void **desc, size_t count, fi_addr_t dest_addr, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+static ssize_t rstream_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+	uint64_t flags)
+{
+	int ret;
+	struct rstream_ep *ep = container_of(ep_fid, struct rstream_ep,
+		util_ep.ep_fid);
+
+	if (flags == FI_PEEK) {
+		fastlock_acquire(&ep->send_lock);
+		ret = rstream_can_send(ep);
+		fastlock_release(&ep->send_lock);
+		return ret;
+	} else {
+		return -FI_ENOSYS;
+	}
+}
+
+/* either posting everything at once or reposting after cq completion */
+ssize_t rstream_post_cq_data_recv(struct rstream_ep *ep,
+	const struct fi_cq_data_entry *cq_entry)
+{
+	struct fi_context *context = NULL;
+	struct fi_msg msg;
+	struct iovec imsg;
+	void *buffer;
+	ssize_t ret;
+
+	if (!cq_entry || !cq_entry->op_context)
+		context = rstream_get_rx_ctx(ep);
+	else if (cq_entry && cq_entry->op_context)
+		context = cq_entry->op_context;
+
+	if (RSTREAM_USING_IWARP) {
+		buffer = (cq_entry && cq_entry->buf) ? cq_entry->buf :
+			rstream_get_next_recv_buffer(ep);
+		assert(buffer);
+		imsg.iov_base = buffer;
+		imsg.iov_len = RSTREAM_IWARP_DATA_SIZE;
+		msg.msg_iov = &imsg;
+		msg.desc = &ep->local_mr.ldesc;
+		msg.iov_count = 1;
+		msg.context = context;
+	} else {
+		msg.msg_iov = NULL;
+		msg.desc = NULL;
+		msg.iov_count = 0;
+		msg.context = context;
+	}
+
+	ret = fi_recvmsg(ep->ep_fd, &msg, 0);
+	if (ret != 0)
+		return ret;
+
+	return ret;
+}
+
+static uint32_t rstream_copy_out_chunk(struct rstream_ep *ep, void *buf,
+	uint32_t len_left)
+{
+	char *rx_data_ptr = NULL;
+	uint32_t current_chunk =
+		rstream_alloc_contig_len_available(&ep->local_mr.rx, &rx_data_ptr,
+			len_left);
+
+	if (current_chunk) {
+		memcpy(buf, rx_data_ptr, current_chunk);
+	}
+
+	return current_chunk;
+}
+
+static ssize_t rstream_recv(struct fid_ep *ep_fid, void *buf, size_t len,
+	void *desc, fi_addr_t src_addr, void *context)
+{
+	struct rstream_ep *ep = container_of(ep_fid, struct rstream_ep,
+		util_ep.ep_fid);
+	uint32_t copy_out_len = 0;
+	ssize_t ret;
+
+	fastlock_acquire(&ep->recv_lock);
+
+	copy_out_len = rstream_copy_out_chunk(ep, buf, len);
+
+	if ((len - copy_out_len)) {
+		ret = rstream_process_cq(ep, RSTREAM_RX_MSG_COMP);
+		if(ret < 0 && ret != -FI_EAGAIN) {
+			fastlock_release(&ep->recv_lock);
+			return ret;
+		}
+
+		copy_out_len = copy_out_len + rstream_copy_out_chunk(ep,
+			((char *)buf + copy_out_len), (len - copy_out_len));
+	}
+
+	fastlock_acquire(&ep->send_lock);
+	ret = rstream_update_target(ep, 0, copy_out_len);
+	fastlock_release(&ep->send_lock);
+	fastlock_release(&ep->recv_lock);
+	if(ret < 0 && ret != -FI_EAGAIN) {
+		return ret;
+	}
+
+	if (copy_out_len) {
+		return copy_out_len;
+	}
+
+	return -FI_EAGAIN;
+}
+
+static ssize_t rstream_recvv(struct fid_ep *ep_fid, const struct iovec *iov,
+	void **desc, size_t count, fi_addr_t src_addr, void *context)
+{
+	return -FI_ENOSYS;
+}
+
+/* can't recv if you can't send a ctrl message -- only way to force user
+ * to progress ctrl msg, but...Continue to receive any queued data even
+ * if the remote side has disconnected (TODO) */
+static ssize_t rstream_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+	uint64_t flags)
+{
+	int ret;
+	struct rstream_ep *ep = container_of(ep_fid, struct rstream_ep,
+		util_ep.ep_fid);
+
+	if (flags == FI_PEEK) {
+		fastlock_acquire(&ep->recv_lock);
+		if (!ep->local_mr.rx.avail_size) {
+			ret = rstream_process_cq(ep, RSTREAM_RX_MSG_COMP);
+			if (ret < 0) {
+				fastlock_release(&ep->recv_lock);
+				return ret;
+			}
+		}
+		fastlock_release(&ep->recv_lock);
+
+		fastlock_acquire(&ep->send_lock);
+		if (rstream_target_rx_full(ep)) {
+			ret = rstream_process_cq(ep, RSTREAM_RX_MSG_COMP);
+			if (ret < 0) {
+				fastlock_release(&ep->send_lock);
+				return ret;
+			}
+		}
+
+		if (!ep->qp_win.ctrl_credits) {
+			ret = rstream_process_cq(ep, RSTREAM_TX_MSG_COMP);
+			fastlock_release(&ep->send_lock);
+			return ret;
+		}
+
+		fastlock_release(&ep->send_lock);
+		return 0;
+	} else {
+		return -FI_ENOSYS;
+	}
+}
+
+struct fi_ops_msg rstream_ops_msg = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = rstream_recv,
+	.recvv = rstream_recvv,
+	.recvmsg = rstream_recvmsg,
+	.send = rstream_send,
+	.sendv = rstream_sendv,
+	.sendmsg = rstream_sendmsg,
+	.inject = rstream_inject,
+	.senddata = fi_no_msg_senddata,
+	.injectdata = fi_no_msg_injectdata,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/Makefile.include
index d89d6f01e..0f2600b24 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/Makefile.include
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/Makefile.include
@@ -8,8 +8,12 @@ _rxd_files = \
 	prov/rxd/src/rxd_cq.c		\
 	prov/rxd/src/rxd_cntr.c		\
 	prov/rxd/src/rxd_ep.c		\
+	prov/rxd/src/rxd_msg.c		\
+	prov/rxd/src/rxd_tagged.c	\
 	prov/rxd/src/rxd_rma.c		\
-	prov/rxd/src/rxd.h
+	prov/rxd/src/rxd_atomic.c	\
+	prov/rxd/src/rxd.h		\
+	prov/rxd/src/rxd_proto.h
 
 if HAVE_RXD_DL
 pkglib_LTLIBRARIES += librxd-fi.la
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd.h
index fecb9e54d..edfbe0178 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd.h
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2015-2017 Intel Corporation, Inc.  All rights reserved.
+ * Copyright (c) 2015-2018 Intel Corporation, Inc.  All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -52,6 +52,9 @@
 #include <ofi_rbuf.h>
 #include <ofi_list.h>
 #include <ofi_util.h>
+#include <ofi_tree.h>
+#include <ofi_atomic.h>
+#include "rxd_proto.h"
 
 #ifndef _RXD_H_
 #define _RXD_H_
@@ -59,51 +62,47 @@
 #define RXD_MAJOR_VERSION 	(1)
 #define RXD_MINOR_VERSION 	(0)
 #define RXD_PROTOCOL_VERSION 	(1)
-#define RXD_FI_VERSION 		FI_VERSION(1,6)
 
-#define RXD_IOV_LIMIT		4
-#define RXD_MAX_DGRAM_ADDR	128
+#define RXD_MAX_MTU_SIZE	4096
 
 #define RXD_MAX_TX_BITS 	10
 #define RXD_MAX_RX_BITS 	10
-#define RXD_TX_ID(seq, id)	(((seq) << RXD_MAX_TX_BITS) | id)
-#define RXD_RX_ID(seq, id)	(((seq) << RXD_MAX_RX_BITS) | id)
-#define RXD_TX_IDX_BITS		((1ULL << RXD_MAX_TX_BITS) - 1)
-#define RXD_RX_IDX_BITS		((1ULL << RXD_MAX_RX_BITS) - 1)
+#define RXD_DEFAULT_AV_SIZE	1024
 
 #define RXD_BUF_POOL_ALIGNMENT	16
 #define RXD_TX_POOL_CHUNK_CNT	1024
 #define RXD_RX_POOL_CHUNK_CNT	1024
-
-#define RXD_MAX_RX_CREDITS	16
-#define RXD_MAX_PEER_TX		8
-#define RXD_MAX_UNACKED		128
-
-#define RXD_EP_MAX_UNEXP_PKT	512
-#define RXD_EP_MAX_UNEXP_MSG	128
-
-#define RXD_USE_OP_FLAGS	(1ULL << 61)
-#define RXD_NO_COMPLETION	(1ULL << 62)
-
+#define RXD_MAX_PENDING		128
 #define RXD_MAX_PKT_RETRY	50
 
-extern int rxd_progress_spin_count;
-extern int rxd_reposted_bufs;
+#define RXD_PKT_IN_USE		(1 << 0)
+#define RXD_PKT_ACKED		(1 << 1)
+
+#define RXD_REMOTE_CQ_DATA	(1 << 0)
+#define RXD_NO_TX_COMP		(1 << 1)
+#define RXD_NO_RX_COMP		(1 << 2)
+#define RXD_INJECT		(1 << 3)
+#define RXD_TAG_HDR		(1 << 4)
+#define RXD_INLINE		(1 << 5)
+#define RXD_MULTI_RECV		(1 << 6)
+#define RXD_CANCELLED		(1 << 7)
+
+struct rxd_env {
+	int spin_count;
+	int retry;
+	int max_peers;
+	int max_unacked;
+};
 
+extern struct rxd_env rxd_env;
 extern struct fi_provider rxd_prov;
 extern struct fi_info rxd_info;
 extern struct fi_fabric_attr rxd_fabric_attr;
 extern struct util_prov rxd_util_prov;
+extern struct fi_ops_msg rxd_ops_msg;
+extern struct fi_ops_tagged rxd_ops_tagged;
 extern struct fi_ops_rma rxd_ops_rma;
-
-enum {
-	RXD_TX_CONN = 0,
-	RXD_TX_MSG,
-	RXD_TX_TAG,
-	RXD_TX_WRITE,
-	RXD_TX_READ_REQ,
-	RXD_TX_READ_RSP,
-};
+extern struct fi_ops_atomic rxd_ops_atomic;
 
 struct rxd_fabric {
 	struct util_fabric util_fabric;
@@ -115,16 +114,55 @@ struct rxd_domain {
 	struct fid_domain *dg_domain;
 
 	ssize_t max_mtu_sz;
+	ssize_t max_inline_msg;
+	ssize_t max_inline_rma;
+	ssize_t max_inline_atom;
+	ssize_t max_seg_sz;
 	int mr_mode;
 	struct ofi_mr_map mr_map;//TODO use util_domain mr_map instead
 };
 
+struct rxd_peer {
+	struct dlist_entry entry;
+	fi_addr_t peer_addr;
+	uint64_t tx_seq_no;
+	uint64_t rx_seq_no;
+	uint64_t last_rx_ack;
+	uint64_t last_tx_ack;
+	uint16_t rx_window;//constant at MAX_UNACKED for now
+	uint16_t tx_window;//unused for now, will be used for slow start
+	int retry_cnt;
+
+	uint16_t unacked_cnt;
+	uint8_t active;
+
+	uint16_t curr_rx_id;
+	uint16_t curr_tx_id;
+
+	struct dlist_entry tx_list;
+	struct dlist_entry rx_list;
+	struct dlist_entry rma_rx_list;
+	struct dlist_entry unacked;
+	struct dlist_entry buf_pkts;
+};
+
+struct rxd_addr {
+	fi_addr_t fi_addr;
+	fi_addr_t dg_addr;
+};
+
 struct rxd_av {
 	struct util_av util_av;
 	struct fid_av *dg_av;
+	struct ofi_rbmap rbmap;
+	int fi_addr_idx;
+	int rxd_addr_idx;
 
 	int dg_av_used;
 	size_t dg_addrlen;
+
+	fi_addr_t *fi_addr_table;
+	struct rxd_addr *rxd_addr_table;
 };
 
 struct rxd_cq;
@@ -135,54 +173,38 @@ struct rxd_cq {
 	rxd_cq_write_fn write_fn;
 };
 
-struct rxd_peer {
-	uint64_t		nxt_msg_id;
-	uint64_t		exp_msg_id;
-	uint64_t		conn_data;
-	fi_addr_t		fiaddr;
-
-	enum util_cmap_state	state;
-	uint16_t		active_tx_cnt;
-};
-
 struct rxd_ep {
 	struct util_ep util_ep;
 	struct fid_ep *dg_ep;
 	struct fid_cq *dg_cq;
 
-	struct rxd_peer *peer_info;
-	size_t max_peers;
-
-	int conn_data_set;
-	uint64_t conn_data;
-
 	size_t rx_size;
-	size_t credits;
-//	uint64_t num_out;
-
+	size_t tx_size;
+	size_t tx_prefix_size;
+	size_t rx_prefix_size;
+	uint32_t posted_bufs;
+	size_t min_multi_recv_size;
 	int do_local_mr;
-	struct dlist_entry wait_rx_list;
-	struct dlist_entry unexp_tag_list;
-	struct dlist_entry unexp_msg_list;
-	uint16_t num_unexp_pkt;
-	uint16_t num_unexp_msg;
+	int next_retry;
+	int dg_cq_fd;
+	size_t pending_cnt;
 
 	struct util_buf_pool *tx_pkt_pool;
 	struct util_buf_pool *rx_pkt_pool;
 	struct slist rx_pkt_list;
 
-	struct rxd_tx_entry_fs *tx_entry_fs;
-	struct dlist_entry tx_entry_list;
-
-	struct rxd_rx_entry_fs *rx_entry_fs;
-	struct dlist_entry rx_entry_list;
+	struct util_buf_pool *tx_entry_pool;
+	struct util_buf_pool *rx_entry_pool;
 
-	struct rxd_recv_fs *recv_fs;
-	struct dlist_entry recv_list;
+	struct dlist_entry unexp_list;
+	struct dlist_entry unexp_tag_list;
+	struct dlist_entry rx_list;
+	struct dlist_entry rx_tag_list;
+	struct dlist_entry active_peers;
+	struct dlist_entry rts_sent_list;
+	struct dlist_entry ctrl_pkts;
 
-	struct rxd_trecv_fs *trecv_fs;
-	struct dlist_entry trecv_list;
-	fastlock_t lock;
+	struct rxd_peer peers[];
 };
 
 static inline struct rxd_domain *rxd_ep_domain(struct rxd_ep *ep)
@@ -205,146 +227,130 @@ static inline struct rxd_cq *rxd_ep_rx_cq(struct rxd_ep *ep)
 	return container_of(ep->util_ep.rx_cq, struct rxd_cq, util_cq);
 }
 
-struct rxd_rx_buf {
-	struct fi_context context;
-	struct slist_entry entry;
-	struct rxd_ep *ep;
-	struct fid_mr *mr;
-	char buf[];
-};
+struct rxd_x_entry {
+	fi_addr_t peer;
+	uint16_t tx_id;
+	uint16_t rx_id;
+	uint64_t bytes_done;
+	uint64_t next_seg_no;
+	uint64_t start_seq;
+	uint64_t offset;
+	uint16_t window;
+	uint64_t num_segs;
+	uint32_t op;
+
+	uint32_t flags;
+	uint64_t ignore;
+	uint8_t iov_count;
+	uint8_t res_count;
+
+	struct iovec iov[RXD_IOV_LIMIT];
+	struct iovec res_iov[RXD_IOV_LIMIT];
 
-struct rxd_rx_entry {
-	struct ofi_op_hdr op_hdr;
-	uint32_t exp_seg_no;
-	uint64_t msg_id;
-	uint64_t key;
-	uint64_t done;
-	uint64_t peer;
-	uint16_t credits;
-	uint32_t last_win_seg;
-	fi_addr_t source;
-	struct rxd_peer *peer_info;
-	struct rxd_rx_buf *unexp_buf;
-	uint64_t nack_stamp;
+	struct fi_cq_tagged_entry cq_entry;
+
+	struct rxd_pkt_entry *pkt;
 	struct dlist_entry entry;
+};
 
-	union {
-		struct rxd_recv_entry *recv;
-		struct rxd_trecv_entry *trecv;
+static inline uint32_t rxd_flags(uint64_t fi_flags)
+{
+	uint32_t rxd_flags = 0;
 
-		struct {
-			struct iovec iov[RXD_IOV_LIMIT];
-		} write;
+	if (fi_flags & FI_REMOTE_CQ_DATA)
+		rxd_flags |= RXD_REMOTE_CQ_DATA;
+	if (fi_flags & FI_INJECT)
+		rxd_flags |= RXD_INJECT;
+	if (fi_flags & FI_MULTI_RECV)
+		rxd_flags |= RXD_MULTI_RECV;
 
-		struct {
-			struct rxd_tx_entry *tx_entry;
-		} read_rsp;
-	};
+	return rxd_flags;
+}
 
-	union {
-		struct dlist_entry wait_entry;
-		struct dlist_entry unexp_entry;
-	};
-};
-DECLARE_FREESTACK(struct rxd_rx_entry, rxd_rx_entry_fs);
+#define rxd_ep_rx_flags(rxd_ep) (rxd_flags((rxd_ep)->util_ep.rx_op_flags))
+#define rxd_ep_tx_flags(rxd_ep) (rxd_flags((rxd_ep)->util_ep.tx_op_flags))
 
-struct rxd_tx_entry {
+struct rxd_pkt_entry {
+	struct dlist_entry d_entry;
+	struct slist_entry s_entry;//TODO - keep both or make separate tx/rx pkt structs
+	uint8_t flags;
+	size_t pkt_size;
+	uint64_t timestamp;
+	struct fi_context context;
+	struct fid_mr *mr;
 	fi_addr_t peer;
-	uint64_t msg_id;
-	uint64_t flags;
-	uint64_t rx_key;
-	uint64_t bytes_sent;
-	uint32_t seg_no;
-	uint32_t window;
-	uint64_t retry_time;
-	uint8_t retry_cnt;
-
-	struct dlist_entry entry;
-	struct dlist_entry pkt_list;
-
-	uint8_t op_type;
-	struct ofi_op_hdr op_hdr;
-
-	union {
-		struct {
-			struct fi_msg msg;
-			struct iovec msg_iov[RXD_IOV_LIMIT];
-		} msg;
-
-		struct {
-			struct fi_msg_tagged tmsg;
-			struct iovec msg_iov[RXD_IOV_LIMIT];
-		} tmsg;
-
-		struct {
-			struct fi_msg_rma msg;
-			struct iovec src_iov[RXD_IOV_LIMIT];
-			struct fi_rma_iov dst_iov[RXD_IOV_LIMIT];
-		} write;
-
-		struct {
-			struct fi_msg_rma msg;
-			struct fi_rma_iov src_iov[RXD_IOV_LIMIT];
-			struct iovec dst_iov[RXD_IOV_LIMIT];
-		} read_req;
-
-		struct {
-			uint64_t peer_msg_id;
-			uint8_t iov_count;
-			struct iovec src_iov[RXD_IOV_LIMIT];
-		} read_rsp;
-	};
+	void *pkt;
 };
-DECLARE_FREESTACK(struct rxd_tx_entry, rxd_tx_entry_fs);
 
-struct rxd_recv_entry {
-	struct dlist_entry entry;
-	struct fi_msg msg;
-	uint64_t flags;
-	struct iovec iov[RXD_IOV_LIMIT];
-	void *desc[RXD_IOV_LIMIT];
-};
-DECLARE_FREESTACK(struct rxd_recv_entry, rxd_recv_fs);
+static inline int rxd_pkt_type(struct rxd_pkt_entry *pkt_entry)
+{
+	return ((struct rxd_base_hdr *) (pkt_entry->pkt))->type;
+}
 
-struct rxd_trecv_entry {
-	struct dlist_entry entry;
-	struct fi_msg_tagged msg;
-	uint64_t flags;
-	struct rxd_rx_entry *rx_entry;
-	struct iovec iov[RXD_IOV_LIMIT];
-	void *desc[RXD_IOV_LIMIT];
-};
-DECLARE_FREESTACK(struct rxd_trecv_entry, rxd_trecv_fs);
+static inline struct rxd_base_hdr *rxd_get_base_hdr(struct rxd_pkt_entry *pkt_entry)
+{
+	return &((struct rxd_ack_pkt *) (pkt_entry->pkt))->base_hdr;
+}
 
-struct rxd_pkt_data_start {
-	struct ofi_ctrl_hdr ctrl;
-	struct ofi_op_hdr op;
-	char data[];
-};
+static inline uint64_t rxd_set_pkt_seq(struct rxd_peer *peer,
+				       struct rxd_pkt_entry *pkt_entry)
+{
+	rxd_get_base_hdr(pkt_entry)->seq_no = peer->tx_seq_no++;
 
-struct rxd_pkt_data {
-	struct ofi_ctrl_hdr ctrl;
-	char data[];
-};
+	return rxd_get_base_hdr(pkt_entry)->seq_no;
+}
 
-#define RXD_PKT_FIRST	(1 << 0)
-#define RXD_PKT_LAST	(1 << 1)
-#define RXD_LOCAL_COMP	(1 << 2)
-#define RXD_REMOTE_ACK	(1 << 3)
-#define RXD_NOT_ACKED	RXD_REMOTE_ACK
+static inline struct rxd_ext_hdr *rxd_get_ext_hdr(struct rxd_pkt_entry *pkt_entry)
+{
+	return &((struct rxd_ack_pkt *) (pkt_entry->pkt))->ext_hdr;
+}
 
-struct rxd_pkt_meta {
-	struct fi_context context;
-	struct dlist_entry entry;
-	struct rxd_tx_entry *tx_entry;
-	struct rxd_ep *ep;
-	struct fid_mr *mr;
-	int flags;
+static inline struct rxd_sar_hdr *rxd_get_sar_hdr(struct rxd_pkt_entry *pkt_entry)
+{
+	return (struct rxd_sar_hdr *) ((char *) pkt_entry->pkt +
+		sizeof(struct rxd_base_hdr));
+}
+
+static inline struct rxd_tag_hdr *rxd_get_tag_hdr(struct rxd_pkt_entry *pkt_entry)
+{
+	struct rxd_base_hdr *hdr = rxd_get_base_hdr(pkt_entry);
+	
+	return (struct rxd_tag_hdr *) ((char *) hdr + sizeof(*hdr) +
+		(hdr->flags & RXD_INLINE ? 0 : sizeof(struct rxd_sar_hdr)));
+}
 
-	/* TODO: use iov and remove data copies */
-	char pkt_data[]; /* rxd_pkt_data*, followed by data */
+static inline void rxd_set_tx_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
+{
+	pkt_entry->pkt = (void *) ((char *) pkt_entry +
+			  sizeof(*pkt_entry) + ep->tx_prefix_size);
+}
+
+static inline void rxd_set_rx_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
+{
+	pkt_entry->pkt = (void *) ((char *) pkt_entry +
+			  sizeof(*pkt_entry) + ep->rx_prefix_size);
+}
+
+static inline void *rxd_pkt_start(struct rxd_pkt_entry *pkt_entry)
+{
+	return (void *) ((char *) pkt_entry + sizeof(*pkt_entry));
+}
+
+struct rxd_match_attr {
+	fi_addr_t	peer;
+	uint64_t	tag;
 };
 
+static inline int rxd_match_addr(fi_addr_t addr, fi_addr_t match_addr)
+{
+	return (addr == FI_ADDR_UNSPEC || addr == match_addr);
+}
+
+static inline int rxd_match_tag(uint64_t tag, uint64_t ignore, uint64_t match_tag)
+{
+	return ((tag | ignore ) == (match_tag | ignore));
+}
+
 int rxd_info_to_core(uint32_t version, const struct fi_info *rxd_info,
 		     struct fi_info *core_info);
 int rxd_info_to_rxd(uint32_t version, const struct fi_info *core_info,
@@ -362,59 +368,92 @@ int rxd_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
 		struct fid_cq **cq_fid, void *context);
 int rxd_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
 		  struct fid_cntr **cntr_fid, void *context);
-
+int rxd_query_atomic(struct fid_domain *domain, enum fi_datatype datatype,
+		     enum fi_op op, struct fi_atomic_attr *attr, uint64_t flags);
 
 /* AV sub-functions */
-int rxd_av_insert_dg_addr(struct rxd_av *av, uint64_t hint_index,
-			  const void *addr, fi_addr_t *dg_fiaddr);
-fi_addr_t rxd_av_dg_addr(struct rxd_av *av, fi_addr_t fi_addr);
-fi_addr_t rxd_av_fi_addr(struct rxd_av *av, fi_addr_t dg_fiaddr);
-int rxd_av_dg_reverse_lookup(struct rxd_av *av, uint64_t start_idx,
-			     const void *addr, fi_addr_t *dg_fiaddr);
-
-/* EP sub-functions */
-void rxd_handle_send_comp(struct fi_cq_msg_entry *comp);
-void rxd_handle_recv_comp(struct rxd_ep *ep, struct fi_cq_msg_entry *comp);
-int rxd_ep_repost_buff(struct rxd_rx_buf *rx_buf);
-int rxd_ep_reply_ack(struct rxd_ep *ep, struct ofi_ctrl_hdr *in_ctrl,
-		     uint8_t type, uint16_t seg_size, uint64_t rx_key,
-		     uint64_t source, fi_addr_t dest);
-struct rxd_peer *rxd_ep_getpeer_info(struct rxd_ep *rxd_ep, fi_addr_t addr);
-
-void rxd_ep_check_unexp_msg_list(struct rxd_ep *ep,
-				 struct rxd_recv_entry *recv_entry);
-void rxd_ep_check_unexp_tag_list(struct rxd_ep *ep,
-				 struct rxd_trecv_entry *trecv_entry);
-void rxd_ep_handle_data_msg(struct rxd_ep *ep, struct rxd_peer *peer,
-			    struct rxd_rx_entry *rx_entry,
-			    struct iovec *iov, size_t iov_count,
-			    struct ofi_ctrl_hdr *ctrl, void *data,
-			    struct rxd_rx_buf *rx_buf);
-void rxd_ep_free_acked_pkts(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry,
-			    uint32_t seg_no);
-ssize_t rxd_ep_start_xfer(struct rxd_ep *ep, struct rxd_peer *peer,
-			  uint8_t op, struct rxd_tx_entry *tx_entry);
-ssize_t rxd_ep_connect(struct rxd_ep *ep, struct rxd_peer *peer, fi_addr_t addr);
-int rxd_mr_verify(struct rxd_domain *rxd_domain, ssize_t len,
-		  uintptr_t *io_addr, uint64_t key, uint64_t access);
-
+int rxd_av_insert_dg_addr(struct rxd_av *av, const void *addr,
+			  fi_addr_t *dg_fiaddr, uint64_t flags,
+			  void *context);
+
+/* Pkt resource functions */
+int rxd_ep_post_buf(struct rxd_ep *ep);
+void rxd_release_repost_rx(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry);
+void rxd_ep_send_ack(struct rxd_ep *rxd_ep, fi_addr_t peer);
+struct rxd_pkt_entry *rxd_get_tx_pkt(struct rxd_ep *ep);
+void rxd_release_rx_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt);
+void rxd_release_tx_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt);
+struct rxd_x_entry *rxd_get_tx_entry(struct rxd_ep *ep);
+struct rxd_x_entry *rxd_get_rx_entry(struct rxd_ep *ep);
+void rxd_release_rx_entry(struct rxd_ep *ep, struct rxd_x_entry *x_entry);
+int rxd_ep_retry_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry);
+ssize_t rxd_ep_post_data_pkts(struct rxd_ep *ep, struct rxd_x_entry *tx_entry);
+void rxd_insert_unacked(struct rxd_ep *ep, fi_addr_t peer,
+			struct rxd_pkt_entry *pkt_entry);
+ssize_t rxd_send_rts_if_needed(struct rxd_ep *rxd_ep, fi_addr_t rxd_addr);
+int rxd_ep_send_op(struct rxd_ep *rxd_ep, struct rxd_x_entry *tx_entry,
+		   const struct fi_rma_iov *rma_iov, size_t rma_count,
+		   const struct iovec *comp_iov, size_t comp_count,
+		   enum fi_datatype datatype, enum fi_op atomic_op);
+void rxd_init_data_pkt(struct rxd_ep *ep, struct rxd_x_entry *tx_entry,
+		       struct rxd_pkt_entry *pkt_entry);
+void rxd_unpack_hdrs(size_t pkt_size, struct rxd_base_hdr *base_hdr,
+		     struct rxd_sar_hdr **sar_hdr, struct rxd_tag_hdr **tag_hdr,
+		     struct rxd_data_hdr **data_hdr, struct rxd_rma_hdr **rma_hdr,
+		     struct rxd_atom_hdr **atom_hdr, void **msg, size_t *msg_size);
 
 /* Tx/Rx entry sub-functions */
-struct rxd_tx_entry *rxd_tx_entry_alloc(struct rxd_ep *ep,
-	struct rxd_peer *peer, fi_addr_t addr, uint64_t flags, uint8_t op);
-void rxd_tx_entry_progress(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry);
-void rxd_tx_entry_discard(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry);
-void rxd_tx_entry_free(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry);
-void rxd_tx_entry_done(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry);
-void rxd_set_timeout(struct rxd_tx_entry *tx_entry);
-
-void rxd_tx_pkt_free(struct rxd_pkt_meta *pkt_meta);
-void rxd_rx_entry_free(struct rxd_ep *ep, struct rxd_rx_entry *rx_entry);
-
+struct rxd_x_entry *rxd_tx_entry_init(struct rxd_ep *ep, const struct iovec *iov,
+				      size_t iov_count, const struct iovec *res_iov,
+				      size_t res_count, size_t rma_count,
+				      uint64_t data, uint64_t tag, void *context,
+				      fi_addr_t addr, uint32_t op, uint32_t flags);
+struct rxd_x_entry *rxd_rx_entry_init(struct rxd_ep *ep,
+			const struct iovec *iov, size_t iov_count, uint64_t tag,
+			uint64_t ignore, void *context, fi_addr_t addr,
+			uint32_t op, uint32_t flags);
+void rxd_tx_entry_free(struct rxd_ep *ep, struct rxd_x_entry *tx_entry);
+void rxd_rx_entry_free(struct rxd_ep *ep, struct rxd_x_entry *rx_entry);
+int rxd_get_timeout(uint8_t retry_cnt);
+uint64_t rxd_get_retry_time(uint64_t start, uint8_t retry_cnt);
+
+/* Generic message functions */
+ssize_t rxd_ep_generic_recvmsg(struct rxd_ep *rxd_ep, const struct iovec *iov,
+			       size_t iov_count, fi_addr_t addr, uint64_t tag,
+			       uint64_t ignore, void *context, uint32_t op,
+			       uint32_t rxd_flags);
+ssize_t rxd_ep_generic_sendmsg(struct rxd_ep *rxd_ep, const struct iovec *iov,
+			       size_t iov_count, fi_addr_t addr, uint64_t tag,
+			       uint64_t data, void *context, uint32_t op,
+			       uint32_t rxd_flags);
+ssize_t rxd_ep_generic_inject(struct rxd_ep *rxd_ep, const struct iovec *iov,
+			      size_t iov_count, fi_addr_t addr, uint64_t tag,
+			      uint64_t data, uint32_t op, uint32_t rxd_flags);
+
+/* Progress functions */
+void rxd_tx_entry_progress(struct rxd_ep *ep, struct rxd_x_entry *tx_entry,
+			   int try_send);
+void rxd_handle_recv_comp(struct rxd_ep *ep, struct fi_cq_msg_entry *comp);
+void rxd_handle_send_comp(struct rxd_ep *ep, struct fi_cq_msg_entry *comp);
+void rxd_handle_error(struct rxd_ep *ep);
+void rxd_progress_op(struct rxd_ep *ep, struct rxd_x_entry *rx_entry,
+		     struct rxd_pkt_entry *pkt_entry,
+		     struct rxd_base_hdr *base_hdr,
+		     struct rxd_sar_hdr *sar_hdr,
+		     struct rxd_tag_hdr *tag_hdr,
+		     struct rxd_data_hdr *data_hdr,
+		     struct rxd_rma_hdr *rma_hdr,
+		     struct rxd_atom_hdr *atom_hdr,
+		     void **msg, size_t size);
+void rxd_progress_tx_list(struct rxd_ep *ep, struct rxd_peer *peer);
+struct rxd_x_entry *rxd_progress_multi_recv(struct rxd_ep *ep,
+					    struct rxd_x_entry *rx_entry,
+					    size_t total_size);
 
 /* CQ sub-functions */
 void rxd_cq_report_error(struct rxd_cq *cq, struct fi_cq_err_entry *err_entry);
-void rxd_cq_report_tx_comp(struct rxd_cq *cq, struct rxd_tx_entry *tx_entry);
-void rxd_cntr_report_tx_comp(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry);
+void rxd_cq_report_tx_comp(struct rxd_cq *cq, struct rxd_x_entry *tx_entry);
+void rxd_cntr_report_tx_comp(struct rxd_ep *ep, struct rxd_x_entry *tx_entry);
+void rxd_cntr_report_rx_comp(struct rxd_ep *ep, struct rxd_x_entry *rx_entry);
 
 #endif
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_atomic.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_atomic.c
new file mode 100644
index 000000000..920849ac6
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_atomic.c
@@ -0,0 +1,427 @@
+/*
+ * Copyright (c) 2013-2018 Intel Corporation. All rights reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdlib.h>
+#include <string.h>
+#include <sys/uio.h>
+
+#include "ofi_iov.h"
+#include "rxd.h"
+
+static ssize_t rxd_generic_atomic(struct rxd_ep *rxd_ep,
+			const struct fi_ioc *ioc, void **desc, size_t count,
+			const struct fi_ioc *compare_ioc, void **compare_desc,
+			size_t compare_count, struct fi_ioc *result_ioc,
+			void **result_desc, size_t result_count,
+			fi_addr_t addr, const struct fi_rma_ioc *rma_ioc,
+			size_t rma_count, uint64_t data, enum fi_datatype datatype,
+			enum fi_op atomic_op, void *context, uint32_t op,
+			uint32_t rxd_flags)
+{
+	struct rxd_x_entry *tx_entry;
+	struct iovec iov[RXD_IOV_LIMIT], res_iov[RXD_IOV_LIMIT], comp_iov[RXD_IOV_LIMIT];
+	struct fi_rma_iov rma_iov[RXD_IOV_LIMIT]; 
+	fi_addr_t rxd_addr;
+	ssize_t ret = -FI_EAGAIN;
+
+	assert(count <= RXD_IOV_LIMIT);
+	assert(rma_count <= RXD_IOV_LIMIT);
+
+	ofi_ioc_to_iov(ioc, iov, count, ofi_datatype_size(datatype));
+
+	assert(ofi_total_iov_len(iov, count) <= (op == RXD_ATOMIC_COMPARE) ?
+	       rxd_ep_domain(rxd_ep)->max_inline_atom / 2 :
+	       rxd_ep_domain(rxd_ep)->max_inline_atom);
+
+	ofi_ioc_to_iov(result_ioc, res_iov, result_count, ofi_datatype_size(datatype));
+	ofi_ioc_to_iov(compare_ioc, comp_iov, compare_count, ofi_datatype_size(datatype));
+	ofi_rma_ioc_to_iov(rma_ioc, rma_iov, rma_count, ofi_datatype_size(datatype));
+
+	fastlock_acquire(&rxd_ep->util_ep.lock);
+	fastlock_acquire(&rxd_ep->util_ep.tx_cq->cq_lock);
+
+	if (ofi_cirque_isfull(rxd_ep->util_ep.tx_cq->cirq))
+		goto out;
+
+	rxd_addr = rxd_ep_av(rxd_ep)->fi_addr_table[addr];
+	ret = rxd_send_rts_if_needed(rxd_ep, rxd_addr);
+	if (ret)
+		goto out;
+
+	tx_entry = rxd_tx_entry_init(rxd_ep, iov, count, res_iov, result_count, rma_count,
+				     data, 0, context, rxd_addr, op, rxd_flags);
+	if (!tx_entry)
+		goto out;
+
+	ret = rxd_ep_send_op(rxd_ep, tx_entry, rma_iov, rma_count, comp_iov,
+			     compare_count, datatype, atomic_op);
+	if (ret)
+		rxd_tx_entry_free(rxd_ep, tx_entry);
+
+out:
+	fastlock_release(&rxd_ep->util_ep.tx_cq->cq_lock);
+	fastlock_release(&rxd_ep->util_ep.lock);
+	return ret;
+}
+
+static ssize_t rxd_atomic_writemsg(struct fid_ep *ep_fid,
+			const struct fi_msg_atomic *msg, uint64_t flags)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_generic_atomic(ep, msg->msg_iov, msg->desc, msg->iov_count,
+				  NULL, NULL, 0, NULL, NULL, 0, msg->addr,
+				  msg->rma_iov, msg->rma_iov_count, msg->data,
+				  msg->datatype, msg->op, msg->context,
+				  ofi_op_atomic, rxd_flags(flags));
+}
+
+static ssize_t rxd_atomic_writev(struct fid_ep *ep_fid,
+			const struct fi_ioc *iov, void **desc, size_t count,
+			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct rxd_ep *ep;
+	struct fi_rma_ioc rma_iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	rma_iov.addr = addr;
+	rma_iov.count = ofi_total_ioc_cnt(iov, count);
+	rma_iov.key = key;
+
+	return rxd_generic_atomic(ep, iov, desc, count, NULL, NULL, 0, NULL,
+				  NULL, 0, dest_addr, &rma_iov, 1, 0, datatype,
+				  op, context, ofi_op_atomic,
+				  rxd_ep_tx_flags(ep));
+}
+
+static ssize_t rxd_atomic_write(struct fid_ep *ep_fid, const void *buf, size_t count,
+			void *desc, fi_addr_t dest_addr, uint64_t addr,
+			uint64_t key, enum fi_datatype datatype, enum fi_op op,
+			void *context)
+{
+	struct fi_ioc iov;
+	struct fi_rma_ioc rma_iov;
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.addr = (void *) buf;
+	iov.count = count;
+
+	rma_iov.addr = addr;
+	rma_iov.count = count;
+	rma_iov.key = key;
+
+	return rxd_generic_atomic(ep, &iov, &desc, 1, NULL, NULL, 0, NULL, NULL, 0,
+				  dest_addr, &rma_iov, 1, 0, datatype, op, context,
+				  ofi_op_atomic, rxd_ep_tx_flags(ep));
+}
+
+static ssize_t rxd_atomic_inject(struct fid_ep *ep_fid, const void *buf,
+			size_t count, fi_addr_t dest_addr, uint64_t addr,
+			uint64_t key, enum fi_datatype datatype, enum fi_op op)
+{
+	struct rxd_ep *rxd_ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+	struct rxd_x_entry *tx_entry;
+	struct iovec iov;
+	struct fi_rma_iov rma_iov; 
+	fi_addr_t rxd_addr;
+	ssize_t ret = -FI_EAGAIN;
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = count * ofi_datatype_size(datatype);
+	assert(iov.iov_len <= rxd_ep_domain(rxd_ep)->max_inline_atom);
+
+	rma_iov.addr = addr;
+	rma_iov.len = count * ofi_datatype_size(datatype);
+	rma_iov.key = key;
+
+	fastlock_acquire(&rxd_ep->util_ep.lock);
+	fastlock_acquire(&rxd_ep->util_ep.tx_cq->cq_lock);
+
+	if (ofi_cirque_isfull(rxd_ep->util_ep.tx_cq->cirq))
+		goto out;
+
+	rxd_addr = rxd_ep_av(rxd_ep)->fi_addr_table[addr];
+	ret = rxd_send_rts_if_needed(rxd_ep, rxd_addr);
+	if (ret)
+		goto out;
+
+	tx_entry = rxd_tx_entry_init(rxd_ep, &iov, 1, NULL, 0, 1, 0, 0, NULL,
+				     rxd_addr, ofi_op_atomic,
+				     RXD_INJECT | RXD_NO_TX_COMP);
+	if (!tx_entry)
+		goto out;
+
+	ret = rxd_ep_send_op(rxd_ep, tx_entry, &rma_iov, 1, NULL, 0, datatype, op);
+	if (ret)
+		rxd_tx_entry_free(rxd_ep, tx_entry);
+
+out:
+	fastlock_release(&rxd_ep->util_ep.tx_cq->cq_lock);
+	fastlock_release(&rxd_ep->util_ep.lock);
+	return ret;
+}
+
+static ssize_t rxd_atomic_readwritemsg(struct fid_ep *ep_fid,
+			const struct fi_msg_atomic *msg, struct fi_ioc *resultv,
+			void **result_desc, size_t result_count, uint64_t flags)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_generic_atomic(ep, msg->msg_iov, msg->desc, msg->iov_count,
+				  NULL, NULL, 0, resultv, result_desc,
+				  result_count, msg->addr,
+				  msg->rma_iov, msg->rma_iov_count, msg->data,
+				  msg->datatype, msg->op, msg->context,
+				  ofi_op_atomic_fetch, rxd_flags(flags));
+}
+
+static ssize_t rxd_atomic_readwritev(struct fid_ep *ep_fid,
+			const struct fi_ioc *iov, void **desc, size_t count,
+			struct fi_ioc *resultv, void **result_desc,
+			size_t result_count, fi_addr_t dest_addr, uint64_t addr,
+			uint64_t key, enum fi_datatype datatype, enum fi_op op,
+			void *context)
+{
+	struct fi_rma_ioc rma_iov;
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	rma_iov.addr = addr;
+	rma_iov.count = ofi_total_ioc_cnt(iov, count);
+	rma_iov.key = key;
+
+	return rxd_generic_atomic(ep, iov, desc, count, NULL, NULL, 0, resultv,
+				  result_desc, result_count, dest_addr,
+				  &rma_iov, 1, 0, datatype, op, context,
+				  ofi_op_atomic_fetch, rxd_ep_tx_flags(ep));
+}
+
+static ssize_t rxd_atomic_readwrite(struct fid_ep *ep_fid, const void *buf,
+			size_t count, void *desc, void *result,
+			void *result_desc, fi_addr_t dest_addr, uint64_t addr,
+			uint64_t key, enum fi_datatype datatype, enum fi_op op,
+			void *context)
+{
+	struct fi_ioc iov, resultv;
+	struct fi_rma_ioc rma_iov;
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.addr = (void *) buf;
+	iov.count = count;
+
+	resultv.addr = result;
+	resultv.count = count;
+
+	rma_iov.addr = addr;
+	rma_iov.count = count;
+	rma_iov.key = key;
+
+	return rxd_generic_atomic(ep, &iov, &desc, 1, NULL, NULL, 0, &resultv,
+				  &result_desc, 1, dest_addr, &rma_iov, 1, 0,
+				  datatype, op, context, ofi_op_atomic_fetch,
+				  rxd_ep_tx_flags(ep));
+}
+
+static ssize_t rxd_atomic_compwritemsg(struct fid_ep *ep_fid,
+			const struct fi_msg_atomic *msg,
+			const struct fi_ioc *comparev, void **compare_desc,
+			size_t compare_count, struct fi_ioc *resultv,
+			void **result_desc, size_t result_count, uint64_t flags)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_generic_atomic(ep, msg->msg_iov, msg->desc, msg->iov_count,
+				  comparev, compare_desc, compare_count,
+				  resultv, result_desc,
+				  result_count, msg->addr,
+				  msg->rma_iov, msg->rma_iov_count, msg->data,
+				  msg->datatype, msg->op, msg->context,
+				  ofi_op_atomic_compare, rxd_flags(flags));
+}
+
+static ssize_t rxd_atomic_compwritev(struct fid_ep *ep_fid,
+			const struct fi_ioc *iov, void **desc, size_t count,
+			const struct fi_ioc *comparev, void **compare_desc,
+			size_t compare_count, struct fi_ioc *resultv,
+			void **result_desc, size_t result_count,
+			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct fi_rma_ioc rma_iov;
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	rma_iov.addr = addr;
+	rma_iov.count = ofi_total_ioc_cnt(iov, count);
+	rma_iov.key = key;
+
+	return rxd_generic_atomic(ep, iov, desc, count, comparev, compare_desc,
+				  compare_count, resultv, result_desc,
+				  result_count, dest_addr, &rma_iov, 1, 0,
+				  datatype, op, context, ofi_op_atomic_compare,
+				  rxd_ep_tx_flags(ep));
+}
+
+static ssize_t rxd_atomic_compwrite(struct fid_ep *ep_fid, const void *buf,
+			size_t count, void *desc, const void *compare,
+			void *compare_desc, void *result, void *result_desc,
+			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct fi_ioc iov, resultv, comparev;
+	struct fi_rma_ioc rma_iov;
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.addr = (void *) buf;
+	iov.count = count;
+
+	resultv.addr = result;
+	resultv.count = count;
+
+	comparev.addr = (void *) compare;
+	comparev.count = count;
+
+	rma_iov.addr = addr;
+	rma_iov.count = count;
+	rma_iov.key = key;
+
+	return rxd_generic_atomic(ep, &iov, &desc, 1, &comparev, &compare_desc,
+				  1, &resultv, &result_desc, 1, dest_addr,
+				  &rma_iov, 1, 0, datatype, op, context,
+				  ofi_op_atomic_compare, rxd_ep_tx_flags(ep));
+}
+
+int rxd_query_atomic(struct fid_domain *domain, enum fi_datatype datatype,
+		     enum fi_op op, struct fi_atomic_attr *attr, uint64_t flags)
+{
+	struct rxd_domain *rxd_domain;
+	int ret;
+	size_t total_size;
+
+	if (flags & FI_TAGGED) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
+			"tagged atomic op not supported\n");
+		return -FI_EINVAL;
+	}
+
+	ret = ofi_atomic_valid(&rxd_prov, datatype, op, flags);
+	if (ret || !attr)
+		return ret;
+
+	rxd_domain = container_of(domain, struct rxd_domain,
+				  util_domain.domain_fid);
+	attr->size = ofi_datatype_size(datatype);
+
+	total_size = (flags & FI_COMPARE_ATOMIC) ?  rxd_domain->max_inline_atom / 2 :
+		      rxd_domain->max_inline_atom;
+	attr->count = total_size / attr->size;
+
+	return ret;
+}
+
+static int rxd_atomic_valid(struct fid_ep *ep, enum fi_datatype datatype,
+			    enum fi_op op, size_t *count)
+{
+	struct fi_atomic_attr attr;
+	int ret;
+
+	ret = rxd_query_atomic(&(container_of(ep,
+			struct util_ep, ep_fid))->domain->domain_fid,
+			datatype, op, &attr, 0);
+	if (!ret)
+		*count = attr.count;
+
+	return ret;
+}
+
+static int rxd_atomic_fetch_valid(struct fid_ep *ep, enum fi_datatype datatype,
+				  enum fi_op op, size_t *count)
+{
+	struct fi_atomic_attr attr;
+	int ret;
+
+	ret = rxd_query_atomic(&(container_of(ep,
+			struct util_ep, ep_fid))->domain->domain_fid,
+			datatype, op, &attr, FI_FETCH_ATOMIC);
+	if (!ret)
+		*count = attr.count;
+
+	return ret;
+}
+
+static int rxd_atomic_comp_valid(struct fid_ep *ep, enum fi_datatype datatype,
+				 enum fi_op op, size_t *count)
+{
+	struct fi_atomic_attr attr;
+	int ret;
+
+	ret = rxd_query_atomic(&(container_of(ep,
+			struct util_ep, ep_fid))->domain->domain_fid,
+			datatype, op, &attr, FI_COMPARE_ATOMIC);
+	if (!ret)
+		*count = attr.count;
+
+	return ret;
+}
+
+struct fi_ops_atomic rxd_ops_atomic = {
+	.size = sizeof(struct fi_ops_atomic),
+	.write = rxd_atomic_write,
+	.writev = rxd_atomic_writev,
+	.writemsg = rxd_atomic_writemsg,
+	.inject = rxd_atomic_inject,
+	.readwrite = rxd_atomic_readwrite,
+	.readwritev = rxd_atomic_readwritev,
+	.readwritemsg = rxd_atomic_readwritemsg,
+	.compwrite = rxd_atomic_compwrite,
+	.compwritev = rxd_atomic_compwritev,
+	.compwritemsg = rxd_atomic_compwritemsg,
+	.writevalid = rxd_atomic_valid,
+	.readwritevalid = rxd_atomic_fetch_valid,
+	.compwritevalid = rxd_atomic_comp_valid,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_attr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_attr.c
index 88e49fd63..f04039c74 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_attr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_attr.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2015-2017 Intel Corporation. All rights reserved.
+ * Copyright (c) 2015-2018 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -32,21 +32,26 @@
 
 #include "rxd.h"
 
-#define RXD_EP_CAPS (FI_MSG | FI_TAGGED | FI_DIRECTED_RECV |	\
-		     FI_RECV | FI_SEND | FI_SOURCE)
+#define RXD_EP_CAPS (FI_MSG | FI_TAGGED | FI_RMA | FI_ATOMIC | FI_SOURCE |  \
+			FI_DIRECTED_RECV | FI_MULTI_RECV | FI_RMA_EVENT)
+#define RXD_TX_CAPS (FI_SEND | FI_WRITE | FI_READ)
+#define RXD_RX_CAPS (FI_RECV | FI_REMOTE_READ | FI_REMOTE_WRITE)
+#define RXD_DOMAIN_CAPS (FI_LOCAL_COMM | FI_REMOTE_COMM)
 
 struct fi_tx_attr rxd_tx_attr = {
-	.caps = RXD_EP_CAPS,
-	.comp_order = FI_ORDER_STRICT,
-	.inject_size = 0,
+	.caps = RXD_EP_CAPS | RXD_TX_CAPS,
+	.comp_order = FI_ORDER_NONE,
+	.msg_order = FI_ORDER_SAS,
+	.inject_size = RXD_MAX_MTU_SIZE - sizeof(struct rxd_base_hdr),
 	.size = (1ULL << RXD_MAX_TX_BITS),
 	.iov_limit = RXD_IOV_LIMIT,
 	.rma_iov_limit = 0,
 };
 
 struct fi_rx_attr rxd_rx_attr = {
-	.caps = RXD_EP_CAPS,
-	.comp_order = FI_ORDER_STRICT,
+	.caps = RXD_EP_CAPS | RXD_RX_CAPS,
+	.comp_order = FI_ORDER_NONE,
+	.msg_order = FI_ORDER_SAS,
 	.total_buffered_recv = 0,
 	.size = (1ULL << RXD_MAX_RX_BITS),
 	.iov_limit = RXD_IOV_LIMIT
@@ -62,11 +67,14 @@ struct fi_ep_attr rxd_ep_attr = {
 };
 
 struct fi_domain_attr rxd_domain_attr = {
+	.caps = RXD_DOMAIN_CAPS,
 	.threading = FI_THREAD_SAFE,
 	.control_progress = FI_PROGRESS_MANUAL,
 	.data_progress = FI_PROGRESS_MANUAL,
 	.resource_mgmt = FI_RM_ENABLED,
 	.av_type = FI_AV_UNSPEC,
+	.mr_mode = FI_MR_BASIC | FI_MR_SCALABLE,
+	.cq_data_size = sizeof_field(struct rxd_data_hdr, cq_data),
 	.mr_key_size = sizeof(uint64_t),
 	.cq_cnt = 128,
 	.ep_cnt = 128,
@@ -82,8 +90,8 @@ struct fi_fabric_attr rxd_fabric_attr = {
 };
 
 struct fi_info rxd_info = {
-	.caps = RXD_EP_CAPS,
-	.addr_format = FI_SOCKADDR,
+	.caps = RXD_DOMAIN_CAPS | RXD_EP_CAPS | RXD_TX_CAPS | RXD_RX_CAPS,
+	.addr_format = FI_FORMAT_UNSPEC,
 	.tx_attr = &rxd_tx_attr,
 	.rx_attr = &rxd_rx_attr,
 	.ep_attr = &rxd_ep_attr,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_av.c
index ddf7e1106..1593f07de 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_av.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_av.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2015-2017 Intel Corporation. All rights reserved.
+ * Copyright (c) 2015-2018 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -34,6 +34,23 @@
 #include <inttypes.h>
 
 
+static int rxd_tree_compare(struct ofi_rbmap *map, void *key, void *data)
+{
+	struct rxd_av *av;
+	uint8_t addr[RXD_NAME_LENGTH];
+	size_t len = RXD_NAME_LENGTH;
+	int ret;
+
+	memset(addr, 0, len);
+	av = container_of(map, struct rxd_av, rbmap);
+	ret = fi_av_lookup(av->dg_av, av->rxd_addr_table[(fi_addr_t) data].dg_addr,
+			   addr, &len);
+	if (ret)
+		return -1;
+
+	return memcmp(key, addr, len);
+}
+
 /*
  * The RXD code is agnostic wrt the datagram address format, but we need
  * to know the size of the address in order to iterate over them.  Because
@@ -46,13 +63,13 @@ static int rxd_av_set_addrlen(struct rxd_av *av, const void *addr)
 	struct rxd_domain *domain;
 	struct fid_av *tmp_av;
 	struct fi_av_attr attr;
-	uint8_t tmp_addr[RXD_MAX_DGRAM_ADDR];
+	uint8_t tmp_addr[RXD_NAME_LENGTH];
+	fi_addr_t fiaddr;
 	size_t len;
 	int ret;
 
 	FI_INFO(&rxd_prov, FI_LOG_AV, "determine dgram address len\n");
 	memset(&attr, 0, sizeof attr);
-	attr.type = FI_AV_TABLE;
 	attr.count = 1;
 
 	domain = container_of(av->util_av.domain, struct rxd_domain, util_domain);
@@ -63,15 +80,16 @@ static int rxd_av_set_addrlen(struct rxd_av *av, const void *addr)
 		return ret;
 	}
 
-	ret = fi_av_insert(tmp_av, addr, 1, NULL, 0, NULL);
+	ret = fi_av_insert(tmp_av, addr, 1, &fiaddr, 0, NULL);
 	if (ret != 1) {
 		FI_WARN(&rxd_prov, FI_LOG_AV, "addr insert failed: %d (%s)\n",
 			-ret, fi_strerror(-ret));
+		ret = -FI_EINVAL;
 		goto close;
 	}
 
 	len = sizeof tmp_addr;
-	ret = fi_av_lookup(tmp_av, 0, tmp_addr, &len);
+	ret = fi_av_lookup(tmp_av, fiaddr, tmp_addr, &len);
 	if (ret) {
 		FI_WARN(&rxd_prov, FI_LOG_AV, "addr lookup failed: %d (%s)\n",
 			-ret, fi_strerror(-ret));
@@ -85,77 +103,77 @@ close:
 	return ret;
 }
 
-fi_addr_t rxd_av_dg_addr(struct rxd_av *av, fi_addr_t fi_addr)
+static fi_addr_t rxd_av_dg_addr(struct rxd_av *av, fi_addr_t fi_addr)
 {
-	uint64_t *dg_idx;
+	fi_addr_t rxd_addr = av->fi_addr_table[fi_addr];
 
-	dg_idx = ofi_av_get_addr(&av->util_av, (int) fi_addr);
-	return *dg_idx;
+	return rxd_addr == FI_ADDR_UNSPEC ? rxd_addr :
+		av->rxd_addr_table[rxd_addr].dg_addr;
 }
 
-fi_addr_t rxd_av_fi_addr(struct rxd_av *av, fi_addr_t dg_fiaddr)
+static fi_addr_t rxd_set_rxd_addr(struct rxd_av *av, fi_addr_t dg_addr)
 {
-	int ret;
+	int tries = 0;
+
+	while (av->rxd_addr_table[av->rxd_addr_idx].dg_addr != FI_ADDR_UNSPEC &&
+	       tries < av->util_av.count) {
+		if (++av->rxd_addr_idx == av->util_av.count)
+			av->rxd_addr_idx = 0;
+		tries++;
+	}
+	assert(av->rxd_addr_idx < av->util_av.count && tries < av->util_av.count);
+	av->rxd_addr_table[av->rxd_addr_idx].dg_addr = dg_addr;
 
-	ret = ofi_av_lookup_index(&av->util_av, &dg_fiaddr, (int) dg_fiaddr);
-	return (ret < 0) ? FI_ADDR_UNSPEC : ret;
+	return av->rxd_addr_idx;
 }
 
-int rxd_av_dg_reverse_lookup(struct rxd_av *av, uint64_t start_idx,
-			      const void *addr, fi_addr_t *dg_fiaddr)
+static fi_addr_t rxd_set_fi_addr(struct rxd_av *av, fi_addr_t rxd_addr)
 {
-	uint8_t curr_addr[RXD_MAX_DGRAM_ADDR];
-	size_t i, len;
-	int ret;
+	int tries = 0;
 
-	for (i = 0; i < (size_t) av->dg_av_used; i++) {
-		len = sizeof curr_addr;
-		ret = fi_av_lookup(av->dg_av, (i + start_idx) % av->dg_av_used,
-				   curr_addr, &len);
-		if (!ret) {
-			*dg_fiaddr = (i + start_idx) % av->dg_av_used;
-			FI_DBG(&rxd_prov, FI_LOG_AV, "found: %" PRIu64 "\n",
-				*dg_fiaddr);
-			return 0;
-		}
+	while (av->fi_addr_table[av->fi_addr_idx] != FI_ADDR_UNSPEC &&
+	       tries < av->util_av.count) {
+		if (++av->fi_addr_idx == av->util_av.count)
+			av->fi_addr_idx = 0;
+		tries++;
 	}
-	FI_DBG(&rxd_prov, FI_LOG_AV, "addr not found\n");
-	return -FI_ENODATA;
+	assert(av->fi_addr_idx < av->util_av.count && tries < av->util_av.count);
+	av->fi_addr_table[av->fi_addr_idx] = rxd_addr;
+	av->rxd_addr_table[rxd_addr].fi_addr = av->fi_addr_idx;
+
+	return av->fi_addr_idx;
 }
 
-int rxd_av_insert_dg_addr(struct rxd_av *av, uint64_t hint_index,
-			  const void *addr, fi_addr_t *dg_fiaddr)
+int rxd_av_insert_dg_addr(struct rxd_av *av, const void *addr,
+			  fi_addr_t *rxd_addr, uint64_t flags,
+			  void *context)
 {
+	fi_addr_t dg_addr;
 	int ret;
 
-	fastlock_acquire(&av->util_av.lock);
-	if (!av->dg_addrlen) {
-		ret = rxd_av_set_addrlen(av, addr);
-		if (ret)
-			goto out;
-		ret = -FI_ENODATA;
-	} else {
-		ret = rxd_av_dg_reverse_lookup(av, hint_index, addr, dg_fiaddr);
-	}
+	ret = fi_av_insert(av->dg_av, addr, 1, &dg_addr,
+			     flags, context);
+	if (ret != 1)
+		return -FI_EINVAL;
 
-	if (ret == -FI_ENODATA) {
-		ret = fi_av_insert(av->dg_av, addr, 1, dg_fiaddr, 0, NULL);
-		if (ret == 1) {
-			av->dg_av_used++;
-			ret = 0;
-		}
+	*rxd_addr = rxd_set_rxd_addr(av, dg_addr);
+
+	ret = ofi_rbmap_insert(&av->rbmap, (void *) addr, (void *) (*rxd_addr));
+	if (ret && ret != -FI_EALREADY) {
+		fi_av_remove(av->dg_av, &dg_addr, 1, flags);
+		return ret;
 	}
-out:
-	fastlock_release(&av->util_av.lock);
-	return ret;
+
+	return 0;
 }
 
 static int rxd_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
 			fi_addr_t *fi_addr, uint64_t flags, void *context)
 {
 	struct rxd_av *av;
-	int i = 0, index, ret = 0, success_cnt = 0, lookup = 1;
-	uint64_t dg_fiaddr;
+	int i = 0, ret = 0, success_cnt = 0;
+	fi_addr_t rxd_addr, util_addr;
+	struct ofi_rbnode *node;
 
 	av = container_of(av_fid, struct rxd_av, util_av.av_fid);
 	fastlock_acquire(&av->util_av.lock);
@@ -163,27 +181,26 @@ static int rxd_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
 		ret = rxd_av_set_addrlen(av, addr);
 		if (ret)
 			goto out;
-		/* Skip lookups if this is the first insertion call.  */
-		lookup = 0;
 	}
 
 	for (; i < count; i++, addr = (uint8_t *) addr + av->dg_addrlen) {
-		ret = lookup ? rxd_av_dg_reverse_lookup(av, i, addr, &dg_fiaddr) :
-				-FI_ENODATA;
-		if (ret) {
-			ret = fi_av_insert(av->dg_av, addr, 1, &dg_fiaddr,
-					   flags, context);
-			if (ret != 1)
+		node = ofi_rbmap_find(&av->rbmap, (void *) addr);
+		if (node) {
+			rxd_addr = (fi_addr_t) node->data;
+		} else {
+			ret = rxd_av_insert_dg_addr(av, addr, &rxd_addr,
+						    flags, context);
+			if (ret)
 				break;
 		}
 
-		ret = ofi_av_insert_addr(&av->util_av, &dg_fiaddr, dg_fiaddr, &index);
-		if (ret)
-			break;
+		util_addr = av->rxd_addr_table[rxd_addr].fi_addr == FI_ADDR_UNSPEC ?
+			    rxd_set_fi_addr(av, rxd_addr) :
+			    av->rxd_addr_table[rxd_addr].fi_addr;
+		if (fi_addr)
+			fi_addr[i] = util_addr;
 
 		success_cnt++;
-		if (fi_addr)
-			fi_addr[i] = index;
 	}
 
 	if (ret) {
@@ -233,19 +250,44 @@ static int rxd_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr, size_t count
 			uint64_t flags)
 {
 	int ret = 0;
-	size_t i;
-	fi_addr_t dg_fiaddr;
+	size_t i, addrlen;
+	fi_addr_t rxd_addr;
 	struct rxd_av *av;
+	uint8_t addr[RXD_NAME_LENGTH];
+	struct ofi_rbnode *node;
 
 	av = container_of(av_fid, struct rxd_av, util_av.av_fid);
 	fastlock_acquire(&av->util_av.lock);
 	for (i = 0; i < count; i++) {
-		dg_fiaddr = rxd_av_dg_addr(av, fi_addr[i]);
-		ret = fi_av_remove(av->dg_av, &dg_fiaddr, 1, flags);
+		rxd_addr = av->fi_addr_table[fi_addr[i]];
+
+		addrlen = RXD_NAME_LENGTH;
+		ret = fi_av_lookup(av->dg_av, av->rxd_addr_table[rxd_addr].dg_addr,
+				   addr, &addrlen);
+		if (ret)
+			goto err;
+		
+		node = ofi_rbmap_find(&av->rbmap, (void *) addr);
+		if (!node)
+			goto err;
+
+		ofi_rbmap_delete(&av->rbmap, node);
+
+		ret = fi_av_remove(av->dg_av, &av->rxd_addr_table[rxd_addr].dg_addr,
+				   1, flags);
 		if (ret)
-			break;
+			goto err;
+
+		av->fi_addr_table[fi_addr[i]] = FI_ADDR_UNSPEC;
+		av->rxd_addr_table[rxd_addr].fi_addr = FI_ADDR_UNSPEC;
+		av->rxd_addr_table[rxd_addr].dg_addr = FI_ADDR_UNSPEC;
 		av->dg_av_used--;
 	}
+
+err:
+	if (ret)
+		FI_WARN(&rxd_prov, FI_LOG_AV, "Unable to remove address from AV\n");
+
 	fastlock_release(&av->util_av.lock);
 	return ret;
 }
@@ -262,11 +304,14 @@ static int rxd_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr,
 			 size_t *addrlen)
 {
 	struct rxd_av *rxd_av;
-	fi_addr_t dg_addr;
+	fi_addr_t dg_fiaddr;
 
 	rxd_av = container_of(av, struct rxd_av, util_av.av_fid);
-	dg_addr = rxd_av_dg_addr(rxd_av, fi_addr);
-	return fi_av_lookup(rxd_av->dg_av, dg_addr, addr, addrlen);
+	dg_fiaddr = rxd_av_dg_addr(rxd_av, fi_addr);
+	if (dg_fiaddr == FI_ADDR_UNSPEC)
+		return -FI_ENODATA;
+
+	return fi_av_lookup(rxd_av->dg_av, dg_fiaddr, addr, addrlen);
 }
 
 static struct fi_ops_av rxd_av_ops = {
@@ -293,6 +338,8 @@ static int rxd_av_close(struct fid *fid)
 	if (ret)
 		return ret;
 
+	free(av->fi_addr_table);
+	free(av->rxd_addr_table);
 	free(av);
 	return 0;
 }
@@ -313,7 +360,7 @@ static struct fi_ops rxd_av_fi_ops = {
 int rxd_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 		   struct fid_av **av_fid, void *context)
 {
-	int ret;
+	int ret, i;
 	struct rxd_av *av;
 	struct rxd_domain *domain;
 	struct util_av_attr util_attr;
@@ -325,24 +372,40 @@ int rxd_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 	if (attr->name)
 		return -FI_ENOSYS;
 
+	attr->count = roundup_power_of_two(attr->count ?
+					   attr->count : RXD_DEFAULT_AV_SIZE);
 	domain = container_of(domain_fid, struct rxd_domain, util_domain.domain_fid);
 	av = calloc(1, sizeof(*av));
 	if (!av)
 		return -FI_ENOMEM;
+	av->fi_addr_table = calloc(1, attr->count * sizeof(fi_addr_t));
+	av->rxd_addr_table = calloc(1, rxd_env.max_peers * sizeof(struct rxd_addr));
+	if (!av->fi_addr_table || !av->rxd_addr_table) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+
 
 	util_attr.addrlen = sizeof(fi_addr_t);
-	util_attr.overhead = attr->count;
-	util_attr.flags = OFI_AV_HASH;
-	if (attr->type == FI_AV_UNSPEC)
-		attr->type = FI_AV_TABLE;
+	util_attr.flags = 0;
+	attr->type = domain->util_domain.av_type != FI_AV_UNSPEC ?
+		     domain->util_domain.av_type : FI_AV_TABLE;
 
 	ret = ofi_av_init(&domain->util_domain, attr, &util_attr,
 			 &av->util_av, context);
 	if (ret)
 		goto err1;
 
+	av->rbmap.compare = &rxd_tree_compare;
+	ofi_rbmap_init(&av->rbmap);
+	for (i = 0; i < attr->count; av->fi_addr_table[i++] = FI_ADDR_UNSPEC)
+		;
+	for (i = 0; i < rxd_env.max_peers; i++) {
+		av->rxd_addr_table[i].fi_addr = FI_ADDR_UNSPEC;
+		av->rxd_addr_table[i].dg_addr = FI_ADDR_UNSPEC;
+	}
+
 	av_attr = *attr;
-	av_attr.type = FI_AV_TABLE;
 	av_attr.count = 0;
 	av_attr.flags = 0;
 	ret = fi_av_open(domain->dg_domain, &av_attr, &av->dg_av, context);
@@ -357,6 +420,8 @@ int rxd_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 err2:
 	ofi_av_close(&av->util_av);
 err1:
+	free(av->fi_addr_table);
+	free(av->rxd_addr_table);
 	free(av);
 	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_cntr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_cntr.c
index bc6ad12bc..a6f2dcc24 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_cntr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_cntr.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -35,6 +35,55 @@
 
 #define RXD_FLAG(flag, mask) (((flag) & (mask)) == (mask))
 
+static int rxd_cntr_wait(struct fid_cntr *cntr_fid, uint64_t threshold, int timeout)
+{
+	struct fid_list_entry *fid_entry;
+	struct util_cntr *cntr;
+	struct rxd_ep *ep;
+	uint64_t start, errcnt;
+	int ret, ep_retry;
+
+	cntr = container_of(cntr_fid, struct util_cntr, cntr_fid);
+	assert(cntr->wait);
+	errcnt = ofi_atomic_get64(&cntr->err);
+	start = (timeout >= 0) ? fi_gettime_ms() : 0;
+
+	do {
+		cntr->progress(cntr);
+		if (threshold <= ofi_atomic_get64(&cntr->cnt))
+			return FI_SUCCESS;
+
+		if (errcnt != ofi_atomic_get64(&cntr->err))
+			return -FI_EAVAIL;
+
+		if (timeout >= 0) {
+			timeout -= (int) (fi_gettime_ms() - start);
+			if (timeout <= 0)
+				return -FI_ETIMEDOUT;
+		}
+
+		ep_retry = -1;
+		fastlock_acquire(&cntr->ep_list_lock);
+		dlist_foreach_container(&cntr->ep_list, struct fid_list_entry,
+					fid_entry, entry) {
+			ep = container_of(fid_entry->fid, struct rxd_ep,
+					  util_ep.ep_fid.fid);
+			if (ep->next_retry == -1)
+				continue;
+			ep_retry = ep_retry == -1 ? ep->next_retry :
+					MIN(ep_retry, ep->next_retry);
+		}
+		fastlock_release(&cntr->ep_list_lock);
+
+		ret = fi_wait(&cntr->wait->wait_fid, ep_retry == -1 ?
+			      timeout : rxd_get_timeout(ep_retry));
+		if (ep_retry != -1 && ret == -FI_ETIMEDOUT)
+			ret = 0;
+	} while (!ret);
+
+	return ret;
+}
+
 int rxd_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
 		  struct fid_cntr **cntr_fid, void *context)
 {
@@ -51,6 +100,7 @@ int rxd_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
 		goto free;
 
 	*cntr_fid = &cntr->cntr_fid;
+	cntr->cntr_fid.ops->wait = rxd_cntr_wait;
 	return FI_SUCCESS;
 
 free:
@@ -58,30 +108,22 @@ free:
 	return ret;
 }
 
-void rxd_cntr_report_tx_comp(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry)
+void rxd_cntr_report_tx_comp(struct rxd_ep *ep, struct rxd_x_entry *tx_entry)
 {
-        struct util_cntr *cntr;
+	uint64_t flags = tx_entry->cq_entry.flags &
+			 (FI_SEND | FI_WRITE | FI_READ);
 
-	switch (tx_entry->op_type) {
-	case RXD_TX_MSG:
-	case RXD_TX_TAG:
-		cntr = ep->util_ep.tx_cntr;
-		break;
-	case RXD_TX_WRITE:
-		cntr = ep->util_ep.wr_cntr;
-		break;
-	case RXD_TX_READ_REQ:
-		cntr = ep->util_ep.rem_rd_cntr;
-		break;
-	case RXD_TX_READ_RSP:
-		return;
-	default:
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "invalid op type\n");
-		return;
-	}
+	assert(ofi_lsb(flags) == ofi_msb(flags));
+	ofi_ep_cntr_inc_funcs[flags](&ep->util_ep);
+}
 
-	if (cntr)
-		cntr->cntr_fid.ops->add(&cntr->cntr_fid, 1);
+void rxd_cntr_report_rx_comp(struct rxd_ep *ep, struct rxd_x_entry *rx_entry)
+{
+	uint64_t flags = rx_entry->cq_entry.flags &
+			(FI_RECV | FI_REMOTE_WRITE | FI_REMOTE_READ);
+
+	assert(ofi_lsb(flags) == ofi_msb(flags));
+	ofi_ep_cntr_inc_funcs[flags](&ep->util_ep);
 }
 
 void rxd_cntr_report_error(struct rxd_ep *ep, struct fi_cq_err_entry *err)
@@ -98,6 +140,3 @@ void rxd_cntr_report_error(struct rxd_ep *ep, struct fi_cq_err_entry *err)
 	if (cntr)
 		cntr->cntr_fid.ops->adderr(&cntr->cntr_fid, 1);
 }
-
-
-
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_cq.c
index 6a929b770..ecd807423 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_cq.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2016 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
  * Copyright (c) 2016 Cisco Systems, Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
@@ -68,6 +68,7 @@ static int rxd_cq_write_ctx(struct rxd_cq *cq,
 			     struct fi_cq_tagged_entry *cq_entry)
 {
 	struct fi_cq_tagged_entry *comp;
+
 	if (ofi_cirque_isfull(cq->util_cq.cirq))
 		return -FI_ENOSPC;
 
@@ -157,979 +158,1042 @@ static int rxd_cq_write_tagged_signal(struct rxd_cq *cq,
 	return ret;
 }
 
-static int rxd_check_start_pkt_order(struct rxd_ep *ep, struct rxd_peer *peer,
-				      struct ofi_ctrl_hdr *ctrl,
-				      struct fi_cq_msg_entry *comp)
+void rxd_rx_entry_free(struct rxd_ep *ep, struct rxd_x_entry *rx_entry)
 {
-	uint64_t msg_id;
-
-	msg_id = ctrl->msg_id >> RXD_MAX_TX_BITS;
-	if (peer->exp_msg_id == msg_id)
-		return 0;
-
-	return (peer->exp_msg_id > msg_id) ?
-		-FI_EALREADY : -FI_EINVAL;
+	rx_entry->op = RXD_NO_OP;
+	dlist_remove(&rx_entry->entry);
+	rxd_release_rx_entry(ep, rx_entry);
 }
 
-static int rxd_rx_entry_match(struct dlist_entry *item, const void *arg)
+static int rxd_match_pkt_entry(struct slist_entry *item, const void *arg)
 {
-	const struct ofi_ctrl_hdr *ctrl = arg;
-	struct rxd_rx_entry *rx_entry;
+	return ((struct rxd_pkt_entry *) arg ==
+		container_of(item, struct rxd_pkt_entry, s_entry));
+} 
 
-	rx_entry = container_of(item, struct rxd_rx_entry, entry);
-	return (rx_entry->msg_id == ctrl->msg_id && rx_entry->peer == ctrl->conn_id);
-}
-
-static void rxd_handle_dup_datastart(struct rxd_ep *ep, struct ofi_ctrl_hdr *ctrl,
-				      struct rxd_rx_buf *rx_buf)
+static void rxd_remove_rx_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
 {
-	struct dlist_entry *item;
-	struct rxd_rx_entry *rx_entry;
-	struct rxd_peer *peer;
+	struct slist_entry *item;
 
-	peer = rxd_ep_getpeer_info(ep, ctrl->conn_id);
-	item = dlist_find_first_match(&ep->rx_entry_list,
-				      rxd_rx_entry_match, ctrl);
+	item = slist_remove_first_match(&ep->rx_pkt_list, rxd_match_pkt_entry,
+					pkt_entry);
 	if (!item) {
-	      /* for small (1-packet) messages we may have situation
-	       * when receiver completed operation and destroyed
-	       * rx_entry, but ack is lost (not delivered to sender).
-	       * in this case just send ack with zero window to
-	       * allow sender complete operation on sender side */
-	      rxd_ep_reply_ack(ep, ctrl, ofi_ctrl_ack, 0, UINT64_MAX,
-			       peer->conn_data, ctrl->conn_id);
-	      return;
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
+			"could not find posted rx to release\n");
 	}
+}
 
-	FI_INFO(&rxd_prov, FI_LOG_EP_CTRL,
-		"duplicate start-data: msg_id: %" PRIu64 ", seg_no: %d\n",
-		ctrl->msg_id, ctrl->seg_no);
+void rxd_release_repost_rx(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
+{
+	rxd_release_rx_pkt(ep, pkt_entry);
+	rxd_ep_post_buf(ep);
+}
 
-	rx_entry = container_of(item, struct rxd_rx_entry, entry);
-	rxd_ep_reply_ack(ep, ctrl, ofi_ctrl_ack, rx_entry->credits, rx_entry->key,
-		       peer->conn_data, ctrl->conn_id);
-	return;
+void rxd_cq_report_error(struct rxd_cq *cq, struct fi_cq_err_entry *err_entry)
+{
+	struct fi_cq_tagged_entry cq_entry = {0};
+	struct util_cq_oflow_err_entry *entry = calloc(1, sizeof(*entry));
+	if (!entry) {
+		FI_WARN(&rxd_prov, FI_LOG_CQ,
+			"out of memory, cannot report CQ error\n");
+		return;
+	}
+
+	entry->comp = *err_entry;
+	slist_insert_tail(&entry->list_entry, &cq->util_cq.oflow_err_list);
+	cq_entry.flags = UTIL_FLAG_ERROR;
+	cq->write_fn(cq, &cq_entry);
 }
 
-static void rxd_handle_conn_req(struct rxd_ep *ep, struct ofi_ctrl_hdr *ctrl,
-				struct fi_cq_msg_entry *comp,
-				struct rxd_rx_buf *rx_buf)
+static void rxd_complete_rx(struct rxd_ep *ep, struct rxd_x_entry *rx_entry)
 {
-	struct rxd_pkt_data *pkt_data;
-	struct rxd_peer *peer_info;
-	fi_addr_t dg_fiaddr;
-	void *addr;
-	int ret;
+	struct fi_cq_err_entry err_entry;
+	struct rxd_cq *rx_cq = rxd_ep_rx_cq(ep);
+	int write_cq = rx_entry->cq_entry.flags & (FI_RECV | FI_REMOTE_CQ_DATA);
 
-	FI_INFO(&rxd_prov, FI_LOG_EP_DATA,
-	       "conn req - rx_key: %" PRIu64 "\n", ctrl->rx_key);
+	if (rx_entry->flags & (RXD_NO_RX_COMP | RXD_CANCELLED))
+		goto out;
 
-	pkt_data = (struct rxd_pkt_data *) ctrl;
-	addr = pkt_data->data;
-	if (ctrl->seg_size > RXD_MAX_DGRAM_ADDR) {
-		FI_WARN(&rxd_prov, FI_LOG_EP_DATA, "addr too large\n");
-		goto repost;
+	if (rx_entry->bytes_done == rx_entry->cq_entry.len) {
+		rxd_cntr_report_rx_comp(ep, rx_entry);
+		if (write_cq)
+			rx_cq->write_fn(rx_cq, &rx_entry->cq_entry);
+	} else if (write_cq) {
+		memset(&err_entry, 0, sizeof(err_entry));
+		err_entry.op_context = rx_entry->cq_entry.op_context;
+		err_entry.flags = rx_entry->cq_entry.flags;
+		err_entry.len = rx_entry->bytes_done;
+		err_entry.err = FI_ETRUNC;
+		err_entry.prov_errno = 0;
+		rxd_cq_report_error(rx_cq, &err_entry);
 	}
 
-	ret = rxd_av_insert_dg_addr(rxd_ep_av(ep), ctrl->rx_key, addr, &dg_fiaddr);
-	if (ret) {
-		FI_WARN(&rxd_prov, FI_LOG_EP_DATA, "failed to insert peer address\n");
-		goto repost;
-	}
+out:
+	rxd_rx_entry_free(ep, rx_entry);
+}
 
-	peer_info = rxd_ep_getpeer_info(ep, dg_fiaddr);
-	if (peer_info->state != CMAP_CONNECTED) {
-		peer_info->state = CMAP_CONNECTED;
-		peer_info->conn_data = ctrl->conn_id;
-		peer_info->exp_msg_id++;
-	}
+static void rxd_complete_tx(struct rxd_ep *ep, struct rxd_x_entry *tx_entry)
+{
+	struct rxd_cq *tx_cq = rxd_ep_tx_cq(ep);
 
-	rxd_ep_reply_ack(ep, ctrl, ofi_ctrl_connresp, 0, ctrl->conn_id,
-			 dg_fiaddr, dg_fiaddr);
-repost:
-	rxd_ep_repost_buff(rx_buf);
+	if (tx_entry->flags & RXD_NO_TX_COMP)
+		goto out;
+
+	tx_cq->write_fn(tx_cq, &tx_entry->cq_entry);
+
+out:
+	rxd_cntr_report_tx_comp(ep, tx_entry);
+	rxd_tx_entry_free(ep, tx_entry);
 }
 
-int rxd_tx_pkt_match(struct dlist_entry *item, const void *arg)
+static int rxd_comp_pkt_seq_no(struct dlist_entry *item, const void *arg)
 {
-	const struct ofi_ctrl_hdr *pkt_ctrl, *ack_ctrl = arg;
-	struct rxd_pkt_meta *tx_pkt;
+	struct rxd_base_hdr *list_hdr;
+	struct rxd_base_hdr *new_hdr;
 
-	tx_pkt = container_of(item, struct rxd_pkt_meta, entry);
-	pkt_ctrl = (struct ofi_ctrl_hdr *) tx_pkt->pkt_data;
-	return (ack_ctrl->seg_no == pkt_ctrl->seg_no) ? 1 : 0;
+	list_hdr = rxd_get_base_hdr(container_of(item,
+				   struct rxd_pkt_entry, d_entry));
+
+	new_hdr = rxd_get_base_hdr(container_of((struct dlist_entry *) arg,
+				  struct rxd_pkt_entry, d_entry));
+
+	return new_hdr->seq_no > list_hdr->seq_no;
 }
 
-static void rxd_handle_ack(struct rxd_ep *ep, struct ofi_ctrl_hdr *ctrl,
-			   struct rxd_rx_buf *rx_buf)
+static void rxd_ep_recv_data(struct rxd_ep *ep, struct rxd_x_entry *x_entry,
+			     struct rxd_data_pkt *pkt, size_t size)
 {
-	struct rxd_tx_entry *tx_entry;
-	uint64_t idx;
+	struct rxd_domain *rxd_domain = rxd_ep_domain(ep);
+	uint64_t done;
+	struct iovec *iov;
+	size_t iov_count;
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-	       "ack- msg_id: %" PRIu64 ", segno: %d, segsz: %d, buf: %p\n",
-	       ctrl->msg_id, ctrl->seg_no, ctrl->seg_size, rx_buf);
+	if (x_entry->cq_entry.flags & FI_ATOMIC) {
+		iov = x_entry->res_iov;
+		iov_count = x_entry->res_count;
+	} else {
+		iov = x_entry->iov;
+		iov_count = x_entry->iov_count;
+	}
 
-	idx = ctrl->msg_id & RXD_TX_IDX_BITS;
-	tx_entry = &ep->tx_entry_fs->buf[idx];
-	if (tx_entry->msg_id != ctrl->msg_id)
-		goto out;
+	done = ofi_copy_to_iov(iov, iov_count, x_entry->offset +
+			       (pkt->ext_hdr.seg_no * rxd_domain->max_seg_sz),
+			       pkt->msg, size - sizeof(struct rxd_data_pkt) -
+			       ep->rx_prefix_size);
 
-	rxd_ep_free_acked_pkts(ep, tx_entry, ctrl->seg_no);
-	if ((tx_entry->bytes_sent == tx_entry->op_hdr.size) &&
-	    dlist_empty(&tx_entry->pkt_list)) {
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-			"reporting TX completion : %p\n", tx_entry);
-		if (tx_entry->op_type != RXD_TX_READ_REQ) {
-			rxd_cq_report_tx_comp(rxd_ep_tx_cq(ep), tx_entry);
-			rxd_cntr_report_tx_comp(ep, tx_entry);
-			rxd_tx_entry_free(ep, tx_entry);
-		}
+	x_entry->bytes_done += done;
+	ep->peers[pkt->base_hdr.peer].rx_seq_no++;
+	x_entry->next_seg_no++;
+
+	if (x_entry->next_seg_no < x_entry->num_segs) {
+		if (!(ep->peers[pkt->base_hdr.peer].rx_seq_no %
+		    ep->peers[pkt->base_hdr.peer].rx_window))
+			rxd_ep_send_ack(ep, pkt->base_hdr.peer);
+		return;
+	}
+	rxd_ep_send_ack(ep, pkt->base_hdr.peer);
+
+	if (x_entry->cq_entry.flags & FI_READ) {
+		fastlock_acquire(&ep->util_ep.tx_cq->cq_lock);
+		rxd_complete_tx(ep, x_entry);
+		fastlock_release(&ep->util_ep.tx_cq->cq_lock);
 	} else {
-		tx_entry->rx_key = ctrl->rx_key;
-		/* do not allow reduce window size (on duplicate acks) */
-		tx_entry->window = MAX(tx_entry->window, ctrl->seg_no + ctrl->seg_size);
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-		       "ack- msg_id: %" PRIu64 ", window: %d\n",
-		       ctrl->msg_id, tx_entry->window);
+		fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
+		rxd_complete_rx(ep, x_entry);
+		fastlock_release(&ep->util_ep.rx_cq->cq_lock);
 	}
-out:
-	rxd_ep_repost_buff(rx_buf);
 }
 
-/*
- * Discarded transfers were discarded by the receiving side, so we abort
- * transferring the rest of the data.  However, the completion is still
- * reported to the sender as successful.  This ensures that short and long
- * messages are treated the same, since short messages would be entirely
- * buffered at the receiver, with no notification that the application later
- * discarded the message.
- */
-static void rxd_handle_discard(struct rxd_ep *ep, struct ofi_ctrl_hdr *ctrl,
-			       struct rxd_rx_buf *rx_buf)
+static void rxd_verify_active(struct rxd_ep *ep, fi_addr_t addr, fi_addr_t peer_addr)
 {
-	struct rxd_tx_entry *tx_entry;
-	uint64_t idx;
+	struct rxd_pkt_entry *pkt_entry;
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-	       "discard- msg_id: %" PRIu64 ", segno: %d\n",
-	       ctrl->msg_id, ctrl->seg_no);
-
-	idx = ctrl->msg_id & RXD_TX_IDX_BITS;
-	tx_entry = &ep->tx_entry_fs->buf[idx];
-	if (tx_entry->msg_id == ctrl->msg_id) {
-		rxd_cq_report_tx_comp(rxd_ep_tx_cq(ep), tx_entry);
-		rxd_cntr_report_tx_comp(ep, tx_entry);
-		rxd_tx_entry_done(ep, tx_entry);
+	if (ep->peers[addr].peer_addr == peer_addr &&
+	    ep->peers[addr].peer_addr != FI_ADDR_UNSPEC)
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
+			"overwriting active peer - unexpected behavior\n");
+
+	ep->peers[addr].peer_addr = peer_addr;
+
+	if (!dlist_empty(&ep->peers[addr].unacked) && 
+	    rxd_get_base_hdr(container_of((&ep->peers[addr].unacked)->next,
+			     struct rxd_pkt_entry, d_entry))->type == RXD_RTS) {
+		dlist_pop_front(&ep->peers[addr].unacked,
+				struct rxd_pkt_entry, pkt_entry, d_entry);
+		if (pkt_entry->flags & RXD_PKT_IN_USE) {
+			dlist_insert_tail(&pkt_entry->d_entry, &ep->ctrl_pkts);
+			pkt_entry->flags |= RXD_PKT_ACKED;
+		} else {
+			rxd_release_tx_pkt(ep, pkt_entry);
+			ep->peers[addr].unacked_cnt--;
+		}
+		dlist_remove(&ep->peers[addr].entry);
 	}
 
-	rxd_ep_repost_buff(rx_buf);
+	if (!ep->peers[addr].active) {
+		dlist_insert_tail(&ep->peers[addr].entry, &ep->active_peers);
+		ep->peers[addr].retry_cnt = 0;
+		ep->peers[addr].active = 1;
+	}
 }
 
-void rxd_tx_pkt_free(struct rxd_pkt_meta *pkt_meta)
+static int rxd_move_tx_pkt(struct rxd_ep *ep, struct rxd_x_entry *tx_entry)
 {
-	util_buf_release(pkt_meta->ep->tx_pkt_pool, pkt_meta);
+	struct rxd_base_hdr *hdr = rxd_get_base_hdr(tx_entry->pkt);
+
+	if (ep->peers[tx_entry->peer].unacked_cnt >= rxd_env.max_unacked)
+		return 0;
+
+	tx_entry->start_seq = rxd_set_pkt_seq(&ep->peers[tx_entry->peer],
+					      tx_entry->pkt);
+	if (tx_entry->op != RXD_READ_REQ && tx_entry->num_segs > 1) {
+		ep->peers[tx_entry->peer].tx_seq_no = tx_entry->start_seq +
+						      tx_entry->num_segs;
+	}
+	hdr->peer = ep->peers[tx_entry->peer].peer_addr;
+	rxd_insert_unacked(ep, tx_entry->peer, tx_entry->pkt);
+	tx_entry->pkt = NULL;
+
+	if (tx_entry->op == RXD_READ_REQ || tx_entry->op == RXD_ATOMIC_FETCH ||
+	    tx_entry->op == RXD_ATOMIC_COMPARE) {
+		dlist_remove(&tx_entry->entry);
+		dlist_insert_tail(&tx_entry->entry,
+				  &ep->peers[tx_entry->peer].rma_rx_list);
+	}
+
+	return ep->peers[tx_entry->peer].unacked_cnt < rxd_env.max_unacked;
 }
 
-void rxd_tx_entry_done(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry)
+void rxd_progress_tx_list(struct rxd_ep *ep, struct rxd_peer *peer)
 {
-	struct rxd_pkt_meta *pkt_meta;
-
-	while (!dlist_empty(&tx_entry->pkt_list)) {
-		pkt_meta = container_of(tx_entry->pkt_list.next,
-					struct rxd_pkt_meta, entry);
-		dlist_remove(&pkt_meta->entry);
-		if (pkt_meta->flags & RXD_LOCAL_COMP)
-			rxd_tx_pkt_free(pkt_meta);
-		else
-			pkt_meta->flags |= RXD_REMOTE_ACK;
+	struct dlist_entry *tmp_entry;
+	struct rxd_x_entry *tx_entry;
+	uint64_t head_seq = peer->last_rx_ack;
+
+	if (!dlist_empty(&peer->unacked)) {
+		head_seq = rxd_get_base_hdr(container_of(
+					    (&peer->unacked)->next,
+					    struct rxd_pkt_entry, d_entry))->seq_no;
 	}
-	rxd_tx_entry_free(ep, tx_entry);
+
+	if (peer->peer_addr == FI_ADDR_UNSPEC)
+		return;
+
+	dlist_foreach_container_safe(&peer->tx_list, struct rxd_x_entry,
+				tx_entry, entry, tmp_entry) {
+		if (tx_entry->pkt) {
+			if (!rxd_move_tx_pkt(ep, tx_entry) ||
+			    tx_entry->op == RXD_READ_REQ)
+				break;
+		}
+
+		if (tx_entry->bytes_done == tx_entry->cq_entry.len) {
+			if (ofi_before(tx_entry->start_seq + (tx_entry->num_segs - 1),
+			    head_seq)) {
+				if (tx_entry->op == RXD_DATA_READ) {
+					fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
+					rxd_complete_rx(ep, tx_entry);
+					fastlock_release(&ep->util_ep.rx_cq->cq_lock);
+				} else {
+					fastlock_acquire(&ep->util_ep.tx_cq->cq_lock);
+					rxd_complete_tx(ep, tx_entry);
+					fastlock_release(&ep->util_ep.tx_cq->cq_lock);
+				}
+			}
+			continue;
+		}
+
+		if (!rxd_ep_post_data_pkts(ep, tx_entry))
+			break;
+	}
+
+	if (dlist_empty(&peer->tx_list))
+		peer->retry_cnt = 0;
 }
 
-static int rxd_conn_msg_match(struct dlist_entry *item, const void *arg)
+static void rxd_update_peer(struct rxd_ep *ep, fi_addr_t peer, fi_addr_t peer_addr)
 {
-	struct rxd_tx_entry *tx_entry;
-	struct ofi_ctrl_hdr *ctrl = (struct ofi_ctrl_hdr *) arg;
-	tx_entry = container_of(item, struct rxd_tx_entry, entry);
-	return (tx_entry->op_type == RXD_TX_CONN &&
-		tx_entry->peer == ctrl->rx_key);
+	rxd_verify_active(ep, peer, peer_addr);
+	rxd_progress_tx_list(ep, &ep->peers[peer]);
 }
 
-static void rxd_handle_connect_ack(struct rxd_ep *ep, struct ofi_ctrl_hdr *ctrl,
-				   struct rxd_rx_buf *rx_buf)
+static int rxd_send_cts(struct rxd_ep *rxd_ep, struct rxd_rts_pkt *rts_pkt,
+			fi_addr_t peer)
 {
-	struct rxd_peer *peer;
-	struct dlist_entry *match;
-	struct rxd_tx_entry *tx_entry;
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_cts_pkt *cts;
+	int ret = 0;
 
-	FI_INFO(&rxd_prov, FI_LOG_EP_CTRL,
-		"connect ack- msg_id: %" PRIu64 ", segno: %d\n",
-		ctrl->msg_id, ctrl->seg_no);
+	rxd_update_peer(rxd_ep, peer, rts_pkt->rts_addr);
 
-	match = dlist_find_first_match(&ep->tx_entry_list,
-					rxd_conn_msg_match, ctrl);
-	if (!match) {
-		FI_INFO(&rxd_prov, FI_LOG_EP_CTRL, "no matching connect\n");
-		goto out;
-	}
+	pkt_entry = rxd_get_tx_pkt(rxd_ep);
+	if (!pkt_entry)
+		return -FI_ENOMEM;
 
-	tx_entry = container_of(match, struct rxd_tx_entry, entry);
-	peer = rxd_ep_getpeer_info(ep, tx_entry->peer);
-	peer->state = CMAP_CONNECTED;
-	peer->conn_data = ctrl->conn_id;
+	cts = (struct rxd_cts_pkt *) (pkt_entry->pkt);
+	pkt_entry->pkt_size = sizeof(*cts) + rxd_ep->tx_prefix_size;
+	pkt_entry->peer = peer;
 
-	dlist_remove(match);
-	rxd_tx_entry_done(ep, tx_entry);
-out:
-	rxd_ep_repost_buff(rx_buf);
-}
+	cts->base_hdr.version = RXD_PROTOCOL_VERSION;
+	cts->base_hdr.type = RXD_CTS;
+	cts->cts_addr = peer;
+	cts->rts_addr = rts_pkt->rts_addr;
 
-static void rxd_set_rx_credits(struct rxd_ep *ep, struct rxd_rx_entry *rx_entry)
-{
-	size_t num_pkts, avail, size_left;
-
-	size_left = rx_entry->op_hdr.size - rx_entry->done;
-	num_pkts = (size_left + rxd_ep_domain(ep)->max_mtu_sz - 1) /
-		    rxd_ep_domain(ep)->max_mtu_sz;
-	avail = MIN(ep->credits, num_pkts);
-	rx_entry->credits = MIN(avail, RXD_MAX_RX_CREDITS);
-	rx_entry->last_win_seg += rx_entry->credits;
-	ep->credits -= rx_entry->credits;
+	dlist_insert_tail(&pkt_entry->d_entry, &rxd_ep->ctrl_pkts);
+	ret = rxd_ep_retry_pkt(rxd_ep, pkt_entry);
+	if (ret) {
+		dlist_remove(&pkt_entry->d_entry);
+		rxd_release_tx_pkt(rxd_ep, pkt_entry);
+	}
+
+	return ret;
 }
 
-static struct rxd_rx_entry *rxd_rx_entry_alloc(struct rxd_ep *ep)
+static int rxd_match_msg(struct dlist_entry *item, const void *arg)
 {
-	struct rxd_rx_entry *rx_entry;
+	struct rxd_match_attr *attr = (struct rxd_match_attr *) arg;
+	struct rxd_x_entry *rx_entry;
 
-	if (freestack_isempty(ep->rx_entry_fs))
-		return NULL;
+	rx_entry = container_of(item, struct rxd_x_entry, entry);
 
-	rx_entry = freestack_pop(ep->rx_entry_fs);
-	rx_entry->key = rx_entry - &ep->rx_entry_fs->buf[0];
-	dlist_insert_tail(&rx_entry->entry, &ep->rx_entry_list);
-	return rx_entry;
+	return rxd_match_addr(rx_entry->peer, attr->peer);
 }
 
-static void rxd_progress_wait_rx(struct rxd_ep *ep,
-				 struct rxd_rx_entry *rx_entry)
+static int rxd_match_tmsg(struct dlist_entry *item, const void *arg)
 {
-	struct ofi_ctrl_hdr ctrl;
+	struct rxd_match_attr *attr = (struct rxd_match_attr *) arg;
+	struct rxd_x_entry *rx_entry;
 
-	rxd_set_rx_credits(ep, rx_entry);
-	if (!rx_entry->credits)
-		return;
+	rx_entry = container_of(item, struct rxd_x_entry, entry);
 
-	dlist_remove(&rx_entry->wait_entry);
+	return rxd_match_addr(rx_entry->peer, attr->peer) &&
+	       rxd_match_tag(rx_entry->cq_entry.tag, rx_entry->ignore,
+			     attr->tag);
+}
 
-	ctrl.msg_id = rx_entry->msg_id;
-	ctrl.seg_no = rx_entry->exp_seg_no - 1;
-	ctrl.conn_id = rx_entry->peer;
+static void rxd_check_post_unexp(struct rxd_ep *ep, struct dlist_entry *list,
+				 struct rxd_pkt_entry *pkt_entry)
+{
+	struct rxd_pkt_entry *unexp_entry;
+	struct rxd_base_hdr *new_hdr = rxd_get_base_hdr(pkt_entry);
+	struct rxd_base_hdr *unexp_hdr;
+
+	if (!rxd_env.retry)
+		goto insert;
+
+	dlist_foreach_container(list, struct rxd_pkt_entry, unexp_entry, d_entry) {
+		unexp_hdr = rxd_get_base_hdr(unexp_entry);
+		if (unexp_hdr->seq_no == new_hdr->seq_no &&
+		    unexp_hdr->peer == new_hdr->peer) {
+			rxd_release_repost_rx(ep, pkt_entry);
+			return;
+		}
+	}
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-	       "rx-entry wait over [%" PRIx64 "], credits: %d\n",
-	       rx_entry->msg_id, rx_entry->credits);
-	rxd_ep_reply_ack(ep, &ctrl, ofi_ctrl_ack, rx_entry->credits,
-		       rx_entry->key, rx_entry->peer_info->conn_data,
-		       ctrl.conn_id);
+insert:
+	dlist_insert_tail(&pkt_entry->d_entry, list);
 }
 
-static void rxd_check_waiting_rx(struct rxd_ep *ep)
+static void rxd_handle_rts(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
 {
-	struct dlist_entry *entry;
-	struct rxd_rx_entry *rx_entry;
+	struct rxd_av *rxd_av;
+	struct ofi_rbnode *node;
+	fi_addr_t rxd_addr;
+	struct rxd_rts_pkt *pkt = (struct rxd_rts_pkt *) (pkt_entry->pkt);
+	int ret;
 
-	if (!ep->credits)
-		return;
+	rxd_av = rxd_ep_av(ep);
+	node = ofi_rbmap_find(&rxd_av->rbmap, pkt->source);
+
+	if (node) {
+		rxd_addr = (fi_addr_t) node->data;
+	} else {
+		ret = rxd_av_insert_dg_addr(rxd_av, (void *) pkt->source,
+					    &rxd_addr, 0, NULL);
+		if (ret)
+			return;
+	}
 
-	while(!dlist_empty(&ep->wait_rx_list) && ep->credits) {
-		entry = ep->wait_rx_list.next;
-		rx_entry = container_of(entry, struct rxd_rx_entry, wait_entry);
-		rxd_progress_wait_rx(ep, rx_entry);
+	if (rxd_send_cts(ep, pkt, rxd_addr)) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
+			"error posting CTS\n");
 	}
 }
 
-void rxd_rx_entry_free(struct rxd_ep *ep, struct rxd_rx_entry *rx_entry)
+struct rxd_x_entry *rxd_progress_multi_recv(struct rxd_ep *ep,
+					   struct rxd_x_entry *rx_entry,
+					   size_t total_size)
 {
-	rx_entry->key = -1;
-	dlist_remove(&rx_entry->entry);
-	freestack_push(ep->rx_entry_fs, rx_entry);
+	struct rxd_x_entry *dup_entry;
+	size_t left;
+	uint32_t dup_id;
 
-	if (ep->credits && !dlist_empty(&ep->wait_rx_list))
-		rxd_check_waiting_rx(ep);
-}
+	left = rx_entry->iov[0].iov_len - total_size;
 
-static int rxd_match_recv_entry(struct dlist_entry *item, const void *arg)
-{
-	const struct rxd_rx_entry *rx_entry = arg;
-	struct rxd_recv_entry *recv_entry;
+	if (left < ep->min_multi_recv_size) {
+		rx_entry->cq_entry.flags |= FI_MULTI_RECV;
+		return NULL;
+	}
 
-	recv_entry = container_of(item, struct rxd_recv_entry, entry);
-	return (recv_entry->msg.addr == FI_ADDR_UNSPEC ||
-		rx_entry->source == FI_ADDR_UNSPEC ||
-		recv_entry->msg.addr == rx_entry->source);
+	dup_entry = rxd_get_rx_entry(ep);
+	if (!dup_entry) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "could not get rx entry\n");
+		return NULL;
+	}
+	dup_id = dup_entry->rx_id;
+	memcpy(dup_entry, rx_entry, sizeof(*rx_entry));
+	dup_entry->rx_id = dup_id;
+	dup_entry->iov[0].iov_base = rx_entry->iov[0].iov_base;
+	dup_entry->iov[0].iov_len = total_size;
+	dup_entry->cq_entry.len = total_size;
+
+	rx_entry->iov[0].iov_base = (char *) rx_entry->iov[0].iov_base + total_size;
+	rx_entry->cq_entry.buf = rx_entry->iov[0].iov_base;
+	rx_entry->iov[0].iov_len = left;
+	rx_entry->cq_entry.len = left;
+
+	return dup_entry;
 }
 
-struct rxd_recv_entry *rxd_get_recv_entry(struct rxd_ep *ep,
-					  struct rxd_rx_entry *rx_entry)
+static struct rxd_x_entry *rxd_match_rx(struct rxd_ep *ep,
+					struct rxd_pkt_entry *pkt_entry,
+					struct rxd_base_hdr *base,
+					struct rxd_tag_hdr *tag,
+					struct rxd_sar_hdr *op, size_t msg_size)
 {
+	struct rxd_x_entry *rx_entry, *dup_entry;
+	struct dlist_entry *rx_list;
+	struct dlist_entry *unexp_list;
 	struct dlist_entry *match;
-	struct rxd_recv_entry *recv_entry;
+	struct rxd_match_attr attr;
+	size_t total_size;
+
+	attr.peer = base->peer;
+
+	if (tag) {
+		attr.tag = tag->tag;
+		rx_list = &ep->rx_tag_list;
+		match = dlist_find_first_match(rx_list, &rxd_match_tmsg,
+					 (void *) &attr);
+		unexp_list = &ep->unexp_tag_list;
+	} else {
+		attr.tag = 0;
+		rx_list = &ep->rx_list;
+		match = dlist_find_first_match(rx_list, &rxd_match_msg,
+					 (void *) &attr);
+		unexp_list = &ep->unexp_list;
+	}
 
-	match = dlist_find_first_match(&ep->recv_list, &rxd_match_recv_entry,
-				       (void *) rx_entry);
 	if (!match) {
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "no matching recv entry\n");
+		rxd_check_post_unexp(ep, unexp_list, pkt_entry);
 		return NULL;
 	}
 
-	dlist_remove(match);
-	recv_entry = container_of(match, struct rxd_recv_entry, entry);
-	return recv_entry;
+	rx_entry = container_of(match, struct rxd_x_entry, entry);
+
+	total_size = op ? op->size : msg_size;
+	if (rx_entry->flags & RXD_CANCELLED)
+		goto out;
+
+	if (rx_entry->flags & RXD_MULTI_RECV) {
+		dup_entry = rxd_progress_multi_recv(ep, rx_entry, total_size);
+		if (!dup_entry)
+			goto out;
+
+		dup_entry->start_seq = base->seq_no;
+		dlist_init(&dup_entry->entry);
+		return dup_entry;
+	}
+
+out:
+	dlist_remove(&rx_entry->entry);
+	rx_entry->cq_entry.len = MIN(rx_entry->cq_entry.len, total_size);
+	return rx_entry;
 }
 
-static int rxd_match_trecv_entry(struct dlist_entry *item, const void *arg)
+static int rxd_verify_iov(struct rxd_ep *ep, struct ofi_rma_iov *rma,
+			  size_t count, uint32_t type, struct iovec *iov)
 {
-	const struct rxd_rx_entry *rx_entry = arg;
-	struct rxd_trecv_entry *trecv_entry;
-
-	trecv_entry = container_of(item, struct rxd_trecv_entry, entry);
-	return ((trecv_entry->msg.tag | trecv_entry->msg.ignore) ==
-		(rx_entry->op_hdr.tag | trecv_entry->msg.ignore) &&
-                ((trecv_entry->msg.addr == FI_ADDR_UNSPEC) ||
-		 (rx_entry->source == FI_ADDR_UNSPEC) ||
-                 (trecv_entry->msg.addr == rx_entry->source)));
+	struct util_domain *util_domain = &rxd_ep_domain(ep)->util_domain;
+	int i, ret;
+
+	for (i = 0; i < count; i++) {
+		ret = ofi_mr_verify(&util_domain->mr_map, rma[i].len,
+			(uintptr_t *)(&rma[i].addr), rma[i].key,
+			ofi_rx_mr_reg_flags(type, 0));
+		iov[i].iov_base = (void *) rma[i].addr;
+		iov[i].iov_len = rma[i].len;
+		if (ret) {
+			FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "could not verify MR\n");
+			return -FI_EACCES; 
+		}
+	}
 	return 0;
 }
 
-struct rxd_trecv_entry *rxd_get_trecv_entry(struct rxd_ep *ep,
-					    struct rxd_rx_entry *rx_entry)
+static struct rxd_x_entry *rxd_rma_read_entry_init(struct rxd_ep *ep,
+			struct rxd_base_hdr *base_hdr, struct rxd_sar_hdr *sar_hdr,
+			struct rxd_rma_hdr *rma_hdr)
 {
-	struct dlist_entry *match;
-	struct rxd_trecv_entry *trecv_entry;
+	struct rxd_x_entry *rx_entry;
+	struct rxd_domain *rxd_domain = rxd_ep_domain(ep);
+	int ret;
 
-	match = dlist_find_first_match(&ep->trecv_list, &rxd_match_trecv_entry,
-				       (void *)rx_entry);
-	if (!match) {
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-		       "no matching trecv entry, tag: %" PRIx64 "\n",
-		       rx_entry->op_hdr.tag);
+	rx_entry = rxd_get_rx_entry(ep);
+	if (!rx_entry) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "could not get rx entry\n");
 		return NULL;
 	}
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "matched - tag: %" PRIx64 "\n",
-	       rx_entry->op_hdr.tag);
+	rx_entry->tx_id = sar_hdr->tx_id;
+	rx_entry->op = RXD_DATA_READ;
+	rx_entry->peer = base_hdr->peer;
+	rx_entry->flags = RXD_NO_TX_COMP;
+	rx_entry->bytes_done = 0;
+	rx_entry->next_seg_no = 0;
+	rx_entry->num_segs = ofi_div_ceil(sar_hdr->size, rxd_domain->max_seg_sz);
+	rx_entry->pkt = NULL;
+
+ 	ret = rxd_verify_iov(ep, rma_hdr->rma, sar_hdr->iov_count,
+			     base_hdr->type, rx_entry->iov);
+	if (ret)
+		return NULL;
+
+	rx_entry->iov_count = sar_hdr->iov_count;
+	rx_entry->cq_entry.flags = ofi_rx_cq_flags(ofi_op_read_req);
+	rx_entry->cq_entry.len = sar_hdr->size;
+
+	dlist_insert_tail(&rx_entry->entry, &ep->peers[rx_entry->peer].tx_list);
 
-	dlist_remove(match);
-	trecv_entry = container_of(match, struct rxd_trecv_entry, entry);
-	trecv_entry->rx_entry = rx_entry;
-	return trecv_entry;
+	rxd_progress_tx_list(ep, &ep->peers[rx_entry->peer]);
+
+	return rx_entry;
 }
 
-void rxd_cq_report_error(struct rxd_cq *cq, struct fi_cq_err_entry *err_entry)
+static struct rxd_x_entry *rxd_rma_rx_entry_init(struct rxd_ep *ep,
+			struct rxd_base_hdr *base_hdr, struct rxd_sar_hdr *sar_hdr,
+			struct rxd_rma_hdr *rma_hdr)
 {
-	struct fi_cq_tagged_entry cq_entry = {0};
-	struct util_cq_err_entry *entry = calloc(1, sizeof(*entry));
-	if (!entry) {
-		FI_WARN(&rxd_prov, FI_LOG_CQ,
-			"out of memory, cannot report CQ error\n");
-		return;
-	}
+	struct rxd_x_entry *rx_entry;
+	struct iovec iov[RXD_IOV_LIMIT];
+	int ret, iov_count;
 
-	entry->err_entry = *err_entry;
-	slist_insert_tail(&entry->list_entry, &cq->util_cq.err_list);
-	cq_entry.flags = UTIL_FLAG_ERROR;
-	cq->write_fn(cq, &cq_entry);
+	iov_count = sar_hdr ? sar_hdr->iov_count : 1;
+	ret = rxd_verify_iov(ep, rma_hdr->rma, iov_count,
+			     base_hdr->type, iov);
+	if (ret)
+		return NULL;
+
+	rx_entry = rxd_rx_entry_init(ep, iov, iov_count, 0, 0, NULL,
+				     base_hdr->peer, base_hdr->type,
+				     base_hdr->flags);
+	if (!rx_entry)
+		return NULL;
+
+	rx_entry->start_seq = base_hdr->seq_no;
+
+	return rx_entry;
 }
 
-void rxd_cq_report_tx_comp(struct rxd_cq *cq, struct rxd_tx_entry *tx_entry)
+static struct rxd_x_entry *rxd_rx_atomic_fetch(struct rxd_ep *ep,
+			struct rxd_base_hdr *base_hdr,
+			struct rxd_sar_hdr *sar_hdr,
+			struct rxd_rma_hdr *rma_hdr,
+			struct rxd_atom_hdr *atom_hdr)
 {
-	struct fi_cq_tagged_entry cq_entry = {0};
+	struct rxd_x_entry *rx_entry;
+	int ret;
 
-	/* todo: handle FI_COMPLETION */
-	switch(tx_entry->op_type) {
-	case RXD_TX_MSG:
-		cq_entry.flags = (FI_TRANSMIT | FI_MSG);
-		cq_entry.op_context = tx_entry->msg.msg.context;
-		cq_entry.len = tx_entry->op_hdr.size;
-		cq_entry.buf = tx_entry->msg.msg_iov[0].iov_base;
-		cq_entry.data = tx_entry->op_hdr.data;
-		break;
-	case RXD_TX_TAG:
-		cq_entry.flags = (FI_TRANSMIT | FI_TAGGED);
-		cq_entry.op_context = tx_entry->tmsg.tmsg.context;
-		cq_entry.len = tx_entry->op_hdr.size;
-		cq_entry.buf = tx_entry->tmsg.msg_iov[0].iov_base;
-		cq_entry.data = tx_entry->op_hdr.data;
-		cq_entry.tag = tx_entry->tmsg.tmsg.tag;
-		break;
-	case RXD_TX_WRITE:
-		cq_entry.flags = (FI_TRANSMIT | FI_RMA | FI_WRITE);
-		cq_entry.op_context = tx_entry->write.msg.context;
-		cq_entry.len = tx_entry->op_hdr.size;
-		cq_entry.buf = tx_entry->write.msg.msg_iov[0].iov_base;
-		cq_entry.data = tx_entry->op_hdr.data;
-		break;
-	case RXD_TX_READ_REQ:
-		cq_entry.flags = (FI_TRANSMIT | FI_RMA | FI_READ);
-		cq_entry.op_context = tx_entry->read_req.msg.context;
-		cq_entry.len = tx_entry->op_hdr.size;
-		cq_entry.buf = tx_entry->read_req.msg.msg_iov[0].iov_base;
-		cq_entry.data = tx_entry->op_hdr.data;
-		break;
-	case RXD_TX_READ_RSP:
-		return;
-	default:
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "invalid op type\n");
-		return;
+	rx_entry = rxd_get_rx_entry(ep);
+	if (!rx_entry) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "could not get tx entry\n");
+		return NULL;
 	}
 
-	cq->write_fn(cq, &cq_entry);
+	rx_entry->pkt = rxd_get_tx_pkt(ep);
+	if (!rx_entry->pkt) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "could not get pkt\n");
+		rxd_rx_entry_free(ep, rx_entry);
+		return NULL;
+	}
+	rx_entry->tx_id = sar_hdr->tx_id;
+
+	rx_entry->op = RXD_DATA_READ;
+	rx_entry->peer = base_hdr->peer;
+	rx_entry->flags = RXD_NO_TX_COMP;
+	rx_entry->bytes_done = 0;
+	rx_entry->next_seg_no = 0;
+	rx_entry->num_segs = 1;
+
+	rx_entry->iov_count = sar_hdr->iov_count;
+ 	ret = rxd_verify_iov(ep, rma_hdr->rma, rx_entry->iov_count,
+			     base_hdr->type, rx_entry->iov);
+	if (ret)
+		return NULL;
+
+	rx_entry->cq_entry.flags = ofi_rx_cq_flags(ofi_op_atomic_fetch);
+	rx_entry->cq_entry.len = sar_hdr->size;
+
+	rxd_init_data_pkt(ep, rx_entry, rx_entry->pkt);
+	if (rx_entry->bytes_done != rx_entry->cq_entry.len)
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "fetch data length mismatch\n");
+
+	dlist_insert_tail(&rx_entry->entry, &ep->peers[rx_entry->peer].tx_list);
+
+	rxd_ep_send_ack(ep, base_hdr->peer);
+
+	rxd_progress_tx_list(ep, &ep->peers[rx_entry->peer]);
+
+	return rx_entry;
 }
 
-void rxd_ep_handle_data_msg(struct rxd_ep *ep, struct rxd_peer *peer,
-			   struct rxd_rx_entry *rx_entry,
-			   struct iovec *iov, size_t iov_count,
-			   struct ofi_ctrl_hdr *ctrl, void *data,
-			   struct rxd_rx_buf *rx_buf)
+void rxd_unpack_hdrs(size_t pkt_size, struct rxd_base_hdr *base_hdr,
+		     struct rxd_sar_hdr **sar_hdr, struct rxd_tag_hdr **tag_hdr,
+		     struct rxd_data_hdr **data_hdr, struct rxd_rma_hdr **rma_hdr,
+		     struct rxd_atom_hdr **atom_hdr, void **msg, size_t *msg_size)
 {
-	struct fi_cq_tagged_entry cq_entry = {0};
-	struct util_cntr *cntr = NULL;
-	uint64_t done;
-	struct rxd_cq *rxd_rx_cq = rxd_ep_rx_cq(ep);
-
-	ep->credits++;
-	done = ofi_copy_to_iov(iov, iov_count, rx_entry->done, data,
-				ctrl->seg_size);
-	rx_entry->done += done;
-	rx_entry->credits--;
-	rx_entry->exp_seg_no++;
-
-	if (done != ctrl->seg_size) {
-		/* todo: generate truncation error */
-		/* inform peer */
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "TODO: message truncated\n");
-	}
+	char *ptr = (char *) base_hdr + sizeof(*base_hdr);
+	uint8_t rma_count = 1;
 
-	if (rx_entry->credits == 0) {
-		rxd_set_rx_credits(ep, rx_entry);
+	if (!(base_hdr->flags & RXD_INLINE)) {
+		*sar_hdr = (struct rxd_sar_hdr *) ptr;
+		rma_count = (*sar_hdr)->iov_count;
+		ptr += sizeof(**sar_hdr);
+	} else {
+		*sar_hdr = NULL;
+	}
 
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "replying ack [%" PRIx64 "] - %d\n",
-		       ctrl->msg_id, ctrl->seg_no);
+	if (base_hdr->flags & RXD_TAG_HDR) {
+		*tag_hdr = (struct rxd_tag_hdr *) ptr;
+		ptr += sizeof(**tag_hdr);
+	} else {
+		*tag_hdr = NULL;
+	}
 
-		rxd_ep_reply_ack(ep, ctrl, ofi_ctrl_ack, rx_entry->credits,
-			       rx_entry->key, peer->conn_data, ctrl->conn_id);
+	if (base_hdr->flags & RXD_REMOTE_CQ_DATA) {
+		*data_hdr = (struct rxd_data_hdr *) ptr;
+		ptr += sizeof(**data_hdr);
+	} else {
+		*data_hdr = NULL;
 	}
 
-	if (rx_entry->op_hdr.size != rx_entry->done) {
-		if (rx_entry->credits == 0) {
-			dlist_init(&rx_entry->wait_entry);
-			dlist_insert_tail(&rx_entry->wait_entry, &ep->wait_rx_list);
-			FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "rx-entry %" PRIx64 " - %d enqueued\n",
-				ctrl->msg_id, ctrl->seg_no);
+	if (base_hdr->type >= RXD_READ_REQ && base_hdr->type <= RXD_ATOMIC_COMPARE) {
+		*rma_hdr = (struct rxd_rma_hdr *) ptr;
+		ptr += (sizeof(*(*rma_hdr)->rma) * rma_count);
+
+		if (base_hdr->type >= RXD_ATOMIC) {
+			*atom_hdr = (struct rxd_atom_hdr *) ptr;
+			ptr += sizeof(**atom_hdr);
 		} else {
-			FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-			       "rx_entry->op_hdr.size: %" PRIu64 ", rx_entry->done: %" PRId64 "\n",
-			       rx_entry->op_hdr.size,
-			       rx_entry->done);
+			*atom_hdr = NULL;
 		}
-		return;
+	} else {
+		*rma_hdr = NULL;
+		*atom_hdr = NULL;
 	}
 
-	/* todo: handle FI_COMPLETION for RX CQ comp */
-	switch(rx_entry->op_hdr.op) {
-	case ofi_op_msg:
-		freestack_push(ep->recv_fs, rx_entry->recv);
-		/* Handle cntr */
-		cntr = ep->util_ep.rx_cntr;
-		/* Handle CQ comp */
-		cq_entry.flags |= FI_RECV;
-		cq_entry.op_context = rx_entry->recv->msg.context;
-		cq_entry.len = rx_entry->done;
-		cq_entry.buf = rx_entry->recv->iov[0].iov_base;
-		cq_entry.data = rx_entry->op_hdr.data;
-		rxd_rx_cq->write_fn(rxd_rx_cq, &cq_entry);
-		break;
-	case ofi_op_tagged:
-		freestack_push(ep->trecv_fs, rx_entry->trecv);
-		/* Handle cntr */
-		cntr = ep->util_ep.rx_cntr;
-		/* Handle CQ comp */
-		cq_entry.flags |= (FI_RECV | FI_TAGGED);
-		cq_entry.op_context = rx_entry->trecv->msg.context;
-		cq_entry.len = rx_entry->done;
-		cq_entry.buf = rx_entry->trecv->iov[0].iov_base;
-		cq_entry.data = rx_entry->op_hdr.data;
-		cq_entry.tag = rx_entry->trecv->msg.tag;\
-		rxd_rx_cq->write_fn(rxd_rx_cq, &cq_entry);
-		break;
-	case ofi_op_atomic:
-		/* Handle cntr */
-		cntr = ep->util_ep.rem_wr_cntr;
-		/* Handle CQ comp */
-		cq_entry.flags |= FI_ATOMIC;
-		rxd_rx_cq->write_fn(rxd_rx_cq, &cq_entry);
-		break;
-	case ofi_op_write:
-		/* Handle cntr */
-		cntr = ep->util_ep.rem_wr_cntr;
-		/* Handle CQ comp */
-		if (rx_entry->op_hdr.flags & OFI_REMOTE_CQ_DATA) {
-			cq_entry.flags |= (FI_RMA | FI_REMOTE_WRITE);
-			cq_entry.op_context = rx_entry->trecv->msg.context;
-			cq_entry.len = rx_entry->done;
-			cq_entry.buf = rx_entry->write.iov[0].iov_base;
-			cq_entry.data = rx_entry->op_hdr.data;
-			rxd_rx_cq->write_fn(rxd_rx_cq, &cq_entry);
-		}
-		break;
-	case ofi_op_read_rsp:
-		rxd_cq_report_tx_comp(rxd_ep_tx_cq(ep), rx_entry->read_rsp.tx_entry);
-		rxd_cntr_report_tx_comp(ep, rx_entry->read_rsp.tx_entry);
-		rxd_tx_entry_done(ep, rx_entry->read_rsp.tx_entry);
-		break;
-	default:
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "invalid op type: %d\n",
-			rx_entry->op_hdr.op);
-		break;
+	if (pkt_size < (ptr - (char *) base_hdr)) {
+		FI_WARN(&rxd_prov, FI_LOG_CQ,
+			"Cannot process packet smaller than minimum header size\n");
+		*msg_size = 0;
+		return;
 	}
 
-	if (cntr)
-		cntr->cntr_fid.ops->add(&cntr->cntr_fid, 1);
-
-	rxd_rx_entry_free(ep, rx_entry);
+	*msg = ptr;
+	*msg_size = pkt_size - (ptr - (char *) base_hdr);
 }
 
-static int rxd_check_data_pkt_order(struct rxd_ep *ep,
-				     struct rxd_peer *peer,
-				     struct ofi_ctrl_hdr *ctrl,
-				     struct rxd_rx_entry *rx_entry)
+static struct rxd_x_entry *rxd_unpack_init_rx(struct rxd_ep *ep,
+					      struct rxd_pkt_entry *pkt_entry,
+					      struct rxd_base_hdr *base_hdr,
+					      struct rxd_sar_hdr **sar_hdr,
+					      struct rxd_tag_hdr **tag_hdr,
+					      struct rxd_data_hdr **data_hdr,
+					      struct rxd_rma_hdr **rma_hdr,
+					      struct rxd_atom_hdr **atom_hdr,
+					      void **msg, size_t *msg_size)
 {
-	if ((rx_entry->msg_id == ctrl->msg_id) &&
-	    (rx_entry->exp_seg_no == ctrl->seg_no))
-		return 0;
-
-	if ((rx_entry->msg_id != ctrl->msg_id) ||
-	    (rx_entry->exp_seg_no > ctrl->seg_no))
-		return -FI_EALREADY;
-
-	return -FI_EINVAL;
+	rxd_unpack_hdrs(pkt_entry->pkt_size - ep->rx_prefix_size, base_hdr, sar_hdr,
+			tag_hdr, data_hdr, rma_hdr, atom_hdr, msg, msg_size);
+
+	switch (base_hdr->type) {
+	case RXD_MSG:
+	case RXD_TAGGED:
+		return rxd_match_rx(ep, pkt_entry, base_hdr, *tag_hdr, *sar_hdr,
+				    *msg_size);
+	case RXD_READ_REQ:
+		return rxd_rma_read_entry_init(ep, base_hdr, *sar_hdr, *rma_hdr);
+	case RXD_ATOMIC_FETCH:
+	case RXD_ATOMIC_COMPARE:
+		return rxd_rx_atomic_fetch(ep, base_hdr, *sar_hdr, *rma_hdr, *atom_hdr);
+	default:
+		return rxd_rma_rx_entry_init(ep, base_hdr, *sar_hdr, *rma_hdr);
+	}
 }
 
-static int rxd_match_unexp_msg(struct dlist_entry *item, const void *arg)
+void rxd_do_atomic(void *src, void *dst, void *cmp, enum fi_datatype datatype,
+		   enum fi_op atomic_op, size_t cnt)
 {
-	const struct rxd_recv_entry *recv_entry = arg;
-	struct rxd_rx_entry *rx_entry;
+	char tmp_result[RXD_MAX_MTU_SIZE];
 
-	rx_entry = container_of(item, struct rxd_rx_entry, unexp_entry);
-	return (recv_entry->msg.addr == FI_ADDR_UNSPEC ||
-		rx_entry->source == FI_ADDR_UNSPEC ||
-		rx_entry->source == recv_entry->msg.addr);
+	if (atomic_op >= OFI_SWAP_OP_START) {
+		ofi_atomic_swap_handlers[atomic_op - OFI_SWAP_OP_START][datatype](dst,
+			src, cmp, tmp_result, cnt);
+	} else if (atomic_op != FI_ATOMIC_READ) {
+		ofi_atomic_write_handlers[atomic_op][datatype](dst, src, cnt);
+	}
 }
 
-void rxd_ep_check_unexp_msg_list(struct rxd_ep *ep, struct rxd_recv_entry *recv_entry)
+void rxd_progress_op_msg(struct rxd_ep *ep, struct rxd_x_entry *rx_entry,
+			 void **msg, size_t size)
 {
-	struct dlist_entry *match;
-	struct rxd_rx_entry *rx_entry;
-	struct rxd_pkt_data_start *pkt_start;
-
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "ep->num_unexp_msg: %d\n", ep->num_unexp_msg);
-	match = dlist_remove_first_match(&ep->unexp_msg_list, &rxd_match_unexp_msg,
-					 (void *) recv_entry);
-	if (match) {
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "progressing unexp msg entry\n");
-		dlist_remove(&recv_entry->entry);
-		ep->num_unexp_msg--;
-
-		rx_entry = container_of(match, struct rxd_rx_entry, unexp_entry);
-		rx_entry->recv = recv_entry;
-
-		pkt_start = (struct rxd_pkt_data_start *) rx_entry->unexp_buf->buf;
-		rxd_ep_handle_data_msg(ep, rx_entry->peer_info, rx_entry, rx_entry->recv->iov,
-				     rx_entry->recv->msg.iov_count, &pkt_start->ctrl,
-				     pkt_start->data, rx_entry->unexp_buf);
-		rxd_ep_repost_buff(rx_entry->unexp_buf);
-	}
+	rx_entry->bytes_done = ofi_copy_to_iov(rx_entry->iov,
+					       rx_entry->iov_count, 0, *msg, size);
 }
 
-static int rxd_match_unexp_tag(struct dlist_entry *item, const void *arg)
+void rxd_progress_atom_op(struct rxd_ep *ep, struct rxd_x_entry *rx_entry,
+			  struct rxd_base_hdr *base_hdr, struct rxd_sar_hdr *sar_hdr,
+			  struct rxd_rma_hdr *rma_hdr, struct rxd_atom_hdr *atom_hdr,
+			  void **msg, size_t msg_size)
 {
-	const struct rxd_trecv_entry *trecv_entry = arg;
-	struct rxd_rx_entry *rx_entry;
-
-	rx_entry = container_of(item, struct rxd_rx_entry, unexp_entry);
-	return ((trecv_entry->msg.tag | trecv_entry->msg.ignore) ==
-		(rx_entry->op_hdr.tag | trecv_entry->msg.ignore) &&
-		((trecv_entry->msg.addr == FI_ADDR_UNSPEC) ||
-		 (rx_entry->source == FI_ADDR_UNSPEC) ||
-		 (trecv_entry->msg.addr == rx_entry->source)));
+	char *src, *cmp;
+	size_t len;
+	int i, iov_count;
+
+	src = (char *) (*msg);
+	cmp = base_hdr->type == RXD_ATOMIC_COMPARE ? (char *) (*msg) +
+		(msg_size / 2) : NULL;
+
+	iov_count = sar_hdr ? sar_hdr->iov_count : 1;
+	for (i = len = 0; i < iov_count; i++) {
+		rxd_do_atomic(&src[len], rx_entry->iov[i].iov_base,
+			      cmp ? &cmp[len] : NULL, atom_hdr->datatype,
+			      atom_hdr->atomic_op, rx_entry->iov[i].iov_len /
+			      ofi_datatype_size(atom_hdr->datatype));
+		len += rx_entry->iov[i].iov_len;
+	}
+
+	if (base_hdr->type == RXD_ATOMIC)
+		rx_entry->bytes_done = len;
 }
 
-void rxd_ep_check_unexp_tag_list(struct rxd_ep *ep, struct rxd_trecv_entry *trecv_entry)
+void rxd_progress_op(struct rxd_ep *ep, struct rxd_x_entry *rx_entry,
+		     struct rxd_pkt_entry *pkt_entry,
+		     struct rxd_base_hdr *base_hdr,
+		     struct rxd_sar_hdr *sar_hdr,
+		     struct rxd_tag_hdr *tag_hdr,
+		     struct rxd_data_hdr *data_hdr,
+		     struct rxd_rma_hdr *rma_hdr,
+		     struct rxd_atom_hdr *atom_hdr,
+		     void **msg, size_t size)
 {
-	struct dlist_entry *match;
-	struct rxd_rx_entry *rx_entry;
-	struct rxd_pkt_data_start *pkt_start;
-
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "ep->num_unexp_msg: %d\n", ep->num_unexp_msg);
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "ep->num_unexp_pkt: %d\n", ep->num_unexp_pkt);
-	match = dlist_find_first_match(&ep->unexp_tag_list, &rxd_match_unexp_tag,
-				       (void *) trecv_entry);
-	if (match) {
-		dlist_remove(match);
-		dlist_remove(&trecv_entry->entry);
-		ep->num_unexp_msg--;
-
-		rx_entry = container_of(match, struct rxd_rx_entry, unexp_entry);
-		rx_entry->trecv = trecv_entry;
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "progressing unexp tagged recv [%" PRIx64 "]\n",
-		       rx_entry->msg_id);
-
-		pkt_start = (struct rxd_pkt_data_start *) rx_entry->unexp_buf->buf;
-		rxd_ep_handle_data_msg(ep, rx_entry->peer_info, rx_entry, rx_entry->trecv->iov,
-				     rx_entry->trecv->msg.iov_count, &pkt_start->ctrl,
-				     pkt_start->data, rx_entry->unexp_buf);
-		rxd_ep_repost_buff(rx_entry->unexp_buf);
+
+	if (rx_entry->flags & RXD_CANCELLED) {
+		rxd_complete_rx(ep, rx_entry);
+		ep->peers[base_hdr->peer].rx_seq_no += base_hdr->flags & RXD_INLINE ?
+				1 : sar_hdr->num_segs;
+		return;
+	}
+
+	ep->peers[base_hdr->peer].rx_seq_no++;
+	if (sar_hdr)
+		ep->peers[base_hdr->peer].curr_tx_id = sar_hdr->tx_id;
+
+	ep->peers[base_hdr->peer].curr_rx_id = rx_entry->rx_id;
+
+	if (base_hdr->type == RXD_READ_REQ)
+		return;
+
+	if (atom_hdr)
+		rxd_progress_atom_op(ep, rx_entry, base_hdr, sar_hdr,
+				     rma_hdr, atom_hdr, msg, size);
+	else
+		rxd_progress_op_msg(ep, rx_entry, msg, size);
+
+	rx_entry->offset = rx_entry->bytes_done;
+
+	if (data_hdr) {
+		rx_entry->cq_entry.flags |= FI_REMOTE_CQ_DATA;
+		rx_entry->cq_entry.data = data_hdr->cq_data;
 	}
+
+	rx_entry->peer = base_hdr->peer;
+
+	if (!sar_hdr || sar_hdr->num_segs == 1) {
+		if (!(rx_entry->cq_entry.flags & FI_REMOTE_READ))
+			rxd_complete_rx(ep, rx_entry);
+		return;
+	}
+
+	rx_entry->tx_id = sar_hdr->tx_id;
+	rx_entry->num_segs = sar_hdr->num_segs;
+	rx_entry->next_seg_no++;
+	rx_entry->start_seq = base_hdr->seq_no;
+
+	dlist_insert_tail(&rx_entry->entry, &ep->peers[base_hdr->peer].rx_list);
 }
 
-static void rxd_handle_data(struct rxd_ep *ep, struct rxd_peer *peer,
-			    struct ofi_ctrl_hdr *ctrl, struct fi_cq_msg_entry *comp,
-			    struct rxd_rx_buf *rx_buf)
+static struct rxd_x_entry *rxd_get_data_x_entry(struct rxd_ep *ep,
+			struct rxd_data_pkt *data_pkt)
 {
-	struct rxd_rx_entry *rx_entry;
-	struct rxd_tx_entry *tx_entry;
-	struct rxd_pkt_data *pkt_data = (struct rxd_pkt_data *) ctrl;
-	uint16_t credits;
-	int ret;
+	if (data_pkt->base_hdr.type == RXD_DATA)
+		return util_buf_get_by_index(ep->rx_entry_pool,
+			     ep->peers[data_pkt->base_hdr.peer].curr_rx_id);
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-	       "data pkt- msg_id: %" PRIu64 ", segno: %d, buf: %p\n",
-	       ctrl->msg_id, ctrl->seg_no, rx_buf);
-
-	rx_entry = &ep->rx_entry_fs->buf[ctrl->rx_key];
+	return util_buf_get_by_index(ep->tx_entry_pool, data_pkt->ext_hdr.tx_id);
+}
 
-	ret = rxd_check_data_pkt_order(ep, peer, ctrl, rx_entry);
-	if (ret) {
-		if (ret == -FI_EALREADY) {
-			FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "duplicate pkt: %d "
-			       "expected:%d, rx-key:%" PRId64 ", ctrl_msg_id: %" PRIx64 "\n",
-			       ctrl->seg_no, rx_entry->exp_seg_no,
-			       ctrl->rx_key,
-			       ctrl->msg_id);
-
-			credits = ((rx_entry->msg_id == ctrl->msg_id) &&
-				  (rx_entry->last_win_seg == ctrl->seg_no)) ?
-				  rx_entry->credits : 0;
-			rxd_ep_reply_ack(ep, ctrl, ofi_ctrl_ack, credits,
-				       ctrl->rx_key, peer->conn_data,
-				       ctrl->conn_id);
-			goto repost;
+static void rxd_progress_buf_pkts(struct rxd_ep *ep, fi_addr_t peer)
+{
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_base_hdr *base_hdr;
+	struct rxd_sar_hdr *sar_hdr;
+	struct rxd_tag_hdr *tag_hdr;
+	struct rxd_data_hdr *data_hdr;
+	struct rxd_rma_hdr *rma_hdr;
+	struct rxd_atom_hdr *atom_hdr;
+	void *msg;
+	size_t msg_size;
+	struct rxd_x_entry *rx_entry;
+	struct rxd_data_pkt *data_pkt;
+
+	while (!dlist_empty(&ep->peers[peer].buf_pkts)) {
+		pkt_entry = container_of((&ep->peers[peer].buf_pkts)->next,
+					struct rxd_pkt_entry, d_entry);
+		base_hdr = rxd_get_base_hdr(pkt_entry);
+		if (base_hdr->seq_no != ep->peers[peer].rx_seq_no)
+			return;
+
+		if (base_hdr->type == RXD_DATA || base_hdr->type == RXD_DATA_READ) {
+			data_pkt = (struct rxd_data_pkt *) (pkt_entry->pkt);
+			rx_entry = rxd_get_data_x_entry(ep, data_pkt);
+			rxd_ep_recv_data(ep, rx_entry, data_pkt, pkt_entry->pkt_size);
 		} else {
-			FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "invalid pkt: segno: %d "
-			       "expected:%d, rx-key:%" PRId64 ", ctrl_msg_id: %" PRIu64 ", "
-			       "rx_entry_msg_id: %" PRIx64 "\n",
-			       ctrl->seg_no, rx_entry->exp_seg_no,
-			       ctrl->rx_key,
-			       ctrl->msg_id, rx_entry->msg_id);
-			FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "invalid pkt: "
-			       "credits: %d, last win: %d\n",
-			       rx_entry->credits, rx_entry->last_win_seg);
-			credits = (rx_entry->msg_id == ctrl->msg_id) ?
-				  rx_entry->last_win_seg - rx_entry->exp_seg_no : 0;
-			rxd_ep_reply_ack(ep, ctrl, ofi_ctrl_ack, credits,
-				       ctrl->rx_key, peer->conn_data,
-				       ctrl->conn_id);
-			goto repost;
+			rx_entry = rxd_unpack_init_rx(ep, pkt_entry, base_hdr, &sar_hdr,
+					      &tag_hdr, &data_hdr, &rma_hdr, &atom_hdr,
+					      &msg, &msg_size);
+			if (!rx_entry)
+				break;
+
+			rxd_progress_op(ep, rx_entry, pkt_entry, base_hdr,
+					sar_hdr, tag_hdr, data_hdr, rma_hdr,
+					atom_hdr, &msg, msg_size);
 		}
+
+		dlist_remove(&pkt_entry->d_entry);
+		rxd_release_repost_rx(ep, pkt_entry);
 	}
+}
 
-	rx_entry->nack_stamp = 0;
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "expected pkt: %d\n", ctrl->seg_no);
-	switch (rx_entry->op_hdr.op) {
-	case ofi_op_msg:
-		rxd_ep_handle_data_msg(ep, peer, rx_entry, rx_entry->recv->iov,
-				     rx_entry->recv->msg.iov_count, ctrl,
-				     pkt_data->data, rx_buf);
-		break;
-	case ofi_op_tagged:
-		rxd_ep_handle_data_msg(ep, peer, rx_entry, rx_entry->trecv->iov,
-				     rx_entry->trecv->msg.iov_count, ctrl,
-				     pkt_data->data, rx_buf);
-		break;
-	case ofi_op_write:
-		rxd_ep_handle_data_msg(ep, peer, rx_entry, rx_entry->write.iov,
-				       rx_entry->op_hdr.iov_count, ctrl,
-				       pkt_data->data, rx_buf);
-		break;
-	case ofi_op_read_rsp:
-		tx_entry = rx_entry->read_rsp.tx_entry;
-		rxd_ep_handle_data_msg(ep, peer, rx_entry, tx_entry->read_req.dst_iov,
-				       tx_entry->read_req.msg.iov_count, ctrl,
-				       pkt_data->data, rx_buf);
-		break;
-	case ofi_op_atomic:
-	default:
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "invalid op type\n");
+static void rxd_handle_data(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
+{
+	struct rxd_data_pkt *pkt = (struct rxd_data_pkt *) (pkt_entry->pkt);
+	struct rxd_x_entry *x_entry;
+
+	if (pkt_entry->pkt_size < sizeof(*pkt) + ep->rx_prefix_size) {
+		FI_WARN(&rxd_prov, FI_LOG_CQ,
+			"Cannot process packet smaller than minimum header size\n");
+		return;
 	}
 
-repost:
-	rxd_ep_repost_buff(rx_buf);
+	if (pkt->base_hdr.seq_no == ep->peers[pkt->base_hdr.peer].rx_seq_no) {
+		x_entry = rxd_get_data_x_entry(ep, pkt);
+		rxd_ep_recv_data(ep, x_entry, pkt, pkt_entry->pkt_size);
+		if (!dlist_empty(&ep->peers[pkt->base_hdr.peer].buf_pkts))
+			rxd_progress_buf_pkts(ep, pkt->base_hdr.peer);
+	} else if (!rxd_env.retry) {
+		rxd_remove_rx_pkt(ep, pkt_entry);
+		dlist_insert_order(&ep->peers[pkt->base_hdr.peer].buf_pkts,
+				   &rxd_comp_pkt_seq_no, &pkt_entry->d_entry);
+		ep->peers[pkt->base_hdr.peer].rx_seq_no++;
+	} else {
+		rxd_ep_send_ack(ep, pkt->base_hdr.peer);
+	}
 }
 
-int rxd_process_start_data(struct rxd_ep *ep, struct rxd_rx_entry *rx_entry,
-			   struct rxd_peer *peer, struct ofi_ctrl_hdr *ctrl,
-			   struct fi_cq_msg_entry *comp,
-			   struct rxd_rx_buf *rx_buf)
+static void rxd_handle_op(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
 {
-	uint64_t idx;
-	int i, offset, ret;
-	struct ofi_rma_iov *rma_iov;
-	struct rxd_pkt_data_start *pkt_start;
-	struct rxd_tx_entry *tx_entry;
-	pkt_start = (struct rxd_pkt_data_start *) ctrl;
-
-	switch (rx_entry->op_hdr.op) {
-	case ofi_op_msg:
-		rx_entry->recv = rxd_get_recv_entry(ep, rx_entry);
-		if (!rx_entry->recv) {
-			if (ep->num_unexp_msg < RXD_EP_MAX_UNEXP_MSG) {
-				dlist_insert_tail(&rx_entry->unexp_entry, &ep->unexp_msg_list);
-				rx_entry->unexp_buf = rx_buf;
-				ep->num_unexp_msg++;
-				return -FI_ENOENT;
-			} else {
-				FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "dropping msg\n");
-				return -FI_ENOMEM;
-			}
+	struct rxd_x_entry *rx_entry;
+	struct rxd_base_hdr *base_hdr = rxd_get_base_hdr(pkt_entry);
+	struct rxd_sar_hdr *sar_hdr;
+	struct rxd_tag_hdr *tag_hdr;
+	struct rxd_data_hdr *data_hdr;
+	struct rxd_rma_hdr *rma_hdr;
+	struct rxd_atom_hdr *atom_hdr;
+	void *msg;
+	size_t msg_size;
+
+	if (base_hdr->seq_no != ep->peers[base_hdr->peer].rx_seq_no) {
+		if (!rxd_env.retry) {
+			rxd_remove_rx_pkt(ep, pkt_entry);
+			dlist_insert_order(&ep->peers[base_hdr->peer].buf_pkts,
+					   &rxd_comp_pkt_seq_no, &pkt_entry->d_entry);
+			ep->peers[base_hdr->peer].rx_seq_no++;
+			return;
 		}
 
-		rxd_ep_handle_data_msg(ep, peer, rx_entry, rx_entry->recv->iov,
-				     rx_entry->recv->msg.iov_count, ctrl,
-				     pkt_start->data, rx_buf);
-		break;
-	case ofi_op_tagged:
-		rx_entry->trecv = rxd_get_trecv_entry(ep, rx_entry);
-		if (!rx_entry->trecv) {
-			if (ep->num_unexp_msg < RXD_EP_MAX_UNEXP_MSG) {
-				dlist_insert_tail(&rx_entry->unexp_entry, &ep->unexp_tag_list);
-				rx_entry->unexp_buf = rx_buf;
-				ep->num_unexp_msg++;
-				return -FI_ENOENT;
-			} else {
-				FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "dropping msg\n");
-				return -FI_ENOMEM;
-			}
-		}
+		if (ep->peers[base_hdr->peer].peer_addr != FI_ADDR_UNSPEC)
+			goto ack;
+		goto release;
+	}
 
-		rxd_ep_handle_data_msg(ep, peer, rx_entry, rx_entry->trecv->iov,
-				     rx_entry->trecv->msg.iov_count, ctrl,
-				     pkt_start->data, rx_buf);
-		break;
-	case ofi_op_write:
-		rma_iov = (struct ofi_rma_iov *) pkt_start->data;
-		for (i = 0; i < rx_entry->op_hdr.iov_count; i++) {
-			ret = rxd_mr_verify(rxd_ep_domain(ep),
-					    rma_iov[i].len,
-					    (uintptr_t *) &rma_iov[i].addr,
-					    rma_iov[i].key, FI_REMOTE_WRITE);
-			if (ret) {
-				/* todo: handle invalid key case */
-				FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "invalid key/access permissions\n");
-				return -FI_EACCES;
-			}
+	if (ep->peers[base_hdr->peer].peer_addr == FI_ADDR_UNSPEC)
+		goto release;
 
-			rx_entry->write.iov[i].iov_base = (void *) (uintptr_t) rma_iov[i].addr;
-			rx_entry->write.iov[i].iov_len = rma_iov[i].len;
+	rx_entry = rxd_unpack_init_rx(ep, pkt_entry, base_hdr, &sar_hdr,
+				      &tag_hdr, &data_hdr, &rma_hdr, &atom_hdr,
+				      &msg, &msg_size);
+	if (!rx_entry) {
+		if (base_hdr->type == RXD_MSG || base_hdr->type == RXD_TAGGED) {
+			rxd_remove_rx_pkt(ep, pkt_entry);
+			return;
 		}
+		goto release;
+	}
 
-		offset = sizeof(struct ofi_rma_iov) * rx_entry->op_hdr.iov_count;
-		ctrl->seg_size -= offset;
-		rxd_ep_handle_data_msg(ep, peer, rx_entry, rx_entry->write.iov,
-				       rx_entry->op_hdr.iov_count, ctrl,
-				       pkt_start->data + offset, rx_buf);
-		break;
-	case ofi_op_read_req:
-		rma_iov = (struct ofi_rma_iov *) pkt_start->data;
-		tx_entry = rxd_tx_entry_alloc(ep, peer, rx_entry->peer, 0,
-						RXD_TX_READ_RSP);
-		if (!tx_entry) {
-			FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "no free tx-entry\n");
-			return -FI_ENOMEM;
-		}
+	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
+	rxd_progress_op(ep, rx_entry, pkt_entry, base_hdr, sar_hdr, tag_hdr,
+			data_hdr, rma_hdr, atom_hdr, &msg, msg_size);
 
-		tx_entry->peer = rx_entry->peer;
-		tx_entry->read_rsp.iov_count = rx_entry->op_hdr.iov_count;
-		for (i = 0; i < rx_entry->op_hdr.iov_count; i++) {
-			ret = rxd_mr_verify(rxd_ep_domain(ep),
-					    rma_iov[i].len,
-					    (uintptr_t *) &rma_iov[i].addr,
-					    rma_iov[i].key, FI_REMOTE_READ);
-			if (ret) {
-				/* todo: handle invalid key case */
-				FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "invalid key/access permissions\n");
-				return -FI_EACCES;
-			}
 
-			tx_entry->read_rsp.src_iov[i].iov_base = (void *) (uintptr_t)
-								rma_iov[i].addr;
-			tx_entry->read_rsp.src_iov[i].iov_len = rma_iov[i].len;
-		}
-		tx_entry->read_rsp.peer_msg_id = ctrl->msg_id;
-		ret = rxd_ep_start_xfer(ep, peer, ofi_op_read_rsp, tx_entry);
-		if (ret)
-			rxd_tx_entry_free(ep, tx_entry);
-		rxd_rx_entry_free(ep, rx_entry);
-		break;
-	case ofi_op_read_rsp:
-		idx = rx_entry->op_hdr.remote_idx & RXD_TX_IDX_BITS;
-		tx_entry = &ep->tx_entry_fs->buf[idx];
-		if (tx_entry->msg_id != rx_entry->op_hdr.remote_idx)
-			return -FI_ENOMEM;
-
-		rx_entry->read_rsp.tx_entry = tx_entry;
-		rxd_ep_handle_data_msg(ep, peer, rx_entry, tx_entry->read_req.dst_iov,
-				       tx_entry->read_req.msg.iov_count, ctrl,
-				       pkt_start->data, rx_buf);
-		break;
-	case ofi_op_atomic:
-	default:
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "invalid op type\n");
-		return -FI_EINVAL;
-	}
-	return 0;
+	if (!dlist_empty(&ep->peers[base_hdr->peer].buf_pkts))
+		rxd_progress_buf_pkts(ep, base_hdr->peer);
+
+	fastlock_release(&ep->util_ep.rx_cq->cq_lock);
+
+ack:
+	rxd_ep_send_ack(ep, base_hdr->peer);
+release:
+	rxd_remove_rx_pkt(ep, pkt_entry);
+	rxd_release_repost_rx(ep, pkt_entry);
 }
 
-static void rxd_handle_start_data(struct rxd_ep *ep, struct rxd_peer *peer,
-				  struct ofi_ctrl_hdr *ctrl,
-				  struct fi_cq_msg_entry *comp,
-				  struct rxd_rx_buf *rx_buf)
+static void rxd_handle_cts(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
 {
-	struct rxd_rx_entry *rx_entry;
-	struct rxd_pkt_data_start *pkt_start;
-	int ret;
+	struct rxd_cts_pkt *cts = (struct rxd_cts_pkt *) (pkt_entry->pkt);
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL,
-	       "start data- msg_id: %" PRIu64 ", segno: %d, buf: %p\n",
-	       ctrl->msg_id, ctrl->seg_no, rx_buf);
+	rxd_update_peer(ep, cts->rts_addr, cts->cts_addr);
+}
 
-	pkt_start = (struct rxd_pkt_data_start *) ctrl;
-	if (pkt_start->op.version != OFI_OP_VERSION) {
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "op version mismatch\n");
-		goto repost;
-	}
+static void rxd_handle_ack(struct rxd_ep *ep, struct rxd_pkt_entry *ack_entry)
+{
+	struct rxd_ack_pkt *ack = (struct rxd_ack_pkt *) (ack_entry->pkt);
+	struct rxd_pkt_entry *pkt_entry;
+	fi_addr_t peer = ack->base_hdr.peer;
+	struct rxd_base_hdr *hdr;
 
-	ret = rxd_check_start_pkt_order(ep, peer, ctrl, comp);
-	if (ret) {
-		if (ret == -FI_EALREADY) {
-			FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "duplicate pkt: %d\n",
-				ctrl->seg_no);
-			rxd_handle_dup_datastart(ep, ctrl, rx_buf);
-			goto repost;
-		} else {
-			FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "unexpected pkt: %d\n",
-				ctrl->seg_no);
-			goto repost;
+	if (ep->peers[peer].last_rx_ack == ack->base_hdr.seq_no)
+		return;
+
+	ep->peers[peer].retry_cnt = 0;
+	ep->peers[peer].last_rx_ack = ack->base_hdr.seq_no;
+
+	if (dlist_empty(&ep->peers[peer].unacked))
+		return;
+
+	pkt_entry = container_of((&ep->peers[peer].unacked)->next,
+				struct rxd_pkt_entry, d_entry);
+
+	while (&pkt_entry->d_entry != &ep->peers[peer].unacked) {
+		hdr = rxd_get_base_hdr(pkt_entry);
+		if (ofi_after_eq(hdr->seq_no, ack->base_hdr.seq_no))
+			break;
+
+		if (pkt_entry->flags & RXD_PKT_IN_USE) {
+			pkt_entry->flags |= RXD_PKT_ACKED;
+			pkt_entry = container_of((&pkt_entry->d_entry)->next,
+						 struct rxd_pkt_entry, d_entry);
+			continue;
 		}
+		dlist_remove(&pkt_entry->d_entry);
+		rxd_release_tx_pkt(ep, pkt_entry);
+	     	ep->peers[peer].unacked_cnt--;
+
+		pkt_entry = container_of((&ep->peers[peer].unacked)->next,
+					struct rxd_pkt_entry, d_entry);
 	}
 
-	rx_entry = rxd_rx_entry_alloc(ep);
-	if (!rx_entry)
-		goto repost;
-
-	rx_entry->peer_info = peer;
-	rx_entry->op_hdr = pkt_start->op;
-	rx_entry->exp_seg_no = 0;
-	rx_entry->msg_id = ctrl->msg_id;
-	rx_entry->done = 0;
-	rx_entry->peer = ctrl->conn_id;
-	rx_entry->source = (ep->util_ep.caps & FI_DIRECTED_RECV) ?
-		rxd_av_fi_addr(rxd_ep_av(ep), ctrl->conn_id) : FI_ADDR_UNSPEC;
-	rx_entry->credits = 1;
-	rx_entry->last_win_seg = 1;
-
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "Assign rx_entry :%" PRId64 " for %" PRIx64 "\n",
-	       rx_entry->key, rx_entry->msg_id);
-
-	ep->credits--;
-	ret = rxd_process_start_data(ep, rx_entry, peer, ctrl, comp, rx_buf);
-	if (ret == -FI_ENOMEM)
-		rxd_rx_entry_free(ep, rx_entry);
-	else if (ret == -FI_ENOENT) {
-		peer->exp_msg_id++;
+	rxd_progress_tx_list(ep, &ep->peers[ack->base_hdr.peer]);
+} 
 
-		/* reply ack, with no window = 0 */
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "Sending wait-ACK [%" PRIx64 "] - %d\n",
-		       ctrl->msg_id, ctrl->seg_no);
-		goto out;
-	} else {
-		peer->exp_msg_id++;
-	}
+void rxd_handle_send_comp(struct rxd_ep *ep, struct fi_cq_msg_entry *comp)
+{
+	struct rxd_pkt_entry *pkt_entry;
+	fi_addr_t peer;
 
-repost:
-	rxd_ep_repost_buff(rx_buf);
-out:
-	assert(rxd_reposted_bufs);
-	return;
+	pkt_entry = container_of(comp->op_context, struct rxd_pkt_entry, context);
+
+	switch (rxd_pkt_type(pkt_entry)) {
+	case RXD_CTS:
+	case RXD_ACK:
+		dlist_remove(&pkt_entry->d_entry);
+		rxd_release_tx_pkt(ep, pkt_entry);
+		break;
+	default:
+		if (pkt_entry->flags & RXD_PKT_ACKED) {
+			peer = pkt_entry->peer;
+			dlist_remove(&pkt_entry->d_entry);
+			rxd_release_tx_pkt(ep, pkt_entry);
+	     		ep->peers[peer].unacked_cnt--;
+			rxd_progress_tx_list(ep, &ep->peers[peer]);
+		} else {
+			pkt_entry->flags &= ~RXD_PKT_IN_USE;
+		}
+	}
+	ep->pending_cnt--;
 }
 
 void rxd_handle_recv_comp(struct rxd_ep *ep, struct fi_cq_msg_entry *comp)
 {
-	struct ofi_ctrl_hdr *ctrl;
-	struct rxd_rx_buf *rx_buf;
-	struct rxd_peer *peer;
+	struct rxd_pkt_entry *pkt_entry;
+	int release = 1;
 
 	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "got recv completion\n");
 
-	assert(rxd_reposted_bufs);
-	rxd_reposted_bufs--;
-
-	rx_buf = container_of(comp->op_context, struct rxd_rx_buf, context);
-	ctrl = (struct ofi_ctrl_hdr *) rx_buf->buf;
-	peer = rxd_ep_getpeer_info(ep, ctrl->conn_id);
+	pkt_entry = container_of(comp->op_context, struct rxd_pkt_entry, context);
+	ep->posted_bufs--;
 
-	if (ctrl->version != OFI_CTRL_VERSION) {
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "ctrl version mismatch\n");
-		return;
-	}
-
-	switch (ctrl->type) {
-	case ofi_ctrl_connreq:
-		rxd_handle_conn_req(ep, ctrl, comp, rx_buf);
-		break;
-	case ofi_ctrl_ack:
-		rxd_handle_ack(ep, ctrl, rx_buf);
-		break;
-	case ofi_ctrl_discard:
-		rxd_handle_discard(ep, ctrl, rx_buf);
+	pkt_entry->pkt_size = comp->len;
+	switch (rxd_pkt_type(pkt_entry)) {
+	case RXD_RTS:
+		rxd_handle_rts(ep, pkt_entry);
 		break;
-	case ofi_ctrl_connresp:
-		rxd_handle_connect_ack(ep, ctrl, rx_buf);
+	case RXD_CTS:
+		rxd_handle_cts(ep, pkt_entry);
 		break;
-	case ofi_ctrl_start_data:
-		rxd_handle_start_data(ep, peer, ctrl, comp, rx_buf);
+	case RXD_ACK:
+		rxd_handle_ack(ep, pkt_entry);
 		break;
-	case ofi_ctrl_data:
-		rxd_handle_data(ep, peer, ctrl, comp, rx_buf);
+	case RXD_DATA:
+	case RXD_DATA_READ:
+		rxd_handle_data(ep, pkt_entry);
 		break;
 	default:
-		rxd_ep_repost_buff(rx_buf);
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
-			"invalid ctrl type %u\n", ctrl->type);
+		rxd_handle_op(ep, pkt_entry);
+		release = 0;
+		break;
 	}
 
-	rxd_check_waiting_rx(ep);
+	if (release) {
+		rxd_remove_rx_pkt(ep, pkt_entry);
+		rxd_release_repost_rx(ep, pkt_entry);
+	}
 }
 
-void rxd_handle_send_comp(struct fi_cq_msg_entry *comp)
+void rxd_handle_error(struct rxd_ep *ep)
 {
-	struct rxd_pkt_meta *pkt_meta;
+	struct fi_cq_err_entry err = {0};
+	int ret;
 
-	pkt_meta = container_of(comp->op_context, struct rxd_pkt_meta, context);
-	if (pkt_meta->flags & (RXD_REMOTE_ACK | RXD_NOT_ACKED))
-		rxd_tx_pkt_free(pkt_meta);
-	else
-		pkt_meta->flags |= RXD_LOCAL_COMP;
+	ret = fi_cq_readerr(ep->dg_cq, &err, 0);
+	if (ret < 0) {
+		FI_WARN(&rxd_prov, FI_LOG_CQ,
+			"Error reading CQ: %s\n", fi_strerror(-ret));
+	} else {
+		FI_WARN(&rxd_prov, FI_LOG_CQ,
+			"Received %s error from core provider: %s\n",
+			err.flags & FI_SEND ? "tx" : "rx", fi_strerror(-err.err)); 
+	}
 }
 
 static int rxd_cq_close(struct fid *fid)
@@ -1153,13 +1217,71 @@ static struct fi_ops rxd_cq_fi_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
+ssize_t rxd_cq_sreadfrom(struct fid_cq *cq_fid, void *buf, size_t count,
+			 fi_addr_t *src_addr, const void *cond, int timeout)
+{
+	struct fid_list_entry *fid_entry;
+	struct util_cq *cq;
+	struct rxd_ep *ep;
+	uint64_t start;
+	int ret, ep_retry;
+
+	cq = container_of(cq_fid, struct util_cq, cq_fid);
+	assert(cq->wait && cq->internal_wait);
+	start = (timeout >= 0) ? fi_gettime_ms() : 0;
+
+	do {
+		ret = ofi_cq_readfrom(cq_fid, buf, count, src_addr);
+		if (ret != -FI_EAGAIN)
+			break;
+
+		if (timeout >= 0) {
+			timeout -= (int) (fi_gettime_ms() - start);
+			if (timeout <= 0)
+				return -FI_EAGAIN;
+		}
+
+		if (ofi_atomic_get32(&cq->signaled)) {
+			ofi_atomic_set32(&cq->signaled, 0);
+			return -FI_ECANCELED;
+		}
+
+		ep_retry = -1;
+		cq->cq_fastlock_acquire(&cq->ep_list_lock);
+		dlist_foreach_container(&cq->ep_list, struct fid_list_entry,
+					fid_entry, entry) {
+			ep = container_of(fid_entry->fid, struct rxd_ep,
+					  util_ep.ep_fid.fid);
+			if (ep->next_retry == -1)
+				continue;
+			ep_retry = ep_retry == -1 ? ep->next_retry :
+					MIN(ep_retry, ep->next_retry);
+		}
+		cq->cq_fastlock_release(&cq->ep_list_lock);
+
+		ret = fi_wait(&cq->wait->wait_fid, ep_retry == -1 ?
+			      timeout : rxd_get_timeout(ep_retry));
+
+		if (ep_retry != -1 && ret == -FI_ETIMEDOUT)
+			ret = 0;
+	} while (!ret);
+
+	return ret == -FI_ETIMEDOUT ? -FI_EAGAIN : ret;
+}
+
+ssize_t rxd_cq_sread(struct fid_cq *cq_fid, void *buf, size_t count,
+		const void *cond, int timeout)
+{
+	return rxd_cq_sreadfrom(cq_fid, buf, count, NULL, cond, timeout);
+}
+
 static struct fi_ops_cq rxd_cq_ops = {
 	.size = sizeof(struct fi_ops_cq),
 	.read = ofi_cq_read,
 	.readfrom = ofi_cq_readfrom,
 	.readerr = ofi_cq_readerr,
-	.sread = ofi_cq_sread,
-	.sreadfrom = ofi_cq_sreadfrom,
+	.sread = rxd_cq_sread,
+	.sreadfrom = rxd_cq_sreadfrom,
 	.signal = ofi_cq_signal,
 	.strerror = rxd_cq_strerror,
 };
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_domain.c
index e0fb34a17..f535c0255 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_domain.c
@@ -47,6 +47,7 @@ static struct fi_ops_domain rxd_domain_ops = {
 	.poll_open = fi_poll_create,
 	.stx_ctx = fi_no_stx_context,
 	.srx_ctx = fi_no_srx_context,
+	.query_atomic = rxd_query_atomic,
 };
 
 static int rxd_domain_close(fid_t fid)
@@ -77,119 +78,11 @@ static struct fi_ops rxd_domain_fi_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
-struct rxd_mr_entry {
-	struct fid_mr mr_fid;
-	struct rxd_domain *domain;
-	uint64_t key;
-	uint64_t flags;
-};
-
-static int rxd_mr_close(struct fid *fid)
-{
-	struct rxd_domain *dom;
-	struct rxd_mr_entry *mr;
-	int err = 0;
-
-	mr = container_of(fid, struct rxd_mr_entry, mr_fid.fid);
-	dom = mr->domain;
-
-	fastlock_acquire(&dom->util_domain.lock);
-	err = ofi_mr_map_remove(&dom->mr_map, mr->key);
-	fastlock_release(&dom->util_domain.lock);
-	if (err)
-		return err;
-
-	ofi_atomic_dec32(&dom->util_domain.ref);
-	free(mr);
-	return 0;
-}
-
-static struct fi_ops rxd_mr_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = rxd_mr_close,
-	.control = fi_no_control,
-	.ops_open = fi_no_ops_open,
-};
-
-
-static int rxd_mr_regattr(struct fid *fid, const struct fi_mr_attr *attr,
-		uint64_t flags, struct fid_mr **mr)
-{
-	struct rxd_domain *dom;
-	struct rxd_mr_entry *_mr;
-	uint64_t key;
-	int ret = 0;
-
-	if (fid->fclass != FI_CLASS_DOMAIN || !attr || attr->iov_count <= 0) {
-		return -FI_EINVAL;
-	}
-
-	dom = container_of(fid, struct rxd_domain, util_domain.domain_fid.fid);
-	_mr = calloc(1, sizeof(*_mr));
-	if (!_mr)
-		return -FI_ENOMEM;
-
-	fastlock_acquire(&dom->util_domain.lock);
-
-	_mr->mr_fid.fid.fclass = FI_CLASS_MR;
-	_mr->mr_fid.fid.context = attr->context;
-	_mr->mr_fid.fid.ops = &rxd_mr_fi_ops;
-
-	_mr->domain = dom;
-	_mr->flags = flags;
-
-	ret = ofi_mr_map_insert(&dom->mr_map, attr, &key, _mr);
-	if (ret != 0) {
-		goto err;
-	}
-
-	_mr->mr_fid.key = _mr->key = key;
-	_mr->mr_fid.mem_desc = (void *) (uintptr_t) key;
-	fastlock_release(&dom->util_domain.lock);
-
-	*mr = &_mr->mr_fid;
-	ofi_atomic_inc32(&dom->util_domain.ref);
-
-	return 0;
-err:
-	fastlock_release(&dom->util_domain.lock);
-	free(_mr);
-	return ret;
-}
-
-static int rxd_mr_regv(struct fid *fid, const struct iovec *iov,
-			size_t count, uint64_t access,
-			uint64_t offset, uint64_t requested_key,
-			uint64_t flags, struct fid_mr **mr, void *context)
-{
-	struct fi_mr_attr attr;
-
-	attr.mr_iov = iov;
-	attr.iov_count = count;
-	attr.access = access;
-	attr.offset = offset;
-	attr.requested_key = requested_key;
-	attr.context = context;
-	return rxd_mr_regattr(fid, &attr, flags, mr);
-}
-
-static int rxd_mr_reg(struct fid *fid, const void *buf, size_t len,
-		       uint64_t access, uint64_t offset, uint64_t requested_key,
-		       uint64_t flags, struct fid_mr **mr, void *context)
-{
-	struct iovec iov;
-
-	iov.iov_base = (void *) buf;
-	iov.iov_len = len;
-	return rxd_mr_regv(fid, &iov, 1, access,  offset, requested_key,
-			    flags, mr, context);
-}
-
 static struct fi_ops_mr rxd_mr_ops = {
 	.size = sizeof(struct fi_ops_mr),
-	.reg = rxd_mr_reg,
-	.regv = rxd_mr_regv,
-	.regattr = rxd_mr_regattr,
+	.reg = ofi_mr_reg,
+	.regv = ofi_mr_regv,
+	.regattr = ofi_mr_regattr,
 };
 
 int rxd_mr_verify(struct rxd_domain *rxd_domain, ssize_t len,
@@ -214,9 +107,6 @@ int rxd_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 
 	rxd_fabric = container_of(fabric, struct rxd_fabric,
 				  util_fabric.fabric_fid);
-	ret = ofi_prov_check_info(&rxd_util_prov, fabric->api_version, info);
-	if (ret)
-		return ret;
 
 	rxd_domain = calloc(1, sizeof(*rxd_domain));
 	if (!rxd_domain)
@@ -234,7 +124,17 @@ int rxd_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 	if (ret)
 		goto err2;
 
-	rxd_domain->max_mtu_sz = dg_info->ep_attr->max_msg_size;
+	rxd_domain->max_mtu_sz = MIN(dg_info->ep_attr->max_msg_size, RXD_MAX_MTU_SIZE);
+	rxd_domain->max_inline_msg = rxd_domain->max_mtu_sz -
+					sizeof(struct rxd_base_hdr) -
+					dg_info->ep_attr->msg_prefix_size;
+	rxd_domain->max_inline_rma = rxd_domain->max_inline_msg -
+					(sizeof(struct rxd_rma_hdr) +
+					(RXD_IOV_LIMIT * sizeof(struct ofi_rma_iov)));
+	rxd_domain->max_inline_atom = rxd_domain->max_inline_rma -
+					sizeof(struct rxd_atom_hdr);
+	rxd_domain->max_seg_sz = rxd_domain->max_mtu_sz - sizeof(struct rxd_data_pkt) -
+				 dg_info->ep_attr->msg_prefix_size;
 	rxd_domain->mr_mode = dg_info->domain_attr->mr_mode;
 
 	ret = ofi_domain_init(fabric, info, &rxd_domain->util_domain, context);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_ep.c
index 5d3c5cde1..27b446d04 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_ep.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -36,1270 +36,748 @@
 #include <ofi_iov.h>
 #include "rxd.h"
 
-int rxd_progress_spin_count = 1000;
-int rxd_reposted_bufs = 0;
-
-static ssize_t rxd_ep_cancel(fid_t fid, void *context)
+struct rxd_pkt_entry *rxd_get_tx_pkt(struct rxd_ep *ep)
 {
-	struct rxd_ep *ep;
-	struct dlist_entry *entry, *next;
-	struct rxd_recv_entry *recv_entry;
-	struct rxd_trecv_entry *trecv_entry;
-	struct fi_cq_err_entry err_entry = {0};
+	struct rxd_pkt_entry *pkt_entry;
+	void *mr = NULL;
 
-	ep = container_of(fid, struct rxd_ep, util_ep.ep_fid.fid);
-	fastlock_acquire(&ep->lock);
-	if (ep->util_ep.caps & FI_MSG) {
-		for (entry = ep->recv_list.next; entry != &ep->recv_list; entry = next) {
-			next = entry->next;
-			recv_entry = container_of(entry, struct rxd_recv_entry, entry);
-			if (recv_entry->msg.context != context)
-				continue;
-
-			dlist_remove(entry);
-			err_entry.op_context = recv_entry->msg.context;
-			err_entry.flags = (FI_MSG | FI_RECV);
-			err_entry.err = FI_ECANCELED;
-			err_entry.prov_errno = -FI_ECANCELED;
-			rxd_cq_report_error(rxd_ep_rx_cq(ep), &err_entry);
-			goto out;
-		}
-	}
+	pkt_entry = ep->do_local_mr ?
+		    util_buf_alloc_ex(ep->tx_pkt_pool, &mr) :
+		    util_buf_alloc(ep->tx_pkt_pool);
 
-	if (ep->util_ep.caps & FI_TAGGED) {
-		for (entry = ep->trecv_list.next; entry != &ep->trecv_list; entry = next) {
-			next = entry->next;
-			trecv_entry = container_of(entry, struct rxd_trecv_entry, entry);
-			if (trecv_entry->msg.context != context)
-				continue;
-
-			dlist_remove(entry);
-			err_entry.op_context = trecv_entry->msg.context;
-			err_entry.flags = (FI_MSG | FI_RECV | FI_TAGGED);
-			err_entry.tag = trecv_entry->msg.tag;
-			err_entry.err = FI_ECANCELED;
-			err_entry.prov_errno = -FI_ECANCELED;
-			rxd_cq_report_error(rxd_ep_rx_cq(ep), &err_entry);
-			goto out;
-		}
-	}
+	if (!pkt_entry)
+		return NULL;
 
-out:
-	fastlock_release(&ep->lock);
-	return 0;
+	pkt_entry->mr = (struct fid_mr *) mr;
+	pkt_entry->flags = 0;
+	rxd_set_tx_pkt(ep, pkt_entry);
+
+	return pkt_entry;
 }
 
-static int rxd_ep_getopt(fid_t fid, int level, int optname,
-		   void *optval, size_t *optlen)
+static struct rxd_pkt_entry *rxd_get_rx_pkt(struct rxd_ep *ep)
 {
-	return -FI_ENOSYS;
+	struct rxd_pkt_entry *pkt_entry;
+	void *mr = NULL;
+
+	pkt_entry = ep->do_local_mr ?
+		    util_buf_alloc_ex(ep->rx_pkt_pool, &mr) :
+		    util_buf_alloc(ep->rx_pkt_pool);
+
+	if (!pkt_entry)
+		return NULL;
+
+	pkt_entry->mr = (struct fid_mr *) mr;
+	rxd_set_rx_pkt(ep, pkt_entry);
+
+	return pkt_entry;
 }
 
-static int rxd_ep_setopt(fid_t fid, int level, int optname,
-		   const void *optval, size_t optlen)
+struct rxd_x_entry *rxd_get_tx_entry(struct rxd_ep *ep)
 {
-	return -FI_ENOSYS;
-}
+	struct rxd_x_entry *tx_entry;
 
-struct fi_ops_ep rxd_ops_ep = {
-	.size = sizeof(struct fi_ops_ep),
-	.cancel = rxd_ep_cancel,
-	.getopt = rxd_ep_getopt,
-	.setopt = rxd_ep_setopt,
-	.tx_ctx = fi_no_tx_ctx,
-	.rx_ctx = fi_no_rx_ctx,
-	.rx_size_left = fi_no_rx_size_left,
-	.tx_size_left = fi_no_tx_size_left,
-};
+	tx_entry = util_buf_indexed_alloc(ep->tx_entry_pool);
+	if (!tx_entry)
+		return NULL;
 
-static ssize_t rxd_ep_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
-			       uint64_t flags)
-{
-	ssize_t ret = 0;
-	size_t i;
-	struct rxd_ep *rxd_ep;
-	struct rxd_recv_entry *recv_entry;
+	tx_entry->tx_id = util_get_buf_index(ep->tx_entry_pool, tx_entry);
 
-	rxd_ep = container_of(ep, struct rxd_ep, util_ep.ep_fid.fid);
+	return tx_entry;
+}
 
-	fastlock_acquire(&rxd_ep->lock);
-	if (freestack_isempty(rxd_ep->recv_fs)) {
-		ret = -FI_EAGAIN;
-		goto out;
-	}
+struct rxd_x_entry *rxd_get_rx_entry(struct rxd_ep *ep)
+{
+	struct rxd_x_entry *rx_entry;
 
-	recv_entry = freestack_pop(rxd_ep->recv_fs);
-	recv_entry->msg = *msg;
-	recv_entry->flags = flags;
-	recv_entry->msg.addr = (rxd_ep->util_ep.caps & FI_DIRECTED_RECV) ?
-		recv_entry->msg.addr : FI_ADDR_UNSPEC;
-	for (i = 0; i < msg->iov_count; i++) {
-		recv_entry->iov[i].iov_base = msg->msg_iov[i].iov_base;
-		recv_entry->iov[i].iov_len = msg->msg_iov[i].iov_len;
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "post recv: %zu\n",
-		       msg->msg_iov[i].iov_len);
-	}
+	rx_entry = util_buf_indexed_alloc(ep->rx_entry_pool);
+	if (!rx_entry)
+		return NULL;
 
-	dlist_init(&recv_entry->entry);
-	dlist_insert_tail(&recv_entry->entry, &rxd_ep->recv_list);
+	rx_entry->rx_id = util_get_buf_index(ep->rx_entry_pool, rx_entry);
 
-	if (!dlist_empty(&rxd_ep->unexp_msg_list)) {
-		rxd_ep_check_unexp_msg_list(rxd_ep, recv_entry);
-	}
-out:
-	fastlock_release(&rxd_ep->lock);
-	return ret;
+	return rx_entry;
 }
 
-static ssize_t rxd_ep_recv(struct fid_ep *ep, void *buf, size_t len, void *desc,
-			    fi_addr_t src_addr, void *context)
+void rxd_release_tx_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = buf;
-	msg_iov.iov_len = len;
-
-	msg.msg_iov = &msg_iov;
-	msg.desc = &desc;
-	msg.iov_count = 1;
-	msg.addr = src_addr;
-	msg.context = context;
-	msg.data = 0;
-	return rxd_ep_recvmsg(ep, &msg, RXD_USE_OP_FLAGS);
+	util_buf_release(ep->tx_pkt_pool, pkt);
 }
 
-static ssize_t rxd_ep_recvv(struct fid_ep *ep, const struct iovec *iov, void **desc,
-			     size_t count, fi_addr_t src_addr, void *context)
+void rxd_release_rx_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt)
 {
-	struct fi_msg msg;
-	memset(&msg, 0, sizeof(msg));
-	msg.msg_iov = iov;
-	msg.desc = desc;
-	msg.iov_count = count;
-	msg.addr = src_addr;
-	msg.context = context;
-	msg.data = 0;
-	return rxd_ep_recvmsg(ep, &msg, RXD_USE_OP_FLAGS);
+	util_buf_release(ep->rx_pkt_pool, pkt);
 }
 
-static inline void *rxd_mr_desc(struct fid_mr *mr, struct rxd_ep *ep)
+static void rxd_release_tx_entry(struct rxd_ep *ep, struct rxd_x_entry *x_entry)
 {
-	return (ep->do_local_mr) ? fi_mr_desc(mr) : NULL;
+	util_buf_indexed_release(ep->tx_entry_pool, x_entry);
 }
 
-int rxd_ep_repost_buff(struct rxd_rx_buf *buf)
+void rxd_release_rx_entry(struct rxd_ep *ep, struct rxd_x_entry *x_entry)
 {
-	int ret;
-	ret = fi_recv(buf->ep->dg_ep, buf->buf, rxd_ep_domain(buf->ep)->max_mtu_sz,
-		      rxd_mr_desc(buf->mr, buf->ep),
-		      FI_ADDR_UNSPEC, &buf->context);
-	if (ret)
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "failed to repost\n");
-	else
-		rxd_reposted_bufs++;
-	return ret;
+	util_buf_indexed_release(ep->rx_entry_pool, x_entry);
 }
 
-/*
- * See ofi_proto.h for how conn_data is being used.
- */
-static uint64_t rxd_ep_conn_data(struct rxd_ep *ep)
+static int rxd_match_ctx(struct dlist_entry *item, const void *arg)
 {
-	char name[RXD_MAX_DGRAM_ADDR];
-	size_t addrlen;
-	int ret;
-
-	if (ep->conn_data_set)
-		return ep->conn_data;
-
-	addrlen = sizeof name;
-	ret = fi_getname(&ep->dg_ep->fid, name, &addrlen);
-	if (ret)
-		return 0;
+	struct rxd_x_entry *x_entry;
 
-	ret = rxd_av_dg_reverse_lookup(rxd_ep_av(ep), 0, name, &ep->conn_data);
-	if (!ret)
-		ep->conn_data_set = 1;
+	x_entry = container_of(item, struct rxd_x_entry, entry);
 
-	return ep->conn_data;
+	return (x_entry->cq_entry.op_context == arg);
 }
 
-static int rxd_ep_enable(struct rxd_ep *ep)
+static ssize_t rxd_ep_cancel_recv(struct rxd_ep *ep, struct dlist_entry *list,
+				  void *context)
 {
-	size_t i;
-	ssize_t ret;
-	void *mr = NULL;
-	struct rxd_rx_buf *rx_buf;
+	struct dlist_entry *entry;
+	struct rxd_x_entry *rx_entry;
+	struct fi_cq_err_entry err_entry;
+	int ret = 0;
 
-	ret = fi_enable(ep->dg_ep);
-	if (ret)
-		return ret;
+	fastlock_acquire(&ep->util_ep.lock);
 
-	fastlock_acquire(&ep->lock);
-	ep->credits = ep->rx_size;
-	for (i = 0; i < ep->rx_size; i++) {
-		rx_buf = ep->do_local_mr ?
-			util_buf_get_ex(ep->rx_pkt_pool, &mr) :
-			util_buf_get(ep->rx_pkt_pool);
+	entry = dlist_find_first_match(list, &rxd_match_ctx, context);
+	if (!entry)
+		goto out;
 
-		if (!rx_buf) {
-			ret = -FI_ENOMEM;
-			goto out;
-		}
+	rx_entry = container_of(entry, struct rxd_x_entry, entry);
+	memset(&err_entry, 0, sizeof(struct fi_cq_err_entry));
+	err_entry.op_context = rx_entry->cq_entry.op_context;
+	err_entry.flags = rx_entry->cq_entry.flags;
+	err_entry.err = FI_ECANCELED;
+	err_entry.prov_errno = 0;
+	rxd_cq_report_error(rxd_ep_rx_cq(ep), &err_entry);
 
-		rx_buf->mr = (struct fid_mr *) mr;
-		rx_buf->ep = ep;
-		ret = rxd_ep_repost_buff(rx_buf);
-		if (ret)
-			goto out;
-		slist_insert_tail(&rx_buf->entry, &ep->rx_pkt_list);
-	}
+	rx_entry->flags |= RXD_CANCELLED;
+
+	ret = 1;
 out:
-	fastlock_release(&ep->lock);
+	fastlock_release(&ep->util_ep.lock);
 	return ret;
 }
 
-struct rxd_peer *rxd_ep_getpeer_info(struct rxd_ep *ep, fi_addr_t addr)
+static ssize_t rxd_ep_cancel(fid_t fid, void *context)
 {
-	return &ep->peer_info[addr];
-}
+	struct rxd_ep *ep;
+	int ret;
 
-/*
- * Exponential back-off starting at 1ms, max 4s.
- */
-void rxd_set_timeout(struct rxd_tx_entry *tx_entry)
-{
-	tx_entry->retry_time = fi_gettime_ms() +
-				MIN(1 << tx_entry->retry_cnt, 4000);
-}
+	ep = container_of(fid, struct rxd_ep, util_ep.ep_fid);
 
-static void rxd_init_ctrl_hdr(struct ofi_ctrl_hdr *ctrl,
-			      uint8_t type, uint16_t seg_size,
-			      uint32_t seg_no, uint64_t msg_id,
-			      uint64_t rx_key, uint64_t source)
-{
-	ctrl->version = OFI_CTRL_VERSION;
-	ctrl->type = type;
-	ctrl->seg_size = seg_size;
-	ctrl->seg_no = seg_no;
-	ctrl->msg_id = msg_id;
-	ctrl->rx_key = rx_key;
-	ctrl->conn_id = source;
-}
+	ret = rxd_ep_cancel_recv(ep, &ep->rx_tag_list, context);
+	if (ret)
+		goto out;
 
-static void rxd_init_op_hdr(struct ofi_op_hdr *op, uint64_t data,
-			    uint64_t msg_sz, uint8_t rx_index,
-			    uint8_t op_type, uint64_t tag, uint32_t flags)
-{
-	op->version = OFI_OP_VERSION;
-	op->rx_index = rx_index;
-	op->op = op_type;
-	op->op_data = 0; /* unused */
-	op->flags = flags;
-	op->size = msg_sz;
-	op->data = data;
-	op->tag = tag;
-}
+	ret = rxd_ep_cancel_recv(ep, &ep->rx_list, context);
 
-static uint32_t rxd_map_fi_flags(uint64_t fi_flags)
-{
-	uint32_t flags = 0;
-
-	if (fi_flags & FI_REMOTE_CQ_DATA)
-		flags = OFI_REMOTE_CQ_DATA;
-	if (fi_flags & FI_TRANSMIT_COMPLETE)
-		flags |= OFI_TRANSMIT_COMPLETE;
-	if (fi_flags & FI_DELIVERY_COMPLETE)
-		flags |= OFI_DELIVERY_COMPLETE;
-	return flags;
+out:
+	return 0;
 }
 
-static struct rxd_pkt_meta *rxd_tx_pkt_alloc(struct rxd_ep *ep)
+static int rxd_ep_getopt(fid_t fid, int level, int optname,
+		   void *optval, size_t *optlen)
 {
-	struct rxd_pkt_meta *pkt_meta;
-	void *mr = NULL;
+	struct rxd_ep *rxd_ep =
+		container_of(fid, struct rxd_ep, util_ep.ep_fid);
 
-	pkt_meta = ep->do_local_mr ?
-		util_buf_alloc_ex(ep->tx_pkt_pool, &mr) :
-		util_buf_alloc(ep->tx_pkt_pool);
+	if ((level != FI_OPT_ENDPOINT) || (optname != FI_OPT_MIN_MULTI_RECV))
+		return -FI_ENOPROTOOPT;
 
-	if (!pkt_meta) {
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "No free tx pkt\n");
-		return NULL;
-	}
+	*(size_t *)optval = rxd_ep->min_multi_recv_size;
+	*optlen = sizeof(size_t);
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "Acquired tx pkt: %p\n", pkt_meta);
-	pkt_meta->ep = ep;
-	pkt_meta->mr = (struct fid_mr *) mr;
-	pkt_meta->flags = 0;
-	return pkt_meta;
+	return FI_SUCCESS;
 }
 
-static uint64_t rxd_ep_start_seg_size(struct rxd_ep *ep, uint64_t msg_size)
-{
-	return MIN(rxd_ep_domain(ep)->max_mtu_sz -
-		   sizeof(struct rxd_pkt_data_start), msg_size);
-}
-
-struct rxd_tx_entry *rxd_tx_entry_alloc(struct rxd_ep *ep,
-	struct rxd_peer *peer, fi_addr_t addr, uint64_t flags, uint8_t op)
+static int rxd_ep_setopt(fid_t fid, int level, int optname,
+		   const void *optval, size_t optlen)
 {
-	struct rxd_tx_entry *tx_entry;
-
-	if (freestack_isempty(ep->tx_entry_fs)) {
-		FI_INFO(&rxd_prov, FI_LOG_EP_CTRL, "no-more tx entries\n");
-		return NULL;
-	}
+	struct rxd_ep *rxd_ep =
+		container_of(fid, struct rxd_ep, util_ep.ep_fid);
 
-	if (peer->active_tx_cnt == RXD_MAX_PEER_TX)
-		return NULL;
+	if ((level != FI_OPT_ENDPOINT) || (optname != FI_OPT_MIN_MULTI_RECV))
+		return -FI_ENOPROTOOPT;
 
-	peer->active_tx_cnt++;
+	rxd_ep->min_multi_recv_size = *(size_t *)optval;
 
-	tx_entry = freestack_pop(ep->tx_entry_fs);
-	tx_entry->peer = addr;
-	tx_entry->flags = flags;
-	tx_entry->bytes_sent = 0;
-	tx_entry->seg_no = 0;
-	tx_entry->window = 1;
-	tx_entry->retry_cnt = 0;
-	tx_entry->op_type = op;
-	dlist_init(&tx_entry->pkt_list);
-	return tx_entry;
+	return FI_SUCCESS;
 }
 
-void rxd_tx_entry_free(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry)
-{
-	struct rxd_peer *peer;
-
-	peer = rxd_ep_getpeer_info(ep, tx_entry->peer);
-	peer->active_tx_cnt--;
-	/* reset ID to invalid state to avoid ID collision */
-	tx_entry->msg_id = UINT64_MAX;
-	dlist_remove(&tx_entry->entry);
-	freestack_push(ep->tx_entry_fs, tx_entry);
-}
+struct fi_ops_ep rxd_ops_ep = {
+	.size = sizeof(struct fi_ops_ep),
+	.cancel = rxd_ep_cancel,
+	.getopt = rxd_ep_getopt,
+	.setopt = rxd_ep_setopt,
+	.tx_ctx = fi_no_tx_ctx,
+	.rx_ctx = fi_no_rx_ctx,
+	.rx_size_left = fi_no_rx_size_left,
+	.tx_size_left = fi_no_tx_size_left,
+};
 
-static size_t rxd_copy_rma_iov(struct ofi_rma_iov *dst,
-				const struct fi_rma_iov *src, size_t count)
+struct rxd_x_entry *rxd_rx_entry_init(struct rxd_ep *ep,
+			const struct iovec *iov, size_t iov_count, uint64_t tag,
+			uint64_t ignore, void *context, fi_addr_t addr,
+			uint32_t op, uint32_t flags)
 {
-	int i;
+	struct rxd_x_entry *rx_entry;
 
-	for (i = 0; i < count; i++) {
-		dst->addr = src->addr;
-		dst->len = src->len;
-		dst->key = src->key;
+	rx_entry = rxd_get_rx_entry(ep);
+	if (!rx_entry) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "could not get rx entry\n");
+		return NULL;
 	}
-	return sizeof(*dst) * count;
-}
 
-static uint64_t rxd_ep_copy_data(struct rxd_tx_entry *tx_entry,
-				 char *buf, uint64_t size)
-{
-	const struct iovec *iov;
-	size_t iov_count;
+	rx_entry->peer = addr;
+	rx_entry->flags = flags;
+	rx_entry->bytes_done = 0;
+	rx_entry->offset = 0;
+	rx_entry->next_seg_no = 0;
+	rx_entry->window = rxd_env.max_unacked;
+	rx_entry->iov_count = iov_count;
+	rx_entry->op = op;
+	rx_entry->ignore = ignore;
 
-	switch(tx_entry->op_hdr.op) {
-	case ofi_op_msg:
-		iov = tx_entry->msg.msg_iov;
-		iov_count = tx_entry->msg.msg.iov_count;
-		break;
-	case ofi_op_tagged:
-		iov = tx_entry->tmsg.msg_iov;
-		iov_count = tx_entry->tmsg.tmsg.iov_count;
-		break;
-	case ofi_op_write:
-		iov = tx_entry->write.src_iov;
-		iov_count = tx_entry->write.msg.iov_count;
-		break;
-	case ofi_op_read_rsp:
-		iov = tx_entry->read_rsp.src_iov;
-		iov_count = tx_entry->read_rsp.iov_count;
-		break;
-	default:
-		return 0;
-	}
+	memcpy(rx_entry->iov, iov, sizeof(*rx_entry->iov) * iov_count);
 
-	return ofi_copy_from_iov(buf, size, iov, iov_count, tx_entry->bytes_sent);
-}
+	rx_entry->cq_entry.op_context = context;
+	rx_entry->cq_entry.len = ofi_total_iov_len(iov, iov_count);
+	rx_entry->cq_entry.buf = iov[0].iov_base;
+	rx_entry->cq_entry.tag = tag;
 
-static void rxd_ep_init_data_pkt(struct rxd_ep *ep, struct rxd_peer *peer,
-				 struct rxd_tx_entry *tx_entry,
-				 struct rxd_pkt_data *pkt)
-{
-	uint16_t seg_size;
-
-	seg_size = rxd_ep_domain(ep)->max_mtu_sz - sizeof(struct rxd_pkt_data);
-	seg_size = MIN(seg_size, tx_entry->op_hdr.size - tx_entry->bytes_sent);
+	rx_entry->cq_entry.flags = ofi_rx_cq_flags(op);
+	dlist_init(&rx_entry->entry);
 
-	rxd_init_ctrl_hdr(&pkt->ctrl, ofi_ctrl_data, seg_size, tx_entry->seg_no,
-			   tx_entry->msg_id, tx_entry->rx_key, peer->conn_data);
-	tx_entry->bytes_sent += rxd_ep_copy_data(tx_entry, pkt->data, seg_size);
-	tx_entry->seg_no++;
+	return rx_entry;
 }
 
-static ssize_t rxd_ep_post_data_msg(struct rxd_ep *ep,
-				    struct rxd_tx_entry *tx_entry)
+static inline void *rxd_mr_desc(struct fid_mr *mr, struct rxd_ep *ep)
 {
-	struct rxd_pkt_meta *pkt_meta;
-	struct rxd_pkt_data *pkt;
-	struct rxd_peer *peer;
-	int ret;
+	return (ep->do_local_mr) ? fi_mr_desc(mr) : NULL;
+}
 
-	peer = rxd_ep_getpeer_info(ep, tx_entry->peer);
+int rxd_ep_post_buf(struct rxd_ep *ep)
+{
+	struct rxd_pkt_entry *pkt_entry;
+	ssize_t ret;
 
-	pkt_meta = rxd_tx_pkt_alloc(ep);
-	if (!pkt_meta)
+	pkt_entry = rxd_get_rx_pkt(ep);
+	if (!pkt_entry)
 		return -FI_ENOMEM;
 
-	pkt_meta->tx_entry = tx_entry;
-	pkt = (struct rxd_pkt_data *) pkt_meta->pkt_data;
-	rxd_ep_init_data_pkt(ep, peer, tx_entry, pkt);
-
-	if (tx_entry->op_hdr.size == pkt->ctrl.seg_size)
-		pkt_meta->flags |= RXD_PKT_LAST;
-
-	ret = fi_send(ep->dg_ep, pkt, sizeof(*pkt) + pkt->ctrl.seg_size,
-		      rxd_mr_desc(pkt_meta->mr, ep), tx_entry->peer,
-		      &pkt_meta->context);
+	ret = fi_recv(ep->dg_ep, rxd_pkt_start(pkt_entry),
+		      rxd_ep_domain(ep)->max_mtu_sz,
+		      rxd_mr_desc(pkt_entry->mr, ep),
+		      FI_ADDR_UNSPEC, &pkt_entry->context);
 	if (ret) {
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "send %d failed\n",
-		       pkt->ctrl.seg_no);
+		rxd_release_rx_pkt(ep, pkt_entry);
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "failed to repost\n");
+		return ret;
 	}
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "msg data %" PRIx64 ", seg %d\n",
-	       pkt->ctrl.msg_id, pkt->ctrl.seg_no);
-	dlist_insert_tail(&pkt_meta->entry, &tx_entry->pkt_list);
+	ep->posted_bufs++;
+	slist_insert_tail(&pkt_entry->s_entry, &ep->rx_pkt_list);
 
-	return ret;
+	return 0;
 }
 
-void rxd_ep_free_acked_pkts(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry,
-			    uint32_t last_acked)
+static int rxd_ep_enable(struct rxd_ep *ep)
 {
-	struct rxd_pkt_meta *pkt;
-	struct ofi_ctrl_hdr *ctrl;
+	size_t i;
+	ssize_t ret;
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "freeing all [%" PRIx64 "] pkts < %d\n",
-	       tx_entry->msg_id, last_acked);
-	while (!dlist_empty(&tx_entry->pkt_list)) {
+	ret = fi_ep_bind(ep->dg_ep, &ep->dg_cq->fid, FI_TRANSMIT | FI_RECV);
+	if (ret)
+		return ret;
 
-		pkt = container_of(tx_entry->pkt_list.next,
-				   struct rxd_pkt_meta, entry);
-		ctrl = (struct ofi_ctrl_hdr *) pkt->pkt_data;
-		if (ctrl->seg_no >= last_acked)
+	ret = fi_enable(ep->dg_ep);
+	if (ret)
+		return ret;
+
+	fastlock_acquire(&ep->util_ep.lock);
+	for (i = 0; i < ep->rx_size; i++) {
+		ret = rxd_ep_post_buf(ep);
+		if (ret)
 			break;
+	}
 
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "freeing [%" PRIx64 "] pkt:%d\n",
-		       tx_entry->msg_id, ctrl->seg_no);
-		dlist_remove(&pkt->entry);
-		if (pkt->flags & RXD_LOCAL_COMP)
-			rxd_tx_pkt_free(pkt);
-		else
-			pkt->flags |= RXD_REMOTE_ACK;
-	};
+	fastlock_release(&ep->util_ep.lock);
+	return 0;
 }
 
-static int rxd_ep_retry_pkt(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry,
-			    struct rxd_pkt_meta *pkt)
+/*
+ * Exponential back-off starting at 1ms, max 4s.
+ */
+int rxd_get_timeout(uint8_t retry_cnt)
 {
-	int ret;
-	struct ofi_ctrl_hdr *ctrl;
-
-	ctrl = (struct ofi_ctrl_hdr *)pkt->pkt_data;
-//	if (pkt->retries > RXD_MAX_PKT_RETRY) {
-//		/* todo: report error */
-//		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "Pkt delivery failed\n", ctrl->seg_no);
-//		return -FI_EIO;
-//	}
-//
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "retry packet : %2d, size: %zd, tx_id :%" PRIx64 "\n",
-	       ctrl->seg_no, ctrl->type == ofi_ctrl_start_data ?
-	       ctrl->seg_size + sizeof(struct rxd_pkt_data_start) :
-	       ctrl->seg_size + sizeof(struct rxd_pkt_data),
-	       ctrl->msg_id);
-
-	ret = fi_send(ep->dg_ep, ctrl,
-		      ctrl->type == ofi_ctrl_start_data ?
-		      ctrl->seg_size + sizeof(struct rxd_pkt_data_start) :
-		      ctrl->seg_size + sizeof(struct rxd_pkt_data),
-		      rxd_mr_desc(pkt->mr, ep),
-		      tx_entry->peer, &pkt->context);
-
-//	if (ret != -FI_EAGAIN)
-//		pkt->retries++;
-
-	if (ret && ret != -FI_EAGAIN) {
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "Pkt sent failed seg: %d, ret: %d\n",
-			ctrl->seg_no, ret);
-	}
-
-	return ret;
+	return MIN(1 << retry_cnt, 4000);
 }
 
-//void rxd_resend_pkt(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry )
-//{
-//	struct dlist_entry *pkt_item;
-//	struct rxd_pkt_meta *pkt;
-//	struct ofi_ctrl_hdr *ctrl;
-//
-//	dlist_foreach(&tx_entry->pkt_list, pkt_item) {
-//		pkt = container_of(pkt_item, struct rxd_pkt_meta, entry);
-//		ctrl = (struct ofi_ctrl_hdr *) pkt->pkt_data;
-//
-//		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "resending pkt %d, %p\n",
-//			ctrl->seg_no, ctrl->msg_id);
-//
-//		rxd_ep_retry_pkt(ep, tx_entry, pkt);
-//	}
-//}
-
-void rxd_tx_entry_progress(struct rxd_ep *ep, struct rxd_tx_entry *tx_entry)
+uint64_t rxd_get_retry_time(uint64_t start, uint8_t retry_cnt)
 {
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "tx: %p [%" PRIx64 "]\n",
-		tx_entry, tx_entry->msg_id);
-
-	while ((tx_entry->seg_no < tx_entry->window) &&
-	       (tx_entry->bytes_sent != tx_entry->op_hdr.size)) {
-		if (rxd_ep_post_data_msg(ep, tx_entry))
-			break;
-	}
-	rxd_set_timeout(tx_entry);
+	return start + rxd_get_timeout(retry_cnt);
 }
 
-int rxd_ep_reply_ack(struct rxd_ep *ep, struct ofi_ctrl_hdr *in_ctrl,
-		   uint8_t type, uint16_t seg_size, uint64_t rx_key,
-		   uint64_t source, fi_addr_t dest)
+void rxd_init_data_pkt(struct rxd_ep *ep, struct rxd_x_entry *tx_entry,
+		       struct rxd_pkt_entry *pkt_entry)
 {
-	ssize_t ret;
-	struct rxd_pkt_meta *pkt_meta;
-	struct rxd_pkt_data *pkt;
-	struct rxd_rx_entry *rx_entry;
+	struct rxd_data_pkt *data_pkt = (struct rxd_data_pkt *) (pkt_entry->pkt);
+	uint32_t seg_size;
 
-	pkt_meta = rxd_tx_pkt_alloc(ep);
-	if (!pkt_meta)
-		return -FI_ENOMEM;
+	seg_size = tx_entry->cq_entry.len - tx_entry->bytes_done;
+	seg_size = MIN(rxd_ep_domain(ep)->max_seg_sz, seg_size);
 
-	rx_entry = (rx_key != UINT64_MAX) ? &ep->rx_entry_fs->buf[rx_key] : NULL;
+	data_pkt->base_hdr.version = RXD_PROTOCOL_VERSION;
+	data_pkt->base_hdr.type = (tx_entry->cq_entry.flags &
+				  (FI_READ | FI_REMOTE_READ)) ?
+				   RXD_DATA_READ : RXD_DATA;
 
-	pkt = (struct rxd_pkt_data *)pkt_meta->pkt_data;
-	rxd_init_ctrl_hdr(&pkt->ctrl, type, seg_size,
-			  rx_entry ? rx_entry->exp_seg_no : 0,
-			  in_ctrl->msg_id, rx_key, source);
+	data_pkt->ext_hdr.rx_id = tx_entry->rx_id;
+	data_pkt->ext_hdr.tx_id = tx_entry->tx_id;
+	data_pkt->ext_hdr.seg_no = tx_entry->next_seg_no++;
+	data_pkt->base_hdr.peer = ep->peers[tx_entry->peer].peer_addr;
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "sending ack [%" PRIx64 "] - segno: %d, window: %d\n",
-	       pkt->ctrl.msg_id, pkt->ctrl.seg_no, pkt->ctrl.seg_size);
+	pkt_entry->pkt_size = ofi_copy_from_iov(data_pkt->msg, seg_size,
+						tx_entry->iov,
+						tx_entry->iov_count,
+						tx_entry->bytes_done);
+	pkt_entry->peer = tx_entry->peer;
 
-	pkt_meta->flags = RXD_NOT_ACKED;
-	ret = fi_send(ep->dg_ep, pkt, sizeof(struct rxd_pkt_data),
-		      rxd_mr_desc(pkt_meta->mr, ep),
-		      dest, &pkt_meta->context);
-	if (ret)
-		util_buf_release(ep->tx_pkt_pool, pkt_meta);
+	tx_entry->bytes_done += pkt_entry->pkt_size;
 
-	return ret;
+	pkt_entry->pkt_size += sizeof(*data_pkt) + ep->tx_prefix_size;
 }
 
-#define RXD_TX_ENTRY_ID(ep, tx_entry) (tx_entry - &ep->tx_entry_fs->buf[0])
-
-static void rxd_ep_init_start_pkt(struct rxd_ep *ep, struct rxd_peer *peer,
-				  uint8_t op, struct rxd_tx_entry *tx_entry,
-				  struct rxd_pkt_data_start *pkt, uint32_t flags)
+struct rxd_x_entry *rxd_tx_entry_init(struct rxd_ep *ep, const struct iovec *iov,
+				      size_t iov_count, const struct iovec *res_iov,
+				      size_t res_count, size_t rma_count,
+				      uint64_t data, uint64_t tag, void *context,
+				      fi_addr_t addr, uint32_t op, uint32_t flags)
 {
-	uint64_t msg_size, iov_size;
-	uint16_t seg_size;
-
-	switch (op) {
-	case ofi_op_msg:
-		msg_size = ofi_total_iov_len(tx_entry->msg.msg_iov,
-					     tx_entry->msg.msg.iov_count);
-		seg_size = rxd_ep_start_seg_size(ep, msg_size);
-		rxd_init_op_hdr(&pkt->op, tx_entry->msg.msg.data, msg_size, 0,
-				op, 0, flags);
-		break;
-	case ofi_op_tagged:
-		msg_size = ofi_total_iov_len(tx_entry->tmsg.msg_iov,
-					     tx_entry->tmsg.tmsg.iov_count);
-		seg_size = rxd_ep_start_seg_size(ep, msg_size);
-		rxd_init_op_hdr(&pkt->op, tx_entry->tmsg.tmsg.data, msg_size, 0,
-				op, tx_entry->tmsg.tmsg.tag, flags);
-		break;
-	case ofi_op_write:
-		msg_size = ofi_total_iov_len(tx_entry->write.msg.msg_iov,
-					     tx_entry->write.msg.iov_count);
-		iov_size = rxd_copy_rma_iov((struct ofi_rma_iov *) pkt->data,
-					    tx_entry->write.dst_iov,
-					    tx_entry->write.msg.rma_iov_count);
-		seg_size = MIN(rxd_ep_domain(ep)->max_mtu_sz -
-			       sizeof(struct rxd_pkt_data_start) - iov_size, msg_size);
-		rxd_init_op_hdr(&pkt->op, tx_entry->write.msg.data, msg_size, 0,
-				op, 0, flags);
-		pkt->op.iov_count = tx_entry->write.msg.rma_iov_count;
-		break;
-	case ofi_op_read_req:
-		msg_size = ofi_total_iov_len(tx_entry->read_req.msg.msg_iov,
-					     tx_entry->read_req.msg.iov_count);
-		iov_size = rxd_copy_rma_iov((struct ofi_rma_iov *) pkt->data,
-					    tx_entry->read_req.src_iov,
-					    tx_entry->read_req.msg.rma_iov_count);
-		seg_size = 0;
-		rxd_init_op_hdr(&pkt->op, tx_entry->read_req.msg.data, msg_size,
-				0, op, 0, flags);
-		pkt->op.iov_count = tx_entry->read_req.msg.rma_iov_count;
-		break;
-	case ofi_op_read_rsp:
-		msg_size = ofi_total_iov_len(tx_entry->read_rsp.src_iov,
-					     tx_entry->read_rsp.iov_count);
-		seg_size = rxd_ep_start_seg_size(ep, msg_size);
-		rxd_init_op_hdr(&pkt->op, 0, msg_size, 0, op, 0, flags);
-		pkt->op.remote_idx = tx_entry->read_rsp.peer_msg_id;
-		break;
-	default:
-		seg_size = 0;
-		assert(0);
+	struct rxd_x_entry *tx_entry;
+	struct rxd_domain *rxd_domain = rxd_ep_domain(ep);
+	size_t max_inline;
+
+	tx_entry = rxd_get_tx_entry(ep);
+	if (!tx_entry) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "could not get tx entry\n");
+		return NULL;
 	}
 
-	rxd_init_ctrl_hdr(&pkt->ctrl, ofi_ctrl_start_data, seg_size, 0,
-			   tx_entry->msg_id, peer->conn_data,
-			   peer->conn_data);
-	/* copy op header here because it is used in ep_copy_data call */
-	tx_entry->op_hdr = pkt->op;
-	tx_entry->bytes_sent = rxd_ep_copy_data(tx_entry, pkt->data,
-						seg_size);
-	tx_entry->seg_no++;
-	assert(tx_entry->bytes_sent == seg_size);
-}
+	tx_entry->op = op;
+	tx_entry->peer = addr;
+	tx_entry->flags = flags;
+	tx_entry->bytes_done = 0;
+	tx_entry->offset = 0;
+	tx_entry->next_seg_no = 0;
+	tx_entry->iov_count = iov_count;
+	memcpy(&tx_entry->iov[0], iov, sizeof(*iov) * iov_count);
+	if (res_count) {
+		tx_entry->res_count = res_count;
+		memcpy(&tx_entry->res_iov[0], res_iov, sizeof(*res_iov) * res_count);
+	}
 
-ssize_t rxd_ep_start_xfer(struct rxd_ep *ep, struct rxd_peer *peer,
-			  uint8_t op, struct rxd_tx_entry *tx_entry)
-{
-	struct rxd_pkt_meta *pkt_meta;
-	struct rxd_pkt_data_start *pkt;
-	uint32_t flags;
-	ssize_t ret;
+	tx_entry->cq_entry.op_context = context;
+	tx_entry->cq_entry.len = ofi_total_iov_len(iov, iov_count);
+	tx_entry->cq_entry.buf = iov[0].iov_base;
+	tx_entry->cq_entry.flags = ofi_tx_cq_flags(op);
+	tx_entry->cq_entry.tag = tag;
 
-	pkt_meta = rxd_tx_pkt_alloc(ep);
-	if (!pkt_meta)
-		return -FI_ENOMEM;
+	tx_entry->pkt = NULL;
 
-	pkt_meta->tx_entry = tx_entry;
-	pkt = (struct rxd_pkt_data_start *) pkt_meta->pkt_data;
-	flags = rxd_map_fi_flags(tx_entry->flags);
-	tx_entry->msg_id = RXD_TX_ID(peer->nxt_msg_id,
-				     RXD_TX_ENTRY_ID(ep, tx_entry));
+	max_inline = rxd_domain->max_inline_msg;
+	if (tx_entry->cq_entry.flags & FI_RMA)
+		max_inline -= sizeof(struct ofi_rma_iov) * rma_count;
 
-	rxd_ep_init_start_pkt(ep, peer, op, tx_entry, pkt, flags);
+	if (tx_entry->flags & RXD_TAG_HDR)
+		max_inline -= sizeof(tx_entry->cq_entry.tag);
+	if (tx_entry->flags & RXD_REMOTE_CQ_DATA) {
+		max_inline -= sizeof(tx_entry->cq_entry.data);
+		tx_entry->cq_entry.data = data;
+	}
 
-	if (tx_entry->op_hdr.size == pkt->ctrl.seg_size)
-		pkt_meta->flags |= RXD_PKT_LAST;
+	if (rma_count > 1 || tx_entry->cq_entry.flags & FI_READ ||
+	    tx_entry->cq_entry.len > max_inline)
+		max_inline -= sizeof(struct rxd_sar_hdr);
+	else
+		tx_entry->flags |= RXD_INLINE;
 
-	ret = fi_send(ep->dg_ep, pkt, sizeof(*pkt) + pkt->ctrl.seg_size,
-		      rxd_mr_desc(pkt_meta->mr, ep),
-		      tx_entry->peer, &pkt_meta->context);
-	if (ret) {
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "send %d failed\n",
-		       pkt->ctrl.seg_no);
-	}
+	if (tx_entry->cq_entry.flags & FI_ATOMIC || tx_entry->cq_entry.len <= max_inline)
+		tx_entry->num_segs = 1;
+	else if (tx_entry->cq_entry.flags & FI_READ)
+		tx_entry->num_segs = ofi_div_ceil(tx_entry->cq_entry.len,
+						  rxd_domain->max_seg_sz);
+	else
+		tx_entry->num_segs = ofi_div_ceil(tx_entry->cq_entry.len - max_inline,
+						  rxd_domain->max_seg_sz) + 1;
+
+	if ((tx_entry->op == RXD_READ_REQ || tx_entry->op == RXD_ATOMIC_FETCH ||
+	     tx_entry->op == RXD_ATOMIC_COMPARE) &&
+	    ep->peers[tx_entry->peer].unacked_cnt < rxd_env.max_unacked &&
+	    ep->peers[tx_entry->peer].peer_addr != FI_ADDR_UNSPEC)
+		dlist_insert_tail(&tx_entry->entry,
+				  &ep->peers[tx_entry->peer].rma_rx_list);
+	else
+		dlist_insert_tail(&tx_entry->entry,
+				  &ep->peers[tx_entry->peer].tx_list);
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "start msg %" PRIx64 ", size: %" PRIu64 "\n",
-	       pkt->ctrl.msg_id, tx_entry->op_hdr.size);
-	rxd_set_timeout(tx_entry);
-	dlist_insert_tail(&pkt_meta->entry, &tx_entry->pkt_list);
-	dlist_insert_tail(&tx_entry->entry, &ep->tx_entry_list);
-	peer->nxt_msg_id++;
+	return tx_entry;
+}
 
-	return 0;
+void rxd_tx_entry_free(struct rxd_ep *ep, struct rxd_x_entry *tx_entry)
+{
+	tx_entry->op = RXD_NO_OP;
+	dlist_remove(&tx_entry->entry);
+	rxd_release_tx_entry(ep, tx_entry);
 }
 
-ssize_t rxd_ep_connect(struct rxd_ep *ep, struct rxd_peer *peer, fi_addr_t addr)
+void rxd_insert_unacked(struct rxd_ep *ep, fi_addr_t peer,
+			struct rxd_pkt_entry *pkt_entry)
 {
-	struct rxd_pkt_data *pkt;
-	struct rxd_pkt_meta *pkt_meta;
-	struct rxd_tx_entry *tx_entry;
-	size_t addrlen;
-	ssize_t ret;
+	dlist_insert_tail(&pkt_entry->d_entry,
+			  &ep->peers[peer].unacked);
+	ep->peers[peer].unacked_cnt++;
+	rxd_ep_retry_pkt(ep, pkt_entry);
+}
 
-	if (peer->state != CMAP_IDLE)
-		return -FI_EALREADY;
+ssize_t rxd_ep_post_data_pkts(struct rxd_ep *ep, struct rxd_x_entry *tx_entry)
+{
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_data_pkt *data;
 
-	tx_entry = rxd_tx_entry_alloc(ep, peer, addr, 0, RXD_TX_CONN);
-	if (!tx_entry)
-		return -FI_EAGAIN;
+	while (tx_entry->bytes_done != tx_entry->cq_entry.len) {
+		if (ep->peers[tx_entry->peer].unacked_cnt >= rxd_env.max_unacked)
+			return 0;
 
-	pkt_meta = rxd_tx_pkt_alloc(ep);
-	if (!pkt_meta) {
-		rxd_tx_entry_free(ep, tx_entry);
-		return -FI_ENOMEM;
-	}
+		pkt_entry = rxd_get_tx_pkt(ep);
+		if (!pkt_entry)
+			return -FI_ENOMEM;
 
-	pkt = (struct rxd_pkt_data *) pkt_meta->pkt_data;
-	addrlen = RXD_MAX_DGRAM_ADDR;
-	ret = fi_getname(&ep->dg_ep->fid, pkt->data, &addrlen);
-	if (ret)
-		goto err;
+		if (tx_entry->op == RXD_DATA_READ && !tx_entry->bytes_done) {
+			tx_entry->start_seq = ep->peers[tx_entry->peer].tx_seq_no;
+			ep->peers[tx_entry->peer].tx_seq_no = tx_entry->start_seq +
+							      tx_entry->num_segs;
+		}
 
-	tx_entry->msg_id = RXD_TX_ID(peer->nxt_msg_id,
-				     RXD_TX_ENTRY_ID(ep, tx_entry));
-	rxd_init_ctrl_hdr(&pkt->ctrl, ofi_ctrl_connreq, (uint16_t) addrlen, 0,
-			   tx_entry->msg_id, rxd_ep_conn_data(ep), addr);
+		rxd_init_data_pkt(ep, tx_entry, pkt_entry);
 
-	ret = fi_send(ep->dg_ep, pkt, addrlen + sizeof(struct rxd_pkt_data),
-		      rxd_mr_desc(pkt_meta->mr, ep),
-		      addr, &pkt_meta->context);
-	if (ret)
-		goto err;
+		data = (struct rxd_data_pkt *) (pkt_entry->pkt);
+		data->base_hdr.seq_no = tx_entry->start_seq +
+				        data->ext_hdr.seg_no;
+		if (data->base_hdr.type != RXD_DATA_READ)
+			data->base_hdr.seq_no++;
 
-	FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "sent conn %" PRIx64 "\n",
-	       pkt->ctrl.msg_id);
-	rxd_set_timeout(tx_entry);
-	dlist_insert_tail(&pkt_meta->entry, &tx_entry->pkt_list);
-	dlist_insert_tail(&tx_entry->entry, &ep->tx_entry_list);
-	peer->nxt_msg_id++;
-	peer->state = CMAP_CONNREQ_SENT;
-	return 0;
-err:
-	rxd_tx_entry_free(ep, tx_entry);
-	util_buf_release(ep->tx_pkt_pool, pkt_meta);
-	return ret;
+		rxd_insert_unacked(ep, tx_entry->peer, pkt_entry);
+	}
+
+	return ep->peers[tx_entry->peer].unacked_cnt < rxd_env.max_unacked;
 }
 
-static ssize_t rxd_ep_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
-			       uint64_t flags)
+int rxd_ep_retry_pkt(struct rxd_ep *ep, struct rxd_pkt_entry *pkt_entry)
 {
-	struct rxd_ep *rxd_ep;
-	struct rxd_peer *peer;
-	struct rxd_tx_entry *tx_entry;
-	fi_addr_t peer_addr;
-	ssize_t ret;
-
-	rxd_ep = container_of(ep, struct rxd_ep, util_ep.ep_fid.fid);
+	int ret;
 
-	peer_addr = rxd_av_dg_addr(rxd_ep_av(rxd_ep), msg->addr);
-	peer = rxd_ep_getpeer_info(rxd_ep, peer_addr);
+	if (ep->pending_cnt >= ep->tx_size)
+		return 1;
 
-	fastlock_acquire(&rxd_ep->lock);
-	if (peer->state != CMAP_CONNECTED) {
-		ret = rxd_ep_connect(rxd_ep, peer, peer_addr);
-		fastlock_release(&rxd_ep->lock);
-		if (ret == -FI_EALREADY) {
-			rxd_ep->util_ep.progress(&rxd_ep->util_ep);
-			ret = -FI_EAGAIN;
-		}
-		return ret ? ret : -FI_EAGAIN;
-	}
+	pkt_entry->timestamp = fi_gettime_ms();
 
-	tx_entry = rxd_tx_entry_alloc(rxd_ep, peer, peer_addr, flags,
-				      RXD_TX_MSG);
-	if (!tx_entry) {
-		ret = -FI_EAGAIN;
-		goto out;
+	ret = fi_send(ep->dg_ep, (const void *) rxd_pkt_start(pkt_entry),
+		      pkt_entry->pkt_size, rxd_mr_desc(pkt_entry->mr, ep),
+		      rxd_ep_av(ep)->rxd_addr_table[pkt_entry->peer].dg_addr,
+		      &pkt_entry->context);
+	if (ret) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "error sending packet: %d (%s)\n",
+			ret, fi_strerror(-ret));
+	} else {
+		pkt_entry->flags |= RXD_PKT_IN_USE;
+		ep->pending_cnt++;
 	}
 
-	tx_entry->msg.msg = *msg;
-	memcpy(&tx_entry->msg.msg_iov[0], msg->msg_iov,
-	       sizeof(*msg->msg_iov) * msg->iov_count);
-	ret = rxd_ep_start_xfer(rxd_ep, peer, ofi_op_msg, tx_entry);
-	if (ret)
-		rxd_tx_entry_free(rxd_ep, tx_entry);
-
-out:
-	fastlock_release(&rxd_ep->lock);
 	return ret;
 }
 
-static ssize_t rxd_ep_sendv(struct fid_ep *ep, const struct iovec *iov, void **desc,
-			    size_t count, fi_addr_t dest_addr, void *context)
+static ssize_t rxd_ep_send_rts(struct rxd_ep *rxd_ep, fi_addr_t rxd_addr)
 {
-	struct fi_msg msg;
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_rts_pkt *rts_pkt;
+	ssize_t ret;
+	size_t addrlen;
 
-	memset(&msg, 0, sizeof(msg));
-	msg.msg_iov = iov;
-	msg.desc = desc;
-	msg.iov_count = count;
-	msg.addr = dest_addr;
-	msg.context = context;
+	pkt_entry = rxd_get_tx_pkt(rxd_ep);
+	if (!pkt_entry)
+		return -FI_ENOMEM;
 
-	return rxd_ep_sendmsg(ep, &msg, RXD_USE_OP_FLAGS);
-}
+	rts_pkt = (struct rxd_rts_pkt *) (pkt_entry->pkt);
+	pkt_entry->pkt_size = sizeof(*rts_pkt) + rxd_ep->tx_prefix_size;
+	pkt_entry->peer = rxd_addr;
 
-static ssize_t rxd_ep_send(struct fid_ep *ep, const void *buf, size_t len, void *desc,
-			   fi_addr_t dest_addr, void *context)
-{
-	struct iovec iov;
+	rts_pkt->base_hdr.version = RXD_PROTOCOL_VERSION;
+	rts_pkt->base_hdr.type = RXD_RTS;
+	rts_pkt->rts_addr = rxd_addr;
 
-	iov.iov_base = (void *) buf;
-	iov.iov_len = len;
+	addrlen = RXD_NAME_LENGTH;
+	memset(rts_pkt->source, 0, RXD_NAME_LENGTH);
+	ret = fi_getname(&rxd_ep->dg_ep->fid, (void *) rts_pkt->source,
+			 &addrlen);
+	if (ret) {
+		rxd_release_tx_pkt(rxd_ep, pkt_entry);
+		return ret;
+	}
 
-	return rxd_ep_sendv(ep, &iov, desc, 1, dest_addr, context);
+	rxd_insert_unacked(rxd_ep, rxd_addr, pkt_entry);
+	dlist_insert_tail(&rxd_ep->peers[rxd_addr].entry, &rxd_ep->rts_sent_list);
+
+	return 0;
 }
 
-static ssize_t rxd_ep_inject(struct fid_ep *ep, const void *buf, size_t len,
-			     fi_addr_t dest_addr)
+ssize_t rxd_send_rts_if_needed(struct rxd_ep *ep, fi_addr_t addr)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
-
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-
-	return rxd_ep_sendmsg(ep, &msg, FI_INJECT |
-			       RXD_NO_COMPLETION | RXD_USE_OP_FLAGS);
+	if (ep->peers[addr].peer_addr == FI_ADDR_UNSPEC &&
+	    dlist_empty(&ep->peers[addr].unacked))
+		return rxd_ep_send_rts(ep, addr);
+	return 0;
 }
 
-static ssize_t rxd_ep_senddata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
-				uint64_t data, fi_addr_t dest_addr, void *context)
+static void rxd_init_base_hdr(struct rxd_ep *rxd_ep, void **ptr,
+			      struct rxd_x_entry *tx_entry)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
-
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
+	struct rxd_base_hdr *hdr = (struct rxd_base_hdr *) *ptr;
 
-	msg.msg_iov = &msg_iov;
-	msg.desc = desc;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.context = context;
-	msg.data = data;
+	hdr->version = RXD_PROTOCOL_VERSION;
+	hdr->type = tx_entry->op;
+	hdr->seq_no = 0;
+	hdr->peer = rxd_ep->peers[tx_entry->peer].peer_addr;
+	hdr->flags = tx_entry->flags;
 
-	return rxd_ep_sendmsg(ep, &msg, FI_REMOTE_CQ_DATA | RXD_USE_OP_FLAGS);
+	*ptr = (char *) (*ptr) + sizeof(*hdr);
 }
 
-static ssize_t rxd_ep_injectdata(struct fid_ep *ep, const void *buf, size_t len,
-				 uint64_t data, fi_addr_t dest_addr)
+static void rxd_init_sar_hdr(void **ptr, struct rxd_x_entry *tx_entry,
+			     size_t iov_count)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
-
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
+	struct rxd_sar_hdr *hdr = (struct rxd_sar_hdr *) *ptr;
 
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.data = data;
+	hdr->size = tx_entry->cq_entry.len;
+	hdr->num_segs = tx_entry->num_segs;
+	hdr->tx_id = tx_entry->tx_id;
+	hdr->iov_count = iov_count;
 
-	return rxd_ep_sendmsg(ep, &msg, FI_REMOTE_CQ_DATA | FI_INJECT |
-			       RXD_NO_COMPLETION | RXD_USE_OP_FLAGS);
+	*ptr = (char *) (*ptr) + sizeof(*hdr);
 }
 
-static struct fi_ops_msg rxd_ops_msg = {
-	.size = sizeof(struct fi_ops_msg),
-	.recv = rxd_ep_recv,
-	.recvv = rxd_ep_recvv,
-	.recvmsg = rxd_ep_recvmsg,
-	.send = rxd_ep_send,
-	.sendv = rxd_ep_sendv,
-	.sendmsg = rxd_ep_sendmsg,
-	.inject = rxd_ep_inject,
-	.senddata = rxd_ep_senddata,
-	.injectdata = rxd_ep_injectdata,
-};
-
-static int rxd_peek_trecv(struct dlist_entry *item, const void *arg)
+static void rxd_init_tag_hdr(void **ptr, struct rxd_x_entry *tx_entry)
 {
-	const struct fi_msg_tagged *msg = (const struct fi_msg_tagged *) arg;
-	struct rxd_rx_entry *rx_entry;
-
-	rx_entry = container_of(item, struct rxd_rx_entry, unexp_entry);
-	return ((rx_entry->op_hdr.tag | msg->ignore) ==
-		(msg->tag | msg->ignore) &&
-                ((rx_entry->source == FI_ADDR_UNSPEC) ||
-		 (msg->addr == FI_ADDR_UNSPEC) ||
-                 (rx_entry->source == msg->addr)));
-}
-
-static void rxd_trx_discard_recv(struct rxd_ep *ep,
-				 struct rxd_rx_entry *rx_entry)
-{
-	struct rxd_rx_buf *rx_buf;
-	struct ofi_ctrl_hdr *ctrl;
-	struct rxd_pkt_meta *pkt_meta;
-	struct rxd_pkt_data *pkt;
-	struct rxd_peer *peer;
-	ssize_t ret;
+	struct rxd_tag_hdr *hdr = (struct rxd_tag_hdr *) *ptr;
 
-	rx_buf = rx_entry->unexp_buf;
-	ctrl = (struct ofi_ctrl_hdr *) rx_buf->buf;
-	peer = rxd_ep_getpeer_info(ep, ctrl->conn_id);
+	hdr->tag = tx_entry->cq_entry.tag;
 
-	dlist_remove(&rx_entry->unexp_entry);
-	ep->num_unexp_msg--;
-
-	pkt_meta = rxd_tx_pkt_alloc(ep);
-	if (!pkt_meta)
-		goto out;
-
-	pkt = (struct rxd_pkt_data *) pkt_meta->pkt_data;
-	rxd_init_ctrl_hdr(&pkt->ctrl, ofi_ctrl_discard, 0, 0,
-			   ctrl->msg_id, ctrl->rx_key, peer->conn_data);
-
-	pkt_meta->flags = RXD_NOT_ACKED;
-	ret = fi_send(ep->dg_ep, pkt, sizeof(struct rxd_pkt_data),
-		      rxd_mr_desc(pkt_meta->mr, ep),
-		      peer->fiaddr, &pkt_meta->context);
-	if (ret)
-		util_buf_release(ep->tx_pkt_pool, pkt_meta);
-
-out:
-	rxd_rx_entry_free(ep, rx_entry);
-	rxd_ep_repost_buff(rx_buf);
+	*ptr = (char *) (*ptr) + sizeof(*hdr);
 }
 
-static ssize_t rxd_trx_peek_recv(struct rxd_ep *ep,
-				  const struct fi_msg_tagged *msg, uint64_t flags)
+static void rxd_init_data_hdr(void **ptr, struct rxd_x_entry *tx_entry)
 {
-	struct dlist_entry *match;
-	struct rxd_rx_entry *rx_entry;
-	struct fi_cq_err_entry err_entry = {0};
-	struct fi_cq_tagged_entry cq_entry = {0};
-	struct fi_context *context;
-
-	match = dlist_find_first_match(&ep->unexp_tag_list,
-				       &rxd_peek_trecv, msg);
-	if (!match) {
-		err_entry.op_context = msg->context;
-		err_entry.flags = (FI_MSG | FI_RECV | FI_TAGGED);
-		err_entry.tag = msg->tag;
-		err_entry.err = FI_ENOMSG;
-		err_entry.prov_errno = -FI_ENOMSG;
-		rxd_cq_report_error(rxd_ep_rx_cq(ep), &err_entry);
-		return 0;
-	}
+	struct rxd_data_hdr *hdr = (struct rxd_data_hdr *) *ptr;
 
-	rx_entry = container_of(match, struct rxd_rx_entry, unexp_entry);
-	cq_entry.flags = (FI_MSG | FI_RECV | FI_TAGGED);
-	cq_entry.op_context = msg->context;
-	cq_entry.len = rx_entry->op_hdr.size;
-	cq_entry.buf = NULL;
-	cq_entry.data = rx_entry->op_hdr.data;
-	cq_entry.tag = rx_entry->op_hdr.tag;
-
-	if (flags & FI_CLAIM) {
-		context = (struct fi_context *)msg->context;
-		context->internal[0] = rx_entry;
-		dlist_remove(match);
-	} else if (flags & FI_DISCARD) {
-		rxd_trx_discard_recv(ep, rx_entry);
-	}
+	hdr->cq_data = tx_entry->cq_entry.data;
 
-	rxd_ep_rx_cq(ep)->write_fn(rxd_ep_rx_cq(ep), &cq_entry);
-	return 0;
+	*ptr = (char *) (*ptr) + sizeof(*hdr);
 }
 
-static ssize_t rxd_trx_claim_recv(struct rxd_ep *ep,
-				  const struct fi_msg_tagged *msg, uint64_t flags)
+static void rxd_init_rma_hdr(void **ptr, const struct fi_rma_iov *rma_iov,
+			     size_t rma_count)
 {
-	size_t i;
-	struct fi_context *context;
-	struct rxd_rx_entry *rx_entry;
-	struct rxd_trecv_entry *trecv_entry;
-	struct rxd_peer *peer;
-	struct rxd_rx_buf *rx_buf;
-	struct ofi_ctrl_hdr *ctrl;
-	struct rxd_pkt_data_start *pkt_start;
-
-	if (freestack_isempty(ep->trecv_fs))
-		return -FI_EAGAIN;
-
-	trecv_entry = freestack_pop(ep->trecv_fs);
-	trecv_entry->msg = *msg;
-	trecv_entry->msg.addr = (ep->util_ep.caps & FI_DIRECTED_RECV) ?
-		msg->addr : FI_ADDR_UNSPEC;
-	trecv_entry->flags = flags;
-	for (i = 0; i < msg->iov_count; i++) {
-		trecv_entry->iov[i].iov_base = msg->msg_iov[i].iov_base;
-		trecv_entry->iov[i].iov_len = msg->msg_iov[i].iov_len;
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "post claim trecv: %zu, tag: %" PRIx64 "\n",
-		       msg->msg_iov[i].iov_len, msg->tag);
-	}
+	struct rxd_rma_hdr *hdr = (struct rxd_rma_hdr *) *ptr;
 
-	context = (struct fi_context *) msg->context;
-	rx_entry = context->internal[0];
-	rx_entry->trecv = trecv_entry;
+	memcpy(hdr->rma, rma_iov, sizeof(*rma_iov) * rma_count);
 
-	rx_buf = rx_entry->unexp_buf;
-	peer = rx_entry->peer_info;
-	ctrl = (struct ofi_ctrl_hdr *) rx_buf->buf;
-	pkt_start = (struct rxd_pkt_data_start *) ctrl;
-
-	rxd_ep_handle_data_msg(ep, peer, rx_entry, rx_entry->trecv->iov,
-			     rx_entry->trecv->msg.iov_count, ctrl,
-			     pkt_start->data, rx_buf);
-	return 0;
+	*ptr = (char *) (*ptr) + (sizeof(*rma_iov) * rma_count);
 }
 
-static ssize_t rxd_ep_trecvmsg(struct fid_ep *ep, const struct fi_msg_tagged *msg,
-			       uint64_t flags)
+static void rxd_init_atom_hdr(void **ptr, enum fi_datatype datatype,
+			      enum fi_op atomic_op)
 {
-	ssize_t ret = 0;
-	size_t i;
-	struct rxd_ep *rxd_ep;
-	struct rxd_trecv_entry *trecv_entry;
+	struct rxd_atom_hdr *hdr = (struct rxd_atom_hdr *) *ptr;
 
-	rxd_ep = container_of(ep, struct rxd_ep, util_ep.ep_fid.fid);
-	fastlock_acquire(&rxd_ep->lock);
+	hdr->datatype = datatype;
+	hdr->atomic_op = atomic_op;
 
-	if (flags & FI_PEEK) {
-		ret = rxd_trx_peek_recv(rxd_ep, msg, flags);
-		goto out;
-	} else if (flags & FI_CLAIM) {
-		ret = rxd_trx_claim_recv(rxd_ep, msg, flags);
-		goto out;
-	}
+	*ptr = (char *) (*ptr) + sizeof(*hdr);
+}
 
-	if (freestack_isempty(rxd_ep->trecv_fs)) {
-		ret = -FI_EAGAIN;
-		goto out;
-	}
+static size_t rxd_init_msg(void **ptr, const struct iovec *iov, size_t iov_count,
+			   size_t total_len, size_t avail_len)
+{
+	size_t done;
 
-	trecv_entry = freestack_pop(rxd_ep->trecv_fs);
-	trecv_entry->msg = *msg;
-	trecv_entry->msg.addr = (rxd_ep->util_ep.caps & FI_DIRECTED_RECV) ?
-		msg->addr : FI_ADDR_UNSPEC;
-	trecv_entry->flags = flags;
-	for (i = 0; i < msg->iov_count; i++) {
-		trecv_entry->iov[i].iov_base = msg->msg_iov[i].iov_base;
-		trecv_entry->iov[i].iov_len = msg->msg_iov[i].iov_len;
-		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "post trecv: %zu, tag: %" PRIx64 "\n",
-			msg->msg_iov[i].iov_len, msg->tag);
-	}
-	dlist_init(&trecv_entry->entry);
-	dlist_insert_tail(&trecv_entry->entry, &rxd_ep->trecv_list);
+	done = ofi_copy_from_iov(*ptr, MIN(total_len, avail_len), iov, iov_count, 0);
 
-	if (!dlist_empty(&rxd_ep->unexp_tag_list)) {
-		rxd_ep_check_unexp_tag_list(rxd_ep, trecv_entry);
-	}
-out:
-	fastlock_release(&rxd_ep->lock);
-	return ret;
-}
+	*ptr = (char *) (*ptr) + done;
 
-static ssize_t rxd_ep_trecv(struct fid_ep *ep, void *buf, size_t len, void *desc,
-			    fi_addr_t src_addr,
-			    uint64_t tag, uint64_t ignore, void *context)
-{
-	struct fi_msg_tagged msg;
-	struct iovec msg_iov;
-
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = buf;
-	msg_iov.iov_len = len;
-
-	msg.msg_iov = &msg_iov;
-	msg.desc = &desc;
-	msg.iov_count = 1;
-	msg.addr = src_addr;
-	msg.context = context;
-	msg.tag = tag;
-	msg.ignore = ignore;
-	msg.data = 0;
-
-	return rxd_ep_trecvmsg(ep, &msg, RXD_USE_OP_FLAGS);
+	return done;
 }
 
-static ssize_t rxd_ep_trecvv(struct fid_ep *ep, const struct iovec *iov,
-			     void **desc, size_t count, fi_addr_t src_addr,
-			     uint64_t tag, uint64_t ignore, void *context)
+int rxd_ep_send_op(struct rxd_ep *rxd_ep, struct rxd_x_entry *tx_entry,
+		   const struct fi_rma_iov *rma_iov, size_t rma_count,
+		   const struct iovec *comp_iov, size_t comp_count,
+		   enum fi_datatype datatype, enum fi_op atomic_op)
 {
-	struct fi_msg_tagged msg;
-
-	memset(&msg, 0, sizeof(msg));
-	msg.msg_iov = iov;
-	msg.desc = desc;
-	msg.iov_count = count;
-	msg.addr = src_addr;
-	msg.context = context;
-	msg.tag = tag;
-	msg.ignore = ignore;
-	msg.data = 0;
-
-	return rxd_ep_trecvmsg(ep, &msg, RXD_USE_OP_FLAGS);
-}
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_base_hdr *base_hdr;
+	int ret = 0;
+	size_t len, avail;
+	void *ptr;
 
-static ssize_t rxd_ep_tsendmsg(struct fid_ep *ep, const struct fi_msg_tagged *msg,
-			       uint64_t flags)
-{
-	struct rxd_ep *rxd_ep;
-	struct rxd_peer *peer;
-	struct rxd_tx_entry *tx_entry;
-	fi_addr_t peer_addr;
-	ssize_t ret;
+	pkt_entry = rxd_get_tx_pkt(rxd_ep);
+	if (!pkt_entry)
+		return -FI_ENOMEM;
 
-	rxd_ep = container_of(ep, struct rxd_ep, util_ep.ep_fid.fid);
+	base_hdr = rxd_get_base_hdr(pkt_entry);
+	ptr = (void *) base_hdr;
+	rxd_init_base_hdr(rxd_ep, &ptr, tx_entry);
 
-	peer_addr = rxd_av_dg_addr(rxd_ep_av(rxd_ep), msg->addr);
-	peer = rxd_ep_getpeer_info(rxd_ep, peer_addr);
+	avail = rxd_ep_domain(rxd_ep)->max_inline_msg;
 
-	fastlock_acquire(&rxd_ep->lock);
-	if (peer->state != CMAP_CONNECTED) {
-		ret = rxd_ep_connect(rxd_ep, peer, peer_addr);
-		fastlock_release(&rxd_ep->lock);
-		if (ret == -FI_EALREADY) {
-			rxd_ep->util_ep.progress(&rxd_ep->util_ep);
-			ret = -FI_EAGAIN;
+	if (!(tx_entry->flags & RXD_INLINE)) {
+		rxd_init_sar_hdr(&ptr, tx_entry, rma_count);
+		avail -= sizeof(struct rxd_sar_hdr);
+	}
+	if (tx_entry->flags & RXD_TAG_HDR) {
+		rxd_init_tag_hdr(&ptr, tx_entry);
+		avail -= sizeof(struct rxd_tag_hdr);
+	}
+	if (tx_entry->flags & RXD_REMOTE_CQ_DATA) {
+		rxd_init_data_hdr(&ptr, tx_entry);
+		avail -= sizeof(struct rxd_data_hdr);
+	}
+	if (tx_entry->cq_entry.flags & (FI_RMA | FI_ATOMIC)) {
+		rxd_init_rma_hdr(&ptr, rma_iov, rma_count);
+		avail -= sizeof(struct ofi_rma_iov) * rma_count;
+		if (tx_entry->cq_entry.flags & FI_ATOMIC) {
+			rxd_init_atom_hdr(&ptr, datatype, atomic_op);
+			avail -= sizeof(struct rxd_atom_hdr);
 		}
-		return ret ? ret : -FI_EAGAIN;
 	}
-
-	tx_entry = rxd_tx_entry_alloc(rxd_ep, peer, peer_addr, flags,
-				      RXD_TX_TAG);
-	if (!tx_entry) {
-		ret = -FI_EAGAIN;
-		goto out;
+	if (tx_entry->op != RXD_READ_REQ && atomic_op != FI_ATOMIC_READ) {
+		tx_entry->bytes_done = rxd_init_msg(&ptr, tx_entry->iov,
+						    tx_entry->iov_count,
+						    tx_entry->cq_entry.len, avail);
+		if (tx_entry->op == RXD_ATOMIC_COMPARE) {
+			avail -= tx_entry->bytes_done;
+			len = rxd_init_msg(&ptr, comp_iov, comp_count,
+					   tx_entry->cq_entry.len, avail);
+			if (len != tx_entry->bytes_done) {
+				FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
+					"compare data length mismatch\n");
+			}
+		}
 	}
 
-	tx_entry->tmsg.tmsg = *msg;
-	memcpy(&tx_entry->tmsg.msg_iov[0], msg->msg_iov,
-	       sizeof(*msg->msg_iov) * msg->iov_count);
-	ret = rxd_ep_start_xfer(rxd_ep, peer, ofi_op_tagged, tx_entry);
-	if (ret)
-		rxd_tx_entry_free(rxd_ep, tx_entry);
-
-out:
-	fastlock_release(&rxd_ep->lock);
-	return ret;
-}
+	pkt_entry->peer = tx_entry->peer;
+	pkt_entry->pkt_size = ((char *) ptr - (char *) base_hdr) + rxd_ep->tx_prefix_size;
+
+	if (rxd_ep->peers[tx_entry->peer].unacked_cnt < rxd_env.max_unacked &&
+	    rxd_ep->peers[tx_entry->peer].peer_addr != FI_ADDR_UNSPEC) {
+		tx_entry->start_seq = rxd_set_pkt_seq(&rxd_ep->peers[tx_entry->peer],
+						      pkt_entry);
+		if (tx_entry->op != RXD_READ_REQ && tx_entry->num_segs > 1)
+			rxd_ep->peers[tx_entry->peer].tx_seq_no = tx_entry->start_seq +
+								  tx_entry->num_segs;
+		rxd_insert_unacked(rxd_ep, tx_entry->peer, pkt_entry);
+		if (tx_entry->op != RXD_READ_REQ && tx_entry->num_segs > 1)
+			ret = rxd_ep_post_data_pkts(rxd_ep, tx_entry);
+	} else {
+		tx_entry->pkt = pkt_entry;
+	}
 
-static ssize_t rxd_ep_tsend(struct fid_ep *ep, const void *buf, size_t len,
-			    void *desc, fi_addr_t dest_addr, uint64_t tag,
-			    void *context)
-{
-	struct fi_msg_tagged msg;
-	struct iovec msg_iov;
-
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.desc = &desc;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.context = context;
-	msg.tag = tag;
-
-	return rxd_ep_tsendmsg(ep, &msg, RXD_USE_OP_FLAGS);
+	return ret == -FI_ENOMEM ? ret : 0;
 }
 
-static ssize_t rxd_ep_tsendv(struct fid_ep *ep, const struct iovec *iov,
-			     void **desc, size_t count, fi_addr_t dest_addr,
-			     uint64_t tag, void *context)
+void rxd_ep_send_ack(struct rxd_ep *rxd_ep, fi_addr_t peer)
 {
-	struct fi_msg_tagged msg;
-
-	memset(&msg, 0, sizeof(msg));
-	msg.msg_iov = iov;
-	msg.desc = desc;
-	msg.iov_count = count;
-	msg.addr = dest_addr;
-	msg.context = context;
-	msg.tag = tag;
-
-	return rxd_ep_tsendmsg(ep, &msg, RXD_USE_OP_FLAGS);
-}
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_ack_pkt *ack;
 
-ssize_t	rxd_ep_tinject(struct fid_ep *ep, const void *buf, size_t len,
-			fi_addr_t dest_addr, uint64_t tag)
-{
-	struct fi_msg_tagged msg;
-	struct iovec msg_iov;
-
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.tag = tag;
-	return rxd_ep_tsendmsg(ep, &msg, FI_INJECT |
-				RXD_NO_COMPLETION | RXD_USE_OP_FLAGS);
-}
+	pkt_entry = rxd_get_tx_pkt(rxd_ep);
+	if (!pkt_entry) {
+		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "Unable to send ack\n");
+		return;
+	}
 
-ssize_t rxd_ep_tsenddata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
-			  uint64_t data, fi_addr_t dest_addr, uint64_t tag, void *context)
-{
-	struct fi_msg_tagged msg;
-	struct iovec msg_iov;
-
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.desc = desc;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.context = context;
-	msg.data = data;
-	msg.tag = tag;
-
-	return rxd_ep_tsendmsg(ep, &msg, FI_REMOTE_CQ_DATA | RXD_USE_OP_FLAGS);
+	ack = (struct rxd_ack_pkt *) (pkt_entry->pkt);
+	pkt_entry->pkt_size = sizeof(*ack) + rxd_ep->tx_prefix_size;
+	pkt_entry->peer = peer;
+
+	ack->base_hdr.version = RXD_PROTOCOL_VERSION;
+	ack->base_hdr.type = RXD_ACK;
+	ack->base_hdr.peer = rxd_ep->peers[peer].peer_addr;
+	ack->base_hdr.seq_no = rxd_ep->peers[peer].rx_seq_no;
+	ack->ext_hdr.tx_id = rxd_ep->peers[peer].curr_tx_id;
+	ack->ext_hdr.rx_id = rxd_ep->peers[peer].curr_rx_id;
+	rxd_ep->peers[peer].last_tx_ack = ack->base_hdr.seq_no;
+
+	dlist_insert_tail(&pkt_entry->d_entry, &rxd_ep->ctrl_pkts);
+	if (rxd_ep_retry_pkt(rxd_ep, pkt_entry)) {
+		dlist_remove(&pkt_entry->d_entry);
+		rxd_release_tx_pkt(rxd_ep, pkt_entry);
+	}
 }
 
-ssize_t	rxd_ep_tinjectdata(struct fid_ep *ep, const void *buf, size_t len,
-			    uint64_t data, fi_addr_t dest_addr, uint64_t tag)
+static void rxd_ep_free_res(struct rxd_ep *ep)
 {
-	struct fi_msg_tagged msg;
-	struct iovec msg_iov;
-
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.data = data;
-	msg.tag = tag;
-
-	return rxd_ep_tsendmsg(ep, &msg, FI_REMOTE_CQ_DATA | FI_INJECT |
-				RXD_NO_COMPLETION | RXD_USE_OP_FLAGS);
+	util_buf_pool_destroy(ep->tx_pkt_pool);
+	util_buf_pool_destroy(ep->rx_pkt_pool);
+	util_buf_pool_destroy(ep->tx_entry_pool);
+	util_buf_pool_destroy(ep->rx_entry_pool);
 }
 
-struct fi_ops_tagged rxd_ops_tagged = {
-	.size = sizeof(struct fi_ops_tagged),
-	.recv = rxd_ep_trecv,
-	.recvv = rxd_ep_trecvv,
-	.recvmsg = rxd_ep_trecvmsg,
-	.send = rxd_ep_tsend,
-	.sendv = rxd_ep_tsendv,
-	.sendmsg = rxd_ep_tsendmsg,
-	.inject = rxd_ep_tinject,
-	.senddata = rxd_ep_tsenddata,
-	.injectdata = rxd_ep_tinjectdata,
-};
-
-static void rxd_ep_free_buf_pools(struct rxd_ep *ep)
+static void rxd_close_peer(struct rxd_ep *ep, struct rxd_peer *peer)
 {
-	util_buf_pool_destroy(ep->tx_pkt_pool);
-	util_buf_pool_destroy(ep->rx_pkt_pool);
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_x_entry *x_entry;
+
+	while (!dlist_empty(&peer->unacked)) {
+		dlist_pop_front(&peer->unacked, struct rxd_pkt_entry,
+				pkt_entry, d_entry);
+		rxd_release_tx_pkt(ep, pkt_entry);
+		peer->unacked_cnt--;
+	}
 
-	if (ep->tx_entry_fs)
-		rxd_tx_entry_fs_free(ep->tx_entry_fs);
+	while(!dlist_empty(&peer->tx_list)) {
+		dlist_pop_front(&peer->tx_list, struct rxd_x_entry,
+				x_entry, entry);
+		rxd_tx_entry_free(ep, x_entry);
+	}
 
-	if (ep->rx_entry_fs)
-		rxd_rx_entry_fs_free(ep->rx_entry_fs);
+	while(!dlist_empty(&peer->rx_list)) {
+		dlist_pop_front(&peer->rx_list, struct rxd_x_entry,
+				x_entry, entry);
+		rxd_rx_entry_free(ep, x_entry);
+	}
 
-	if (ep->recv_fs)
-		rxd_recv_fs_free(ep->recv_fs);
+	while(!dlist_empty(&peer->rma_rx_list)) {
+		dlist_pop_front(&peer->rma_rx_list, struct rxd_x_entry,
+				x_entry, entry);
+		rxd_tx_entry_free(ep, x_entry);
+	}
 
-	if (ep->trecv_fs)
-		rxd_trecv_fs_free(ep->trecv_fs);
+	dlist_remove(&peer->entry);
+	peer->active = 0;
 }
 
 static int rxd_ep_close(struct fid *fid)
 {
 	int ret;
 	struct rxd_ep *ep;
+	struct rxd_pkt_entry *pkt_entry;
 	struct slist_entry *entry;
-	struct rxd_rx_buf *buf;
+	struct rxd_peer *peer;
 
 	ep = container_of(fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	dlist_foreach_container(&ep->active_peers, struct rxd_peer, peer, entry)
+		rxd_close_peer(ep, peer);
+
 	ret = fi_close(&ep->dg_ep->fid);
 	if (ret)
 		return ret;
@@ -1308,10 +786,28 @@ static int rxd_ep_close(struct fid *fid)
 	if (ret)
 		return ret;
 
-	while(!slist_empty(&ep->rx_pkt_list)) {
+	while (!slist_empty(&ep->rx_pkt_list)) {
 		entry = slist_remove_head(&ep->rx_pkt_list);
-		buf = container_of(entry, struct rxd_rx_buf, entry);
-		util_buf_release(ep->rx_pkt_pool, buf);
+		pkt_entry = container_of(entry, struct rxd_pkt_entry, s_entry);
+		rxd_release_rx_pkt(ep, pkt_entry);
+	}
+
+	while (!dlist_empty(&ep->unexp_list)) {
+		dlist_pop_front(&ep->unexp_list, struct rxd_pkt_entry,
+				pkt_entry, d_entry);
+		rxd_release_rx_pkt(ep, pkt_entry);
+	}
+
+	while (!dlist_empty(&ep->unexp_tag_list)) {
+		dlist_pop_front(&ep->unexp_tag_list, struct rxd_pkt_entry,
+				pkt_entry, d_entry);
+		rxd_release_rx_pkt(ep, pkt_entry);
+	}
+
+	while (!dlist_empty(&ep->ctrl_pkts)) {
+		dlist_pop_front(&ep->ctrl_pkts, struct rxd_pkt_entry,
+				pkt_entry, d_entry);
+		rxd_release_tx_pkt(ep, pkt_entry);
 	}
 
 	if (ep->util_ep.tx_cq) {
@@ -1330,54 +826,80 @@ static int rxd_ep_close(struct fid *fid)
 		}
 	}
 
-	fastlock_destroy(&ep->lock);
-	rxd_ep_free_buf_pools(ep);
-	free(ep->peer_info);
+	rxd_ep_free_res(ep);
 	ofi_endpoint_close(&ep->util_ep);
 	free(ep);
 	return 0;
 }
 
-static int rxd_ep_bind_cq(struct rxd_ep *ep, struct rxd_cq *cq, uint64_t flags)
+static int rxd_ep_trywait(void *arg)
 {
-	int ret;
+	struct rxd_fabric *rxd_fabric;
+	struct rxd_ep *rxd_ep = (struct rxd_ep *) arg;
+	struct fid *fids[1] = {&rxd_ep->dg_cq->fid};
 
-	if (flags & ~(FI_TRANSMIT | FI_RECV)) {
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "unsupported flags\n");
-		return -FI_EBADFLAGS;
-	}
+	rxd_fabric = container_of(rxd_ep->util_ep.domain->fabric,
+				  struct rxd_fabric, util_fabric);
+
+	return fi_trywait(rxd_fabric->dg_fabric, fids, 1);
+}
+
+static int rxd_ep_get_wait_cq_fd(struct rxd_ep *rxd_ep, enum fi_wait_obj wait_obj)
+{
+	int ret = 0;
 
-	if (((flags & FI_TRANSMIT) && rxd_ep_tx_cq(ep)) ||
-	    ((flags & FI_RECV) && rxd_ep_rx_cq(ep))) {
-		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "duplicate CQ binding\n");
-		return -FI_EINVAL;
+	if (wait_obj == FI_WAIT_FD && (!rxd_ep->dg_cq_fd)) {
+		ret = fi_control(&rxd_ep->dg_cq->fid, FI_GETWAIT,
+				 &rxd_ep->dg_cq_fd);
+		if (ret)
+			FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
+				"Unable to get dg CQ fd\n");
 	}
+	return ret;
+}
 
-	ret = fid_list_insert(&cq->util_cq.ep_list,
-			      &cq->util_cq.ep_list_lock,
-			      &ep->util_ep.ep_fid.fid);
+static int rxd_ep_wait_fd_add(struct rxd_ep *rxd_ep, struct util_wait *wait)
+{
+	return ofi_wait_fd_add(wait, rxd_ep->dg_cq_fd, FI_EPOLL_IN,
+			       rxd_ep_trywait, rxd_ep,
+			       &rxd_ep->util_ep.ep_fid.fid);
+}
+
+static int rxd_dg_cq_open(struct rxd_ep *rxd_ep, enum fi_wait_obj wait_obj)
+{
+	struct rxd_domain *rxd_domain;
+	struct fi_cq_attr cq_attr = {0};
+	int ret;
+
+	assert((wait_obj == FI_WAIT_NONE) || (wait_obj == FI_WAIT_FD));
+
+	cq_attr.size = rxd_ep->tx_size + rxd_ep->rx_size;
+	cq_attr.format = FI_CQ_FORMAT_MSG;
+	cq_attr.wait_obj = wait_obj;
+
+	rxd_domain = container_of(rxd_ep->util_ep.domain, struct rxd_domain,
+				  util_domain);
+
+	ret = fi_cq_open(rxd_domain->dg_domain, &cq_attr, &rxd_ep->dg_cq, rxd_ep);
 	if (ret)
 		return ret;
 
-	if (flags & FI_TRANSMIT) {
-		ep->util_ep.tx_cq = &cq->util_cq;
-		ofi_atomic_inc32(&cq->util_cq.ref);
-		/* TODO: wait handling */
-	}
-
-	if (flags & FI_RECV) {
-		ep->util_ep.rx_cq = &cq->util_cq;
-		ofi_atomic_inc32(&cq->util_cq.ref);
-		/* TODO: wait handling */
-	}
+	ret = rxd_ep_get_wait_cq_fd(rxd_ep, wait_obj);
+	if (ret)
+		goto err;
 
 	return 0;
+err:
+	fi_close(&rxd_ep->dg_cq->fid);
+	return ret;
 }
 
 static int rxd_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 {
 	struct rxd_ep *ep;
 	struct rxd_av *av;
+	struct util_cq *cq;
+	struct util_cntr *cntr;
 	int ret = 0;
 
 	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
@@ -1391,20 +913,54 @@ static int rxd_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 		ret = fi_ep_bind(ep->dg_ep, &av->dg_av->fid, flags);
 		if (ret)
 			return ret;
-
-		ep->peer_info = calloc(av->util_av.count, sizeof(struct rxd_peer));
-		ep->max_peers = av->util_av.count;
-		if (!ep->peer_info)
-			return -FI_ENOMEM;
 		break;
 	case FI_CLASS_CQ:
-		ret = rxd_ep_bind_cq(ep, container_of(bfid, struct rxd_cq,
-						       util_cq.cq_fid.fid), flags);
+		cq = container_of(bfid, struct util_cq, cq_fid.fid);
+
+		ret = ofi_ep_bind_cq(&ep->util_ep, cq, flags);
+		if (ret)
+			return ret;
+
+		if (!ep->dg_cq) {
+			ret = rxd_dg_cq_open(ep, cq->wait ? FI_WAIT_FD : FI_WAIT_NONE);
+			if (ret)
+				return ret;
+		}
+
+		if (cq->wait)
+			ret = rxd_ep_wait_fd_add(ep, cq->wait);
 		break;
 	case FI_CLASS_EQ:
 		break;
 	case FI_CLASS_CNTR:
-		return ofi_ep_bind(&ep->util_ep, bfid, flags);
+		cntr = container_of(bfid, struct util_cntr, cntr_fid.fid);
+
+		ret = ofi_ep_bind_cntr(&ep->util_ep, cntr, flags);
+		if (ret)
+			return ret;
+
+		if (!ep->dg_cq) {
+			ret = rxd_dg_cq_open(ep, cntr->wait ? FI_WAIT_FD : FI_WAIT_NONE);
+			if (ret)
+				return ret;
+		} else if (!ep->dg_cq_fd && cntr->wait) {
+			/* Reopen CQ with WAIT fd set */
+			ret = fi_close(&ep->dg_cq->fid);
+			if (ret) {
+				FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
+					"Unable to close dg CQ: %s\n",
+					fi_strerror(-ret));
+				return ret;
+			} else {
+				ret = rxd_dg_cq_open(ep, FI_WAIT_FD);
+				if (ret)
+					return ret;
+			}
+		}
+
+		if (cntr->wait)
+			ret = rxd_ep_wait_fd_add(ep, cntr->wait);
+		break;
 	default:
 		FI_WARN(&rxd_prov, FI_LOG_EP_CTRL,
 			"invalid fid class\n");
@@ -1468,68 +1024,113 @@ struct fi_ops_cm rxd_ep_cm = {
 	.join = fi_no_join,
 };
 
+static void rxd_peer_timeout(struct rxd_ep *rxd_ep, struct rxd_peer *peer)
+{
+	struct fi_cq_err_entry err_entry;
+	struct rxd_x_entry *tx_entry;
+	struct rxd_pkt_entry *pkt_entry;
+
+	while (!dlist_empty(&peer->tx_list)) {
+		dlist_pop_front(&peer->tx_list, struct rxd_x_entry, tx_entry, entry);
+		memset(&err_entry, 0, sizeof(struct fi_cq_err_entry));
+		rxd_tx_entry_free(rxd_ep, tx_entry);
+		err_entry.op_context = tx_entry->cq_entry.op_context;
+		err_entry.flags = tx_entry->cq_entry.flags;
+		err_entry.err = FI_ECONNREFUSED;
+		err_entry.prov_errno = 0;
+		rxd_cq_report_error(rxd_ep_tx_cq(rxd_ep), &err_entry);
+	}
+
+	while (!dlist_empty(&peer->unacked)) {
+		dlist_pop_front(&peer->unacked, struct rxd_pkt_entry, pkt_entry,
+				d_entry);
+		rxd_release_tx_pkt(rxd_ep, pkt_entry);
+	     	peer->unacked_cnt--;
+	}
+
+	dlist_remove(&peer->entry);
+}
+
+static void rxd_progress_pkt_list(struct rxd_ep *ep, struct rxd_peer *peer)
+{
+	struct rxd_pkt_entry *pkt_entry;
+	uint64_t current;
+	int ret, retry = 0;
+
+	current = fi_gettime_ms();
+	if (peer->retry_cnt > RXD_MAX_PKT_RETRY) {
+		rxd_peer_timeout(ep, peer);
+		return;
+	}
+
+	dlist_foreach_container(&peer->unacked, struct rxd_pkt_entry,
+				pkt_entry, d_entry) {
+		if (pkt_entry->flags & (RXD_PKT_IN_USE | RXD_PKT_ACKED) ||
+		    current < rxd_get_retry_time(pkt_entry->timestamp, peer->retry_cnt))
+			continue;
+		retry = 1;
+		ret = rxd_ep_retry_pkt(ep, pkt_entry);
+		if (ret)
+			break;
+	}
+	if (retry)
+		peer->retry_cnt++;
+
+	if (!dlist_empty(&peer->unacked))
+		ep->next_retry = ep->next_retry == -1 ? peer->retry_cnt :
+				 MIN(ep->next_retry, peer->retry_cnt);
+}
 
 static void rxd_ep_progress(struct util_ep *util_ep)
 {
-	struct dlist_entry *tx_item, *pkt_item;
-	struct rxd_tx_entry *tx_entry;
+	struct rxd_peer *peer;
 	struct fi_cq_msg_entry cq_entry;
-	struct rxd_pkt_meta *pkt;
+	struct dlist_entry *tmp;
 	struct rxd_ep *ep;
-	uint64_t cur_time;
 	ssize_t ret;
 	int i;
 
 	ep = container_of(util_ep, struct rxd_ep, util_ep);
 
-	fastlock_acquire(&ep->lock);
+	fastlock_acquire(&ep->util_ep.lock);
 	for(ret = 1, i = 0;
-	    ret > 0 && (!rxd_progress_spin_count || i < rxd_progress_spin_count);
+	    ret > 0 && (!rxd_env.spin_count || i < rxd_env.spin_count);
 	    i++) {
 		ret = fi_cq_read(ep->dg_cq, &cq_entry, 1);
 		if (ret == -FI_EAGAIN)
 			break;
 
-		if (cq_entry.flags & FI_SEND)
-			rxd_handle_send_comp(&cq_entry);
-		else if (cq_entry.flags & FI_RECV)
+		if (ret == -FI_EAVAIL) {
+			rxd_handle_error(ep);
+			continue;
+		}
+
+		if (cq_entry.flags & FI_RECV)
 			rxd_handle_recv_comp(ep, &cq_entry);
 		else
-			assert (0);
+			rxd_handle_send_comp(ep, &cq_entry);
 	}
 
-	cur_time = fi_gettime_us();
-	dlist_foreach(&ep->tx_entry_list, tx_item) {
-		tx_entry = container_of(tx_item, struct rxd_tx_entry, entry);
+	if (!rxd_env.retry)
+		goto out;
 
-		if (tx_entry->seg_no < tx_entry->window) {
-			rxd_tx_entry_progress(ep, tx_entry);
-		} else if ((tx_entry->retry_time > cur_time) /* &&
-			 dlist_empty(&tx_entry->pkt_list)*/ ) {
+	ep->next_retry = -1;
+	dlist_foreach_container_safe(&ep->rts_sent_list, struct rxd_peer,
+				     peer, entry, tmp)
+		rxd_progress_pkt_list(ep, peer);
 
-			FI_WARN(&rxd_prov, FI_LOG_EP_CTRL, "Progressing waiting entry [%" PRIx64 "]\n",
-				tx_entry->msg_id);
+	dlist_foreach_container_safe(&ep->active_peers, struct rxd_peer,
+				     peer, entry, tmp) {
+		rxd_progress_pkt_list(ep, peer);
+		if (dlist_empty(&peer->unacked))
+			rxd_progress_tx_list(ep, peer);
+	}
 
-			rxd_tx_entry_progress(ep, tx_entry);
-//			rxd_set_timeout(tx_entry);
-		}
+out:
+	while (ep->posted_bufs < ep->rx_size && !ret)
+		ret = rxd_ep_post_buf(ep);
 
-		dlist_foreach(&tx_entry->pkt_list, pkt_item) {
-			pkt = container_of(pkt_item, struct rxd_pkt_meta, entry);
-//			/* TODO: This if check is repeated.  Create a function
-//			 * to perform this check, and figure out what the check
-//			 * is actually doing with the bit-shift, multiply operation.
-//			 */
-//			if (curr_stamp > pkt->us_stamp &&
-//			    curr_stamp - pkt->us_stamp >
-//			    (((uint64_t) 1) << ((uint64_t) pkt->retries + 1)) *
-//			     RXD_RETRY_TIMEOUT) {
-//				pkt->us_stamp = curr_stamp;
-				rxd_ep_retry_pkt(ep, tx_entry, pkt);
-//			}
-		}
-	}
-	fastlock_release(&ep->lock);
+	fastlock_release(&ep->util_ep.lock);
 }
 
 static int rxd_buf_region_alloc_hndlr(void *pool_ctx, void *addr, size_t len,
@@ -1550,49 +1151,58 @@ static void rxd_buf_region_free_hndlr(void *pool_ctx, void *context)
 	fi_close((struct fid *) context);
 }
 
-int rxd_ep_create_buf_pools(struct rxd_ep *ep, struct fi_info *fi_info)
+int rxd_ep_init_res(struct rxd_ep *ep, struct fi_info *fi_info)
 {
+	struct rxd_domain *rxd_domain = rxd_ep_domain(ep);
+	struct util_buf_attr entry_pool_attr = {
+		.size		= sizeof(struct rxd_x_entry),
+		.alignment	= RXD_BUF_POOL_ALIGNMENT,
+		.max_cnt	= 0,
+		.indexing	= {
+			.used 		= 1,
+			.ordered	= 1,
+		},
+	};
+
 	int ret = util_buf_pool_create_ex(
 		&ep->tx_pkt_pool,
-		rxd_ep_domain(ep)->max_mtu_sz + sizeof(struct rxd_pkt_meta),
+		rxd_domain->max_mtu_sz + sizeof(struct rxd_pkt_entry),
 		RXD_BUF_POOL_ALIGNMENT, 0, RXD_TX_POOL_CHUNK_CNT,
-	        (fi_info->mode & FI_LOCAL_MR) ? rxd_buf_region_alloc_hndlr : NULL,
-		(fi_info->mode & FI_LOCAL_MR) ? rxd_buf_region_free_hndlr : NULL,
-		rxd_ep_domain(ep));
+	        ep->do_local_mr ? rxd_buf_region_alloc_hndlr : NULL,
+		ep->do_local_mr ? rxd_buf_region_free_hndlr : NULL,
+		rxd_domain);
 	if (ret)
 		return -FI_ENOMEM;
 
 	ret = util_buf_pool_create_ex(
 		&ep->rx_pkt_pool,
-		rxd_ep_domain(ep)->max_mtu_sz + sizeof (struct rxd_rx_buf),
+		rxd_domain->max_mtu_sz + sizeof (struct rxd_pkt_entry),
 		RXD_BUF_POOL_ALIGNMENT, 0, RXD_RX_POOL_CHUNK_CNT,
-	        (fi_info->mode & FI_LOCAL_MR) ? rxd_buf_region_alloc_hndlr : NULL,
-		(fi_info->mode & FI_LOCAL_MR) ? rxd_buf_region_free_hndlr : NULL,
-		rxd_ep_domain(ep));
+	        ep->do_local_mr ? rxd_buf_region_alloc_hndlr : NULL,
+		ep->do_local_mr ? rxd_buf_region_free_hndlr : NULL,
+		rxd_domain);
 	if (ret)
 		goto err;
 
-	ep->tx_entry_fs = rxd_tx_entry_fs_create(1ULL << RXD_MAX_TX_BITS);
-	if (!ep->tx_entry_fs)
+	entry_pool_attr.chunk_cnt = ep->tx_size;
+	ret = util_buf_pool_create_attr(&entry_pool_attr, &ep->tx_entry_pool);
+	if (ret)
 		goto err;
 
-	ep->rx_entry_fs = rxd_rx_entry_fs_create(1ULL << RXD_MAX_RX_BITS);
-	if (!ep->rx_entry_fs)
+	entry_pool_attr.chunk_cnt = ep->rx_size;
+	ret = util_buf_pool_create_attr(&entry_pool_attr, &ep->rx_entry_pool);
+	if (ret)
 		goto err;
 
-	if (ep->util_ep.caps & FI_MSG) {
-		ep->recv_fs = rxd_recv_fs_create(ep->rx_size);
-		dlist_init(&ep->recv_list);
-		if (!ep->recv_fs)
-			goto err;
-	}
 
-	if (ep->util_ep.caps & FI_TAGGED) {
-		ep->trecv_fs = rxd_trecv_fs_create(ep->rx_size);
-		dlist_init(&ep->trecv_list);
-		if (!ep->trecv_fs)
-			goto err;
-	}
+	dlist_init(&ep->rx_list);
+	dlist_init(&ep->rx_tag_list);
+	dlist_init(&ep->active_peers);
+	dlist_init(&ep->rts_sent_list);
+	dlist_init(&ep->unexp_list);
+	dlist_init(&ep->unexp_tag_list);
+	dlist_init(&ep->ctrl_pkts);
+	slist_init(&ep->rx_pkt_list);
 
 	return 0;
 err:
@@ -1602,39 +1212,48 @@ err:
 	if (ep->rx_pkt_pool)
 		util_buf_pool_destroy(ep->rx_pkt_pool);
 
-	if (ep->tx_entry_fs)
-		rxd_tx_entry_fs_free(ep->tx_entry_fs);
-
-	if (ep->rx_entry_fs)
-		rxd_rx_entry_fs_free(ep->rx_entry_fs);
+	if (ep->tx_entry_pool)
+		util_buf_pool_destroy(ep->tx_entry_pool);
 
-	if (ep->recv_fs)
-		rxd_recv_fs_free(ep->recv_fs);
-
-	if (ep->trecv_fs)
-		rxd_trecv_fs_free(ep->trecv_fs);
+	if (ep->rx_entry_pool)
+		util_buf_pool_destroy(ep->rx_entry_pool);
 
 	return -FI_ENOMEM;
 }
 
+static void rxd_init_peer(struct rxd_ep *ep, uint64_t rxd_addr)
+{
+	ep->peers[rxd_addr].peer_addr = FI_ADDR_UNSPEC;
+	ep->peers[rxd_addr].tx_seq_no = 0;
+	ep->peers[rxd_addr].rx_seq_no = 0;
+	ep->peers[rxd_addr].last_rx_ack = 0;
+	ep->peers[rxd_addr].last_tx_ack = 0;
+	ep->peers[rxd_addr].rx_window = rxd_env.max_unacked;
+	ep->peers[rxd_addr].unacked_cnt = 0;
+	ep->peers[rxd_addr].retry_cnt = 0;
+	ep->peers[rxd_addr].active = 0;
+	dlist_init(&ep->peers[rxd_addr].unacked);
+	dlist_init(&ep->peers[rxd_addr].tx_list);
+	dlist_init(&ep->peers[rxd_addr].rx_list);
+	dlist_init(&ep->peers[rxd_addr].rma_rx_list);
+	dlist_init(&ep->peers[rxd_addr].buf_pkts);
+}
+
 int rxd_endpoint(struct fid_domain *domain, struct fi_info *info,
 		 struct fid_ep **ep, void *context)
 {
 	struct fi_info *dg_info;
 	struct rxd_domain *rxd_domain;
 	struct rxd_ep *rxd_ep;
-	struct fi_cq_attr cq_attr;
-	int ret;
+	int ret, i;
 
-	rxd_ep = calloc(1, sizeof(*rxd_ep));
+	rxd_ep = calloc(1, sizeof(*rxd_ep) + sizeof(struct rxd_peer) *
+			rxd_env.max_peers);
 	if (!rxd_ep)
 		return -FI_ENOMEM;
 
 	rxd_domain = container_of(domain, struct rxd_domain,
 				  util_domain.domain_fid);
-	memset(&cq_attr, 0, sizeof cq_attr);
-	cq_attr.format = FI_CQ_FORMAT_MSG;
-	cq_attr.wait_obj = FI_WAIT_FD;
 
 	ret = ofi_endpoint_init(domain, &rxd_util_prov, info, &rxd_ep->util_ep,
 				context, rxd_ep_progress);
@@ -1647,27 +1266,29 @@ int rxd_endpoint(struct fid_domain *domain, struct fi_info *info,
 	if (ret)
 		goto err2;
 
+	memcpy(dg_info->src_addr, info->src_addr, info->src_addrlen);
 	rxd_ep->do_local_mr = (rxd_domain->mr_mode & FI_MR_LOCAL) ? 1 : 0;
 
 	ret = fi_endpoint(rxd_domain->dg_domain, dg_info, &rxd_ep->dg_ep, rxd_ep);
-	cq_attr.size = dg_info->tx_attr->size + dg_info->rx_attr->size;
-	fi_freeinfo(dg_info);
 	if (ret)
 		goto err2;
 
-	ret = fi_cq_open(rxd_domain->dg_domain, &cq_attr, &rxd_ep->dg_cq, rxd_ep);
-	if (ret)
-		goto err3;
+	rxd_ep->tx_prefix_size = dg_info->tx_attr->mode & FI_MSG_PREFIX ?
+				 dg_info->ep_attr->msg_prefix_size : 0;
+	rxd_ep->rx_prefix_size = dg_info->rx_attr->mode & FI_MSG_PREFIX ?
+				 dg_info->ep_attr->msg_prefix_size : 0;
+	fi_freeinfo(dg_info);
 
-	ret = fi_ep_bind(rxd_ep->dg_ep, &rxd_ep->dg_cq->fid,
-			 FI_TRANSMIT | FI_RECV);
-	if (ret)
-		goto err4;
+	rxd_ep->rx_size = MIN(dg_info->rx_attr->size, info->rx_attr->size);
+	rxd_ep->tx_size = MIN(dg_info->tx_attr->size, info->tx_attr->size);
 
-	rxd_ep->rx_size = info->rx_attr->size;
-	ret = rxd_ep_create_buf_pools(rxd_ep, info);
+	rxd_ep->next_retry = -1;
+	ret = rxd_ep_init_res(rxd_ep, info);
 	if (ret)
-		goto err4;
+		goto err3;
+
+	for (i = 0; i < rxd_env.max_peers; rxd_init_peer(rxd_ep, i++))
+		;
 
 	rxd_ep->util_ep.ep_fid.fid.ops = &rxd_ep_fi_ops;
 	rxd_ep->util_ep.ep_fid.cm = &rxd_ep_cm;
@@ -1675,20 +1296,11 @@ int rxd_endpoint(struct fid_domain *domain, struct fi_info *info,
 	rxd_ep->util_ep.ep_fid.msg = &rxd_ops_msg;
 	rxd_ep->util_ep.ep_fid.tagged = &rxd_ops_tagged;
 	rxd_ep->util_ep.ep_fid.rma = &rxd_ops_rma;
-
-	dlist_init(&rxd_ep->tx_entry_list);
-	dlist_init(&rxd_ep->rx_entry_list);
-	dlist_init(&rxd_ep->wait_rx_list);
-	dlist_init(&rxd_ep->unexp_msg_list);
-	dlist_init(&rxd_ep->unexp_tag_list);
-	slist_init(&rxd_ep->rx_pkt_list);
-	fastlock_init(&rxd_ep->lock);
+	rxd_ep->util_ep.ep_fid.atomic = &rxd_ops_atomic;
 
 	*ep = &rxd_ep->util_ep.ep_fid;
 	return 0;
 
-err4:
-	fi_close(&rxd_ep->dg_cq->fid);
 err3:
 	fi_close(&rxd_ep->dg_ep->fid);
 err2:
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_fabric.c
index dce5a870e..fefd0ae25 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_fabric.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_fabric.c
@@ -74,7 +74,7 @@ int rxd_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
 		void *context)
 {
 	struct rxd_fabric *rxd_fabric;
-	struct fi_info hints, *dg_info;
+	struct fi_info *dg_info;
 	int ret;
 
 	rxd_fabric = calloc(1, sizeof(*rxd_fabric));
@@ -86,41 +86,27 @@ int rxd_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
 	if (ret)
 		goto err1;
 
-	memset(&hints, 0, sizeof hints);
-	if (!(hints.fabric_attr = calloc(1, sizeof(*hints.fabric_attr)))) {
-		ret = -FI_ENOMEM;
-		goto err2;
-	}
-	hints.fabric_attr->name = attr->name;
-
-	ret = ofi_get_core_info(attr->api_version, NULL, NULL, 0, &rxd_util_prov,
-				&hints, rxd_info_to_core, &dg_info);
+	ret = ofi_get_core_info_fabric(&rxd_prov, attr, &dg_info);
 	if (ret) {
+		FI_WARN(&rxd_prov, FI_LOG_FABRIC, "Unable to get core info!\n");
 		ret = -FI_EINVAL;
-		goto err3;
+		goto err2; 
 	}
 
 	ret = fi_fabric(dg_info->fabric_attr, &rxd_fabric->dg_fabric, context);
-	if (ret) {
-		goto err4;
-	}
+	if (ret)
+		goto err3;
 
 	*fabric = &rxd_fabric->util_fabric.fabric_fid;
 	(*fabric)->fid.ops = &rxd_fabric_fi_ops;
 	(*fabric)->ops = &rxd_fabric_ops;
 
-	free(hints.fabric_attr);
 	fi_freeinfo(dg_info);
-
-	fi_param_get_int(&rxd_prov, "spin_count", &rxd_progress_spin_count);
-
 	return 0;
-err4:
-	fi_freeinfo(dg_info);
 err3:
-	free(hints.fabric_attr);
+	fi_freeinfo(dg_info);
 err2:
-	ofi_fabric_close(&rxd_fabric->util_fabric);
+	(void) ofi_fabric_close(&rxd_fabric->util_fabric);
 err1:
 	free(rxd_fabric);
 	return ret;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_init.c
index b3486fa83..2d08f54ed 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_init.c
@@ -35,12 +35,29 @@
 #include <ofi_prov.h>
 #include "rxd.h"
 
+struct rxd_env rxd_env = {
+	.spin_count	= 1000,
+	.retry		= 1,
+	.max_peers	= 1024,
+	.max_unacked	= 128,
+};
+
+static void rxd_init_env(void)
+{
+	fi_param_get_int(&rxd_prov, "spin_count", &rxd_env.spin_count);
+	fi_param_get_bool(&rxd_prov, "retry", &rxd_env.retry);
+	fi_param_get_int(&rxd_prov, "max_peers", &rxd_env.max_peers);
+	fi_param_get_int(&rxd_prov, "max_unacked", &rxd_env.max_unacked);
+}
+
 int rxd_info_to_core(uint32_t version, const struct fi_info *rxd_info,
 		     struct fi_info *core_info)
 {
 	core_info->caps = FI_MSG;
-	core_info->mode = FI_LOCAL_MR;
+	core_info->mode = FI_LOCAL_MR | FI_CONTEXT | FI_MSG_PREFIX;
 	core_info->ep_attr->type = FI_EP_DGRAM;
+
+	core_info->domain_attr->mr_mode = FI_MR_LOCAL | FI_MR_ALLOCATED;
 	return 0;
 }
 
@@ -51,6 +68,12 @@ int rxd_info_to_rxd(uint32_t version, const struct fi_info *core_info,
 	info->mode = rxd_info.mode;
 
 	*info->tx_attr = *rxd_info.tx_attr;
+	info->tx_attr->inject_size = MIN(core_info->ep_attr->max_msg_size,
+			RXD_MAX_MTU_SIZE) - (sizeof(struct rxd_base_hdr) +
+			core_info->ep_attr->msg_prefix_size +
+			sizeof(struct rxd_rma_hdr) + (RXD_IOV_LIMIT *
+			sizeof(struct ofi_rma_iov)) + sizeof(struct rxd_atom_hdr));
+
 	*info->rx_attr = *rxd_info.rx_attr;
 	*info->ep_attr = *rxd_info.ep_attr;
 	*info->domain_attr = *rxd_info.domain_attr;
@@ -73,7 +96,7 @@ static void rxd_fini(void)
 struct fi_provider rxd_prov = {
 	.name = OFI_UTIL_PREFIX "rxd",
 	.version = FI_VERSION(RXD_MAJOR_VERSION, RXD_MINOR_VERSION),
-	.fi_version = RXD_FI_VERSION,
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = rxd_getinfo,
 	.fabric = rxd_fabric,
 	.cleanup = rxd_fini
@@ -83,6 +106,14 @@ RXD_INI
 {
 	fi_param_define(&rxd_prov, "spin_count", FI_PARAM_INT,
 			"Number of iterations to receive packets (0 - infinite)");
+	fi_param_define(&rxd_prov, "retry", FI_PARAM_BOOL,
+			"Toggle packet retrying (default: yes)");
+	fi_param_define(&rxd_prov, "max_peers", FI_PARAM_INT,
+			"Maximum number of peers to track (default: 1024)");
+	fi_param_define(&rxd_prov, "max_unacked", FI_PARAM_INT,
+			"Maximum number of packets to send at once (default: 128)");
+
+	rxd_init_env();
 
 	return &rxd_prov;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_msg.c
new file mode 100644
index 000000000..2d4b45bd1
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_msg.c
@@ -0,0 +1,376 @@
+/*
+ * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdlib.h>
+#include <string.h>
+#include <ofi_mem.h>
+#include <ofi_iov.h>
+#include "rxd.h"
+
+static int rxd_match_unexp(struct dlist_entry *item, const void *arg)
+{
+	struct rxd_x_entry *rx_entry = (struct rxd_x_entry *) arg;
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_base_hdr *hdr;
+
+	pkt_entry = container_of(item, struct rxd_pkt_entry, d_entry);
+	hdr = rxd_get_base_hdr(pkt_entry);
+
+	if (!rxd_match_addr(rx_entry->peer, hdr->peer))
+		return 0;
+
+	if (hdr->type != RXD_TAGGED)
+		return 1;
+
+	return rxd_match_tag(rx_entry->cq_entry.tag, rx_entry->ignore,
+			     rxd_get_tag_hdr(pkt_entry)->tag);
+}
+
+static int rxd_ep_check_unexp_msg_list(struct rxd_ep *ep,
+					struct dlist_entry *unexp_list,
+					struct dlist_entry *rx_list,
+					struct rxd_x_entry *rx_entry)
+{
+	struct dlist_entry *match;
+	struct rxd_x_entry *progress_entry, *dup_entry = NULL;
+	struct rxd_pkt_entry *pkt_entry;
+	struct rxd_base_hdr *base_hdr;
+	struct rxd_sar_hdr *sar_hdr = NULL;
+	struct rxd_tag_hdr *tag_hdr = NULL;
+	struct rxd_data_hdr *data_hdr = NULL;
+	struct rxd_atom_hdr *atom_hdr = NULL;
+	struct rxd_rma_hdr *rma_hdr = NULL;
+	void *msg = NULL;
+	size_t msg_size, total_size;
+
+	while (!dlist_empty(unexp_list)) {
+		match = dlist_remove_first_match(unexp_list, &rxd_match_unexp,
+						 (void *) rx_entry);
+		if (!match)
+			return 0;
+
+		FI_DBG(&rxd_prov, FI_LOG_EP_CTRL, "progressing unexp msg entry\n");
+	
+		pkt_entry = container_of(match, struct rxd_pkt_entry, d_entry);
+		base_hdr = rxd_get_base_hdr(pkt_entry);
+
+		rxd_unpack_hdrs(pkt_entry->pkt_size - ep->rx_prefix_size,
+				base_hdr, &sar_hdr, &tag_hdr,
+				&data_hdr, &rma_hdr, &atom_hdr, &msg, &msg_size);
+
+		total_size = sar_hdr ? sar_hdr->size : msg_size;
+		if (rx_entry->flags & RXD_MULTI_RECV)
+			dup_entry = rxd_progress_multi_recv(ep, rx_entry, total_size);
+
+		progress_entry = dup_entry ? dup_entry : rx_entry;
+	
+		progress_entry->cq_entry.len = MIN(rx_entry->cq_entry.len, total_size);
+
+		rxd_progress_op(ep, progress_entry, pkt_entry, base_hdr, sar_hdr, tag_hdr,
+				data_hdr, rma_hdr, atom_hdr, &msg, msg_size);
+		rxd_release_repost_rx(ep, pkt_entry);
+		rxd_ep_send_ack(ep, base_hdr->peer);
+
+		if (!dup_entry)
+			return 1;
+	}
+
+	return 0;
+}
+
+ssize_t rxd_ep_generic_recvmsg(struct rxd_ep *rxd_ep, const struct iovec *iov,
+			       size_t iov_count, fi_addr_t addr, uint64_t tag,
+			       uint64_t ignore, void *context, uint32_t op,
+			       uint32_t rxd_flags)
+{
+	ssize_t ret = 0;
+	struct rxd_x_entry *rx_entry;
+	struct dlist_entry *unexp_list, *rx_list;
+
+	assert(iov_count <= RXD_IOV_LIMIT);
+	assert(!(rxd_flags & RXD_MULTI_RECV) || iov_count == 1);
+
+	fastlock_acquire(&rxd_ep->util_ep.lock);
+	fastlock_acquire(&rxd_ep->util_ep.rx_cq->cq_lock);
+
+	if (ofi_cirque_isfull(rxd_ep->util_ep.rx_cq->cirq)) {
+		ret = -FI_EAGAIN;
+		goto out;
+	}
+
+	rx_entry = rxd_rx_entry_init(rxd_ep, iov, iov_count, tag, ignore, context,
+				(rxd_ep->util_ep.caps & FI_DIRECTED_RECV &&
+				addr != FI_ADDR_UNSPEC) ?
+				rxd_ep_av(rxd_ep)->fi_addr_table[addr] :
+				FI_ADDR_UNSPEC, op, rxd_flags);
+	if (!rx_entry) {
+		ret = -FI_EAGAIN;
+		goto out;
+	}
+
+	if (op == ofi_op_tagged) {
+		unexp_list = &rxd_ep->unexp_tag_list;
+		rx_list = &rxd_ep->rx_tag_list;
+	} else {
+		unexp_list = &rxd_ep->unexp_list;
+		rx_list = &rxd_ep->rx_list;
+	}
+
+	if (!dlist_empty(unexp_list) &&
+	    rxd_ep_check_unexp_msg_list(rxd_ep, unexp_list, rx_list, rx_entry))
+		goto out;
+
+	dlist_insert_tail(&rx_entry->entry, rx_list);
+out:
+	fastlock_release(&rxd_ep->util_ep.rx_cq->cq_lock);
+	fastlock_release(&rxd_ep->util_ep.lock);
+	return ret;
+}
+
+static ssize_t rxd_ep_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+			      uint64_t flags)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_ep_generic_recvmsg(ep, msg->msg_iov, msg->iov_count,
+				      msg->addr, 0, ~0, msg->context, ofi_op_msg,
+				      rxd_flags(flags));
+}
+
+static ssize_t rxd_ep_recv(struct fid_ep *ep_fid, void *buf, size_t len, void *desc,
+			   fi_addr_t src_addr, void *context)
+{
+	struct rxd_ep *ep;
+	struct iovec msg_iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	msg_iov.iov_base = buf;
+	msg_iov.iov_len = len;
+
+	return rxd_ep_generic_recvmsg(ep, &msg_iov, 1, src_addr, 0, ~0, context,
+				      ofi_op_msg, rxd_ep_rx_flags(ep));
+}
+
+static ssize_t rxd_ep_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+			    size_t count, fi_addr_t src_addr, void *context)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_ep_generic_recvmsg(ep, iov, count, src_addr,
+				      0, ~0, context, ofi_op_msg, rxd_ep_rx_flags(ep));
+}
+
+ssize_t rxd_ep_generic_inject(struct rxd_ep *rxd_ep, const struct iovec *iov,
+			      size_t iov_count, fi_addr_t addr, uint64_t tag,
+			      uint64_t data, uint32_t op, uint32_t rxd_flags)
+{
+	struct rxd_x_entry *tx_entry;
+	ssize_t ret = -FI_EAGAIN;
+	fi_addr_t rxd_addr;
+
+	assert(iov_count <= RXD_IOV_LIMIT);
+	assert(ofi_total_iov_len(iov, iov_count) <=
+	       rxd_ep_domain(rxd_ep)->max_inline_msg);
+
+	fastlock_acquire(&rxd_ep->util_ep.lock);
+	fastlock_acquire(&rxd_ep->util_ep.tx_cq->cq_lock);
+
+	if (ofi_cirque_isfull(rxd_ep->util_ep.tx_cq->cirq))
+		goto out;
+
+	rxd_addr = rxd_ep_av(rxd_ep)->fi_addr_table[addr];
+	ret = rxd_send_rts_if_needed(rxd_ep, rxd_addr);
+	if (ret)
+		goto out;
+
+	tx_entry = rxd_tx_entry_init(rxd_ep, iov, iov_count, NULL, 0, 0, data,
+				     tag, NULL, rxd_addr, op, rxd_flags | RXD_INJECT);
+	if (!tx_entry)
+		goto out;
+
+	ret = rxd_ep_send_op(rxd_ep, tx_entry, NULL, 0, NULL, 0, 0, 0);
+	if (ret)
+		rxd_tx_entry_free(rxd_ep, tx_entry);
+
+out:
+	fastlock_release(&rxd_ep->util_ep.tx_cq->cq_lock);
+	fastlock_release(&rxd_ep->util_ep.lock);
+	return ret;
+}
+
+ssize_t rxd_ep_generic_sendmsg(struct rxd_ep *rxd_ep, const struct iovec *iov,
+			       size_t iov_count, fi_addr_t addr, uint64_t tag,
+			       uint64_t data, void *context, uint32_t op,
+			       uint32_t rxd_flags)
+{
+	struct rxd_x_entry *tx_entry;
+	ssize_t ret = -FI_EAGAIN;
+	fi_addr_t rxd_addr;
+
+	assert(iov_count <= RXD_IOV_LIMIT);
+
+	if (rxd_flags & RXD_INJECT)
+		return rxd_ep_generic_inject(rxd_ep, iov, iov_count, addr, tag, 0,
+					     op, rxd_flags);
+
+	fastlock_acquire(&rxd_ep->util_ep.lock);
+	fastlock_acquire(&rxd_ep->util_ep.tx_cq->cq_lock);
+
+	if (ofi_cirque_isfull(rxd_ep->util_ep.tx_cq->cirq))
+		goto out;
+
+	rxd_addr = rxd_ep_av(rxd_ep)->fi_addr_table[addr];
+	ret = rxd_send_rts_if_needed(rxd_ep, rxd_addr);
+	if (ret)
+		goto out;
+
+	tx_entry = rxd_tx_entry_init(rxd_ep, iov, iov_count, NULL, 0, 0,
+				     data, tag, context, rxd_addr, op, rxd_flags);
+	if (!tx_entry)
+		goto out;
+
+	ret = rxd_ep_send_op(rxd_ep, tx_entry, NULL, 0, NULL, 0, 0, 0);
+	if (ret)
+		rxd_tx_entry_free(rxd_ep, tx_entry);
+
+out:
+	fastlock_release(&rxd_ep->util_ep.tx_cq->cq_lock);
+	fastlock_release(&rxd_ep->util_ep.lock);
+	return ret;
+}
+
+static ssize_t rxd_ep_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+			      uint64_t flags)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_ep_generic_sendmsg(ep, msg->msg_iov, msg->iov_count,
+				   msg->addr, 0, msg->data, msg->context,
+				   ofi_op_msg, rxd_flags(flags));
+
+}
+
+static ssize_t rxd_ep_sendv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+			    size_t count, fi_addr_t dest_addr, void *context)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_ep_generic_sendmsg(ep, iov, count, dest_addr, 0,
+				      0, context, ofi_op_msg,
+				      rxd_ep_tx_flags(ep));
+}
+
+static ssize_t rxd_ep_send(struct fid_ep *ep_fid, const void *buf, size_t len,
+			   void *desc, fi_addr_t dest_addr, void *context)
+{
+	struct rxd_ep *ep;
+	struct iovec iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
+
+	return rxd_ep_generic_sendmsg(ep, &iov, 1, dest_addr, 0,
+				      0, context, ofi_op_msg,
+				      rxd_ep_tx_flags(ep));
+}
+
+static ssize_t rxd_ep_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
+			     fi_addr_t dest_addr)
+{
+	struct rxd_ep *ep;
+	struct iovec iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
+
+	return rxd_ep_generic_inject(ep, &iov, 1, dest_addr, 0, 0, ofi_op_msg,
+				     RXD_NO_TX_COMP | RXD_INJECT);
+}
+
+static ssize_t rxd_ep_senddata(struct fid_ep *ep_fid, const void *buf, size_t len,
+			       void *desc, uint64_t data, fi_addr_t dest_addr,
+			       void *context)
+{
+	struct rxd_ep *ep;
+	struct iovec iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
+
+	return rxd_ep_generic_sendmsg(ep, &iov, 1, dest_addr, 0, data, context,
+				      ofi_op_msg, rxd_ep_tx_flags(ep) |
+				      RXD_REMOTE_CQ_DATA);
+}
+
+static ssize_t rxd_ep_injectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
+				 uint64_t data, fi_addr_t dest_addr)
+{
+	struct rxd_ep *ep;
+	struct iovec iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
+
+	return rxd_ep_generic_inject(ep, &iov, 1, dest_addr, 0, data, ofi_op_msg,
+				     RXD_NO_TX_COMP | RXD_INJECT |
+				     RXD_REMOTE_CQ_DATA);
+}
+
+struct fi_ops_msg rxd_ops_msg = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = rxd_ep_recv,
+	.recvv = rxd_ep_recvv,
+	.recvmsg = rxd_ep_recvmsg,
+	.send = rxd_ep_send,
+	.sendv = rxd_ep_sendv,
+	.sendmsg = rxd_ep_sendmsg,
+	.inject = rxd_ep_inject,
+	.senddata = rxd_ep_senddata,
+	.injectdata = rxd_ep_injectdata,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_proto.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_proto.h
new file mode 100644
index 000000000..dcaab88ed
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_proto.h
@@ -0,0 +1,178 @@
+/*
+ * Copyright (c) 2015-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#if HAVE_CONFIG_H
+#  include <config.h>
+#endif /* HAVE_CONFIG_H */
+
+#include <ofi.h>
+#include <ofi_proto.h>
+
+#ifndef _RXD_PROTO_H_
+#define _RXD_PROTO_H_
+
+#define RXD_IOV_LIMIT		4
+#define RXD_NAME_LENGTH		64
+
+enum rxd_pkt_type {
+	RXD_MSG			= ofi_op_msg,
+	RXD_TAGGED		= ofi_op_tagged,
+	RXD_READ_REQ		= ofi_op_read_req,
+	RXD_WRITE		= ofi_op_write,
+	RXD_ATOMIC		= ofi_op_atomic,
+	RXD_ATOMIC_FETCH	= ofi_op_atomic_fetch,
+	RXD_ATOMIC_COMPARE	= ofi_op_atomic_compare,
+	RXD_RTS,
+	RXD_CTS,
+	RXD_ACK,
+	RXD_DATA,
+	RXD_DATA_READ,
+	RXD_NO_OP,
+};
+
+/* Base header: all packets must start with base_hdr
+ * 	- version: RXD version the app is using
+ * 	- type: type of message (see above definitions)
+ * 	- flags: any neccesary flags including hdr flags indicating which headers
+ * 		 are included in the packet
+ * 	- peer: RX side peer address (exchanged during RTS-CTS process)
+ * 	- seq_no: sequence number (per peer)
+ */
+struct rxd_base_hdr {
+	uint8_t		version;
+	uint8_t		type;
+	uint16_t	flags;
+	uint32_t	peer;
+	uint64_t	seq_no;
+};
+
+/*
+ * Extended header: used for large transfers and ACKs
+ * 	- tx_id/rx_id:
+ * 		- for large messages: the tx/rx index for the messages
+ * 		- for ACKs: the tx/rx index which the ACK corresponds to
+ */
+struct rxd_ext_hdr {
+	uint32_t	tx_id;
+	uint32_t	rx_id;
+	uint64_t	seg_no;
+};
+
+/*
+ * Ready to send: initialize peer communication and exchange addressing info
+ * 	- rts_addr: local address for peer sending RTS
+ * 	- source: name of transmitting endpoint for peer to add to AV
+ */
+struct rxd_rts_pkt {
+	struct rxd_base_hdr	base_hdr;
+	uint64_t		rts_addr;
+	uint8_t			source[RXD_NAME_LENGTH];
+};
+
+/*
+ * Clear to send: response to RTS request
+ * 	- rts_addr: peer address packet is responding to
+ * 	- cts_addr: local address for peer
+ */
+struct rxd_cts_pkt {
+	struct	rxd_base_hdr	base_hdr;
+	uint64_t		rts_addr;
+	uint64_t		cts_addr;
+};
+
+/*
+ * ACK: to signal received packets and send tx/rx id info
+ */
+struct rxd_ack_pkt {
+	struct rxd_base_hdr	base_hdr;
+	struct rxd_ext_hdr	ext_hdr;
+	//TODO fill in more fields? Selective ack?
+};
+
+/*
+ * Data: send larger block of data using known tx/rx ids for matching
+ */
+struct rxd_data_pkt {
+	struct rxd_base_hdr	base_hdr;
+	struct rxd_ext_hdr	ext_hdr;
+
+	char			msg[];
+};
+
+/*
+ * The below five headers are used for op pkts and can be used in combination.
+ * The presence of each header is determined by either op type or flags (in base_hr).
+ * The op header order is as follows:
+ * base_hdr (present for all packets)
+ *
+ * sar_hdr: for all messages requiring more than one packet
+ * 	- lack of the sar_hdr is signaled by base_hdr->flags & RXD_INLINE
+ * tag_hdr: for all tagged messages
+ * 	- signaled by base_hdr->flags & RXD_TAG_HDR
+ * data_hdr: for messages carrying remote CQ data
+ * 	- signaled by base_hdr->flags & RXD_REMOTE_CQ_DATA
+ * rma_hdr: for FI_RMA and FI_ATOMIC operations
+ * 	- signaled by base_hdr->type = RXD_READ_REQ, RXD_WRITE, RXD_ATOMIC,
+ * 	  RXD_ATOMIC_FETCH, and RXD_ATOMIC_COMPARE
+ * atom_hdr: for FI_ATOMIC operations
+ * 	- signaled by base_hdr->type = RXD_ATOMIC, RXD_ATOMIC_FETCH,
+ * 	  RXD_ATOMIC_COMPARE
+ * 
+ * Any data in the packet following these headers is part of the incoming packet message
+ */
+
+struct rxd_sar_hdr {
+	uint64_t		size;
+	uint64_t		num_segs;
+	uint32_t		tx_id;
+	uint8_t			iov_count;
+	uint8_t			resv[3];
+};
+
+struct rxd_tag_hdr {
+	uint64_t	tag;
+};
+
+struct rxd_data_hdr {
+	uint64_t	cq_data;
+};
+
+struct rxd_rma_hdr {
+	struct ofi_rma_iov	rma[RXD_IOV_LIMIT];
+};
+
+struct rxd_atom_hdr {
+	uint32_t	datatype;
+	uint32_t	atomic_op;
+};
+
+#endif
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_rma.c
index ce4c5b438..fb739754e 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_rma.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_rma.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2016 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -33,309 +33,273 @@
 #include <stdlib.h>
 #include <string.h>
 #include <ofi_mem.h>
+#include <ofi_iov.h>
 #include "rxd.h"
 
-ssize_t	rxd_ep_readmsg(struct fid_ep *ep, const struct fi_msg_rma *msg,
-		       uint64_t flags)
+static ssize_t rxd_generic_write_inject(struct rxd_ep *rxd_ep,
+		const struct iovec *iov, size_t iov_count,
+		const struct fi_rma_iov *rma_iov, size_t rma_count,
+		fi_addr_t addr, void *context, uint32_t op, uint64_t data,
+		uint32_t rxd_flags)
 {
-	struct rxd_ep *rxd_ep;
-	struct rxd_peer *peer;
-	struct rxd_tx_entry *tx_entry;
-	uint64_t peer_addr;
-	ssize_t ret;
-
-	rxd_ep = container_of(ep, struct rxd_ep, util_ep.ep_fid);
-
-	peer_addr = rxd_av_dg_addr(rxd_ep_av(rxd_ep), msg->addr);
-	peer = rxd_ep_getpeer_info(rxd_ep, peer_addr);
-
-	fastlock_acquire(&rxd_ep->lock);
-	if (peer->state != CMAP_CONNECTED) {
-		ret = rxd_ep_connect(rxd_ep, peer, peer_addr);
-		fastlock_release(&rxd_ep->lock);
-		if (ret == -FI_EALREADY) {
-			rxd_ep->util_ep.progress(&rxd_ep->util_ep);
-			ret = -FI_EAGAIN;
-		}
-		return ret ? ret : -FI_EAGAIN;
-	}
+	struct rxd_x_entry *tx_entry;
+	fi_addr_t rxd_addr;
+	ssize_t ret = -FI_EAGAIN;
+
+	assert(iov_count <= RXD_IOV_LIMIT && rma_count <= RXD_IOV_LIMIT);
+	assert(ofi_total_iov_len(iov, iov_count) <= rxd_ep_domain(rxd_ep)->max_inline_rma);
 
-	tx_entry = rxd_tx_entry_alloc(rxd_ep, peer, peer_addr, flags,
-				      RXD_TX_READ_REQ);
-	if (!tx_entry) {
-		ret = -FI_EAGAIN;
+	fastlock_acquire(&rxd_ep->util_ep.lock);
+	fastlock_acquire(&rxd_ep->util_ep.tx_cq->cq_lock);
+
+	if (ofi_cirque_isfull(rxd_ep->util_ep.tx_cq->cirq))
+		goto out;
+
+	rxd_addr = rxd_ep_av(rxd_ep)->fi_addr_table[addr];
+	ret = rxd_send_rts_if_needed(rxd_ep, rxd_addr);
+	if (ret)
+		goto out;
+
+	tx_entry = rxd_tx_entry_init(rxd_ep, iov, iov_count, NULL, 0, rma_count, data,
+				     0, context, rxd_addr, op, rxd_flags);
+	if (!tx_entry)
+		goto out;
+
+	ret = rxd_ep_send_op(rxd_ep, tx_entry, rma_iov, rma_count, NULL, 0, 0, 0);
+	if (ret) {
+		rxd_tx_entry_free(rxd_ep, tx_entry);
 		goto out;
 	}
 
-	tx_entry->read_req.msg = *msg;
-	memcpy(&tx_entry->read_req.dst_iov[0], msg->msg_iov,
-	       sizeof(*msg->msg_iov)* msg->iov_count);
-	memcpy(&tx_entry->read_req.src_iov[0], msg->rma_iov,
-	       sizeof(*msg->rma_iov) * msg->rma_iov_count);
-	ret = rxd_ep_start_xfer(rxd_ep, peer, ofi_op_read_req, tx_entry);
+	if (tx_entry->op == RXD_READ_REQ)
+		goto out;
+
+	ret = 0;
+
+out:
+	fastlock_release(&rxd_ep->util_ep.tx_cq->cq_lock);
+	fastlock_release(&rxd_ep->util_ep.lock);
+	return ret;
+}
+
+ssize_t rxd_generic_rma(struct rxd_ep *rxd_ep, const struct iovec *iov,
+	size_t iov_count, const struct fi_rma_iov *rma_iov, size_t rma_count,
+	void **desc, fi_addr_t addr, void *context, uint32_t op, uint64_t data,
+	uint32_t rxd_flags)
+{
+	struct rxd_x_entry *tx_entry;
+	fi_addr_t rxd_addr;
+	ssize_t ret = -FI_EAGAIN;
+
+	if (rxd_flags & RXD_INJECT)
+		return rxd_generic_write_inject(rxd_ep, iov, iov_count, rma_iov,
+						rma_count, addr, context, op,
+						data, rxd_flags);
+
+	assert(iov_count <= RXD_IOV_LIMIT && rma_count <= RXD_IOV_LIMIT);
+
+	fastlock_acquire(&rxd_ep->util_ep.lock);
+	fastlock_acquire(&rxd_ep->util_ep.tx_cq->cq_lock);
+
+	if (ofi_cirque_isfull(rxd_ep->util_ep.tx_cq->cirq))
+		goto out;
+
+	rxd_addr = rxd_ep_av(rxd_ep)->fi_addr_table[addr];
+	ret = rxd_send_rts_if_needed(rxd_ep, rxd_addr);
+	if (ret)
+		goto out;
+
+	tx_entry = rxd_tx_entry_init(rxd_ep, iov, iov_count, NULL, 0, rma_count,
+				     data, 0, context, rxd_addr, op, rxd_flags);
+	if (!tx_entry)
+		goto out;
+
+	ret = rxd_ep_send_op(rxd_ep, tx_entry, rma_iov, rma_count, NULL, 0, 0, 0);
 	if (ret)
 		rxd_tx_entry_free(rxd_ep, tx_entry);
 
 out:
-	fastlock_release(&rxd_ep->lock);
+	fastlock_release(&rxd_ep->util_ep.tx_cq->cq_lock);
+	fastlock_release(&rxd_ep->util_ep.lock);
 	return ret;
 }
 
-static ssize_t rxd_ep_read(struct fid_ep *ep, void *buf, size_t len,
-				 void *desc, fi_addr_t src_addr, uint64_t addr,
-				 uint64_t key, void *context)
+ssize_t rxd_read(struct fid_ep *ep_fid, void *buf, size_t len, void *desc,
+	fi_addr_t src_addr, uint64_t addr, uint64_t key, void *context)
 {
-	struct fi_msg_rma msg;
+	struct rxd_ep *ep;
 	struct iovec msg_iov;
 	struct fi_rma_iov rma_iov;
 
-	memset(&msg, 0, sizeof(msg));
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
 	msg_iov.iov_base = (void *) buf;
 	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.desc = &desc;
-	msg.iov_count = 1;
-
 	rma_iov.addr = addr;
-	rma_iov.key = key;
 	rma_iov.len = len;
-	msg.rma_iov_count = 1;
-	msg.rma_iov = &rma_iov;
-
-	msg.addr = src_addr;
-	msg.context = context;
+	rma_iov.key = key;
 
-	return rxd_ep_readmsg(ep, &msg, RXD_USE_OP_FLAGS);
+	return rxd_generic_rma(ep, &msg_iov, 1, &rma_iov, 1, &desc, 
+			       src_addr, context, ofi_op_read_req, 0,
+			       rxd_ep_tx_flags(ep));
 }
 
-static ssize_t rxd_ep_readv(struct fid_ep *ep, const struct iovec *iov,
-				void **desc, size_t count,
-				fi_addr_t src_addr, uint64_t addr, uint64_t key,
-				void *context)
+ssize_t rxd_readv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+	size_t count, fi_addr_t src_addr, uint64_t addr, uint64_t key,
+	void *context)
 {
-	size_t len, i;
-	struct fi_msg_rma msg;
+	struct rxd_ep *ep;
 	struct fi_rma_iov rma_iov;
 
-	assert(count <= RXD_IOV_LIMIT);
-	memset(&msg, 0, sizeof(msg));
-	msg.msg_iov = iov;
-	msg.desc = desc;
-	msg.iov_count = count;
-	msg.rma_iov_count = 1;
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
 
 	rma_iov.addr = addr;
+	rma_iov.len  = ofi_total_iov_len(iov, count);
 	rma_iov.key = key;
 
-	for (i = 0, len = 0; i < count; i++)
-		len += iov[i].iov_len;
-	rma_iov.len = len;
-
-	msg.rma_iov = &rma_iov;
-	msg.addr = src_addr;
-	msg.context = context;
-
-	return rxd_ep_readmsg(ep, &msg, RXD_USE_OP_FLAGS);
+	return rxd_generic_rma(ep, iov, count, &rma_iov, 1, desc,
+			       src_addr, context, ofi_op_read_req, 0,
+			       rxd_ep_tx_flags(ep));
 }
 
-ssize_t	rxd_ep_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg,
-			uint64_t flags)
+ssize_t rxd_readmsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
+	uint64_t flags)
 {
-	struct rxd_ep *rxd_ep;
-	struct rxd_peer *peer;
-	struct rxd_tx_entry *tx_entry;
-	uint64_t peer_addr;
-	ssize_t ret;
-
-	rxd_ep = container_of(ep, struct rxd_ep, util_ep.ep_fid);
-	peer_addr = rxd_av_dg_addr(rxd_ep_av(rxd_ep), msg->addr);
-	peer = rxd_ep_getpeer_info(rxd_ep, peer_addr);
-
-	fastlock_acquire(&rxd_ep->lock);
-	if (peer->state != CMAP_CONNECTED) {
-		ret = rxd_ep_connect(rxd_ep, peer, peer_addr);
-		fastlock_release(&rxd_ep->lock);
-		if (ret == -FI_EALREADY) {
-			rxd_ep->util_ep.progress(&rxd_ep->util_ep);
-			ret = -FI_EAGAIN;
-		}
-		return ret ? ret : -FI_EAGAIN;
-	}
-
-	tx_entry = rxd_tx_entry_alloc(rxd_ep, peer, peer_addr, flags,
-				      RXD_TX_WRITE);
-	if (!tx_entry) {
-		ret = -FI_EAGAIN;
-		goto out;
-	}
+	struct rxd_ep *ep;
 
-	tx_entry->write.msg = *msg;
-	memcpy(&tx_entry->write.src_iov[0], msg->msg_iov,
-	       sizeof(*msg->msg_iov) * msg->iov_count);
-	memcpy(&tx_entry->write.dst_iov[0], msg->rma_iov,
-	       sizeof(*msg->rma_iov) * msg->rma_iov_count);
-	ret = rxd_ep_start_xfer(rxd_ep, peer, ofi_op_write, tx_entry);
-	if (ret)
-		rxd_tx_entry_free(rxd_ep, tx_entry);
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
 
-out:
-	fastlock_release(&rxd_ep->lock);
-	return ret;
+	return rxd_generic_rma(ep, msg->msg_iov, msg->iov_count,
+			       msg->rma_iov, msg->rma_iov_count,
+			       msg->desc, msg->addr, msg->context,
+			       ofi_op_read_req, msg->data, rxd_flags(flags));
 }
 
-static ssize_t rxd_ep_write(struct fid_ep *ep, const void *buf,
-			    size_t len, void *desc, fi_addr_t dest_addr,
-			    uint64_t addr, uint64_t key, void *context)
+ssize_t rxd_write(struct fid_ep *ep_fid, const void *buf, size_t len, void *desc,
+	fi_addr_t dest_addr, uint64_t addr, uint64_t key, void *context)
 {
-	struct fi_msg_rma msg;
+	struct rxd_ep *ep;
 	struct iovec msg_iov;
 	struct fi_rma_iov rma_iov;
 
-	memset(&msg, 0, sizeof(msg));
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
 	msg_iov.iov_base = (void *) buf;
 	msg_iov.iov_len = len;
-
-	msg.msg_iov = &msg_iov;
-	msg.desc = &desc;
-	msg.iov_count = 1;
-
 	rma_iov.addr = addr;
-	rma_iov.key = key;
 	rma_iov.len = len;
+	rma_iov.key = key;
 
-	msg.rma_iov_count = 1;
-	msg.rma_iov = &rma_iov;
-
-	msg.addr = dest_addr;
-	msg.context = context;
-
-	return rxd_ep_writemsg(ep, &msg, RXD_USE_OP_FLAGS);
+	return rxd_generic_rma(ep, &msg_iov, 1, &rma_iov, 1, &desc, 
+			       dest_addr, context, ofi_op_write, 0,
+			       rxd_ep_tx_flags(ep));
 }
 
-static ssize_t rxd_ep_writev(struct fid_ep *ep, const struct iovec *iov,
-			     void **desc, size_t count, fi_addr_t dest_addr,
-			     uint64_t addr, uint64_t key, void *context)
+ssize_t rxd_writev(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		size_t count, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		void *context)
 {
-	size_t i;
-	size_t len;
-	struct fi_msg_rma msg;
+	struct rxd_ep *ep;
 	struct fi_rma_iov rma_iov;
 
-	assert(count <= RXD_IOV_LIMIT);
-	memset(&msg, 0, sizeof(msg));
-	msg.msg_iov = iov;
-	msg.desc = desc;
-	msg.iov_count = count;
-	msg.rma_iov_count = 1;
-
-	for (i = 0, len = 0; i < count; i++)
-		len += iov[i].iov_len;
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
 
 	rma_iov.addr = addr;
+	rma_iov.len  = ofi_total_iov_len(iov, count);
 	rma_iov.key = key;
-	rma_iov.len = len;
 
-	msg.rma_iov = &rma_iov;
-	msg.context = context;
-	msg.addr = dest_addr;
+	return rxd_generic_rma(ep, iov, count, &rma_iov, 1, desc,
+			       dest_addr, context, ofi_op_write, 0,
+			       rxd_ep_tx_flags(ep));
+}
+
+
+ssize_t rxd_writemsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
+	uint64_t flags)
+{
+	struct rxd_ep *ep;
 
-	return rxd_ep_writemsg(ep, &msg, RXD_USE_OP_FLAGS);
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_generic_rma(ep, msg->msg_iov, msg->iov_count,
+			       msg->rma_iov, msg->rma_iov_count,
+			       msg->desc, msg->addr, msg->context,
+			       ofi_op_write, msg->data, rxd_flags(flags));
 }
 
-static ssize_t rxd_ep_writedata(struct fid_ep *ep, const void *buf,
-				size_t len, void *desc, uint64_t data,
-				fi_addr_t dest_addr, uint64_t addr,
-				uint64_t key, void *context)
+ssize_t rxd_writedata(struct fid_ep *ep_fid, const void *buf, size_t len,
+		      void *desc, uint64_t data, fi_addr_t dest_addr,
+		      uint64_t addr, uint64_t key, void *context)
 {
-	struct fi_msg_rma msg;
-	struct iovec msg_iov;
+	struct rxd_ep *ep;
+	struct iovec iov;
 	struct fi_rma_iov rma_iov;
 
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.desc = &desc;
-	msg.iov_count = 1;
-	msg.rma_iov_count = 1;
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
 
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
 	rma_iov.addr = addr;
+	rma_iov.len  = len;
 	rma_iov.key = key;
-	rma_iov.len = len;
 
-	msg.rma_iov = &rma_iov;
-	msg.msg_iov = &msg_iov;
-
-	msg.addr = dest_addr;
-	msg.context = context;
-	msg.data = data;
-
-	return rxd_ep_writemsg(ep, &msg, FI_REMOTE_CQ_DATA |
-					RXD_USE_OP_FLAGS);
+	return rxd_generic_rma(ep, &iov, 1, &rma_iov, 1, &desc,
+			       dest_addr, context, ofi_op_write, data,
+			       rxd_ep_tx_flags(ep) | RXD_REMOTE_CQ_DATA);
 }
 
-static ssize_t rxd_ep_inject(struct fid_ep *ep, const void *buf,
-			     size_t len, fi_addr_t dest_addr, uint64_t addr,
-			     uint64_t key)
+ssize_t rxd_inject_write(struct fid_ep *ep_fid, const void *buf,
+	size_t len, fi_addr_t dest_addr, uint64_t addr, uint64_t key)
 {
-	struct fi_msg_rma msg;
-	struct iovec msg_iov;
+	struct rxd_ep *rxd_ep;
+	struct iovec iov;
 	struct fi_rma_iov rma_iov;
 
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.iov_count = 1;
-	msg.rma_iov_count = 1;
+	rxd_ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
 
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
 	rma_iov.addr = addr;
-	rma_iov.key = key;
 	rma_iov.len = len;
+	rma_iov.key = key;
 
-	msg.rma_iov = &rma_iov;
-	msg.msg_iov = &msg_iov;
-	msg.addr = dest_addr;
-
-	return rxd_ep_writemsg(ep, &msg, FI_INJECT |
-				    RXD_NO_COMPLETION | RXD_USE_OP_FLAGS);
+	return rxd_generic_write_inject(rxd_ep, &iov, 1, &rma_iov, 1,
+					dest_addr, NULL, ofi_op_write, 0,
+					RXD_NO_TX_COMP | RXD_INJECT);
 }
 
-static ssize_t rxd_ep_injectdata(struct fid_ep *ep, const void *buf,
-				 size_t len, uint64_t data,
-				 fi_addr_t dest_addr, uint64_t addr,
-					uint64_t key)
+ssize_t rxd_inject_writedata(struct fid_ep *ep_fid, const void *buf, size_t len,
+			     uint64_t data, fi_addr_t dest_addr, uint64_t addr,
+			     uint64_t key)
 {
-	struct fi_msg_rma msg;
-	struct iovec msg_iov;
+	struct rxd_ep *rxd_ep;
+	struct iovec iov;
 	struct fi_rma_iov rma_iov;
 
-	memset(&msg, 0, sizeof(msg));
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.iov_count = 1;
-	msg.rma_iov_count = 1;
+	rxd_ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
 
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
 	rma_iov.addr = addr;
-	rma_iov.key = key;
 	rma_iov.len = len;
+	rma_iov.key = key;
 
-	msg.rma_iov = &rma_iov;
-	msg.msg_iov = &msg_iov;
-	msg.addr = dest_addr;
-	msg.data = data;
-	return rxd_ep_writemsg(ep, &msg, FI_INJECT | FI_REMOTE_CQ_DATA |
-		RXD_NO_COMPLETION | RXD_USE_OP_FLAGS);
+	return rxd_generic_write_inject(rxd_ep, &iov, 1, &rma_iov, 1,
+					dest_addr, NULL, ofi_op_write,
+					data, RXD_NO_TX_COMP | RXD_INJECT |
+					RXD_REMOTE_CQ_DATA);
 }
 
 struct fi_ops_rma rxd_ops_rma = {
-	.size = sizeof (struct fi_ops_rma),
-	.read = rxd_ep_read,
-	.readv = rxd_ep_readv,
-	.readmsg = rxd_ep_readmsg,
-	.write = rxd_ep_write,
-	.writev = rxd_ep_writev,
-	.writemsg = rxd_ep_writemsg,
-	.inject = rxd_ep_inject,
-	.writedata = rxd_ep_writedata,
-	.injectdata = rxd_ep_injectdata,
+	.size = sizeof(struct fi_ops_rma),
+	.read = rxd_read,
+	.readv = rxd_readv,
+	.readmsg = rxd_readmsg,
+	.write = rxd_write,
+	.writev = rxd_writev,
+	.writemsg = rxd_writemsg,
+	.inject = rxd_inject_write,
+	.writedata = rxd_writedata,
+	.injectdata = rxd_inject_writedata,
+
 };
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_tagged.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_tagged.c
new file mode 100644
index 000000000..1467c8dc6
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxd/src/rxd_tagged.c
@@ -0,0 +1,181 @@
+/*
+ * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdlib.h>
+#include <string.h>
+#include <ofi_mem.h>
+#include <ofi_iov.h>
+#include "rxd.h"
+
+ssize_t rxd_ep_trecv(struct fid_ep *ep_fid, void *buf, size_t len, void *desc,
+	fi_addr_t src_addr, uint64_t tag, uint64_t ignore, void *context)
+{
+	struct rxd_ep *ep;
+	struct iovec msg_iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	msg_iov.iov_base = (void *) buf;
+	msg_iov.iov_len = len;
+
+	return rxd_ep_generic_recvmsg(ep, &msg_iov, 1, src_addr, tag, ignore,
+				      context, ofi_op_tagged,
+				      rxd_ep_tx_flags(ep) | RXD_TAG_HDR);
+}
+
+ssize_t rxd_ep_trecvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+	size_t count, fi_addr_t src_addr, uint64_t tag, uint64_t ignore,
+	void *context)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_ep_generic_recvmsg(ep, iov, count, src_addr, tag, ignore,
+				      context, ofi_op_tagged,
+				      rxd_ep_tx_flags(ep) | RXD_TAG_HDR);
+}
+
+ssize_t rxd_ep_trecvmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *msg,
+	uint64_t flags)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_ep_generic_recvmsg(ep, msg->msg_iov, msg->iov_count, msg->addr,
+				      msg->tag, msg->ignore, msg->context,
+				      ofi_op_tagged, rxd_flags(flags) | RXD_TAG_HDR);
+}
+
+ssize_t rxd_ep_tsend(struct fid_ep *ep_fid, const void *buf, size_t len,
+	void *desc, fi_addr_t dest_addr, uint64_t tag, void *context)
+{
+	struct rxd_ep *ep;
+	struct iovec msg_iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	msg_iov.iov_base = (void *) buf;
+	msg_iov.iov_len = len;
+
+	return rxd_ep_generic_sendmsg(ep, &msg_iov, 1, dest_addr, tag,
+				      0, context, ofi_op_tagged,
+				      rxd_ep_tx_flags(ep) | RXD_TAG_HDR);
+}
+
+ssize_t rxd_ep_tsendv(struct fid_ep *ep_fid, const struct iovec *iov,
+	void **desc, size_t count, fi_addr_t dest_addr, uint64_t tag,
+	void *context)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_ep_generic_sendmsg(ep, iov, count, dest_addr, tag,
+				      0, context, ofi_op_tagged,
+				      rxd_ep_tx_flags(ep) | RXD_TAG_HDR);
+}
+
+ssize_t rxd_ep_tsendmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *msg,
+			uint64_t flags)
+{
+	struct rxd_ep *ep;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	return rxd_ep_generic_sendmsg(ep, msg->msg_iov, msg->iov_count,
+				      msg->addr, msg->tag, msg->data, msg->context,
+				      ofi_op_tagged, rxd_flags(flags) | RXD_TAG_HDR);
+}
+
+ssize_t rxd_ep_tinject(struct fid_ep *ep_fid, const void *buf, size_t len,
+		       fi_addr_t dest_addr, uint64_t tag)
+{
+	struct rxd_ep *ep;
+	struct iovec iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
+
+	return rxd_ep_generic_inject(ep, &iov, 1, dest_addr, tag, 0,
+				     ofi_op_tagged, RXD_NO_TX_COMP | RXD_INJECT |
+				     RXD_TAG_HDR);
+}
+
+ssize_t rxd_ep_tsenddata(struct fid_ep *ep_fid, const void *buf, size_t len,
+		         void *desc, uint64_t data, fi_addr_t dest_addr,
+		         uint64_t tag, void *context)
+{
+	struct rxd_ep *ep;
+	struct iovec iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
+
+	return rxd_ep_generic_sendmsg(ep, &iov, 1, dest_addr, tag, data, context,
+				      ofi_op_tagged, rxd_ep_tx_flags(ep) |
+				      RXD_REMOTE_CQ_DATA | RXD_TAG_HDR);
+}
+
+ssize_t rxd_ep_tinjectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
+			   uint64_t data, fi_addr_t dest_addr, uint64_t tag)
+{
+	struct rxd_ep *ep;
+	struct iovec iov;
+
+	ep = container_of(ep_fid, struct rxd_ep, util_ep.ep_fid.fid);
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
+
+	return rxd_ep_generic_inject(ep, &iov, 1, dest_addr, tag, data, ofi_op_tagged,
+				     RXD_NO_TX_COMP | RXD_INJECT |
+				     RXD_REMOTE_CQ_DATA | RXD_TAG_HDR);
+}
+
+struct fi_ops_tagged rxd_ops_tagged = {
+	.size = sizeof(struct fi_ops_tagged),
+	.recv = rxd_ep_trecv,
+	.recvv = rxd_ep_trecvv,
+	.recvmsg = rxd_ep_trecvmsg,
+	.send = rxd_ep_tsend,
+	.sendv = rxd_ep_tsendv,
+	.sendmsg = rxd_ep_tsendmsg,
+	.inject = rxd_ep_tinject,
+	.senddata = rxd_ep_tsenddata,
+	.injectdata = rxd_ep_tinjectdata,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/Makefile.include
index 8c777346b..36703e80f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/Makefile.include
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/Makefile.include
@@ -7,7 +7,9 @@ _rxm_files = \
        prov/rxm/src/rxm_conn.c		\
        prov/rxm/src/rxm_ep.c		\
        prov/rxm/src/rxm_cq.c		\
+       prov/rxm/src/rxm_av.c		\
        prov/rxm/src/rxm_rma.c		\
+       prov/rxm/src/rxm_atomic.c		\
        prov/rxm/src/rxm.h
 
 if HAVE_RXM_DL
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm.h
index 250ed933f..d9276f425 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm.h
@@ -1,3 +1,4 @@
+
 /*
  * Copyright (c) 2016 Intel Corporation, Inc.  All rights reserved.
  *
@@ -60,7 +61,15 @@
 #define RXM_MAJOR_VERSION 1
 #define RXM_MINOR_VERSION 0
 
-#define RXM_BUF_SIZE 16384
+#define RXM_OP_VERSION		3
+#define RXM_CTRL_VERSION	3
+
+#define RXM_BUF_SIZE	16384
+
+#define RXM_SAR_LIMIT	131072
+#define RXM_SAR_TX_ERROR	UINT64_MAX
+#define RXM_SAR_RX_INIT		UINT64_MAX
+
 #define RXM_IOV_LIMIT 4
 
 #define RXM_MR_MODES	(OFI_MR_BASIC_MAP | FI_MR_LOCAL)
@@ -71,15 +80,15 @@
 			       info->domain_attr->mr_mode & FI_MR_PROV_KEY)
 
 #define RXM_LOG_STATE(subsystem, pkt, prev_state, next_state) 			\
-	FI_DBG(&rxm_prov, subsystem, "[LMT] msg_id: 0x%" PRIx64 " %s -> %s\n",	\
+	FI_DBG(&rxm_prov, subsystem, "[RNDV] msg_id: 0x%" PRIx64 " %s -> %s\n",	\
 	       pkt.ctrl_hdr.msg_id, rxm_proto_state_str[prev_state],		\
 	       rxm_proto_state_str[next_state])
 
-#define RXM_LOG_STATE_TX(subsystem, tx_entry, next_state)		\
-	RXM_LOG_STATE(subsystem, tx_entry->tx_buf->pkt, tx_entry->state,\
+#define RXM_LOG_STATE_TX(subsystem, tx_buf, next_state)		\
+	RXM_LOG_STATE(subsystem, tx_buf->pkt, tx_buf->hdr.state,	\
 		      next_state)
 
-#define RXM_LOG_STATE_RX(subsystem, rx_buf, next_state)			\
+#define RXM_LOG_STATE_RX(subsystem, rx_buf, next_state)		\
 	RXM_LOG_STATE(subsystem, rx_buf->pkt, rx_buf->hdr.state,	\
 		      next_state)
 
@@ -88,10 +97,9 @@
 	       " (fi_addr: 0x%" PRIx64 " tag: 0x%" PRIx64 ")\n",\
 	       addr, tag)
 
-#define RXM_GET_PROTO_STATE(comp)			\
-	(*(enum rxm_proto_state *)			\
-	  ((unsigned char *)(comp)->op_context +	\
-		offsetof(struct rxm_buf, state)))
+#define RXM_GET_PROTO_STATE(context)					\
+	(*(enum rxm_proto_state *)					\
+	  ((unsigned char *)context + offsetof(struct rxm_buf, state)))
 
 #define RXM_SET_PROTO_STATE(comp, new_state)				\
 do {									\
@@ -100,45 +108,213 @@ do {									\
 		offsetof(struct rxm_buf, state))) = (new_state);	\
 } while (0)
 
+#define rxm_tx_buf_2_msg_id(rxm_ep, pool_type, tx_buf)				\
+	((uint64_t) rxm_get_buf_index(&(rxm_ep)->buf_pools[pool_type],		\
+				       (void *) tx_buf))
+#define rxm_msg_id_2_tx_buf(rxm_ep, pool_type, msg_id)				\
+	((void *) rxm_buf_get_by_index(&(rxm_ep)->buf_pools[pool_type],		\
+				       (uint64_t) msg_id))
+
+#define RXM_Q_STRERROR(prov, log, q, q_str, entry, strerror)					\
+	FI_WARN(prov, log, "fi_" q_str "_readerr: err: %d, prov_err: %s (%d)\n",		\
+		(entry).err,strerror((q), (entry).prov_errno, (entry).err_data, NULL, 0),	\
+		(entry).prov_errno)
+
+#define RXM_CQ_READERR(prov, log, cq, ret, err_entry)			\
+	do {								\
+		(ret) = fi_cq_readerr((cq), &(err_entry), 0);		\
+		if ((ret) < 0) {					\
+			FI_WARN(prov, log,				\
+				"Unable to fi_cq_readerr: %zd\n", ret);	\
+		} else {						\
+			RXM_Q_STRERROR(prov, log, cq, "cq",		\
+				       err_entry, fi_cq_strerror);	\
+		}							\
+	} while (0)
+
+#define RXM_EQ_READERR(prov, log, eq, ret, err_entry)			\
+	do {								\
+		(ret) = fi_eq_readerr((eq), &(err_entry), 0);		\
+		if ((ret) != sizeof(err_entry)) {			\
+			FI_WARN(prov, log,				\
+				"Unable to fi_eq_readerr: %zd\n", ret);	\
+		} else {						\
+			RXM_Q_STRERROR(prov, log, eq, "eq",		\
+				       err_entry, fi_eq_strerror);	\
+		}							\
+	} while (0)
+
 extern struct fi_provider rxm_prov;
 extern struct util_prov rxm_util_prov;
 extern struct fi_ops_rma rxm_ops_rma;
-extern int rxm_defer_requests;
+extern struct fi_ops_atomic rxm_ops_atomic;
 
 extern size_t rxm_msg_tx_size;
 extern size_t rxm_msg_rx_size;
 extern size_t rxm_def_univ_size;
 
+/*
+ * Connection Map
+ */
+
+#define RXM_CMAP_IDX_BITS OFI_IDX_INDEX_BITS
+
+enum rxm_cmap_signal {
+	RXM_CMAP_FREE,
+	RXM_CMAP_EXIT,
+};
+
+enum rxm_cmap_state {
+	RXM_CMAP_IDLE,
+	RXM_CMAP_CONNREQ_SENT,
+	RXM_CMAP_CONNREQ_RECV,
+	RXM_CMAP_ACCEPT,
+	RXM_CMAP_CONNECTED_NOTIFY,
+	RXM_CMAP_CONNECTED,
+	RXM_CMAP_SHUTDOWN,
+};
+
+enum rxm_cmap_reject_flag {
+	RXM_CMAP_REJECT_GENUINE,
+	RXM_CMAP_REJECT_SIMULT_CONN,
+};
+
+struct rxm_cmap_handle {
+	struct rxm_cmap *cmap;
+	enum rxm_cmap_state state;
+	/* Unique identifier for a connection. Can be exchanged with a peer
+	 * during connection setup and can later be used in a message header
+	 * to identify the source of the message (Used for FI_SOURCE, RNDV
+	 * protocol, etc.) */
+	uint64_t key;
+	uint64_t remote_key;
+	fi_addr_t fi_addr;
+	struct rxm_cmap_peer *peer;
+};
+
+struct rxm_cmap_peer {
+	struct rxm_cmap_handle *handle;
+	struct dlist_entry entry;
+	uint8_t addr[];
+};
+
+struct rxm_cmap_attr {
+	void 				*name;
+	/* user guarantee for serializing access to cmap objects */
+	uint8_t				serial_access;
+};
+
+struct rxm_cmap {
+	struct util_ep		*ep;
+	struct util_av		*av;
+
+	/* cmap handles that correspond to addresses in AV */
+	struct rxm_cmap_handle **handles_av;
+	size_t			num_allocated;
+
+	/* Store all cmap handles (inclusive of handles_av) in an indexer.
+	 * This allows reverse lookup of the handle using the index. */
+	struct indexer		handles_idx;
+
+	struct ofi_key_idx	key_idx;
+
+	struct dlist_entry	peer_list;
+	struct rxm_cmap_attr	attr;
+	pthread_t		cm_thread;
+	ofi_fastlock_acquire_t	acquire;
+	ofi_fastlock_release_t	release;
+	fastlock_t		lock;
+};
+
+struct rxm_ep;
+
+struct rxm_cmap_handle *rxm_cmap_key2handle(struct rxm_cmap *cmap, uint64_t key);
+int rxm_cmap_get_handle(struct rxm_cmap *cmap, fi_addr_t fi_addr,
+			struct rxm_cmap_handle **handle);
+int rxm_cmap_update(struct rxm_cmap *cmap, const void *addr, fi_addr_t fi_addr);
+
+void rxm_cmap_process_conn_notify(struct rxm_cmap *cmap,
+				  struct rxm_cmap_handle *handle);
+void rxm_cmap_process_connect(struct rxm_cmap *cmap,
+			      struct rxm_cmap_handle *handle,
+			      uint64_t *remote_key);
+void rxm_cmap_process_reject(struct rxm_cmap *cmap,
+			     struct rxm_cmap_handle *handle,
+			     enum rxm_cmap_reject_flag cm_reject_flag);
+int rxm_cmap_process_connreq(struct rxm_cmap *cmap, void *addr,
+			     struct rxm_cmap_handle **handle_ret,
+			     enum rxm_cmap_reject_flag *cm_reject_flag);
+void rxm_cmap_process_shutdown(struct rxm_cmap *cmap,
+			       struct rxm_cmap_handle *handle);
+int rxm_cmap_handle_unconnected(struct rxm_ep *rxm_ep, struct rxm_cmap_handle *handle,
+				fi_addr_t dest_addr);
+void rxm_cmap_del_handle_ts(struct rxm_cmap_handle *handle);
+void rxm_cmap_free(struct rxm_cmap *cmap);
+int rxm_cmap_alloc(struct rxm_ep *rxm_ep, struct rxm_cmap_attr *attr);
+int rxm_cmap_handle_connect(struct rxm_cmap *cmap, fi_addr_t fi_addr,
+			    struct rxm_cmap_handle *handle);
+/* Caller must hold cmap->lock */
+int rxm_cmap_move_handle_to_peer_list(struct rxm_cmap *cmap, int index);
+
+static inline struct rxm_cmap_handle *
+rxm_cmap_acquire_handle(struct rxm_cmap *cmap, fi_addr_t fi_addr)
+{
+	assert(fi_addr < cmap->num_allocated);
+	return cmap->handles_av[fi_addr];
+}
+
 struct rxm_fabric {
 	struct util_fabric util_fabric;
 	struct fid_fabric *msg_fabric;
 };
 
-struct rxm_conn {
-	struct fid_ep *msg_ep;
-	struct dlist_entry postponed_tx_list;
-	struct util_cmap_handle handle;
-};
-
 struct rxm_domain {
 	struct util_domain util_domain;
 	struct fid_domain *msg_domain;
+	size_t max_atomic_size;
 	uint8_t mr_local;
 };
 
+int rxm_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+		struct fid_av **av, void *context);
+
 struct rxm_mr {
 	struct fid_mr mr_fid;
 	struct fid_mr *msg_mr;
+	struct rxm_domain *domain;
+};
+
+struct rxm_ep_wire_proto {
+	uint8_t	ctrl_version;
+	uint8_t	op_version;
+	uint8_t endianness;
+	uint8_t padding[5];
+	uint64_t eager_size;
 };
 
 struct rxm_cm_data {
 	struct sockaddr name;
 	uint64_t conn_id;
+	struct rxm_ep_wire_proto proto;
 };
 
-struct rxm_rma_iov {
+struct rxm_rndv_hdr {
+	struct ofi_rma_iov iov[RXM_IOV_LIMIT];
 	uint8_t count;
-	struct ofi_rma_iov iov[];
+};
+
+#define rxm_pkt_rndv_data(rxm_pkt) \
+	((rxm_pkt)->data + sizeof(struct rxm_rndv_hdr))
+
+struct rxm_atomic_hdr {
+	struct fi_rma_ioc rma_ioc[RXM_IOV_LIMIT];
+	char data[];
+};
+
+struct rxm_atomic_resp_hdr {
+	int32_t status;
+	uint32_t result_len;
+	char data[];
 };
 
 /*
@@ -160,17 +336,20 @@ struct rxm_rma_iov {
  */
 
 /* RXM protocol states / tx/rx context */
-#define RXM_PROTO_STATES(FUNC)	\
-	FUNC(RXM_TX_NOBUF),	\
-	FUNC(RXM_TX),		\
-	FUNC(RXM_TX_RMA),	\
-	FUNC(RXM_RX),		\
-	FUNC(RXM_LMT_TX),	\
-	FUNC(RXM_LMT_ACK_WAIT),	\
-	FUNC(RXM_LMT_READ),	\
-	FUNC(RXM_LMT_ACK_SENT), \
-	FUNC(RXM_LMT_ACK_RECVD),\
-	FUNC(RXM_LMT_FINISH),
+#define RXM_PROTO_STATES(FUNC)		\
+	FUNC(RXM_TX),			\
+	FUNC(RXM_INJECT_TX),		\
+	FUNC(RXM_RMA),			\
+	FUNC(RXM_RX),			\
+	FUNC(RXM_SAR_TX),		\
+	FUNC(RXM_RNDV_TX),		\
+	FUNC(RXM_RNDV_ACK_WAIT),	\
+	FUNC(RXM_RNDV_READ),		\
+	FUNC(RXM_RNDV_ACK_SENT),	\
+	FUNC(RXM_RNDV_ACK_RECVD),	\
+	FUNC(RXM_RNDV_FINISH),		\
+	FUNC(RXM_ATOMIC_RESP_WAIT),	\
+	FUNC(RXM_ATOMIC_RESP_SENT)
 
 enum rxm_proto_state {
 	RXM_PROTO_STATES(OFI_ENUM_VAL)
@@ -184,6 +363,30 @@ struct rxm_pkt {
 	char data[];
 };
 
+union rxm_sar_ctrl_data {
+	struct {
+		enum rxm_sar_seg_type {
+			RXM_SAR_SEG_FIRST	= 1,
+			RXM_SAR_SEG_MIDDLE	= 2,
+			RXM_SAR_SEG_LAST	= 3,	
+		} seg_type : 2;
+		uint32_t offset;
+	};
+	uint64_t align;
+};
+
+static inline enum rxm_sar_seg_type
+rxm_sar_get_seg_type(struct ofi_ctrl_hdr *ctrl_hdr)
+{
+	return ((union rxm_sar_ctrl_data *)&(ctrl_hdr->ctrl_data))->seg_type;
+}
+
+static inline void
+rxm_sar_set_seg_type(struct ofi_ctrl_hdr *ctrl_hdr, enum rxm_sar_seg_type seg_type)
+{
+	((union rxm_sar_ctrl_data *)&(ctrl_hdr->ctrl_data))->seg_type = seg_type;
+}
+
 struct rxm_recv_match_attr {
 	fi_addr_t addr;
 	uint64_t tag;
@@ -202,20 +405,17 @@ struct rxm_iov {
 	uint8_t count;
 };
 
-struct rxm_rma_iov_storage {
-	struct fi_rma_iov iov[RXM_IOV_LIMIT];
-	uint8_t count;
-};
-
 enum rxm_buf_pool_type {
 	RXM_BUF_POOL_RX		= 0,
 	RXM_BUF_POOL_START	= RXM_BUF_POOL_RX,
-	RXM_BUF_POOL_TX_MSG,
-	RXM_BUF_POOL_TX_START	= RXM_BUF_POOL_TX_MSG,
-	RXM_BUF_POOL_TX_TAGGED,
+	RXM_BUF_POOL_TX,
+	RXM_BUF_POOL_TX_START	= RXM_BUF_POOL_TX,
+	RXM_BUF_POOL_TX_INJECT,
 	RXM_BUF_POOL_TX_ACK,
-	RXM_BUF_POOL_TX_LMT,
-	RXM_BUF_POOL_TX_END	= RXM_BUF_POOL_TX_LMT,
+	RXM_BUF_POOL_TX_RNDV,
+	RXM_BUF_POOL_TX_ATOMIC,
+	RXM_BUF_POOL_TX_SAR,
+	RXM_BUF_POOL_TX_END	= RXM_BUF_POOL_TX_SAR,
 	RXM_BUF_POOL_RMA,
 	RXM_BUF_POOL_MAX,
 };
@@ -226,82 +426,155 @@ struct rxm_buf {
 
 	enum rxm_proto_state state;
 
-	struct dlist_entry entry;
 	void *desc;
-	/* MSG EP / shared context to which bufs would be posted to */
-	struct fid_ep *msg_ep;
 };
 
 struct rxm_rx_buf {
 	/* Must stay at top */
 	struct rxm_buf hdr;
-	struct dlist_entry entry;
 
 	struct rxm_ep *ep;
+	/* MSG EP / shared context to which bufs would be posted to */
+	struct fid_ep *msg_ep;
 	struct dlist_entry repost_entry;
 	struct rxm_conn *conn;
-	struct rxm_recv_queue *recv_queue;
 	struct rxm_recv_entry *recv_entry;
 	struct rxm_unexp_msg unexp_msg;
 	uint64_t comp_flags;
+	struct fi_recv_context recv_context;
+	// TODO remove this and modify unexp msg handling path to not repost
+	// rx_buf
 	uint8_t repost;
 
 	/* Used for large messages */
-	struct rxm_iov match_iov[RXM_IOV_LIMIT];
-	struct rxm_rma_iov *rma_iov;
-	size_t index;
+	struct rxm_rndv_hdr *rndv_hdr;
+	size_t rndv_rma_index;
 	struct fid_mr *mr[RXM_IOV_LIMIT];
 
 	/* Must stay at bottom */
 	struct rxm_pkt pkt;
 };
 
-struct rxm_tx_buf {
+struct rxm_tx_base_buf {
 	/* Must stay at top */
 	struct rxm_buf hdr;
 
-	enum rxm_buf_pool_type type;
+	/* Must stay at bottom */
+	struct rxm_pkt pkt;
+};
+
+struct rxm_tx_eager_buf {
+	/* Must stay at top */
+	struct rxm_buf hdr;
+
+	void *app_context;
+	uint64_t flags;
 
 	/* Must stay at bottom */
 	struct rxm_pkt pkt;
 };
 
-struct rxm_rma_buf {
+struct rxm_tx_sar_buf {
 	/* Must stay at top */
 	struct rxm_buf hdr;
 
-	struct fi_msg_rma msg;
-	struct rxm_iov rxm_iov;
-	struct rxm_rma_iov_storage rxm_rma_iov;
+	void *app_context;
+	uint64_t flags;
 
 	/* Must stay at bottom */
 	struct rxm_pkt pkt;
 };
 
-struct rxm_tx_entry {
+struct rxm_tx_rndv_buf {
 	/* Must stay at top */
-	union {
-		struct fi_context fi_context;
-		struct dlist_entry postponed_entry;
+	struct rxm_buf hdr;
+
+	void *app_context;
+	uint64_t flags;
+	struct rxm_rx_buf *rx_buf;
+	struct fid_mr *mr[RXM_IOV_LIMIT];
+	uint8_t count;
+
+	/* Must stay at bottom */
+	struct rxm_pkt pkt;
+};
+
+struct rxm_rma_buf {
+	/* Must stay at top */
+	struct rxm_buf hdr;
+
+	void *app_context;
+	uint64_t flags;
+
+	/* Must stay at bottom */
+ 	union {
+		struct rxm_pkt pkt;
+		struct {
+			struct fid_mr *mr[RXM_IOV_LIMIT];
+			uint8_t count;
+		} mr;
 	};
+};
 
-	enum rxm_proto_state state;
+struct rxm_tx_atomic_buf {
+	/* Must stay at top */
+	struct rxm_buf hdr;
 
-	struct rxm_ep *ep;
-	uint8_t count;
-	void *context;
+	void *app_context;
 	uint64_t flags;
-	uint64_t comp_flags;
+	struct iovec result_iov[RXM_IOV_LIMIT];
+	uint8_t result_iov_count;
+
+	/* Must stay at bottom */
+	struct rxm_pkt pkt;
+};
+
+enum rxm_deferred_tx_entry_type {
+	RXM_DEFERRED_TX_RNDV_ACK,
+	RXM_DEFERRED_TX_RNDV_READ,
+	RXM_DEFERRED_TX_SAR_SEG,
+	RXM_DEFERRED_TX_ATOMIC_RESP,
+};
+
+struct rxm_deferred_tx_entry {
+	struct rxm_ep *rxm_ep;
+	struct rxm_conn *rxm_conn;
+	struct dlist_entry entry;
+	enum rxm_deferred_tx_entry_type type;
+
 	union {
-		struct rxm_tx_buf *tx_buf;
-		struct rxm_rma_buf *rma_buf;
+		struct {
+			struct rxm_rx_buf *rx_buf;
+		} rndv_ack;
+		struct {
+			struct rxm_rx_buf *rx_buf;
+			struct fi_rma_iov rma_iov;
+			struct rxm_iov rxm_iov;
+		} rndv_read;
+		struct {
+			struct rxm_tx_sar_buf *cur_seg_tx_buf;
+			struct {
+				struct iovec iov[RXM_IOV_LIMIT];
+				uint8_t count;
+				size_t cur_iov_offset;
+				uint64_t data;
+				uint64_t tag;
+			} payload;
+			size_t next_seg_no;
+			size_t segs_cnt;
+			uint8_t op;
+			size_t total_len;
+			size_t remain_len;
+			uint64_t msg_id;
+			void *app_context;
+			uint64_t flags;
+		} sar_seg;
+		struct {
+			struct rxm_tx_atomic_buf *tx_buf;
+			ssize_t len;
+		} atomic_resp;
 	};
-
-	/* Used for large messages and RMA */
-	struct fid_mr *mr[RXM_IOV_LIMIT];
-	struct rxm_rx_buf *rx_buf;
 };
-DECLARE_FREESTACK(struct rxm_tx_entry, rxm_txe_fs);
 
 struct rxm_recv_entry {
 	struct dlist_entry entry;
@@ -313,16 +586,31 @@ struct rxm_recv_entry {
 	uint64_t ignore;
 	uint64_t comp_flags;
 	size_t total_len;
-	void *multi_recv_buf;
-};
-DECLARE_FREESTACK(struct rxm_recv_entry, rxm_recv_fs);
+	struct rxm_recv_queue *recv_queue;
+	struct {
+		void	*buf;
+		size_t	len;
+	} multi_recv;
 
-struct rxm_send_queue {
-	struct rxm_txe_fs *fs;
-	fastlock_t lock;
+	union {
+		/* Used for SAR protocol */
+		struct {
+			struct dlist_entry entry;
+			size_t total_recv_len;
+			struct rxm_conn *conn;
+			uint64_t msg_id;
+		} sar;
+		/* Used for Rendezvous protocol */
+		struct {
+			/* This is used to send RNDV ACK */
+			struct rxm_tx_base_buf *tx_buf;
+		} rndv;
+	};
 };
+DECLARE_FREESTACK(struct rxm_recv_entry, rxm_recv_fs);
 
 enum rxm_recv_queue_type {
+	RXM_RECV_QUEUE_UNSPEC,
 	RXM_RECV_QUEUE_MSG,
 	RXM_RECV_QUEUE_TAGGED,
 };
@@ -335,44 +623,81 @@ struct rxm_recv_queue {
 	struct dlist_entry unexp_msg_list;
 	dlist_func_t *match_recv;
 	dlist_func_t *match_unexp;
-	fastlock_t lock;
 };
 
 struct rxm_buf_pool {
-	struct util_buf_pool *pool;
 	enum rxm_buf_pool_type type;
-	struct rxm_ep *ep;
-	fastlock_t lock;
+	struct util_buf_pool *pool;
+	struct rxm_ep *rxm_ep;
+};
+
+struct rxm_msg_eq_entry {
+	struct slist_entry	slist_entry;
+	ssize_t			rd;
+	uint32_t		event;
+	/* Used for connection refusal */
+	void			*context;
+	struct fi_eq_err_entry	err_entry;
+	/* must stay at the bottom */
+	struct fi_eq_cm_entry	cm_entry;
 };
 
+#define RXM_MSG_EQ_ENTRY_SZ (sizeof(struct rxm_msg_eq_entry) + \
+			     sizeof(struct rxm_cm_data))
+#define RXM_CM_ENTRY_SZ (sizeof(struct fi_eq_cm_entry) + \
+			 sizeof(struct rxm_cm_data))
+
 struct rxm_ep {
 	struct util_ep 		util_ep;
 	struct fi_info 		*rxm_info;
 	struct fi_info 		*msg_info;
+	struct rxm_cmap		*cmap;
 	struct fid_pep 		*msg_pep;
 	struct fid_eq 		*msg_eq;
+	struct slistfd		msg_eq_entry_list;
+	fastlock_t		msg_eq_entry_list_lock;
 	struct fid_cq 		*msg_cq;
 	int			msg_cq_fd;
-	struct dlist_entry	msg_cq_fd_ref_list;
 	struct fid_ep 		*srx_ctx;
 	size_t 			comp_per_progress;
 	int			msg_mr_local;
 	int			rxm_mr_local;
 	size_t			min_multi_recv_size;
+	size_t			buffered_min;
+	size_t			buffered_limit;
 
-	struct rxm_buf_pool	buf_pools[RXM_BUF_POOL_MAX];
+	size_t			inject_limit;
+	size_t			eager_limit;
+	size_t			sar_limit;
+
+	struct rxm_buf_pool	*buf_pools;
 
-	struct dlist_entry	post_rx_list;
 	struct dlist_entry	repost_ready_list;
+	struct dlist_entry	deferred_tx_conn_queue;
 
-	struct rxm_send_queue	send_queue;
 	struct rxm_recv_queue	recv_queue;
 	struct rxm_recv_queue	trecv_queue;
 };
 
-struct rxm_ep_wait_ref {
-	struct util_wait	*wait;
-	struct dlist_entry	entry;
+struct rxm_conn {
+	/* This should stay at the top */
+	struct rxm_cmap_handle handle;
+
+	struct fid_ep *msg_ep;
+
+	/* This is used only in non-FI_THREAD_SAFE case */
+	struct rxm_pkt *inject_pkt;
+	struct rxm_pkt *inject_data_pkt;
+	struct rxm_pkt *tinject_pkt;
+	struct rxm_pkt *tinject_data_pkt;
+
+	struct dlist_entry deferred_conn_entry;
+	struct dlist_entry deferred_tx_queue;
+	struct dlist_entry sar_rx_msg_list;
+
+	/* This is saved MSG EP fid, that hasn't been closed during
+	 * handling of CONN_RECV in RXM_CMAP_CONNREQ_SENT for passive side */
+	struct fid_ep *saved_msg_ep;
 };
 
 extern struct fi_provider rxm_prov;
@@ -382,17 +707,6 @@ extern struct fi_domain_attr rxm_domain_attr;
 extern struct fi_tx_attr rxm_tx_attr;
 extern struct fi_rx_attr rxm_rx_attr;
 
-// TODO move to common code?
-static inline int rxm_match_addr(fi_addr_t recv_addr, fi_addr_t rx_addr)
-{
-	return (recv_addr == FI_ADDR_UNSPEC) || (recv_addr == rx_addr);
-}
-
-static inline int rxm_match_tag(uint64_t tag, uint64_t ignore, uint64_t match_tag)
-{
-	return ((tag | ignore) == (match_tag | ignore));
-}
-
 #define rxm_ep_rx_flags(rxm_ep)	((rxm_ep)->util_ep.rx_op_flags)
 #define rxm_ep_tx_flags(rxm_ep)	((rxm_ep)->util_ep.tx_op_flags)
 
@@ -406,33 +720,129 @@ int rxm_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 			     struct fid_domain **dom, void *context);
 int rxm_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
 			 struct fid_cq **cq_fid, void *context);
-ssize_t rxm_cq_handle_data(struct rxm_rx_buf *rx_buf);
+ssize_t rxm_cq_handle_rx_buf(struct rxm_rx_buf *rx_buf);
 
 int rxm_endpoint(struct fid_domain *domain, struct fi_info *info,
 			  struct fid_ep **ep, void *context);
 
-struct util_cmap *rxm_conn_cmap_alloc(struct rxm_ep *rxm_ep);
-
-void rxm_ep_progress_one(struct util_ep *util_ep);
-void rxm_ep_progress_multi(struct util_ep *util_ep);
+int rxm_conn_cmap_alloc(struct rxm_ep *rxm_ep);
+void rxm_cq_write_error(struct util_cq *cq, struct util_cntr *cntr,
+			void *op_context, int err);
+void rxm_ep_progress(struct util_ep *util_ep);
+void rxm_ep_do_progress(struct util_ep *util_ep);
 
 int rxm_ep_prepost_buf(struct rxm_ep *rxm_ep, struct fid_ep *msg_ep);
 
-int rxm_ep_msg_mr_regv(struct rxm_ep *rxm_ep, const struct iovec *iov,
-		       size_t count, uint64_t access, struct fid_mr **mr);
-void rxm_ep_msg_mr_closev(struct fid_mr **mr, size_t count);
+int rxm_ep_query_atomic(struct fid_domain *domain, enum fi_datatype datatype,
+			enum fi_op op, struct fi_atomic_attr *attr,
+			uint64_t flags);
+static inline ssize_t
+rxm_atomic_send_respmsg(struct rxm_ep *rxm_ep, struct rxm_conn *conn,
+			struct rxm_tx_atomic_buf *resp_buf, ssize_t len)
+{
+	struct iovec iov = {
+		.iov_base = (void *) &resp_buf->pkt,
+		.iov_len = len,
+	};
+	struct fi_msg msg = {
+		.msg_iov = &iov,
+		.desc = NULL,
+		.iov_count = 1,
+		.context = resp_buf,
+		.data = 0,
+	};
+	return fi_sendmsg(conn->msg_ep, &msg, FI_COMPLETION);
+}
+
+static inline struct rxm_conn *rxm_key2conn(struct rxm_ep *rxm_ep, uint64_t key)
+{
+	return (struct rxm_conn *)rxm_cmap_key2handle(rxm_ep->cmap, key);
+}
 
-void rxm_ep_handle_postponed_tx_op(struct rxm_ep *rxm_ep,
-				   struct rxm_conn *rxm_conn,
-				   struct rxm_tx_entry *tx_entry);
-void rxm_ep_handle_postponed_rma_op(struct rxm_ep *rxm_ep,
-				    struct rxm_conn *rxm_conn,
-				    struct rxm_tx_entry *tx_entry);
+void rxm_ep_progress_deferred_queue(struct rxm_ep *rxm_ep,
+				    struct rxm_conn *rxm_conn);
 
-static inline void rxm_cntr_inc(struct util_cntr *cntr)
+struct rxm_deferred_tx_entry *
+rxm_ep_alloc_deferred_tx_entry(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+			       enum rxm_deferred_tx_entry_type type);
+
+static inline void
+rxm_ep_enqueue_deferred_tx_queue(struct rxm_deferred_tx_entry *tx_entry)
 {
-	if (cntr)
-		cntr->cntr_fid.ops->add(&cntr->cntr_fid, 1);
+	if (dlist_empty(&tx_entry->rxm_conn->deferred_tx_queue))
+		dlist_insert_tail(&tx_entry->rxm_conn->deferred_conn_entry,
+				  &tx_entry->rxm_ep->deferred_tx_conn_queue);
+	dlist_insert_tail(&tx_entry->entry, &tx_entry->rxm_conn->deferred_tx_queue);
+}
+
+static inline void
+rxm_ep_dequeue_deferred_tx_queue(struct rxm_deferred_tx_entry *tx_entry)
+{
+	dlist_remove_init(&tx_entry->entry);
+	if (dlist_empty(&tx_entry->rxm_conn->deferred_tx_queue))
+		dlist_remove(&tx_entry->rxm_conn->deferred_conn_entry);
+}
+
+int rxm_conn_process_eq_events(struct rxm_ep *rxm_ep);
+
+static inline void rxm_ep_msg_mr_closev(struct fid_mr **mr, size_t count)
+{
+	int ret;
+	size_t i;
+
+	for (i = 0; i < count; i++) {
+		if (mr[i]) {
+			ret = fi_close(&mr[i]->fid);
+			if (ret)
+				FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+					"Unable to close msg mr: %zu\n", i);
+			mr[i] = NULL;
+		}
+	}
+}
+
+static inline int
+rxm_ep_msg_mr_regv(struct rxm_ep *rxm_ep, const struct iovec *iov, size_t count,
+		   uint64_t access, struct fid_mr **mr)
+{
+	int ret;
+	size_t i;
+	struct rxm_domain *rxm_domain =
+		container_of(rxm_ep->util_ep.domain, struct rxm_domain, util_domain);
+ 
+	for (i = 0; i < count; i++) {
+		ret = fi_mr_reg(rxm_domain->msg_domain, iov[i].iov_base,
+				iov[i].iov_len, access, 0, 0, 0, &mr[i], NULL);
+		if (ret)
+			goto err;
+	}
+	return 0;
+err:
+	rxm_ep_msg_mr_closev(mr, count);
+	return ret;
+}
+
+static inline int
+rxm_ep_msg_mr_regv_lim(struct rxm_ep *rxm_ep, const struct iovec *iov, size_t count,
+		       size_t total_reg_len, uint64_t access, struct fid_mr **mr)
+{
+	int ret;
+	size_t i;
+	struct rxm_domain *rxm_domain =
+		container_of(rxm_ep->util_ep.domain, struct rxm_domain, util_domain);
+ 
+	for (i = 0; i < count && total_reg_len; i++) {
+		size_t len = MIN(iov[i].iov_len, total_reg_len);
+		ret = fi_mr_reg(rxm_domain->msg_domain, iov[i].iov_base,
+				len, access, 0, 0, 0, &mr[i], NULL);
+		if (ret)
+			goto err;
+		total_reg_len -= len;
+	}
+	return 0;
+err:
+	rxm_ep_msg_mr_closev(mr, count);
+	return ret;
 }
 
 static inline void rxm_cntr_incerr(struct util_cntr *cntr)
@@ -441,6 +851,18 @@ static inline void rxm_cntr_incerr(struct util_cntr *cntr)
 		cntr->cntr_fid.ops->adderr(&cntr->cntr_fid, 1);
 }
 
+
+
+static inline void rxm_cq_log_comp(uint64_t flags)
+{
+#if ENABLE_DEBUG
+	FI_DBG(&rxm_prov, FI_LOG_CQ, "Reporting %s completion\n",
+	       fi_tostr((void *)&flags, FI_TYPE_CQ_EVENT_FLAGS));
+#else
+	/* NOP */
+#endif
+}
+
 /* Caller must hold recv_queue->lock */
 static inline struct rxm_rx_buf *
 rxm_check_unexp_msg_list(struct rxm_recv_queue *recv_queue, fi_addr_t addr,
@@ -473,86 +895,187 @@ rxm_process_recv_entry(struct rxm_recv_queue *recv_queue,
 {
 	struct rxm_rx_buf *rx_buf;
 
-	fastlock_acquire(&recv_queue->lock);
 	rx_buf = rxm_check_unexp_msg_list(recv_queue, recv_entry->addr,
 					  recv_entry->tag, recv_entry->ignore);
 	if (rx_buf) {
+		assert((recv_queue->type == RXM_RECV_QUEUE_MSG &&
+			rx_buf->pkt.hdr.op == ofi_op_msg) ||
+		       (recv_queue->type == RXM_RECV_QUEUE_TAGGED &&
+			rx_buf->pkt.hdr.op == ofi_op_tagged));
 		dlist_remove(&rx_buf->unexp_msg.entry);
 		rx_buf->recv_entry = recv_entry;
-		fastlock_release(&recv_queue->lock);
-		return rxm_cq_handle_data(rx_buf);
+
+		if (rx_buf->pkt.ctrl_hdr.type != ofi_ctrl_seg_data) {
+			return rxm_cq_handle_rx_buf(rx_buf);
+		} else {
+			struct dlist_entry *entry;
+			enum rxm_sar_seg_type last =
+				(rxm_sar_get_seg_type(&rx_buf->pkt.ctrl_hdr)
+								== RXM_SAR_SEG_LAST);
+			ssize_t ret = rxm_cq_handle_rx_buf(rx_buf);
+			struct rxm_recv_match_attr match_attr;
+
+			if (ret || last)
+				return ret;
+
+			match_attr.addr = recv_entry->addr;
+			match_attr.tag = recv_entry->tag;
+			match_attr.ignore = recv_entry->ignore;
+
+			dlist_foreach_container_safe(&recv_queue->unexp_msg_list,
+						     struct rxm_rx_buf, rx_buf,
+						     unexp_msg.entry, entry) {
+				if (!recv_queue->match_unexp(&rx_buf->unexp_msg.entry,
+							     &match_attr))
+					continue;
+				/* Handle unordered completions from MSG provider */
+				if ((rx_buf->pkt.ctrl_hdr.msg_id != recv_entry->sar.msg_id) ||
+				    ((rx_buf->pkt.ctrl_hdr.type != ofi_ctrl_seg_data)))
+					continue;
+
+				if (!rx_buf->conn) {
+					rx_buf->conn = rxm_key2conn(rx_buf->ep,
+								    rx_buf->pkt.ctrl_hdr.conn_id);
+				}
+				if (recv_entry->sar.conn != rx_buf->conn)
+					continue;
+				rx_buf->recv_entry = recv_entry;
+				dlist_remove(&rx_buf->unexp_msg.entry);
+				last = (rxm_sar_get_seg_type(&rx_buf->pkt.ctrl_hdr)
+								== RXM_SAR_SEG_LAST);
+				ret = rxm_cq_handle_rx_buf(rx_buf);
+				if (ret || last)
+					break;
+			}
+			return ret;
+		}
 	}
 
 	RXM_DBG_ADDR_TAG(FI_LOG_EP_DATA, "Enqueuing recv", recv_entry->addr,
 			 recv_entry->tag);
 	dlist_insert_tail(&recv_entry->entry, &recv_queue->recv_list);
-	fastlock_release(&recv_queue->lock);
 
 	return FI_SUCCESS;
 }
 
-static inline
-struct rxm_buf *rxm_buf_get(struct rxm_buf_pool *pool)
+static inline struct rxm_conn *
+rxm_acquire_conn(struct rxm_ep *rxm_ep, fi_addr_t fi_addr)
 {
-	struct rxm_buf *buf;
+	return (struct rxm_conn *)rxm_cmap_acquire_handle(rxm_ep->cmap,
+							  fi_addr);
+}
 
-	fastlock_acquire(&pool->lock);
-	buf = util_buf_alloc(pool->pool);
-	if (OFI_UNLIKELY(!buf)) {
-		fastlock_release(&pool->lock);
-		return NULL;
+static inline int
+rxm_acquire_conn_connect(struct rxm_ep *rxm_ep, fi_addr_t fi_addr,
+			 struct rxm_conn **rxm_conn)
+{
+	*rxm_conn = rxm_acquire_conn(rxm_ep, fi_addr);
+	if (OFI_UNLIKELY(!*rxm_conn || (*rxm_conn)->handle.state != RXM_CMAP_CONNECTED)) {
+		int ret;
+		if (!*rxm_conn)
+			return -FI_EHOSTUNREACH;
+		rxm_ep->cmap->acquire(&rxm_ep->cmap->lock);
+		ret = rxm_cmap_handle_unconnected(rxm_ep, &(*rxm_conn)->handle, fi_addr);
+		rxm_ep->cmap->release(&rxm_ep->cmap->lock);
+		return ret;
+	}
+	return 0;
+}
+
+static inline ssize_t
+rxm_ep_prepare_tx(struct rxm_ep *rxm_ep, fi_addr_t dest_addr,
+		 struct rxm_conn **rxm_conn)
+{
+	ssize_t ret = rxm_acquire_conn_connect(rxm_ep, dest_addr, rxm_conn);
+
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	if (OFI_UNLIKELY(!dlist_empty(&(*rxm_conn)->deferred_tx_queue))) {
+		rxm_ep_progress(&rxm_ep->util_ep);
+		if (!dlist_empty(&(*rxm_conn)->deferred_tx_queue))
+			return -FI_EAGAIN;
 	}
-	fastlock_release(&pool->lock);
-	return buf;
+
+	return 0;
+}
+
+static inline void
+rxm_ep_format_tx_buf_pkt(struct rxm_conn *rxm_conn, size_t len, uint8_t op,
+			 uint64_t data, uint64_t tag, uint64_t flags,
+			 struct rxm_pkt *pkt)
+{
+	pkt->ctrl_hdr.conn_id = rxm_conn->handle.remote_key;
+	pkt->hdr.size = len;
+	pkt->hdr.op = op;
+	pkt->hdr.tag = tag;
+	pkt->hdr.flags = (flags & FI_REMOTE_CQ_DATA);
+	pkt->hdr.data = data;
+}
+
+static inline struct rxm_buf *rxm_buf_alloc(struct rxm_buf_pool *pool)
+{
+	return util_buf_alloc(pool->pool);
 }
 
 static inline
 void rxm_buf_release(struct rxm_buf_pool *pool, struct rxm_buf *buf)
 {
-	fastlock_acquire(&pool->lock);
 	util_buf_release(pool->pool, buf);
-	fastlock_release(&pool->lock);
 }
 
-static inline struct rxm_tx_buf *
-rxm_tx_buf_get(struct rxm_ep *rxm_ep, enum rxm_buf_pool_type type)
+static inline struct rxm_buf *
+rxm_buf_get_by_index(struct rxm_buf_pool *pool, size_t index)
+{
+	return util_buf_get_by_index(pool->pool, index);
+}
+
+static inline
+size_t rxm_get_buf_index(struct rxm_buf_pool *pool, struct rxm_buf *buf)
+{
+	return util_get_buf_index(pool->pool, buf);
+}
+
+static inline struct rxm_buf *
+rxm_tx_buf_alloc(struct rxm_ep *rxm_ep, enum rxm_buf_pool_type type)
 {
-	assert((type == RXM_BUF_POOL_TX_MSG) ||
-	       (type == RXM_BUF_POOL_TX_TAGGED) ||
+	assert((type == RXM_BUF_POOL_TX) ||
+	       (type == RXM_BUF_POOL_TX_INJECT) ||
 	       (type == RXM_BUF_POOL_TX_ACK) ||
-	       (type == RXM_BUF_POOL_TX_LMT));
-	return (struct rxm_tx_buf *)rxm_buf_get(&rxm_ep->buf_pools[type]);
+	       (type == RXM_BUF_POOL_TX_RNDV) ||
+	       (type == RXM_BUF_POOL_TX_ATOMIC) ||
+	       (type == RXM_BUF_POOL_TX_SAR));
+	return rxm_buf_alloc(&rxm_ep->buf_pools[type]);
 }
 
 static inline void
-rxm_tx_buf_release(struct rxm_ep *rxm_ep, struct rxm_tx_buf *tx_buf)
+rxm_tx_buf_release(struct rxm_ep *rxm_ep, enum rxm_buf_pool_type type, void *tx_buf)
 {
-	assert((tx_buf->type == RXM_BUF_POOL_TX_MSG) ||
-	       (tx_buf->type == RXM_BUF_POOL_TX_TAGGED) ||
-	       (tx_buf->type == RXM_BUF_POOL_TX_ACK) ||
-	       (tx_buf->type == RXM_BUF_POOL_TX_LMT));
-	tx_buf->pkt.hdr.flags &= ~OFI_REMOTE_CQ_DATA;
-	rxm_buf_release(&rxm_ep->buf_pools[tx_buf->type],
-			(struct rxm_buf *)tx_buf);
+	rxm_buf_release(&rxm_ep->buf_pools[type], (struct rxm_buf *)tx_buf);
 }
 
-static inline struct rxm_rx_buf *rxm_rx_buf_get(struct rxm_ep *rxm_ep)
+static inline struct rxm_rx_buf *rxm_rx_buf_alloc(struct rxm_ep *rxm_ep)
 {
-	return (struct rxm_rx_buf *)rxm_buf_get(
-			&rxm_ep->buf_pools[RXM_BUF_POOL_RX]);
+	return (struct rxm_rx_buf *)
+		rxm_buf_alloc(&rxm_ep->buf_pools[RXM_BUF_POOL_RX]);
 }
 
 static inline void
 rxm_rx_buf_release(struct rxm_ep *rxm_ep, struct rxm_rx_buf *rx_buf)
 {
-	rxm_buf_release(&rxm_ep->buf_pools[RXM_BUF_POOL_RX],
-			(struct rxm_buf *)rx_buf);
+	if (rx_buf->repost) {
+		dlist_insert_tail(&rx_buf->repost_entry,
+				  &rx_buf->ep->repost_ready_list);
+	} else {
+		util_buf_release(rxm_ep->buf_pools[RXM_BUF_POOL_RX].pool,
+				 rx_buf);
+	}
 }
 
-static inline struct rxm_rma_buf *rxm_rma_buf_get(struct rxm_ep *rxm_ep)
+static inline struct rxm_rma_buf *rxm_rma_buf_alloc(struct rxm_ep *rxm_ep)
 {
-	return (struct rxm_rma_buf *)rxm_buf_get(
-			&rxm_ep->buf_pools[RXM_BUF_POOL_RMA]);
+	return (struct rxm_rma_buf *)
+		rxm_buf_alloc(&rxm_ep->buf_pools[RXM_BUF_POOL_RMA]);
 }
 
 static inline void
@@ -562,45 +1085,51 @@ rxm_rma_buf_release(struct rxm_ep *rxm_ep, struct rxm_rma_buf *rx_buf)
 			(struct rxm_buf *)rx_buf);
 }
 
-#define rxm_entry_pop(queue, entry)			\
-	do {						\
-		fastlock_acquire(&queue->lock);		\
-		entry = freestack_isempty(queue->fs) ?	\
-			NULL : freestack_pop(queue->fs);\
-		fastlock_release(&queue->lock);		\
-	} while (0)
+static inline
+struct rxm_tx_atomic_buf *rxm_tx_atomic_buf_alloc(struct rxm_ep *rxm_ep)
+{
+	return (struct rxm_tx_atomic_buf *)
+		rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX_ATOMIC);
+}
 
-#define rxm_entry_push(queue, entry)			\
-	do {						\
-		fastlock_acquire(&queue->lock);		\
-		freestack_push(queue->fs, entry);	\
-		fastlock_release(&queue->lock);		\
-	} while (0)
+static inline struct rxm_recv_entry *rxm_recv_entry_get(struct rxm_recv_queue *queue)
+{
+	return (freestack_isempty(queue->fs) ?
+		NULL : freestack_pop(queue->fs));
+}
+
+static inline void
+rxm_recv_entry_release(struct rxm_recv_queue *queue, struct rxm_recv_entry *entry)
+{
+	entry->total_len = 0;
+	freestack_push(queue->fs, entry);
+}
+
+static inline int rxm_cq_write_recv_comp(struct rxm_rx_buf *rx_buf,
+					 void *context, uint64_t flags,
+					 size_t len, char *buf)
+{
+	if (rx_buf->ep->rxm_info->caps & FI_SOURCE)
+		return ofi_cq_write_src(rx_buf->ep->util_ep.rx_cq, context,
+					flags, len, buf, rx_buf->pkt.hdr.data,
+					rx_buf->pkt.hdr.tag,
+					rx_buf->conn->handle.fi_addr);
+	else
+		return ofi_cq_write(rx_buf->ep->util_ep.rx_cq, context,
+				    flags, len, buf, rx_buf->pkt.hdr.data,
+				    rx_buf->pkt.hdr.tag);
+}
 
-#define rxm_tx_entry_cleanup(entry)		(entry)->tx_buf = NULL
-#define rxm_recv_entry_cleanup(entry)		(entry)->total_len = 0
-
-#define RXM_DEFINE_QUEUE_ENTRY(type, queue_type)				\
-static inline struct rxm_ ## type ## _entry *					\
-rxm_ ## type ## _entry_get(struct rxm_ ## queue_type ## _queue *queue)		\
-{										\
-	struct rxm_ ## type ## _entry *entry;					\
-	rxm_entry_pop(queue, entry);						\
-	if (!entry) {								\
-		FI_WARN(&rxm_prov, FI_LOG_CQ,					\
-			"Exhausted " #type "_entry freestack\n");		\
-		return NULL;							\
-	}									\
-	return entry;								\
-}										\
-										\
-static inline void								\
-rxm_ ## type ## _entry_release(struct rxm_ ## queue_type ## _queue *queue,	\
-			       struct rxm_ ## type ## _entry *entry)		\
-{										\
-	rxm_ ## type ## _entry_cleanup(entry);					\
-	rxm_entry_push(queue, entry);						\
-}
-
-RXM_DEFINE_QUEUE_ENTRY(tx, send);
-RXM_DEFINE_QUEUE_ENTRY(recv, recv);
+static inline int
+rxm_cq_write_multi_recv_comp(struct rxm_ep *rxm_ep, struct rxm_recv_entry *recv_entry)
+{
+	if (rxm_ep->rxm_info->caps & FI_SOURCE)
+		return ofi_cq_write_src(rxm_ep->util_ep.rx_cq, recv_entry->context,
+					FI_MULTI_RECV, recv_entry->multi_recv.len,
+					recv_entry->multi_recv.buf, 0, 0,
+					recv_entry->addr);
+	else
+		return ofi_cq_write(rxm_ep->util_ep.rx_cq, recv_entry->context,
+				    FI_MULTI_RECV, recv_entry->multi_recv.len,
+				    recv_entry->multi_recv.buf, 0, 0);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_atomic.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_atomic.c
new file mode 100644
index 000000000..ce7c58cce
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_atomic.c
@@ -0,0 +1,507 @@
+/*
+ * Copyright (c) 2018 Cray Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <ofi_atomic.h>
+
+#include "rxm.h"
+
+static void
+rxm_ep_format_atomic_pkt_hdr(struct rxm_conn *rxm_conn,
+		 struct rxm_tx_atomic_buf *tx_buf, size_t data_len,
+		 uint32_t pkt_op, enum fi_datatype datatype,
+		 uint8_t atomic_op, uint64_t flags, uint64_t data,
+		 const struct fi_rma_ioc *rma_ioc, size_t rma_ioc_count)
+{
+	struct rxm_atomic_hdr *atomic_hdr;
+
+	atomic_hdr = (struct rxm_atomic_hdr *)tx_buf->pkt.data;
+	rxm_ep_format_tx_buf_pkt(rxm_conn, data_len, pkt_op, data, 0,
+				 flags, &tx_buf->pkt);
+	tx_buf->pkt.ctrl_hdr.type = ofi_ctrl_atomic;
+	tx_buf->pkt.hdr.op = pkt_op;
+	tx_buf->pkt.hdr.atomic.datatype = datatype;
+	tx_buf->pkt.hdr.atomic.op = atomic_op;
+	tx_buf->pkt.hdr.atomic.ioc_count = rma_ioc_count;
+	if (rma_ioc_count)
+		memcpy(atomic_hdr->rma_ioc, rma_ioc,
+		       rma_ioc_count * sizeof(struct fi_rma_ioc));
+	tx_buf->flags = flags;
+}
+
+static inline int
+rxm_ep_send_atomic_req(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		       struct rxm_tx_atomic_buf *tx_buf, uint64_t len)
+{
+	int ret;
+
+	/* Atomic request TX completion processing is performed when the
+	 * software generated atomic response message is received. */
+	tx_buf->hdr.state = RXM_ATOMIC_RESP_WAIT;
+	if (len <= rxm_ep->inject_limit)
+		ret = fi_inject(rxm_conn->msg_ep, &tx_buf->pkt, len, 0);
+	else
+		ret = fi_send(rxm_conn->msg_ep, &tx_buf->pkt, len,
+			      tx_buf->hdr.desc, 0, tx_buf);
+	if (ret == -FI_EAGAIN)
+		rxm_ep_do_progress(&rxm_ep->util_ep);
+
+	return ret;
+}
+
+static ssize_t
+rxm_ep_atomic_common(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		const struct fi_msg_atomic *msg, const struct fi_ioc *comparev,
+		void **compare_desc, size_t compare_iov_count,
+		struct fi_ioc *resultv, void **result_desc,
+		size_t result_iov_count, uint32_t op, uint64_t flags)
+{
+	struct rxm_tx_atomic_buf *tx_buf;
+	struct rxm_atomic_hdr *atomic_hdr;
+	struct iovec buf_iov[RXM_IOV_LIMIT];
+	struct iovec cmp_iov[RXM_IOV_LIMIT];
+	size_t datatype_sz = ofi_datatype_size(msg->datatype);
+	size_t buf_len = 0;
+	size_t cmp_len = 0;
+	size_t tot_len;
+	ssize_t ret;
+
+	assert(msg->iov_count <= RXM_IOV_LIMIT &&
+	       msg->rma_iov_count <= RXM_IOV_LIMIT);
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
+		       "Atomic with remote CQ data not supported\n");
+		return -FI_EINVAL;
+	}
+
+	if (msg->op != FI_ATOMIC_READ) {
+		assert(msg->msg_iov);
+		ofi_ioc_to_iov(msg->msg_iov, buf_iov, msg->iov_count,
+			       datatype_sz);
+		buf_len = ofi_total_iov_len(buf_iov, msg->iov_count);
+	}
+
+	if (op == ofi_op_atomic_compare) {
+		assert(comparev);
+		ofi_ioc_to_iov(comparev, cmp_iov, compare_iov_count,
+			       datatype_sz);
+		cmp_len = ofi_total_iov_len(cmp_iov, compare_iov_count);
+		assert(buf_len == cmp_len);
+	}
+
+	tot_len = buf_len + cmp_len + sizeof(struct rxm_atomic_hdr) +
+			sizeof(struct rxm_pkt);
+
+	if (tot_len > rxm_ep->eager_limit) {
+		FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
+		       "atomic data too large %" PRId64 "\n", tot_len);
+		return -FI_EINVAL;
+	}
+
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
+	tx_buf = (struct rxm_tx_atomic_buf *)
+		 rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX_ATOMIC);
+	if (OFI_UNLIKELY(!tx_buf)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Ran out of buffers from Atomic buffer pool\n");
+		ret = -FI_EAGAIN;
+		goto unlock;
+	}
+
+	rxm_ep_format_atomic_pkt_hdr(rxm_conn, tx_buf, tot_len, op,
+				msg->datatype, msg->op, flags, msg->data,
+				msg->rma_iov, msg->rma_iov_count);
+	tx_buf->pkt.ctrl_hdr.msg_id = rxm_tx_buf_2_msg_id(rxm_ep,
+					  RXM_BUF_POOL_TX_ATOMIC, tx_buf);
+	tx_buf->app_context = msg->context;
+
+	atomic_hdr = (struct rxm_atomic_hdr *) tx_buf->pkt.data;
+
+	ofi_copy_from_iov(atomic_hdr->data, buf_len, buf_iov,
+			  msg->iov_count, 0);
+	if (cmp_len)
+		ofi_copy_from_iov(atomic_hdr->data + buf_len, cmp_len,
+				  cmp_iov, compare_iov_count, 0);
+
+	tx_buf->result_iov_count = result_iov_count;
+	if (resultv)
+		ofi_ioc_to_iov(resultv, tx_buf->result_iov, result_iov_count,
+			       datatype_sz);
+
+	ret = rxm_ep_send_atomic_req(rxm_ep, rxm_conn, tx_buf, tot_len);
+	if (ret)
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_ATOMIC, tx_buf);
+unlock:
+	ofi_ep_lock_release(&rxm_ep->util_ep);
+	return ret;
+}
+
+static ssize_t
+rxm_ep_atomic_writemsg(struct fid_ep *ep_fid, const struct fi_msg_atomic *msg,
+		       uint64_t flags)
+{
+	int ret;
+	struct rxm_conn *rxm_conn;
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid.fid);
+
+	ret = rxm_ep_prepare_tx(rxm_ep, msg->addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_atomic_common(rxm_ep, rxm_conn, msg, NULL, NULL, 0,
+				    NULL, NULL, 0, ofi_op_atomic,
+				    flags | rxm_ep_tx_flags(rxm_ep));
+}
+
+static ssize_t
+rxm_ep_atomic_writev(struct fid_ep *ep_fid, const struct fi_ioc *iov,
+		     void **desc, size_t count, fi_addr_t dest_addr,
+		     uint64_t addr, uint64_t key, enum fi_datatype datatype,
+		     enum fi_op op, void *context)
+{
+	struct fi_rma_ioc rma_iov = {
+		.addr = addr,
+		.count = ofi_total_ioc_cnt(iov, count),
+		.key = key,
+	};
+	struct fi_msg_atomic msg = {
+		.msg_iov = iov,
+		.desc = desc,
+		.iov_count = count,
+		.addr = dest_addr,
+		.rma_iov = &rma_iov,
+		.rma_iov_count = 1,
+		.datatype = datatype,
+		.op = op,
+		.context = context,
+		.data = 0,
+	};
+
+	return rxm_ep_atomic_writemsg(ep_fid, &msg, 0);
+}
+
+static ssize_t
+rxm_ep_atomic_write(struct fid_ep *ep_fid, const void *buf, size_t count,
+		    void *desc, fi_addr_t dest_addr, uint64_t addr,
+		    uint64_t key, enum fi_datatype datatype, enum fi_op op,
+		    void *context)
+{
+	const struct fi_ioc iov = {
+		.addr = (void *) buf,
+		.count = count,
+	};
+
+	return rxm_ep_atomic_writev(ep_fid, &iov, &desc, 1, dest_addr, addr,
+				    key, datatype, op, context);
+}
+
+static ssize_t
+rxm_ep_atomic_inject(struct fid_ep *ep_fid, const void *buf, size_t count,
+		     fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		     enum fi_datatype datatype, enum fi_op op)
+{
+	struct fi_ioc msg_iov = {
+		.addr = (void *) buf,
+		.count = count,
+	};
+	struct fi_rma_ioc rma_iov = {
+		.addr = addr,
+		.count = count,
+		.key = key,
+	};
+	struct fi_msg_atomic msg = {
+		.msg_iov = &msg_iov,
+		.desc = NULL,
+		.iov_count = 1,
+		.addr = dest_addr,
+		.rma_iov = &rma_iov,
+		.rma_iov_count = 1,
+		.datatype = datatype,
+		.op = op,
+		.context = NULL,
+		.data = 0,
+	};
+
+	return rxm_ep_atomic_writemsg(ep_fid, &msg, FI_INJECT);
+}
+
+static ssize_t
+rxm_ep_atomic_readwritemsg(struct fid_ep *ep_fid,
+			   const struct fi_msg_atomic *msg,
+			   struct fi_ioc *resultv, void **result_desc,
+			   size_t result_count, uint64_t flags)
+{
+	int ret;
+	struct rxm_conn *rxm_conn;
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid.fid);
+
+	ret = rxm_ep_prepare_tx(rxm_ep, msg->addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_atomic_common(rxm_ep, rxm_conn, msg, NULL, NULL, 0,
+				    resultv, result_desc, result_count,
+				    ofi_op_atomic_fetch,
+				    flags | rxm_ep_tx_flags(rxm_ep));
+}
+
+static ssize_t
+rxm_ep_atomic_readwritev(struct fid_ep *ep_fid, const struct fi_ioc *iov,
+		 void **desc, size_t count, struct fi_ioc *resultv,
+		 void **result_desc, size_t result_count, fi_addr_t dest_addr,
+		 uint64_t addr, uint64_t key, enum fi_datatype datatype,
+		 enum fi_op op, void *context)
+{
+	struct fi_rma_ioc rma_iov = {
+		.addr = addr,
+		.count = ofi_total_ioc_cnt(iov, count),
+		.key = key,
+	};
+	struct fi_msg_atomic msg = {
+		.msg_iov = iov,
+		.desc = desc,
+		.iov_count = count,
+		.addr = dest_addr,
+		.rma_iov = &rma_iov,
+		.rma_iov_count = 1,
+		.datatype = datatype,
+		.op = op,
+		.context = context,
+		.data = 0,
+	};
+
+	return rxm_ep_atomic_readwritemsg(ep_fid, &msg, resultv, result_desc,
+					  result_count, 0);
+}
+
+static ssize_t
+rxm_ep_atomic_readwrite(struct fid_ep *ep_fid, const void *buf, size_t count,
+			void *desc, void *result, void *result_desc,
+			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct fi_ioc iov = {
+		.addr = (op == FI_ATOMIC_READ) ? NULL : (void *) buf,
+		.count = count,
+	};
+	struct fi_ioc result_iov = {
+		.addr = result,
+		.count = count,
+	};
+
+	if (!buf && op != FI_ATOMIC_READ)
+		return -FI_EINVAL;
+
+	return rxm_ep_atomic_readwritev(ep_fid, &iov, &desc, 1, &result_iov,
+					&result_desc, 1, dest_addr, addr, key,
+					datatype, op, context);
+}
+
+static ssize_t
+rxm_ep_atomic_compwritemsg(struct fid_ep *ep_fid,
+			   const struct fi_msg_atomic *msg,
+			   const struct fi_ioc *comparev, void **compare_desc,
+			   size_t compare_count, struct fi_ioc *resultv,
+			   void **result_desc, size_t result_count,
+			   uint64_t flags)
+{
+	int ret;
+	struct rxm_conn *rxm_conn;
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid.fid);
+
+	ret = rxm_ep_prepare_tx(rxm_ep, msg->addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_atomic_common(rxm_ep, rxm_conn, msg, comparev,
+				    compare_desc, compare_count, resultv,
+				    result_desc, result_count,
+				    ofi_op_atomic_compare,
+				    flags | rxm_ep_tx_flags(rxm_ep));
+}
+
+static ssize_t
+rxm_ep_atomic_compwritev(struct fid_ep *ep_fid, const struct fi_ioc *iov,
+		 void **desc, size_t count, const struct fi_ioc *comparev,
+		 void **compare_desc, size_t compare_count,
+		 struct fi_ioc *resultv, void **result_desc,
+		 size_t result_count, fi_addr_t dest_addr, uint64_t addr,
+		 uint64_t key, enum fi_datatype datatype, enum fi_op op,
+		 void *context)
+{
+	struct fi_rma_ioc rma_iov = {
+		.addr = addr,
+		.count = ofi_total_ioc_cnt(iov, count),
+		.key = key,
+	};
+	struct fi_msg_atomic msg = {
+		.msg_iov = iov,
+		.desc = desc,
+		.iov_count = count,
+		.addr = dest_addr,
+		.rma_iov = &rma_iov,
+		.rma_iov_count = 1,
+		.datatype = datatype,
+		.op = op,
+		.context = context,
+		.data = 0,
+	};
+
+	return rxm_ep_atomic_compwritemsg(ep_fid, &msg, comparev, compare_desc,
+				compare_count, resultv, result_desc,
+				result_count, 0);
+}
+
+static ssize_t
+rxm_ep_atomic_compwrite(struct fid_ep *ep_fid, const void *buf, size_t count,
+			void *desc, const void *compare, void *compare_desc,
+			void *result, void *result_desc, fi_addr_t dest_addr,
+			uint64_t addr, uint64_t key, enum fi_datatype datatype,
+			enum fi_op op, void *context)
+{
+	struct fi_ioc iov = {
+		.addr = (void *) buf,
+		.count = count,
+	};
+	struct fi_ioc resultv = {
+		.addr = result,
+		.count = count,
+	};
+	struct fi_ioc comparev = {
+		.addr = (void *) compare,
+		.count = count,
+	};
+
+	return rxm_ep_atomic_compwritev(ep_fid, &iov, &desc, 1,
+					&comparev, &compare_desc, 1,
+					&resultv, &result_desc, 1,
+					dest_addr, addr, key,
+					datatype, op, context);
+}
+
+int rxm_ep_query_atomic(struct fid_domain *domain, enum fi_datatype datatype,
+			enum fi_op op, struct fi_atomic_attr *attr,
+			uint64_t flags)
+{
+	struct rxm_domain *rxm_domain = container_of(domain,
+						     struct rxm_domain,
+						     util_domain.domain_fid);
+	size_t tot_size;
+	int ret;
+
+	if (flags & FI_TAGGED) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"tagged atomic op not supported\n");
+		return -FI_EINVAL;
+	}
+
+	ret = ofi_atomic_valid(&rxm_prov, datatype, op, flags);
+	if (ret || !attr)
+		return ret;
+
+	tot_size = flags & FI_COMPARE_ATOMIC ?
+		rxm_domain->max_atomic_size / 2 : rxm_domain->max_atomic_size;
+	attr->size = ofi_datatype_size(datatype);
+	attr->count = tot_size / attr->size;
+
+	return FI_SUCCESS;
+}
+
+static int rxm_ep_atomic_valid(struct fid_ep *ep_fid, enum fi_datatype datatype,
+			       enum fi_op op, size_t *count)
+{
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid);
+	struct fi_atomic_attr attr;
+	int ret;
+
+	ret = rxm_ep_query_atomic(&rxm_ep->util_ep.domain->domain_fid,
+				  datatype, op, &attr, 0);
+	if (!ret)
+		*count = attr.count;
+
+	return ret;
+}
+
+static int rxm_ep_atomic_fetch_valid(struct fid_ep *ep_fid,
+				     enum fi_datatype datatype, enum fi_op op,
+				     size_t *count)
+{
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid);
+	struct fi_atomic_attr attr;
+	int ret;
+
+	ret = rxm_ep_query_atomic(&rxm_ep->util_ep.domain->domain_fid,
+				  datatype, op, &attr, FI_FETCH_ATOMIC);
+	if (!ret)
+		*count = attr.count;
+
+	return ret;
+}
+
+static int rxm_ep_atomic_cswap_valid(struct fid_ep *ep_fid,
+				     enum fi_datatype datatype, enum fi_op op,
+				     size_t *count)
+{
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid);
+	struct fi_atomic_attr attr;
+	int ret;
+
+	ret = rxm_ep_query_atomic(&rxm_ep->util_ep.domain->domain_fid,
+				  datatype, op, &attr, FI_COMPARE_ATOMIC);
+	if (!ret)
+		*count = attr.count;
+
+	return ret;
+}
+
+struct fi_ops_atomic rxm_ops_atomic = {
+	.size = sizeof(struct fi_ops_atomic),
+	.write = rxm_ep_atomic_write,
+	.writev = rxm_ep_atomic_writev,
+	.writemsg = rxm_ep_atomic_writemsg,
+	.inject = rxm_ep_atomic_inject,
+	.readwrite = rxm_ep_atomic_readwrite,
+	.readwritev = rxm_ep_atomic_readwritev,
+	.readwritemsg = rxm_ep_atomic_readwritemsg,
+	.compwrite = rxm_ep_atomic_compwrite,
+	.compwritev = rxm_ep_atomic_compwritev,
+	.compwritemsg = rxm_ep_atomic_compwritemsg,
+	.writevalid = rxm_ep_atomic_valid,
+	.readwritevalid = rxm_ep_atomic_fetch_valid,
+	.compwritevalid = rxm_ep_atomic_cswap_valid,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_attr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_attr.c
index eb2fd93fc..0c4f6c992 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_attr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_attr.c
@@ -32,9 +32,9 @@
 
 #include "rxm.h"
 
-#define RXM_EP_CAPS (FI_MSG | FI_RMA | FI_TAGGED | FI_DIRECTED_RECV |	\
-		     FI_READ | FI_WRITE | FI_RECV | FI_SEND |		\
-		     FI_REMOTE_READ | FI_REMOTE_WRITE | FI_SOURCE)
+#define RXM_EP_CAPS (FI_MSG | FI_RMA | FI_TAGGED | FI_ATOMIC |		\
+		     FI_DIRECTED_RECV |	FI_READ | FI_WRITE | FI_RECV |	\
+		     FI_SEND | FI_REMOTE_READ | FI_REMOTE_WRITE | FI_SOURCE)
 
 #define RXM_DOMAIN_CAPS (FI_LOCAL_COMM | FI_REMOTE_COMM)
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_av.c
new file mode 100644
index 000000000..6ae0b7ccb
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_av.c
@@ -0,0 +1,203 @@
+/*
+ * Copyright (c) 2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "rxm.h"
+
+static int rxm_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr,
+			 size_t count, uint64_t flags)
+{
+	struct util_av *av = container_of(av_fid, struct util_av, av_fid);
+	struct rxm_ep *rxm_ep;
+	int i, ret;
+
+	/* This should be before ofi_ip_av_remove as we need to know
+	 * fi_addr -> addr mapping when moving handle to peer list. */
+	dlist_foreach_container(&av->ep_list, struct rxm_ep,
+				rxm_ep, util_ep.av_entry) {
+		for (i = 0; i < count; i++) {
+			if (!rxm_ep->cmap->handles_av[fi_addr[i]])
+				continue;
+			/* TODO this is not optimal. Replace this with something
+			 * more deterministic: delete handle if we know that peer
+			 * isn't actively communicating with us
+			 */
+			ret = rxm_cmap_move_handle_to_peer_list(rxm_ep->cmap, i);
+			if (ret) {
+				FI_WARN(&rxm_prov, FI_LOG_DOMAIN,
+					"Unable to move  handle to "
+					"peer list. Deleting it.\n");
+				rxm_cmap_del_handle_ts(rxm_ep->cmap->handles_av[i]);
+				return ret;
+			}
+		}
+	}
+
+	return ofi_ip_av_remove(av_fid, fi_addr, count, flags);
+}
+
+static int
+rxm_av_insert_cmap(struct fid_av *av_fid, const void *addr, size_t count,
+		   fi_addr_t *fi_addr, uint64_t flags)
+{
+	struct util_av *av = container_of(av_fid, struct util_av, av_fid);
+	struct rxm_ep *rxm_ep;
+	fi_addr_t fi_addr_tmp;
+	size_t i;
+	int ret = 0;
+	const void *cur_addr;
+
+	dlist_foreach_container(&av->ep_list, struct rxm_ep,
+				rxm_ep, util_ep.av_entry) {
+		for (i = 0; i < count; i++) {
+			cur_addr = (const void *) ((char *) addr + i * av->addrlen);
+			fi_addr_tmp = (fi_addr ? fi_addr[i] :
+				       ofi_av_lookup_fi_addr(av, cur_addr));
+			if (fi_addr_tmp == FI_ADDR_NOTAVAIL)
+				continue;
+			ret = rxm_cmap_update(rxm_ep->cmap, cur_addr, fi_addr_tmp);
+			if (OFI_UNLIKELY(ret)) {
+				FI_WARN(&rxm_prov, FI_LOG_AV,
+					"Unable to update CM for OFI endpoints\n");
+				return ret;
+			}
+		}
+	}
+	return 0;
+}
+
+static int rxm_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
+			 fi_addr_t *fi_addr, uint64_t flags, void *context)
+{
+	struct util_av *av = container_of(av_fid, struct util_av, av_fid);
+	int ret, retv;
+
+	ret = ofi_ip_av_insert(av_fid, addr, count, fi_addr, flags, context);
+	if (ret < 0)
+		return ret;
+
+	if (!av->eq && !ret)
+		return ret;
+
+	retv = rxm_av_insert_cmap(av_fid, addr, count, fi_addr, flags);
+	if (retv) {
+		ret = rxm_av_remove(av_fid, fi_addr, count, flags);
+		if (ret)
+			FI_WARN(&rxm_prov, FI_LOG_AV, "Failed to remove addr "
+				"from AV during error handling\n");
+		return retv;
+	}
+	return ret;
+}
+
+static int rxm_av_insertsym(struct fid_av *av_fid, const char *node,
+			    size_t nodecnt, const char *service, size_t svccnt,
+			    fi_addr_t *fi_addr, uint64_t flags, void *context)
+{
+	struct util_av *av = container_of(av_fid, struct util_av, av_fid);
+	void *addr;
+	size_t addrlen, count = nodecnt * svccnt;
+	int ret, retv;
+
+	ret = ofi_verify_av_insert(av, flags);
+	if (ret)
+		return ret;
+
+	ret = ofi_ip_av_sym_getaddr(av, node, nodecnt, service,
+				    svccnt, &addr, &addrlen);
+	if (ret <= 0)
+		return ret;
+
+	assert(ret == count);
+
+	ret = ofi_ip_av_insertv(av, addr, addrlen, count, fi_addr, context);
+	if (ret < 0)
+		goto out;
+
+	if (!av->eq && !ret)
+		goto out;
+
+	retv = rxm_av_insert_cmap(av_fid, addr, count, fi_addr, flags);
+	if (retv) {
+		ret = rxm_av_remove(av_fid, fi_addr, count, flags);
+		if (ret)
+			FI_WARN(&rxm_prov, FI_LOG_AV, "Failed to remove addr "
+				"from AV during error handling\n");
+		ret = retv;
+	}
+out:
+	free(addr);
+	return ret;
+
+}
+
+int rxm_av_insertsvc(struct fid_av *av, const char *node, const char *service,
+		     fi_addr_t *fi_addr, uint64_t flags, void *context)
+{
+	return rxm_av_insertsym(av, node, 1, service, 1, fi_addr, flags, context);
+}
+
+static const char *
+rxm_av_straddr(struct fid_av *av_fid, const void *addr, char *buf, size_t *len)
+{
+	return ofi_ip_av_straddr(av_fid, addr, buf, len);
+}
+
+int rxm_av_lookup(struct fid_av *av_fid, fi_addr_t fi_addr,
+		  void *addr, size_t *addrlen)
+{
+	return ofi_ip_av_lookup(av_fid, fi_addr, addr, addrlen);
+}
+
+
+static struct fi_ops_av rxm_av_ops = {
+	.size = sizeof(struct fi_ops_av),
+	.insert = rxm_av_insert,
+	.insertsvc = rxm_av_insertsvc,
+	.insertsym = rxm_av_insertsym,
+	.remove = rxm_av_remove,
+	.lookup = rxm_av_lookup,
+	.straddr = rxm_av_straddr,
+};
+
+int rxm_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+		struct fid_av **av, void *context)
+{
+	int ret;
+
+	ret = ofi_ip_av_create(domain_fid, attr, av, context);
+	if (ret)
+		return ret;
+
+	(*av)->ops = &rxm_av_ops;
+	return 0;
+}
+
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_conn.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_conn.c
index 0d1af1d0c..adb62895d 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_conn.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_conn.c
@@ -37,6 +37,797 @@
 #include <ofi_util.h>
 #include "rxm.h"
 
+static struct rxm_cmap_handle *rxm_conn_alloc(struct rxm_cmap *cmap);
+static void rxm_conn_connected_handler(struct rxm_cmap_handle *handle);
+static void rxm_conn_close_saved(struct rxm_cmap_handle *handle);
+static void rxm_conn_close(struct rxm_cmap_handle *handle);
+static void rxm_conn_save(struct rxm_cmap_handle *handle);
+static int
+rxm_conn_connect(struct util_ep *util_ep, struct rxm_cmap_handle *handle,
+		 const void *addr, size_t addrlen);
+static int rxm_conn_signal(struct util_ep *util_ep, void *context,
+			   enum rxm_cmap_signal signal);
+static void
+rxm_conn_av_updated_handler(struct rxm_cmap_handle *handle);
+static void *rxm_conn_progress(void *arg);
+static void *rxm_conn_eq_read(void *arg);
+
+
+/*
+ * Connection map
+ */
+
+/* Caller should hold cmap->lock */
+static void rxm_cmap_set_key(struct rxm_cmap_handle *handle)
+{
+	handle->key = ofi_idx2key(&handle->cmap->key_idx,
+		ofi_idx_insert(&handle->cmap->handles_idx, handle));
+}
+
+/* Caller should hold cmap->lock */
+static void rxm_cmap_clear_key(struct rxm_cmap_handle *handle)
+{
+	int index = ofi_key2idx(&handle->cmap->key_idx, handle->key);
+
+	if (!ofi_idx_is_valid(&handle->cmap->handles_idx, index))
+		FI_WARN(handle->cmap->av->prov, FI_LOG_AV, "Invalid key!\n");
+	else
+		ofi_idx_remove(&handle->cmap->handles_idx, index);
+}
+
+struct rxm_cmap_handle *rxm_cmap_key2handle(struct rxm_cmap *cmap, uint64_t key)
+{
+	struct rxm_cmap_handle *handle;
+
+	cmap->acquire(&cmap->lock);
+	if (!(handle = ofi_idx_lookup(&cmap->handles_idx,
+				      ofi_key2idx(&cmap->key_idx, key)))) {
+		FI_WARN(cmap->av->prov, FI_LOG_AV, "Invalid key!\n");
+	} else {
+		if (handle->key != key) {
+			FI_WARN(cmap->av->prov, FI_LOG_AV,
+				"handle->key not matching given key\n");
+			handle = NULL;
+		}
+	}
+	cmap->release(&cmap->lock);
+	return handle;
+}
+
+/* Caller must hold cmap->lock */
+static void rxm_cmap_init_handle(struct rxm_cmap_handle *handle,
+				  struct rxm_cmap *cmap,
+				  enum rxm_cmap_state state,
+				  fi_addr_t fi_addr,
+				  struct rxm_cmap_peer *peer)
+{
+	handle->cmap = cmap;
+	handle->state = state;
+	rxm_cmap_set_key(handle);
+	handle->fi_addr = fi_addr;
+	handle->peer = peer;
+}
+
+static int rxm_cmap_match_peer(struct dlist_entry *entry, const void *addr)
+{
+	struct rxm_cmap_peer *peer;
+
+	peer = container_of(entry, struct rxm_cmap_peer, entry);
+	return !memcmp(peer->addr, addr, peer->handle->cmap->av->addrlen);
+}
+
+/* Caller must hold cmap->lock */
+static int rxm_cmap_del_handle(struct rxm_cmap_handle *handle)
+{
+	struct rxm_cmap *cmap = handle->cmap;
+	int ret;
+
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+	       "Deleting connection handle: %p\n", handle);
+	if (handle->peer) {
+		dlist_remove(&handle->peer->entry);
+		free(handle->peer);
+		handle->peer = NULL;
+	} else {
+		cmap->handles_av[handle->fi_addr] = 0;
+	}
+	rxm_cmap_clear_key(handle);
+
+	handle->state = RXM_CMAP_SHUTDOWN;
+	/* Signal CM thread to delete the handle. This is required
+	 * so that the CM thread handles any pending events for this
+	 * ep correctly. Handle would be freed finally after processing the
+	 * events */
+	ret = rxm_conn_signal(cmap->ep, handle, RXM_CMAP_FREE);
+	if (ret) {
+		FI_WARN(cmap->av->prov, FI_LOG_FABRIC,
+			"Unable to signal CM thread\n");
+		return ret;
+	}
+	return 0;
+}
+
+static inline int
+rxm_cmap_check_and_realloc_handles_table(struct rxm_cmap *cmap,
+					 fi_addr_t fi_addr)
+{
+	void *new_handles;
+	size_t grow_size;
+
+	if (OFI_LIKELY(fi_addr < cmap->num_allocated))
+		return 0;
+
+	grow_size = MAX(cmap->av->count, fi_addr - cmap->num_allocated + 1);
+
+	new_handles = realloc(cmap->handles_av,
+			      (grow_size + cmap->num_allocated) *
+			      sizeof(*cmap->handles_av));
+	if (OFI_LIKELY(!new_handles))
+		return -FI_ENOMEM;
+
+	cmap->handles_av = new_handles;
+	memset(&cmap->handles_av[cmap->num_allocated], 0,
+	       sizeof(*cmap->handles_av) * grow_size);
+	cmap->num_allocated += grow_size;
+	return 0;
+}
+
+void rxm_cmap_del_handle_ts(struct rxm_cmap_handle *handle)
+{
+	struct rxm_cmap *cmap = handle->cmap;
+	cmap->acquire(&cmap->lock);
+	rxm_cmap_del_handle(handle);
+	cmap->release(&cmap->lock);
+}
+
+static struct rxm_pkt *
+rxm_conn_inject_pkt_alloc(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+			  uint8_t op, uint64_t flags)
+{
+	struct rxm_pkt *inject_pkt;
+	int ret = ofi_memalign((void **) &inject_pkt, 16,
+			       rxm_ep->inject_limit + sizeof(*inject_pkt));
+
+	if (ret)
+		return NULL;
+
+	memset(inject_pkt, 0, rxm_ep->inject_limit + sizeof(*inject_pkt));
+	inject_pkt->ctrl_hdr.version = RXM_CTRL_VERSION;
+	inject_pkt->ctrl_hdr.type = ofi_ctrl_data;
+	inject_pkt->hdr.version = OFI_OP_VERSION;
+	inject_pkt->hdr.op = op;
+	inject_pkt->hdr.flags = flags;
+
+	return inject_pkt;
+}
+static void rxm_conn_res_free(struct rxm_conn *rxm_conn)
+{
+	ofi_freealign(rxm_conn->inject_pkt);
+	rxm_conn->inject_pkt = NULL;
+	ofi_freealign(rxm_conn->inject_data_pkt);
+	rxm_conn->inject_data_pkt = NULL;
+	ofi_freealign(rxm_conn->tinject_pkt);
+	rxm_conn->tinject_pkt = NULL;
+	ofi_freealign(rxm_conn->tinject_data_pkt);
+	rxm_conn->tinject_data_pkt = NULL;
+}
+static int rxm_conn_res_alloc(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn)
+{
+	dlist_init(&rxm_conn->deferred_conn_entry);
+	dlist_init(&rxm_conn->deferred_tx_queue);
+	dlist_init(&rxm_conn->sar_rx_msg_list);
+
+	if (rxm_ep->util_ep.domain->threading != FI_THREAD_SAFE) {
+		rxm_conn->inject_pkt =
+			rxm_conn_inject_pkt_alloc(rxm_ep, rxm_conn,
+						  ofi_op_msg, 0);
+		rxm_conn->inject_data_pkt =
+			rxm_conn_inject_pkt_alloc(rxm_ep, rxm_conn,
+						  ofi_op_msg, FI_REMOTE_CQ_DATA);
+		rxm_conn->tinject_pkt =
+			rxm_conn_inject_pkt_alloc(rxm_ep, rxm_conn,
+						  ofi_op_tagged, 0);
+		rxm_conn->tinject_data_pkt =
+			rxm_conn_inject_pkt_alloc(rxm_ep, rxm_conn,
+						  ofi_op_tagged, FI_REMOTE_CQ_DATA);
+
+		if (!rxm_conn->inject_pkt || !rxm_conn->inject_data_pkt ||
+		    !rxm_conn->tinject_pkt || !rxm_conn->tinject_data_pkt) {
+			rxm_conn_res_free(rxm_conn);
+			return -FI_ENOMEM;
+		}
+	}
+
+	return 0;
+}
+
+static void rxm_conn_free(struct rxm_cmap_handle *handle)
+{
+	struct rxm_conn *rxm_conn =
+		container_of(handle, struct rxm_conn, handle);
+
+	/* This handles case when saved_msg_ep wasn't closed */
+	if (rxm_conn->saved_msg_ep) {
+		if (fi_close(&rxm_conn->saved_msg_ep->fid)) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+				"Unable to close saved msg_ep\n");
+		} else {
+			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+			       "Closed saved msg_ep\n");
+		}
+		rxm_conn->saved_msg_ep = NULL;
+	}
+
+	if (!rxm_conn->msg_ep)
+		return;
+	/* Assuming fi_close also shuts down the connection gracefully if the
+	 * endpoint is in connected state */
+	if (fi_close(&rxm_conn->msg_ep->fid)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"Unable to close msg_ep\n");
+	} else {
+		FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+		       "Closed msg_ep\n");
+	}
+	rxm_conn->msg_ep = NULL;
+
+	rxm_conn_res_free(rxm_conn);
+
+	free(container_of(handle, struct rxm_conn, handle));
+}
+
+/* Caller must hold cmap->lock */
+static int rxm_cmap_alloc_handle(struct rxm_cmap *cmap, fi_addr_t fi_addr,
+				 enum rxm_cmap_state state,
+				 struct rxm_cmap_handle **handle)
+{
+	int ret;
+
+	*handle = rxm_conn_alloc(cmap);
+	if (OFI_UNLIKELY(!*handle))
+		return -FI_ENOMEM;
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+	       "Allocated handle: %p for fi_addr: %" PRIu64 "\n",
+	       *handle, fi_addr);
+	ret = rxm_cmap_check_and_realloc_handles_table(cmap, fi_addr);
+	if (OFI_UNLIKELY(ret)) {
+		rxm_conn_free(*handle);
+		return ret;
+	}
+	rxm_cmap_init_handle(*handle, cmap, state, fi_addr, NULL);
+	cmap->handles_av[fi_addr] = *handle;
+	return 0;
+}
+
+/* Caller must hold cmap->lock */
+static int rxm_cmap_alloc_handle_peer(struct rxm_cmap *cmap, void *addr,
+				       enum rxm_cmap_state state,
+				       struct rxm_cmap_handle **handle)
+{
+	struct rxm_cmap_peer *peer;
+
+	peer = calloc(1, sizeof(*peer) + cmap->av->addrlen);
+	if (!peer)
+		return -FI_ENOMEM;
+	*handle = rxm_conn_alloc(cmap);
+	if (!*handle) {
+		free(peer);
+		return -FI_ENOMEM;
+	}
+	ofi_straddr_dbg(cmap->av->prov, FI_LOG_AV, "Allocated handle for addr",
+			addr);
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "handle: %p\n", *handle);
+	rxm_cmap_init_handle(*handle, cmap, state, FI_ADDR_NOTAVAIL, peer);
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Adding handle to peer list\n");
+	peer->handle = *handle;
+	memcpy(peer->addr, addr, cmap->av->addrlen);
+	dlist_insert_tail(&peer->entry, &cmap->peer_list);
+	return 0;
+}
+
+/* Caller must hold cmap->lock */
+static struct rxm_cmap_handle *
+rxm_cmap_get_handle_peer(struct rxm_cmap *cmap, const void *addr)
+{
+	struct rxm_cmap_peer *peer;
+	struct dlist_entry *entry;
+
+	entry = dlist_find_first_match(&cmap->peer_list, rxm_cmap_match_peer,
+				       addr);
+	if (!entry)
+		return NULL;
+	ofi_straddr_dbg(cmap->av->prov, FI_LOG_AV,
+			"handle found in peer list for addr", addr);
+	peer = container_of(entry, struct rxm_cmap_peer, entry);
+	return peer->handle;
+}
+
+int rxm_cmap_move_handle_to_peer_list(struct rxm_cmap *cmap, int index)
+{
+	struct rxm_cmap_handle *handle;
+	int ret = 0;
+
+	cmap->acquire(&cmap->lock);
+	handle = cmap->handles_av[index];
+	if (!handle)
+		goto unlock;
+
+	handle->peer = calloc(1, sizeof(*handle->peer) + cmap->av->addrlen);
+	if (!handle->peer) {
+		ret = -FI_ENOMEM;
+		goto unlock;
+	}
+	handle->fi_addr = FI_ADDR_NOTAVAIL;
+	cmap->handles_av[index] = NULL;
+	handle->peer->handle = handle;
+	memcpy(handle->peer->addr, ofi_av_get_addr(cmap->av, index),
+	       cmap->av->addrlen);
+	dlist_insert_tail(&handle->peer->entry, &cmap->peer_list);
+unlock:
+	cmap->release(&cmap->lock);
+	return ret;
+}
+
+/* Caller must hold cmap->lock */
+static int rxm_cmap_move_handle(struct rxm_cmap_handle *handle,
+				fi_addr_t fi_addr)
+{
+	int ret;
+
+	dlist_remove(&handle->peer->entry);
+	free(handle->peer);
+	handle->peer = NULL;
+	handle->fi_addr = fi_addr;
+	ret = rxm_cmap_check_and_realloc_handles_table(handle->cmap, fi_addr);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+	handle->cmap->handles_av[fi_addr] = handle;
+	return 0;
+}
+
+int rxm_cmap_update(struct rxm_cmap *cmap, const void *addr, fi_addr_t fi_addr)
+{
+	struct rxm_cmap_handle *handle;
+	int ret;
+
+	cmap->acquire(&cmap->lock);
+	/* Check whether we have already allocated a handle for this `fi_addr`. */
+	/* We rely on the fact that `ofi_ip_av_insert`/`ofi_av_insert_addr` returns
+	 * the same `fi_addr` for the equal addresses */
+	if (fi_addr < cmap->num_allocated) {
+		handle = rxm_cmap_acquire_handle(cmap, fi_addr);
+		if (handle) {
+			cmap->release(&cmap->lock);
+			return 0;
+		}
+	}
+
+	handle = rxm_cmap_get_handle_peer(cmap, addr);
+	if (!handle) {
+		ret = rxm_cmap_alloc_handle(cmap, fi_addr,
+					    RXM_CMAP_IDLE, &handle);
+		cmap->release(&cmap->lock);
+		return ret;
+	}
+	ret = rxm_cmap_move_handle(handle, fi_addr);
+	cmap->release(&cmap->lock);
+	if (ret)
+		return ret;
+
+	rxm_conn_av_updated_handler(handle);
+	return 0;
+}
+
+void rxm_cmap_process_shutdown(struct rxm_cmap *cmap,
+			       struct rxm_cmap_handle *handle)
+{
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+		"Processing shutdown for handle: %p\n", handle);
+	cmap->acquire(&cmap->lock);
+	if (handle->state > RXM_CMAP_SHUTDOWN) {
+		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL,
+			"Invalid handle on shutdown event\n");
+	} else if (handle->state != RXM_CMAP_SHUTDOWN) {
+		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Got remote shutdown\n");
+		rxm_cmap_del_handle(handle);
+	} else {
+		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Got local shutdown\n");
+	}
+	cmap->release(&cmap->lock);
+}
+
+/* Caller must hold cmap->lock */
+void rxm_cmap_process_conn_notify(struct rxm_cmap *cmap,
+				  struct rxm_cmap_handle *handle)
+{
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+	       "Processing connection notification for handle: %p.\n", handle);
+	handle->state = RXM_CMAP_CONNECTED;
+	rxm_conn_connected_handler(handle);
+}
+
+/* Caller must hold cmap->lock */
+void rxm_cmap_process_connect(struct rxm_cmap *cmap,
+			      struct rxm_cmap_handle *handle,
+			      uint64_t *remote_key)
+{
+	struct rxm_conn *rxm_conn;
+
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+	       "Processing connect for handle: %p\n", handle);
+	handle->state = RXM_CMAP_CONNECTED_NOTIFY;
+	if (remote_key)
+		handle->remote_key = *remote_key;
+
+	/* Set the remote key to the inject packets */
+	if (cmap->ep->domain->threading != FI_THREAD_SAFE) {
+		rxm_conn = container_of(handle, struct rxm_conn, handle);
+
+		rxm_conn->inject_pkt->ctrl_hdr.conn_id = rxm_conn->handle.remote_key;
+		rxm_conn->inject_data_pkt->ctrl_hdr.conn_id = rxm_conn->handle.remote_key;
+		rxm_conn->tinject_pkt->ctrl_hdr.conn_id = rxm_conn->handle.remote_key;
+		rxm_conn->tinject_data_pkt->ctrl_hdr.conn_id = rxm_conn->handle.remote_key;
+	}
+}
+
+void rxm_cmap_process_reject(struct rxm_cmap *cmap,
+			     struct rxm_cmap_handle *handle,
+			     enum rxm_cmap_reject_flag cm_reject_flag)
+{
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+		"Processing reject for handle: %p\n", handle);
+	cmap->acquire(&cmap->lock);
+	switch (handle->state) {
+	case RXM_CMAP_CONNREQ_RECV:
+	case RXM_CMAP_CONNECTED:
+	case RXM_CMAP_CONNECTED_NOTIFY:
+		/* Handle is being re-used for incoming connection request */
+		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+			"Connection handle is being re-used. Close saved connection\n");
+		rxm_conn_close_saved(handle);
+		break;
+	case RXM_CMAP_CONNREQ_SENT:
+		if (cm_reject_flag == RXM_CMAP_REJECT_GENUINE) {
+			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+			       "Deleting connection handle\n");
+			rxm_cmap_del_handle(handle);
+		} else {
+			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+			       "Connection handle is being re-used. Close the connection\n");
+			rxm_conn_close(handle);
+		}
+		break;
+	case RXM_CMAP_SHUTDOWN:
+		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+			"Connection handle already being deleted\n");
+		break;
+	default:
+		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL, "Invalid cmap state: "
+			"%d when receiving connection reject\n", handle->state);
+		assert(0);
+	}
+	cmap->release(&cmap->lock);
+}
+
+int rxm_cmap_process_connreq(struct rxm_cmap *cmap, void *addr,
+			     struct rxm_cmap_handle **handle_ret,
+			     enum rxm_cmap_reject_flag *cm_reject_flag)
+{
+	struct rxm_cmap_handle *handle;
+	int ret = 0, cmp;
+	fi_addr_t fi_addr = ofi_ip_av_get_fi_addr(cmap->av, addr);
+
+	/* Reset flag to initial state */
+	*cm_reject_flag = RXM_CMAP_REJECT_GENUINE;
+
+	ofi_straddr_dbg(cmap->av->prov, FI_LOG_EP_CTRL,
+			"Processing connreq for addr", addr);
+
+	cmap->acquire(&cmap->lock);
+	if (fi_addr == FI_ADDR_NOTAVAIL)
+		handle = rxm_cmap_get_handle_peer(cmap, addr);
+	else
+		handle = rxm_cmap_acquire_handle(cmap, fi_addr);
+
+	if (!handle) {
+		if (fi_addr == FI_ADDR_NOTAVAIL)
+			ret = rxm_cmap_alloc_handle_peer(cmap, addr,
+							 RXM_CMAP_CONNREQ_RECV,
+							 &handle);
+		else
+			ret = rxm_cmap_alloc_handle(cmap, fi_addr,
+						    RXM_CMAP_CONNREQ_RECV,
+						    &handle);
+		if (ret)
+			goto unlock;
+	}
+
+	switch (handle->state) {
+	case RXM_CMAP_CONNECTED_NOTIFY:
+	case RXM_CMAP_CONNECTED:
+		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+			"Connection already present.\n");
+		ret = -FI_EALREADY;
+		break;
+	case RXM_CMAP_CONNREQ_SENT:
+		ofi_straddr_dbg(cmap->av->prov, FI_LOG_EP_CTRL, "local_name",
+				cmap->attr.name);
+		ofi_straddr_dbg(cmap->av->prov, FI_LOG_EP_CTRL, "remote_name",
+				addr);
+
+		cmp = ofi_addr_cmp(cmap->av->prov, addr, cmap->attr.name);
+
+		if (cmp < 0) {
+			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+				"Remote name lower than local name.\n");
+			*cm_reject_flag = RXM_CMAP_REJECT_SIMULT_CONN;
+			ret = -FI_EALREADY;
+			break;
+		} else if (cmp > 0) {
+			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+				"Re-using handle: %p to accept remote "
+				"connection\n", handle);
+			/* Re-use handle. If it receives FI_REJECT the handle
+			 * would not be deleted in this state */
+			rxm_conn_save(handle);
+		} else {
+			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
+				"Endpoint connects to itself\n");
+			ret = rxm_cmap_alloc_handle_peer(cmap, addr,
+							  RXM_CMAP_CONNREQ_RECV,
+							  &handle);
+			if (ret)
+				goto unlock;
+			assert(fi_addr != FI_ADDR_NOTAVAIL);
+			handle->fi_addr = fi_addr;
+		}
+		/* Fall through */
+	case RXM_CMAP_IDLE:
+		handle->state = RXM_CMAP_CONNREQ_RECV;
+		/* Fall through */
+	case RXM_CMAP_CONNREQ_RECV:
+		*handle_ret = handle;
+		break;
+	default:
+		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL,
+		       "Invalid cmap state\n");
+		assert(0);
+		ret = -FI_EOPBADSTATE;
+	}
+unlock:
+	cmap->release(&cmap->lock);
+	return ret;
+}
+
+/* Caller must hold `cmap::lock` */
+int rxm_cmap_handle_connect(struct rxm_cmap *cmap, fi_addr_t fi_addr,
+			    struct rxm_cmap_handle *handle)
+{
+	int ret;
+
+	if (handle->state == RXM_CMAP_CONNECTED_NOTIFY ||
+	    handle->state == RXM_CMAP_CONNECTED)
+		return FI_SUCCESS;
+
+	switch (handle->state) {
+	case RXM_CMAP_IDLE:
+		ret = rxm_conn_connect(cmap->ep, handle,
+				       ofi_av_get_addr(cmap->av, fi_addr),
+				       cmap->av->addrlen);
+		if (ret) {
+			rxm_cmap_del_handle(handle);
+			return ret;
+		}
+		handle->state = RXM_CMAP_CONNREQ_SENT;
+		ret = -FI_EAGAIN;
+		// TODO sleep on event fd instead of busy polling
+		break;
+	case RXM_CMAP_CONNREQ_SENT:
+	case RXM_CMAP_CONNREQ_RECV:
+	case RXM_CMAP_ACCEPT:
+	case RXM_CMAP_SHUTDOWN:
+		ret = -FI_EAGAIN;
+		break;
+	default:
+		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL,
+			"Invalid cmap handle state\n");
+		assert(0);
+		ret = -FI_EOPBADSTATE;
+	}
+	return ret;
+}
+
+/* Caller must hold cmap->lock */
+int rxm_cmap_handle_unconnected(struct rxm_ep *rxm_ep, struct rxm_cmap_handle *handle,
+				fi_addr_t dest_addr)
+{
+	int ret;
+
+	if (handle->state == RXM_CMAP_CONNECTED_NOTIFY) {
+		rxm_cmap_process_conn_notify(rxm_ep->cmap, handle);
+		return 0;
+	}
+	/* Since we handling unoonnected state and `cmap:lock`
+	 * is on hold, it shouldn't return 0 */
+	ret = rxm_cmap_handle_connect(rxm_ep->cmap,
+				      dest_addr, handle);
+	if (OFI_UNLIKELY(ret != -FI_EAGAIN))
+		return ret;
+
+	return -FI_EAGAIN;
+}
+
+int rxm_cmap_get_handle(struct rxm_cmap *cmap, fi_addr_t fi_addr,
+			struct rxm_cmap_handle **handle_ret)
+{
+	int ret;
+
+	cmap->acquire(&cmap->lock);
+	*handle_ret = rxm_cmap_acquire_handle(cmap, fi_addr);
+	if (OFI_UNLIKELY(!*handle_ret)) {
+		ret = -FI_EAGAIN;
+		goto unlock;
+	}
+
+	ret = rxm_cmap_handle_connect(cmap, fi_addr, *handle_ret);
+unlock:
+	cmap->release(&cmap->lock);
+	return ret;
+}
+
+static int rxm_cmap_cm_thread_close(struct rxm_cmap *cmap)
+{
+	int ret;
+
+	ret = rxm_conn_signal(cmap->ep, NULL, RXM_CMAP_EXIT);
+	if (ret) {
+		FI_WARN(cmap->av->prov, FI_LOG_FABRIC,
+			"Unable to signal CM thread\n");
+		return ret;
+	}
+	/* Release lock so that CM thread could process shutdown events */
+	cmap->release(&cmap->lock);
+	ret = pthread_join(cmap->cm_thread, NULL);
+	cmap->acquire(&cmap->lock);
+	if (ret) {
+		FI_WARN(cmap->av->prov, FI_LOG_FABRIC,
+			"Unable to join CM thread\n");
+		return ret;
+	}
+	return 0;
+}
+
+static int rxm_conn_cleanup(void *arg)
+{
+	return rxm_conn_process_eq_events(container_of(arg, struct rxm_ep,
+						       util_ep));
+}
+
+
+void rxm_cmap_free(struct rxm_cmap *cmap)
+{
+	struct rxm_cmap_peer *peer;
+	struct dlist_entry *entry;
+	size_t i;
+
+	cmap->acquire(&cmap->lock);
+	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Closing cmap\n");
+	for (i = 0; i < cmap->num_allocated; i++) {
+		if (cmap->handles_av[i])
+			rxm_cmap_del_handle(cmap->handles_av[i]);
+	}
+	while(!dlist_empty(&cmap->peer_list)) {
+		entry = cmap->peer_list.next;
+		peer = container_of(entry, struct rxm_cmap_peer, entry);
+		rxm_cmap_del_handle(peer->handle);
+	}
+	rxm_cmap_cm_thread_close(cmap);
+	cmap->release(&cmap->lock);
+
+	/* cleanup function would be used in manual progress mode */
+	if (cmap->ep->domain->data_progress != FI_PROGRESS_AUTO)
+		rxm_conn_cleanup(cmap->ep);
+
+	free(cmap->handles_av);
+	free(cmap->attr.name);
+	ofi_idx_reset(&cmap->handles_idx);
+	if (!cmap->attr.serial_access)
+		fastlock_destroy(&cmap->lock);
+	free(cmap);
+}
+
+static int
+rxm_cmap_update_addr(struct util_av *av, void *addr,
+		     fi_addr_t fi_addr, void *arg)
+{
+	return rxm_cmap_update((struct rxm_cmap *)arg, addr, fi_addr);
+}
+
+int rxm_cmap_bind_to_av(struct rxm_cmap *cmap, struct util_av *av)
+{
+	cmap->av = av;
+	return ofi_av_elements_iter(av, rxm_cmap_update_addr, (void *)cmap);
+}
+
+int rxm_cmap_alloc(struct rxm_ep *rxm_ep, struct rxm_cmap_attr *attr)
+{
+	struct rxm_cmap *cmap;
+	struct util_ep *ep = &rxm_ep->util_ep;
+	int ret;
+
+	cmap = calloc(1, sizeof *cmap);
+	if (!cmap)
+		return -FI_ENOMEM;
+
+	cmap->ep = ep;
+	cmap->av = ep->av;
+
+	cmap->handles_av = calloc(cmap->av->count, sizeof(*cmap->handles_av));
+	if (!cmap->handles_av) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+	cmap->num_allocated = ep->av->count;
+
+	cmap->attr = *attr;
+	cmap->attr.name = mem_dup(attr->name, ep->av->addrlen);
+	if (!cmap->attr.name) {
+		ret = -FI_ENOMEM;
+		goto err2;
+	}
+
+	memset(&cmap->handles_idx, 0, sizeof(cmap->handles_idx));
+	ofi_key_idx_init(&cmap->key_idx, RXM_CMAP_IDX_BITS);
+
+	dlist_init(&cmap->peer_list);
+
+	if (cmap->attr.serial_access) {
+		cmap->acquire = ofi_fastlock_acquire_noop;
+		cmap->release = ofi_fastlock_release_noop;
+	} else {
+		fastlock_init(&cmap->lock);
+		cmap->acquire = ofi_fastlock_acquire;
+		cmap->release = ofi_fastlock_release;
+	}
+
+	rxm_ep->cmap = cmap;
+
+	if (ep->domain->data_progress == FI_PROGRESS_AUTO) {
+		if (pthread_create(&cmap->cm_thread, 0,
+				   rxm_conn_progress, ep)) {
+			FI_WARN(ep->av->prov, FI_LOG_FABRIC,
+				"Unable to create cmap thread\n");
+			ret = -ofi_syserr();
+			goto err3;
+		}
+	} else {
+		if (pthread_create(&cmap->cm_thread, 0,
+				   rxm_conn_eq_read, ep)) {
+			FI_WARN(ep->av->prov, FI_LOG_FABRIC,
+				"Unable to create cmap thread\n");
+			ret = -ofi_syserr();
+			goto err3;
+		}
+	}
+
+	assert(ep->av);
+	ret = rxm_cmap_bind_to_av(cmap, ep->av);
+	if (ret)
+		goto err4;
+
+	return FI_SUCCESS;
+err4:
+	rxm_cmap_cm_thread_close(cmap);
+err3:
+	rxm_ep->cmap = NULL;
+	free(cmap->attr.name);
+err2:
+	free(cmap->handles_av);
+err1:
+	free(cmap);
+	return ret;
+}
+
 static int rxm_msg_ep_open(struct rxm_ep *rxm_ep, struct fi_info *msg_info,
 			   struct rxm_conn *rxm_conn, void *context)
 {
@@ -94,48 +885,237 @@ err:
 	return ret;
 }
 
-void rxm_conn_close(struct util_cmap_handle *handle)
+static void rxm_conn_close(struct rxm_cmap_handle *handle)
 {
-	struct rxm_conn *rxm_conn = container_of(handle, struct rxm_conn, handle);
+	struct rxm_conn *rxm_conn =
+		container_of(handle, struct rxm_conn, handle);
+
+	if (!rxm_conn->msg_ep)
+		return;
+
+	if (handle->cmap->attr.serial_access) {
+		if (fi_close(&rxm_conn->msg_ep->fid)) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+				"Unable to close msg_ep\n");
+		} else {
+			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+			       "Closed msg_ep\n");
+		}
+	} else {
+		rxm_conn->saved_msg_ep = rxm_conn->msg_ep;
+		FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+		       "Saved MSG EP fid for further deletion in main thread\n");
+	}
+	rxm_conn->msg_ep = NULL;
+
+	rxm_conn_res_free(rxm_conn);
+}
+
+static void rxm_conn_save(struct rxm_cmap_handle *handle)
+{
+	struct rxm_conn *rxm_conn =
+		container_of(handle, struct rxm_conn, handle);
+
 	if (!rxm_conn->msg_ep)
 		return;
 
+	rxm_conn->saved_msg_ep = rxm_conn->msg_ep;
+	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+	       "Saved MSG EP fid for further deletion\n");
+	rxm_conn->msg_ep = NULL;
+}
+
+static void rxm_conn_close_saved(struct rxm_cmap_handle *handle)
+{
+	struct rxm_conn *rxm_conn =
+		container_of(handle, struct rxm_conn, handle);
+
+	if (!rxm_conn->saved_msg_ep)
+		return;
+
+	/* If user doesn't guarantee for serializing access to cmap
+	 * objects, postpone the closing of the saved MSG EP for
+	 * further deletion in main thread  */
+	if (handle->cmap->attr.serial_access) {
+		if (fi_close(&rxm_conn->saved_msg_ep->fid)) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+				"Unable to close saved msg_ep\n");
+		} else {
+			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+			       "Closed saved msg_ep\n");
+		}
+		rxm_conn->saved_msg_ep = NULL;
+	}
+}
+
+static void rxm_conn_connected_handler(struct rxm_cmap_handle *handle)
+{
+	struct rxm_conn *rxm_conn = container_of(handle, struct rxm_conn, handle);
+
+	if (!rxm_conn->saved_msg_ep)
+		return;
 	/* Assuming fi_close also shuts down the connection gracefully if the
 	 * endpoint is in connected state */
-	if (fi_close(&rxm_conn->msg_ep->fid))
-		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to close msg_ep\n");
-	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL, "Closed msg_ep\n");
-	rxm_conn->msg_ep = NULL;
+	if (fi_close(&rxm_conn->saved_msg_ep->fid))
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to close saved msg_ep\n");
+	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL, "Closed saved msg_ep\n");
+	rxm_conn->saved_msg_ep = NULL;
 }
 
-static void rxm_conn_free(struct util_cmap_handle *handle)
+static int rxm_conn_reprocess_directed_recvs(struct rxm_recv_queue *recv_queue)
 {
-	rxm_conn_close(handle);
-	free(container_of(handle, struct rxm_conn, handle));
+	struct rxm_rx_buf *rx_buf;
+	struct dlist_entry *entry, *tmp_entry;
+	struct rxm_recv_match_attr match_attr;
+	struct fi_cq_err_entry err_entry = {0};
+	int ret, count = 0;
+
+	ofi_ep_lock_acquire(&recv_queue->rxm_ep->util_ep);
+	dlist_foreach_container_safe(&recv_queue->unexp_msg_list,
+				     struct rxm_rx_buf, rx_buf,
+				     unexp_msg.entry, tmp_entry) {
+		if (rx_buf->unexp_msg.addr == rx_buf->conn->handle.fi_addr)
+			continue;
+
+		assert(rx_buf->unexp_msg.addr == FI_ADDR_NOTAVAIL);
+
+		rx_buf->unexp_msg.addr = rx_buf->conn->handle.fi_addr;
+		match_attr.addr = rx_buf->unexp_msg.addr;
+		match_attr.tag = rx_buf->unexp_msg.tag;
+
+		entry = dlist_remove_first_match(&recv_queue->recv_list,
+						 recv_queue->match_recv,
+						 &match_attr);
+		if (!entry)
+			continue;
+
+		dlist_remove(&rx_buf->unexp_msg.entry);
+		rx_buf->recv_entry = container_of(entry, struct rxm_recv_entry,
+						  entry);
+
+		ret = rxm_cq_handle_rx_buf(rx_buf);
+		if (ret) {
+			err_entry.op_context = rx_buf;
+			err_entry.flags = rx_buf->recv_entry->comp_flags;
+			err_entry.len = rx_buf->pkt.hdr.size;
+			err_entry.data = rx_buf->pkt.hdr.data;
+			err_entry.tag = rx_buf->pkt.hdr.tag;
+			err_entry.err = ret;
+			err_entry.prov_errno = ret;
+			ofi_cq_write_error(recv_queue->rxm_ep->util_ep.rx_cq,
+					   &err_entry);
+			if (rx_buf->ep->util_ep.flags & OFI_CNTR_ENABLED)
+				rxm_cntr_incerr(rx_buf->ep->util_ep.rx_cntr);
+
+			rxm_rx_buf_release(recv_queue->rxm_ep, rx_buf);
+
+			if (!(rx_buf->recv_entry->flags & FI_MULTI_RECV))
+				rxm_recv_entry_release(recv_queue,
+						       rx_buf->recv_entry);
+		}
+		count++;
+	}
+	ofi_ep_lock_release(&recv_queue->rxm_ep->util_ep);
+
+	return count;
 }
 
-static struct util_cmap_handle *rxm_conn_alloc(void)
+static void
+rxm_conn_av_updated_handler(struct rxm_cmap_handle *handle)
+{
+	struct rxm_ep *rxm_ep = container_of(handle->cmap->ep, struct rxm_ep, util_ep);
+	int count = 0;
+
+	if (rxm_ep->rxm_info->caps & FI_DIRECTED_RECV) {
+		count += rxm_conn_reprocess_directed_recvs(&rxm_ep->recv_queue);
+		count += rxm_conn_reprocess_directed_recvs(&rxm_ep->trecv_queue);
+
+		FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+		       "Reprocessed directed recvs - %d\n", count);
+	}
+}
+
+static struct rxm_cmap_handle *rxm_conn_alloc(struct rxm_cmap *cmap)
 {
 	struct rxm_conn *rxm_conn = calloc(1, sizeof(*rxm_conn));
+
 	if (OFI_UNLIKELY(!rxm_conn))
 		return NULL;
 
-	dlist_init(&rxm_conn->postponed_tx_list);
 	return &rxm_conn->handle;
 }
 
+static inline int
+rxm_conn_verify_cm_data(struct rxm_cm_data *remote_cm_data,
+			struct rxm_cm_data *local_cm_data)
+{
+	if (remote_cm_data->proto.endianness != local_cm_data->proto.endianness) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"endianness of two peers (%"PRIu8" vs %"PRIu8")"
+			"are mismatched\n",
+			remote_cm_data->proto.endianness,
+			local_cm_data->proto.endianness);
+		goto err;
+	}
+	if (remote_cm_data->proto.ctrl_version != local_cm_data->proto.ctrl_version) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"ctrl_version of two peers (%"PRIu8" vs %"PRIu8")"
+			"are mismatched\n",
+			remote_cm_data->proto.ctrl_version,
+			local_cm_data->proto.ctrl_version);
+		goto err;
+	}
+	if (remote_cm_data->proto.op_version != local_cm_data->proto.op_version) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"op_version of two peers (%"PRIu8" vs %"PRIu8")"
+			"are mismatched\n",
+			remote_cm_data->proto.op_version,
+			local_cm_data->proto.op_version);
+		goto err;
+	}
+	if (remote_cm_data->proto.eager_size != local_cm_data->proto.eager_size) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"inject_size of two peers (%"PRIu64" vs %"PRIu64")"
+			"are mismatched\n",
+			remote_cm_data->proto.eager_size,
+			local_cm_data->proto.eager_size);
+		goto err;
+	}
+	return FI_SUCCESS;
+err:
+	return -FI_EINVAL;
+}
+
 static int
 rxm_msg_process_connreq(struct rxm_ep *rxm_ep, struct fi_info *msg_info,
 			void *data)
 {
 	struct rxm_conn *rxm_conn;
 	struct rxm_cm_data *remote_cm_data = data;
-	struct rxm_cm_data cm_data;
-	struct util_cmap_handle *handle;
+	struct rxm_cm_data cm_data = {
+		.proto = {
+			.ctrl_version = RXM_CTRL_VERSION,
+			.op_version = RXM_OP_VERSION,
+			.endianness = ofi_detect_endianness(),
+			.eager_size = rxm_ep->rxm_info->tx_attr->inject_size,
+		},
+	};
+	struct rxm_cmap_handle *handle;
 	int ret;
+	enum rxm_cmap_reject_flag cm_reject_flag = RXM_CMAP_REJECT_GENUINE;
 
-	ret = ofi_cmap_process_connreq(rxm_ep->util_ep.cmap,
-				       &remote_cm_data->name, &handle);
+	remote_cm_data->proto.eager_size = ntohll(remote_cm_data->proto.eager_size);
+
+	if (rxm_conn_verify_cm_data(remote_cm_data, &cm_data)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"CM data mismatch was detected\n");
+		ret = -FI_EINVAL;
+		goto err1;
+	}
+
+	ret = rxm_cmap_process_connreq(rxm_ep->cmap,
+				       &remote_cm_data->name,
+				       &handle, &cm_reject_flag);
 	if (ret)
 		goto err1;
 
@@ -148,143 +1128,262 @@ rxm_msg_process_connreq(struct rxm_ep *rxm_ep, struct fi_info *msg_info,
 		goto err2;
 
 	cm_data.conn_id = rxm_conn->handle.key;
+	cm_data.proto.eager_size = htonll(cm_data.proto.eager_size);
 
 	ret = fi_accept(rxm_conn->msg_ep, &cm_data, sizeof(cm_data));
 	if (ret) {
 		FI_WARN(&rxm_prov, FI_LOG_FABRIC,
-				"Unable to accept incoming connection\n");
+			"Unable to accept incoming connection\n");
 		goto err2;
 	}
+
+	ret = rxm_conn_res_alloc(rxm_ep, rxm_conn);
+	if (ret) {
+		FI_WARN(&rxm_prov, FI_LOG_FABRIC,
+			"Unable to allocate TX/RX resources for connection\n");
+		goto err2;
+	}
+
 	return ret;
 err2:
-	ofi_cmap_del_handle(&rxm_conn->handle);
+	rxm_cmap_del_handle_ts(&rxm_conn->handle);
 err1:
 	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-		"Rejecting incoming connection request\n");
-	if (fi_reject(rxm_ep->msg_pep, msg_info->handle, NULL, 0))
+	       "Rejecting incoming connection request (reject flag - %d)\n",
+	       cm_reject_flag);
+	if (fi_reject(rxm_ep->msg_pep, msg_info->handle,
+		      &cm_reject_flag, sizeof(cm_reject_flag)))
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
-				"Unable to reject incoming connection\n");
+			"Unable to reject incoming connection\n");
 	return ret;
 }
 
 static int rxm_conn_handle_notify(struct fi_eq_entry *eq_entry)
 {
-	switch((enum ofi_cmap_signal)eq_entry->data) {
-	case OFI_CMAP_FREE:
-		FI_DBG(&rxm_prov, FI_LOG_FABRIC, "Freeing handle\n");
-		rxm_conn_free((struct util_cmap_handle *)eq_entry->context);
+	if ((enum rxm_cmap_signal)eq_entry->data == RXM_CMAP_FREE) {
+		rxm_conn_free((struct rxm_cmap_handle *)eq_entry->context);
 		return 0;
-	case OFI_CMAP_EXIT:
-		FI_TRACE(&rxm_prov, FI_LOG_FABRIC, "Closing event handler\n");
-		return 1;
-	default:
+	} else {
 		FI_WARN(&rxm_prov, FI_LOG_FABRIC, "Unknown cmap signal\n");
-		return 1;
+		assert(0);
+		return -FI_EOTHER;
+	}
+}
+
+static void rxm_conn_wake_up_wait_obj(struct rxm_ep *rxm_ep)
+{
+	if (rxm_ep->util_ep.tx_cq->wait)
+		util_cq_signal(rxm_ep->util_ep.tx_cq);
+	if (rxm_ep->util_ep.tx_cntr && rxm_ep->util_ep.tx_cntr->wait)
+		util_cntr_signal(rxm_ep->util_ep.tx_cntr);
+}
+
+static int
+rxm_conn_handle_event(struct rxm_ep *rxm_ep, struct rxm_msg_eq_entry *entry)
+{
+	struct rxm_cm_data *cm_data;
+
+	if (entry->rd == -FI_ECONNREFUSED) {
+		enum rxm_cmap_reject_flag cm_reject_flag;
+
+		if (OFI_LIKELY(entry->err_entry.err_data_size >=
+				sizeof(enum rxm_cmap_reject_flag))) {
+			assert(entry->err_entry.err_data);
+			cm_reject_flag = *((enum rxm_cmap_reject_flag *)
+						entry->err_entry.err_data);
+		} else {
+			FI_WARN(&rxm_prov, FI_LOG_FABRIC,
+				"Error -FI_ECONNREFUSED was provided without error data\n");
+			cm_reject_flag = RXM_CMAP_REJECT_GENUINE;
+		}
+
+		FI_DBG(&rxm_prov, FI_LOG_FABRIC,
+		       "Received reject (reject flag - %d)\n",
+		       cm_reject_flag);
+		assert((cm_reject_flag == RXM_CMAP_REJECT_GENUINE) ||
+		       (cm_reject_flag == RXM_CMAP_REJECT_SIMULT_CONN));
+		rxm_cmap_process_reject(rxm_ep->cmap, entry->context,
+					cm_reject_flag);
+		return 0;
+	}
+
+	switch(entry->event) {
+	case FI_NOTIFY:
+		if (rxm_conn_handle_notify((struct fi_eq_entry *)&entry->cm_entry))
+			goto err;
+		break;
+	case FI_CONNREQ:
+		FI_DBG(&rxm_prov, FI_LOG_FABRIC, "Got new connection\n");
+		if ((size_t)entry->rd != RXM_CM_ENTRY_SZ) {
+			FI_WARN(&rxm_prov, FI_LOG_FABRIC,
+				"Received size (%zd) not matching "
+				"expected (%zu)\n", entry->rd, RXM_CM_ENTRY_SZ);
+			goto err;
+		}
+		rxm_msg_process_connreq(rxm_ep, entry->cm_entry.info, entry->cm_entry.data);
+		fi_freeinfo(entry->cm_entry.info);
+		break;
+	case FI_CONNECTED:
+		FI_DBG(&rxm_prov, FI_LOG_FABRIC,
+		       "Connection successful\n");
+		rxm_ep->cmap->acquire(&rxm_ep->cmap->lock);
+		cm_data = (void *)entry->cm_entry.data;
+		rxm_cmap_process_connect(rxm_ep->cmap,
+					 entry->cm_entry.fid->context,
+					 ((entry->rd - sizeof(entry->cm_entry)) ?
+					  &cm_data->conn_id : NULL));
+		rxm_conn_wake_up_wait_obj(rxm_ep);
+		rxm_ep->cmap->release(&rxm_ep->cmap->lock);
+		break;
+	case FI_SHUTDOWN:
+		FI_DBG(&rxm_prov, FI_LOG_FABRIC,
+		       "Received connection shutdown\n");
+		rxm_cmap_process_shutdown(rxm_ep->cmap,
+					  entry->cm_entry.fid->context);
+		break;
+	default:
+		FI_WARN(&rxm_prov, FI_LOG_FABRIC,
+			"Unknown event: %u\n", entry->event);
+		goto err;
+	}
+	return 0;
+err:
+	return -FI_EOTHER;
+}
+
+int rxm_conn_process_eq_events(struct rxm_ep *rxm_ep)
+{
+	struct rxm_msg_eq_entry *entry;
+	struct slist_entry *slist_entry;
+	int ret;
+
+	fastlock_acquire(&rxm_ep->msg_eq_entry_list_lock);
+	while (!slistfd_empty(&rxm_ep->msg_eq_entry_list)) {
+		slist_entry = slistfd_remove_head(&rxm_ep->msg_eq_entry_list);
+		entry = container_of(slist_entry, struct rxm_msg_eq_entry,
+				     slist_entry);
+
+		fastlock_release(&rxm_ep->msg_eq_entry_list_lock);
+
+		ret = rxm_conn_handle_event(rxm_ep, entry);
+		free(entry);
+		fastlock_acquire(&rxm_ep->msg_eq_entry_list_lock);
+		if (ret)
+			break;
 	}
+	fastlock_release(&rxm_ep->msg_eq_entry_list_lock);
+	return ret;
 }
 
-static void rxm_conn_handle_eq_err(struct rxm_ep *rxm_ep, ssize_t rd)
+static ssize_t rxm_eq_sread(struct rxm_ep *rxm_ep, size_t len,
+			    struct rxm_msg_eq_entry *entry)
 {
-	struct fi_eq_err_entry err_entry = {0};
+	ssize_t rd;
+	int once = 1;
+
+	do {
+		rd = fi_eq_sread(rxm_ep->msg_eq, &entry->event, &entry->cm_entry,
+				 len, -1, 0);
+		if (rd >= 0)
+			return rd;
+		if (rd == -FI_EINTR && once) {
+			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL, "Ignoring EINTR\n");
+			once = 0;
+		}
+	} while (rd == -FI_EINTR);
 
 	if (rd != -FI_EAVAIL) {
-		FI_WARN(&rxm_prov, FI_LOG_FABRIC, "Unable to fi_eq_sread\n");
-		return;
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"Unable to fi_eq_sread: %zu\n", rd);
+		return rd;
 	}
-	OFI_EQ_READERR(&rxm_prov, FI_LOG_FABRIC, rxm_ep->msg_eq, rd, err_entry);
-	if (err_entry.err == ECONNREFUSED) {
-		FI_DBG(&rxm_prov, FI_LOG_FABRIC, "Connection refused\n");
-		ofi_cmap_process_reject(rxm_ep->util_ep.cmap,
-					err_entry.fid->context);
+
+	RXM_EQ_READERR(&rxm_prov, FI_LOG_EP_CTRL, rxm_ep->msg_eq, rd, entry->err_entry);
+
+	if (entry->err_entry.err == ECONNREFUSED) {
+		FI_DBG(&rxm_prov, FI_LOG_EP_CTRL, "Connection refused\n");
+		entry->context = entry->err_entry.fid->context;
+		return -FI_ECONNREFUSED;
+	} else {
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unknown error: %d\n",
+			entry->err_entry.err);
+		return rd;
 	}
 }
 
-static void rxm_conn_handle_postponed_op(struct rxm_ep *rxm_ep,
-					 struct util_cmap_handle *handle)
+static void *rxm_conn_eq_read(void *arg)
 {
-	struct rxm_tx_entry *tx_entry;
-	struct rxm_conn *rxm_conn = container_of(handle, struct rxm_conn, handle);
+	struct rxm_ep *rxm_ep = arg;
+	struct rxm_msg_eq_entry *entry;
 
-	while (!dlist_empty(&rxm_conn->postponed_tx_list)) {
-		dlist_pop_front(&rxm_conn->postponed_tx_list, struct rxm_tx_entry,
-				tx_entry, postponed_entry);
-		if (!(tx_entry->comp_flags & FI_RMA))
-			rxm_ep_handle_postponed_tx_op(rxm_ep, rxm_conn, tx_entry);
-		else
-			rxm_ep_handle_postponed_rma_op(rxm_ep, rxm_conn, tx_entry);
+	while (1) {
+		entry = calloc(1, RXM_MSG_EQ_ENTRY_SZ);
+		if (!entry) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+				"Unable to allocate memory!\n");
+			return NULL;
+		}
+
+		entry->rd = rxm_eq_sread(rxm_ep, RXM_CM_ENTRY_SZ, entry);
+		if (entry->rd < 0 && entry->rd != -FI_ECONNREFUSED)
+			goto exit;
+
+		if (entry->event == FI_NOTIFY &&
+		    (enum rxm_cmap_signal)((struct fi_eq_entry *)
+					   &entry->cm_entry)->data == RXM_CMAP_EXIT) {
+			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL, "Closing CM thread\n");
+			goto exit;
+		}
+
+		FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+		       "Enqueing event: %d\n", entry->event);
+		fastlock_acquire(&rxm_ep->msg_eq_entry_list_lock);
+		slistfd_insert_tail(&entry->slist_entry,
+				    &rxm_ep->msg_eq_entry_list);
+		fastlock_release(&rxm_ep->msg_eq_entry_list_lock);
 	}
+exit:
+	free(entry);
+	return NULL;
 }
 
-static void *rxm_conn_event_handler(void *arg)
+static void *rxm_conn_progress(void *arg)
 {
-	struct fi_eq_cm_entry *entry;
-	size_t datalen = sizeof(struct rxm_cm_data);
-	size_t len = sizeof(*entry) + datalen;
 	struct rxm_ep *rxm_ep = container_of(arg, struct rxm_ep, util_ep);
-	struct rxm_cm_data *cm_data;
-	uint32_t event;
-	ssize_t rd;
+	struct rxm_msg_eq_entry *entry;
+	int ret;
 
-	entry = calloc(1, len);
+	entry = calloc(1, RXM_MSG_EQ_ENTRY_SZ);
 	if (!entry) {
-		FI_WARN(&rxm_prov, FI_LOG_FABRIC, "Unable to allocate memory!\n");
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"Unable to allocate memory!\n");
 		return NULL;
 	}
+	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL, "Starting conn event handler\n");
 
-	FI_DBG(&rxm_prov, FI_LOG_FABRIC, "Starting conn event handler\n");
 	while (1) {
-		rd = fi_eq_sread(rxm_ep->msg_eq, &event, entry, len, -1, 0);
-		/* We would receive more bytes than sizeof *entry during CONNREQ */
-		if (rd < 0) {
-			rxm_conn_handle_eq_err(rxm_ep, rd);
-			continue;
-		}
+		entry->rd = rxm_eq_sread(rxm_ep, RXM_CM_ENTRY_SZ, entry);
+		if (entry->rd < 0 && entry->rd != -FI_ECONNREFUSED)
+			goto exit;
 
-		switch(event) {
-		case FI_NOTIFY:
-			if (rxm_conn_handle_notify((struct fi_eq_entry *)entry))
-				goto exit;
-			break;
-		case FI_CONNREQ:
-			FI_DBG(&rxm_prov, FI_LOG_FABRIC, "Got new connection\n");
-			if ((size_t)rd != len) {
-				FI_WARN(&rxm_prov, FI_LOG_FABRIC,
-					"Received size (%zd) not matching "
-					"expected (%zu)\n", rd, len);
-				goto exit;
-			}
-			rxm_msg_process_connreq(rxm_ep, entry->info, entry->data);
-			break;
-		case FI_CONNECTED:
-			FI_DBG(&rxm_prov, FI_LOG_FABRIC,
-			       "Connection successful\n");
-			fastlock_acquire(&rxm_ep->util_ep.cmap->lock);
-			cm_data = (void *)entry->data;
-			ofi_cmap_process_connect(rxm_ep->util_ep.cmap,
-						 entry->fid->context,
-						 ((rd - sizeof(*entry)) ?
-						  &cm_data->conn_id : NULL));
-			rxm_conn_handle_postponed_op(rxm_ep, entry->fid->context);
-			fastlock_release(&rxm_ep->util_ep.cmap->lock);
-			break;
-		case FI_SHUTDOWN:
-			FI_DBG(&rxm_prov, FI_LOG_FABRIC,
-			       "Received connection shutdown\n");
-			ofi_cmap_process_shutdown(rxm_ep->util_ep.cmap,
-						  entry->fid->context);
-			break;
-		default:
-			FI_WARN(&rxm_prov, FI_LOG_FABRIC,
-				"Unknown event: %u\n", event);
+		if (entry->event == FI_NOTIFY &&
+		    (enum rxm_cmap_signal)((struct fi_eq_entry *)
+					   &entry->cm_entry)->data == RXM_CMAP_EXIT) {
+			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
+			       "Closing CM thread\n");
 			goto exit;
 		}
+		ret = rxm_conn_handle_event(rxm_ep, entry);
+		if (ret)
+			goto exit;
+		memset(entry, 0, RXM_MSG_EQ_ENTRY_SZ);
 	}
 exit:
 	free(entry);
 	return NULL;
 }
 
-static int rxm_prepare_cm_data(struct fid_pep *pep, struct util_cmap_handle *handle,
+static int rxm_prepare_cm_data(struct fid_pep *pep, struct rxm_cmap_handle *handle,
 		struct rxm_cm_data *cm_data)
 {
 	size_t cm_data_size = 0;
@@ -315,18 +1414,23 @@ static int rxm_prepare_cm_data(struct fid_pep *pep, struct util_cmap_handle *han
 }
 
 static int
-rxm_conn_connect(struct util_ep *util_ep, struct util_cmap_handle *handle,
+rxm_conn_connect(struct util_ep *util_ep, struct rxm_cmap_handle *handle,
 		 const void *addr, size_t addrlen)
 {
-	struct rxm_ep *rxm_ep;
-	struct rxm_conn *rxm_conn;
 	struct fi_info *msg_info;
-	struct rxm_cm_data cm_data;
 	int ret;
-
-	rxm_ep = container_of(util_ep, struct rxm_ep, util_ep);
-
-	rxm_conn = container_of(handle, struct rxm_conn, handle);
+	struct rxm_ep *rxm_ep =
+		container_of(util_ep, struct rxm_ep, util_ep);
+	struct rxm_conn *rxm_conn =
+		container_of(handle, struct rxm_conn, handle);
+	struct rxm_cm_data cm_data = {
+		.proto = {
+			.ctrl_version = RXM_CTRL_VERSION,
+			.op_version = RXM_OP_VERSION,
+			.endianness = ofi_detect_endianness(),
+			.eager_size = rxm_ep->rxm_info->tx_attr->inject_size,
+		},
+	};
 
 	free(rxm_ep->msg_info->dest_addr);
 	rxm_ep->msg_info->dest_addrlen = addrlen;
@@ -351,11 +1455,18 @@ rxm_conn_connect(struct util_ep *util_ep, struct util_cmap_handle *handle,
 	if (ret)
 		goto err2;
 
+	cm_data.proto.eager_size = htonll(cm_data.proto.eager_size);
+
 	ret = fi_connect(rxm_conn->msg_ep, msg_info->dest_addr, &cm_data, sizeof(cm_data));
 	if (ret) {
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to connect msg_ep\n");
 		goto err2;
 	}
+
+	ret = rxm_conn_res_alloc(rxm_ep, rxm_conn);
+	if (ret)
+		goto err2;
+
 	fi_freeinfo(msg_info);
 	return 0;
 err2:
@@ -367,7 +1478,7 @@ err1:
 }
 
 static int rxm_conn_signal(struct util_ep *util_ep, void *context,
-			   enum ofi_cmap_signal signal)
+			   enum rxm_cmap_signal signal)
 {
 	struct rxm_ep *rxm_ep = container_of(util_ep, struct rxm_ep, util_ep);
 	struct fi_eq_entry entry = {0};
@@ -384,20 +1495,16 @@ static int rxm_conn_signal(struct util_ep *util_ep, void *context,
 	return 0;
 }
 
-struct util_cmap *rxm_conn_cmap_alloc(struct rxm_ep *rxm_ep)
+int rxm_conn_cmap_alloc(struct rxm_ep *rxm_ep)
 {
-	struct util_cmap_attr attr;
-	struct util_cmap *cmap = NULL;
-	void *name;
-	size_t len;
+	struct rxm_cmap_attr attr;
 	int ret;
-
-	len = rxm_ep->msg_info->src_addrlen;
-	name = calloc(1, len);
+	size_t len = rxm_ep->util_ep.av->addrlen;
+	void *name = calloc(1, len);
 	if (!name) {
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
 			"Unable to allocate memory for EP name\n");
-		return NULL;
+		return -FI_ENOMEM;
 	}
 
 	/* Passive endpoint should already have fi_setname or fi_listen
@@ -411,18 +1518,18 @@ struct util_cmap *rxm_conn_cmap_alloc(struct rxm_ep *rxm_ep)
 	ofi_straddr_dbg(&rxm_prov, FI_LOG_EP_CTRL, "local_name", name);
 
 	attr.name		= name;
-	attr.alloc 		= rxm_conn_alloc;
-	attr.close 		= rxm_conn_close;
-	attr.free 		= rxm_conn_free;
-	attr.connect 		= rxm_conn_connect;
-	attr.event_handler	= rxm_conn_event_handler;
-	attr.signal		= rxm_conn_signal;
-
-	cmap = ofi_cmap_alloc(&rxm_ep->util_ep, &attr);
-	if (!cmap)
+
+	if (rxm_ep->util_ep.domain->threading == FI_THREAD_DOMAIN &&
+	    rxm_ep->util_ep.domain->data_progress == FI_PROGRESS_MANUAL)
+		attr.serial_access = 1;
+	else
+		attr.serial_access = 0;
+
+	ret = rxm_cmap_alloc(rxm_ep, &attr);
+	if (ret)
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
 			"Unable to allocate CMAP\n");
 fn:
 	free(name);
-	return cmap;
+	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_cq.c
index 1daa279b3..15f945be9 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_cq.c
@@ -1,5 +1,6 @@
 /*
  * Copyright (c) 2013-2016 Intel Corporation. All rights reserved.
+ * Copyright (c) 2018 Cray Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -35,18 +36,11 @@
 #include <inttypes.h>
 
 #include "ofi.h"
+#include "ofi_iov.h"
+#include "ofi_atomic.h"
 
 #include "rxm.h"
 
-static struct rxm_conn *rxm_key2conn(struct rxm_ep *rxm_ep, uint64_t key)
-{
-	struct util_cmap_handle *handle;
-	handle = ofi_cmap_key2handle(rxm_ep->util_ep.cmap, key);
-	if (!handle)
-		return NULL;
-	return container_of(handle, struct rxm_conn, handle);
-}
-
 static const char *rxm_cq_strerror(struct fid_cq *cq_fid, int prov_errno,
 		const void *err_data, char *buf, size_t len)
 {
@@ -61,39 +55,6 @@ static const char *rxm_cq_strerror(struct fid_cq *cq_fid, int prov_errno,
 	return fi_cq_strerror(rxm_ep->msg_cq, prov_errno, err_data, buf, len);
 }
 
-#if ENABLE_DEBUG
-static void rxm_cq_log_comp(uint64_t flags)
-{
-	flags &= (FI_SEND | FI_WRITE | FI_READ | FI_REMOTE_READ |
-		  FI_REMOTE_WRITE);
-
-	switch (flags) {
-	case FI_SEND:
-		FI_DBG(&rxm_prov, FI_LOG_CQ, "Reporting send completion\n");
-		break;
-	case FI_WRITE:
-		FI_DBG(&rxm_prov, FI_LOG_CQ, "Reporting write completion\n");
-		break;
-	case FI_READ:
-		FI_DBG(&rxm_prov, FI_LOG_CQ, "Reporting read completion\n");
-		break;
-	case FI_REMOTE_READ:
-		FI_DBG(&rxm_prov, FI_LOG_CQ, "Reporting remote read completion\n");
-		break;
-	case FI_REMOTE_WRITE:
-		FI_DBG(&rxm_prov, FI_LOG_CQ, "Reporting remote write completion\n");
-		break;
-	default:
-		FI_WARN(&rxm_prov, FI_LOG_CQ, "Unknown completion\n");
-	}
-}
-#else
-static void rxm_cq_log_comp(uint64_t flags)
-{
-	// NOP
-}
-#endif
-
 /* Get a match_iov derived from iov whose size matches given length */
 static int rxm_match_iov(const struct iovec *iov, void **desc,
 			 uint8_t count, uint64_t offset, size_t match_len,
@@ -131,438 +92,632 @@ static int rxm_match_iov(const struct iovec *iov, void **desc,
 	return FI_SUCCESS;
 }
 
-static int rxm_match_rma_iov(struct rxm_recv_entry *recv_entry,
-			     struct rxm_rma_iov *rma_iov,
-			     struct rxm_iov *match_iov)
+static inline uint64_t
+rxm_cq_get_rx_comp_and_op_flags(struct rxm_rx_buf *rx_buf)
 {
-	uint64_t offset = 0;
-	uint8_t i, j;
-	uint8_t count;
-	int ret;
+	return (rx_buf->pkt.hdr.flags | ofi_rx_flags[rx_buf->pkt.hdr.op]);
+}
 
-	assert(rma_iov->count <= RXM_IOV_LIMIT);
+static inline uint64_t
+rxm_cq_get_rx_comp_flags(struct rxm_rx_buf *rx_buf)
+{
+	return (rx_buf->pkt.hdr.flags);
+}
 
-	for (i = 0, j = 0; i < rma_iov->count; ) {
-		ret = rxm_match_iov(&recv_entry->rxm_iov.iov[j],
-				    &recv_entry->rxm_iov.desc[j],
-				    recv_entry->rxm_iov.count - j, offset,
-				    rma_iov->iov[i].len, &match_iov[i]);
-		if (ret)
-			return ret;
+static int rxm_finish_buf_recv(struct rxm_rx_buf *rx_buf)
+{
+	uint64_t flags = rxm_cq_get_rx_comp_and_op_flags(rx_buf);
+	char *data;
 
-		count = match_iov[i].count;
+	if (rx_buf->pkt.ctrl_hdr.type != ofi_ctrl_data)
+		flags |= FI_MORE;
 
-		j += count - 1;
-		offset = (((count - 1) == 0) ? offset : 0) +
-			match_iov[i].iov[count - 1].iov_len;
-		i++;
+	if (rx_buf->pkt.ctrl_hdr.type == ofi_ctrl_large_data)
+		data = rxm_pkt_rndv_data(&rx_buf->pkt);
+	else
+		data = rx_buf->pkt.data;
 
-		if (j >= recv_entry->rxm_iov.count)
-			break;
-	}
-
-	if (i < rma_iov->count) {
-		FI_WARN(&rxm_prov, FI_LOG_CQ, "posted recv_entry size < "
-			"rndv rma read size!\n");
-		return -FI_ETOOSMALL;
-	}
+	FI_DBG(&rxm_prov, FI_LOG_CQ, "writing buffered recv completion: "
+	       "length: %" PRIu64 "\n", rx_buf->pkt.hdr.size);
+	rx_buf->recv_context.ep = &rx_buf->ep->util_ep.ep_fid;
 
-	return FI_SUCCESS;
+	return rxm_cq_write_recv_comp(rx_buf, &rx_buf->recv_context, flags,
+				      rx_buf->pkt.hdr.size, data);
 }
 
-static inline void rxm_enqueue_repost_ready_list(struct rxm_rx_buf *rx_buf)
+static int rxm_cq_write_error_trunc(struct rxm_rx_buf *rx_buf, size_t done_len)
 {
-	if (!rx_buf->repost) {
-		dlist_remove(&rx_buf->entry);
-		rxm_rx_buf_release(rx_buf->ep, rx_buf);
-	} else {
-		fastlock_acquire(&rx_buf->ep->util_ep.lock);
-		dlist_insert_tail(&rx_buf->repost_entry,
-				  &rx_buf->ep->repost_ready_list);
-		fastlock_release(&rx_buf->ep->util_ep.lock);
+	int ret;
+
+	if (rx_buf->ep->util_ep.flags & OFI_CNTR_ENABLED)
+		rxm_cntr_incerr(rx_buf->ep->util_ep.rx_cntr);
+
+	FI_WARN(&rxm_prov, FI_LOG_CQ, "Message truncated: "
+		"recv buf length: %zu message length: %" PRIu64 "\n",
+		done_len, rx_buf->pkt.hdr.size);
+	ret = ofi_cq_write_error_trunc(rx_buf->ep->util_ep.rx_cq,
+				       rx_buf->recv_entry->context,
+				       rx_buf->recv_entry->comp_flags |
+				       rxm_cq_get_rx_comp_flags(rx_buf),
+				       rx_buf->pkt.hdr.size,
+				       rx_buf->recv_entry->rxm_iov.iov[0].iov_base,
+				       rx_buf->pkt.hdr.data, rx_buf->pkt.hdr.tag,
+				       rx_buf->pkt.hdr.size - done_len);
+	if (OFI_UNLIKELY(ret)) {
+		FI_WARN(&rxm_prov, FI_LOG_CQ,
+			"Unable to write recv error CQ\n");
+		return ret;
 	}
+	return 0;
 }
 
 static int rxm_finish_recv(struct rxm_rx_buf *rx_buf, size_t done_len)
 {
 	int ret;
+	struct rxm_recv_entry *recv_entry = rx_buf->recv_entry;
 
 	if (OFI_UNLIKELY(done_len < rx_buf->pkt.hdr.size)) {
-		FI_WARN(&rxm_prov, FI_LOG_CQ, "Message truncated\n");
-		ret = ofi_cq_write_error_trunc(rx_buf->ep->util_ep.rx_cq,
-					       rx_buf->recv_entry->context,
-					       rx_buf->recv_entry->comp_flags |
-					       ((rx_buf->pkt.hdr.flags & OFI_REMOTE_CQ_DATA) ?
-					        FI_REMOTE_CQ_DATA : 0),
-					       rx_buf->pkt.hdr.size,
-					       rx_buf->recv_entry->rxm_iov.iov[0].iov_base,
-					       rx_buf->pkt.hdr.data, rx_buf->pkt.hdr.tag,
-					       rx_buf->pkt.hdr.size - done_len);
-		if (OFI_UNLIKELY(ret)) {
-			FI_WARN(&rxm_prov, FI_LOG_CQ,
-				"Unable to write recv error CQ\n");
+		ret = rxm_cq_write_error_trunc(rx_buf, done_len);
+		if (ret)
 			return ret;
-		}
-		if (rx_buf->ep->util_ep.flags & OFI_CNTR_ENABLED)
-			rxm_cntr_incerr(rx_buf->ep->util_ep.rx_cntr);
 	} else {
 		if (rx_buf->recv_entry->flags & FI_COMPLETION) {
-			FI_DBG(&rxm_prov, FI_LOG_CQ, "writing recv completion\n");
-			ret = ofi_cq_write(rx_buf->ep->util_ep.rx_cq,
-					   rx_buf->recv_entry->context,
-					   rx_buf->recv_entry->comp_flags |
-					   ((rx_buf->pkt.hdr.flags & OFI_REMOTE_CQ_DATA) ?
-					    FI_REMOTE_CQ_DATA : 0),
-					   rx_buf->pkt.hdr.size,
-					   rx_buf->recv_entry->rxm_iov.iov[0].iov_base,
-					   rx_buf->pkt.hdr.data, rx_buf->pkt.hdr.tag);
-			if (OFI_UNLIKELY(ret)) {
-				FI_WARN(&rxm_prov, FI_LOG_CQ,
-					"Unable to write recv completion\n");
+			ret = rxm_cq_write_recv_comp(
+					rx_buf, rx_buf->recv_entry->context,
+					rx_buf->recv_entry->comp_flags |
+					rxm_cq_get_rx_comp_flags(rx_buf),
+					rx_buf->pkt.hdr.size,
+					rx_buf->recv_entry->rxm_iov.iov[0].iov_base);
+			if (ret)
 				return ret;
-			}
 		}
-		if (rx_buf->ep->util_ep.flags & OFI_CNTR_ENABLED)
-			rxm_cntr_inc(rx_buf->ep->util_ep.rx_cntr);
+		ofi_ep_rx_cntr_inc(&rx_buf->ep->util_ep);
 	}
 
-	rxm_enqueue_repost_ready_list(rx_buf);
-
 	if (rx_buf->recv_entry->flags & FI_MULTI_RECV) {
 		struct rxm_iov rxm_iov;
+		size_t recv_size = rx_buf->pkt.hdr.size;
+		struct rxm_ep *rxm_ep = rx_buf->ep;
+
+		rxm_rx_buf_release(rxm_ep, rx_buf);
 
-		rx_buf->recv_entry->total_len -= rx_buf->pkt.hdr.size;
+		recv_entry->total_len -= recv_size;
 
-		if (rx_buf->recv_entry->total_len <= rx_buf->ep->min_multi_recv_size) {
+		if (recv_entry->total_len <= rxm_ep->min_multi_recv_size) {
 			FI_DBG(&rxm_prov, FI_LOG_CQ,
 			       "Buffer %p has been completely consumed. "
 			       "Reporting Multi-Recv completion\n",
-			       rx_buf->recv_entry->multi_recv_buf);
-			ret = ofi_cq_write(rx_buf->ep->util_ep.rx_cq,
-					   rx_buf->recv_entry->context,
-					   FI_MULTI_RECV, rx_buf->pkt.hdr.size,
-					   rx_buf->recv_entry->multi_recv_buf,
-					   rx_buf->pkt.hdr.data, rx_buf->pkt.hdr.tag);
+			       recv_entry->multi_recv.buf);
+			ret = rxm_cq_write_multi_recv_comp(rxm_ep, recv_entry);
 			if (OFI_UNLIKELY(ret)) {
 				FI_WARN(&rxm_prov, FI_LOG_CQ,
 					"Unable to write FI_MULTI_RECV completion\n");
 				return ret;
 			}
 			/* Since buffer is elapsed, release recv_entry */
-			rxm_recv_entry_release(rx_buf->recv_queue, rx_buf->recv_entry);
+			rxm_recv_entry_release(recv_entry->recv_queue,
+					       recv_entry);
 			return ret;
 		}
 
 		FI_DBG(&rxm_prov, FI_LOG_CQ,
 		       "Repost Multi-Recv entry: "
-		       "consumed len = %"PRIu64", remain len = %zu\n",
-		       rx_buf->pkt.hdr.size,
-		       rx_buf->recv_entry->total_len);
-
-		rxm_iov = rx_buf->recv_entry->rxm_iov;
-		ret = rxm_match_iov(rxm_iov.iov, rxm_iov.desc, rxm_iov.count,	/* prev iovecs */
-				    rx_buf->pkt.hdr.size,			/* offset */
-				    rx_buf->recv_entry->total_len,		/* match_len */
-				    &rx_buf->recv_entry->rxm_iov);		/* match_iov */
+		       "consumed len = %zu, remain len = %zu\n",
+		       recv_size, recv_entry->total_len);
+
+		rxm_iov = recv_entry->rxm_iov;
+		ret = rxm_match_iov(/* prev iovecs */
+				    rxm_iov.iov, rxm_iov.desc, rxm_iov.count,
+				    recv_size,			/* offset */
+				    recv_entry->total_len,	/* match_len */
+				    &recv_entry->rxm_iov);	/* match_iov */
 		if (OFI_UNLIKELY(ret))
 			return ret;
 
-		return rxm_process_recv_entry(&rx_buf->ep->recv_queue, rx_buf->recv_entry);
+		return rxm_process_recv_entry(recv_entry->recv_queue, recv_entry);
 	} else {
-		rxm_recv_entry_release(rx_buf->recv_queue, rx_buf->recv_entry);
+		rxm_rx_buf_release(rx_buf->ep, rx_buf);
+		rxm_recv_entry_release(recv_entry->recv_queue, recv_entry);
 	}
 
 	return FI_SUCCESS;
 }
 
-static int rxm_finish_send_nobuf(struct rxm_tx_entry *tx_entry)
+static inline int
+rxm_cq_tx_comp_write(struct rxm_ep *rxm_ep, uint64_t comp_flags,
+		     void *app_context,  uint64_t flags)
 {
-	int ret;
-
-	if (tx_entry->flags & FI_COMPLETION) {
-		ret = ofi_cq_write(tx_entry->ep->util_ep.tx_cq,
-				   tx_entry->context, tx_entry->comp_flags, 0,
-				   NULL, 0, 0);
-		if (ret) {
+	if (flags & FI_COMPLETION) {
+		int ret = ofi_cq_write(rxm_ep->util_ep.tx_cq, app_context,
+				       comp_flags, 0, NULL, 0, 0);
+		if (OFI_UNLIKELY(ret)) {
 			FI_WARN(&rxm_prov, FI_LOG_CQ,
-					"Unable to report completion\n");
+				"Unable to report completion\n");
 			return ret;
 		}
-		rxm_cq_log_comp(tx_entry->comp_flags);
-	}
-	if (tx_entry->ep->util_ep.flags & OFI_CNTR_ENABLED) {
-		if (tx_entry->comp_flags & FI_SEND)
-			rxm_cntr_inc(tx_entry->ep->util_ep.tx_cntr);
-		else if (tx_entry->comp_flags & FI_WRITE)
-			rxm_cntr_inc(tx_entry->ep->util_ep.wr_cntr);
-		else
-			rxm_cntr_inc(tx_entry->ep->util_ep.rd_cntr);
+		rxm_cq_log_comp(comp_flags);
 	}
-	rxm_tx_entry_release(&tx_entry->ep->send_queue, tx_entry);
 	return 0;
 }
 
-static int rxm_finish_send(struct rxm_tx_entry *tx_entry)
+static inline int rxm_finish_rma(struct rxm_ep *rxm_ep, struct rxm_rma_buf *rma_buf,
+				 uint64_t comp_flags)
 {
-	rxm_tx_buf_release(tx_entry->ep, tx_entry->tx_buf);
-	return rxm_finish_send_nobuf(tx_entry);
+	int ret = rxm_cq_tx_comp_write(rxm_ep, comp_flags,
+				       rma_buf->app_context, rma_buf->flags);
+
+	assert(((comp_flags & FI_WRITE) && !(comp_flags & FI_READ)) ||
+	       ((comp_flags & FI_READ) && !(comp_flags & FI_WRITE)));
+	ofi_ep_cntr_inc_funcs[comp_flags & (FI_WRITE | FI_READ)](&rxm_ep->util_ep);
+
+	if (!(rma_buf->flags & FI_INJECT) && !rxm_ep->rxm_mr_local && rxm_ep->msg_mr_local) {
+		rxm_ep_msg_mr_closev(rma_buf->mr.mr, rma_buf->mr.count);
+	}
+
+	rxm_rma_buf_release(rxm_ep, rma_buf);
+	return ret;
 }
 
-static inline int rxm_finish_send_lmt_ack(struct rxm_rx_buf *rx_buf)
+static inline int rxm_finish_eager_send(struct rxm_ep *rxm_ep, struct rxm_tx_eager_buf *tx_buf)
 {
-	RXM_LOG_STATE(FI_LOG_CQ, rx_buf->pkt, RXM_LMT_ACK_SENT, RXM_LMT_FINISH);
-	rx_buf->hdr.state = RXM_LMT_FINISH;
-	if (!rx_buf->ep->rxm_mr_local)
-		rxm_ep_msg_mr_closev(rx_buf->mr, rx_buf->recv_entry->rxm_iov.count);
-	return rxm_finish_recv(rx_buf, rx_buf->recv_entry->total_len);
+	int ret = rxm_cq_tx_comp_write(rxm_ep, ofi_tx_cq_flags(tx_buf->pkt.hdr.op),
+				       tx_buf->app_context, tx_buf->flags);
+
+	assert(ofi_tx_cq_flags(tx_buf->pkt.hdr.op) & FI_SEND);
+	ofi_ep_tx_cntr_inc(&rxm_ep->util_ep);
+
+	return ret;
 }
 
-static ssize_t rxm_lmt_rma_read(struct rxm_rx_buf *rx_buf)
+static inline int rxm_finish_sar_segment_send(struct rxm_ep *rxm_ep, struct rxm_tx_sar_buf *tx_buf)
 {
-	struct rxm_iov *match_iov = &rx_buf->match_iov[rx_buf->index];
-	struct ofi_rma_iov *rma_iov = &rx_buf->rma_iov->iov[rx_buf->index];
-	ssize_t ret;
+	int ret = FI_SUCCESS;
+	struct rxm_tx_sar_buf *first_tx_buf;
 
-	ret = fi_readv(rx_buf->conn->msg_ep, match_iov->iov, match_iov->desc,
-		       match_iov->count, 0, rma_iov->addr, rma_iov->key, rx_buf);
-	if (ret)
-		return ret;
-	rx_buf->index++;
-	return FI_SUCCESS;
+	switch (rxm_sar_get_seg_type(&tx_buf->pkt.ctrl_hdr)) {
+	case RXM_SAR_SEG_FIRST:
+		break;
+	case RXM_SAR_SEG_MIDDLE:
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_SAR, tx_buf);
+		break;
+	case RXM_SAR_SEG_LAST:
+		ret = rxm_cq_tx_comp_write(rxm_ep, ofi_tx_cq_flags(tx_buf->pkt.hdr.op),
+					   tx_buf->app_context, tx_buf->flags);
+
+		assert(ofi_tx_cq_flags(tx_buf->pkt.hdr.op) & FI_SEND);
+		ofi_ep_tx_cntr_inc(&rxm_ep->util_ep);
+		first_tx_buf = rxm_msg_id_2_tx_buf(rxm_ep, RXM_BUF_POOL_TX_SAR,
+						   tx_buf->pkt.ctrl_hdr.msg_id);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_SAR, first_tx_buf);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_SAR, tx_buf);
+		break;
+	}
+
+	return ret;
+}
+
+static inline int rxm_finish_send_rndv_ack(struct rxm_rx_buf *rx_buf)
+{
+	RXM_LOG_STATE(FI_LOG_CQ, rx_buf->pkt, RXM_RNDV_ACK_SENT, RXM_RNDV_FINISH);
+	rx_buf->hdr.state = RXM_RNDV_FINISH;
+	if (!rx_buf->ep->rxm_mr_local)
+		rxm_ep_msg_mr_closev(rx_buf->mr, rx_buf->recv_entry->rxm_iov.count);
+	return rxm_finish_recv(rx_buf, rx_buf->recv_entry->total_len);
 }
 
-static int rxm_lmt_tx_finish(struct rxm_tx_entry *tx_entry)
+static int rxm_rndv_tx_finish(struct rxm_ep *rxm_ep, struct rxm_tx_rndv_buf *tx_buf)
 {
 	int ret;
 
-	RXM_LOG_STATE_TX(FI_LOG_CQ, tx_entry, RXM_LMT_FINISH);
-	tx_entry->state = RXM_LMT_FINISH;
+	RXM_LOG_STATE_TX(FI_LOG_CQ, tx_buf, RXM_RNDV_FINISH);
+	tx_buf->hdr.state = RXM_RNDV_FINISH;
 
-	if (!tx_entry->ep->rxm_mr_local)
-		rxm_ep_msg_mr_closev(tx_entry->mr, tx_entry->count);
+	if (!rxm_ep->rxm_mr_local)
+		rxm_ep_msg_mr_closev(tx_buf->mr, tx_buf->count);
 
-	ret = rxm_finish_send(tx_entry);
-	if (ret)
-		return ret;
+	ret = rxm_cq_tx_comp_write(rxm_ep, ofi_tx_cq_flags(tx_buf->pkt.hdr.op),
+				   tx_buf->app_context, tx_buf->flags);
+
+	assert(ofi_tx_cq_flags(tx_buf->pkt.hdr.op) & FI_SEND);
+	ofi_ep_tx_cntr_inc(&rxm_ep->util_ep);
+
+	rxm_rx_buf_release(rxm_ep, tx_buf->rx_buf);
+	rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_RNDV, tx_buf);
 
-	rxm_enqueue_repost_ready_list(tx_entry->rx_buf);
 	return ret;
 }
 
-static int rxm_lmt_handle_ack(struct rxm_rx_buf *rx_buf)
+static int rxm_rndv_handle_ack(struct rxm_ep *rxm_ep, struct rxm_rx_buf *rx_buf)
 {
-	struct rxm_tx_entry *tx_entry;
+	struct rxm_tx_rndv_buf *tx_buf =
+		rxm_msg_id_2_tx_buf(rxm_ep, RXM_BUF_POOL_TX_RNDV,
+				    rx_buf->pkt.ctrl_hdr.msg_id);
 
 	FI_DBG(&rxm_prov, FI_LOG_CQ, "Got ACK for msg_id: 0x%" PRIx64 "\n",
 	       rx_buf->pkt.ctrl_hdr.msg_id);
 
-	tx_entry = &rx_buf->ep->send_queue.fs->buf[rx_buf->pkt.ctrl_hdr.msg_id];
+	assert(tx_buf->pkt.ctrl_hdr.msg_id == rx_buf->pkt.ctrl_hdr.msg_id);
 
-	assert(tx_entry->tx_buf->pkt.ctrl_hdr.msg_id == rx_buf->pkt.ctrl_hdr.msg_id);
+	tx_buf->rx_buf = rx_buf;
 
-	tx_entry->rx_buf = rx_buf;
-
-	if (tx_entry->state == RXM_LMT_ACK_WAIT) {
-		return rxm_lmt_tx_finish(tx_entry);
+	if (tx_buf->hdr.state == RXM_RNDV_ACK_WAIT) {
+		return rxm_rndv_tx_finish(rxm_ep, tx_buf);
 	} else {
-		assert(tx_entry->state == RXM_LMT_TX);
-		RXM_LOG_STATE_TX(FI_LOG_CQ, tx_entry, RXM_LMT_ACK_RECVD);
-		tx_entry->state = RXM_LMT_ACK_RECVD;
+		assert(tx_buf->hdr.state == RXM_RNDV_TX);
+		RXM_LOG_STATE_TX(FI_LOG_CQ, tx_buf, RXM_RNDV_ACK_RECVD);
+		tx_buf->hdr.state = RXM_RNDV_ACK_RECVD;
 		return 0;
 	}
 }
 
-ssize_t rxm_cq_handle_data(struct rxm_rx_buf *rx_buf)
+static inline
+ssize_t rxm_cq_handle_seg_data(struct rxm_rx_buf *rx_buf)
 {
-	size_t i;
-	int ret;
+	uint64_t done_len = ofi_copy_to_iov(rx_buf->recv_entry->rxm_iov.iov,
+					    rx_buf->recv_entry->rxm_iov.count,
+					    rx_buf->recv_entry->sar.total_recv_len,
+					    rx_buf->pkt.data,
+					    rx_buf->pkt.ctrl_hdr.seg_size);
+	rx_buf->recv_entry->sar.total_recv_len += done_len;
 
-	if (rx_buf->pkt.ctrl_hdr.type == ofi_ctrl_large_data) {
-		if (!rx_buf->conn) {
-			rx_buf->conn = rxm_key2conn(rx_buf->ep, rx_buf->pkt.ctrl_hdr.conn_id);
-			if (OFI_UNLIKELY(!rx_buf->conn))
-				return -FI_EOTHER;
-		}
+	if ((rxm_sar_get_seg_type(&rx_buf->pkt.ctrl_hdr) == RXM_SAR_SEG_LAST) ||
+	    (done_len != rx_buf->pkt.ctrl_hdr.seg_size)) {
+		dlist_remove(&rx_buf->recv_entry->sar.entry);
 
-		FI_DBG(&rxm_prov, FI_LOG_CQ,
-		       "Got incoming recv with msg_id: 0x%" PRIx64 "\n",
-		       rx_buf->pkt.ctrl_hdr.msg_id);
+		/* Mark rxm_recv_entry::msg_id as unknown for futher re-use */
+		rx_buf->recv_entry->sar.msg_id = RXM_SAR_RX_INIT;
 
-		rx_buf->rma_iov = (struct rxm_rma_iov *)rx_buf->pkt.data;
-		rx_buf->index = 0;
+		done_len = rx_buf->recv_entry->sar.total_recv_len;
+		rx_buf->recv_entry->sar.total_recv_len = 0;
 
-		if (!rx_buf->ep->rxm_mr_local) {
-			ret = rxm_ep_msg_mr_regv(rx_buf->ep, rx_buf->recv_entry->rxm_iov.iov,
-						 rx_buf->recv_entry->rxm_iov.count, FI_READ,
-						 rx_buf->mr);
-			if (ret)
-				return ret;
+		return rxm_finish_recv(rx_buf, done_len);
+	} else {
+		if (rx_buf->recv_entry->sar.msg_id == RXM_SAR_RX_INIT) {
+			if (!rx_buf->conn) {
+				rx_buf->conn = rxm_key2conn(rx_buf->ep,
+							    rx_buf->pkt.ctrl_hdr.conn_id);
+			}
 
-			for (i = 0; i < rx_buf->recv_entry->rxm_iov.count; i++)
-				rx_buf->recv_entry->rxm_iov.desc[i] =
-					fi_mr_desc(rx_buf->mr[i]);
-		} else {
-			for (i = 0; i < rx_buf->recv_entry->rxm_iov.count; i++)
-				rx_buf->recv_entry->rxm_iov.desc[i] =
-					fi_mr_desc(rx_buf->recv_entry->rxm_iov.desc[i]);
+			rx_buf->recv_entry->sar.conn = rx_buf->conn;
+			rx_buf->recv_entry->sar.msg_id = rx_buf->pkt.ctrl_hdr.msg_id;
+
+			dlist_insert_tail(&rx_buf->recv_entry->sar.entry,
+					  &rx_buf->conn->sar_rx_msg_list);
 		}
 
-		/* Ignore the case when the posted recv buffer is not large enough,
-		 * FI_TRUNC error will be generated to user at the end */
-		rxm_match_rma_iov(rx_buf->recv_entry, rx_buf->rma_iov, rx_buf->match_iov);
-		RXM_LOG_STATE_RX(FI_LOG_CQ, rx_buf, RXM_LMT_READ);
-		rx_buf->hdr.state = RXM_LMT_READ;
-		return rxm_lmt_rma_read(rx_buf);
-	} else {
-		uint64_t done_len = ofi_copy_to_iov(rx_buf->recv_entry->rxm_iov.iov,
-						    rx_buf->recv_entry->rxm_iov.count,
-						    0, rx_buf->pkt.data,
-						    rx_buf->pkt.hdr.size);
-		return rxm_finish_recv(rx_buf, done_len);
+		/* The RX buffer can be reposted for further re-use */
+		rx_buf->recv_entry = NULL;
+		rxm_rx_buf_release(rx_buf->ep, rx_buf);
+		return FI_SUCCESS;
 	}
 }
 
-static ssize_t rxm_handle_recv_comp(struct rxm_rx_buf *rx_buf)
+static inline ssize_t
+rxm_cq_rndv_read_prepare_deferred(struct rxm_deferred_tx_entry **def_tx_entry, size_t index,
+				 struct iovec *iov, void *desc[RXM_IOV_LIMIT],
+				 size_t count, struct rxm_rx_buf *rx_buf)
 {
-	struct rxm_recv_match_attr match_attr;
-	struct dlist_entry *entry;
-	struct util_cq *util_cq;
-	struct fid_ep *msg_ep;
-	struct rxm_ep *rxm_ep;
+	uint8_t i;
 
-	util_cq = rx_buf->ep->util_ep.rx_cq;
+	*def_tx_entry = rxm_ep_alloc_deferred_tx_entry(rx_buf->ep, rx_buf->conn,
+						       RXM_DEFERRED_TX_RNDV_READ);
+	if (OFI_UNLIKELY(!*def_tx_entry))
+		return -FI_ENOMEM;
+
+	(*def_tx_entry)->rndv_read.rx_buf = rx_buf;
+	(*def_tx_entry)->rndv_read.rma_iov.addr =
+			rx_buf->rndv_hdr->iov[index].addr;
+	(*def_tx_entry)->rndv_read.rma_iov.key =
+			rx_buf->rndv_hdr->iov[index].key;
+	for (i = 0; i < count; i++) {
+		(*def_tx_entry)->rndv_read.rxm_iov.iov[i] = iov[i];
+		(*def_tx_entry)->rndv_read.rxm_iov.desc[i] = desc[i];
+	}
+	(*def_tx_entry)->rndv_read.rxm_iov.count = count;
 
-	if ((rx_buf->ep->rxm_info->caps & (FI_SOURCE | FI_DIRECTED_RECV)) &&
-	    !rx_buf->conn) {
-		rx_buf->conn = rxm_key2conn(rx_buf->ep, rx_buf->pkt.ctrl_hdr.conn_id);
+	return 0;
+}
+
+static inline
+ssize_t rxm_cq_handle_large_data(struct rxm_rx_buf *rx_buf)
+{
+	size_t i, index = 0, offset = 0, count, total_recv_len;
+	struct iovec iov[RXM_IOV_LIMIT];
+	void *desc[RXM_IOV_LIMIT];
+	int ret = 0;
+
+	if (!rx_buf->conn) {
+		assert(rx_buf->ep->srx_ctx);
+		rx_buf->conn = rxm_key2conn(rx_buf->ep,
+					    rx_buf->pkt.ctrl_hdr.conn_id);
 		if (OFI_UNLIKELY(!rx_buf->conn))
 			return -FI_EOTHER;
-		match_attr.addr = rx_buf->conn->handle.fi_addr;
+	}
+	assert(rx_buf->conn);
+
+	FI_DBG(&rxm_prov, FI_LOG_CQ,
+	       "Got incoming recv with msg_id: 0x%" PRIx64 "\n",
+	       rx_buf->pkt.ctrl_hdr.msg_id);
+
+	rx_buf->rndv_hdr = (struct rxm_rndv_hdr *)rx_buf->pkt.data;
+	rx_buf->rndv_rma_index = 0;
+
+	if (!rx_buf->ep->rxm_mr_local) {
+		total_recv_len = MIN(rx_buf->recv_entry->total_len,
+				     rx_buf->pkt.hdr.size);
+		ret = rxm_ep_msg_mr_regv_lim(rx_buf->ep,
+					     rx_buf->recv_entry->rxm_iov.iov,
+					     rx_buf->recv_entry->rxm_iov.count,
+					     total_recv_len,
+					     FI_READ, rx_buf->mr);
+		if (OFI_UNLIKELY(ret))
+			return ret;
+
+		for (i = 0; i < rx_buf->recv_entry->rxm_iov.count; i++)
+			rx_buf->recv_entry->rxm_iov.desc[i] =
+						fi_mr_desc(rx_buf->mr[i]);
 	} else {
-		match_attr.addr = FI_ADDR_UNSPEC;
+		for (i = 0; i < rx_buf->recv_entry->rxm_iov.count; i++) {
+			rx_buf->recv_entry->rxm_iov.desc[i] =
+				fi_mr_desc(rx_buf->recv_entry->rxm_iov.desc[i]);
+		}
+		total_recv_len = MIN(rx_buf->recv_entry->total_len,
+				     rx_buf->pkt.hdr.size);
 	}
 
-	if (rx_buf->ep->rxm_info->caps & FI_SOURCE)
-		util_cq->src[ofi_cirque_windex(util_cq->cirq)] = rx_buf->conn->handle.fi_addr;
+	assert(rx_buf->rndv_hdr->count &&
+	       (rx_buf->rndv_hdr->count <= RXM_IOV_LIMIT));
 
-	switch(rx_buf->pkt.hdr.op) {
-	case ofi_op_msg:
-		FI_DBG(&rxm_prov, FI_LOG_CQ, "Got MSG op\n");
-		rx_buf->recv_queue = &rx_buf->ep->recv_queue;
-		break;
-	case ofi_op_tagged:
-		FI_DBG(&rxm_prov, FI_LOG_CQ, "Got TAGGED op\n");
-		match_attr.tag = rx_buf->pkt.hdr.tag;
-		rx_buf->recv_queue = &rx_buf->ep->trecv_queue;
-		break;
+	RXM_LOG_STATE_RX(FI_LOG_CQ, rx_buf, RXM_RNDV_READ);
+	rx_buf->hdr.state = RXM_RNDV_READ;
+
+	for (i = 0; i < rx_buf->rndv_hdr->count; i++) {
+		size_t copy_len = MIN(rx_buf->rndv_hdr->iov[i].len,
+				      total_recv_len);
+
+		ret = ofi_copy_iov_desc(&iov[0], &desc[0], &count,
+					&rx_buf->recv_entry->rxm_iov.iov[0],
+					&rx_buf->recv_entry->rxm_iov.desc[0],
+					rx_buf->recv_entry->rxm_iov.count,
+					&index, &offset, copy_len);
+		if (ret) {
+			assert(ret == -FI_ETOOSMALL);
+			return rxm_cq_write_error_trunc(
+				rx_buf, rx_buf->recv_entry->total_len);
+		}
+		total_recv_len -= copy_len;
+		ret = fi_readv(rx_buf->conn->msg_ep, iov, desc, count, 0,
+			       rx_buf->rndv_hdr->iov[i].addr,
+			       rx_buf->rndv_hdr->iov[i].key, rx_buf);
+		if (OFI_UNLIKELY(ret)) {
+			if (OFI_LIKELY(ret == -FI_EAGAIN)) {
+				struct rxm_deferred_tx_entry *def_tx_entry;
+
+				ret = rxm_cq_rndv_read_prepare_deferred(
+						&def_tx_entry, i, iov, desc,
+						count, rx_buf);
+				if (ret)
+					goto readv_err;
+				rxm_ep_enqueue_deferred_tx_queue(def_tx_entry);
+				continue;
+			}
+readv_err:
+			rxm_cq_write_error(rx_buf->ep->util_ep.rx_cq,
+					   rx_buf->ep->util_ep.rx_cntr,
+					   rx_buf->recv_entry->context, ret);
+			break;
+		}
+	}
+	assert(!total_recv_len);
+	return ret;
+}
+
+static inline
+ssize_t rxm_cq_handle_data(struct rxm_rx_buf *rx_buf)
+{
+	uint64_t done_len = ofi_copy_to_iov(rx_buf->recv_entry->rxm_iov.iov,
+					    rx_buf->recv_entry->rxm_iov.count,
+					    0, rx_buf->pkt.data,
+					    rx_buf->pkt.hdr.size);
+	return rxm_finish_recv(rx_buf, done_len);
+}
+
+ssize_t rxm_cq_handle_rx_buf(struct rxm_rx_buf *rx_buf)
+{
+	switch (rx_buf->pkt.ctrl_hdr.type) {
+	case ofi_ctrl_data:
+		return rxm_cq_handle_data(rx_buf);
+	case ofi_ctrl_large_data:
+		return rxm_cq_handle_large_data(rx_buf);
+	case ofi_ctrl_seg_data:
+		return rxm_cq_handle_seg_data(rx_buf);
 	default:
-		FI_WARN(&rxm_prov, FI_LOG_CQ, "Unknown op!\n");
+		FI_WARN(&rxm_prov, FI_LOG_CQ, "Unknown message type\n");
 		assert(0);
 		return -FI_EINVAL;
 	}
+}
 
-	fastlock_acquire(&rx_buf->recv_queue->lock);
-	entry = dlist_remove_first_match(&rx_buf->recv_queue->recv_list,
-					 rx_buf->recv_queue->match_recv, &match_attr);
+static inline ssize_t
+rxm_cq_match_rx_buf(struct rxm_rx_buf *rx_buf,
+		    struct rxm_recv_queue *recv_queue,
+		    struct rxm_recv_match_attr *match_attr)
+{
+	struct dlist_entry *entry;
+	struct rxm_ep *rxm_ep;
+	struct fid_ep *msg_ep;
+
+	entry = dlist_remove_first_match(&recv_queue->recv_list,
+					 recv_queue->match_recv, match_attr);
 	if (!entry) {
 		RXM_DBG_ADDR_TAG(FI_LOG_CQ, "No matching recv found for "
-				 "incoming msg", match_attr.addr,
-				 match_attr.tag);
+				 "incoming msg", match_attr->addr,
+				 match_attr->tag);
 		FI_DBG(&rxm_prov, FI_LOG_CQ, "Enqueueing msg to unexpected msg"
 		       "queue\n");
-		rx_buf->unexp_msg.addr = match_attr.addr;
-		rx_buf->unexp_msg.tag = match_attr.tag;
+		rx_buf->unexp_msg.addr = match_attr->addr;
+		rx_buf->unexp_msg.tag = match_attr->tag;
 		rx_buf->repost = 0;
 
-		msg_ep = rx_buf->hdr.msg_ep;
+		msg_ep = rx_buf->msg_ep;
 		rxm_ep = rx_buf->ep;
 
 		dlist_insert_tail(&rx_buf->unexp_msg.entry,
-				  &rx_buf->recv_queue->unexp_msg_list);
-		fastlock_release(&rx_buf->recv_queue->lock);
+				  &recv_queue->unexp_msg_list);
 
-		rx_buf = rxm_rx_buf_get(rxm_ep);
-		if (!rx_buf)
+		rx_buf = rxm_rx_buf_alloc(rxm_ep);
+		if (OFI_UNLIKELY(!rx_buf)) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+				"Ran out of buffers from RX buffer pool\n");
 			return -FI_ENOMEM;
+		}
 
 		rx_buf->hdr.state = RXM_RX;
-		rx_buf->hdr.msg_ep = msg_ep;
+		rx_buf->msg_ep = msg_ep;
 		rx_buf->repost = 1;
 		if (!rxm_ep->srx_ctx)
 			rx_buf->conn = container_of(msg_ep->fid.context,
 						    struct rxm_conn,
 						    handle);
 
-		fastlock_acquire(&rx_buf->ep->util_ep.lock);
-		dlist_insert_tail(&rx_buf->entry, &rxm_ep->post_rx_list);
-		dlist_insert_tail(&rx_buf->repost_entry,
-				  &rx_buf->ep->repost_ready_list);
-		fastlock_release(&rx_buf->ep->util_ep.lock);
+		rxm_rx_buf_release(rxm_ep, rx_buf);
 		return 0;
 	}
-	fastlock_release(&rx_buf->recv_queue->lock);
 
 	rx_buf->recv_entry = container_of(entry, struct rxm_recv_entry, entry);
-	return rxm_cq_handle_data(rx_buf);
+	return rxm_cq_handle_rx_buf(rx_buf);
+}
+
+static inline ssize_t rxm_handle_recv_comp(struct rxm_rx_buf *rx_buf)
+{
+	struct rxm_recv_match_attr match_attr = {
+		.addr = FI_ADDR_UNSPEC,
+	};
+
+	if (rx_buf->ep->rxm_info->caps & (FI_SOURCE | FI_DIRECTED_RECV)) {
+		if (rx_buf->ep->srx_ctx)
+			rx_buf->conn =
+				rxm_key2conn(rx_buf->ep, rx_buf->pkt.ctrl_hdr.conn_id);
+		if (OFI_UNLIKELY(!rx_buf->conn))
+			return -FI_EOTHER;
+		match_attr.addr = rx_buf->conn->handle.fi_addr;
+	}
+
+	if (rx_buf->ep->rxm_info->mode & FI_BUFFERED_RECV)
+		return rxm_finish_buf_recv(rx_buf);
+
+	switch(rx_buf->pkt.hdr.op) {
+	case ofi_op_msg:
+		FI_DBG(&rxm_prov, FI_LOG_CQ, "Got MSG op\n");
+		return rxm_cq_match_rx_buf(rx_buf, &rx_buf->ep->recv_queue,
+					   &match_attr);
+	case ofi_op_tagged:
+		FI_DBG(&rxm_prov, FI_LOG_CQ, "Got TAGGED op\n");
+		match_attr.tag = rx_buf->pkt.hdr.tag;
+		return rxm_cq_match_rx_buf(rx_buf, &rx_buf->ep->trecv_queue,
+					   &match_attr);
+	default:
+		FI_WARN(&rxm_prov, FI_LOG_CQ, "Unknown op!\n");
+		assert(0);
+		return -FI_EINVAL;
+	}
+}
+
+static int rxm_sar_match_msg_id(struct dlist_entry *item, const void *arg)
+{
+	uint64_t msg_id = *((uint64_t *)arg);
+	struct rxm_recv_entry *recv_entry =
+		container_of(item, struct rxm_recv_entry, sar.entry);
+	return (msg_id == recv_entry->sar.msg_id);
 }
 
-static ssize_t rxm_lmt_send_ack(struct rxm_rx_buf *rx_buf)
+static inline
+ssize_t rxm_sar_handle_segment(struct rxm_rx_buf *rx_buf)
+{
+	struct dlist_entry *sar_entry;
+
+	rx_buf->conn = rxm_key2conn(rx_buf->ep,
+				    rx_buf->pkt.ctrl_hdr.conn_id);
+	if (OFI_UNLIKELY(!rx_buf->conn))
+		return -FI_EOTHER;
+	FI_DBG(&rxm_prov, FI_LOG_CQ,
+	       "Got incoming recv with msg_id: 0x%" PRIx64 "for conn - %p\n",
+	       rx_buf->pkt.ctrl_hdr.msg_id, rx_buf->conn);
+	sar_entry = dlist_find_first_match(&rx_buf->conn->sar_rx_msg_list,
+					   rxm_sar_match_msg_id,
+					   &rx_buf->pkt.ctrl_hdr.msg_id);
+	if (!sar_entry)
+		return rxm_handle_recv_comp(rx_buf);
+	rx_buf->recv_entry =
+		container_of(sar_entry, struct rxm_recv_entry, sar.entry);
+	return rxm_cq_handle_seg_data(rx_buf);
+}
+
+static ssize_t rxm_rndv_send_ack(struct rxm_rx_buf *rx_buf)
 {
-	struct rxm_tx_entry *tx_entry;
-	struct rxm_tx_buf *tx_buf;
 	ssize_t ret;
 
 	assert(rx_buf->conn);
 
-	tx_buf = rxm_tx_buf_get(rx_buf->ep, RXM_BUF_POOL_TX_ACK);
-	if (OFI_UNLIKELY(!tx_buf)) {
-		FI_WARN(&rxm_prov, FI_LOG_CQ, "TX queue full!\n");
+	rx_buf->recv_entry->rndv.tx_buf = (struct rxm_tx_base_buf *)
+		rxm_tx_buf_alloc(rx_buf->ep, RXM_BUF_POOL_TX_ACK);
+	if (OFI_UNLIKELY(!rx_buf->recv_entry->rndv.tx_buf)) {
+		FI_WARN(&rxm_prov, FI_LOG_CQ,
+			"Ran out of buffers from ACK buffer pool\n");
 		return -FI_EAGAIN;
 	}
-	assert(tx_buf->pkt.ctrl_hdr.type == ofi_ctrl_ack);
+	assert(rx_buf->recv_entry->rndv.tx_buf->pkt.ctrl_hdr.type == ofi_ctrl_ack);
 
-	tx_entry = rxm_tx_entry_get(&rx_buf->ep->send_queue);
-	if (OFI_UNLIKELY(!tx_entry)) {
-		ret = -FI_EAGAIN;
-		goto err1;
-	}
+	RXM_LOG_STATE(FI_LOG_CQ, rx_buf->pkt, RXM_RNDV_READ, RXM_RNDV_ACK_SENT);
+	rx_buf->hdr.state = RXM_RNDV_ACK_SENT;
 
-	RXM_LOG_STATE(FI_LOG_CQ, rx_buf->pkt, RXM_LMT_READ, RXM_LMT_ACK_SENT);
-	rx_buf->hdr.state = RXM_LMT_ACK_SENT;
+	rx_buf->recv_entry->rndv.tx_buf->pkt.ctrl_hdr.conn_id =
+		rx_buf->conn->handle.remote_key;
+	rx_buf->recv_entry->rndv.tx_buf->pkt.ctrl_hdr.msg_id =
+		rx_buf->pkt.ctrl_hdr.msg_id;
 
-	tx_entry->state 	= rx_buf->hdr.state;
-	tx_entry->context 	= rx_buf;
-	tx_entry->tx_buf 	= tx_buf;
-
-	tx_buf->pkt.ctrl_hdr.conn_id 	= rx_buf->conn->handle.remote_key;
-	tx_buf->pkt.ctrl_hdr.msg_id 	= rx_buf->pkt.ctrl_hdr.msg_id;
-
-	ret = fi_send(rx_buf->conn->msg_ep, &tx_buf->pkt, sizeof(tx_buf->pkt),
-		      tx_buf->hdr.desc, 0, tx_entry);
+	ret = fi_send(rx_buf->conn->msg_ep, &rx_buf->recv_entry->rndv.tx_buf->pkt,
+		      sizeof(rx_buf->recv_entry->rndv.tx_buf->pkt),
+		      rx_buf->recv_entry->rndv.tx_buf->hdr.desc, 0, rx_buf);
 	if (OFI_UNLIKELY(ret)) {
 		FI_WARN(&rxm_prov, FI_LOG_CQ, "Unable to send ACK\n");
-		goto err2;
+		if (OFI_LIKELY(ret == -FI_EAGAIN)) {
+			struct rxm_deferred_tx_entry *def_tx_entry =
+				rxm_ep_alloc_deferred_tx_entry(rx_buf->ep, rx_buf->conn,
+							       RXM_DEFERRED_TX_RNDV_ACK);
+			if (OFI_UNLIKELY(!def_tx_entry)) {
+				FI_WARN(&rxm_prov, FI_LOG_CQ,
+					"Unable to allocate TX entry for deferred ACK\n");
+				ret = -FI_EAGAIN;
+				goto err;
+			}
+
+			def_tx_entry->rndv_ack.rx_buf = rx_buf;
+			rxm_ep_enqueue_deferred_tx_queue(def_tx_entry);
+
+			return 0;
+		}
+		goto err;
 	}
 	return 0;
-err2:
-	rxm_tx_entry_release(&rx_buf->ep->send_queue, tx_entry);
-err1:
-	rxm_tx_buf_release(rx_buf->ep, tx_buf);
+err:
+	rxm_tx_buf_release(rx_buf->ep, RXM_BUF_POOL_TX_ACK,
+			   rx_buf->recv_entry->rndv.tx_buf);
 	return ret;
 }
 
-static ssize_t rxm_lmt_send_ack_fast(struct rxm_rx_buf *rx_buf)
+static ssize_t rxm_rndv_send_ack_fast(struct rxm_rx_buf *rx_buf)
 {
 	struct rxm_pkt pkt;
 	ssize_t ret;
 
 	assert(rx_buf->conn);
 
-	RXM_LOG_STATE(FI_LOG_CQ, rx_buf->pkt, RXM_LMT_READ, RXM_LMT_ACK_SENT);
+	RXM_LOG_STATE(FI_LOG_CQ, rx_buf->pkt, RXM_RNDV_READ, RXM_RNDV_ACK_SENT);
 
 	pkt.hdr.op		= ofi_op_msg;
 	pkt.hdr.version		= OFI_OP_VERSION;
-	pkt.ctrl_hdr.version	= OFI_CTRL_VERSION;
+	pkt.ctrl_hdr.version	= RXM_CTRL_VERSION;
 	pkt.ctrl_hdr.type	= ofi_ctrl_ack;
 	pkt.ctrl_hdr.conn_id 	= rx_buf->conn->handle.remote_key;
 	pkt.ctrl_hdr.msg_id 	= rx_buf->pkt.ctrl_hdr.msg_id;
@@ -571,14 +726,20 @@ static ssize_t rxm_lmt_send_ack_fast(struct rxm_rx_buf *rx_buf)
 	if (OFI_UNLIKELY(ret)) {
 		FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
 		       "fi_inject(ack pkt) for MSG provider failed\n");
+		if (OFI_LIKELY(ret == -FI_EAGAIN)) {
+			/* Issues the normal RNDV ACK sending to allocate the
+			 * TX entry, send it out or insert it to deferred
+			 * TX queue for the further processing */
+			return rxm_rndv_send_ack(rx_buf);
+		}
 		return ret;
 	}
 
-	return rxm_finish_send_lmt_ack(rx_buf);
+	return rxm_finish_send_rndv_ack(rx_buf);
 }
 
 static int rxm_handle_remote_write(struct rxm_ep *rxm_ep,
-				   struct fi_cq_tagged_entry *comp)
+				   struct fi_cq_data_entry *comp)
 {
 	int ret;
 
@@ -590,74 +751,329 @@ static int rxm_handle_remote_write(struct rxm_ep *rxm_ep,
 				"Unable to write remote write completion\n");
 		return ret;
 	}
-	rxm_cntr_inc(rxm_ep->util_ep.rem_wr_cntr);
-	if (comp->op_context) {
-		fastlock_acquire(&rxm_ep->util_ep.lock);
-		dlist_insert_tail(&((struct rxm_rx_buf *)
-					comp->op_context)->repost_entry,
-				  &rxm_ep->repost_ready_list);
-		fastlock_release(&rxm_ep->util_ep.lock);
-	}
+	ofi_ep_rem_wr_cntr_inc(&rxm_ep->util_ep);
+	if (comp->op_context)
+		rxm_rx_buf_release(rxm_ep, comp->op_context);
 	return 0;
 }
 
+static inline void rxm_ep_format_atomic_resp_pkt_hdr(struct rxm_conn *rxm_conn,
+				struct rxm_tx_atomic_buf *tx_buf,
+				size_t data_len, uint32_t pkt_op,
+				enum fi_datatype datatype, uint8_t atomic_op)
+{
+	rxm_ep_format_tx_buf_pkt(rxm_conn, data_len, pkt_op, 0, 0, 0,
+				 &tx_buf->pkt);
+	tx_buf->pkt.ctrl_hdr.type = ofi_ctrl_atomic_resp;
+	tx_buf->pkt.hdr.op = pkt_op;
+	tx_buf->pkt.hdr.atomic.datatype = datatype;
+	tx_buf->pkt.hdr.atomic.op = atomic_op;
+	tx_buf->pkt.hdr.atomic.ioc_count = 0;
+}
+
+static ssize_t rxm_atomic_send_resp(struct rxm_ep *rxm_ep,
+				    struct rxm_rx_buf *rx_buf,
+				    struct rxm_tx_atomic_buf *resp_buf,
+				    ssize_t result_len, uint32_t status)
+{
+	struct rxm_deferred_tx_entry *def_tx_entry;
+	struct rxm_atomic_resp_hdr *atomic_hdr;
+	ssize_t ret;
+	ssize_t resp_len = result_len + sizeof(struct rxm_atomic_resp_hdr) +
+				sizeof(struct rxm_pkt);
+
+	resp_buf->hdr.state = RXM_ATOMIC_RESP_SENT;
+	rxm_ep_format_atomic_resp_pkt_hdr(rx_buf->conn,
+					  resp_buf,
+					  resp_len,
+					  rx_buf->pkt.hdr.op,
+					  rx_buf->pkt.hdr.atomic.datatype,
+					  rx_buf->pkt.hdr.atomic.op);
+	resp_buf->pkt.ctrl_hdr.conn_id = rx_buf->conn->handle.remote_key;
+	resp_buf->pkt.ctrl_hdr.msg_id = rx_buf->pkt.ctrl_hdr.msg_id;
+	atomic_hdr = (struct rxm_atomic_resp_hdr *) resp_buf->pkt.data;
+	atomic_hdr->status = htonl(status);
+	atomic_hdr->result_len = htonl(result_len);
+
+	if (resp_len < rxm_ep->inject_limit) {
+		ret = fi_inject(rx_buf->conn->msg_ep, &resp_buf->pkt,
+				resp_len, 0);
+		if (OFI_LIKELY(!ret))
+			rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_ATOMIC,
+					   resp_buf);
+	} else {
+		ret = rxm_atomic_send_respmsg(rxm_ep, rx_buf->conn, resp_buf,
+					      resp_len);
+	}
+	if (OFI_UNLIKELY(ret)) {
+		FI_WARN(&rxm_prov, FI_LOG_CQ,
+			"Unable to send Atomic Response\n");
+		if (OFI_LIKELY(ret == -FI_EAGAIN)) {
+			def_tx_entry =
+				rxm_ep_alloc_deferred_tx_entry(rxm_ep,
+						rx_buf->conn,
+						RXM_DEFERRED_TX_ATOMIC_RESP);
+			if (OFI_UNLIKELY(!def_tx_entry)) {
+				FI_WARN(&rxm_prov, FI_LOG_CQ,
+					"Unable to allocate deferred Atomic "
+					"Response\n");
+				return -FI_ENOMEM;
+			}
+
+			def_tx_entry->atomic_resp.tx_buf = resp_buf;
+			def_tx_entry->atomic_resp.len = resp_len;
+			rxm_ep_enqueue_deferred_tx_queue(def_tx_entry);
+			ret = 0;
+		}
+	}
+	rxm_rx_buf_release(rxm_ep, rx_buf);
+
+	return ret;
+}
+
+static inline void rxm_do_atomic(struct rxm_pkt *pkt, void *dst, void *src,
+				 void *cmp, void *res, size_t count,
+				 enum fi_datatype datatype, enum fi_op op)
+{
+	switch (pkt->hdr.op) {
+	case ofi_op_atomic:
+		ofi_atomic_write_handlers[op][datatype](dst, src, count);
+		break;
+	case ofi_op_atomic_fetch:
+		ofi_atomic_readwrite_handlers[op][datatype](dst, src, res,
+							    count);
+		break;
+	case ofi_op_atomic_compare:
+		ofi_atomic_swap_handlers[op - OFI_SWAP_OP_START][datatype](dst,
+						src, cmp, res, count);
+		break;
+	default:
+		/* Validated prior to calling function */
+		break;
+	}
+}
+
+static inline ssize_t rxm_handle_atomic_req(struct rxm_ep *rxm_ep,
+					    struct rxm_rx_buf *rx_buf)
+{
+	struct rxm_atomic_hdr *req_hdr =
+			(struct rxm_atomic_hdr *) rx_buf->pkt.data;
+	enum fi_datatype datatype = rx_buf->pkt.hdr.atomic.datatype;
+	enum fi_op atomic_op = rx_buf->pkt.hdr.atomic.op;
+	size_t datatype_sz = ofi_datatype_size(datatype);
+	size_t len;
+	ssize_t result_len;
+	uint64_t offset;
+	int i;
+	int ret = 0;
+	struct rxm_tx_atomic_buf *resp_buf;
+	struct rxm_atomic_resp_hdr *resp_hdr;
+	struct rxm_domain *domain = container_of(rxm_ep->util_ep.domain,
+					 struct rxm_domain, util_domain);
+
+	assert(!(rx_buf->comp_flags &
+		 ~(FI_RECV | FI_RECV | FI_REMOTE_CQ_DATA)));
+	assert(rx_buf->pkt.hdr.op == ofi_op_atomic ||
+	       rx_buf->pkt.hdr.op == ofi_op_atomic_fetch ||
+	       rx_buf->pkt.hdr.op == ofi_op_atomic_compare);
+
+	if (rx_buf->ep->srx_ctx)
+		rx_buf->conn = rxm_key2conn(rx_buf->ep,
+					    rx_buf->pkt.ctrl_hdr.conn_id);
+	if (OFI_UNLIKELY(!rx_buf->conn))
+		return -FI_EOTHER;
+
+	resp_buf = (struct rxm_tx_atomic_buf *)
+		   rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX_ATOMIC);
+	if (OFI_UNLIKELY(!resp_buf)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Unable to allocate from Atomic buffer pool\n");
+		/* TODO: Should this be -FI_ENOMEM - how does it get
+		 * processed again */
+		return -FI_EAGAIN;
+	}
+
+	for (i = 0; i < rx_buf->pkt.hdr.atomic.ioc_count; i++) {
+		ret = ofi_mr_verify(&domain->util_domain.mr_map,
+				    req_hdr->rma_ioc[i].count * datatype_sz,
+				    (uintptr_t *)&req_hdr->rma_ioc[i].addr,
+				    req_hdr->rma_ioc[i].key,
+				    ofi_rx_mr_reg_flags(rx_buf->pkt.hdr.op,
+							atomic_op));
+		if (ret) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+				"Atomic RMA MR verify error %d\n", ret);
+			ret = -FI_EACCES;
+			goto send_nak;
+		}
+	}
+
+	len = ofi_total_rma_ioc_cnt(req_hdr->rma_ioc,
+			rx_buf->pkt.hdr.atomic.ioc_count) * datatype_sz;
+	resp_hdr = (struct rxm_atomic_resp_hdr *) resp_buf->pkt.data;
+
+	for (i = 0, offset = 0; i < rx_buf->pkt.hdr.atomic.ioc_count; i++) {
+		rxm_do_atomic(&rx_buf->pkt,
+			      (uintptr_t *) req_hdr->rma_ioc[i].addr,
+			      req_hdr->data + offset,
+			      req_hdr->data + len + offset,
+			      resp_hdr->data + offset,
+			      req_hdr->rma_ioc[i].count, datatype, atomic_op);
+		offset += req_hdr->rma_ioc[i].count * datatype_sz;
+	}
+	result_len = rx_buf->pkt.hdr.op == ofi_op_atomic ? 0 : offset;
+
+	if (rx_buf->pkt.hdr.op == ofi_op_atomic)
+		ofi_ep_rem_wr_cntr_inc(&rxm_ep->util_ep);
+	else
+		ofi_ep_rem_rd_cntr_inc(&rxm_ep->util_ep);
+
+	return rxm_atomic_send_resp(rxm_ep, rx_buf, resp_buf,
+				    result_len, FI_SUCCESS);
+send_nak:
+	return rxm_atomic_send_resp(rxm_ep, rx_buf, resp_buf, 0, ret);
+}
+
+
+static inline ssize_t rxm_handle_atomic_resp(struct rxm_ep *rxm_ep,
+					     struct rxm_rx_buf *rx_buf)
+{
+	struct rxm_tx_atomic_buf *tx_buf;
+	struct rxm_atomic_resp_hdr *resp_hdr =
+			(struct rxm_atomic_resp_hdr *) rx_buf->pkt.data;
+	uint64_t len;
+	int ret = 0;
+
+	tx_buf = rxm_msg_id_2_tx_buf(rxm_ep, RXM_BUF_POOL_TX_ATOMIC,
+				     rx_buf->pkt.ctrl_hdr.msg_id);
+	FI_DBG(&rxm_prov, FI_LOG_CQ,
+	       "Received Atomic Response for msg_id: 0x%" PRIx64 "\n",
+	       rx_buf->pkt.ctrl_hdr.msg_id);
+
+	assert(!(rx_buf->comp_flags & ~(FI_RECV | FI_REMOTE_CQ_DATA)));
+
+	if (resp_hdr->status) {
+		FI_DBG(&rxm_prov, FI_LOG_CQ,
+		       "Bad Atomic response status %d\n", ntohl(resp_hdr->status));
+		rxm_cq_write_error(rxm_ep->util_ep.tx_cq,
+				   rxm_ep->util_ep.tx_cntr,
+				   tx_buf->app_context, ntohl(resp_hdr->status));
+		goto done;
+	}
+
+	len = ofi_total_iov_len(tx_buf->result_iov, tx_buf->result_iov_count);
+	assert(ntohl(resp_hdr->result_len) == len);
+	ofi_copy_to_iov(tx_buf->result_iov, tx_buf->result_iov_count, 0,
+			resp_hdr->data, len);
+
+	if (!(tx_buf->flags & FI_INJECT))
+		ret = rxm_cq_tx_comp_write(rxm_ep,
+					   ofi_tx_cq_flags(tx_buf->pkt.hdr.op),
+					   tx_buf->app_context, tx_buf->flags);
+done:
+	if (tx_buf->pkt.hdr.atomic.op == ofi_op_atomic)
+		ofi_ep_wr_cntr_inc(&rxm_ep->util_ep);
+	else
+		ofi_ep_rd_cntr_inc(&rxm_ep->util_ep);
+
+	rxm_rx_buf_release(rxm_ep, rx_buf);
+	rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_ATOMIC, tx_buf);
+
+	return ret;
+}
+
 static ssize_t rxm_cq_handle_comp(struct rxm_ep *rxm_ep,
-				  struct fi_cq_tagged_entry *comp)
+				  struct fi_cq_data_entry *comp)
 {
-	struct rxm_rx_buf *rx_buf = comp->op_context;
-	struct rxm_tx_entry *tx_entry = comp->op_context;
+	ssize_t ret;
+	struct rxm_rx_buf *rx_buf;
+	struct rxm_tx_sar_buf *tx_sar_buf;
+	struct rxm_tx_eager_buf *tx_eager_buf;
+	struct rxm_tx_rndv_buf *tx_rndv_buf;
+	struct rxm_tx_atomic_buf *tx_atomic_buf;
+	struct rxm_rma_buf *rma_buf;
 
 	/* Remote write events may not consume a posted recv so op context
 	 * and hence state would be NULL */
 	if (comp->flags & FI_REMOTE_WRITE)
 		return rxm_handle_remote_write(rxm_ep, comp);
 
-	switch (RXM_GET_PROTO_STATE(comp)) {
-	case RXM_TX_NOBUF:
-		assert(comp->flags & (FI_SEND | FI_WRITE | FI_READ));
-		if (tx_entry->ep->msg_mr_local && !tx_entry->ep->rxm_mr_local)
-			rxm_ep_msg_mr_closev(tx_entry->mr, tx_entry->count);
-		return rxm_finish_send_nobuf(tx_entry);
+	switch (RXM_GET_PROTO_STATE(comp->op_context)) {
 	case RXM_TX:
+	case RXM_INJECT_TX:
+		tx_eager_buf = comp->op_context;
 		assert(comp->flags & FI_SEND);
-		return rxm_finish_send(tx_entry);
-	case RXM_TX_RMA:
-		assert(comp->flags & (FI_WRITE | FI_READ));
-		if (tx_entry->ep->msg_mr_local && !tx_entry->ep->rxm_mr_local)
-			rxm_ep_msg_mr_closev(tx_entry->mr, tx_entry->count);
-		rxm_rma_buf_release(rxm_ep, tx_entry->rma_buf);
-		return rxm_finish_send_nobuf(tx_entry);
+		ret = rxm_finish_eager_send(rxm_ep, tx_eager_buf);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX, tx_eager_buf);
+		return ret;
+	case RXM_SAR_TX:
+		tx_sar_buf = comp->op_context;
+		assert(comp->flags & FI_SEND);
+		return rxm_finish_sar_segment_send(rxm_ep, tx_sar_buf);
+	case RXM_RMA:
+		rma_buf = comp->op_context;
+		assert((comp->flags & (FI_WRITE | FI_RMA)) ||
+		       (comp->flags & (FI_READ | FI_RMA)));
+		return rxm_finish_rma(rxm_ep, rma_buf, comp->flags);
 	case RXM_RX:
+		rx_buf = comp->op_context;
 		assert(!(comp->flags & FI_REMOTE_READ));
 		assert((rx_buf->pkt.hdr.version == OFI_OP_VERSION) &&
-		       (rx_buf->pkt.ctrl_hdr.version == OFI_CTRL_VERSION));
+		       (rx_buf->pkt.ctrl_hdr.version == RXM_CTRL_VERSION));
 
-		if (rx_buf->pkt.ctrl_hdr.type == ofi_ctrl_ack)
-			return rxm_lmt_handle_ack(rx_buf);
-		else
+		switch (rx_buf->pkt.ctrl_hdr.type) {
+		case ofi_ctrl_data:
+		case ofi_ctrl_large_data:
 			return rxm_handle_recv_comp(rx_buf);
-	case RXM_LMT_TX:
+		case ofi_ctrl_ack:
+			return rxm_rndv_handle_ack(rxm_ep, rx_buf);
+		case ofi_ctrl_seg_data:
+			return rxm_sar_handle_segment(rx_buf);
+		case ofi_ctrl_atomic:
+			return rxm_handle_atomic_req(rxm_ep, rx_buf);
+		case ofi_ctrl_atomic_resp:
+			return rxm_handle_atomic_resp(rxm_ep, rx_buf);
+		default:
+			FI_WARN(&rxm_prov, FI_LOG_CQ, "Unknown message type\n");
+			assert(0);
+			return -FI_EINVAL;
+		}
+	case RXM_RNDV_TX:
+		tx_rndv_buf = comp->op_context;
 		assert(comp->flags & FI_SEND);
-		RXM_LOG_STATE_TX(FI_LOG_CQ, tx_entry, RXM_LMT_ACK_WAIT);
-		RXM_SET_PROTO_STATE(comp, RXM_LMT_ACK_WAIT);
+		RXM_LOG_STATE_TX(FI_LOG_CQ, tx_rndv_buf, RXM_RNDV_ACK_WAIT);
+		RXM_SET_PROTO_STATE(comp, RXM_RNDV_ACK_WAIT);
 		return 0;
-	case RXM_LMT_ACK_RECVD:
+	case RXM_RNDV_ACK_RECVD:
+		tx_rndv_buf = comp->op_context;
 		assert(comp->flags & FI_SEND);
-		return rxm_lmt_tx_finish(tx_entry);
-	case RXM_LMT_READ:
+		return rxm_rndv_tx_finish(rxm_ep, tx_rndv_buf);
+	case RXM_RNDV_READ:
+		rx_buf = comp->op_context;
 		assert(comp->flags & FI_READ);
-		if (rx_buf->index < rx_buf->rma_iov->count)
-			return rxm_lmt_rma_read(rx_buf);
-		else if (sizeof(rx_buf->pkt) > rxm_ep->msg_info->tx_attr->inject_size)
-			return rxm_lmt_send_ack(rx_buf);
+		if (++rx_buf->rndv_rma_index < rx_buf->rndv_hdr->count)
+			return 0;
+		else if (sizeof(rx_buf->pkt) <= rxm_ep->inject_limit)
+			return rxm_rndv_send_ack_fast(rx_buf);
 		else
-			return rxm_lmt_send_ack_fast(rx_buf);
-	case RXM_LMT_ACK_SENT:
+			return rxm_rndv_send_ack(rx_buf);
+	case RXM_RNDV_ACK_SENT:
+		rx_buf = comp->op_context;
+		assert(comp->flags & FI_SEND);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_ACK,
+				   rx_buf->recv_entry->rndv.tx_buf);
+		return rxm_finish_send_rndv_ack(rx_buf);
+	case RXM_ATOMIC_RESP_SENT:
+		tx_atomic_buf = comp->op_context;
+		assert(comp->flags & FI_SEND);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_ATOMIC,
+				   tx_atomic_buf);
+		return 0;
+	case RXM_ATOMIC_RESP_WAIT:
+		/* Optional atomic request completion; TX completion
+		 * processing is performed when atomic response is received */
 		assert(comp->flags & FI_SEND);
-		rx_buf = tx_entry->context;
-		rxm_tx_buf_release(rx_buf->ep, tx_entry->tx_buf);
-		rxm_tx_entry_release(&tx_entry->ep->send_queue, tx_entry);
-		return rxm_finish_send_lmt_ack(rx_buf);
+		return 0;
 	default:
 		FI_WARN(&rxm_prov, FI_LOG_CQ, "Invalid state!\n");
 		assert(0);
@@ -665,81 +1081,149 @@ static ssize_t rxm_cq_handle_comp(struct rxm_ep *rxm_ep,
 	}
 }
 
-static ssize_t rxm_cq_write_error(struct fid_cq *msg_cq,
-				  struct fi_cq_tagged_entry *comp,
-				  ssize_t err)
+void rxm_cq_write_error(struct util_cq *cq, struct util_cntr *cntr,
+			void *op_context, int err)
+{
+	struct fi_cq_err_entry err_entry = {0};
+	err_entry.op_context = op_context;
+	err_entry.prov_errno = err;
+	err_entry.err = err;
+
+	if (cntr)
+		rxm_cntr_incerr(cntr);
+	if (ofi_cq_write_error(cq, &err_entry)) {
+		FI_WARN(&rxm_prov, FI_LOG_CQ, "Unable to ofi_cq_write_error\n");
+		assert(0);
+	}
+}
+
+static void rxm_cq_write_error_all(struct rxm_ep *rxm_ep, int err)
+{
+	struct fi_cq_err_entry err_entry = {0};
+	ssize_t ret = 0;
+
+	err_entry.prov_errno = err;
+	err_entry.err = err;
+	if (rxm_ep->util_ep.tx_cq) {
+		ret = ofi_cq_write_error(rxm_ep->util_ep.tx_cq, &err_entry);
+		if (ret) {
+			FI_WARN(&rxm_prov, FI_LOG_CQ,
+				"Unable to ofi_cq_write_error\n");
+			assert(0);
+		}
+	}
+	if (rxm_ep->util_ep.rx_cq) {
+		ret = ofi_cq_write_error(rxm_ep->util_ep.rx_cq, &err_entry);
+		if (ret) {
+			FI_WARN(&rxm_prov, FI_LOG_CQ,
+				"Unable to ofi_cq_write_error\n");
+			assert(0);
+		}
+	}
+	if (rxm_ep->util_ep.tx_cntr)
+		rxm_cntr_incerr(rxm_ep->util_ep.tx_cntr);
+
+	if (rxm_ep->util_ep.rx_cntr)
+		rxm_cntr_incerr(rxm_ep->util_ep.rx_cntr);
+
+	if (rxm_ep->util_ep.wr_cntr)
+		rxm_cntr_incerr(rxm_ep->util_ep.wr_cntr);
+
+	if (rxm_ep->util_ep.rd_cntr)
+		rxm_cntr_incerr(rxm_ep->util_ep.rd_cntr);
+}
+
+#define RXM_IS_PROTO_STATE_TX(state)	\
+	((state == RXM_SAR_TX) ||	\
+	 (state == RXM_TX) ||		\
+	 (state == RXM_RNDV_TX))
+
+static void rxm_cq_read_write_error(struct rxm_ep *rxm_ep)
 {
-	struct rxm_tx_entry *tx_entry;
+	struct rxm_tx_eager_buf *eager_buf;
+	struct rxm_tx_sar_buf *sar_buf;
+	struct rxm_tx_rndv_buf *rndv_buf;
 	struct rxm_rx_buf *rx_buf;
-	struct fi_cq_err_entry err_entry;
-	struct util_cq *util_cq;
+	struct fi_cq_err_entry err_entry = {0};
+	struct util_cq *util_cq = NULL;
 	struct util_cntr *util_cntr = NULL;
-	void *op_context;
+	enum rxm_proto_state state = RXM_GET_PROTO_STATE(err_entry.op_context);
 	ssize_t ret;
 
-	op_context = comp->op_context;
-	memset(&err_entry, 0, sizeof(err_entry));
+	RXM_CQ_READERR(&rxm_prov, FI_LOG_CQ, rxm_ep->msg_cq, ret,
+		       err_entry);
+	if (ret < 0) {
+		FI_WARN(&rxm_prov, FI_LOG_CQ,
+			"Unable to fi_cq_readerr on msg cq\n");
+		rxm_cq_write_error_all(rxm_ep, (int)ret);
+		return;
+	}
 
-	if (err == -FI_EAVAIL) {
-		OFI_CQ_READERR(&rxm_prov, FI_LOG_CQ, msg_cq, ret, err_entry);
-		if (ret < 0) {
-			FI_WARN(&rxm_prov, FI_LOG_CQ,
-					"Unable to fi_cq_readerr on msg cq\n");
-			err_entry.prov_errno = (int)ret;
-			err = ret;
-		} else {
-			op_context = err_entry.op_context;
-		}
-	} else {
-		err_entry.prov_errno = (int)err;
+	if (RXM_IS_PROTO_STATE_TX(state)) {
+		util_cq = rxm_ep->util_ep.tx_cq;
+		util_cntr = rxm_ep->util_ep.tx_cntr;
 	}
 
-	switch (RXM_GET_PROTO_STATE(comp)) {
+	switch (state) {
+	case RXM_SAR_TX:
+		assert(err_entry.flags & FI_SEND);
+		sar_buf = err_entry.op_context;
+		err_entry.op_context = sar_buf->app_context;
+		err_entry.flags = ofi_tx_cq_flags(sar_buf->pkt.hdr.op);
+		break;
 	case RXM_TX:
-	case RXM_LMT_TX:
-		tx_entry = (struct rxm_tx_entry *)op_context;
-		util_cq = tx_entry->ep->util_ep.tx_cq;
-		if (tx_entry->ep->util_ep.flags & OFI_CNTR_ENABLED) {
-			if (tx_entry->comp_flags & FI_SEND)
-				util_cntr = tx_entry->ep->util_ep.tx_cntr;
-			else if (tx_entry->comp_flags & FI_WRITE)
-				util_cntr = tx_entry->ep->util_ep.wr_cntr;
-			else
-				util_cntr = tx_entry->ep->util_ep.rd_cntr;
-		}
+		assert(err_entry.flags & FI_SEND);
+		eager_buf = err_entry.op_context;
+		err_entry.op_context = eager_buf->app_context;
+		err_entry.flags = ofi_tx_cq_flags(eager_buf->pkt.hdr.op);
 		break;
-	case RXM_LMT_ACK_SENT:
-		tx_entry = (struct rxm_tx_entry *)op_context;
-		util_cq = tx_entry->ep->util_ep.rx_cq;
-		util_cntr = tx_entry->ep->util_ep.rx_cntr;
+	case RXM_RNDV_TX:
+		assert(err_entry.flags & FI_SEND);
+		rndv_buf = err_entry.op_context;
+		err_entry.op_context = rndv_buf->app_context;
+		err_entry.flags = ofi_tx_cq_flags(rndv_buf->pkt.hdr.op);
 		break;
+	case RXM_RNDV_ACK_SENT:
+		/* fall through */
 	case RXM_RX:
-	case RXM_LMT_READ:
-		rx_buf = (struct rxm_rx_buf *)op_context;
+		/* fall through */
+	case RXM_RNDV_READ:
+		assert(((state == RXM_RNDV_ACK_SENT) && (err_entry.flags & FI_SEND)) ||
+		       ((state == RXM_RX) && (err_entry.flags & FI_RECV)) ||
+		       ((state == RXM_RNDV_READ) && (err_entry.flags & FI_READ)));
+		rx_buf = (struct rxm_rx_buf *)err_entry.op_context;
 		util_cq = rx_buf->ep->util_ep.rx_cq;
 		util_cntr = rx_buf->ep->util_ep.rx_cntr;
+		err_entry.op_context = rx_buf->recv_entry->context;
+		err_entry.flags = rx_buf->recv_entry->comp_flags;
 		break;
 	default:
 		FI_WARN(&rxm_prov, FI_LOG_CQ, "Invalid state!\n");
-		if (err == -FI_EAVAIL)
-			FI_WARN(&rxm_prov, FI_LOG_CQ, "msg cq error info: %s\n",
-				fi_cq_strerror(msg_cq, err_entry.prov_errno,
-					       err_entry.err_data, NULL, 0));
-		return -FI_EOPBADSTATE;
+		FI_WARN(&rxm_prov, FI_LOG_CQ, "msg cq error info: %s\n",
+			fi_cq_strerror(rxm_ep->msg_cq, err_entry.prov_errno,
+				       err_entry.err_data, NULL, 0));
+		rxm_cq_write_error_all(rxm_ep, -FI_EOPBADSTATE);
+	}
+	if (util_cntr)
+		rxm_cntr_incerr(util_cntr);
+	if (util_cq) {
+		ret = ofi_cq_write_error(util_cq, &err_entry);
+		if (ret) {
+			FI_WARN(&rxm_prov, FI_LOG_CQ, "Unable to ofi_cq_write_error\n");
+			assert(0);
+		}
 	}
-	rxm_cntr_incerr(util_cntr);
-	return ofi_cq_write_error(util_cq, &err_entry);
 }
 
 static inline int rxm_ep_repost_buf(struct rxm_rx_buf *rx_buf)
 {
-	rx_buf->conn = NULL;
+	if (rx_buf->ep->srx_ctx)
+		rx_buf->conn = NULL;
 	rx_buf->hdr.state = RXM_RX;
 
-	if (fi_recv(rx_buf->hdr.msg_ep, &rx_buf->pkt,
-		    rx_buf->ep->rxm_info->tx_attr->inject_size +
-		    sizeof(struct rxm_pkt), rx_buf->hdr.desc,
-		    FI_ADDR_UNSPEC, rx_buf)) {
+	if (fi_recv(rx_buf->msg_ep, &rx_buf->pkt,
+		    rx_buf->ep->eager_limit + sizeof(struct rxm_pkt),
+		    rx_buf->hdr.desc, FI_ADDR_UNSPEC, rx_buf)) {
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to repost buf\n");
 		return -FI_EAVAIL;
 	}
@@ -753,188 +1237,82 @@ int rxm_ep_prepost_buf(struct rxm_ep *rxm_ep, struct fid_ep *msg_ep)
 	size_t i;
 
 	for (i = 0; i < rxm_ep->msg_info->rx_attr->size; i++) {
-		rx_buf = rxm_rx_buf_get(rxm_ep);
-		if (OFI_UNLIKELY(!rx_buf))
+		rx_buf = rxm_rx_buf_alloc(rxm_ep);
+		if (OFI_UNLIKELY(!rx_buf)) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+				"Ran out of buffers from RX buffer pool\n");
 			return -FI_ENOMEM;
+		}
 
 		rx_buf->hdr.state = RXM_RX;
-		rx_buf->hdr.msg_ep = msg_ep;
+		rx_buf->msg_ep = msg_ep;
 		rx_buf->repost = 1;
 
+		if (!rxm_ep->srx_ctx)
+			rx_buf->conn = container_of(msg_ep->fid.context,
+						    struct rxm_conn,
+						    handle);
 		ret = rxm_ep_repost_buf(rx_buf);
 		if (ret) {
-			rxm_rx_buf_release(rxm_ep, rx_buf);
+			rxm_buf_release(&rxm_ep->buf_pools[RXM_BUF_POOL_RX],
+					&rx_buf->hdr);
 			return ret;
 		}
-		dlist_insert_tail(&rx_buf->entry, &rxm_ep->post_rx_list);
 	}
 	return 0;
 }
 
-static inline void rxm_cq_repost_rx_buffers(struct rxm_ep *rxm_ep)
+void rxm_ep_do_progress(struct util_ep *util_ep)
 {
+	struct rxm_ep *rxm_ep = container_of(util_ep, struct rxm_ep, util_ep);
+	struct fi_cq_data_entry comp;
+	struct dlist_entry *conn_entry_tmp;
+	struct rxm_conn *rxm_conn;
 	struct rxm_rx_buf *buf;
-	fastlock_acquire(&rxm_ep->util_ep.lock);
+	ssize_t ret;
+	size_t comp_read = 0;
+
+	if (!slistfd_empty(&rxm_ep->msg_eq_entry_list))
+		rxm_conn_process_eq_events(rxm_ep);
+
 	while (!dlist_empty(&rxm_ep->repost_ready_list)) {
 		dlist_pop_front(&rxm_ep->repost_ready_list, struct rxm_rx_buf,
 				buf, repost_entry);
 		(void) rxm_ep_repost_buf(buf);
 	}
-	fastlock_release(&rxm_ep->util_ep.lock);
-}
-
-static int rxm_cq_reprocess_directed_recvs(struct rxm_recv_queue *recv_queue)
-{
-	struct rxm_rx_buf *rx_buf;
-	struct dlist_entry *entry, *tmp_entry;
-	struct rxm_recv_match_attr match_attr;
-	struct dlist_entry rx_buf_list;
-	struct fi_cq_err_entry err_entry = {0};
-	int ret, count = 0;
-
-	dlist_init(&rx_buf_list);
-
-	fastlock_acquire(&recv_queue->rxm_ep->util_ep.cmap->lock);
-	fastlock_acquire(&recv_queue->lock);
-
-	dlist_foreach_container_safe(&recv_queue->unexp_msg_list,
-				     struct rxm_rx_buf, rx_buf,
-				     unexp_msg.entry, tmp_entry) {
-		if (rx_buf->unexp_msg.addr == rx_buf->conn->handle.fi_addr)
-			continue;
-
-		assert(rx_buf->unexp_msg.addr == FI_ADDR_NOTAVAIL);
-
-		match_attr.addr = rx_buf->unexp_msg.addr =
-			rx_buf->conn->handle.fi_addr;
-		match_attr.tag = rx_buf->unexp_msg.tag;
-
-		entry = dlist_remove_first_match(&recv_queue->recv_list,
-						 recv_queue->match_recv,
-						 &match_attr);
-		if (!entry)
-			continue;
-
-		dlist_remove(&rx_buf->unexp_msg.entry);
-		rx_buf->recv_entry = container_of(entry, struct rxm_recv_entry,
-						  entry);
-		dlist_insert_tail(&rx_buf->unexp_msg.entry, &rx_buf_list);
-	}
-	fastlock_release(&recv_queue->lock);
-	fastlock_release(&recv_queue->rxm_ep->util_ep.cmap->lock);
 
-	while (!dlist_empty(&rx_buf_list)) {
-		dlist_pop_front(&rx_buf_list, struct rxm_rx_buf,
-				rx_buf, unexp_msg.entry);
-		ret = rxm_cq_handle_data(rx_buf);
-		if (ret) {
-			err_entry.op_context = rx_buf;
-			err_entry.flags = rx_buf->recv_entry->comp_flags;
-			err_entry.len = rx_buf->pkt.hdr.size;
-			err_entry.data = rx_buf->pkt.hdr.data;
-			err_entry.tag = rx_buf->pkt.hdr.tag;
-			err_entry.err = ret;
-			err_entry.prov_errno = ret;
-			ofi_cq_write_error(recv_queue->rxm_ep->util_ep.rx_cq,
-					   &err_entry);
-			if (rx_buf->ep->util_ep.flags & OFI_CNTR_ENABLED)
-				rxm_cntr_incerr(rx_buf->ep->util_ep.rx_cntr);
-
-			rxm_enqueue_repost_ready_list(rx_buf);
-
-			if (!(rx_buf->recv_entry->flags & FI_MULTI_RECV))
-				rxm_recv_entry_release(recv_queue,
-						       rx_buf->recv_entry);
+	do {
+		ret = fi_cq_read(rxm_ep->msg_cq, &comp, 1);
+		if (ret > 0) {
+			// We don't have enough info to write a good
+			// error entry to the CQ at this point
+			ret = rxm_cq_handle_comp(rxm_ep, &comp);
+			if (OFI_UNLIKELY(ret)) {
+				rxm_cq_write_error_all(rxm_ep, ret);
+			} else {
+				ret = 1;
+			}
+		} else if (ret < 0 && (ret != -FI_EAGAIN)) {
+			if (ret == -FI_EAVAIL)
+				rxm_cq_read_write_error(rxm_ep);
+			else
+				rxm_cq_write_error_all(rxm_ep, ret);
 		}
-		count++;
-	}
-	return count;
-}
-
-static int rxm_cq_reprocess_recv_queues(struct rxm_ep *rxm_ep)
-{
-	int count = 0;
-
-	fastlock_acquire(&rxm_ep->util_ep.cmap->lock);
-
-	if (!rxm_ep->util_ep.cmap->av_updated) {
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
-		return 0;
-	}
-
-	rxm_ep->util_ep.cmap->av_updated = 0;
-	fastlock_release(&rxm_ep->util_ep.cmap->lock);
-
-	count += rxm_cq_reprocess_directed_recvs(&rxm_ep->recv_queue);
-	count += rxm_cq_reprocess_directed_recvs(&rxm_ep->trecv_queue);
-	return count;
-}
-
-void rxm_ep_progress_one(struct util_ep *util_ep)
-{
-	struct rxm_ep *rxm_ep =
-		container_of(util_ep, struct rxm_ep, util_ep);
-	struct fi_cq_tagged_entry comp;
-	ssize_t ret;
-
-	rxm_cq_repost_rx_buffers(rxm_ep);
+	} while ((ret > 0) && (++comp_read < rxm_ep->comp_per_progress));
 
-	if (OFI_UNLIKELY(rxm_ep->util_ep.cmap->av_updated)) {
-		ret = rxm_cq_reprocess_recv_queues(rxm_ep);
-		if (ret > 0)
-			return;
+	if (OFI_UNLIKELY(!dlist_empty(&rxm_ep->deferred_tx_conn_queue))) {
+		dlist_foreach_container_safe(&rxm_ep->deferred_tx_conn_queue,
+					     struct rxm_conn, rxm_conn,
+					     deferred_conn_entry, conn_entry_tmp)
+			rxm_ep_progress_deferred_queue(rxm_ep, rxm_conn);
 	}
-
-	ret = fi_cq_read(rxm_ep->msg_cq, &comp, 1);
-	if (ret == -FI_EAGAIN || !ret)
-		return;
-	if (OFI_UNLIKELY(ret < 0))
-		goto err;
-
-	ret = rxm_cq_handle_comp(rxm_ep, &comp);
-	if (OFI_UNLIKELY(ret))
-		goto err;
-
-	return;
-err:
-	if (rxm_cq_write_error(rxm_ep->msg_cq, &comp, ret))
-		assert(0);
 }
 
-void rxm_ep_progress_multi(struct util_ep *util_ep)
+void rxm_ep_progress(struct util_ep *util_ep)
 {
-	struct rxm_ep *rxm_ep =
-		container_of(util_ep, struct rxm_ep, util_ep);
-	struct fi_cq_tagged_entry comp;
-	ssize_t ret;
-	size_t comp_read = 0;
-
-	rxm_cq_repost_rx_buffers(rxm_ep);
-
-	if (OFI_UNLIKELY(rxm_ep->util_ep.cmap->av_updated)) {
-		ret = rxm_cq_reprocess_recv_queues(rxm_ep);
-		if (ret > 0)
-			return;
-	}
-
-	do {
-		ret = fi_cq_read(rxm_ep->msg_cq, &comp, 1);
-		if (ret == -FI_EAGAIN)
-			return;
-		if (OFI_UNLIKELY(ret < 0))
-			goto err;
-		if (ret) {
-			ret = rxm_cq_handle_comp(rxm_ep, &comp);
-			if (OFI_UNLIKELY(ret))
-				goto err;
-			comp_read++;
-		}
-	} while (comp_read < rxm_ep->comp_per_progress);
-
-	return;
-err:
-	if (rxm_cq_write_error(rxm_ep->msg_cq, &comp, ret))
-		assert(0);
+	ofi_ep_lock_acquire(util_ep);
+	rxm_ep_do_progress(util_ep);
+	ofi_ep_lock_release(util_ep);
 }
 
 static int rxm_cq_close(struct fid *fid)
@@ -956,7 +1334,7 @@ static struct fi_ops rxm_cq_fi_ops = {
 	.size = sizeof(struct fi_ops),
 	.close = rxm_cq_close,
 	.bind = fi_no_bind,
-	.control = fi_no_control,
+	.control = ofi_cq_control,
 	.ops_open = fi_no_ops_open,
 };
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_domain.c
index 5000f4556..1d7d0f39f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_domain.c
@@ -60,15 +60,9 @@ free:
 	return ret;
 }
 
-int rxm_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
-		  struct fid_av **av, void *context)
-{
-	return ip_av_create_flags(domain_fid, attr, av, context, OFI_AV_HASH);
-}
-
 static struct fi_ops_domain rxm_domain_ops = {
 	.size = sizeof(struct fi_ops_domain),
-	.av_open = rxm_av_create,
+	.av_open = rxm_av_open,
 	.cq_open = rxm_cq_open,
 	.endpoint = rxm_endpoint,
 	.scalable_ep = fi_no_scalable_ep,
@@ -76,9 +70,40 @@ static struct fi_ops_domain rxm_domain_ops = {
 	.poll_open = fi_poll_create,
 	.stx_ctx = fi_no_stx_context,
 	.srx_ctx = fi_no_srx_context,
-	.query_atomic = fi_no_query_atomic,
+	.query_atomic = rxm_ep_query_atomic,
 };
 
+static void rxm_mr_remove_map_entry(struct rxm_mr *mr)
+{
+	fastlock_acquire(&mr->domain->util_domain.lock);
+	(void) ofi_mr_map_remove(&mr->domain->util_domain.mr_map,
+				 mr->mr_fid.key);
+	fastlock_release(&mr->domain->util_domain.lock);
+}
+
+static int rxm_mr_add_map_entry(struct util_domain *domain,
+				struct fi_mr_attr *msg_attr,
+				struct rxm_mr *rxm_mr)
+{
+	uint64_t temp_key;
+	int ret;
+
+	msg_attr->requested_key = rxm_mr->mr_fid.key;
+
+	fastlock_acquire(&domain->lock);
+	ret = ofi_mr_map_insert(&domain->mr_map, msg_attr, &temp_key, rxm_mr);
+	if (OFI_UNLIKELY(ret)) {
+		FI_WARN(&rxm_prov, FI_LOG_DOMAIN,
+			"MR map insert for atomic verification failed %d\n",
+			ret);
+	} else {
+		assert(rxm_mr->mr_fid.key == temp_key);
+	}
+	fastlock_release(&domain->lock);
+
+	return ret;
+}
+
 static int rxm_domain_close(fid_t fid)
 {
 	struct rxm_domain *rxm_domain;
@@ -112,9 +137,15 @@ static int rxm_mr_close(fid_t fid)
 	int ret;
 
 	rxm_mr = container_of(fid, struct rxm_mr, mr_fid.fid);
+
+	if (rxm_mr->domain->util_domain.info_domain_caps & FI_ATOMIC)
+		rxm_mr_remove_map_entry(rxm_mr);
+
 	ret = fi_close(&rxm_mr->msg_mr->fid);
 	if (ret)
 		FI_WARN(&rxm_prov, FI_LOG_DOMAIN, "Unable to close MSG MR\n");
+
+	ofi_atomic_dec32(&rxm_mr->domain->util_domain.ref);
 	free(rxm_mr);
 	return ret;
 }
@@ -127,55 +158,143 @@ static struct fi_ops rxm_mr_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
-static int rxm_mr_reg(struct fid *domain_fid, const void *buf, size_t len,
-	   uint64_t access, uint64_t offset, uint64_t requested_key,
-	   uint64_t flags, struct fid_mr **mr, void *context)
+static uint64_t
+rxm_mr_get_msg_access(struct rxm_domain *rxm_domain, uint64_t access)
+{
+	/* Additional flags to use RMA read for large message transfers */
+	access |= FI_READ | FI_REMOTE_READ;
+
+	if (rxm_domain->mr_local)
+		access |= FI_WRITE;
+	return access;
+}
+
+static void rxm_mr_init(struct rxm_mr *rxm_mr, struct rxm_domain *domain,
+			void *context)
+{
+	rxm_mr->mr_fid.fid.fclass = FI_CLASS_MR;
+	rxm_mr->mr_fid.fid.context = context;
+	rxm_mr->mr_fid.fid.ops = &rxm_mr_ops;
+	/* Store msg_mr as rxm_mr descriptor so that we can get its key when
+	 * the app passes msg_mr as the descriptor in fi_send and friends.
+	 * The key would be used in large message transfer protocol and RMA. */
+	rxm_mr->mr_fid.mem_desc = rxm_mr->msg_mr;
+	rxm_mr->mr_fid.key = fi_mr_key(rxm_mr->msg_mr);
+	rxm_mr->domain = domain;
+	ofi_atomic_inc32(&domain->util_domain.ref);
+}
+
+static int rxm_mr_regattr(struct fid *fid, const struct fi_mr_attr *attr,
+			  uint64_t flags, struct fid_mr **mr)
 {
 	struct rxm_domain *rxm_domain;
+	struct fi_mr_attr msg_attr = *attr;
 	struct rxm_mr *rxm_mr;
 	int ret;
 
-	rxm_domain = container_of(domain_fid, struct rxm_domain,
-			util_domain.domain_fid.fid);
+	rxm_domain = container_of(fid, struct rxm_domain,
+				  util_domain.domain_fid.fid);
 
 	rxm_mr = calloc(1, sizeof(*rxm_mr));
 	if (!rxm_mr)
 		return -FI_ENOMEM;
 
-	/* Additional flags to use RMA read for large message transfers */
-	access |= FI_READ | FI_REMOTE_READ;
-
-	if (rxm_domain->mr_local)
-		access |= FI_WRITE;
+	msg_attr.access = rxm_mr_get_msg_access(rxm_domain, attr->access);
 
-	ret = fi_mr_reg(rxm_domain->msg_domain, buf, len, access, offset, requested_key,
-			flags, &rxm_mr->msg_mr, context);
+	ret = fi_mr_regattr(rxm_domain->msg_domain, &msg_attr,
+			    flags, &rxm_mr->msg_mr);
 	if (ret) {
 		FI_WARN(&rxm_prov, FI_LOG_DOMAIN, "Unable to register MSG MR\n");
 		goto err;
 	}
+	rxm_mr_init(rxm_mr, rxm_domain, attr->context);
+	*mr = &rxm_mr->mr_fid;
 
-	rxm_mr->mr_fid.fid.fclass = FI_CLASS_MR;
-	rxm_mr->mr_fid.fid.context = context;
-	rxm_mr->mr_fid.fid.ops = &rxm_mr_ops;
-	/* Store msg_mr as rxm_mr descriptor so that we can get its key when
-	 * the app passes msg_mr as the descriptor in fi_send and friends.
-	 * The key would be used in large message transfer protocol and RMA. */
-	rxm_mr->mr_fid.mem_desc = rxm_mr->msg_mr;
-	rxm_mr->mr_fid.key = fi_mr_key(rxm_mr->msg_mr);
+	if (rxm_domain->util_domain.info_domain_caps & FI_ATOMIC) {
+		ret = rxm_mr_add_map_entry(&rxm_domain->util_domain,
+					   &msg_attr, rxm_mr);
+		if (ret)
+			goto map_err;
+	}
+
+	return 0;
+
+map_err:
+	fi_close(&rxm_mr->mr_fid.fid);
+	return ret;
+err:
+	free(rxm_mr);
+	return ret;
+
+}
+
+static int rxm_mr_regv(struct fid *fid, const struct iovec *iov, size_t count,
+		       uint64_t access, uint64_t offset, uint64_t requested_key,
+		       uint64_t flags, struct fid_mr **mr, void *context)
+{
+	struct rxm_domain *rxm_domain;
+	struct rxm_mr *rxm_mr;
+	int ret;
+	struct fi_mr_attr msg_attr = {
+		.mr_iov = iov,
+		.iov_count = count,
+		.access = access,
+		.offset = offset,
+		.requested_key = requested_key,
+		.context = context,
+	};
+
+	rxm_domain = container_of(fid, struct rxm_domain,
+				  util_domain.domain_fid.fid);
+
+	rxm_mr = calloc(1, sizeof(*rxm_mr));
+	if (!rxm_mr)
+		return -FI_ENOMEM;
+
+	access = rxm_mr_get_msg_access(rxm_domain, access);
+
+	ret = fi_mr_regv(rxm_domain->msg_domain, iov, count, access, offset,
+			 requested_key, flags, &rxm_mr->msg_mr, context);
+	if (ret) {
+		FI_WARN(&rxm_prov, FI_LOG_DOMAIN, "Unable to register MSG MR\n");
+		goto err;
+	}
+	rxm_mr_init(rxm_mr, rxm_domain, context);
 	*mr = &rxm_mr->mr_fid;
 
+	if (rxm_domain->util_domain.info_domain_caps & FI_ATOMIC) {
+		ret = rxm_mr_add_map_entry(&rxm_domain->util_domain,
+					   &msg_attr, rxm_mr);
+		if (ret)
+			goto map_err;
+	}
+
 	return 0;
+map_err:
+	fi_close(&rxm_mr->mr_fid.fid);
+	return ret;
 err:
 	free(rxm_mr);
 	return ret;
 }
 
+static int rxm_mr_reg(struct fid *fid, const void *buf, size_t len,
+		      uint64_t access, uint64_t offset, uint64_t requested_key,
+		      uint64_t flags, struct fid_mr **mr, void *context)
+{
+	struct iovec iov;
+
+	iov.iov_base = (void *) buf;
+	iov.iov_len = len;
+	return rxm_mr_regv(fid, &iov, 1, access, offset, requested_key,
+			   flags, mr, context);
+}
+
 static struct fi_ops_mr rxm_domain_mr_ops = {
 	.size = sizeof(struct fi_ops_mr),
 	.reg = rxm_mr_reg,
-	.regv = fi_no_mr_regv,
-	.regattr = fi_no_mr_regattr,
+	.regv = rxm_mr_regv,
+	.regattr = rxm_mr_regattr,
 };
 
 int rxm_domain_open(struct fid_fabric *fabric, struct fi_info *info,
@@ -214,14 +333,22 @@ int rxm_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 		goto err3;
 	}
 
+	/* We maintain an RMA key to MR map used for emulated atomic access
+	 * and bounds validation. We turn off the map mode bit FI_MR_PROV_KEY
+	 * since we specify the key used by MSG_EP provider. */
+	rxm_domain->util_domain.mr_map.mode &= ~FI_MR_PROV_KEY;
+
+	/* Must be set to eager size or less */
+	rxm_domain->max_atomic_size = info->tx_attr ?
+				      info->tx_attr->inject_size : 0;
+
 	*domain = &rxm_domain->util_domain.domain_fid;
 	(*domain)->fid.ops = &rxm_domain_fi_ops;
 	/* Replace MR ops set by ofi_domain_init() */
 	(*domain)->mr = &rxm_domain_mr_ops;
 	(*domain)->ops = &rxm_domain_ops;
 
-	rxm_domain->mr_local = OFI_CHECK_MR_LOCAL(msg_info) &&
-				!OFI_CHECK_MR_LOCAL(info);
+	rxm_domain->mr_local = ofi_mr_local(msg_info) && !ofi_mr_local(info);
 
 	fi_freeinfo(msg_info);
 	return 0;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_ep.c
index 683cb6c50..11683c8a0 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_ep.c
@@ -31,62 +31,75 @@
  */
 
 #include <inttypes.h>
+#include <math.h>
 
 #include "ofi.h"
 #include <ofi_util.h>
 
 #include "rxm.h"
 
-#define RXM_EP_RECV_SANITIZE_SRC_ADDR(rxm_ep, src_addr)	\
-	((rxm_ep->rxm_info->caps & FI_DIRECTED_RECV) ?	\
-	 src_addr : FI_ADDR_UNSPEC)
-
-const size_t rxm_pkt_size = sizeof(struct rxm_pkt);
+static int rxm_match_noop(struct dlist_entry *item, const void *arg)
+{
+	OFI_UNUSED(item);
+	OFI_UNUSED(arg);
+	return 1;
+}
 
 static int rxm_match_recv_entry(struct dlist_entry *item, const void *arg)
 {
 	struct rxm_recv_match_attr *attr = (struct rxm_recv_match_attr *) arg;
-	struct rxm_recv_entry *recv_entry;
-
-	recv_entry = container_of(item, struct rxm_recv_entry, entry);
-	return rxm_match_addr(recv_entry->addr, attr->addr);
+	struct rxm_recv_entry *recv_entry =
+		container_of(item, struct rxm_recv_entry, entry);
+	return ofi_match_addr(recv_entry->addr, attr->addr);
 }
 
-static int rxm_match_recv_entry_tagged(struct dlist_entry *item, const void *arg)
+static int rxm_match_recv_entry_tag(struct dlist_entry *item, const void *arg)
 {
 	struct rxm_recv_match_attr *attr = (struct rxm_recv_match_attr *)arg;
-	struct rxm_recv_entry *recv_entry;
+	struct rxm_recv_entry *recv_entry =
+		container_of(item, struct rxm_recv_entry, entry);
+	return ofi_match_tag(recv_entry->tag, recv_entry->ignore, attr->tag);
+}
 
-	recv_entry = container_of(item, struct rxm_recv_entry, entry);
-	return rxm_match_addr(recv_entry->addr, attr->addr) &&
-		rxm_match_tag(recv_entry->tag, recv_entry->ignore, attr->tag);
+static int rxm_match_recv_entry_tag_addr(struct dlist_entry *item, const void *arg)
+{
+	struct rxm_recv_match_attr *attr = (struct rxm_recv_match_attr *)arg;
+	struct rxm_recv_entry *recv_entry =
+		container_of(item, struct rxm_recv_entry, entry);
+	return ofi_match_addr(recv_entry->addr, attr->addr) &&
+		ofi_match_tag(recv_entry->tag, recv_entry->ignore, attr->tag);
 }
 
 static int rxm_match_recv_entry_context(struct dlist_entry *item, const void *context)
 {
-	struct rxm_recv_entry *recv_entry;
-
-	recv_entry = container_of(item, struct rxm_recv_entry, entry);
+	struct rxm_recv_entry *recv_entry =
+		container_of(item, struct rxm_recv_entry, entry);
 	return recv_entry->context == context;
 }
 
 static int rxm_match_unexp_msg(struct dlist_entry *item, const void *arg)
 {
 	struct rxm_recv_match_attr *attr = (struct rxm_recv_match_attr *)arg;
-	struct rxm_unexp_msg *unexp_msg;
-
-	unexp_msg = container_of(item, struct rxm_unexp_msg, entry);
-	return rxm_match_addr(attr->addr, unexp_msg->addr);
+	struct rxm_unexp_msg *unexp_msg =
+		container_of(item, struct rxm_unexp_msg, entry);
+	return ofi_match_addr(attr->addr, unexp_msg->addr);
 }
 
-static int rxm_match_unexp_msg_tagged(struct dlist_entry *item, const void *arg)
+static int rxm_match_unexp_msg_tag(struct dlist_entry *item, const void *arg)
 {
 	struct rxm_recv_match_attr *attr = (struct rxm_recv_match_attr *)arg;
-	struct rxm_unexp_msg *unexp_msg;
+	struct rxm_unexp_msg *unexp_msg =
+		container_of(item, struct rxm_unexp_msg, entry);
+	return ofi_match_tag(attr->tag, attr->ignore, unexp_msg->tag);
+}
 
-	unexp_msg = container_of(item, struct rxm_unexp_msg, entry);
-	return rxm_match_addr(attr->addr, unexp_msg->addr) &&
-		rxm_match_tag(attr->tag, attr->ignore, unexp_msg->tag);
+static int rxm_match_unexp_msg_tag_addr(struct dlist_entry *item, const void *arg)
+{
+	struct rxm_recv_match_attr *attr = (struct rxm_recv_match_attr *)arg;
+	struct rxm_unexp_msg *unexp_msg =
+		container_of(item, struct rxm_unexp_msg, entry);
+	return ofi_match_addr(attr->addr, unexp_msg->addr) &&
+		ofi_match_tag(attr->tag, attr->ignore, unexp_msg->tag);
 }
 
 static inline int
@@ -111,59 +124,127 @@ rxm_mr_buf_reg(struct rxm_ep *rxm_ep, void *addr, size_t len, void **context)
 	return ret;
 }
 
+static void rxm_buf_reg_set_common(struct rxm_buf *hdr, struct rxm_pkt *pkt,
+				   uint8_t type, void *mr_desc)
+{
+	if (pkt) {
+		pkt->ctrl_hdr.version = RXM_CTRL_VERSION;
+		pkt->hdr.version = OFI_OP_VERSION;
+		pkt->ctrl_hdr.type = type;
+	}
+	if (hdr) {
+		hdr->desc = mr_desc;
+	}
+}
+
 static int rxm_buf_reg(void *pool_ctx, void *addr, size_t len, void **context)
 {
 	struct rxm_buf_pool *pool = (struct rxm_buf_pool *)pool_ctx;
 	size_t i, entry_sz = pool->pool->entry_sz;
 	int ret;
-	struct rxm_tx_buf *tx_buf;
-	struct rxm_rx_buf *rx_buf;
 	void *mr_desc;
+	uint8_t type;
+	struct rxm_buf *hdr;
+	struct rxm_pkt *pkt;
+	struct rxm_rx_buf *rx_buf;
+	struct rxm_tx_base_buf *tx_base_buf;
+	struct rxm_tx_eager_buf *tx_eager_buf;
+	struct rxm_tx_sar_buf *tx_sar_buf;
+	struct rxm_tx_rndv_buf *tx_rndv_buf;
+	struct rxm_tx_atomic_buf *tx_atomic_buf;
+	struct rxm_rma_buf *rma_buf;
+
+	if ((pool->type != RXM_BUF_POOL_TX_INJECT) && pool->rxm_ep->msg_mr_local) {
+		ret = rxm_mr_buf_reg(pool->rxm_ep, addr, len, context);
+		if (ret)
+			return ret;
+		mr_desc = fi_mr_desc((struct fid_mr *)*context);
+	} else {
+		*context = mr_desc = NULL;
+	}
 
-	ret = rxm_mr_buf_reg(pool->ep, addr, len, context);
-	if (ret)
-		return ret;
-
-	mr_desc = (*context != NULL) ? fi_mr_desc((struct fid_mr *)*context) : NULL;
-
-	for (i = 0; i < pool->pool->chunk_cnt; i++) {
-		if (pool->type == RXM_BUF_POOL_RX) {
-			rx_buf = (struct rxm_rx_buf *)((char *)addr + i * entry_sz);
-			rx_buf->ep = pool->ep;
-			rx_buf->hdr.desc = mr_desc;
-		} else {
-			tx_buf = (struct rxm_tx_buf *)((char *)addr + i * entry_sz);
-			tx_buf->type = pool->type;
-			tx_buf->pkt.ctrl_hdr.version = OFI_CTRL_VERSION;
-			tx_buf->pkt.hdr.version = OFI_OP_VERSION;
-			if (rxm_ep_tx_flags(pool->ep) & FI_TRANSMIT_COMPLETE)
-				tx_buf->pkt.hdr.flags |= OFI_TRANSMIT_COMPLETE;
-			if (rxm_ep_tx_flags(pool->ep) & FI_DELIVERY_COMPLETE)
-				tx_buf->pkt.hdr.flags |= OFI_DELIVERY_COMPLETE;
-			tx_buf->hdr.desc = mr_desc;
-
-			switch (pool->type) {
-			case RXM_BUF_POOL_TX_MSG:
-			case RXM_BUF_POOL_RMA:
-				tx_buf->pkt.ctrl_hdr.type = ofi_ctrl_data;
-				tx_buf->pkt.hdr.op = ofi_op_msg;
-				break;
-			case RXM_BUF_POOL_TX_TAGGED:
-				tx_buf->pkt.ctrl_hdr.type = ofi_ctrl_data;
-				tx_buf->pkt.hdr.op = ofi_op_tagged;
-				break;
-			case RXM_BUF_POOL_TX_ACK:
-				tx_buf->pkt.ctrl_hdr.type = ofi_ctrl_ack;
-				tx_buf->pkt.hdr.op = ofi_op_msg;
-				break;
-			case RXM_BUF_POOL_TX_LMT:
-				tx_buf->pkt.ctrl_hdr.type = ofi_ctrl_large_data;
-				break;
-			default:
-				assert(0);
-				break;
-			}
+	for (i = 0; i < pool->pool->attr.chunk_cnt; i++) {
+		switch (pool->type) {
+		case RXM_BUF_POOL_RX:
+			rx_buf = (struct rxm_rx_buf *)
+				((char *)addr + i * entry_sz);
+			rx_buf->ep = pool->rxm_ep;
+
+			hdr = &rx_buf->hdr;
+			pkt = NULL;
+			type = ofi_ctrl_data; /* This can be any value */
+			break;
+		case RXM_BUF_POOL_TX:
+			tx_eager_buf = (struct rxm_tx_eager_buf *)
+				((char *)addr + i * entry_sz);
+			tx_eager_buf->hdr.state = RXM_TX;
+
+			hdr = &tx_eager_buf->hdr;
+			pkt = &tx_eager_buf->pkt;
+			type = ofi_ctrl_data;
+			break;
+		case RXM_BUF_POOL_TX_INJECT:
+			tx_base_buf = (struct rxm_tx_base_buf *)
+				((char *)addr + i * entry_sz);
+			tx_base_buf->hdr.state = RXM_INJECT_TX;
+
+			hdr = NULL;
+			pkt = &tx_base_buf->pkt;
+			type = ofi_ctrl_data;
+			break;
+		case RXM_BUF_POOL_TX_SAR:
+			tx_sar_buf = (struct rxm_tx_sar_buf *)
+				((char *)addr + i * entry_sz);
+			tx_sar_buf->hdr.state = RXM_SAR_TX;
+
+			hdr = &tx_sar_buf->hdr;
+			pkt = &tx_sar_buf->pkt;
+			type = ofi_ctrl_seg_data;
+			break;
+		case RXM_BUF_POOL_TX_RNDV:
+			tx_rndv_buf = (struct rxm_tx_rndv_buf *)
+				((char *)addr + i * entry_sz);
+
+			hdr = &tx_rndv_buf->hdr;
+			pkt = &tx_rndv_buf->pkt;
+			type = ofi_ctrl_large_data;
+			break;
+		case RXM_BUF_POOL_TX_ATOMIC:
+			tx_atomic_buf = (struct rxm_tx_atomic_buf *)
+				((char *)addr + i * entry_sz);
+
+			hdr = &tx_atomic_buf->hdr;
+			pkt = &tx_atomic_buf->pkt;
+			type = ofi_ctrl_atomic;
+			break;
+		case RXM_BUF_POOL_TX_ACK:
+			tx_base_buf = (struct rxm_tx_base_buf *)
+				((char *)addr + i * entry_sz);
+			tx_base_buf->pkt.hdr.op = ofi_op_msg;
+
+			hdr = &tx_base_buf->hdr;
+			pkt = &tx_base_buf->pkt;
+			type = ofi_ctrl_ack;
+			break;
+		case RXM_BUF_POOL_RMA:
+			rma_buf = (struct rxm_rma_buf *)
+				((char *)addr + i * entry_sz);
+			rma_buf->pkt.hdr.op = ofi_op_msg;
+			rma_buf->hdr.state = RXM_RMA;
+
+			hdr = &rma_buf->hdr;
+			pkt = &rma_buf->pkt;
+			type = ofi_ctrl_data;
+			break;
+		default:
+			assert(0);
+			hdr = NULL;
+			pkt = NULL;
+			mr_desc = NULL;
+			type = ofi_ctrl_data;
+			break;
 		}
+		rxm_buf_reg_set_common(hdr, pkt, type, mr_desc);
 	}
 
 	return FI_SUCCESS;
@@ -171,10 +252,10 @@ static int rxm_buf_reg(void *pool_ctx, void *addr, size_t len, void **context)
 
 static inline void rxm_buf_close(void *pool_ctx, void *context)
 {
-	struct rxm_ep *rxm_ep =
-		(struct rxm_ep *)((struct rxm_buf_pool *)pool_ctx)->ep;
+	struct rxm_buf_pool *pool = (struct rxm_buf_pool *)pool_ctx;
+	struct rxm_ep *rxm_ep = pool->rxm_ep;
 
-	if (rxm_ep->msg_mr_local) {
+	if ((rxm_ep->msg_mr_local) && (pool->type != RXM_BUF_POOL_TX_INJECT)) {
 		/* We would get a (fid_mr *) in context but
 		 * it is safe to cast it into (fid *) */
 		fi_close((struct fid *)context);
@@ -183,17 +264,9 @@ static inline void rxm_buf_close(void *pool_ctx, void *context)
 
 static void rxm_buf_pool_destroy(struct rxm_buf_pool *pool)
 {
-	fastlock_destroy(&pool->lock);
-	util_buf_pool_destroy(pool->pool);
-}
-
-static void rxm_ep_cleanup_post_rx_list(struct rxm_ep *rxm_ep)
-{
-	struct rxm_rx_buf *rx_buf;
-	while (!dlist_empty(&rxm_ep->post_rx_list)) {
-		dlist_pop_front(&rxm_ep->post_rx_list, struct rxm_rx_buf,
-				rx_buf, entry);
-		rxm_rx_buf_release(rxm_ep, rx_buf);
+	/* This indicates whether the pool is allocated or not */
+	if (pool->rxm_ep) {
+		util_buf_pool_destroy(pool->pool);
 	}
 }
 
@@ -202,131 +275,152 @@ static int rxm_buf_pool_create(struct rxm_ep *rxm_ep,
 			       struct rxm_buf_pool *pool,
 			       enum rxm_buf_pool_type type)
 {
+	struct util_buf_attr attr = {
+		.size		= size,
+		.alignment	= 16,
+		.max_cnt	= 0,
+		.chunk_cnt	= chunk_count,
+		.alloc_hndlr	= rxm_buf_reg,
+		.free_hndlr	= rxm_buf_close,
+		.ctx		= pool,
+		.track_used	= 0,
+	};
 	int ret;
 
-	pool->ep = rxm_ep;
+	switch (type) {
+	case RXM_BUF_POOL_TX_RNDV:
+	case RXM_BUF_POOL_TX_ATOMIC:
+	case RXM_BUF_POOL_TX_SAR:
+		attr.indexing.used = 1;
+		break;
+	default:
+		attr.indexing.used = 0;
+		break;
+	}
+
+	pool->rxm_ep = rxm_ep;
 	pool->type = type;
-	ret = util_buf_pool_create_ex(&pool->pool, size, 16, 0, chunk_count,
-				      rxm_buf_reg, rxm_buf_close, pool);
+	ret = util_buf_pool_create_attr(&attr, &pool->pool);
 	if (ret) {
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to create buf pool\n");
 		return -FI_ENOMEM;
 	}
-	fastlock_init(&pool->lock);
+
 	return 0;
 }
 
-static int rxm_send_queue_init(struct rxm_ep *rxm_ep, struct rxm_send_queue *send_queue,
-			       size_t size)
+static void rxm_recv_entry_init(struct rxm_recv_entry *entry, void *arg)
 {
-	ssize_t i;
+	struct rxm_recv_queue *recv_queue = arg;
 
-	send_queue->fs = rxm_txe_fs_create(size);
-	if (!send_queue->fs)
-		return -FI_ENOMEM;
+	assert(recv_queue->type != RXM_RECV_QUEUE_UNSPEC);
 
-	for (i = send_queue->fs->size - 1; i >= 0; i--)
-		send_queue->fs->buf[i].ep = rxm_ep;
+	entry->recv_queue = recv_queue;
+	entry->sar.msg_id = RXM_SAR_RX_INIT;
+	entry->sar.total_recv_len = 0;
+	entry->comp_flags = FI_RECV;
 
-	fastlock_init(&send_queue->lock);
-	return 0;
+	if (recv_queue->type == RXM_RECV_QUEUE_MSG)
+		entry->comp_flags |= FI_MSG;
+	else
+		entry->comp_flags |= FI_TAGGED;
 }
 
 static int rxm_recv_queue_init(struct rxm_ep *rxm_ep,  struct rxm_recv_queue *recv_queue,
 			       size_t size, enum rxm_recv_queue_type type)
 {
-	ssize_t i;
-
 	recv_queue->rxm_ep = rxm_ep;
 	recv_queue->type = type;
-	recv_queue->fs = rxm_recv_fs_create(size);
+	recv_queue->fs = rxm_recv_fs_create(size, rxm_recv_entry_init, recv_queue);
 	if (!recv_queue->fs)
 		return -FI_ENOMEM;
 
 	dlist_init(&recv_queue->recv_list);
 	dlist_init(&recv_queue->unexp_msg_list);
 	if (type == RXM_RECV_QUEUE_MSG) {
-		recv_queue->match_recv = rxm_match_recv_entry;
-		recv_queue->match_unexp = rxm_match_unexp_msg;
-		for (i = recv_queue->fs->size - 1; i >= 0; i--)
-			recv_queue->fs->buf[i].comp_flags = FI_MSG | FI_RECV;
+		if (rxm_ep->rxm_info->caps & FI_DIRECTED_RECV) {
+			recv_queue->match_recv = rxm_match_recv_entry;
+			recv_queue->match_unexp = rxm_match_unexp_msg;
+		} else {
+			recv_queue->match_recv = rxm_match_noop;
+			recv_queue->match_unexp = rxm_match_noop;
+		}
 	} else {
-		recv_queue->match_recv = rxm_match_recv_entry_tagged;
-		recv_queue->match_unexp = rxm_match_unexp_msg_tagged;
-		for (i = recv_queue->fs->size - 1; i >= 0; i--)
-			recv_queue->fs->buf[i].comp_flags = FI_TAGGED | FI_RECV;
-	}
-	fastlock_init(&recv_queue->lock);
-	return 0;
-}
-
-static void rxm_send_queue_close(struct rxm_send_queue *send_queue)
-{
-	if (send_queue->fs) {
-		struct rxm_tx_entry *tx_entry;
-		ssize_t i;
-
-		for (i = send_queue->fs->size - 1; i >= 0; i--) {
-			tx_entry = &send_queue->fs->buf[i];
-			if (tx_entry->tx_buf) {
-				rxm_tx_buf_release(tx_entry->ep, tx_entry->tx_buf);
-				tx_entry->tx_buf = NULL;
-			}
+		if (rxm_ep->rxm_info->caps & FI_DIRECTED_RECV) {
+			recv_queue->match_recv = rxm_match_recv_entry_tag_addr;
+			recv_queue->match_unexp = rxm_match_unexp_msg_tag_addr;
+		} else {
+			recv_queue->match_recv = rxm_match_recv_entry_tag;
+			recv_queue->match_unexp = rxm_match_unexp_msg_tag;
 		}
-		rxm_txe_fs_free(send_queue->fs);
 	}
-	fastlock_destroy(&send_queue->lock);
+
+	return 0;
 }
 
 static void rxm_recv_queue_close(struct rxm_recv_queue *recv_queue)
 {
-	if (recv_queue->fs)
+	/* It indicates that the recv_queue were allocated */
+	if (recv_queue->fs) {
 		rxm_recv_fs_free(recv_queue->fs);
-	fastlock_destroy(&recv_queue->lock);
+	}
 	// TODO cleanup recv_list and unexp msg list
 }
 
 static int rxm_ep_txrx_pool_create(struct rxm_ep *rxm_ep)
 {
-	size_t i;
-	int ret;
+	int ret, i;
+	size_t queue_sizes[] = {
+		[RXM_BUF_POOL_RX] = rxm_ep->msg_info->rx_attr->size,
+		[RXM_BUF_POOL_TX] = rxm_ep->msg_info->tx_attr->size,
+		[RXM_BUF_POOL_TX_INJECT] = rxm_ep->msg_info->tx_attr->size,
+		[RXM_BUF_POOL_TX_ACK] = rxm_ep->msg_info->tx_attr->size,
+		[RXM_BUF_POOL_TX_RNDV] = rxm_ep->msg_info->tx_attr->size,
+		[RXM_BUF_POOL_TX_ATOMIC] = rxm_ep->msg_info->tx_attr->size,
+		[RXM_BUF_POOL_TX_SAR] = rxm_ep->msg_info->tx_attr->size,
+		[RXM_BUF_POOL_RMA] = rxm_ep->msg_info->tx_attr->size,
+	};
+	size_t entry_sizes[] = {		
+		[RXM_BUF_POOL_RX] = rxm_ep->eager_limit +
+				    sizeof(struct rxm_rx_buf),
+		[RXM_BUF_POOL_TX] = rxm_ep->eager_limit +
+				    sizeof(struct rxm_tx_eager_buf),
+		[RXM_BUF_POOL_TX_INJECT] = rxm_ep->inject_limit +
+					   sizeof(struct rxm_tx_base_buf),
+		[RXM_BUF_POOL_TX_ACK] = sizeof(struct rxm_tx_base_buf),
+		[RXM_BUF_POOL_TX_RNDV] = sizeof(struct rxm_rndv_hdr) +
+					 rxm_ep->buffered_min +
+					 sizeof(struct rxm_tx_rndv_buf),
+		[RXM_BUF_POOL_TX_ATOMIC] = rxm_ep->eager_limit +
+					 sizeof(struct rxm_tx_atomic_buf),
+		[RXM_BUF_POOL_TX_SAR] = rxm_ep->eager_limit +
+					sizeof(struct rxm_tx_sar_buf),
+		[RXM_BUF_POOL_RMA] = rxm_ep->eager_limit +
+				     sizeof(struct rxm_rma_buf),
+	};
 
-	ret = rxm_buf_pool_create(rxm_ep,
-				  rxm_ep->msg_info->rx_attr->size,
-				  rxm_ep->rxm_info->tx_attr->inject_size +
-				  sizeof(struct rxm_rx_buf),
-				  &rxm_ep->buf_pools[RXM_BUF_POOL_RX],
-				  RXM_BUF_POOL_RX);
-	if (ret)
-		return ret;
-	dlist_init(&rxm_ep->post_rx_list);
 	dlist_init(&rxm_ep->repost_ready_list);
 
-	/* Allocates resources for TX pools */
-	for (i = RXM_BUF_POOL_TX_START; i <= RXM_BUF_POOL_TX_END; i++) {
-		ret = rxm_buf_pool_create(rxm_ep,
-					  rxm_ep->msg_info->tx_attr->size,
-					  rxm_ep->rxm_info->tx_attr->inject_size +
-					  sizeof(struct rxm_tx_buf),
+	rxm_ep->buf_pools = calloc(1, RXM_BUF_POOL_MAX * sizeof(*rxm_ep->buf_pools));
+	if (!rxm_ep->buf_pools)
+		return -FI_ENOMEM;
+
+	for (i = RXM_BUF_POOL_START; i < RXM_BUF_POOL_MAX; i++) {
+		if ((i == RXM_BUF_POOL_TX_INJECT) &&
+		    (rxm_ep->util_ep.domain->threading != FI_THREAD_SAFE))
+			continue;
+
+		ret = rxm_buf_pool_create(rxm_ep, queue_sizes[i], entry_sizes[i],
 					  &rxm_ep->buf_pools[i], i);
 		if (ret)
 			goto err;
 	}
 
-	ret = rxm_buf_pool_create(rxm_ep,
-				  rxm_ep->msg_info->tx_attr->size,
-				  rxm_ep->rxm_info->tx_attr->inject_size +
-				  sizeof(struct rxm_rma_buf),
-				  &rxm_ep->buf_pools[RXM_BUF_POOL_RMA],
-				  RXM_BUF_POOL_RMA);
-	if (ret)
-		goto err;
-
 	return FI_SUCCESS;
 err:
-	while (--i >= RXM_BUF_POOL_TX_START)
+	while (--i >= RXM_BUF_POOL_START)
 		rxm_buf_pool_destroy(&rxm_ep->buf_pools[i]);
-	rxm_buf_pool_destroy(&rxm_ep->buf_pools[RXM_BUF_POOL_RX]);
+	free(rxm_ep->buf_pools);
 	return ret;
 }
 
@@ -336,22 +430,18 @@ static void rxm_ep_txrx_pool_destroy(struct rxm_ep *rxm_ep)
 
 	for (i = RXM_BUF_POOL_START; i < RXM_BUF_POOL_MAX; i++)
 		rxm_buf_pool_destroy(&rxm_ep->buf_pools[i]);
+	free(rxm_ep->buf_pools);
 }
 
-static int rxm_ep_txrx_queue_init(struct rxm_ep *rxm_ep)
+static int rxm_ep_rx_queue_init(struct rxm_ep *rxm_ep)
 {
 	int ret;
 
-	ret = rxm_send_queue_init(rxm_ep, &rxm_ep->send_queue,
-				  rxm_ep->rxm_info->tx_attr->size);
-	if (ret)
-		return ret;
-
 	ret = rxm_recv_queue_init(rxm_ep, &rxm_ep->recv_queue,
 				  rxm_ep->rxm_info->rx_attr->size,
 				  RXM_RECV_QUEUE_MSG);
 	if (ret)
-		goto err_recv_msg;
+		return ret;
 
 	ret = rxm_recv_queue_init(rxm_ep, &rxm_ep->trecv_queue,
 				  rxm_ep->rxm_info->rx_attr->size,
@@ -362,46 +452,22 @@ static int rxm_ep_txrx_queue_init(struct rxm_ep *rxm_ep)
 	return FI_SUCCESS;
 err_recv_tag:
 	rxm_recv_queue_close(&rxm_ep->recv_queue);
-err_recv_msg:
-	rxm_send_queue_close(&rxm_ep->send_queue);
 	return ret;
 }
 
-static void rxm_ep_txrx_queue_close(struct rxm_ep *rxm_ep)
+static void rxm_ep_rx_queue_close(struct rxm_ep *rxm_ep)
 {
 	rxm_recv_queue_close(&rxm_ep->trecv_queue);
 	rxm_recv_queue_close(&rxm_ep->recv_queue);
-	rxm_send_queue_close(&rxm_ep->send_queue);
-}
-
-static int rxm_ep_txrx_res_open(struct rxm_ep *rxm_ep)
-{
-	int ret;
-
-	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-	       "MSG provider mr_mode & FI_MR_LOCAL: %d\n",
-	       rxm_ep->msg_mr_local);
-
-	ret = rxm_ep_txrx_pool_create(rxm_ep);
-	if (ret)
-		return ret;
-
-	ret = rxm_ep_txrx_queue_init(rxm_ep);
-	if (ret)
-		goto err;
-
-	return FI_SUCCESS;
-err:
-	rxm_ep_txrx_pool_destroy(rxm_ep);
-	return ret;
 }
 
+/* It is safe to call this function, even if `rxm_ep_txrx_res_open`
+ * has not yet been called */
 static void rxm_ep_txrx_res_close(struct rxm_ep *rxm_ep)
 {
-	rxm_ep_txrx_queue_close(rxm_ep);
-
-	rxm_ep_cleanup_post_rx_list(rxm_ep);
-	rxm_ep_txrx_pool_destroy(rxm_ep);
+	rxm_ep_rx_queue_close(rxm_ep);
+	if (rxm_ep->buf_pools)
+		rxm_ep_txrx_pool_destroy(rxm_ep);
 }
 
 static int rxm_setname(fid_t fid, void *addr, size_t addrlen)
@@ -439,12 +505,12 @@ static int rxm_ep_cancel_recv(struct rxm_ep *rxm_ep,
 	struct fi_cq_err_entry err_entry;
 	struct rxm_recv_entry *recv_entry;
 	struct dlist_entry *entry;
+	int ret;
 
-	fastlock_acquire(&recv_queue->lock);
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
 	entry = dlist_remove_first_match(&recv_queue->recv_list,
 					 rxm_match_recv_entry_context,
 					 context);
-	fastlock_release(&recv_queue->lock);
 	if (entry) {
 		recv_entry = container_of(entry, struct rxm_recv_entry, entry);
 		memset(&err_entry, 0, sizeof(err_entry));
@@ -454,9 +520,12 @@ static int rxm_ep_cancel_recv(struct rxm_ep *rxm_ep,
 		err_entry.err = FI_ECANCELED;
 		err_entry.prov_errno = -FI_ECANCELED;
 		rxm_recv_entry_release(recv_queue, recv_entry);
-		return ofi_cq_write_error(rxm_ep->util_ep.rx_cq, &err_entry);
+		ret = ofi_cq_write_error(rxm_ep->util_ep.rx_cq, &err_entry);
+	} else {
+		ret = 0;
 	}
-	return 0;
+	ofi_ep_lock_release(&rxm_ep->util_ep);
+	return ret;
 }
 
 static ssize_t rxm_ep_cancel(fid_t fid_ep, void *context)
@@ -481,12 +550,28 @@ static int rxm_ep_getopt(fid_t fid, int level, int optname, void *optval,
 	struct rxm_ep *rxm_ep =
 		container_of(fid, struct rxm_ep, util_ep.ep_fid);
 
-	if ((level != FI_OPT_ENDPOINT) || (optname != FI_OPT_MIN_MULTI_RECV))
+	if (level != FI_OPT_ENDPOINT)
 		return -FI_ENOPROTOOPT;
 
-	*(size_t *)optval = rxm_ep->min_multi_recv_size;
-	*optlen = sizeof(size_t);
-
+	switch (optname) {
+	case FI_OPT_MIN_MULTI_RECV:
+		assert(sizeof(rxm_ep->min_multi_recv_size) == sizeof(size_t));
+		*(size_t *)optval = rxm_ep->min_multi_recv_size;
+		*optlen = sizeof(size_t);
+		break;
+	case FI_OPT_BUFFERED_MIN:
+		assert(sizeof(rxm_ep->buffered_min) == sizeof(size_t));
+		*(size_t *)optval = rxm_ep->buffered_min;
+		*optlen = sizeof(size_t);
+		break;
+	case FI_OPT_BUFFERED_LIMIT:
+		assert(sizeof(rxm_ep->buffered_limit) == sizeof(size_t));
+		*(size_t *)optval = rxm_ep->buffered_limit;
+		*optlen = sizeof(size_t);
+		break;
+	default:
+		return -FI_ENOPROTOOPT;
+	}
 	return FI_SUCCESS;
 }
 
@@ -495,13 +580,50 @@ static int rxm_ep_setopt(fid_t fid, int level, int optname,
 {
 	struct rxm_ep *rxm_ep =
 		container_of(fid, struct rxm_ep, util_ep.ep_fid);
+	int ret = FI_SUCCESS;
 
-	if ((level != FI_OPT_ENDPOINT) || (optname != FI_OPT_MIN_MULTI_RECV))
+	if (level != FI_OPT_ENDPOINT)
 		return -FI_ENOPROTOOPT;
 
-	rxm_ep->min_multi_recv_size = *(size_t *)optval;
-
-	return FI_SUCCESS;
+	switch (optname) {
+	case FI_OPT_MIN_MULTI_RECV:
+		rxm_ep->min_multi_recv_size = *(size_t *)optval;
+		break;
+	case FI_OPT_BUFFERED_MIN:
+		if (rxm_ep->buf_pools) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+				"Endpoint already enabled. Can't set opt now!\n");
+			ret = -FI_EOPBADSTATE;
+		} else if (*(size_t *)optval > rxm_ep->buffered_limit) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Invalid value for FI_OPT_BUFFERED_MIN: %zu "
+			"( > FI_OPT_BUFFERED_LIMIT: %zu)\n",
+			*(size_t *)optval, rxm_ep->buffered_limit);
+			ret = -FI_EINVAL;
+		} else {
+			rxm_ep->buffered_min = *(size_t *)optval;
+		}
+		break;
+	case FI_OPT_BUFFERED_LIMIT:
+		if (rxm_ep->buf_pools) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+				"Endpoint already enabled. Can't set opt now!\n");
+			ret = -FI_EOPBADSTATE;
+		/* We do not check for maximum as we allow sizes up to SIZE_MAX */
+		} else if (*(size_t *)optval < rxm_ep->buffered_min) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Invalid value for FI_OPT_BUFFERED_LIMIT: %zu"
+			" ( < FI_OPT_BUFFERED_MIN: %zu)\n",
+			*(size_t *)optval, rxm_ep->buffered_min);
+			ret = -FI_EINVAL;
+		} else {
+			rxm_ep->buffered_limit = *(size_t *)optval;
+		}
+		break;
+	default:
+		ret = -FI_ENOPROTOOPT;
+	}
+	return ret;
 }
 
 static struct fi_ops_ep rxm_ops_ep = {
@@ -521,11 +643,8 @@ static int rxm_ep_discard_recv(struct rxm_ep *rxm_ep, struct rxm_rx_buf *rx_buf,
 	RXM_DBG_ADDR_TAG(FI_LOG_EP_DATA, "Discarding message",
 			 rx_buf->unexp_msg.addr, rx_buf->unexp_msg.tag);
 
-	fastlock_acquire(&rxm_ep->util_ep.lock);
 	dlist_insert_tail(&rx_buf->repost_entry,
 			  &rx_buf->ep->repost_ready_list);
-	fastlock_release(&rxm_ep->util_ep.lock);
-
 	return ofi_cq_write(rxm_ep->util_ep.rx_cq, context, FI_TAGGED | FI_RECV,
 			    0, NULL, rx_buf->pkt.hdr.data, rx_buf->pkt.hdr.tag);
 }
@@ -538,13 +657,10 @@ static int rxm_ep_peek_recv(struct rxm_ep *rxm_ep, fi_addr_t addr, uint64_t tag,
 
 	RXM_DBG_ADDR_TAG(FI_LOG_EP_DATA, "Peeking message", addr, tag);
 
-	rxm_ep_progress_multi(&rxm_ep->util_ep);
-
-	fastlock_acquire(&recv_queue->lock);
+	rxm_ep_do_progress(&rxm_ep->util_ep);
 
 	rx_buf = rxm_check_unexp_msg_list(recv_queue, addr, tag, ignore);
 	if (!rx_buf) {
-		fastlock_release(&recv_queue->lock);
 		FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "Message not found\n");
 		return ofi_cq_write_error_peek(rxm_ep->util_ep.rx_cq, tag,
 					       context);
@@ -554,7 +670,6 @@ static int rxm_ep_peek_recv(struct rxm_ep *rxm_ep, fi_addr_t addr, uint64_t tag,
 
 	if (flags & FI_DISCARD) {
 		dlist_remove(&rx_buf->unexp_msg.entry);
-		fastlock_release(&recv_queue->lock);
 		return rxm_ep_discard_recv(rxm_ep, rx_buf, context);
 	}
 
@@ -563,7 +678,6 @@ static int rxm_ep_peek_recv(struct rxm_ep *rxm_ep, fi_addr_t addr, uint64_t tag,
 		((struct fi_context *)context)->internal[0] = rx_buf;
 		dlist_remove(&rx_buf->unexp_msg.entry);
 	}
-	fastlock_release(&recv_queue->lock);
 
 	return ofi_cq_write(rxm_ep->util_ep.rx_cq, context, FI_TAGGED | FI_RECV,
 			    rx_buf->pkt.hdr.size, NULL,
@@ -584,12 +698,11 @@ rxm_ep_format_rx_res(struct rxm_ep *rxm_ep, const struct iovec *iov,
 		return -FI_EAGAIN;
 
 	(*recv_entry)->rxm_iov.count 	= (uint8_t)count;
-	(*recv_entry)->addr 		= RXM_EP_RECV_SANITIZE_SRC_ADDR(rxm_ep, src_addr);
+	(*recv_entry)->addr 		= src_addr;
 	(*recv_entry)->context 		= context;
 	(*recv_entry)->flags 		= flags;
 	(*recv_entry)->ignore 		= ignore;
 	(*recv_entry)->tag		= tag;
-	(*recv_entry)->multi_recv_buf	= iov[0].iov_base;
 
 	for (i = 0; i < count; i++) {
 		(*recv_entry)->rxm_iov.iov[i].iov_base = iov[i].iov_base;
@@ -599,14 +712,17 @@ rxm_ep_format_rx_res(struct rxm_ep *rxm_ep, const struct iovec *iov,
 			(*recv_entry)->rxm_iov.desc[i] = desc[i];
 	}
 
+	(*recv_entry)->multi_recv.len	= (*recv_entry)->total_len;
+	(*recv_entry)->multi_recv.buf	= iov[0].iov_base;
+
 	return FI_SUCCESS;
 }
 
 static inline ssize_t
-rxm_ep_recv_common(struct rxm_ep *rxm_ep, const struct iovec *iov,
-		   void **desc, size_t count, fi_addr_t src_addr,
-		   uint64_t tag, uint64_t ignore, void *context,
-		   uint64_t op_flags, struct rxm_recv_queue *recv_queue)
+rxm_ep_post_recv(struct rxm_ep *rxm_ep, const struct iovec *iov,
+		 void **desc, size_t count, fi_addr_t src_addr,
+		 uint64_t tag, uint64_t ignore, void *context,
+		 uint64_t op_flags, struct rxm_recv_queue *recv_queue)
 {
 	struct rxm_recv_entry *recv_entry;
 	ssize_t ret;
@@ -618,7 +734,28 @@ rxm_ep_recv_common(struct rxm_ep *rxm_ep, const struct iovec *iov,
 				   recv_queue, &recv_entry);
 	if (OFI_UNLIKELY(ret))
 		return ret;
-	return rxm_process_recv_entry(recv_queue, recv_entry);
+
+	FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "Posting recv with length: %zu "
+	       "tag: 0x%" PRIx64 " ignore: 0x%" PRIx64 "\n",
+	       recv_entry->total_len, recv_entry->tag, recv_entry->ignore);
+	ret = rxm_process_recv_entry(recv_queue, recv_entry);
+
+	return ret;
+}
+
+static inline ssize_t
+rxm_ep_recv_common(struct rxm_ep *rxm_ep, const struct iovec *iov,
+		   void **desc, size_t count, fi_addr_t src_addr,
+		   uint64_t tag, uint64_t ignore, void *context,
+		   uint64_t op_flags, struct rxm_recv_queue *recv_queue)
+{
+	ssize_t ret;
+
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
+	ret = rxm_ep_post_recv(rxm_ep, iov, desc, count, src_addr,
+			       tag, ignore, context, op_flags, recv_queue);
+	ofi_ep_lock_release(&rxm_ep->util_ep);
+	return ret;
 }
 
 static ssize_t rxm_ep_recv_common_flags(struct rxm_ep *rxm_ep, const struct iovec *iov,
@@ -628,44 +765,74 @@ static ssize_t rxm_ep_recv_common_flags(struct rxm_ep *rxm_ep, const struct iove
 					struct rxm_recv_queue *recv_queue)
 {
 	struct rxm_recv_entry *recv_entry;
+	struct fi_recv_context *recv_ctx;
 	struct rxm_rx_buf *rx_buf;
+	ssize_t ret = 0;
 
 	assert(count <= rxm_ep->rxm_info->rx_attr->iov_limit);
-	assert(!(flags & (FI_PEEK | FI_CLAIM | FI_DISCARD)) ||
+	assert(!(flags & FI_PEEK) ||
 		(recv_queue->type == RXM_RECV_QUEUE_TAGGED));
 	assert(!(flags & (FI_MULTI_RECV)) ||
 		(recv_queue->type == RXM_RECV_QUEUE_MSG));
 
-	if (flags & FI_PEEK)
-		return rxm_ep_peek_recv(rxm_ep,
-					RXM_EP_RECV_SANITIZE_SRC_ADDR(rxm_ep, src_addr),
-					tag, ignore, context,
-					flags, recv_queue);
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
+	if (rxm_ep->rxm_info->mode & FI_BUFFERED_RECV) {
+		assert(!(flags & FI_PEEK));
+		recv_ctx = context;
+		context = recv_ctx->context;
+		rx_buf = container_of(recv_ctx, struct rxm_rx_buf, recv_context);
+
+		if (flags & FI_CLAIM) {
+			FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
+			       "Claiming buffered receive\n");
+			goto claim;
+		}
 
-	if (flags & FI_CLAIM) {
-		ssize_t ret;
+		assert(flags & FI_DISCARD);
+		FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "Discarding buffered receive\n");
+		dlist_insert_tail(&rx_buf->repost_entry,
+				  &rx_buf->ep->repost_ready_list);
+		goto unlock;
+	}
+
+	if (flags & FI_PEEK) {
+		ret = rxm_ep_peek_recv(rxm_ep, src_addr, tag, ignore,
+					context, flags, recv_queue);
+		goto unlock;
+	}
 
-		rx_buf = ((struct fi_context *)context)->internal[0];
-		assert(rx_buf);
-		FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "Claim message\n");
+	if (!(flags & FI_CLAIM)) {
+		ret = rxm_ep_post_recv(rxm_ep, iov, desc, count, src_addr,
+				       tag, ignore, context, flags | op_flags,
+				       recv_queue);
+		goto unlock;
+	}
 
-		if (flags & FI_DISCARD)
-			return rxm_ep_discard_recv(rxm_ep, rx_buf, context);
+	rx_buf = ((struct fi_context *)context)->internal[0];
+	assert(rx_buf);
+	FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "Claim message\n");
 
-		ret = rxm_ep_format_rx_res(rxm_ep, iov, desc, count,
-					   RXM_EP_RECV_SANITIZE_SRC_ADDR(rxm_ep, src_addr),
-					   tag, ignore, context,
-					   flags | op_flags,
-					   recv_queue, &recv_entry);
-		if (OFI_UNLIKELY(ret))
-			return ret;
-		rx_buf->recv_entry = recv_entry;
-		return rxm_cq_handle_data(rx_buf);
-	} else {
-		return rxm_ep_recv_common(rxm_ep, iov, desc, count, src_addr,
-					  tag, ignore, context, flags | op_flags,
-					  recv_queue);
+	if (flags & FI_DISCARD) {
+		ret = rxm_ep_discard_recv(rxm_ep, rx_buf, context);
+		goto unlock;
 	}
+
+claim:
+	ret = rxm_ep_format_rx_res(rxm_ep, iov, desc, count, src_addr,
+				   tag, ignore, context, flags | op_flags,
+				   recv_queue, &recv_entry);
+	if (OFI_UNLIKELY(ret))
+		goto unlock;
+
+	if (rxm_ep->rxm_info->mode & FI_BUFFERED_RECV)
+		recv_entry->comp_flags |= FI_CLAIM;
+
+	rx_buf->recv_entry = recv_entry;
+	ret = rxm_cq_handle_rx_buf(rx_buf);
+
+unlock:
+	ofi_ep_lock_release(&rxm_ep->util_ep);
+	return ret;
 }
 
 static ssize_t rxm_ep_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
@@ -706,207 +873,128 @@ static ssize_t rxm_ep_recvv(struct fid_ep *ep_fid, const struct iovec *iov,
 				  &rxm_ep->recv_queue);
 }
 
-void rxm_ep_msg_mr_closev(struct fid_mr **mr, size_t count)
-{
-	int ret;
-	size_t i;
-
-	for (i = 0; i < count; i++) {
-		if (mr[i]) {
-			ret = fi_close(&mr[i]->fid);
-			if (ret)
-				FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
-					"Unable to close msg mr: %zu\n", i);
-		}
-	}
-}
-
-int rxm_ep_msg_mr_regv(struct rxm_ep *rxm_ep, const struct iovec *iov,
-		       size_t count, uint64_t access, struct fid_mr **mr)
-{
-	struct rxm_domain *rxm_domain;
-	int ret;
-	size_t i;
-
-	rxm_domain = container_of(rxm_ep->util_ep.domain, struct rxm_domain, util_domain);
-
-	// TODO do fi_mr_regv if provider supports it
-	for (i = 0; i < count; i++) {
-		ret = fi_mr_reg(rxm_domain->msg_domain, iov[i].iov_base,
-				iov[i].iov_len, access, 0, 0, 0, &mr[i], NULL);
-		if (ret)
-			goto err;
-	}
-	return 0;
-err:
-	rxm_ep_msg_mr_closev(mr, count);
-	return ret;
-}
-
-static ssize_t rxm_rma_iov_init(struct rxm_ep *rxm_ep, void *buf,
-				const struct iovec *iov, size_t count,
-				struct fid_mr **mr)
+static void rxm_rndv_hdr_init(struct rxm_ep *rxm_ep, void *buf,
+			      const struct iovec *iov, size_t count,
+			      struct fid_mr **mr)
 {
-	struct rxm_rma_iov *rma_iov = (struct rxm_rma_iov *)buf;
+	struct rxm_rndv_hdr *rndv_hdr = (struct rxm_rndv_hdr *)buf;
 	size_t i;
 
 	for (i = 0; i < count; i++) {
-		rma_iov->iov[i].addr = RXM_MR_VIRT_ADDR(rxm_ep->msg_info) ?
+		rndv_hdr->iov[i].addr = RXM_MR_VIRT_ADDR(rxm_ep->msg_info) ?
 			(uintptr_t)iov[i].iov_base : 0;
-		rma_iov->iov[i].len = (uint64_t)iov[i].iov_len;
-		rma_iov->iov[i].key = fi_mr_key(mr[i]);
+		rndv_hdr->iov[i].len = (uint64_t)iov[i].iov_len;
+		rndv_hdr->iov[i].key = fi_mr_key(mr[i]);
 	}
-	rma_iov->count = (uint8_t)count;
-	return sizeof(*rma_iov) + sizeof(*rma_iov->iov) * count;
+	rndv_hdr->count = (uint8_t)count;
 }
 
 static inline ssize_t
-rxm_ep_format_tx_res_lightweight(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
-				 size_t len, uint64_t data, uint64_t flags, uint64_t tag,
-				 struct rxm_tx_buf **tx_buf, struct rxm_buf_pool *pool)
+rxm_ep_msg_inject_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		       struct rxm_pkt *tx_pkt, size_t pkt_size,
+		       ofi_cntr_inc_func cntr_inc_func)
 {
-	*tx_buf = (struct rxm_tx_buf *)rxm_buf_get(pool);
-	if (OFI_UNLIKELY(!*tx_buf)) {
-		FI_WARN(&rxm_prov, FI_LOG_EP_DATA, "TX queue full!\n");
-		return -FI_EAGAIN;
-	}
-
-	assert((((*tx_buf)->pkt.ctrl_hdr.type == ofi_ctrl_data) &&
-		 (len <= rxm_ep->rxm_info->tx_attr->inject_size)) ||
-	       ((*tx_buf)->pkt.ctrl_hdr.type == ofi_ctrl_large_data));
+	FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "Posting inject with length: %" PRIu64
+	       " tag: 0x%" PRIx64 "\n", pkt_size, tx_pkt->hdr.tag);
 
-	(*tx_buf)->pkt.ctrl_hdr.conn_id = rxm_conn->handle.remote_key;
+	assert((tx_pkt->hdr.flags & FI_REMOTE_CQ_DATA) || !tx_pkt->hdr.flags);
+	assert(pkt_size <= rxm_ep->inject_limit);
 
-	(*tx_buf)->pkt.hdr.size = len;
-	(*tx_buf)->pkt.hdr.tag = tag;
-
-	if (flags & FI_REMOTE_CQ_DATA) {
-		(*tx_buf)->pkt.hdr.flags = OFI_REMOTE_CQ_DATA;
-		(*tx_buf)->pkt.hdr.data = data;
+	ssize_t ret = fi_inject(rxm_conn->msg_ep, tx_pkt, pkt_size, 0);
+	if (OFI_LIKELY(!ret)) {
+		cntr_inc_func(rxm_ep->util_ep.tx_cntr);
+	} else {
+		FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
+		       "fi_inject for MSG provider failed with ret - %" PRId64"\n",
+		       ret);
+		if (OFI_LIKELY(ret == -FI_EAGAIN))
+			rxm_ep_do_progress(&rxm_ep->util_ep);
 	}
-
-	return FI_SUCCESS;
+	return ret;
 }
 
 static inline ssize_t
-rxm_ep_format_tx_entry(struct rxm_ep *rxm_ep, void *context, uint8_t count,
-		       uint64_t flags, uint64_t comp_flags,
-		       struct rxm_tx_buf *tx_buf, struct rxm_tx_entry **tx_entry)
+rxm_ep_msg_normal_send(struct rxm_conn *rxm_conn, struct rxm_pkt *tx_pkt,
+		       size_t pkt_size, void *desc, void *context)
 {
-	*tx_entry = rxm_tx_entry_get(&rxm_ep->send_queue);
-	if (OFI_UNLIKELY(!*tx_entry))
-		return -FI_EAGAIN;
+	FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "Posting send with length: %" PRIu64
+	       " tag: 0x%" PRIx64 "\n", pkt_size, tx_pkt->hdr.tag);
 
-	(*tx_entry)->count = count;
-	(*tx_entry)->context = context;
-	(*tx_entry)->flags = flags;
-	(*tx_entry)->tx_buf = tx_buf;
-	(*tx_entry)->comp_flags = comp_flags | FI_SEND;
+	assert((tx_pkt->hdr.flags & FI_REMOTE_CQ_DATA) || !tx_pkt->hdr.flags);
 
-	return FI_SUCCESS;
+	return fi_send(rxm_conn->msg_ep, tx_pkt, pkt_size, desc, 0, context);
 }
 
 static inline ssize_t
-rxm_ep_format_tx_res(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
-		     void *context, uint8_t count, size_t len, uint64_t data,
-		     uint64_t flags, uint64_t tag, uint64_t comp_flags,
-		     struct rxm_tx_buf **tx_buf, struct rxm_tx_entry **tx_entry,
-		     struct rxm_buf_pool *pool)
+rxm_ep_alloc_rndv_tx_res(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn, void *context,
+			uint8_t count, const struct iovec *iov, void **desc, size_t data_len,
+			uint64_t data, uint64_t flags, uint64_t tag, uint8_t op,
+			struct rxm_tx_rndv_buf **tx_rndv_buf)
 {
+	struct fid_mr **mr_iov;
 	ssize_t ret;
+	struct rxm_tx_rndv_buf *tx_buf = (struct rxm_tx_rndv_buf *)
+			rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX_RNDV);
 
-	ret = rxm_ep_format_tx_res_lightweight(rxm_ep, rxm_conn, len, data,
-					       flags, tag, tx_buf, pool);
-	if (OFI_UNLIKELY(ret))
-		return ret;
-
-	ret = rxm_ep_format_tx_entry(rxm_ep, context, count, flags, comp_flags,
-				     *tx_buf, tx_entry);
-	if (OFI_UNLIKELY(ret))
-		goto err;
-
-	return FI_SUCCESS;
-err:
-	rxm_tx_buf_release(rxm_ep, *tx_buf);
-	return ret;
-}
-
-static inline ssize_t
-rxm_ep_normal_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
-		   struct rxm_tx_entry *tx_entry, size_t pkt_size)
-{
-	ssize_t ret = fi_send(rxm_conn->msg_ep, &tx_entry->tx_buf->pkt, pkt_size,
-			      tx_entry->tx_buf->hdr.desc, 0, tx_entry);
-	if (OFI_UNLIKELY(ret)) {
-		if (ret == -FI_EAGAIN)
-			rxm_ep_progress_multi(&rxm_ep->util_ep);
-		else
-			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
-				"fi_send for MSG provider failed\n");
-		rxm_tx_buf_release(rxm_ep, tx_entry->tx_buf);
-		rxm_tx_entry_release(&rxm_ep->send_queue, tx_entry);
+	if (OFI_UNLIKELY(!tx_buf)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Ran out of buffers from RNDV buffer pool\n");
+		return -FI_EAGAIN;
 	}
-	return ret;
-}
 
-static inline ssize_t
-rxm_ep_alloc_lmt_tx_res(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
-			void *context, uint8_t count, const struct iovec *iov,
-			void **desc, size_t data_len, uint64_t data, uint64_t flags,
-			uint64_t tag, uint64_t comp_flags, uint8_t op,
-			struct rxm_tx_entry **tx_entry)
-{
-	struct rxm_tx_buf *tx_buf;
-	struct fid_mr **mr_iov;
-	ssize_t ret;
+	rxm_ep_format_tx_buf_pkt(rxm_conn, data_len, op, data, tag, flags, &(tx_buf)->pkt);
+	tx_buf->pkt.ctrl_hdr.msg_id = rxm_tx_buf_2_msg_id(rxm_ep, RXM_BUF_POOL_TX_RNDV, tx_buf);
+	tx_buf->app_context = context;
+	tx_buf->flags = flags;
+	tx_buf->count = count;
 
-	/* Use LMT buf pool instead of buf pool provided to the function */
-	ret = rxm_ep_format_tx_res(rxm_ep, rxm_conn, context, (uint8_t)count,
-				   data_len, data, flags, tag, comp_flags,
-				   &tx_buf, tx_entry,
-				   &rxm_ep->buf_pools[RXM_BUF_POOL_TX_LMT]);
-	if (OFI_UNLIKELY(ret))
-		return ret;
-	tx_buf->pkt.hdr.op = op;
-	tx_buf->pkt.ctrl_hdr.msg_id = rxm_txe_fs_index(rxm_ep->send_queue.fs,
-						       (*tx_entry));
 	if (!rxm_ep->rxm_mr_local) {
-		ret = rxm_ep_msg_mr_regv(rxm_ep, iov, (*tx_entry)->count,
-					 FI_REMOTE_READ, (*tx_entry)->mr);
+		ret = rxm_ep_msg_mr_regv(rxm_ep, iov, tx_buf->count,
+					 FI_REMOTE_READ, tx_buf->mr);
 		if (ret)
 			goto err;
-		mr_iov = (*tx_entry)->mr;
+		mr_iov = tx_buf->mr;
 	} else {
 		/* desc is msg fid_mr * array */
 		mr_iov = (struct fid_mr **)desc;
 	}
 
-	return rxm_rma_iov_init(rxm_ep, &(*tx_entry)->tx_buf->pkt.data, iov,
-				count, mr_iov);
+	rxm_rndv_hdr_init(rxm_ep, &tx_buf->pkt.data, iov, tx_buf->count, mr_iov);
+
+	ret = sizeof(struct rxm_pkt) + sizeof(struct rxm_rndv_hdr);
+
+	if (rxm_ep->rxm_info->mode & FI_BUFFERED_RECV) {
+		ofi_copy_from_iov(rxm_pkt_rndv_data(&tx_buf->pkt),
+				  rxm_ep->buffered_min, iov, count, 0);
+		ret += rxm_ep->buffered_min;
+	}
+
+	*tx_rndv_buf = tx_buf;
+	return ret;
 err:
-	rxm_tx_entry_release(&rxm_ep->send_queue, (*tx_entry));
-	rxm_tx_buf_release(rxm_ep, tx_buf);
+	*tx_rndv_buf = NULL;
+	rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_RNDV, tx_buf);
 	return ret;
 }
 
 static inline ssize_t
-rxm_ep_lmt_tx_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
-		   struct rxm_tx_entry *tx_entry, size_t pkt_size)
+rxm_ep_rndv_tx_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		   struct rxm_tx_rndv_buf *tx_buf, size_t pkt_size)
 {
 	ssize_t ret;
 
-	RXM_LOG_STATE(FI_LOG_EP_DATA, tx_entry->tx_buf->pkt,
-		      RXM_TX, RXM_LMT_TX);
-	if (pkt_size <= rxm_ep->msg_info->tx_attr->inject_size) {
-		RXM_LOG_STATE(FI_LOG_CQ, tx_entry->tx_buf->pkt,
-			      RXM_LMT_TX, RXM_LMT_ACK_WAIT);
-		tx_entry->state = RXM_LMT_ACK_WAIT;
+	RXM_LOG_STATE(FI_LOG_EP_DATA, tx_buf->pkt, RXM_TX, RXM_RNDV_TX);
+	if (pkt_size <= rxm_ep->inject_limit) {
+		RXM_LOG_STATE(FI_LOG_CQ, tx_buf->pkt, RXM_RNDV_TX, RXM_RNDV_ACK_WAIT);
+		tx_buf->hdr.state = RXM_RNDV_ACK_WAIT;
 
-		ret = fi_inject(rxm_conn->msg_ep, &tx_entry->tx_buf->pkt, pkt_size, 0);
+		ret = rxm_ep_msg_inject_send(rxm_ep, rxm_conn, &tx_buf->pkt,
+					     pkt_size, ofi_cntr_inc_noop);
 	} else {
-		tx_entry->state = RXM_LMT_TX;
+		tx_buf->hdr.state = RXM_RNDV_TX;
 
-		ret = rxm_ep_normal_send(rxm_ep, rxm_conn, tx_entry, pkt_size);
+		ret = rxm_ep_msg_normal_send(rxm_conn, &tx_buf->pkt, pkt_size,
+					     tx_buf->hdr.desc, tx_buf);
 	}
 	if (OFI_UNLIKELY(ret))
 		goto err;
@@ -915,253 +1003,562 @@ err:
 	FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
 	       "Transmit for MSG provider failed\n");
 	if (!rxm_ep->rxm_mr_local)
-		rxm_ep_msg_mr_closev(tx_entry->mr, tx_entry->count);
-	rxm_tx_buf_release(rxm_ep, tx_entry->tx_buf);
-	rxm_tx_entry_release(&rxm_ep->send_queue, tx_entry);
+		rxm_ep_msg_mr_closev(tx_buf->mr, tx_buf->count);
+	rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_RNDV, tx_buf);
 	return ret;
 }
 
-static inline ssize_t
-rxm_ep_inject_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
-		   struct rxm_tx_buf *tx_buf, size_t pkt_size)
+static inline size_t
+rxm_ep_sar_calc_segs_cnt(struct rxm_ep *rxm_ep, size_t data_len)
 {
-	ssize_t ret = fi_inject(rxm_conn->msg_ep, &tx_buf->pkt, pkt_size, 0);
-	if (OFI_LIKELY(!ret))
-		rxm_cntr_inc(rxm_ep->util_ep.tx_cntr);
-	/* release allocated buffer for further reuse */
-	rxm_tx_buf_release(rxm_ep, tx_buf);
-	return ret;
+	return (data_len + rxm_ep->eager_limit - 1) /
+	       rxm_ep->eager_limit;
 }
 
-void rxm_ep_handle_postponed_tx_op(struct rxm_ep *rxm_ep,
-				   struct rxm_conn *rxm_conn,
-				   struct rxm_tx_entry *tx_entry)
+static inline struct rxm_tx_sar_buf *
+rxm_ep_sar_tx_prepare_segment(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+			      void *app_context, size_t total_len, size_t seg_len,
+			      size_t seg_no, uint64_t data, uint64_t flags, uint64_t tag,
+			      uint8_t op, enum rxm_sar_seg_type seg_type, uint64_t *msg_id)
 {
-	size_t tx_size = rxm_pkt_size + tx_entry->tx_buf->pkt.hdr.size;
+	struct rxm_tx_sar_buf *tx_buf = (struct rxm_tx_sar_buf *)
+		rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX_SAR);
 
-	tx_entry->tx_buf->pkt.ctrl_hdr.conn_id = rxm_conn->handle.remote_key;
-	FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
-	       "Send deffered TX request (len - %"PRIu64") for %p conn\n",
-	       tx_entry->tx_buf->pkt.hdr.size, rxm_conn);
-
-	if ((tx_size <= rxm_ep->msg_info->tx_attr->inject_size) &&
-	    (tx_entry->flags & FI_INJECT) && !(tx_entry->flags & FI_COMPLETION))  {
-		(void) rxm_ep_inject_send(rxm_ep, rxm_conn,
-					  tx_entry->tx_buf, tx_size);
-		/* Release TX entry for futher reuse */
-		rxm_tx_entry_release(&rxm_ep->send_queue, tx_entry);
-	} else if (tx_entry->tx_buf->pkt.hdr.size >
-			rxm_ep->rxm_info->tx_attr->inject_size) {
-		struct rxm_rma_iov *rma_iov =
-			(struct rxm_rma_iov *)&tx_entry->tx_buf->pkt.data;
-		(void) rxm_ep_lmt_tx_send(rxm_ep, rxm_conn, tx_entry,
-					  rxm_pkt_size + sizeof(*rma_iov) +
-					  sizeof(*rma_iov->iov) * tx_entry->count);
+	if (OFI_UNLIKELY(!tx_buf)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Ran out of buffers from SAR buffer pool\n");
+		return NULL;
+	};
+
+	rxm_ep_format_tx_buf_pkt(rxm_conn, total_len, op, data, tag, flags, &tx_buf->pkt);
+	if (seg_type == RXM_SAR_SEG_FIRST) {
+		*msg_id = tx_buf->pkt.ctrl_hdr.msg_id =
+			rxm_tx_buf_2_msg_id(rxm_ep, RXM_BUF_POOL_TX_SAR, tx_buf);
 	} else {
-		(void) rxm_ep_normal_send(rxm_ep, rxm_conn, tx_entry, tx_size);
+		tx_buf->pkt.ctrl_hdr.msg_id = *msg_id;
 	}
+	tx_buf->pkt.ctrl_hdr.seg_size = seg_len;
+	tx_buf->pkt.ctrl_hdr.seg_no = seg_no;
+	tx_buf->app_context = app_context;
+	tx_buf->flags = flags;
+	rxm_sar_set_seg_type(&tx_buf->pkt.ctrl_hdr, seg_type);
+
+	return tx_buf;
 }
 
-static inline ssize_t
-rxm_ep_postpone_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
-		     void *context, uint8_t count, const struct iovec *iov,
-		     void **desc, size_t len, uint64_t data, uint64_t flags,
-		     uint64_t tag, uint64_t comp_flags,
-		     struct rxm_buf_pool *pool, uint8_t op)
+static void
+rxm_ep_sar_tx_cleanup(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		      struct rxm_tx_sar_buf *tx_buf)
 {
-	struct rxm_tx_entry *tx_entry;
-	struct rxm_tx_buf *tx_buf;
+	struct rxm_tx_sar_buf *first_tx_buf =
+		rxm_msg_id_2_tx_buf(rxm_ep, RXM_BUF_POOL_TX_SAR,
+				    tx_buf->pkt.ctrl_hdr.msg_id);
+	rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_SAR, first_tx_buf);
+	rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_SAR, tx_buf);
+}
 
-	FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
-	       "Buffer TX request (len - %zd) for %p conn\n", len, rxm_conn);
+static inline ssize_t
+rxm_ep_sar_tx_prepare_and_send_segment(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+				       void *app_context, size_t data_len, size_t remain_len,
+				       uint64_t msg_id, size_t seg_len, size_t seg_no, size_t segs_cnt,
+				       uint64_t data, uint64_t flags, uint64_t tag, uint8_t op,
+				       const struct iovec *iov, uint8_t count, size_t *iov_offset,
+				       struct rxm_tx_sar_buf **out_tx_buf)
+{
+	struct rxm_tx_sar_buf *tx_buf;
+	enum rxm_sar_seg_type seg_type = RXM_SAR_SEG_MIDDLE;
+
+	if (seg_no == (segs_cnt - 1)) {
+		seg_type = RXM_SAR_SEG_LAST;
+		assert(remain_len <= seg_len);
+		seg_len = remain_len;
+	}
 
-	if (len > rxm_ep->rxm_info->tx_attr->inject_size) {
-		if (rxm_ep_alloc_lmt_tx_res(rxm_ep, rxm_conn, context,
-					    count, iov, desc, len, data,
-					    flags, tag, comp_flags,
-					    op, &tx_entry) < 0)
-			return -FI_EAGAIN;
-	} else {
-		ssize_t ret = rxm_ep_format_tx_res(rxm_ep, rxm_conn, context, count,
-						   len, data, flags, tag, comp_flags,
-						   &tx_buf, &tx_entry, pool);
-		if (OFI_UNLIKELY(ret))
-			return ret;
-		ofi_copy_from_iov(tx_buf->pkt.data, tx_buf->pkt.hdr.size,
-				  iov, count, 0);
-		tx_entry->state = RXM_TX;
+	tx_buf = rxm_ep_sar_tx_prepare_segment(rxm_ep, rxm_conn, app_context, data_len, seg_len,
+					       seg_no, data, flags, tag, op, seg_type, &msg_id);
+	if (OFI_UNLIKELY(!tx_buf)) {
+		*out_tx_buf = NULL;
+		return -FI_EAGAIN;
 	}
 
-	dlist_insert_tail(&tx_entry->postponed_entry, &rxm_conn->postponed_tx_list);
+	ofi_copy_from_iov(tx_buf->pkt.data, seg_len, iov, count, *iov_offset);
+	*iov_offset += seg_len;
 
-	return FI_SUCCESS;
+	*out_tx_buf = tx_buf;
+
+	return fi_send(rxm_conn->msg_ep, &tx_buf->pkt, sizeof(struct rxm_pkt) +
+		       tx_buf->pkt.ctrl_hdr.seg_size, tx_buf->hdr.desc, 0, tx_buf);
 }
 
 static inline ssize_t
-rxm_ep_inject_common(struct rxm_ep *rxm_ep, const void *buf, size_t len,
-		     fi_addr_t dest_addr, uint64_t data, uint64_t flags,
-		     uint64_t tag, uint64_t comp_flags,
-		     struct rxm_buf_pool *pool)
+rxm_ep_sar_tx_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		   void *context, uint8_t count, const struct iovec *iov,
+		   size_t data_len, size_t segs_cnt, uint64_t data,
+		   uint64_t flags, uint64_t tag, uint8_t op)
 {
-	struct util_cmap_handle *handle;
-	struct rxm_conn *rxm_conn;
-	struct rxm_tx_entry *tx_entry = NULL;
-	struct rxm_tx_buf *tx_buf;
-	size_t pkt_size = rxm_pkt_size + len;
+	struct rxm_tx_sar_buf *tx_buf, *first_tx_buf;
+	size_t i, iov_offset = 0, remain_len = data_len;
 	ssize_t ret;
+	struct rxm_deferred_tx_entry *def_tx_entry;
+	uint64_t msg_id = 0;
 
-	assert(len <= rxm_ep->rxm_info->tx_attr->inject_size);
+	assert(segs_cnt >= 2);	
 
-	fastlock_acquire(&rxm_ep->util_ep.cmap->lock);
-	handle = ofi_cmap_acquire_handle(rxm_ep->util_ep.cmap, dest_addr);
-	if (OFI_UNLIKELY(!handle)) {
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
+	first_tx_buf = rxm_ep_sar_tx_prepare_segment(rxm_ep, rxm_conn, context, data_len,
+						     rxm_ep->eager_limit, 0, data, flags,
+						     tag, op, RXM_SAR_SEG_FIRST, &msg_id);
+	if (OFI_UNLIKELY(!first_tx_buf))
 		return -FI_EAGAIN;
-	} else if (OFI_UNLIKELY(handle->state != CMAP_CONNECTED)) {
-		struct iovec iov = {
-			.iov_base = (void *)buf,
-			.iov_len = len,
-		};
-		ret = ofi_cmap_handle_connect(rxm_ep->util_ep.cmap,
-					      dest_addr, handle);
-		if (ret && (!rxm_defer_requests || OFI_UNLIKELY(ret != -FI_EAGAIN)))
-			goto cmap_err;
-		rxm_conn = container_of(handle, struct rxm_conn, handle);
-		ret = rxm_ep_postpone_send(rxm_ep, rxm_conn, NULL, 1,
-					   &iov, NULL, len, data, flags,
-					   tag, comp_flags, pool, 0);
-cmap_err:
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
+
+	ofi_copy_from_iov(first_tx_buf->pkt.data, rxm_ep->eager_limit,
+			  iov, count, iov_offset);
+	iov_offset += rxm_ep->eager_limit;
+
+	ret = fi_send(rxm_conn->msg_ep, &first_tx_buf->pkt, sizeof(struct rxm_pkt) +
+		      first_tx_buf->pkt.ctrl_hdr.seg_size, first_tx_buf->hdr.desc, 0, first_tx_buf);
+	if (OFI_UNLIKELY(ret)) {
+		if (OFI_LIKELY(ret == -FI_EAGAIN))
+			rxm_ep_do_progress(&rxm_ep->util_ep);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_SAR, first_tx_buf);
 		return ret;
 	}
-	fastlock_release(&rxm_ep->util_ep.cmap->lock);
-	rxm_conn = container_of(handle, struct rxm_conn, handle);
-
-	assert(dlist_empty(&rxm_conn->postponed_tx_list));
-
-	if (pkt_size <= rxm_ep->msg_info->tx_attr->inject_size) {
-		ret = rxm_ep_format_tx_res_lightweight(rxm_ep, rxm_conn, len,
-						       data, flags, tag,
-						       &tx_buf, pool);
-		if (OFI_UNLIKELY(ret))
-	    		return ret;
-		memcpy(tx_buf->pkt.data, buf, tx_buf->pkt.hdr.size);
-		return rxm_ep_inject_send(rxm_ep, rxm_conn, tx_buf, pkt_size);
-	} else {
-		FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "passed data (size = %zu) "
-		       "is too big for MSG provider (max inject size = %zd)\n",
-		       pkt_size, rxm_ep->msg_info->tx_attr->inject_size);
-		ret = rxm_ep_format_tx_res(rxm_ep, rxm_conn, NULL, 1,
-					   len, data, flags, tag, comp_flags,
-					   &tx_buf, &tx_entry, pool);
-		if (OFI_UNLIKELY(ret))
+
+	remain_len -= rxm_ep->eager_limit;
+
+	for (i = 1; i < segs_cnt; i++) {
+		ret = rxm_ep_sar_tx_prepare_and_send_segment(
+					rxm_ep, rxm_conn, context, data_len, remain_len,
+					msg_id, rxm_ep->eager_limit, i, segs_cnt, data,
+					flags, tag, op, iov, count, &iov_offset, &tx_buf);
+		if (OFI_UNLIKELY(ret)) {
+			if (OFI_LIKELY(ret == -FI_EAGAIN)) {
+				def_tx_entry = rxm_ep_alloc_deferred_tx_entry(rxm_ep, rxm_conn,
+									      RXM_DEFERRED_TX_SAR_SEG);
+				if (OFI_UNLIKELY(!def_tx_entry)) {
+					if (tx_buf)
+						rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_SAR,
+								   tx_buf);
+					return -FI_ENOMEM;
+				}
+				memcpy(def_tx_entry->sar_seg.payload.iov, iov, sizeof(*iov) * count);
+				def_tx_entry->sar_seg.payload.count = count;
+				def_tx_entry->sar_seg.payload.cur_iov_offset = iov_offset;
+				def_tx_entry->sar_seg.payload.tag = tag;
+				def_tx_entry->sar_seg.payload.data = data;
+				def_tx_entry->sar_seg.cur_seg_tx_buf = tx_buf;
+				def_tx_entry->sar_seg.app_context = context;
+				def_tx_entry->sar_seg.flags = flags;
+				def_tx_entry->sar_seg.op = op;
+				def_tx_entry->sar_seg.next_seg_no = i;
+				def_tx_entry->sar_seg.segs_cnt = segs_cnt;
+				def_tx_entry->sar_seg.total_len = data_len;
+				def_tx_entry->sar_seg.remain_len = remain_len;
+				def_tx_entry->sar_seg.msg_id = msg_id;
+				rxm_ep_enqueue_deferred_tx_queue(def_tx_entry);
+				return 0;
+			}
+
+			rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_SAR, first_tx_buf);
 			return ret;
-		memcpy(tx_buf->pkt.data, buf, tx_buf->pkt.hdr.size);
-		tx_entry->state = RXM_TX;
-		return rxm_ep_normal_send(rxm_ep, rxm_conn, tx_entry, pkt_size);
+		}
+		remain_len -= rxm_ep->eager_limit;
 	}
+
+	return 0;
 }
 
-// TODO handle all flags
-static ssize_t
-rxm_ep_send_common(struct rxm_ep *rxm_ep, const struct iovec *iov, void **desc,
-		   size_t count, fi_addr_t dest_addr, void *context, uint64_t data,
-		   uint64_t flags, uint64_t tag, uint64_t comp_flags,
-		   struct rxm_buf_pool *pool, uint8_t op)
+static inline ssize_t
+rxm_ep_emulate_inject(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		      const void *buf, size_t len, size_t pkt_size,
+		      uint64_t data, uint64_t flags, uint64_t tag,
+		      uint8_t op)
 {
-	struct util_cmap_handle *handle;
-	struct rxm_conn *rxm_conn;
-	struct rxm_tx_entry *tx_entry;
-	struct rxm_tx_buf *tx_buf;
-	size_t data_len = ofi_total_iov_len(iov, count);
+	struct rxm_tx_eager_buf *tx_buf;
 	ssize_t ret;
 
-	assert(count <= rxm_ep->rxm_info->tx_attr->iov_limit);
+	FI_DBG(&rxm_prov, FI_LOG_EP_DATA, "passed data (size = %zu) "
+	       "is too big for MSG provider (max inject size = %zd)\n",
+	       pkt_size, rxm_ep->inject_limit);
 
-	fastlock_acquire(&rxm_ep->util_ep.cmap->lock);
-	handle = ofi_cmap_acquire_handle(rxm_ep->util_ep.cmap, dest_addr);
-	if (OFI_UNLIKELY(!handle)) {
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
+	tx_buf = (struct rxm_tx_eager_buf *)
+		  rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX);
+	if (OFI_UNLIKELY(!tx_buf)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Ran out of buffers from Eager buffer pool\n");
 		return -FI_EAGAIN;
-	} else if (OFI_UNLIKELY(handle->state != CMAP_CONNECTED)) {
-		ret = ofi_cmap_handle_connect(rxm_ep->util_ep.cmap,
-					      dest_addr, handle);
-		if (ret && (!rxm_defer_requests || OFI_UNLIKELY(ret != -FI_EAGAIN)))
-			goto cmap_err;
-		rxm_conn = container_of(handle, struct rxm_conn, handle);
-		ret = rxm_ep_postpone_send(
-				rxm_ep, rxm_conn, context, count, iov,
-				desc, data_len, data, flags, tag, comp_flags,
-				(data_len <=
-					rxm_ep->rxm_info->tx_attr->inject_size ?
-				 pool :
-				 &rxm_ep->buf_pools[RXM_BUF_POOL_TX_LMT]), op);
-cmap_err:
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
-		return ret;
 	}
-	fastlock_release(&rxm_ep->util_ep.cmap->lock);
-	rxm_conn = container_of(handle, struct rxm_conn, handle);
+	/* This is needed so that we don't report bogus context in fi_cq_err_entry */
+	tx_buf->app_context = NULL;
+
+	rxm_ep_format_tx_buf_pkt(rxm_conn, len, op, data, tag, flags, &tx_buf->pkt);
+	memcpy(tx_buf->pkt.data, buf, len);
+	tx_buf->flags = flags;
+
+	ret = rxm_ep_msg_normal_send(rxm_conn, &tx_buf->pkt, pkt_size,
+				     tx_buf->hdr.desc, tx_buf);
+	if (OFI_UNLIKELY(ret)) {
+		if (OFI_LIKELY(ret == -FI_EAGAIN))
+			rxm_ep_do_progress(&rxm_ep->util_ep);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX, tx_buf);
+	}
+	return ret;
+}
+
+static inline ssize_t
+rxm_ep_inject_send_fast(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+			const void *buf, size_t len, struct rxm_pkt *inject_pkt)
+{
+	size_t pkt_size = sizeof(struct rxm_pkt) + len;
+	ssize_t ret;
+
+	assert(len <= rxm_ep->eager_limit);
+
+	if (pkt_size <= rxm_ep->inject_limit) {
+		inject_pkt->hdr.size = len;
+		memcpy(inject_pkt->data, buf, len);
+		ret = rxm_ep_msg_inject_send(rxm_ep, rxm_conn, inject_pkt,
+					      pkt_size, rxm_ep->util_ep.tx_cntr_inc);
+	} else {
+		ret = rxm_ep_emulate_inject(rxm_ep, rxm_conn, buf, len, pkt_size,
+					    inject_pkt->hdr.data, inject_pkt->hdr.flags,
+					    inject_pkt->hdr.tag, inject_pkt->hdr.op);
+	}
+	return ret;
+}
 
-	assert(dlist_empty(&rxm_conn->postponed_tx_list));
+static inline ssize_t
+rxm_ep_inject_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		   const void *buf, size_t len, uint64_t data,
+		   uint64_t flags, uint64_t tag, uint8_t op)
+{
+	size_t pkt_size = sizeof(struct rxm_pkt) + len;
+	ssize_t ret;
+
+	assert(len <= rxm_ep->eager_limit);
 
-	if (data_len > rxm_ep->rxm_info->tx_attr->inject_size) {
-		if (OFI_UNLIKELY(flags & FI_INJECT)) {
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
+	if (pkt_size <= rxm_ep->inject_limit) {
+		struct rxm_tx_base_buf *tx_buf = (struct rxm_tx_base_buf *)
+			rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX_INJECT);
+		if (OFI_UNLIKELY(!tx_buf)) {
 			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
-				"inject size supported: %zu, msg size: %zu\n",
-				rxm_tx_attr.inject_size, data_len);
-			return -FI_EMSGSIZE;
+				"Ran out of buffers from Eager Inject buffer pool\n");
+			ret = -FI_EAGAIN;
+			goto unlock;
 		}
-		ret = rxm_ep_alloc_lmt_tx_res(rxm_ep, rxm_conn, context, (uint8_t)count,
-					      iov, desc, data_len, data, flags, tag,
-					      comp_flags, op, &tx_entry);
-		if (OFI_UNLIKELY(ret < 0))
-			return ret;			
-		return rxm_ep_lmt_tx_send(rxm_ep, rxm_conn, tx_entry, rxm_pkt_size + ret);
+		rxm_ep_format_tx_buf_pkt(rxm_conn, len, op, data, tag,
+					 flags, &tx_buf->pkt);
+		memcpy(tx_buf->pkt.data, buf, len);
+
+		ret = rxm_ep_msg_inject_send(rxm_ep, rxm_conn, &tx_buf->pkt,
+					     pkt_size, rxm_ep->util_ep.tx_cntr_inc);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_INJECT, tx_buf);
+	} else {
+		ret = rxm_ep_emulate_inject(rxm_ep, rxm_conn, buf, len,
+					    pkt_size, data, flags, tag, op);
+	}
+unlock:
+	ofi_ep_lock_release(&rxm_ep->util_ep);
+	return ret;
+
+}
+
+static inline ssize_t
+rxm_ep_inject_send_common(struct rxm_ep *rxm_ep, const struct iovec *iov, size_t count,
+			  struct rxm_conn *rxm_conn, void *context, uint64_t data,
+			  uint64_t flags, uint64_t tag, uint8_t op, size_t data_len,
+			  size_t total_len, struct rxm_pkt *inject_pkt)
+{
+	int ret;
+
+	if (rxm_ep->util_ep.domain->threading != FI_THREAD_SAFE) {
+		assert((op == inject_pkt->hdr.op) &&
+		       ((flags & FI_REMOTE_CQ_DATA) == inject_pkt->hdr.flags));
+
+		inject_pkt->hdr.data = data;
+		inject_pkt->hdr.tag = tag;
+		inject_pkt->hdr.size = data_len;
+		ofi_copy_from_iov(inject_pkt->data, inject_pkt->hdr.size,
+				  iov, count, 0);
+
+		ret = rxm_ep_msg_inject_send(rxm_ep, rxm_conn, inject_pkt,
+					     total_len, rxm_ep->util_ep.tx_cntr_inc);
 	} else {
-		size_t total_len = rxm_pkt_size + data_len;
+		struct rxm_tx_base_buf *tx_buf = (struct rxm_tx_base_buf *)
+			rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX_INJECT);
+		if (OFI_UNLIKELY(!tx_buf)) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+				"Ran out of buffers from Eager Inject buffer pool\n");
+			return -FI_EAGAIN;
+		}
+		rxm_ep_format_tx_buf_pkt(rxm_conn, data_len, op, data, tag,
+				         flags, &tx_buf->pkt);
+		ofi_copy_from_iov(tx_buf->pkt.data, tx_buf->pkt.hdr.size,
+				  iov, count, 0);
+
+		ret = rxm_ep_msg_inject_send(rxm_ep, rxm_conn, &tx_buf->pkt,
+					     total_len, rxm_ep->util_ep.tx_cntr_inc);
+		rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX_INJECT, tx_buf);
+	}
+	if (OFI_UNLIKELY(ret))
+		return ret;
 
-		ret = rxm_ep_format_tx_res_lightweight(rxm_ep, rxm_conn, data_len, data,
-						       flags, tag, &tx_buf, pool);
-		if (OFI_UNLIKELY(ret))
+	if (flags & FI_COMPLETION) {
+		ret = ofi_cq_write(rxm_ep->util_ep.tx_cq, context,
+				   ofi_tx_flags[op], 0, NULL, 0, 0);
+		if (OFI_UNLIKELY(ret)) {
+			FI_WARN(&rxm_prov, FI_LOG_CQ,
+				"Unable to report completion\n");
 			return ret;
+		}
+		rxm_cq_log_comp(ofi_tx_flags[op]);
+	}
+	return FI_SUCCESS;
+}
+
+static ssize_t
+rxm_ep_send_common(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+		   const struct iovec *iov, void **desc, size_t count,
+		   void *context, uint64_t data, uint64_t flags, uint64_t tag,
+		   uint8_t op, struct rxm_pkt *inject_pkt)
+{
+	size_t data_len = ofi_total_iov_len(iov, count);
+	size_t total_len = sizeof(struct rxm_pkt) + data_len;
+	ssize_t ret;
+
+	assert(count <= rxm_ep->rxm_info->tx_attr->iov_limit);
+	assert((!(flags & FI_INJECT) && (data_len > rxm_ep->eager_limit)) ||
+	       (data_len <= rxm_ep->eager_limit));
+
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
+	if (total_len <= rxm_ep->inject_limit) {
+		ret = rxm_ep_inject_send_common(rxm_ep, iov, count, rxm_conn,
+						context, data, flags, tag, op,
+						data_len, total_len, inject_pkt);
+	} else if (data_len <= rxm_ep->eager_limit) {
+		struct rxm_tx_eager_buf *tx_buf = (struct rxm_tx_eager_buf *)
+			rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX);
+
+		if (OFI_UNLIKELY(!tx_buf)) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+				"Ran out of buffers from Eager buffer pool\n");
+			ret = -FI_EAGAIN;
+			goto unlock;
+		}
+
+		rxm_ep_format_tx_buf_pkt(rxm_conn, data_len, op, data, tag,
+					 flags, &tx_buf->pkt);
 		ofi_copy_from_iov(tx_buf->pkt.data, tx_buf->pkt.hdr.size,
 				  iov, count, 0);
+		tx_buf->app_context = context;
+		tx_buf->flags = flags;
+
+		ret = rxm_ep_msg_normal_send(rxm_conn, &tx_buf->pkt, total_len,
+					     tx_buf->hdr.desc, tx_buf);
+		if (OFI_UNLIKELY(ret)) {
+			if (ret == -FI_EAGAIN)
+				rxm_ep_do_progress(&rxm_ep->util_ep);
+			rxm_tx_buf_release(rxm_ep, RXM_BUF_POOL_TX, tx_buf);
+		}
+	} else if (data_len <= rxm_ep->sar_limit) {
+		ret = rxm_ep_sar_tx_send(rxm_ep, rxm_conn, context,
+					 count, iov, data_len,
+					 rxm_ep_sar_calc_segs_cnt(rxm_ep, data_len),
+					 data, flags, tag, op);
+	} else {
+		struct rxm_tx_rndv_buf *tx_buf;
+
+		ret = rxm_ep_alloc_rndv_tx_res(rxm_ep, rxm_conn, context, (uint8_t)count,
+					      iov, desc, data_len, data, flags, tag, op,
+					      &tx_buf);
+		if (OFI_LIKELY(ret >= 0))
+			ret = rxm_ep_rndv_tx_send(rxm_ep, rxm_conn, tx_buf, ret);
+	}
+unlock:
+	ofi_ep_lock_release(&rxm_ep->util_ep);
+	return ret;
+}
+
+struct rxm_deferred_tx_entry *
+rxm_ep_alloc_deferred_tx_entry(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+			       enum rxm_deferred_tx_entry_type type)
+{
+	struct rxm_deferred_tx_entry *def_tx_entry =
+			calloc(1, sizeof(*def_tx_entry));
+	if (OFI_UNLIKELY(!def_tx_entry))
+		return NULL;
+
+	def_tx_entry->rxm_ep = rxm_ep;
+	def_tx_entry->rxm_conn = rxm_conn;
+	def_tx_entry->type = type;
+	dlist_init(&def_tx_entry->entry);
+
+	return def_tx_entry;
+}
+
+static inline void
+rxm_ep_sar_handle_segment_failure(struct rxm_deferred_tx_entry *def_tx_entry, ssize_t ret)
+{
+	rxm_ep_sar_tx_cleanup(def_tx_entry->rxm_ep, def_tx_entry->rxm_conn,
+			      def_tx_entry->sar_seg.cur_seg_tx_buf);
+	rxm_cq_write_error(def_tx_entry->rxm_ep->util_ep.tx_cq,
+			   def_tx_entry->rxm_ep->util_ep.tx_cntr,
+			   def_tx_entry->sar_seg.app_context, ret);
+}
+
+/* Returns FI_SUCCESS if the SAR deferred TX queue is empty,
+ * otherwise, it returns -FI_EAGAIN or error from MSG provider */
+static ssize_t
+rxm_ep_progress_sar_deferred_segments(struct rxm_deferred_tx_entry *def_tx_entry)
+{
+	ssize_t ret = 0;
+	struct rxm_tx_sar_buf *tx_buf = def_tx_entry->sar_seg.cur_seg_tx_buf;
+
+	if (tx_buf) {
+		ret = fi_send(def_tx_entry->rxm_conn->msg_ep, &tx_buf->pkt, sizeof(tx_buf->pkt) +
+			      tx_buf->pkt.ctrl_hdr.seg_size, tx_buf->hdr.desc, 0, tx_buf);
+		if (OFI_UNLIKELY(ret)) {
+			if (OFI_LIKELY(ret != -FI_EAGAIN)) {
+				rxm_ep_sar_handle_segment_failure(def_tx_entry, ret);
+				goto sar_finish;
+			}
+			return ret;
+		}
 
-		if ((flags & FI_INJECT) && !(flags & FI_COMPLETION) &&
-		    (total_len <= rxm_ep->msg_info->tx_attr->inject_size))
-			return rxm_ep_inject_send(rxm_ep, rxm_conn, tx_buf, total_len);
+		def_tx_entry->sar_seg.next_seg_no++;
+		def_tx_entry->sar_seg.remain_len -= def_tx_entry->rxm_ep->eager_limit;
 
-		ret = rxm_ep_format_tx_entry(rxm_ep, context, (uint8_t)count,
-					     flags, comp_flags, tx_buf, &tx_entry);
+		if (def_tx_entry->sar_seg.next_seg_no == def_tx_entry->sar_seg.segs_cnt) {
+			assert(rxm_sar_get_seg_type(&tx_buf->pkt.ctrl_hdr) == RXM_SAR_SEG_LAST);
+			goto sar_finish;
+		}
+	}
+
+	while (def_tx_entry->sar_seg.next_seg_no != def_tx_entry->sar_seg.segs_cnt) {
+		ret = rxm_ep_sar_tx_prepare_and_send_segment(
+				def_tx_entry->rxm_ep, def_tx_entry->rxm_conn,
+				def_tx_entry->sar_seg.app_context,
+				def_tx_entry->sar_seg.total_len, def_tx_entry->sar_seg.remain_len,
+				def_tx_entry->sar_seg.msg_id, def_tx_entry->rxm_ep->eager_limit,
+				def_tx_entry->sar_seg.next_seg_no, def_tx_entry->sar_seg.segs_cnt,
+				def_tx_entry->sar_seg.payload.data, def_tx_entry->sar_seg.flags,
+				def_tx_entry->sar_seg.payload.tag, def_tx_entry->sar_seg.op,
+				def_tx_entry->sar_seg.payload.iov,
+				def_tx_entry->sar_seg.payload.count,
+				&def_tx_entry->sar_seg.payload.cur_iov_offset,
+				&def_tx_entry->sar_seg.cur_seg_tx_buf);
 		if (OFI_UNLIKELY(ret)) {
-			rxm_tx_buf_release(rxm_ep, tx_buf);
+			if (OFI_LIKELY(ret != -FI_EAGAIN)) {
+				rxm_ep_sar_handle_segment_failure(def_tx_entry, ret);
+				goto sar_finish;
+			}
+
 			return ret;
 		}
-		tx_entry->state = RXM_TX;
-		return rxm_ep_normal_send(rxm_ep, rxm_conn, tx_entry, total_len);
+		def_tx_entry->sar_seg.next_seg_no++;
+		def_tx_entry->sar_seg.remain_len -= def_tx_entry->rxm_ep->eager_limit;
 	}
+
+sar_finish:
+	rxm_ep_dequeue_deferred_tx_queue(def_tx_entry);
+	free(def_tx_entry);
+
+	return ret;
 }
 
-#define rxm_ep_tx_flags_inject(rxm_ep) \
-	((rxm_ep_tx_flags(rxm_ep) & ~FI_COMPLETION) | FI_INJECT)
+void rxm_ep_progress_deferred_queue(struct rxm_ep *rxm_ep,
+				    struct rxm_conn *rxm_conn)
+{
+	struct rxm_deferred_tx_entry *def_tx_entry;
+	ssize_t ret = 0;
+
+	while (!dlist_empty(&rxm_conn->deferred_tx_queue) && !ret) {
+		def_tx_entry = container_of(rxm_conn->deferred_tx_queue.next,
+					    struct rxm_deferred_tx_entry, entry);
+		switch (def_tx_entry->type) {
+		case RXM_DEFERRED_TX_RNDV_ACK:
+			ret = fi_send(def_tx_entry->rxm_conn->msg_ep,
+				      &def_tx_entry->rndv_ack.rx_buf->
+					recv_entry->rndv.tx_buf->pkt,
+				      sizeof(def_tx_entry->rndv_ack.rx_buf->
+					recv_entry->rndv.tx_buf->pkt),
+				      def_tx_entry->rndv_ack.rx_buf->recv_entry->
+					rndv.tx_buf->hdr.desc,
+				      0, def_tx_entry->rndv_ack.rx_buf);
+			if (OFI_UNLIKELY(ret)) {
+				if (OFI_LIKELY(ret == -FI_EAGAIN))
+					break;
+				rxm_cq_write_error(def_tx_entry->rxm_ep->util_ep.rx_cq,
+						   def_tx_entry->rxm_ep->util_ep.rx_cntr,
+						   def_tx_entry->rndv_read.rx_buf->
+							recv_entry->context, ret);
+			}
+			rxm_ep_dequeue_deferred_tx_queue(def_tx_entry);
+			free(def_tx_entry);
+			break;
+		case RXM_DEFERRED_TX_RNDV_READ:
+			ret = fi_readv(def_tx_entry->rxm_conn->msg_ep,
+				       def_tx_entry->rndv_read.rxm_iov.iov,
+				       def_tx_entry->rndv_read.rxm_iov.desc,
+				       def_tx_entry->rndv_read.rxm_iov.count, 0,
+				       def_tx_entry->rndv_read.rma_iov.addr,
+				       def_tx_entry->rndv_read.rma_iov.key,
+				       def_tx_entry->rndv_read.rx_buf);
+			if (OFI_UNLIKELY(ret)) {
+				if (OFI_LIKELY(ret == -FI_EAGAIN))
+					break;
+				rxm_cq_write_error(def_tx_entry->rxm_ep->util_ep.rx_cq,
+						   def_tx_entry->rxm_ep->util_ep.rx_cntr,
+						   def_tx_entry->rndv_read.rx_buf->
+							recv_entry->context, ret);
+				break;
+			}
+			rxm_ep_dequeue_deferred_tx_queue(def_tx_entry);
+			free(def_tx_entry);
+			break;
+		case RXM_DEFERRED_TX_SAR_SEG:
+			ret = rxm_ep_progress_sar_deferred_segments(def_tx_entry);
+			break;
+		case RXM_DEFERRED_TX_ATOMIC_RESP:
+			ret = rxm_atomic_send_respmsg(rxm_ep,
+					def_tx_entry->rxm_conn,
+					def_tx_entry->atomic_resp.tx_buf,
+					def_tx_entry->atomic_resp.len);
+			if (OFI_UNLIKELY(ret))
+				if (OFI_LIKELY(ret == -FI_EAGAIN))
+					break;
+			rxm_ep_dequeue_deferred_tx_queue(def_tx_entry);
+			free(def_tx_entry);
+			break;
+		}
+	}
+}
 
 static ssize_t rxm_ep_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
 			      uint64_t flags)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_send_common(rxm_ep, msg->msg_iov, msg->desc, msg->iov_count,
-				  msg->addr, msg->context, msg->data,
+	ret = rxm_ep_prepare_tx(rxm_ep, msg->addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_send_common(rxm_ep, rxm_conn, msg->msg_iov, msg->desc,
+				  msg->iov_count, msg->context, msg->data,
 				  flags | (rxm_ep_tx_flags(rxm_ep) & FI_COMPLETION),
-				  0, FI_MSG, &rxm_ep->buf_pools[RXM_BUF_POOL_TX_MSG],
-				  ofi_op_msg);
+				  0, ofi_op_msg,
+				  ((flags & FI_REMOTE_CQ_DATA) ?
+				   rxm_conn->inject_data_pkt : rxm_conn->inject_pkt));
 }
 
 static ssize_t rxm_ep_send(struct fid_ep *ep_fid, const void *buf, size_t len,
 			   void *desc, fi_addr_t dest_addr, void *context)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct iovec iov = {
 		.iov_base = (void *)buf,
 		.iov_len = len,
@@ -1169,39 +1566,72 @@ static ssize_t rxm_ep_send(struct fid_ep *ep_fid, const void *buf, size_t len,
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_send_common(rxm_ep, &iov, &desc, 1, dest_addr, context, 0,
-				  rxm_ep_tx_flags(rxm_ep), 0, FI_MSG,
-				  &rxm_ep->buf_pools[RXM_BUF_POOL_TX_MSG],
-				  ofi_op_msg);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_send_common(rxm_ep, rxm_conn, &iov, &desc, 1, context,
+				  0, rxm_ep_tx_flags(rxm_ep), 0, ofi_op_msg,
+				  rxm_conn->inject_pkt);
 }
 
 static ssize_t rxm_ep_sendv(struct fid_ep *ep_fid, const struct iovec *iov,
 			    void **desc, size_t count, fi_addr_t dest_addr,
 			    void *context)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_send_common(rxm_ep, iov, desc, count, dest_addr, context, 0,
-				  rxm_ep_tx_flags(rxm_ep), 0, FI_MSG,
-				  &rxm_ep->buf_pools[RXM_BUF_POOL_TX_MSG], ofi_op_msg);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_send_common(rxm_ep, rxm_conn, iov, desc, count, context,
+				  0, rxm_ep_tx_flags(rxm_ep), 0, ofi_op_msg,
+				  rxm_conn->inject_pkt);
 }
 
 static ssize_t rxm_ep_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
 			     fi_addr_t dest_addr)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_inject_common(rxm_ep, buf, len, dest_addr, 0,
-				    rxm_ep_tx_flags_inject(rxm_ep),
-				    0, FI_MSG, &rxm_ep->buf_pools[RXM_BUF_POOL_TX_MSG]);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_inject_send(rxm_ep, rxm_conn, buf, len, 0,
+				  rxm_ep->util_ep.inject_op_flags,
+				  0, ofi_op_msg);
+}
+
+static ssize_t rxm_ep_inject_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+				  fi_addr_t dest_addr)
+{
+	int ret;
+	struct rxm_conn *rxm_conn;
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid.fid);
+
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_inject_send_fast(rxm_ep, rxm_conn, buf, len,
+				       rxm_conn->inject_pkt);
 }
 
 static ssize_t rxm_ep_senddata(struct fid_ep *ep_fid, const void *buf, size_t len,
 			       void *desc, uint64_t data, fi_addr_t dest_addr,
 			       void *context)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct iovec iov = {
 		.iov_base = (void *)buf,
 		.iov_len = len,
@@ -1209,21 +1639,48 @@ static ssize_t rxm_ep_senddata(struct fid_ep *ep_fid, const void *buf, size_t le
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_send_common(rxm_ep, &iov, desc, 1, dest_addr, context, data,
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_send_common(rxm_ep, rxm_conn, &iov, desc, 1, context, data,
 				  rxm_ep_tx_flags(rxm_ep) | FI_REMOTE_CQ_DATA,
-				  0, FI_MSG, &rxm_ep->buf_pools[RXM_BUF_POOL_TX_MSG],
-				  ofi_op_msg);
+				  0, ofi_op_msg, rxm_conn->inject_data_pkt);
 }
 
 static ssize_t rxm_ep_injectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
 				 uint64_t data, fi_addr_t dest_addr)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_inject_common(rxm_ep, buf, len, dest_addr, data,
-				    rxm_ep_tx_flags_inject(rxm_ep) | FI_REMOTE_CQ_DATA,
-				    0, FI_MSG, &rxm_ep->buf_pools[RXM_BUF_POOL_TX_MSG]);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_inject_send(rxm_ep, rxm_conn, buf, len, data,
+				  rxm_ep->util_ep.inject_op_flags |
+				  FI_REMOTE_CQ_DATA, 0, ofi_op_msg);
+}
+
+static ssize_t rxm_ep_injectdata_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+				      uint64_t data, fi_addr_t dest_addr)
+{
+	int ret;
+	struct rxm_conn *rxm_conn;
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid.fid);
+
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	rxm_conn->inject_data_pkt->hdr.data = data;
+
+	return rxm_ep_inject_send_fast(rxm_ep, rxm_conn, buf, len,
+				       rxm_conn->inject_data_pkt);
 }
 
 static struct fi_ops_msg rxm_ops_msg = {
@@ -1239,6 +1696,19 @@ static struct fi_ops_msg rxm_ops_msg = {
 	.injectdata = rxm_ep_injectdata,
 };
 
+static struct fi_ops_msg rxm_ops_msg_thread_unsafe = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = rxm_ep_recv,
+	.recvv = rxm_ep_recvv,
+	.recvmsg = rxm_ep_recvmsg,
+	.send = rxm_ep_send,
+	.sendv = rxm_ep_sendv,
+	.sendmsg = rxm_ep_sendmsg,
+	.inject = rxm_ep_inject_fast,
+	.senddata = rxm_ep_senddata,
+	.injectdata = rxm_ep_injectdata_fast,
+};
+
 static ssize_t rxm_ep_trecvmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *msg,
 			       uint64_t flags)
 {
@@ -1282,21 +1752,29 @@ static ssize_t rxm_ep_trecvv(struct fid_ep *ep_fid, const struct iovec *iov,
 static ssize_t rxm_ep_tsendmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *msg,
 			       uint64_t flags)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_send_common(rxm_ep, msg->msg_iov, msg->desc, msg->iov_count,
-				  msg->addr, msg->context, msg->data,
+	ret = rxm_ep_prepare_tx(rxm_ep, msg->addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_send_common(rxm_ep, rxm_conn, msg->msg_iov, msg->desc,
+				  msg->iov_count, msg->context, msg->data,
 				  flags | (rxm_ep_tx_flags(rxm_ep) & FI_COMPLETION),
-				  msg->tag, FI_TAGGED,
-				  &rxm_ep->buf_pools[RXM_BUF_POOL_TX_TAGGED],
-				  ofi_op_tagged);
+				  msg->tag, ofi_op_tagged,
+				  ((flags & FI_REMOTE_CQ_DATA) ?
+				   rxm_conn->tinject_data_pkt : rxm_conn->tinject_pkt));
 }
 
 static ssize_t rxm_ep_tsend(struct fid_ep *ep_fid, const void *buf, size_t len,
 			    void *desc, fi_addr_t dest_addr, uint64_t tag,
 			    void *context)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct iovec iov = {
 		.iov_base = (void *)buf,
 		.iov_len = len,
@@ -1304,40 +1782,74 @@ static ssize_t rxm_ep_tsend(struct fid_ep *ep_fid, const void *buf, size_t len,
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_send_common(rxm_ep, &iov, &desc, 1, dest_addr, context, 0,
-				  rxm_ep_tx_flags(rxm_ep), tag, FI_TAGGED,
-				  &rxm_ep->buf_pools[RXM_BUF_POOL_TX_TAGGED],
-				  ofi_op_tagged);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_send_common(rxm_ep, rxm_conn, &iov, &desc, 1, context, 0,
+				  rxm_ep_tx_flags(rxm_ep), tag, ofi_op_tagged,
+				  rxm_conn->tinject_pkt);
 }
 
 static ssize_t rxm_ep_tsendv(struct fid_ep *ep_fid, const struct iovec *iov,
 			     void **desc, size_t count, fi_addr_t dest_addr,
 			     uint64_t tag, void *context)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_send_common(rxm_ep, iov, desc, count, dest_addr, context, 0,
-				  rxm_ep_tx_flags(rxm_ep), tag, FI_TAGGED,
-				  &rxm_ep->buf_pools[RXM_BUF_POOL_TX_TAGGED],
-				  ofi_op_tagged);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_send_common(rxm_ep, rxm_conn, iov, desc, count, context, 0,
+				  rxm_ep_tx_flags(rxm_ep), tag, ofi_op_tagged,
+				  rxm_conn->tinject_pkt);
 }
 
 static ssize_t rxm_ep_tinject(struct fid_ep *ep_fid, const void *buf, size_t len,
 			      fi_addr_t dest_addr, uint64_t tag)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid.fid);
+
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_inject_send(rxm_ep, rxm_conn, buf, len, 0,
+				  rxm_ep->util_ep.inject_op_flags, tag,
+				  ofi_op_tagged);
+}
+
+static ssize_t rxm_ep_tinject_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+				   fi_addr_t dest_addr, uint64_t tag)
+{
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_inject_common(rxm_ep, buf, len, dest_addr, 0,
-				    rxm_ep_tx_flags_inject(rxm_ep), tag, FI_TAGGED,
-				    &rxm_ep->buf_pools[RXM_BUF_POOL_TX_TAGGED]);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	rxm_conn->tinject_pkt->hdr.tag = tag;
+
+	return rxm_ep_inject_send_fast(rxm_ep, rxm_conn, buf, len,
+				       rxm_conn->tinject_pkt);
 }
 
 static ssize_t rxm_ep_tsenddata(struct fid_ep *ep_fid, const void *buf, size_t len,
 				void *desc, uint64_t data, fi_addr_t dest_addr,
 				uint64_t tag, void *context)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct iovec iov = {
 		.iov_base = (void *)buf,
 		.iov_len = len,
@@ -1345,26 +1857,52 @@ static ssize_t rxm_ep_tsenddata(struct fid_ep *ep_fid, const void *buf, size_t l
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_send_common(rxm_ep, &iov, desc, 1, dest_addr, context, data,
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_send_common(rxm_ep, rxm_conn, &iov, desc, 1, context, data,
 				  rxm_ep_tx_flags(rxm_ep) | FI_REMOTE_CQ_DATA,
-				  tag, FI_TAGGED,
-				  &rxm_ep->buf_pools[RXM_BUF_POOL_TX_TAGGED],
-				  ofi_op_tagged);
+				  tag, ofi_op_tagged, rxm_conn->tinject_data_pkt);
 }
 
 static ssize_t rxm_ep_tinjectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
 				  uint64_t data, fi_addr_t dest_addr, uint64_t tag)
 {
+	int ret;
+	struct rxm_conn *rxm_conn;
+	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
+					     util_ep.ep_fid.fid);
+
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	return rxm_ep_inject_send(rxm_ep, rxm_conn, buf, len, data,
+				  rxm_ep->util_ep.inject_op_flags |
+				  FI_REMOTE_CQ_DATA, tag, ofi_op_tagged);
+}
+
+static ssize_t rxm_ep_tinjectdata_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+				       uint64_t data, fi_addr_t dest_addr, uint64_t tag)
+{
+	int ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_inject_common(rxm_ep, buf, len, dest_addr, data,
-				    rxm_ep_tx_flags_inject(rxm_ep) | FI_REMOTE_CQ_DATA,
-				    tag, FI_TAGGED,
-				    &rxm_ep->buf_pools[RXM_BUF_POOL_TX_TAGGED]);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	rxm_conn->tinject_data_pkt->hdr.tag = tag;
+	rxm_conn->tinject_data_pkt->hdr.data = data;
+
+	return rxm_ep_inject_send_fast(rxm_ep, rxm_conn, buf, len,
+				       rxm_conn->tinject_data_pkt);
 }
 
-struct fi_ops_tagged rxm_ops_tagged = {
+static struct fi_ops_tagged rxm_ops_tagged = {
 	.size = sizeof(struct fi_ops_tagged),
 	.recv = rxm_ep_trecv,
 	.recvv = rxm_ep_trecvv,
@@ -1377,6 +1915,19 @@ struct fi_ops_tagged rxm_ops_tagged = {
 	.injectdata = rxm_ep_tinjectdata,
 };
 
+static struct fi_ops_tagged rxm_ops_tagged_thread_unsafe = {
+	.size = sizeof(struct fi_ops_tagged),
+	.recv = rxm_ep_trecv,
+	.recvv = rxm_ep_trecvv,
+	.recvmsg = rxm_ep_trecvmsg,
+	.send = rxm_ep_tsend,
+	.sendv = rxm_ep_tsendv,
+	.sendmsg = rxm_ep_tsendmsg,
+	.inject = rxm_ep_tinject_fast,
+	.senddata = rxm_ep_tsenddata,
+	.injectdata = rxm_ep_tinjectdata_fast,
+};
+
 static int rxm_ep_msg_res_close(struct rxm_ep *rxm_ep)
 {
 	int ret, retv = 0;
@@ -1422,23 +1973,14 @@ static int rxm_ep_close(struct fid *fid)
 	int ret, retv = 0;
 	struct rxm_ep *rxm_ep =
 		container_of(fid, struct rxm_ep, util_ep.ep_fid.fid);
-	struct rxm_ep_wait_ref *wait_ref;
-	struct dlist_entry *tmp_list_entry;
-
-	dlist_foreach_container_safe(&rxm_ep->msg_cq_fd_ref_list,
-				     struct rxm_ep_wait_ref,
-				     wait_ref, entry, tmp_list_entry) {
-		ret = ofi_wait_fd_del(wait_ref->wait,
-				      rxm_ep->msg_cq_fd);
-		if (ret)
-			retv = ret;
-		dlist_remove(&wait_ref->entry);
-		free(wait_ref);
-	}
-	OFI_UNUSED(tmp_list_entry); /* to avoid "set, but not used" warning*/
 
-	if (rxm_ep->util_ep.cmap)
-		ofi_cmap_free(rxm_ep->util_ep.cmap);
+	if (rxm_ep->cmap)
+		rxm_cmap_free(rxm_ep->cmap);
+
+	// TODO move this to cmap_free and encapsulate eq progress fns
+	// these vars shouldn't be accessed outside rxm_conn file
+	fastlock_destroy(&rxm_ep->msg_eq_entry_list_lock);
+	slistfd_free(&rxm_ep->msg_eq_entry_list);
 
 	ret = rxm_listener_close(rxm_ep);
 	if (ret)
@@ -1446,10 +1988,12 @@ static int rxm_ep_close(struct fid *fid)
 
 	rxm_ep_txrx_res_close(rxm_ep);
 
-	ret = fi_close(&rxm_ep->msg_cq->fid);
-	if (ret) {
-		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to close msg CQ\n");
-		retv = ret;
+	if (rxm_ep->msg_cq) {
+		ret = fi_close(&rxm_ep->msg_cq->fid);
+		if (ret) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to close msg CQ\n");
+			retv = ret;
+		}
 	}
 
 	ret = rxm_ep_msg_res_close(rxm_ep);
@@ -1457,6 +2001,7 @@ static int rxm_ep_close(struct fid *fid)
 		retv = ret;
 
 	ofi_endpoint_close(&rxm_ep->util_ep);
+	fi_freeinfo(rxm_ep->rxm_info);
 	free(rxm_ep);
 	return retv;
 }
@@ -1502,9 +2047,18 @@ static int rxm_ep_msg_cq_open(struct rxm_ep *rxm_ep, enum fi_wait_obj wait_obj)
 
 	return 0;
 err:
-	ret = fi_close(&rxm_ep->msg_cq->fid);
-	if (ret)
-		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to close msg CQ\n");
+	fi_close(&rxm_ep->msg_cq->fid);
+	return ret;
+}
+
+static int rxm_ep_eq_entry_list_trywait(void *arg)
+{
+	struct rxm_ep *rxm_ep = (struct rxm_ep *)arg;
+	int ret;
+
+	fastlock_acquire(&rxm_ep->msg_eq_entry_list_lock);
+	ret = slistfd_empty(&rxm_ep->msg_eq_entry_list) ? 0 : -FI_EAGAIN;
+	fastlock_release(&rxm_ep->msg_eq_entry_list_lock);
 	return ret;
 }
 
@@ -1519,6 +2073,29 @@ static int rxm_ep_trywait(void *arg)
 	return fi_trywait(rxm_fabric->msg_fabric, fids, 1);
 }
 
+static int rxm_ep_wait_fd_add(struct rxm_ep *rxm_ep, struct util_wait *wait)
+{
+	int ret;
+
+	ret = ofi_wait_fd_add(wait, rxm_ep->msg_cq_fd, FI_EPOLL_IN,
+			      rxm_ep_trywait, rxm_ep,
+			      &rxm_ep->util_ep.ep_fid.fid);
+	if (ret)
+		return ret;
+
+	if (rxm_ep->util_ep.domain->data_progress == FI_PROGRESS_MANUAL) {
+		ret = ofi_wait_fd_add(
+				wait, slistfd_get_fd(&rxm_ep->msg_eq_entry_list),
+				FI_EPOLL_IN, rxm_ep_eq_entry_list_trywait,
+				rxm_ep, &rxm_ep->util_ep.ep_fid.fid);
+		if (ret) {
+			ofi_wait_fd_del(wait, rxm_ep->msg_cq_fd);
+			return ret;
+		}
+	}
+	return 0;
+}
+
 static int rxm_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 {
 	struct rxm_ep *rxm_ep =
@@ -1526,7 +2103,6 @@ static int rxm_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 	struct util_cq *cq;
 	struct util_av *av;
 	struct util_cntr *cntr;
-	struct rxm_ep_wait_ref *wait_ref = NULL;
 	int ret = 0;
 
 	switch (bfid->fclass) {
@@ -1535,6 +2111,18 @@ static int rxm_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 		ret = ofi_ep_bind_av(&rxm_ep->util_ep, av);
 		if (ret)
 			return ret;
+
+		ret = fi_listen(rxm_ep->msg_pep);
+		if (ret) {
+			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+				"Unable to set msg PEP to listen state\n");
+			return ret;
+		}
+
+		ret = rxm_conn_cmap_alloc(rxm_ep);
+		if (ret)
+			return ret;
+
 		break;
 	case FI_CLASS_CQ:
 		cq = container_of(bfid, struct util_cq, cq_fid.fid);
@@ -1551,19 +2139,9 @@ static int rxm_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 		}
 
 		if (cq->wait) {
-			wait_ref = calloc(1, sizeof(struct rxm_ep_wait_ref));
-			if (!wait_ref) {
-				ret = -FI_ENOMEM;
-				goto err1;
-			}
-			wait_ref->wait = cq->wait;
-			dlist_insert_tail(&wait_ref->entry,
-					  &rxm_ep->msg_cq_fd_ref_list);
-			ret = ofi_wait_fd_add(cq->wait, rxm_ep->msg_cq_fd,
-					      rxm_ep_trywait, rxm_ep,
-					      &rxm_ep->util_ep.ep_fid.fid);
+			ret = rxm_ep_wait_fd_add(rxm_ep, cq->wait);
 			if (ret)
-				goto err2;
+				goto err;
 		}
 		break;
 	case FI_CLASS_CNTR:
@@ -1590,19 +2168,9 @@ static int rxm_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 		}
 
 		if (cntr->wait) {
-			wait_ref = calloc(1, sizeof(struct rxm_ep_wait_ref));
-			if (!wait_ref) {
-				ret = -FI_ENOMEM;
-				goto err1;
-			}
-			wait_ref->wait = cntr->wait;
-			dlist_insert_tail(&wait_ref->entry,
-					  &rxm_ep->msg_cq_fd_ref_list);
-			ret = ofi_wait_fd_add(cntr->wait, rxm_ep->msg_cq_fd,
-					      rxm_ep_trywait, rxm_ep,
-					      &rxm_ep->util_ep.ep_fid.fid);
+			ret = rxm_ep_wait_fd_add(rxm_ep, cntr->wait);
 			if (ret)
-				goto err2;
+				goto err;
 		}
 		break;
 	case FI_CLASS_EQ:
@@ -1613,46 +2181,140 @@ static int rxm_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 		break;
 	}
 	return ret;
-err2:
-	free(wait_ref);
-err1:
+err:
 	if (fi_close(&rxm_ep->msg_cq->fid))
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to close msg CQ\n");
 	return ret;
 }
 
-static int rxm_ep_ctrl(struct fid *fid, int command, void *arg)
+static void rxm_ep_sar_init(struct rxm_ep *rxm_ep)
+{
+	size_t param;
+
+	/* The SAR initialization must be done after Eager is initialized */
+	assert(rxm_ep->eager_limit > 0);
+
+	if (!fi_param_get_size_t(&rxm_prov, "sar_limit", &param)) {
+		if (param <= rxm_ep->eager_limit) {
+			FI_WARN(&rxm_prov, FI_LOG_CORE,
+				"Requsted SAR limit (%zd) less or equal "
+				"Eager limit (%zd). SAR limit won't be used. "
+				"Messages of size <= SAR limit would be "
+				"transmitted via Inject/Eager protocol. "
+				"Messages of size > SAR limit would be "
+				"transmitted via Rendezvous protocol\n",
+				param, rxm_ep->eager_limit);
+			param = rxm_ep->eager_limit;
+		}
+
+		rxm_ep->sar_limit = param;
+	} else {
+		size_t sar_limit = rxm_ep->msg_info->tx_attr->size *
+				   rxm_ep->eager_limit;
+
+		rxm_ep->sar_limit = (sar_limit > RXM_SAR_LIMIT) ?
+				    RXM_SAR_LIMIT : sar_limit;
+	}
+}
+
+static void rxm_ep_settings_init(struct rxm_ep *rxm_ep)
+{
+	size_t max_prog_val;
+
+	assert(rxm_ep->msg_info);
+
+	max_prog_val = MIN(rxm_ep->msg_info->tx_attr->size,
+			   rxm_ep->msg_info->rx_attr->size) / 2;
+	rxm_ep->comp_per_progress = (rxm_ep->comp_per_progress > max_prog_val) ?
+				    max_prog_val : rxm_ep->comp_per_progress;
+
+	rxm_ep->msg_mr_local = ofi_mr_local(rxm_ep->msg_info);
+	rxm_ep->rxm_mr_local = ofi_mr_local(rxm_ep->rxm_info);
+
+	rxm_ep->inject_limit = rxm_ep->msg_info->tx_attr->inject_size;
+
+	if (!rxm_ep->buffered_min) {
+		if (rxm_ep->inject_limit >
+		    (sizeof(struct rxm_pkt) + sizeof(struct rxm_rndv_hdr)))
+			rxm_ep->buffered_min = (rxm_ep->inject_limit -
+						(sizeof(struct rxm_pkt) +
+						 sizeof(struct rxm_rndv_hdr)));
+		else
+			assert(!rxm_ep->buffered_min);
+	}
+
+	rxm_ep->eager_limit = rxm_ep->rxm_info->tx_attr->inject_size;
+
+	rxm_ep->min_multi_recv_size = rxm_ep->min_multi_recv_size ?
+				      rxm_ep->min_multi_recv_size :
+				      rxm_ep->eager_limit;
+	rxm_ep->buffered_limit = rxm_ep->buffered_limit ?
+				 rxm_ep->buffered_limit :
+				 rxm_ep->eager_limit;
+
+	rxm_ep_sar_init(rxm_ep);
+
+ 	FI_INFO(&rxm_prov, FI_LOG_CORE,
+		"Settings:\n"
+		"\t\t MR local: MSG - %d, RxM - %d\n"
+		"\t\t Completions per progress: MSG - %zu\n"
+		"\t\t Protocol limits: MSG Inject - %zu, "
+				      "Eager - %zu, "
+				      "SAR - %zu\n",
+		rxm_ep->msg_mr_local, rxm_ep->rxm_mr_local,
+		rxm_ep->comp_per_progress,
+		rxm_ep->inject_limit, rxm_ep->eager_limit, rxm_ep->sar_limit);
+}
+
+static int rxm_ep_txrx_res_open(struct rxm_ep *rxm_ep)
 {
-	struct rxm_ep *rxm_ep;
 	int ret;
 
-	rxm_ep = container_of(fid, struct rxm_ep, util_ep.ep_fid.fid);
+	rxm_ep_settings_init(rxm_ep);
+
+	ret = rxm_ep_txrx_pool_create(rxm_ep);
+	if (ret)
+		return ret;
+
+	dlist_init(&rxm_ep->deferred_tx_conn_queue);
+
+	ret = rxm_ep_rx_queue_init(rxm_ep);
+	if (ret)
+		goto err;
+
+	return FI_SUCCESS;
+err:
+	rxm_ep_txrx_pool_destroy(rxm_ep);
+	return ret;
+}
+
+static int rxm_ep_ctrl(struct fid *fid, int command, void *arg)
+{
+	int ret;
+	struct rxm_ep *rxm_ep
+		= container_of(fid, struct rxm_ep, util_ep.ep_fid.fid);
 
 	switch (command) {
 	case FI_ENABLE:
 		if (!rxm_ep->util_ep.rx_cq || !rxm_ep->util_ep.tx_cq)
 			return -FI_ENOCQ;
-		if (!rxm_ep->util_ep.av)
+		if (!rxm_ep->util_ep.av || !rxm_ep->cmap)
 			return -FI_EOPBADSTATE;
-
-		ret = fi_listen(rxm_ep->msg_pep);
-		if (ret) {
-			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
-				"Unable to set msg PEP to listen state\n");
+		/* At the time of enabling endpoint, FI_OPT_BUFFERED_MIN,
+		 * FI_OPT_BUFFERED_LIMIT should have been frozen so we can
+		 * create the rendezvous protocol message pool with the right
+		 * size */
+		ret = rxm_ep_txrx_res_open(rxm_ep);
+		if (ret)
 			return ret;
-		}
-
-		rxm_ep->util_ep.cmap = rxm_conn_cmap_alloc(rxm_ep);
-		if (!rxm_ep->util_ep.cmap)
-			return -FI_ENOMEM;
 
 		if (rxm_ep->srx_ctx) {
 			ret = rxm_ep_prepost_buf(rxm_ep, rxm_ep->srx_ctx);
 			if (ret) {
-				ofi_cmap_free(rxm_ep->util_ep.cmap);
+				rxm_cmap_free(rxm_ep->cmap);
 				FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
 					"Unable to prepost recv bufs\n");
-				return ret;
+				goto err;
 			}
 		}
 		break;
@@ -1660,6 +2322,9 @@ static int rxm_ep_ctrl(struct fid *fid, int command, void *arg)
 		return -FI_ENOSYS;
 	}
 	return 0;
+err:
+	rxm_ep_txrx_res_close(rxm_ep);
+	return ret;
 }
 
 static struct fi_ops rxm_ep_fi_ops = {
@@ -1672,14 +2337,14 @@ static struct fi_ops rxm_ep_fi_ops = {
 
 static int rxm_listener_open(struct rxm_ep *rxm_ep)
 {
-	struct rxm_fabric *rxm_fabric;
-	struct fi_eq_attr eq_attr;
-	eq_attr.wait_obj = FI_WAIT_UNSPEC;
-	eq_attr.flags = FI_WRITE;
+	struct fi_eq_attr eq_attr = {
+		.wait_obj = FI_WAIT_UNSPEC,
+		.flags = FI_WRITE,
+	};
 	int ret;
-
-	rxm_fabric = container_of(rxm_ep->util_ep.domain->fabric,
-				  struct rxm_fabric, util_fabric);
+	struct rxm_fabric *rxm_fabric =
+		container_of(rxm_ep->util_ep.domain->fabric,
+			     struct rxm_fabric, util_fabric);
 
 	ret = fi_eq_open(rxm_fabric->msg_fabric, &eq_attr, &rxm_ep->msg_eq, NULL);
 	if (ret) {
@@ -1697,7 +2362,7 @@ static int rxm_listener_open(struct rxm_ep *rxm_ep)
 	ret = fi_pep_bind(rxm_ep->msg_pep, &rxm_ep->msg_eq->fid, 0);
 	if (ret) {
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
-				"Unable to bind msg PEP to msg EQ\n");
+			"Unable to bind msg PEP to msg EQ\n");
 		goto err;
 	}
 
@@ -1707,56 +2372,19 @@ err:
 	return ret;
 }
 
-static int rxm_info_to_core_srx_ctx(uint32_t version, const struct fi_info *rxm_hints,
-				    struct fi_info *core_hints)
-{
-	int ret;
-
-	ret = rxm_info_to_core(version, rxm_hints, core_hints);
-	if (ret)
-		return ret;
-	core_hints->ep_attr->rx_ctx_cnt = FI_SHARED_CONTEXT;
-	return 0;
-}
-
-static int rxm_ep_get_core_info(uint32_t version, const struct fi_info *hints,
-				struct fi_info **info)
-{
-	int ret;
-
-	ret = ofi_get_core_info(version, NULL, NULL, 0, &rxm_util_prov, hints,
-				rxm_info_to_core_srx_ctx, info);
-	if (!ret)
-		return 0;
-
-	FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Shared receive context not "
-		"supported by MSG provider.\n");
-
-	return ofi_get_core_info(version, NULL, NULL, 0, &rxm_util_prov, hints,
-				 rxm_info_to_core, info);
-}
-
-static int rxm_ep_msg_res_open(struct util_domain *util_domain,
-			       struct rxm_ep *rxm_ep)
+static int rxm_ep_msg_res_open(struct rxm_ep *rxm_ep)
 {
 	int ret;
-	size_t max_prog_val;
 	struct rxm_domain *rxm_domain =
-		container_of(util_domain, struct rxm_domain, util_domain);
+		container_of(rxm_ep->util_ep.domain, struct rxm_domain, util_domain);
 
-	ret = rxm_ep_get_core_info(util_domain->fabric->fabric_fid.api_version,
-				   rxm_ep->rxm_info, &rxm_ep->msg_info);
+ 	ret = ofi_get_core_info(rxm_ep->util_ep.domain->fabric->fabric_fid.api_version,
+				NULL, NULL, 0, &rxm_util_prov, rxm_ep->rxm_info,
+				rxm_info_to_core, &rxm_ep->msg_info);
 	if (ret)
 		return ret;
 
-	max_prog_val = MIN(rxm_ep->msg_info->tx_attr->size,
-			   rxm_ep->msg_info->rx_attr->size) / 2;
-	rxm_ep->comp_per_progress = (rxm_ep->comp_per_progress > max_prog_val) ?
-				    max_prog_val : rxm_ep->comp_per_progress;
-
-	dlist_init(&rxm_ep->msg_cq_fd_ref_list);
-
-	if (rxm_ep->msg_info->ep_attr->rx_ctx_cnt == FI_SHARED_CONTEXT) {
+ 	if (rxm_ep->msg_info->ep_attr->rx_ctx_cnt == FI_SHARED_CONTEXT) {
 		ret = fi_srx_context(rxm_domain->msg_domain, rxm_ep->msg_info->rx_attr,
 				     &rxm_ep->srx_ctx, NULL);
 		if (ret) {
@@ -1766,11 +2394,11 @@ static int rxm_ep_msg_res_open(struct util_domain *util_domain,
 		}
 	}
 
-	ret = rxm_listener_open(rxm_ep);
+ 	ret = rxm_listener_open(rxm_ep);
 	if (ret)
 		goto err2;
 
-	/* Zero out the port as we would be creating multiple MSG EPs for a single
+ 	/* Zero out the port as we would be creating multiple MSG EPs for a single
 	 * RXM EP and we don't want address conflicts. */
 	if (rxm_ep->msg_info->src_addr) {
 		if (((struct sockaddr *)rxm_ep->msg_info->src_addr)->sa_family == AF_INET)
@@ -1778,9 +2406,11 @@ static int rxm_ep_msg_res_open(struct util_domain *util_domain,
 		else
 			((struct sockaddr_in6 *)(rxm_ep->msg_info->src_addr))->sin6_port = 0;
 	}
+
 	return 0;
 err2:
-	fi_close(&rxm_ep->srx_ctx->fid);
+	if (rxm_ep->srx_ctx)
+		fi_close(&rxm_ep->srx_ctx->fid);
 err1:
 	fi_freeinfo(rxm_ep->msg_info);
 	return ret;
@@ -1789,7 +2419,6 @@ err1:
 int rxm_endpoint(struct fid_domain *domain, struct fi_info *info,
 		 struct fid_ep **ep_fid, void *context)
 {
-	struct util_domain *util_domain;
 	struct rxm_ep *rxm_ep;
 	int ret;
 
@@ -1803,49 +2432,39 @@ int rxm_endpoint(struct fid_domain *domain, struct fi_info *info,
 		goto err1;
 	}
 
-	if (!fi_param_get_int(&rxm_prov, "comp_per_progress",
-			     (int *)&rxm_ep->comp_per_progress)) {
-		ret = ofi_endpoint_init(domain, &rxm_util_prov,
-					info, &rxm_ep->util_ep,
-					context, &rxm_ep_progress_multi);
-	} else {
+	if (fi_param_get_int(&rxm_prov, "comp_per_progress",
+			     (int *)&rxm_ep->comp_per_progress))
 		rxm_ep->comp_per_progress = 1;
-		ret = ofi_endpoint_init(domain, &rxm_util_prov,
-					info, &rxm_ep->util_ep,
-					context, &rxm_ep_progress_one);
-		if (ret)
-			goto err1;
-	}
+
+	ret = ofi_endpoint_init(domain, &rxm_util_prov, info, &rxm_ep->util_ep,
+				context, &rxm_ep_progress);
 	if (ret)
 		goto err1;
 
-
-	util_domain = container_of(domain, struct util_domain, domain_fid);
-
-	ret = rxm_ep_msg_res_open(util_domain, rxm_ep);
+	ret = rxm_ep_msg_res_open(rxm_ep);
 	if (ret)
 		goto err2;
 
-	rxm_ep->msg_mr_local = OFI_CHECK_MR_LOCAL(rxm_ep->msg_info);
-	rxm_ep->rxm_mr_local = OFI_CHECK_MR_LOCAL(rxm_ep->rxm_info);
-
-	rxm_ep->min_multi_recv_size = rxm_ep->rxm_info->tx_attr->inject_size;
-
-	ret = rxm_ep_txrx_res_open(rxm_ep);
-	if (ret)
-		goto err3;
+	slistfd_init(&rxm_ep->msg_eq_entry_list);
+	fastlock_init(&rxm_ep->msg_eq_entry_list_lock);
 
 	*ep_fid = &rxm_ep->util_ep.ep_fid;
 	(*ep_fid)->fid.ops = &rxm_ep_fi_ops;
 	(*ep_fid)->ops = &rxm_ops_ep;
 	(*ep_fid)->cm = &rxm_ops_cm;
-	(*ep_fid)->msg = &rxm_ops_msg;
-	(*ep_fid)->tagged = &rxm_ops_tagged;
+	if (rxm_ep->util_ep.domain->threading != FI_THREAD_SAFE) {
+		(*ep_fid)->msg = &rxm_ops_msg_thread_unsafe;
+		(*ep_fid)->tagged = &rxm_ops_tagged_thread_unsafe;
+	} else {
+		(*ep_fid)->msg = &rxm_ops_msg;
+		(*ep_fid)->tagged = &rxm_ops_tagged;
+	}
 	(*ep_fid)->rma = &rxm_ops_rma;
 
+	if (rxm_ep->rxm_info->caps & FI_ATOMIC)
+		(*ep_fid)->atomic = &rxm_ops_atomic;
+
 	return 0;
-err3:
-	rxm_ep_msg_res_close(rxm_ep);
 err2:
 	ofi_endpoint_close(&rxm_ep->util_ep);
 err1:
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_fabric.c
index 0280518c6..49c000828 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_fabric.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_fabric.c
@@ -89,7 +89,7 @@ int rxm_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
 	if (ret)
 		goto err1;
 
-	ret = ofi_get_core_info_fabric(attr, &msg_info);
+	ret = ofi_get_core_info_fabric(&rxm_prov, attr, &msg_info);
 	if (ret) {
 		FI_WARN(&rxm_prov, FI_LOG_FABRIC, "Unable to get core info!\n");
 		ret = -FI_EINVAL;
@@ -109,7 +109,7 @@ int rxm_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
 err3:
 	fi_freeinfo(msg_info);
 err2:
-	ofi_fabric_close(&rxm_fabric->util_fabric);
+	(void) ofi_fabric_close(&rxm_fabric->util_fabric);
 err1:
 	free(rxm_fabric);
 	return ret;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_init.c
index 70cd28fcc..eb0a36e0a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_init.c
@@ -38,7 +38,10 @@
 #include <ofi_prov.h>
 #include "rxm.h"
 
-int rxm_defer_requests = 0;
+#define RXM_ATOMIC_UNSUPPORTED_MSG_ORDER (FI_ORDER_RAR | FI_ORDER_RAW |	\
+					  FI_ORDER_WAR | FI_ORDER_WAW |	\
+					  FI_ORDER_SAR | FI_ORDER_SAW)
+
 size_t rxm_msg_tx_size		= 128;
 size_t rxm_msg_rx_size		= 128;
 size_t rxm_def_univ_size	= 256;
@@ -81,6 +84,8 @@ void rxm_info_to_core_mr_modes(uint32_t version, const struct fi_info *hints,
 int rxm_info_to_core(uint32_t version, const struct fi_info *hints,
 		     struct fi_info *core_info)
 {
+	int use_srx = 0;
+
 	rxm_info_to_core_mr_modes(version, hints, core_info);
 
 	core_info->mode |= FI_RX_CQ_DATA | FI_CONTEXT;
@@ -95,6 +100,7 @@ int rxm_info_to_core(uint32_t version, const struct fi_info *hints,
 
 		if (hints->domain_attr) {
 			core_info->domain_attr->caps |= hints->domain_attr->caps;
+			core_info->domain_attr->threading = hints->domain_attr->threading;
 		}
 		if (hints->tx_attr) {
 			core_info->tx_attr->msg_order = hints->tx_attr->msg_order;
@@ -106,6 +112,11 @@ int rxm_info_to_core(uint32_t version, const struct fi_info *hints,
 		}
 	}
 	core_info->ep_attr->type = FI_EP_MSG;
+	if (!fi_param_get_bool(&rxm_prov, "use_srx", &use_srx) && use_srx) {
+		FI_DBG(&rxm_prov, FI_LOG_FABRIC,
+		       "Requesting shared receive context from core provider\n");
+		core_info->ep_attr->rx_ctx_cnt = FI_SHARED_CONTEXT;
+	}
 
 	core_info->tx_attr->size = rxm_msg_tx_size;
 	core_info->rx_attr->size = rxm_msg_rx_size;
@@ -155,9 +166,9 @@ int rxm_info_to_rxm(uint32_t version, const struct fi_info *core_info,
 
 static int rxm_init_info(void)
 {
-	int param;
+	size_t param;
 
-	if (!fi_param_get_int(&rxm_prov, "buffer_size", &param)) {
+	if (!fi_param_get_size_t(&rxm_prov, "buffer_size", &param)) {
 		if (param > sizeof(struct rxm_pkt)) {
 			rxm_info.tx_attr->inject_size = param;
 		} else {
@@ -181,12 +192,42 @@ static void rxm_alter_info(const struct fi_info *hints, struct fi_info *info)
 		/* Remove the following caps if they are not requested as they
 		 * may affect performance in fast-path */
 		if (!hints) {
-			cur->caps &= ~(FI_DIRECTED_RECV | FI_SOURCE);
+			cur->caps &= ~(FI_DIRECTED_RECV | FI_SOURCE |
+				       FI_ATOMIC);
+			cur->tx_attr->caps &= ~FI_ATOMIC;
+			cur->rx_attr->caps &= ~FI_ATOMIC;
+			cur->domain_attr->data_progress = FI_PROGRESS_MANUAL;
 		} else {
 			if (!(hints->caps & FI_DIRECTED_RECV))
 				cur->caps &= ~FI_DIRECTED_RECV;
 			if (!(hints->caps & FI_SOURCE))
 				cur->caps &= ~FI_SOURCE;
+
+			if (hints->mode & FI_BUFFERED_RECV)
+				cur->mode |= FI_BUFFERED_RECV;
+
+			if (hints->caps & FI_ATOMIC) {
+				cur->tx_attr->msg_order &=
+					~(RXM_ATOMIC_UNSUPPORTED_MSG_ORDER);
+				cur->rx_attr->msg_order &=
+					~(RXM_ATOMIC_UNSUPPORTED_MSG_ORDER);
+			} else {
+				cur->caps &= ~FI_ATOMIC;
+				cur->tx_attr->caps &= ~FI_ATOMIC;
+				cur->rx_attr->caps &= ~FI_ATOMIC;
+			}
+
+			if (!ofi_mr_local(hints)) {
+				cur->mode &= ~FI_LOCAL_MR;
+				cur->tx_attr->mode &= ~FI_LOCAL_MR;
+				cur->rx_attr->mode &= ~FI_LOCAL_MR;
+				cur->domain_attr->mr_mode &= ~FI_MR_LOCAL;
+			}
+
+			if (!hints->domain_attr ||
+			    hints->domain_attr->data_progress != FI_PROGRESS_AUTO)
+				cur->domain_attr->data_progress = FI_PROGRESS_MANUAL;
+
 			if (hints->ep_attr && hints->ep_attr->mem_tag_format &&
 			    (info->caps & FI_TAGGED)) {
 				FI_INFO(&rxm_prov, FI_LOG_CORE,
@@ -201,11 +242,31 @@ static void rxm_alter_info(const struct fi_info *hints, struct fi_info *info)
 	}
 }
 
+static int rxm_validate_atomic_hints(const struct fi_info *hints)
+{
+	if (!hints || !(hints->caps & FI_ATOMIC))
+		return 0;
+
+	if (hints->tx_attr && (hints->tx_attr->msg_order &
+			       RXM_ATOMIC_UNSUPPORTED_MSG_ORDER)) {
+		FI_DBG(&rxm_prov, FI_LOG_FABRIC,
+		       "Hints tx_attr msg_order not supported for atomics\n");
+		return -FI_EINVAL;
+	}
+	if (hints->rx_attr && (hints->rx_attr->msg_order &
+			       RXM_ATOMIC_UNSUPPORTED_MSG_ORDER)) {
+		FI_DBG(&rxm_prov, FI_LOG_FABRIC,
+		       "Hints rx_attr msg_order not supported for atomics\n");
+		return -FI_EINVAL;
+	}
+	return 0;
+}
+
 static int rxm_getinfo(uint32_t version, const char *node, const char *service,
 			uint64_t flags, const struct fi_info *hints,
 			struct fi_info **info)
 {
-	struct fi_info *cur, *dup;
+	struct fi_info *cur;
 	struct addrinfo *ai;
 	uint16_t port_save = 0;
 	int ret;
@@ -227,6 +288,9 @@ static int rxm_getinfo(uint32_t version, const char *node, const char *service,
 			ofi_addr_set_port(hints->src_addr, 0);
 		}
 	}
+	ret = rxm_validate_atomic_hints(hints);
+	if (ret)
+		return ret;
 
 	ret = ofix_getinfo(version, node, service, flags, &rxm_util_prov, hints,
 			   rxm_info_to_core, rxm_info_to_rxm, info);
@@ -241,33 +305,6 @@ static int rxm_getinfo(uint32_t version, const char *node, const char *service,
 	}
 
 	rxm_alter_info(hints, *info);
-
-	/* If app supports FI_MR_LOCAL, prioritize requiring it for
-	 * better performance. */
-	if (hints && hints->domain_attr &&
-	    (OFI_CHECK_MR_LOCAL(hints))) {
-		for (cur = *info; cur; cur = cur->next) {
-			if (!OFI_CHECK_MR_LOCAL(cur))
-				continue;
-			dup = fi_dupinfo(cur);
-			if (!dup) {
-				fi_freeinfo(*info);
-				return -FI_ENOMEM;
-			} 
-
-			dup->mode &= ~FI_LOCAL_MR;
-			dup->domain_attr->mr_mode &= ~FI_MR_LOCAL;
-
-			dup->next = cur->next;
-			cur->next = dup;
-			cur = dup;
-		}
-	} else {
-		for (cur = *info; cur; cur = cur->next) {
-			cur->mode &= ~FI_LOCAL_MR;
-			cur->domain_attr->mr_mode &= ~FI_MR_LOCAL;
-		}
-	}
 	return 0;
 }
 
@@ -280,7 +317,7 @@ static void rxm_fini(void)
 struct fi_provider rxm_prov = {
 	.name = OFI_UTIL_PREFIX "rxm",
 	.version = FI_VERSION(RXM_MAJOR_VERSION, RXM_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = rxm_getinfo,
 	.fabric = rxm_fabric,
 	.cleanup = rxm_fini
@@ -288,23 +325,31 @@ struct fi_provider rxm_prov = {
 
 RXM_INI
 {
-	fi_param_define(&rxm_prov, "buffer_size", FI_PARAM_INT,
+	fi_param_define(&rxm_prov, "buffer_size", FI_PARAM_SIZE_T,
 			"Defines the transmit buffer size / inject size. Messages"
 			" of size less than this would be transmitted via an "
 			"eager protocol and those above would be transmitted "
-			"via a rendezvous protocol. Transmit data would be copied"
-			" up to this size (default: ~16k).");
+			"via a rendezvous or SAR (Segmentation And Reassembly) "
+			"protocol. Transmit data would be copied up to this size "
+			"(default: ~16k).");
 
 	fi_param_define(&rxm_prov, "comp_per_progress", FI_PARAM_INT,
 			"Defines the maximum number of MSG provider CQ entries "
 			"(default: 1) that would be read per progress "
 			"(RxM CQ read).");
 
-	fi_param_define(&rxm_prov, "defer_requests", FI_PARAM_BOOL,
-			"Defer requests when connection is not established "
-			"(default: false)\n");
-
-	fi_param_get_bool(&rxm_prov, "defer_requests", &rxm_defer_requests);
+	fi_param_define(&rxm_prov, "sar_limit", FI_PARAM_SIZE_T,
+			"Set this environment variable to control the RxM SAR "
+			"(Segmentation And Reassembly) protocol. "
+			"Messages of size greater than this (default: 256 Kb) "
+			"would be transmitted via rendezvous protocol.");
+
+	fi_param_define(&rxm_prov, "use_srx", FI_PARAM_BOOL,
+			"Set this enivronment variable to control the RxM "
+			"receive path. If this variable set to 1 (default: 0), "
+			"the RxM uses Shared Receive Context. This mode improves "
+			"memory consumption, but it may increase small message "
+			"latency as a side-effect.");
 
 	fi_param_define(&rxm_prov, "tx_size", FI_PARAM_SIZE_T,
 			"Defines default tx context size (default: 1024).");
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_rma.c
index 4e7e56f0c..8e755ca8a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_rma.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/rxm/src/rxm_rma.c
@@ -37,9 +37,8 @@ typedef ssize_t rxm_rma_msg_fn(struct fid_ep *ep_fid,
 
 static inline ssize_t
 rxm_ep_rma_reg_iov(struct rxm_ep *rxm_ep, const struct iovec *msg_iov,
-		   void **desc, void **desc_storage,
-		   size_t iov_count, uint64_t comp_flags,
-		   struct rxm_tx_entry *tx_entry)
+		   void **desc, void **desc_storage, size_t iov_count,
+		   uint64_t comp_flags, struct rxm_rma_buf *rma_buf)
 {
 	size_t i;
 
@@ -48,12 +47,13 @@ rxm_ep_rma_reg_iov(struct rxm_ep *rxm_ep, const struct iovec *msg_iov,
 			ssize_t ret =
 				rxm_ep_msg_mr_regv(rxm_ep, msg_iov, iov_count,
 						   comp_flags & (FI_WRITE | FI_READ),
-						   tx_entry->mr);
+						   rma_buf->mr.mr);
 			if (OFI_UNLIKELY(ret))
 				return ret;
 
 			for (i = 0; i < iov_count; i++)
-				desc_storage[i] = fi_mr_desc(tx_entry->mr[i]);
+				desc_storage[i] = fi_mr_desc(rma_buf->mr.mr[i]);
+			rma_buf->mr.count = iov_count;
 		} else {
 			for (i = 0; i < iov_count; i++)
 				desc_storage[i] = fi_mr_desc(desc[i]);
@@ -62,312 +62,58 @@ rxm_ep_rma_reg_iov(struct rxm_ep *rxm_ep, const struct iovec *msg_iov,
 	return FI_SUCCESS;
 }
 
-static inline void
-rxm_ep_rma_fill_msg(struct fi_msg_rma *msg_rma, struct iovec *iov,
-		    size_t iov_count, void **desc,
-		    struct rxm_rma_iov_storage *rma_iov,
-		    struct rxm_tx_entry *tx_entry,
-		    const struct fi_msg_rma *orig_msg)
-{
-	msg_rma->msg_iov = iov;
-	msg_rma->desc = desc;
-	msg_rma->iov_count = iov_count;
-	msg_rma->addr = orig_msg->addr;
-	msg_rma->rma_iov = rma_iov->iov;
-	msg_rma->rma_iov_count = rma_iov->count;
-	msg_rma->context = tx_entry;
-	msg_rma->data = orig_msg->data;
-}
-
-static inline void
-rxm_ep_rma_fill_msg_no_buf(struct rxm_rma_buf *rma_buf,
-			   struct rxm_tx_entry *tx_entry,
-			   const struct fi_msg_rma *orig_msg)
-{
-	rma_buf->rxm_iov.count = (uint8_t)orig_msg->iov_count;
-
-	rxm_ep_rma_fill_msg(&rma_buf->msg, rma_buf->rxm_iov.iov,
-			    rma_buf->rxm_iov.count, rma_buf->rxm_iov.desc,
-			    &rma_buf->rxm_rma_iov, tx_entry, orig_msg);
-}
-
-static inline void
-rxm_ep_rma_fill_msg_buf(struct rxm_rma_buf *rma_buf,
-			struct rxm_tx_entry *tx_entry,
-			const struct fi_msg_rma *orig_msg)
-{
-	ofi_copy_from_iov(rma_buf->pkt.data, rma_buf->pkt.hdr.size,
-			  orig_msg->msg_iov, orig_msg->iov_count, 0);
-
-	rma_buf->rxm_iov.iov[0].iov_base = &rma_buf->pkt.data;
-	rma_buf->rxm_iov.iov[0].iov_len = rma_buf->pkt.hdr.size;
-
-	rxm_ep_rma_fill_msg(&rma_buf->msg, rma_buf->rxm_iov.iov,
-			    1, &rma_buf->hdr.desc, &rma_buf->rxm_rma_iov,
-			    tx_entry, orig_msg);
-}
-
-static inline ssize_t
-rxm_ep_format_rma_res_lightweight(struct rxm_ep *rxm_ep, uint64_t flags,
-				  uint64_t comp_flags, const struct fi_msg_rma *orig_msg,
-				  struct rxm_tx_entry **tx_entry)
-{
-	*tx_entry = rxm_tx_entry_get(&rxm_ep->send_queue);
-	if (OFI_UNLIKELY(!*tx_entry)) {
-		FI_WARN(&rxm_prov, FI_LOG_CQ,
-			"Unable to allocate TX entry for RMA!\n");
-		rxm_ep_progress_multi(&rxm_ep->util_ep);
-		return -FI_EAGAIN;
-	}
-
-	(*tx_entry)->state = RXM_TX_NOBUF;
-	(*tx_entry)->context = orig_msg->context;
-	(*tx_entry)->flags = flags;
-	(*tx_entry)->comp_flags = FI_RMA | comp_flags;
-	(*tx_entry)->count = orig_msg->iov_count;
-
-	return FI_SUCCESS;
-}
-
-static inline ssize_t
-rxm_ep_format_rma_buf(struct rxm_ep *rxm_ep, size_t total_size,
-		      const struct fi_msg_rma *orig_msg,
-		      struct rxm_rma_buf **rma_buf, struct rxm_tx_entry *tx_entry)
-{
-	size_t i;
-
-	*rma_buf = rxm_rma_buf_get(rxm_ep);
-	if (OFI_UNLIKELY(!*rma_buf))
-		return -FI_EAGAIN;
-
-	tx_entry->state = RXM_TX_RMA;
-	tx_entry->rma_buf = *rma_buf;
-	(*rma_buf)->pkt.hdr.size = total_size;
-	(*rma_buf)->rxm_iov.count = orig_msg->iov_count;
-	(*rma_buf)->rxm_rma_iov.count = orig_msg->rma_iov_count;
-	for (i = 0; i < orig_msg->iov_count; i++)
-		(*rma_buf)->rxm_iov.iov[i] = orig_msg->msg_iov[i];
-	for (i = 0; i < orig_msg->rma_iov_count; i++)
-		(*rma_buf)->rxm_rma_iov.iov[i] = orig_msg->rma_iov[i];
-
-	return FI_SUCCESS;
-}
-
-static inline ssize_t
-rxm_ep_format_rma_res(struct rxm_ep *rxm_ep, size_t total_size,
-		      uint64_t flags, uint64_t comp_flags,
-		      const struct fi_msg_rma *orig_msg,
-		      struct rxm_rma_buf **rma_buf,
-		      struct rxm_tx_entry **tx_entry)
-{
-	ssize_t ret;
-
-	ret = rxm_ep_format_rma_res_lightweight(rxm_ep, flags, comp_flags,
-						orig_msg, tx_entry);
-	if (OFI_UNLIKELY(ret))
-		return ret;
-
-	ret = rxm_ep_format_rma_buf(rxm_ep, total_size, orig_msg,
-				    rma_buf, *tx_entry);
-	if (OFI_UNLIKELY(ret))
-		goto err;
-
-	return FI_SUCCESS;
-err:
-	FI_WARN(&rxm_prov, FI_LOG_CQ, "Unable to allocate RMA resources!\n");
-	rxm_tx_entry_release(&rxm_ep->send_queue, *tx_entry);
-	return ret;
-}
-
-void rxm_ep_handle_postponed_rma_op(struct rxm_ep *rxm_ep,
-				    struct rxm_conn *rxm_conn,
-				    struct rxm_tx_entry *tx_entry)
-{
-	ssize_t ret;
-	struct util_cntr *cntr;
-	struct util_cq *cq;
-	struct fi_cq_err_entry err_entry;
-
-	FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
-	       "Perform deffered RMA operation (len - %"PRIu64") for %p conn\n",
-	       tx_entry->rma_buf->pkt.hdr.size, rxm_conn);
-
-	if (tx_entry->comp_flags & FI_WRITE) {
-		uint64_t flags = ((tx_entry->flags & FI_INJECT) ?
-				  ((tx_entry->flags & ~FI_INJECT) |
-				   FI_COMPLETION) : tx_entry->flags);
-		ret = fi_writemsg(rxm_conn->msg_ep,
-				  &tx_entry->rma_buf->msg,
-				  flags);
-		if (OFI_UNLIKELY(ret)) {
-			cntr = rxm_ep->util_ep.wr_cntr;
-			cq = rxm_ep->util_ep.tx_cq;
-			goto err;
-		}
-	} else if (tx_entry->comp_flags & FI_READ) {
-		ret = fi_readmsg(rxm_conn->msg_ep,
-				 &tx_entry->rma_buf->msg,
-				 tx_entry->flags);
-		if (OFI_UNLIKELY(ret)) {
-			cntr = rxm_ep->util_ep.rd_cntr;
-			cq = rxm_ep->util_ep.tx_cq;
-			goto err;
-		}
-	} else {
-		assert(0);
-	}
-
-	return;
-err:
-	FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
-		"Unable to perform deffered RMA operation\n");
-
-	memset(&err_entry, 0, sizeof(err_entry));
-	err_entry.op_context = tx_entry->context;
-	err_entry.prov_errno = (int)ret;
-
-	rxm_cntr_incerr(cntr);
-	if (ofi_cq_write_error(cq, &err_entry))
-		assert(0);
-}
-
-static inline ssize_t
-rxm_ep_format_rma_inject_res(struct rxm_ep *rxm_ep, size_t total_size,
-			     uint64_t flags, uint64_t comp_flags,
-			     const struct fi_msg_rma *orig_msg,
-			     struct rxm_rma_buf **rma_buf,
-			     struct rxm_tx_entry **tx_entry)
-{
-	ssize_t ret = rxm_ep_format_rma_res(rxm_ep, total_size, flags, comp_flags,
-					    orig_msg, rma_buf, tx_entry);
-	if (OFI_UNLIKELY(ret))
-		return ret;
-
-	rxm_ep_rma_fill_msg_buf(*rma_buf, *tx_entry, orig_msg);
-
-	return ret;
-}
-
 static inline ssize_t
-rxm_ep_format_rma_non_inject_res(struct rxm_ep *rxm_ep, size_t total_size,
-				 uint64_t flags, uint64_t comp_flags,
-				 const struct fi_msg_rma *orig_msg,
-				 struct rxm_rma_buf **rma_buf,
-				 struct rxm_tx_entry **tx_entry)
-{
-	ssize_t ret = rxm_ep_format_rma_res(rxm_ep, total_size, flags, comp_flags,
-					    orig_msg, rma_buf, tx_entry);
-	if (OFI_UNLIKELY(ret))
-		return ret;
-
-	ret = rxm_ep_rma_reg_iov(rxm_ep, (*rma_buf)->rxm_iov.iov,
-				 /* addr of desc from rma_buf will be assign to itself */
-				 orig_msg->desc,
-				 (*rma_buf)->rxm_iov.desc,
-				 orig_msg->iov_count,
-				 comp_flags & (FI_WRITE | FI_READ), *tx_entry);
-	if (OFI_UNLIKELY(ret))
-		goto err;
-
-	rxm_ep_rma_fill_msg_no_buf(*rma_buf, *tx_entry, orig_msg);
-
-	return ret;
-err:
-	rxm_rma_buf_release(rxm_ep, (*tx_entry)->rma_buf);
-	rxm_tx_entry_release(&rxm_ep->send_queue, *tx_entry);
-	return ret;
-}
-
-static inline int
-rxm_ep_postpone_rma(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
-		    size_t total_size, uint64_t flags,
-		    uint64_t comp_flags, const struct fi_msg_rma *orig_msg)
-{
-	struct rxm_tx_entry *tx_entry;
-	struct rxm_rma_buf *rma_buf;
-	int ret;
-
-	if (flags & FI_INJECT) {
-		assert(comp_flags & FI_WRITE);
-		ret = rxm_ep_format_rma_inject_res(rxm_ep, total_size,
-						   flags, comp_flags, orig_msg,
-						   &rma_buf, &tx_entry);
-	} else {
-		ret = rxm_ep_format_rma_non_inject_res(rxm_ep, total_size,
-						       flags, comp_flags, orig_msg,
-						       &rma_buf, &tx_entry);
-	}
-	if (OFI_UNLIKELY(ret))
-		return ret;
-
-	dlist_insert_tail(&tx_entry->postponed_entry,
-			  &rxm_conn->postponed_tx_list);
-
-	return ret;
-}
-
-static ssize_t
 rxm_ep_rma_common(struct rxm_ep *rxm_ep, const struct fi_msg_rma *msg, uint64_t flags,
 		  rxm_rma_msg_fn rma_msg, uint64_t comp_flags)
 {
-	struct rxm_tx_entry *tx_entry;
+	struct rxm_rma_buf *rma_buf;
 	struct fi_msg_rma msg_rma = *msg;
-	struct util_cmap_handle *handle;
 	struct rxm_conn *rxm_conn;
 	void *mr_desc[RXM_IOV_LIMIT] = { 0 };
 	int ret;
 
 	assert(msg->rma_iov_count <= rxm_ep->rxm_info->tx_attr->rma_iov_limit);
 
-	fastlock_acquire(&rxm_ep->util_ep.cmap->lock);
-	handle = ofi_cmap_acquire_handle(rxm_ep->util_ep.cmap, msg->addr);
-	if (OFI_UNLIKELY(!handle)) {
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
-		return -FI_EAGAIN;
-	} else if (OFI_UNLIKELY(handle->state != CMAP_CONNECTED)) {
-		ret = ofi_cmap_handle_connect(rxm_ep->util_ep.cmap,
-					      msg->addr, handle);
-		if (OFI_UNLIKELY(ret != -FI_EAGAIN))
-			goto cmap_err;
-		rxm_conn = container_of(handle, struct rxm_conn, handle);
-		ret = rxm_ep_postpone_rma(rxm_ep, rxm_conn,
-					  ofi_total_iov_len(msg->msg_iov,
-							    msg->iov_count),
-					  flags, comp_flags, msg);
-cmap_err:
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
+	ret = rxm_ep_prepare_tx(rxm_ep, msg->addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
 		return ret;
-	}
-	fastlock_release(&rxm_ep->util_ep.cmap->lock);
-	rxm_conn = container_of(handle, struct rxm_conn, handle);
 
-	ret = rxm_ep_format_rma_res_lightweight(rxm_ep, flags, comp_flags,
-						msg, &tx_entry);
-	if (OFI_UNLIKELY(ret))
-		return -FI_EAGAIN;
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
+	rma_buf = rxm_rma_buf_alloc(rxm_ep);
+	if (OFI_UNLIKELY(!rma_buf)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Ran out of buffers from RMA buffer pool\n");
+		ret = -FI_ENOMEM;
+		goto unlock;
+	}
 
-	msg_rma.context = tx_entry;
+	rma_buf->app_context = msg->context;
+	rma_buf->flags = flags;
 
-	ret = rxm_ep_rma_reg_iov(rxm_ep, msg->msg_iov, msg_rma.desc, mr_desc,
-				 msg->iov_count, comp_flags & (FI_WRITE | FI_READ),
-				 tx_entry);
+	ret = rxm_ep_rma_reg_iov(rxm_ep, msg_rma.msg_iov, msg_rma.desc, mr_desc,
+				 msg_rma.iov_count, comp_flags & (FI_WRITE | FI_READ),
+				 rma_buf);
 	if (OFI_UNLIKELY(ret))
-		goto err;
+		goto release;
+
 	msg_rma.desc = mr_desc;
+	msg_rma.context = rma_buf;
 
 	ret = rma_msg(rxm_conn->msg_ep, &msg_rma, flags);
 	if (OFI_LIKELY(!ret))
-		return ret;
+		goto unlock;
 
 	if ((rxm_ep->msg_mr_local) && (!rxm_ep->rxm_mr_local))
-		rxm_ep_msg_mr_closev(tx_entry->mr, tx_entry->count);
-err:
-	rxm_tx_entry_release(&rxm_ep->send_queue, tx_entry);
+		rxm_ep_msg_mr_closev(rma_buf->mr.mr, rma_buf->mr.count);
+release:
+	rxm_rma_buf_release(rxm_ep, rma_buf);
+unlock:
+	ofi_ep_lock_release(&rxm_ep->util_ep);
 	return ret;
 }
 
-static ssize_t rxm_ep_readmsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
-			      uint64_t flags)
+static inline ssize_t
+rxm_ep_readmsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg, uint64_t flags)
 {
 	struct rxm_ep *rxm_ep =
 		container_of(ep_fid, struct rxm_ep, util_ep.ep_fid.fid);
@@ -429,88 +175,145 @@ static ssize_t rxm_ep_read(struct fid_ep *ep_fid, void *buf, size_t len,
 	return rxm_ep_readmsg(ep_fid, &msg, rxm_ep_tx_flags(rxm_ep));
 }
 
-static ssize_t
-rxm_ep_rma_inject(struct rxm_ep *rxm_ep, const struct fi_msg_rma *msg, uint64_t flags)
+static inline void
+rxm_ep_format_rma_msg(struct rxm_rma_buf *rma_buf, const struct fi_msg_rma *orig_msg,
+		      struct iovec *rxm_iov, struct fi_msg_rma *rxm_msg)
+{
+	rxm_msg->context = rma_buf;
+	rxm_msg->addr = orig_msg->addr;
+	rxm_msg->data = orig_msg->data;
+
+	ofi_copy_from_iov(rma_buf->pkt.data, rma_buf->pkt.hdr.size,
+			  orig_msg->msg_iov, orig_msg->iov_count, 0);
+	rxm_iov->iov_base = &rma_buf->pkt.data;
+	rxm_iov->iov_len = rma_buf->pkt.hdr.size;
+	rxm_msg->msg_iov = rxm_iov;
+	rxm_msg->desc = &rma_buf->hdr.desc;
+	rxm_msg->iov_count = 1;
+
+	rxm_msg->rma_iov = orig_msg->rma_iov;
+	rxm_msg->rma_iov_count = orig_msg->rma_iov_count;
+}
+
+static inline ssize_t
+rxm_ep_rma_emulate_inject_msg(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn, size_t total_size,
+			      const struct fi_msg_rma *msg, uint64_t flags)
 {
-	struct rxm_tx_entry *tx_entry;
 	struct rxm_rma_buf *rma_buf;
-	struct util_cmap_handle *handle;
-	struct rxm_conn *rxm_conn;
-	size_t total_size = ofi_total_iov_len(msg->msg_iov, msg->iov_count);
 	ssize_t ret;
+	struct iovec rxm_msg_iov = { 0 };
+	struct fi_msg_rma rxm_rma_msg = { 0 };
 
 	assert(msg->rma_iov_count <= rxm_ep->rxm_info->tx_attr->rma_iov_limit);
 
-	fastlock_acquire(&rxm_ep->util_ep.cmap->lock);
-	handle = ofi_cmap_acquire_handle(rxm_ep->util_ep.cmap, msg->addr);
-	if (OFI_UNLIKELY(!handle)) {
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
-		return -FI_EAGAIN;
-	} else if (OFI_UNLIKELY(handle->state != CMAP_CONNECTED)) {
-		ret = ofi_cmap_handle_connect(rxm_ep->util_ep.cmap,
-					      msg->addr, handle);
-		if (OFI_UNLIKELY(ret != -FI_EAGAIN))
-			goto cmap_err;
-		rxm_conn = container_of(handle, struct rxm_conn, handle);
-		ret = rxm_ep_postpone_rma(rxm_ep, rxm_conn, total_size,
-					  flags, FI_WRITE, msg);
-cmap_err:
-		fastlock_release(&rxm_ep->util_ep.cmap->lock);
-		return ret;
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
+	rma_buf = rxm_rma_buf_alloc(rxm_ep);
+	if (OFI_UNLIKELY(!rma_buf)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+			"Ran out of buffers from RMA buffer pool\n");
+		ret = -FI_ENOMEM;
+		goto unlock;
 	}
-	fastlock_release(&rxm_ep->util_ep.cmap->lock);
-	rxm_conn = container_of(handle, struct rxm_conn, handle);
 
-	if (OFI_UNLIKELY(total_size > rxm_ep->rxm_info->tx_attr->inject_size))
-		return -FI_EMSGSIZE;
+	rma_buf->pkt.hdr.size = total_size;
+	rma_buf->app_context = msg->context;
+	rma_buf->flags = flags;
+	rxm_ep_format_rma_msg(rma_buf, msg, &rxm_msg_iov, &rxm_rma_msg);
+
+	flags = (flags & ~FI_INJECT) | FI_COMPLETION;
+
+	ret = fi_writemsg(rxm_conn->msg_ep, &rxm_rma_msg, flags);
+	if (OFI_UNLIKELY(ret)) {
+		if (ret == -FI_EAGAIN)
+			rxm_ep_do_progress(&rxm_ep->util_ep);
+		rxm_rma_buf_release(rxm_ep, rma_buf);
+	}
+unlock:
+	ofi_ep_lock_release(&rxm_ep->util_ep);
+	return ret;
+}
+
+static inline ssize_t
+rxm_ep_rma_emulate_inject(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
+			  const void *buf, size_t len, uint64_t data,
+			  fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			  uint64_t flags)
+{
+	struct fi_rma_iov rma_iov = {
+		.addr = addr,
+		.len = len,
+		.key = key,
+	};
+	struct iovec iov = {
+		.iov_base = (void*)buf,
+		.iov_len = len,
+	};
+	struct fi_msg_rma msg = {
+		.msg_iov = &iov,
+		.desc = NULL,
+		.iov_count = 1,
+		.addr = dest_addr,
+		.rma_iov = &rma_iov,
+		.rma_iov_count = 1,
+		.context = NULL,
+		.data = data,
+	};
+
+	return rxm_ep_rma_emulate_inject_msg(rxm_ep, rxm_conn, len, &msg, flags);
+}
+
+static inline ssize_t
+rxm_ep_rma_inject_common(struct rxm_ep *rxm_ep, const struct fi_msg_rma *msg, uint64_t flags)
+{
+	struct rxm_conn *rxm_conn;
+	size_t total_size = ofi_total_iov_len(msg->msg_iov, msg->iov_count);
+	ssize_t ret;
+
+	assert(total_size <= rxm_ep->rxm_info->tx_attr->inject_size);
+
+	ret = rxm_ep_prepare_tx(rxm_ep, msg->addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
 
-	/* Use fi_inject_write instead of fi_writemsg since the latter generates
-	 * completion by default */
 	if ((total_size <= rxm_ep->msg_info->tx_attr->inject_size) &&
-	    !(flags & FI_COMPLETION)) {
-		if (flags & FI_REMOTE_CQ_DATA)
+	    !(flags & FI_COMPLETION) &&
+	    (msg->iov_count == 1) && (msg->rma_iov_count == 1)) {
+		if (flags & FI_REMOTE_CQ_DATA) {
 			ret = fi_inject_writedata(rxm_conn->msg_ep,
 						  msg->msg_iov->iov_base,
 						  msg->msg_iov->iov_len, msg->data,
 						  msg->addr, msg->rma_iov->addr,
 						  msg->rma_iov->key);
-		else
+		} else {
 			ret = fi_inject_write(rxm_conn->msg_ep,
 					      msg->msg_iov->iov_base,
 					      msg->msg_iov->iov_len, msg->addr,
 					      msg->rma_iov->addr,
 					      msg->rma_iov->key);
-		if (OFI_LIKELY(!ret))
-			rxm_cntr_inc(rxm_ep->util_ep.wr_cntr);
-		return ret;
-	}
-
-	ret = rxm_ep_format_rma_inject_res(rxm_ep, total_size, flags, FI_WRITE,
-					   msg, &rma_buf, &tx_entry);
-	if (OFI_UNLIKELY(ret))
+		}
+		if (OFI_LIKELY(!ret)) {
+			ofi_ep_wr_cntr_inc(&rxm_ep->util_ep);
+		} else {
+			FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
+			       "fi_inject_write* for MSG provider failed with ret - %"
+			       PRId64"\n", ret);
+			if (OFI_LIKELY(ret == -FI_EAGAIN))
+				rxm_ep_progress(&rxm_ep->util_ep);
+		}
 		return ret;
-	flags = (flags & ~FI_INJECT) | FI_COMPLETION;
-	ret = fi_writemsg(rxm_conn->msg_ep, &rma_buf->msg, flags);
-	if (OFI_UNLIKELY(ret)) {
-		if (ret == -FI_EAGAIN)
-			rxm_ep_progress_multi(&rxm_ep->util_ep);
-		goto err;
+	} else {
+		return rxm_ep_rma_emulate_inject_msg(rxm_ep, rxm_conn, total_size, msg, flags);
 	}
-	return 0;
-err:
-	rxm_rma_buf_release(rxm_ep, tx_entry->rma_buf);
-	rxm_tx_entry_release(&rxm_ep->send_queue, tx_entry);
-	return ret;
 }
 
-static ssize_t rxm_ep_writemsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
-			       uint64_t flags)
+static inline ssize_t
+rxm_ep_writemsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg, uint64_t flags)
 {
 	struct rxm_ep *rxm_ep =
 		container_of(ep_fid, struct rxm_ep, util_ep.ep_fid.fid);
 
 	if (flags & FI_INJECT)
-		return rxm_ep_rma_inject(rxm_ep, msg, flags);
+		return rxm_ep_rma_inject_common(rxm_ep, msg, flags);
 	else
 		return rxm_ep_rma_common(rxm_ep, msg, flags,
 					 fi_writemsg, FI_WRITE);
@@ -602,34 +405,35 @@ static ssize_t rxm_ep_write(struct fid_ep *ep_fid, const void *buf,
 }
 
 static ssize_t rxm_ep_inject_write(struct fid_ep *ep_fid, const void *buf,
-			     size_t len, fi_addr_t dest_addr, uint64_t addr,
-			     uint64_t key)
+				   size_t len, fi_addr_t dest_addr,
+				   uint64_t addr, uint64_t key)
 {
-	struct fi_rma_iov rma_iov = {
-		.addr = addr,
-		.len = len,
-		.key = key,
-	};
-	struct iovec iov = {
-		.iov_base = (void*)buf,
-		.iov_len = len,
-	};
-	struct fi_msg_rma msg = {
-		.msg_iov = &iov,
-		.desc = NULL,
-		.iov_count = 1,
-		.addr = dest_addr,
-		.rma_iov = &rma_iov,
-		.rma_iov_count = 1,
-		.context = NULL,
-		.data = 0,
-	};
+	ssize_t ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
 
-	return rxm_ep_writemsg(ep_fid, &msg,
-			       (rxm_ep_tx_flags(rxm_ep) & ~FI_COMPLETION) |
-			       FI_INJECT);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
+
+	if (len <= rxm_ep->msg_info->tx_attr->inject_size) {
+		ret = fi_inject_write(rxm_conn->msg_ep, buf, len,
+				      dest_addr, addr, key);
+		if (OFI_LIKELY(!ret)) {
+			ofi_ep_wr_cntr_inc(&rxm_ep->util_ep);
+		} else {
+			FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
+			       "fi_inject_write for MSG provider failed with ret - %"
+			       PRId64"\n", ret);
+			if (OFI_LIKELY(ret == -FI_EAGAIN))
+				rxm_ep_progress(&rxm_ep->util_ep);
+		}
+		return ret;
+	} else {
+		return rxm_ep_rma_emulate_inject(rxm_ep, rxm_conn, buf, len,
+						 0, dest_addr, addr, key, FI_INJECT);
+	}
 }
 
 static ssize_t rxm_ep_inject_writedata(struct fid_ep *ep_fid, const void *buf,
@@ -637,31 +441,32 @@ static ssize_t rxm_ep_inject_writedata(struct fid_ep *ep_fid, const void *buf,
 				       fi_addr_t dest_addr, uint64_t addr,
 				       uint64_t key)
 {
-	struct fi_rma_iov rma_iov = {
-		.addr = addr,
-		.len = len,
-		.key = key,
-	};
-	struct iovec iov = {
-		.iov_base = (void*)buf,
-		.iov_len = len,
-	};
-	struct fi_msg_rma msg = {
-		.msg_iov = &iov,
-		.desc = NULL,
-		.iov_count = 1,
-		.addr = dest_addr,
-		.rma_iov = &rma_iov,
-		.rma_iov_count = 1,
-		.context = NULL,
-		.data = data,
-	};
+	ssize_t ret;
+	struct rxm_conn *rxm_conn;
 	struct rxm_ep *rxm_ep = container_of(ep_fid, struct rxm_ep,
 					     util_ep.ep_fid.fid);
+	ret = rxm_ep_prepare_tx(rxm_ep, dest_addr, &rxm_conn);
+	if (OFI_UNLIKELY(ret))
+		return ret;
 
-	return rxm_ep_writemsg(ep_fid, &msg,
-			       (rxm_ep_tx_flags(rxm_ep) & ~FI_COMPLETION) |
-			       FI_INJECT | FI_REMOTE_CQ_DATA);
+	if (len <= rxm_ep->msg_info->tx_attr->inject_size) {
+		ret = fi_inject_writedata(rxm_conn->msg_ep, buf, len,
+					  data, dest_addr, addr, key);
+		if (OFI_LIKELY(!ret)) {
+			ofi_ep_wr_cntr_inc(&rxm_ep->util_ep);
+		} else {
+			FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
+			       "fi_inject_writedata for MSG provider failed with ret - %"
+			       PRId64"\n", ret);
+			if (OFI_LIKELY(ret == -FI_EAGAIN))
+				rxm_ep_progress(&rxm_ep->util_ep);
+		}
+		return ret;
+	} else {
+		return rxm_ep_rma_emulate_inject(rxm_ep, rxm_conn, buf, len,
+						 data, dest_addr, addr, key,
+						 FI_REMOTE_CQ_DATA | FI_INJECT);
+	}
 }
 
 struct fi_ops_rma rxm_ops_rma = {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr.h
index 6e19f5602..06a4f227b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr.h
@@ -233,10 +233,7 @@ int smr_rx_comp_signal(struct smr_ep *ep, void *context, uint64_t flags,
 int smr_rx_src_comp_signal(struct smr_ep *ep, void *context, uint64_t flags,
 			   size_t len, void *buf, void *addr, uint64_t tag,
 			   uint64_t data, uint64_t err);
-
-uint64_t smr_tx_comp_flags(uint32_t op);
-uint64_t smr_rx_comp_flags(uint32_t op, uint16_t op_flags);
-uint64_t smr_mr_reg_flags(uint32_t op, uint16_t atomic_op);
+uint64_t smr_rx_cq_flags(uint32_t op, uint16_t op_flags);
 
 void smr_ep_progress(struct util_ep *util_ep);
 int smr_progress_unexp(struct smr_ep *ep, struct smr_ep_entry *entry);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_atomic.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_atomic.c
index f536e936b..519361b25 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_atomic.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_atomic.c
@@ -119,16 +119,6 @@ static void smr_format_inject_atomic(struct smr_cmd *cmd, fi_addr_t peer_id,
 	}
 }
 
-static void smr_ioc_to_iov(const struct fi_ioc *ioc, struct iovec *iov,
-			   size_t count, size_t size)
-{
-	int i;
-	for (i = 0; i < count; i++) {
-		iov[i].iov_base = ioc[i].addr;
-		iov[i].iov_len = ioc[i].count * size;
-	}
-}
-
 static int smr_fetch_result(struct smr_ep *ep, struct smr_region *peer_smr,
 			    struct iovec *iov, size_t iov_count,
 			    const struct fi_rma_ioc *rma_ioc, size_t rma_count,
@@ -235,13 +225,13 @@ static ssize_t smr_generic_atomic(struct fid_ep *ep_fid,
 	switch (op) {
 	case ofi_op_atomic_compare:
 		assert(compare_ioc);
-		smr_ioc_to_iov(compare_ioc, compare_iov, compare_count,
+		ofi_ioc_to_iov(compare_ioc, compare_iov, compare_count,
 			       ofi_datatype_size(datatype));
 		total_len *= 2;
 		/* fall through */
 	case ofi_op_atomic_fetch:
 		assert(result_ioc);
-		smr_ioc_to_iov(result_ioc, result_iov, result_count,
+		ofi_ioc_to_iov(result_ioc, result_iov, result_count,
 			       ofi_datatype_size(datatype));
 		if (!domain->fast_rma)
 			flags |= SMR_RMA_REQ;
@@ -249,7 +239,7 @@ static ssize_t smr_generic_atomic(struct fid_ep *ep_fid,
 	case ofi_op_atomic:
 		if (atomic_op != FI_ATOMIC_READ) {
 			assert(ioc);
-			smr_ioc_to_iov(ioc, iov, count, ofi_datatype_size(datatype));
+			ofi_ioc_to_iov(ioc, iov, count, ofi_datatype_size(datatype));
 		} else {
 			count = 0;
 		}
@@ -293,7 +283,7 @@ static ssize_t smr_generic_atomic(struct fid_ep *ep_fid,
 				"unable to fetch results");
 	}
 
-	ret = ep->tx_comp(ep, context, smr_tx_comp_flags(op), err);
+	ret = ep->tx_comp(ep, context, ofi_tx_cq_flags(op), err);
 	if (ret) {
 		FI_WARN(&smr_prov, FI_LOG_EP_CTRL,
 			"unable to process tx completion\n");
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_av.c
index 505e0ebed..18c819834 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_av.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_av.c
@@ -72,7 +72,7 @@ static int smr_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
 
 	for (i = 0; i < count; i++) {
 		ep_name = smr_no_prefix((const char *) smr_names[i].name);
-		ret = ofi_av_insert_addr(util_av, ep_name, 0, &index);
+		ret = ofi_av_insert_addr(util_av, ep_name, (fi_addr_t *)&index);
 		if (ret) {
 			if (util_av->eq)
 				ofi_av_write_event(util_av, i, -ret, context);
@@ -119,7 +119,7 @@ static int smr_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr, size_t count
 
 	fastlock_acquire(&util_av->lock);
 	for (i = 0; i < count; i++) {
-		ret = ofi_av_remove_addr(util_av, 0, fi_addr[i]);
+		ret = ofi_av_remove_addr(util_av, fi_addr[i]);
 		if (ret) {
 			FI_WARN(&smr_prov, FI_LOG_AV,
 				"Unable to remove address from AV\n");
@@ -212,7 +212,6 @@ int smr_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 		return -FI_ENOMEM;
 
 	util_attr.addrlen = sizeof(int);
-	util_attr.overhead = 0;
 	util_attr.flags = 0;
 	if (attr->count > SMR_MAX_PEERS) {
 		ret = -FI_ENOSYS;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_comp.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_comp.c
index 58e44c3d8..5fc57497d 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_comp.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_comp.c
@@ -41,18 +41,18 @@
 int smr_tx_comp(struct smr_ep *ep, void *context, uint64_t flags, uint64_t err)
 {
 	struct fi_cq_tagged_entry *comp;
-	struct util_cq_err_entry *entry;
+	struct util_cq_oflow_err_entry *entry;
 
 	comp = ofi_cirque_tail(ep->util_ep.tx_cq->cirq);
 	if (err) {
 		if (!(entry = calloc(1, sizeof(*entry))))
 			return -FI_ENOMEM;
-		entry->err_entry.op_context = context;
-		entry->err_entry.flags = flags;
-		entry->err_entry.err = err;
-		entry->err_entry.prov_errno = -err;
+		entry->comp.op_context = context;
+		entry->comp.flags = flags;
+		entry->comp.err = err;
+		entry->comp.prov_errno = -err;
 		slist_insert_tail(&entry->list_entry,
-				  &ep->util_ep.tx_cq->err_list);
+				  &ep->util_ep.tx_cq->oflow_err_list);
 		comp->flags = UTIL_FLAG_ERROR;
 	} else {
 		comp->op_context = context;
@@ -82,19 +82,19 @@ int smr_rx_comp(struct smr_ep *ep, void *context, uint64_t flags, size_t len,
 		uint64_t err)
 {
 	struct fi_cq_tagged_entry *comp;
-	struct util_cq_err_entry *entry;
+	struct util_cq_oflow_err_entry *entry;
 
 	comp = ofi_cirque_tail(ep->util_ep.rx_cq->cirq);
 	if (err) {
 		if (!(entry = calloc(1, sizeof(*entry))))
 			return -FI_ENOMEM;
-		entry->err_entry.op_context = context;
-		entry->err_entry.flags = flags;
-		entry->err_entry.tag = tag;
-		entry->err_entry.err = err;
-		entry->err_entry.prov_errno = -err;
+		entry->comp.op_context = context;
+		entry->comp.flags = flags;
+		entry->comp.tag = tag;
+		entry->comp.err = err;
+		entry->comp.prov_errno = -err;
 		slist_insert_tail(&entry->list_entry,
-				  &ep->util_ep.rx_cq->err_list);
+				  &ep->util_ep.rx_cq->oflow_err_list);
 		comp->flags = UTIL_FLAG_ERROR;
 	} else {
 		comp->op_context = context;
@@ -144,57 +144,14 @@ int smr_rx_src_comp_signal(struct smr_ep *ep, void *context, uint64_t flags,
 
 }
 
-static const uint64_t smr_tx_flags[] = {
-	[ofi_op_msg] = FI_SEND,
-	[ofi_op_tagged] = FI_SEND | FI_TAGGED,
-	[ofi_op_read_req] = FI_RMA | FI_READ,
-	[ofi_op_write] = FI_RMA | FI_WRITE,
-	[ofi_op_atomic] = FI_ATOMIC | FI_WRITE,
-	[ofi_op_atomic_fetch] = FI_ATOMIC | FI_WRITE | FI_READ,
-	[ofi_op_atomic_compare] = FI_ATOMIC | FI_WRITE | FI_READ,
-};
-
-uint64_t smr_tx_comp_flags(uint32_t op)
-{
-	return smr_tx_flags[op];
-}
-
-static const uint64_t smr_rx_flags[] = {
-	[ofi_op_msg] = FI_RECV,
-	[ofi_op_tagged] = FI_RECV | FI_TAGGED,
-	[ofi_op_read_req] = FI_RMA | FI_REMOTE_READ,
-	[ofi_op_write] = FI_RMA | FI_REMOTE_WRITE,
-	[ofi_op_atomic] = FI_ATOMIC | FI_REMOTE_WRITE,
-	[ofi_op_atomic_fetch] = FI_ATOMIC | FI_REMOTE_WRITE | FI_REMOTE_READ,
-	[ofi_op_atomic_compare] = FI_ATOMIC | FI_REMOTE_WRITE | FI_REMOTE_READ,
-};
-
-uint64_t smr_rx_comp_flags(uint32_t op, uint16_t op_flags)
+uint64_t smr_rx_cq_flags(uint32_t op, uint16_t op_flags)
 {
 	uint64_t flags;
 
-	flags = smr_rx_flags[op];
+	flags = ofi_rx_cq_flags(op);
 
 	if (op_flags & SMR_REMOTE_CQ_DATA)
 		flags |= FI_REMOTE_CQ_DATA;
 
 	return flags;
 }
-
-static const uint64_t smr_mr_flags[] = {
-	[ofi_op_msg] = FI_RECV,
-	[ofi_op_tagged] = FI_RECV,
-	[ofi_op_read_req] = FI_REMOTE_READ,
-	[ofi_op_write] = FI_REMOTE_WRITE,
-	[ofi_op_atomic] = FI_REMOTE_WRITE,
-	[ofi_op_atomic_fetch] =  FI_REMOTE_WRITE | FI_REMOTE_READ,
-	[ofi_op_atomic_compare] = FI_REMOTE_WRITE | FI_REMOTE_READ,
-};
-
-uint64_t smr_mr_reg_flags(uint32_t op, uint16_t atomic_op)
-{
-	if (atomic_op == FI_ATOMIC_READ)
-		return FI_REMOTE_READ;
-
-	return smr_mr_flags[op];
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_ep.c
index 4fae47ea8..f4815f37d 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_ep.c
@@ -476,9 +476,9 @@ int smr_endpoint(struct fid_domain *domain, struct fi_info *info,
 	if (ret)
 		goto err1;
 
-	ep->recv_fs = smr_recv_fs_create(info->rx_attr->size);
-	ep->unexp_fs = smr_unexp_fs_create(info->rx_attr->size);
-	ep->pend_fs = smr_pend_fs_create(info->tx_attr->size);
+	ep->recv_fs = smr_recv_fs_create(info->rx_attr->size, NULL, NULL);
+	ep->unexp_fs = smr_unexp_fs_create(info->rx_attr->size, NULL, NULL);
+	ep->pend_fs = smr_pend_fs_create(info->tx_attr->size, NULL, NULL);
 	smr_init_queue(&ep->recv_queue, smr_match_msg);
 	smr_init_queue(&ep->trecv_queue, smr_match_tagged);
 	smr_init_queue(&ep->unexp_queue, smr_match_unexp);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_init.c
index fc29c4b89..c49a97a53 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_init.c
@@ -112,7 +112,7 @@ static void smr_fini(void)
 struct fi_provider smr_prov = {
 	.name = "shm",
 	.version = FI_VERSION(SMR_MAJOR_VERSION, SMR_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = smr_getinfo,
 	.fabric = smr_fabric,
 	.cleanup = smr_fini
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_msg.c
index 0738ef658..82bcd7599 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_msg.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_msg.c
@@ -38,88 +38,110 @@
 #include "smr.h"
 
 
-static ssize_t smr_generic_recvmsg(struct smr_ep *ep, const struct iovec *iov,
-				   size_t iov_count, fi_addr_t addr, uint64_t tag,
-				   uint64_t ignore, void *context, uint64_t flags)
+static inline struct smr_ep_entry *smr_get_recv_entry(struct smr_ep *ep)
 {
-	struct smr_queue *recv_queue;
 	struct smr_ep_entry *entry;
-	ssize_t ret;
 
-	assert(iov_count <= SMR_IOV_LIMIT);
-	assert(!(flags & FI_MULTI_RECV) || iov_count == 1);
+	if (freestack_isempty(ep->recv_fs))
+		return NULL;
+
+	entry = freestack_pop(ep->recv_fs);
+
+	entry->tag = 0; /* does this need to be set? */
+	entry->ignore = 0; /* does this need to be set? */
+	entry->err = 0;
+	return entry;
+}
+
+ssize_t smr_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+		    uint64_t flags)
+{
+	struct smr_ep_entry *entry;
+	struct smr_ep *ep;
+	ssize_t ret = 0;
+
+	assert(msg->iov_count <= SMR_IOV_LIMIT);
+	assert(!(flags & FI_MULTI_RECV) || msg->iov_count == 1);
 
+	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
 	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
-	if (freestack_isempty(ep->recv_fs)) {
+	entry = smr_get_recv_entry(ep);
+	if (!entry) {
 		ret = -FI_EAGAIN;
 		goto out;
 	}
-	entry = freestack_pop(ep->recv_fs);
-	memset(entry, 0, sizeof(*entry));
 
-	for (entry->iov_count = 0; entry->iov_count < iov_count;
-	     entry->iov_count++) {
-		entry->iov[entry->iov_count] = iov[entry->iov_count];
-	}
+	entry->iov_count = msg->iov_count;
+	memcpy(&entry->iov, msg->msg_iov, sizeof(*msg->msg_iov) * msg->iov_count);
 
-	entry->context = context;
+	entry->context = msg->context;
 	entry->flags = flags;
-	entry->addr = addr;
-	entry->tag = tag;
-	entry->ignore = ignore;
+	entry->addr = msg->addr;
 
-	if (flags & FI_TAGGED) {
-		ret = smr_progress_unexp(ep, entry);
-		if (!ret || ret == -FI_EAGAIN)
-			goto out;
-		recv_queue = &ep->trecv_queue;
-	} else {
-		recv_queue = &ep->recv_queue;
-	}
-
-	dlist_insert_tail(&entry->entry, &recv_queue->list);
-
-	ret = 0;
+	dlist_insert_tail(&entry->entry, &ep->recv_queue.list);
 out:
 	fastlock_release(&ep->util_ep.rx_cq->cq_lock);
 	return ret;
 }
 
-ssize_t smr_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
-		    uint64_t flags)
+ssize_t smr_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		size_t count, fi_addr_t src_addr, void *context)
 {
+	struct smr_ep_entry *entry;
 	struct smr_ep *ep;
+	ssize_t ret = 0;
 
 	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
+	assert(count <= SMR_IOV_LIMIT);
+	assert(!(smr_ep_rx_flags(ep) & FI_MULTI_RECV) || count == 1);
 
-	return smr_generic_recvmsg(ep, msg->msg_iov, msg->iov_count,
-				   msg->addr, 0, 0, msg->context, flags);
-}
+	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
+	entry = smr_get_recv_entry(ep);
+	if (!entry) {
+		ret = -FI_EAGAIN;
+		goto out;
+	}
 
-ssize_t smr_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
-		size_t count, fi_addr_t src_addr, void *context)
-{
-	struct smr_ep *ep;
+	entry->iov_count = count;
+	memcpy(&entry->iov, iov, sizeof(*iov) * count);
 
-	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
+	entry->context = context;
+	entry->flags = smr_ep_rx_flags(ep);
+	entry->addr = src_addr;
 
-	return smr_generic_recvmsg(ep, iov, count, src_addr,
-				   0, 0, context, smr_ep_rx_flags(ep));
+	dlist_insert_tail(&entry->entry, &ep->recv_queue.list);
+out:
+	fastlock_release(&ep->util_ep.rx_cq->cq_lock);
+	return ret;
 }
 
 ssize_t smr_recv(struct fid_ep *ep_fid, void *buf, size_t len, void *desc,
 		fi_addr_t src_addr, void *context)
 {
+	struct smr_ep_entry *entry;
 	struct smr_ep *ep;
-	struct iovec msg_iov;
+	ssize_t ret = 0;
 
 	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
+	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
+	entry = smr_get_recv_entry(ep);
+	if (!entry) {
+		ret = -FI_EAGAIN;
+		goto out;
+	}
 
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
+	entry->iov_count = 1;
+	entry->iov[0].iov_base = buf;
+	entry->iov[0].iov_len = len;
+
+	entry->context = context;
+	entry->flags = smr_ep_rx_flags(ep);
+	entry->addr = src_addr;
 
-	return smr_generic_recvmsg(ep, &msg_iov, 1, src_addr, 0, 0, context,
-				   smr_ep_rx_flags(ep));
+	dlist_insert_tail(&entry->entry, &ep->recv_queue.list);
+out:
+	fastlock_release(&ep->util_ep.rx_cq->cq_lock);
+	return ret;
 }
 
 static ssize_t smr_generic_sendmsg(struct smr_ep *ep, const struct iovec *iov,
@@ -178,7 +200,7 @@ static ssize_t smr_generic_sendmsg(struct smr_ep *ep, const struct iovec *iov,
 		ofi_cirque_commit(smr_resp_queue(ep->region));
 		goto commit;
 	}
-	ret = ep->tx_comp(ep, context, smr_tx_comp_flags(op), 0);
+	ret = ep->tx_comp(ep, context, ofi_tx_cq_flags(op), 0);
 	if (ret) {
 		FI_WARN(&smr_prov, FI_LOG_EP_CTRL,
 			"unable to process tx completion\n");
@@ -328,43 +350,127 @@ struct fi_ops_msg smr_msg_ops = {
 	.injectdata = smr_injectdata,
 };
 
+static inline struct smr_ep_entry *smr_get_trecv_entry(struct smr_ep *ep)
+{
+	struct smr_ep_entry *entry;
+
+	if (freestack_isempty(ep->recv_fs))
+		return NULL;
+
+	entry = freestack_pop(ep->recv_fs);
+	entry->err = 0;
+	return entry;
+}
+
+static inline ssize_t
+smr_proccess_trecv_post(struct smr_ep *ep, struct smr_ep_entry *entry)
+{
+	ssize_t ret;
+
+	ret = smr_progress_unexp(ep, entry);
+	if (!ret || ret == -FI_EAGAIN)
+		return ret;
+
+	dlist_insert_tail(&entry->entry, &ep->trecv_queue.list);
+	return 0;
+}
+
 ssize_t smr_trecv(struct fid_ep *ep_fid, void *buf, size_t len, void *desc,
 	fi_addr_t src_addr, uint64_t tag, uint64_t ignore, void *context)
 {
+	struct smr_ep_entry *entry;
 	struct smr_ep *ep;
-	struct iovec msg_iov;
+	ssize_t ret;
 
 	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
+	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
+	entry = smr_get_trecv_entry(ep);
+	if (!entry) {
+		ret = -FI_EAGAIN;
+		goto out;
+	}
 
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
+	entry->iov_count = 1;
+	entry->iov[0].iov_base = buf;
+	entry->iov[0].iov_len = len;
 
-	return smr_generic_recvmsg(ep, &msg_iov, 1, src_addr, tag, ignore,
-				   context, FI_TAGGED | smr_ep_tx_flags(ep));
+	entry->context = context;
+	entry->flags = smr_ep_rx_flags(ep);
+	entry->addr = src_addr;
+	entry->tag = tag;
+	entry->ignore = ignore;
+
+	ret = smr_proccess_trecv_post(ep, entry);
+out:
+	fastlock_release(&ep->util_ep.rx_cq->cq_lock);
+	return ret;
 }
 
 ssize_t smr_trecvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
 	size_t count, fi_addr_t src_addr, uint64_t tag, uint64_t ignore,
 	void *context)
 {
+	struct smr_ep_entry *entry;
 	struct smr_ep *ep;
+	ssize_t ret;
 
 	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
+	assert(count <= SMR_IOV_LIMIT);
+	assert(!(smr_ep_rx_flags(ep) & FI_MULTI_RECV) || count == 1);
+
+	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
+	entry = smr_get_trecv_entry(ep);
+	if (!entry) {
+		ret = -FI_EAGAIN;
+		goto out;
+	}
 
-	return smr_generic_recvmsg(ep, iov, count, src_addr, tag, ignore,
-				   context, FI_TAGGED | smr_ep_tx_flags(ep));
+	entry->iov_count = count;
+	memcpy(&entry->iov, iov, sizeof(*iov) * count);
+
+	entry->context = context;
+	entry->flags = smr_ep_rx_flags(ep);
+	entry->addr = src_addr;
+	entry->tag = tag;
+	entry->ignore = ignore;
+
+	ret = smr_proccess_trecv_post(ep, entry);
+out:
+	fastlock_release(&ep->util_ep.rx_cq->cq_lock);
+	return ret;
 }
 
 ssize_t smr_trecvmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *msg,
 	uint64_t flags)
 {
+	struct smr_ep_entry *entry;
 	struct smr_ep *ep;
+	ssize_t ret;
+
+	assert(msg->iov_count <= SMR_IOV_LIMIT);
+	assert(!(flags & FI_MULTI_RECV) || msg->iov_count == 1);
 
 	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
+	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
+	entry = smr_get_trecv_entry(ep);
+	if (!entry) {
+		ret = -FI_EAGAIN;
+		goto out;
+	}
+
+	entry->iov_count = msg->iov_count;
+	memcpy(&entry->iov, msg->msg_iov, sizeof(*msg->msg_iov) * msg->iov_count);
+
+	entry->context = msg->context;
+	entry->flags = flags;
+	entry->addr = msg->addr;
+	entry->tag = msg->tag;
+	entry->ignore = msg->ignore;
 
-	return smr_generic_recvmsg(ep, msg->msg_iov, msg->iov_count, msg->addr,
-				   msg->tag, msg->ignore, msg->context,
-				   flags | FI_TAGGED);
+	ret = smr_proccess_trecv_post(ep, entry);
+out:
+	fastlock_release(&ep->util_ep.rx_cq->cq_lock);
+	return ret;
 }
 
 ssize_t smr_tsend(struct fid_ep *ep_fid, const void *buf, size_t len,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_progress.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_progress.c
index c2a49e84b..eecbb7680 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_progress.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_progress.c
@@ -95,7 +95,7 @@ static void smr_progress_resp(struct smr_ep *ep)
 				break;
 
 		ret = ep->tx_comp(ep, (void *) (uintptr_t) pending->msg.hdr.msg_id,
-				  smr_tx_comp_flags(pending->msg.hdr.op),
+				  ofi_tx_cq_flags(pending->msg.hdr.op),
 				  -(resp->status));
 		if (ret) {
 			FI_WARN(&smr_prov, FI_LOG_EP_CTRL,
@@ -381,7 +381,7 @@ static int smr_progress_cmd_msg(struct smr_ep *ep, struct smr_cmd *cmd)
 			"unidentified operation type\n");
 		err = -FI_EINVAL;
 	}
-	ret = ep->rx_comp(ep, entry->context, smr_rx_comp_flags(cmd->msg.hdr.op,
+	ret = ep->rx_comp(ep, entry->context, smr_rx_cq_flags(cmd->msg.hdr.op,
 			  cmd->msg.hdr.op_flags), total_len,
 			  entry->iov[0].iov_base, &addr, cmd->msg.hdr.tag,
 			  cmd->msg.hdr.data, err);
@@ -430,7 +430,7 @@ static int smr_progress_cmd_rma(struct smr_ep *ep, struct smr_cmd *cmd)
 				rma_cmd->rma.rma_iov[iov_count].len,
 				(uintptr_t *) &(rma_cmd->rma.rma_iov[iov_count].addr),
 				rma_cmd->rma.rma_iov[iov_count].key,
-				smr_mr_reg_flags(cmd->msg.hdr.op, 0));
+				ofi_rx_mr_reg_flags(cmd->msg.hdr.op, 0));
 		if (ret)
 			break;
 
@@ -459,7 +459,7 @@ static int smr_progress_cmd_rma(struct smr_ep *ep, struct smr_cmd *cmd)
 	}
 	if (cmd->msg.hdr.op_flags & SMR_REMOTE_CQ_DATA) {
 		ret = ep->rx_comp(ep, (void *) cmd->msg.hdr.msg_id,
-				  smr_rx_comp_flags(cmd->msg.hdr.op,
+				  smr_rx_cq_flags(cmd->msg.hdr.op,
 				  cmd->msg.hdr.op_flags), total_len,
 				  NULL, &cmd->msg.hdr.addr, 0,
 				  cmd->msg.hdr.data, err);
@@ -496,7 +496,7 @@ static int smr_progress_cmd_atomic(struct smr_ep *ep, struct smr_cmd *cmd)
 				ofi_datatype_size(cmd->msg.hdr.datatype),
 				(uintptr_t *) &(rma_cmd->rma.rma_ioc[ioc_count].addr),
 				rma_cmd->rma.rma_ioc[ioc_count].key,
-				smr_mr_reg_flags(cmd->msg.hdr.op,
+				ofi_rx_mr_reg_flags(cmd->msg.hdr.op,
 				cmd->msg.hdr.atomic_op));
 		if (ret)
 			break;
@@ -643,7 +643,7 @@ int smr_progress_unexp(struct smr_ep *ep, struct smr_ep_entry *entry)
 		entry->err = FI_EINVAL;
 	}
 	ret = ep->rx_comp(ep, entry->context,
-			  smr_rx_comp_flags(unexp_msg->cmd.msg.hdr.op,
+			  smr_rx_cq_flags(unexp_msg->cmd.msg.hdr.op,
 			  unexp_msg->cmd.msg.hdr.op_flags), total_len,
 			  entry->iov[0].iov_base, &entry->addr, entry->tag,
 			  unexp_msg->cmd.msg. hdr.data, entry->err);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_rma.c
index d5a86cc85..724779398 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_rma.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/shm/src/smr_rma.c
@@ -178,7 +178,7 @@ commit_comp:
 	if (!comp)
 		goto unlock_cq;
 
-	ret = ep->tx_comp(ep, context, smr_tx_comp_flags(op), err);
+	ret = ep->tx_comp(ep, context, ofi_tx_cq_flags(op), err);
 	if (ret) {
 		FI_WARN(&smr_prov, FI_LOG_EP_CTRL,
 			"unable to process tx completion\n");
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/include/sock.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/include/sock.h
index fd4e21575..51ece303b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/include/sock.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/include/sock.h
@@ -64,7 +64,8 @@
 #ifndef _SOCK_H_
 #define _SOCK_H_
 
-#define SOCK_EP_MAX_MSG_SZ (SIZE_MAX - 4096) /* 4k allocated for all sockets headers */
+/* 4k allocated for all sockets headers */
+#define SOCK_EP_MAX_MSG_SZ (OFI_MAX_SOCKET_BUF_SIZE - 4096)
 #define SOCK_EP_MAX_INJECT_SZ ((1<<8) - 1)
 #define SOCK_EP_MAX_BUFF_RECV (1<<26)
 #define SOCK_EP_MAX_ORDER_RAW_SZ SOCK_EP_MAX_MSG_SZ
@@ -104,6 +105,7 @@
 #define SOCK_EP_MAX_RETRY (5)
 #define SOCK_EP_MAX_CM_DATA_SZ (256)
 #define SOCK_CM_DEF_BACKLOG (128)
+#define SOCK_CM_DEF_TIMEOUT (15000)
 #define SOCK_CM_DEF_RETRY (5)
 #define SOCK_CM_CONN_IN_PROGRESS ((struct sock_conn *)(0x1L))
 
@@ -178,7 +180,7 @@ enum {
 #define SOCK_MAJOR_VERSION 2
 #define SOCK_MINOR_VERSION 0
 
-#define SOCK_WIRE_PROTO_VERSION (1)
+#define SOCK_WIRE_PROTO_VERSION (2)
 
 struct sock_service_entry {
 	int service;
@@ -200,7 +202,7 @@ struct sock_conn {
 	int sock_fd;
 	int connected;
 	int address_published;
-	struct sockaddr_in addr;
+	union ofi_sock_ip addr;
 	struct sock_pe_entry *rx_pe_entry;
 	struct sock_pe_entry *tx_pe_entry;
 	struct sock_ep_attr *ep_attr;
@@ -226,6 +228,15 @@ struct sock_conn_listener {
 	int do_listen;
 };
 
+struct sock_ep_cm_head {
+	fi_epoll_t emap;
+	struct fd_signal signal;
+	fastlock_t signal_lock;
+	pthread_t listener_thread;
+	struct dlist_entry msg_list;
+	int do_listen;
+};
+
 struct sock_domain {
 	struct fi_info		info;
 	struct fid_domain	dom_fid;
@@ -242,6 +253,7 @@ struct sock_domain {
 	struct dlist_entry	dom_list_entry;
 	struct fi_domain_attr	attr;
 	struct sock_conn_listener conn_listener;
+	struct sock_ep_cm_head cm_head;
 };
 
 /* move to fi_trigger.h when removing experimental tag from work queues */
@@ -339,7 +351,7 @@ struct sock_mr {
 };
 
 struct sock_av_addr {
-	struct sockaddr_storage addr;
+	union ofi_sock_ip addr;
 	uint8_t valid;
 	uint8_t reserved[7];
 };
@@ -511,21 +523,28 @@ struct sock_comp {
 	struct sock_eq *eq;
 };
 
-struct sock_cm_entry {
+enum sock_cm_state {
+	SOCK_CM_STATE_DISCONNECTED = 0,
+	SOCK_CM_STATE_REQUESTED,
+	SOCK_CM_STATE_CONNECTED,
+};
+
+struct sock_pep_cm_entry {
 	int sock;
 	int do_listen;
 	int signal_fds[2];
-	uint64_t next_msg_id;
-	fastlock_t lock;
-	int is_connected;
 	pthread_t listener_thread;
-	struct dlist_entry msg_list;
+};
+
+struct sock_ep_cm_entry {
+	int sock;
+	fastlock_t lock;
+	enum sock_cm_state state;
 };
 
 struct sock_conn_handle {
 	int sock;
 	int do_listen;
-	char service[NI_MAXSERV];
 };
 
 struct sock_ep_attr {
@@ -556,15 +575,15 @@ struct sock_ep_attr {
 	struct fi_ep_attr ep_attr;
 
 	enum fi_ep_type ep_type;
-	struct sockaddr_in *src_addr;
-	struct sockaddr_in *dest_addr;
+	union ofi_sock_ip *src_addr;
+	union ofi_sock_ip *dest_addr;
 	uint16_t msg_src_port;
 	uint16_t msg_dest_port;
 
 	uint64_t peer_fid;
 	uint16_t key;
 	int is_enabled;
-	struct sock_cm_entry cm;
+	struct sock_ep_cm_entry cm;
 	struct sock_conn_handle conn_handle;
 	fastlock_t lock;
 
@@ -584,8 +603,9 @@ struct sock_pep {
 	struct fid_pep	pep;
 	struct sock_fabric *sock_fab;
 
-	struct sock_cm_entry cm;
-	struct sockaddr_in src_addr;
+	struct sock_ep_cm_head cm_head;
+	struct sock_pep_cm_entry cm;
+	union ofi_sock_ip src_addr;
 	struct fi_info info;
 	struct sock_eq *eq;
 	int name_set;
@@ -905,7 +925,7 @@ struct sock_conn_hdr {
 
 struct sock_conn_req {
 	struct sock_conn_hdr hdr;
-	struct sockaddr_in src_addr;
+	union ofi_sock_ip src_addr;
 	uint64_t caps;
 	char cm_data[0];
 };
@@ -917,22 +937,34 @@ enum {
 	SOCK_CONN_SHUTDOWN,
 };
 
+enum sock_conn_handle_state {
+	SOCK_CONN_HANDLE_ACTIVE,
+	SOCK_CONN_HANDLE_ACCEPTED,
+	SOCK_CONN_HANDLE_REJECTED,
+	SOCK_CONN_HANDLE_DELETED,
+	SOCK_CONN_HANDLE_FINALIZING,
+	SOCK_CONN_HANDLE_FINALIZED,
+};
+
 struct sock_conn_req_handle {
 	struct fid handle;
 	struct sock_conn_req *req;
 	int sock_fd;
-	int is_accepted;
+	uint8_t monitored;
+	enum sock_conn_handle_state state;
+	pthread_mutex_t	finalized_mutex;
+	pthread_cond_t	finalized_cond;
 	struct sock_pep *pep;
 	struct sock_ep *ep;
 	size_t paramlen;
-	pthread_t req_handler;
-	struct sockaddr_in dest_addr;
+	union ofi_sock_ip dest_addr;
 	struct dlist_entry entry;
 	char cm_data[SOCK_EP_MAX_CM_DATA_SZ];
 };
 
 struct sock_host_list_entry {
-	char hostname[HOST_NAME_MAX];
+	char ipstr[INET6_ADDRSTRLEN];
+	union ofi_sock_ip ipaddr;
 	struct slist_entry entry;
 };
 
@@ -987,9 +1019,10 @@ int sock_dgram_verify_ep_attr(const struct fi_ep_attr *ep_attr,
 int sock_msg_verify_ep_attr(const struct fi_ep_attr *ep_attr,
 			    const struct fi_tx_attr *tx_attr,
 			    const struct fi_rx_attr *rx_attr);
-int sock_get_src_addr(struct sockaddr_in *dest_addr,
-		      struct sockaddr_in *src_addr);
-int sock_get_src_addr_from_hostname(struct sockaddr_in *src_addr, const char *service);
+int sock_get_src_addr(union ofi_sock_ip *dest_addr,
+		      union ofi_sock_ip *src_addr);
+int sock_get_src_addr_from_hostname(union ofi_sock_ip *src_addr,
+				    const char *service, uint16_t sa_family);
 
 struct fi_info *sock_fi_info(uint32_t version, enum fi_ep_type ep_type,
 			     const struct fi_info *hints, void *src_addr,
@@ -1122,10 +1155,10 @@ int sock_wait_close(fid_t fid);
 int sock_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 		 struct fid_av **av, void *context);
 int sock_av_compare_addr(struct sock_av *av, fi_addr_t addr1, fi_addr_t addr2);
-int sock_av_get_addr_index(struct sock_av *av, struct sockaddr_in *addr);
+int sock_av_get_addr_index(struct sock_av *av, union ofi_sock_ip *addr);
 
 struct sock_conn *sock_ep_lookup_conn(struct sock_ep_attr *attr, fi_addr_t index,
-                                      struct sockaddr_in *addr);
+				      union ofi_sock_ip *addr);
 int sock_ep_get_conn(struct sock_ep_attr *ep_attr, struct sock_tx_ctx *tx_ctx,
 		     fi_addr_t index, struct sock_conn **pconn);
 void sock_ep_remove_conn(struct sock_ep_attr *ep_attr, struct sock_conn *conn);
@@ -1221,4 +1254,11 @@ static inline size_t sock_rx_avail_len(struct sock_rx_entry *rx_entry)
 	return rx_entry->total_len - rx_entry->used;
 }
 
+int sock_ep_cm_start_thread(struct sock_ep_cm_head *cm_head);
+void sock_ep_cm_signal(struct sock_ep_cm_head *cm_head);
+void sock_ep_cm_signal_locked(struct sock_ep_cm_head *cm_head);
+void sock_ep_cm_stop_thread(struct sock_ep_cm_head *cm_head);
+void sock_ep_cm_wait_handle_finalized(struct sock_ep_cm_head *cm_head,
+                                      struct sock_conn_req_handle *handle);
+
 #endif
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/include/sock_util.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/include/sock_util.h
index a4e428474..fc5c58601 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/include/sock_util.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/include/sock_util.h
@@ -44,6 +44,7 @@ extern const char sock_dom_name[];
 extern const char sock_prov_name[];
 extern struct fi_provider sock_prov;
 extern int sock_pe_waittime;
+extern int sock_conn_timeout;
 extern int sock_conn_retry;
 extern int sock_cm_def_map_sz;
 extern int sock_av_def_sz;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_av.c
index 2fc025fe5..e2760e2e2 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_av.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_av.c
@@ -63,7 +63,7 @@
 				count * sizeof(struct sock_av_addr))
 #define SOCK_IS_SHARED_AV(av_name) ((av_name) ? 1 : 0)
 
-int sock_av_get_addr_index(struct sock_av *av, struct sockaddr_in *addr)
+int sock_av_get_addr_index(struct sock_av *av, union ofi_sock_ip *addr)
 {
 	int i;
 	struct sock_av_addr *av_addr;
@@ -73,7 +73,8 @@ int sock_av_get_addr_index(struct sock_av *av, struct sockaddr_in *addr)
 		if (!av_addr->valid)
 			continue;
 
-		 if (ofi_equals_sockaddr(addr, (struct sockaddr_in *)&av_addr->addr))
+		 if (ofi_equals_sockaddr((const struct sockaddr *) addr,
+					 (const struct sockaddr *) &av_addr->addr))
 			return i;
 	}
 	SOCK_LOG_DBG("failed to get index in AV\n");
@@ -98,8 +99,8 @@ int sock_av_compare_addr(struct sock_av *av,
 	av_addr1 = &av->table[index1];
 	av_addr2 = &av->table[index2];
 
-	return memcmp(&av_addr1->addr, &av_addr2->addr,
-		      sizeof(struct sockaddr_in));
+	/* Return 0 if the addresses match */
+	return !ofi_equals_sockaddr(&av_addr1->addr.sa, &av_addr2->addr.sa);
 }
 
 static inline void sock_av_report_success(struct sock_av *av, void *context,
@@ -127,9 +128,9 @@ static inline void sock_av_report_error(struct sock_av *av,
 			     context, index, err, -err, NULL, 0);
 }
 
-static int sock_av_is_valid_address(struct sockaddr_in *addr)
+static int sock_av_is_valid_address(const struct sockaddr *addr)
 {
-	return addr->sin_family == AF_INET ? 1 : 0;
+	return ofi_sizeofaddr(addr);
 }
 
 static void sock_update_av_table(struct sock_av *_av, size_t count)
@@ -180,13 +181,13 @@ static int sock_av_get_next_index(struct sock_av *av)
 	return -1;
 }
 
-static int sock_check_table_in(struct sock_av *_av, struct sockaddr_in *addr,
+static int sock_check_table_in(struct sock_av *_av, const struct sockaddr *addr,
 			       fi_addr_t *fi_addr, int count, uint64_t flags,
 			       void *context)
 {
 	int i, ret = 0;
 	uint64_t j;
-	char sa_ip[INET_ADDRSTRLEN];
+	char sa_ip[INET6_ADDRSTRLEN];
 	struct sock_av_addr *av_addr;
 	int index;
 
@@ -207,7 +208,7 @@ static int sock_check_table_in(struct sock_av *_av, struct sockaddr_in *addr,
 
 				av_addr = &_av->table[j];
 				if (memcmp(&av_addr->addr, &addr[i],
-					   sizeof(struct sockaddr_in)) == 0) {
+					   ofi_sizeofaddr(&addr[i])) == 0) {
 					SOCK_LOG_DBG("Found addr in shared av\n");
 					if (fi_addr)
 						fi_addr[i] = (fi_addr_t)j;
@@ -242,12 +243,13 @@ static int sock_check_table_in(struct sock_av *_av, struct sockaddr_in *addr,
 		}
 
 		av_addr = &_av->table[index];
-		inet_ntop(addr[i].sin_family, &addr[i].sin_addr, sa_ip, INET_ADDRSTRLEN);
+		inet_ntop(addr[i].sa_family, ofi_get_ipaddr(&addr[i]),
+			  sa_ip, sizeof sa_ip);
 		SOCK_LOG_DBG("AV-INSERT: dst_addr family: %d, IP %s, port: %d\n",
-			      ((struct sockaddr_in *)&addr[i])->sin_family,
-				sa_ip, ntohs(((struct sockaddr_in *)&addr[i])->sin_port));
+			      (&addr[i])->sa_family, sa_ip,
+			      ofi_addr_get_port(&addr[i]));
 
-		memcpy(&av_addr->addr, &addr[i], sizeof(struct sockaddr_in));
+		memcpy(&av_addr->addr, &addr[i], ofi_sizeofaddr(&addr[i]));
 		if (fi_addr)
 			fi_addr[i] = (fi_addr_t)index;
 
@@ -263,7 +265,7 @@ static int sock_av_insert(struct fid_av *av, const void *addr, size_t count,
 {
 	struct sock_av *_av;
 	_av = container_of(av, struct sock_av, av_fid);
-	return sock_check_table_in(_av, (struct sockaddr_in *)addr,
+	return sock_check_table_in(_av, (const struct sockaddr *) addr,
 				   fi_addr, count, flags, context);
 }
 
@@ -298,6 +300,7 @@ static int _sock_av_insertsvc(struct fid_av *av, const char *node,
 
 	_av = container_of(av, struct sock_av, av_fid);
 	memset(&sock_hints, 0, sizeof(struct addrinfo));
+	/* Map all services to IPv4 addresses -- for compatibility */
 	sock_hints.ai_family = AF_INET;
 	sock_hints.ai_socktype = SOCK_STREAM;
 
@@ -310,7 +313,7 @@ static int _sock_av_insertsvc(struct fid_av *av, const char *node,
 		return -ret;
 	}
 
-	ret = sock_check_table_in(_av, (struct sockaddr_in *)result->ai_addr,
+	ret = sock_check_table_in(_av, result->ai_addr,
 				  fi_addr, 1, flags, context);
 	freeaddrinfo(result);
 	return ret;
@@ -426,15 +429,16 @@ static int sock_av_remove(struct fid_av *av, fi_addr_t *fi_addr, size_t count,
 static const char *sock_av_straddr(struct fid_av *av, const void *addr,
 				   char *buf, size_t *len)
 {
-	const struct sockaddr_in *sin;
-	char straddr[24];
-	char ipaddr[24];
+	const struct sockaddr *sa = addr;
+	char straddr[OFI_ADDRSTRLEN];
+	char ipaddr[INET6_ADDRSTRLEN];
 	int size;
 
-	sin = addr;
-	inet_ntop(sin->sin_family, (void*)&sin->sin_addr, ipaddr, sizeof(ipaddr));
+	if (!inet_ntop(sa->sa_family, ofi_get_ipaddr(sa), ipaddr, sizeof(ipaddr)))
+		return NULL;
+
 	size = snprintf(straddr, sizeof(straddr), "%s:%d",
-			ipaddr, ntohs(sin->sin_port));
+			ipaddr, ofi_addr_get_port(sa));
 	snprintf(buf, *len, "%s", straddr);
 	*len = size + 1;
 	return buf;
@@ -611,8 +615,11 @@ int sock_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 	case FI_SOCKADDR_IN:
 		_av->addrlen = sizeof(struct sockaddr_in);
 		break;
+	case FI_SOCKADDR_IN6:
+		_av->addrlen = sizeof(struct sockaddr_in6);
+		break;
 	default:
-		SOCK_LOG_ERROR("Invalid address format: only IPv4 supported\n");
+		SOCK_LOG_ERROR("Invalid address format: only IP supported\n");
 		ret = -FI_EINVAL;
 		goto err2;
 	}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_comm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_comm.c
index d5362db8e..10d5380d7 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_comm.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_comm.c
@@ -55,9 +55,8 @@ static ssize_t sock_comm_send_socket(struct sock_conn *conn,
 			ret = 0;
 		} else if (ofi_sockerr() == EPIPE) {
 			conn->connected = 0;
-			SOCK_LOG_DBG("Disconnected: %s:%d\n",
-				     inet_ntoa(conn->addr.sin_addr),
-				     ntohs(conn->addr.sin_port));
+			SOCK_LOG_DBG("Disconnected port: %d\n",
+				     ofi_addr_get_port(&conn->addr.sa));
 		} else {
 			SOCK_LOG_DBG("write error: %s\n",
 				     strerror(ofi_sockerr()));
@@ -136,9 +135,8 @@ static ssize_t sock_comm_recv_socket(struct sock_conn *conn,
 	ret = ofi_recv_socket(conn->sock_fd, buf, len, 0);
 	if (ret == 0) {
 		conn->connected = 0;
-		SOCK_LOG_DBG("Disconnected: %s:%d\n",
-			     inet_ntoa(conn->addr.sin_addr),
-			     ntohs(conn->addr.sin_port));
+		SOCK_LOG_DBG("Disconnected: port %d\n",
+			     ofi_addr_get_port(&conn->addr.sa));
 		return ret;
 	}
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_conn.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_conn.c
index 912f00893..5f1c59d1a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_conn.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_conn.c
@@ -69,7 +69,7 @@ ssize_t sock_conn_send_src_addr(struct sock_ep_attr *ep_attr, struct sock_tx_ctx
 	SOCK_LOG_DBG("New conn msg on TX: %p using conn: %p\n", tx_ctx, conn);
 
 	total_len = 0;
-	tx_op.src_iov_len = sizeof(struct sockaddr_in);
+	tx_op.src_iov_len = sizeof(union ofi_sock_ip);
 	total_len = tx_op.src_iov_len + sizeof(struct sock_op_send);
 
 	sock_tx_ctx_start(tx_ctx);
@@ -80,7 +80,10 @@ ssize_t sock_conn_send_src_addr(struct sock_ep_attr *ep_attr, struct sock_tx_ctx
 
 	sock_tx_ctx_write_op_send(tx_ctx, &tx_op, 0, (uintptr_t) NULL, 0, 0,
 				   ep_attr, conn);
-	sock_tx_ctx_write(tx_ctx, ep_attr->src_addr, sizeof(struct sockaddr_in));
+
+	ofi_straddr_dbg(&sock_prov, FI_LOG_EP_CTRL, "sending src addr: ",
+			ep_attr->src_addr);
+	sock_tx_ctx_write(tx_ctx, ep_attr->src_addr, sizeof(union ofi_sock_ip));
 	sock_tx_ctx_commit(tx_ctx);
 	conn->address_published = 1;
 	return 0;
@@ -179,7 +182,7 @@ static int sock_conn_get_next_index(struct sock_conn_map *map)
 }
 
 static struct sock_conn *sock_conn_map_insert(struct sock_ep_attr *ep_attr,
-				struct sockaddr_in *addr, int conn_fd,
+				union ofi_sock_ip *addr, int conn_fd,
 				int addr_published)
 {
 	int index;
@@ -207,7 +210,7 @@ static struct sock_conn *sock_conn_map_insert(struct sock_ep_attr *ep_attr,
 	                  (ep_attr->ep_type == FI_EP_MSG ?
 	                   SOCK_OPTS_KEEPALIVE : 0));
 
-	if (fi_epoll_add(map->epoll_set, conn_fd, &map->table[index]))
+	if (fi_epoll_add(map->epoll_set, conn_fd, FI_EPOLL_IN, &map->table[index]))
 		SOCK_LOG_ERROR("failed to add to epoll set: %d\n", conn_fd);
 
 	map->table[index].address_published = addr_published;
@@ -316,7 +319,7 @@ static void *sock_conn_listener_thread(void *arg)
 	void *ep_contexts[SOCK_EPOLL_WAIT_EVENTS];
 	struct sock_ep_attr *ep_attr;
 	int num_fds, i, conn_fd;
-	struct sockaddr_in remote;
+	union ofi_sock_ip remote;
 	socklen_t addr_size;
 
 	while (conn_listener->do_listen) {
@@ -336,19 +339,20 @@ static void *sock_conn_listener_thread(void *arg)
 				continue;
 			}
 
+			memset(&remote, 0, sizeof remote);
 			addr_size = sizeof(remote);
-			conn_fd = accept(conn_handle->sock, (struct sockaddr *) &remote,
+			conn_fd = accept(conn_handle->sock, &remote.sa,
 			                 &addr_size);
 			SOCK_LOG_DBG("CONN: accepted conn-req: %d\n", conn_fd);
+			ofi_straddr_dbg(&sock_prov, FI_LOG_EP_CTRL,
+					"accepted peer addr: ", &remote.sa);
+
 			if (conn_fd < 0) {
 				SOCK_LOG_ERROR("failed to accept: %s\n",
 				               strerror(ofi_sockerr()));
 				continue;
 			}
 
-			SOCK_LOG_DBG("ACCEPT: %s, %d\n", inet_ntoa(remote.sin_addr),
-				     ntohs(remote.sin_port));
-
 			ep_attr = container_of(conn_handle, struct sock_ep_attr, conn_handle);
 			fastlock_acquire(&ep_attr->cmap.lock);
 			sock_conn_map_insert(ep_attr, &remote, conn_fd, 1);
@@ -380,7 +384,8 @@ int sock_conn_start_listener_thread(struct sock_conn_listener *conn_listener)
 	}
 
 	ret = fi_epoll_add(conn_listener->emap,
-	                   conn_listener->signal.fd[FI_READ_FD], NULL);
+	                   conn_listener->signal.fd[FI_READ_FD],
+	                   FI_EPOLL_IN, NULL);
 	if (ret != 0){
 		SOCK_LOG_ERROR("failed to add signal fd to epoll\n");
 		goto err3;
@@ -407,99 +412,59 @@ err1:
 
 int sock_conn_listen(struct sock_ep_attr *ep_attr)
 {
-	struct addrinfo *s_res = NULL, *p;
-	struct addrinfo hints = { 0 };
-	int listen_fd = 0, ret;
+	int listen_fd, ret;
 	socklen_t addr_size;
-	struct sockaddr_in addr;
+	union ofi_sock_ip addr;
 	struct sock_conn_handle *conn_handle = &ep_attr->conn_handle;
-	char service[NI_MAXSERV] = {0};
-	char *port;
-	char ipaddr[24];
-
-	hints.ai_family = AF_INET;
-	hints.ai_socktype = SOCK_STREAM;
-	hints.ai_flags = AI_PASSIVE;
-
-	memcpy(&addr, ep_attr->src_addr, sizeof(addr));
-	if (getnameinfo((void *)ep_attr->src_addr, sizeof(*ep_attr->src_addr),
-			NULL, 0, conn_handle->service,
-			sizeof(conn_handle->service), NI_NUMERICSERV)) {
-		SOCK_LOG_ERROR("could not resolve src_addr\n");
-		return -FI_EINVAL;
-	}
 
-	if (ep_attr->ep_type == FI_EP_MSG) {
-		memset(conn_handle->service, 0, NI_MAXSERV);
-		port = NULL;
-		addr.sin_port = 0;
-	} else
-		port = conn_handle->service;
-
-	inet_ntop(addr.sin_family, &addr.sin_addr, ipaddr, sizeof(ipaddr));
-	ret = getaddrinfo(ipaddr, port, &hints, &s_res);
-	if (ret) {
-		SOCK_LOG_ERROR("no available AF_INET address, service %s, %s\n",
-			       conn_handle->service, gai_strerror(ret));
-		return -FI_EINVAL;
-	}
+	listen_fd = ofi_socket(ep_attr->src_addr->sa.sa_family,
+				SOCK_STREAM, IPPROTO_TCP);
+	if (listen_fd == INVALID_SOCKET)
+		return -ofi_sockerr();
 
-	SOCK_LOG_DBG("Binding listener thread to port: %s\n", conn_handle->service);
-	for (p = s_res; p; p = p->ai_next) {
-		listen_fd = ofi_socket(p->ai_family, p->ai_socktype, p->ai_protocol);
-		if (listen_fd >= 0) {
-			sock_set_sockopts(listen_fd, SOCK_OPTS_NONBLOCK);
+	sock_set_sockopts(listen_fd, SOCK_OPTS_NONBLOCK);
 
-			if (!bind(listen_fd, s_res->ai_addr, s_res->ai_addrlen))
-				break;
-			ofi_close_socket(listen_fd);
-			listen_fd = -1;
-		}
-	}
-	freeaddrinfo(s_res);
+	addr = *ep_attr->src_addr;
+	if (ep_attr->ep_type == FI_EP_MSG)
+		ofi_addr_set_port(&addr.sa, 0);
 
-	if (listen_fd < 0) {
-		SOCK_LOG_ERROR("failed to listen to port: %s\n",
-			       conn_handle->service);
+	ret = bind(listen_fd, &addr.sa, ofi_sizeofaddr(&addr.sa));
+	if (ret) {
+		SOCK_LOG_ERROR("failed to bind listener: %s\n",
+			       strerror(ofi_sockerr()));
+		ofi_straddr_log(&sock_prov, FI_LOG_WARN, FI_LOG_EP_CTRL,
+				"bind failed to addr: ", &addr.sa);
+		ret = -ofi_sockerr();
 		goto err;
 	}
 
-	if (atoi(conn_handle->service) == 0) {
-		addr_size = sizeof(addr);
-		if (getsockname(listen_fd, (struct sockaddr *) &addr,
-				&addr_size))
-			goto err;
-		snprintf(conn_handle->service, sizeof(conn_handle->service), "%d",
-			 ntohs(addr.sin_port));
-		SOCK_LOG_DBG("Bound to port: %s - %d\n",
-			     conn_handle->service, getpid());
-		ep_attr->msg_src_port = ntohs(addr.sin_port);
+	addr_size = sizeof(addr);
+	ret = ofi_getsockname(listen_fd, &addr.sa, &addr_size);
+	if (ret) {
+		ret = -ofi_sockerr();
+		goto err;
 	}
 
-	if (ep_attr->src_addr->sin_addr.s_addr == 0) {
-		snprintf(service, sizeof service, "%s", conn_handle->service);
-		ret = sock_get_src_addr_from_hostname(ep_attr->src_addr, service);
-		if (ret)
-			goto err;
-	}
+	ep_attr->msg_src_port = ofi_addr_get_port(&addr.sa);
+	if (!ofi_addr_get_port(&ep_attr->src_addr->sa))
+		ofi_addr_set_port(&ep_attr->src_addr->sa, ep_attr->msg_src_port);
 
-	if (listen(listen_fd, sock_cm_def_map_sz)) {
+	ofi_straddr_dbg(&sock_prov, FI_LOG_EP_CTRL, "listening at addr: ",
+			&addr.sa);
+	ret = listen(listen_fd, sock_cm_def_map_sz);
+	if (ret) {
 		SOCK_LOG_ERROR("failed to listen socket: %s\n",
 			       strerror(ofi_sockerr()));
+		ret = -ofi_sockerr();
 		goto err;
 	}
 
-	if (((struct sockaddr_in *) (ep_attr->src_addr))->sin_port == 0) {
-		((struct sockaddr_in *) (ep_attr->src_addr))->sin_port =
-			htons(atoi(conn_handle->service));
-	}
-
 	conn_handle->sock = listen_fd;
 	conn_handle->do_listen = 1;
 
 	fastlock_acquire(&ep_attr->domain->conn_listener.signal_lock);
 	ret = fi_epoll_add(ep_attr->domain->conn_listener.emap,
-	                   conn_handle->sock, conn_handle);
+	                   conn_handle->sock, FI_EPOLL_IN, conn_handle);
 	fd_signal_set(&ep_attr->domain->conn_listener.signal);
 	fastlock_release(&ep_attr->domain->conn_listener.signal_lock);
 	if (ret) {
@@ -509,10 +474,13 @@ int sock_conn_listen(struct sock_ep_attr *ep_attr)
 
 	return 0;
 err:
-	if (listen_fd >= 0)
+	if (listen_fd != INVALID_SOCKET) {
 		ofi_close_socket(listen_fd);
+		conn_handle->sock = INVALID_SOCKET;
+		conn_handle->do_listen = 0;
+	}
 
-	return -FI_EINVAL;
+	return ret;
 }
 
 int sock_ep_connect(struct sock_ep_attr *ep_attr, fi_addr_t index,
@@ -521,7 +489,7 @@ int sock_ep_connect(struct sock_ep_attr *ep_attr, fi_addr_t index,
 	int conn_fd = -1, ret;
 	int do_retry = sock_conn_retry;
 	struct sock_conn *new_conn;
-	struct sockaddr_in addr;
+	union ofi_sock_ip addr;
 	socklen_t lon;
 	int valopt = 0;
 	struct pollfd poll_fd;
@@ -531,9 +499,9 @@ int sock_ep_connect(struct sock_ep_attr *ep_attr, fi_addr_t index,
 		   passed to endpoint */
 		assert(ep_attr->dest_addr);
 		addr = *ep_attr->dest_addr;
-		addr.sin_port = htons(ep_attr->msg_dest_port);
+		ofi_addr_set_port(&addr.sa, ep_attr->msg_dest_port);
 	} else {
-		addr = *((struct sockaddr_in *)&ep_attr->av->table[index].addr);
+		addr = ep_attr->av->table[index].addr;
 	}
 
 do_connect:
@@ -544,7 +512,7 @@ do_connect:
 	if (*conn != SOCK_CM_CONN_IN_PROGRESS)
 		return FI_SUCCESS;
 
-	conn_fd = ofi_socket(AF_INET, SOCK_STREAM, 0);
+	conn_fd = ofi_socket(addr.sa.sa_family, SOCK_STREAM, 0);
 	if (conn_fd == -1) {
 		SOCK_LOG_ERROR("failed to create conn_fd, errno: %d\n",
 			       ofi_sockerr());
@@ -560,18 +528,15 @@ do_connect:
 		return -FI_EOTHER;
 	}
 
-	SOCK_LOG_DBG("Connecting to: %s:%d\n", inet_ntoa(addr.sin_addr),
-		     ntohs(addr.sin_port));
-	SOCK_LOG_DBG("Connecting using address:%s\n",
-		     inet_ntoa(ep_attr->src_addr->sin_addr));
-
-	ret = connect(conn_fd, (struct sockaddr *) &addr, sizeof addr);
+	ofi_straddr_dbg(&sock_prov, FI_LOG_EP_CTRL, "connecting to addr: ",
+			&addr.sa);
+	ret = connect(conn_fd, &addr.sa, ofi_sizeofaddr(&addr.sa));
 	if (ret < 0) {
 		if (OFI_SOCK_TRY_CONN_AGAIN(ofi_sockerr())) {
 			poll_fd.fd = conn_fd;
 			poll_fd.events = POLLOUT;
 
-			ret = poll(&poll_fd, 1, 15 * 1000);
+			ret = poll(&poll_fd, 1, sock_conn_timeout);
 			if (ret < 0) {
 				SOCK_LOG_DBG("poll failed\n");
 				goto retry;
@@ -590,22 +555,12 @@ do_connect:
 				SOCK_LOG_DBG("Error in connection() "
 					     "%d - %s - %d\n",
 					     valopt, strerror(valopt), conn_fd);
-				SOCK_LOG_DBG("Connecting to: %s:%d\n",
-					     inet_ntoa(addr.sin_addr),
-					     ntohs(addr.sin_port));
-				SOCK_LOG_DBG("Connecting using address:%s\n",
-				inet_ntoa(ep_attr->src_addr->sin_addr));
 				goto retry;
 			}
 			goto out;
 		} else {
 			SOCK_LOG_DBG("Timeout or error() - %s: %d\n",
 				     strerror(ofi_sockerr()), conn_fd);
-			SOCK_LOG_DBG("Connecting to: %s:%d\n",
-				     inet_ntoa(addr.sin_addr),
-				     ntohs(addr.sin_port));
-			SOCK_LOG_DBG("Connecting using address:%s\n",
-				     inet_ntoa(ep_attr->src_addr->sin_addr));
 			goto retry;
 		}
 	} else {
@@ -614,7 +569,6 @@ do_connect:
 
 retry:
 	do_retry--;
-	sleep(10);
 	if (!do_retry)
 		goto err;
 
@@ -625,10 +579,6 @@ retry:
 
 	SOCK_LOG_ERROR("Connect error, retrying - %s - %d\n",
 		       strerror(ofi_sockerr()), conn_fd);
-	SOCK_LOG_DBG("Connecting to: %s:%d\n", inet_ntoa(addr.sin_addr),
-			ntohs(addr.sin_port));
-	SOCK_LOG_DBG("Connecting using address:%s\n",
-			inet_ntoa(ep_attr->src_addr->sin_addr));
         goto do_connect;
 
 out:
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_dom.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_dom.c
index d28baecbd..a78bf71c0 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_dom.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_dom.c
@@ -182,6 +182,7 @@ static int sock_dom_close(struct fid *fid)
 		return -FI_EBUSY;
 
 	sock_conn_stop_listener_thread(&dom->conn_listener);
+	sock_ep_cm_stop_thread(&dom->cm_head);
 
 	sock_pe_finalize(dom->pe);
 	fastlock_destroy(&dom->lock);
@@ -336,9 +337,15 @@ int sock_domain(struct fid_fabric *fabric, struct fi_info *info,
 	if (ret)
 		goto err2;
 
+	ret = sock_ep_cm_start_thread(&sock_domain->cm_head);
+	if (ret)
+		goto err3;
+
 	sock_dom_add_to_list(sock_domain);
 	return 0;
 
+err3:
+	sock_conn_stop_listener_thread(&sock_domain->conn_listener);
 err2:
 	sock_pe_finalize(sock_domain->pe);
 err1:
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_ep.c
index ff6f3fec2..d6eb12785 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_ep.c
@@ -644,8 +644,8 @@ static void sock_ep_clear_eq_list(struct dlistfd_head *list,
 
 static int sock_ep_close(struct fid *fid)
 {
+	struct sock_conn_req_handle *handle;
 	struct sock_ep *sock_ep;
-	char c = 0;
 
 	switch (fid->fclass) {
 	case FI_CLASS_EP:
@@ -670,17 +670,14 @@ static int sock_ep_close(struct fid *fid)
 		return -FI_EBUSY;
 
 	if (sock_ep->attr->ep_type == FI_EP_MSG) {
-		sock_ep->attr->cm.do_listen = 0;
-		if (ofi_write_socket(sock_ep->attr->cm.signal_fds[0], &c, 1) != 1)
-			SOCK_LOG_DBG("Failed to signal\n");
-
-		if (sock_ep->attr->cm.listener_thread &&
-			pthread_join(sock_ep->attr->cm.listener_thread, NULL)) {
-			SOCK_LOG_ERROR("pthread join failed (%d)\n",
-				       ofi_syserr());
+		if (sock_ep->attr->info.handle) {
+			handle = container_of(sock_ep->attr->info.handle,
+		                          struct sock_conn_req_handle, handle);
+			sock_ep_cm_wait_handle_finalized(&sock_ep->attr->domain->cm_head,
+			                                 handle);
+			free(handle->req);
+			free(handle);
 		}
-		ofi_close_socket(sock_ep->attr->cm.signal_fds[0]);
-		ofi_close_socket(sock_ep->attr->cm.signal_fds[1]);
 	} else {
 		if (sock_ep->attr->av)
 			ofi_atomic_dec32(&sock_ep->attr->av->ref);
@@ -1335,27 +1332,13 @@ int sock_srx_ctx(struct fid_domain *domain,
 }
 
 #if HAVE_GETIFADDRS
-static int sock_get_prefix_len(uint32_t net_addr)
-{
-	uint32_t addr;
-	int count = 0;
-
-	addr = ntohl(net_addr);
-	while (addr > 0) {
-		addr = addr << 1;
-		count++;
-	}
-	return count;
-}
-
-char *sock_get_fabric_name(struct sockaddr_in *src_addr)
+static char *sock_get_fabric_name(struct sockaddr *src_addr)
 {
 	int ret;
         struct ifaddrs *ifaddrs, *ifa;
 	char *fabric_name = NULL;
-	struct in_addr net_in_addr;
-	struct sockaddr_in *host_addr, *net_addr;
-	char netbuf[SOCK_MAX_NETWORK_ADDR_SZ];
+	union ofi_sock_ip net_in_addr;
+	char netbuf[OFI_ADDRSTRLEN];
 	int prefix_len;
 
 	ret = ofi_getifaddrs(&ifaddrs);
@@ -1363,20 +1346,32 @@ char *sock_get_fabric_name(struct sockaddr_in *src_addr)
 		return NULL;
 
 	for (ifa = ifaddrs; ifa != NULL; ifa = ifa->ifa_next) {
-		if (ifa->ifa_addr == NULL || !(ifa->ifa_flags & IFF_UP) ||
-		     (ifa->ifa_addr->sa_family != AF_INET))
+		if (ifa->ifa_addr == NULL || !(ifa->ifa_flags & IFF_UP))
 			continue;
-		if (ofi_equals_ipaddr((struct sockaddr_in *)ifa->ifa_addr, src_addr)) {
-			host_addr = (struct sockaddr_in *)ifa->ifa_addr;
-			net_addr = (struct sockaddr_in *)ifa->ifa_netmask;
-			/* set fabric name to the network_adress in the format of a.b.c.d/e */
-			net_in_addr.s_addr = (uint32_t)((uint32_t) host_addr->sin_addr.s_addr &
-						(uint32_t) net_addr->sin_addr.s_addr);
-			inet_ntop(host_addr->sin_family, (void *)&(net_in_addr), netbuf,
-				   sizeof(netbuf));
-			prefix_len = sock_get_prefix_len(net_addr->sin_addr.s_addr);
+
+		if (ofi_equals_ipaddr(ifa->ifa_addr, src_addr)) {
+			prefix_len = ofi_mask_addr(&net_in_addr.sa,
+					ifa->ifa_addr, ifa->ifa_netmask);
+
+			switch (net_in_addr.sa.sa_family) {
+			case AF_INET:
+				inet_ntop(AF_INET,
+					&((struct sockaddr_in *)&net_in_addr)->sin_addr,
+					netbuf, sizeof(netbuf));
+				break;
+			case AF_INET6:
+				inet_ntop(AF_INET6,
+					&((struct sockaddr_in6 *)&net_in_addr)->sin6_addr,
+					netbuf, sizeof(netbuf));
+				break;
+			default:
+				snprintf(netbuf, sizeof(netbuf), "%s", "<unknown>");
+				netbuf[sizeof(netbuf)-1] = '\0';
+				break;
+			}
 			snprintf(netbuf + strlen(netbuf), sizeof(netbuf) - strlen(netbuf),
-				  "%s%d", "/", prefix_len);
+				 "%s%d", "/", prefix_len);
+			netbuf[sizeof(netbuf)-1] = '\0';
 			fabric_name = strdup(netbuf);
 			goto out;
 		}
@@ -1386,7 +1381,7 @@ out:
 	return fabric_name;
 }
 
-char *sock_get_domain_name(struct sockaddr_in *src_addr)
+char *sock_get_domain_name(struct sockaddr *src_addr)
 {
 	int ret;
         struct ifaddrs *ifaddrs, *ifa;
@@ -1397,10 +1392,10 @@ char *sock_get_domain_name(struct sockaddr_in *src_addr)
 		return NULL;
 
 	for (ifa = ifaddrs; ifa != NULL; ifa = ifa->ifa_next) {
-		if (ifa->ifa_addr == NULL || !(ifa->ifa_flags & IFF_UP) ||
-		     (ifa->ifa_addr->sa_family != AF_INET))
+		if (ifa->ifa_addr == NULL || !(ifa->ifa_flags & IFF_UP))
 			continue;
-		if (ofi_equals_ipaddr((struct sockaddr_in *)ifa->ifa_addr, src_addr)) {
+
+		if (ofi_equals_ipaddr(ifa->ifa_addr, src_addr)) {
 			domain_name = strdup(ifa->ifa_name);
 			goto out;
 		}
@@ -1410,12 +1405,12 @@ out:
 	return domain_name;
 }
 #else
-char *sock_get_fabric_name(struct sockaddr_in *src_addr)
+static char *sock_get_fabric_name(struct sockaddr *src_addr)
 {
 	return NULL;
 }
 
-char *sock_get_domain_name(struct sockaddr_in *src_addr)
+char *sock_get_domain_name(struct sockaddr *src_addr)
 {
 	return NULL;
 }
@@ -1524,25 +1519,32 @@ struct fi_info *sock_fi_info(uint32_t version, enum fi_ep_type ep_type,
 	if (!info)
 		return NULL;
 
-	info->src_addr = calloc(1, sizeof(struct sockaddr_in));
+	info->src_addr = calloc(1, sizeof(union ofi_sock_ip));
 	if (!info->src_addr)
 		goto err;
 
 	info->mode = SOCK_MODE;
-	info->addr_format = FI_SOCKADDR_IN;
 
-	if (src_addr)
-		memcpy(info->src_addr, src_addr, sizeof(struct sockaddr_in));
+	if (src_addr) {
+		memcpy(info->src_addr, src_addr, ofi_sizeofaddr(src_addr));
+	} else {
+		sock_get_src_addr_from_hostname(info->src_addr, NULL,
+			dest_addr ? ((struct sockaddr *) dest_addr)->sa_family :
+			ofi_get_sa_family(hints));
+	}
+
+	info->src_addrlen = ofi_sizeofaddr(info->src_addr);
+	if (info->src_addrlen == sizeof(struct sockaddr_in6))
+		info->addr_format = FI_SOCKADDR_IN6;
 	else
-		sock_get_src_addr_from_hostname(info->src_addr, NULL);
-	info->src_addrlen = sizeof(struct sockaddr_in);
+		info->addr_format = FI_SOCKADDR_IN;
 
 	if (dest_addr) {
-		info->dest_addr = calloc(1, sizeof(struct sockaddr_in));
+		info->dest_addr = calloc(1, sizeof(union ofi_sock_ip));
 		if (!info->dest_addr)
 			goto err;
-		info->dest_addrlen = sizeof(struct sockaddr_in);
-		memcpy(info->dest_addr, dest_addr, sizeof(struct sockaddr_in));
+		info->dest_addrlen = ofi_sizeofaddr(dest_addr);
+		memcpy(info->dest_addr, dest_addr, info->dest_addrlen);
 	}
 
 	if (hints) {
@@ -1577,39 +1579,39 @@ err:
 	return NULL;
 }
 
-int sock_get_src_addr_from_hostname(struct sockaddr_in *src_addr,
-					const char *service)
+int sock_get_src_addr_from_hostname(union ofi_sock_ip *src_addr,
+				    const char *service, uint16_t sa_family)
 {
 	int ret;
 	struct addrinfo ai, *rai = NULL;
 	char hostname[HOST_NAME_MAX];
 
 	memset(&ai, 0, sizeof(ai));
-	ai.ai_family = AF_INET;
+	ai.ai_family = sa_family;
 	ai.ai_socktype = SOCK_STREAM;
 
-	ofi_getnodename(hostname, sizeof(hostname));
+	ofi_getnodename(sa_family, hostname, sizeof(hostname));
 	ret = getaddrinfo(hostname, service, &ai, &rai);
 	if (ret) {
 		SOCK_LOG_DBG("getaddrinfo failed!\n");
 		return -FI_EINVAL;
 	}
-	memcpy(src_addr, (struct sockaddr_in *)rai->ai_addr,
-		sizeof(*src_addr));
+	memcpy(src_addr, rai->ai_addr, rai->ai_addrlen);
 	freeaddrinfo(rai);
 	return 0;
 }
 
 static int sock_ep_assign_src_addr(struct sock_ep *sock_ep, struct fi_info *info)
 {
-	sock_ep->attr->src_addr = calloc(1, sizeof(struct sockaddr_in));
+	sock_ep->attr->src_addr = calloc(1, sizeof(union ofi_sock_ip));
 	if (!sock_ep->attr->src_addr)
 		return -FI_ENOMEM;
 
 	if (info && info->dest_addr)
 		return sock_get_src_addr(info->dest_addr, sock_ep->attr->src_addr);
 	else
-		return sock_get_src_addr_from_hostname(sock_ep->attr->src_addr, NULL);
+		return sock_get_src_addr_from_hostname(sock_ep->attr->src_addr,
+						       NULL, 0);
 }
 
 int sock_alloc_endpoint(struct fid_domain *domain, struct fi_info *info,
@@ -1681,23 +1683,25 @@ int sock_alloc_endpoint(struct fid_domain *domain, struct fi_info *info,
 		}
 
 		if (info->src_addr) {
-			sock_ep->attr->src_addr = calloc(1, sizeof(struct sockaddr_in));
+			sock_ep->attr->src_addr = calloc(1, sizeof(*sock_ep->
+							 attr->src_addr));
 			if (!sock_ep->attr->src_addr) {
 				ret = -FI_ENOMEM;
 				goto err2;
 			}
 			memcpy(sock_ep->attr->src_addr, info->src_addr,
-			       sizeof(struct sockaddr_in));
+			       info->src_addrlen);
 		}
 
 		if (info->dest_addr) {
-			sock_ep->attr->dest_addr = calloc(1, sizeof(struct sockaddr_in));
+			sock_ep->attr->dest_addr = calloc(1, sizeof(*sock_ep->
+							  attr->dest_addr));
 			if (!sock_ep->attr->dest_addr) {
 				ret = -FI_ENOMEM;
 				goto err2;
 			}
 			memcpy(sock_ep->attr->dest_addr, info->dest_addr,
-			       sizeof(struct sockaddr_in));
+			       info->dest_addrlen);
 		}
 
 		if (info->tx_attr) {
@@ -1789,17 +1793,6 @@ int sock_alloc_endpoint(struct fid_domain *domain, struct fi_info *info,
 
 	sock_ep->attr->domain = sock_dom;
 	fastlock_init(&sock_ep->attr->cm.lock);
-	if (sock_ep->attr->ep_type == FI_EP_MSG) {
-		dlist_init(&sock_ep->attr->cm.msg_list);
-		if (socketpair(AF_UNIX, SOCK_STREAM, 0,
-			       sock_ep->attr->cm.signal_fds) < 0) {
-			ret = -FI_EINVAL;
-			goto err2;
-		}
-
-		if (fi_fd_nonblock(sock_ep->attr->cm.signal_fds[1]))
-			SOCK_LOG_ERROR("fi_fd_nonblock failed");
-	}
 
 	if (sock_conn_map_init(sock_ep, sock_cm_def_map_sz)) {
 		SOCK_LOG_ERROR("failed to init connection map\n");
@@ -1828,7 +1821,7 @@ void sock_ep_remove_conn(struct sock_ep_attr *attr, struct sock_conn *conn)
 }
 
 struct sock_conn *sock_ep_lookup_conn(struct sock_ep_attr *attr, fi_addr_t index,
-					struct sockaddr_in *addr)
+				      union ofi_sock_ip *addr)
 {
 	int i;
 	uint16_t idx;
@@ -1847,7 +1840,7 @@ struct sock_conn *sock_ep_lookup_conn(struct sock_ep_attr *attr, fi_addr_t index
 		if (!attr->cmap.table[i].connected)
 			continue;
 
-		if (ofi_equals_sockaddr(&attr->cmap.table[i].addr, addr)) {
+		if (ofi_equals_sockaddr(&attr->cmap.table[i].addr.sa, &addr->sa)) {
 			conn = &attr->cmap.table[i];
 			if (conn->av_index == FI_ADDR_NOTAVAIL)
 				conn->av_index = idx;
@@ -1863,13 +1856,13 @@ int sock_ep_get_conn(struct sock_ep_attr *attr, struct sock_tx_ctx *tx_ctx,
 	struct sock_conn *conn;
 	uint64_t av_index = (attr->ep_type == FI_EP_MSG) ?
 			    0 : (index & attr->av->mask);
-	struct sockaddr_in *addr;
+	union ofi_sock_ip *addr;
 	int ret = FI_SUCCESS;
 
 	if (attr->ep_type == FI_EP_MSG)
 		addr = attr->dest_addr;
 	else
-		addr = (struct sockaddr_in *)&attr->av->table[av_index].addr;
+		addr = &attr->av->table[av_index].addr;
 
 	fastlock_acquire(&attr->cmap.lock);
 	conn = sock_ep_lookup_conn(attr, av_index, addr);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_ep_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_ep_msg.c
index 1455b904b..ff6360c8a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_ep_msg.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_ep_msg.c
@@ -255,104 +255,79 @@ static int sock_ep_cm_getname(fid_t fid, void *addr, size_t *addrlen)
 	struct sock_pep *sock_pep = NULL;
 	size_t len;
 
-	len = MIN(*addrlen, sizeof(struct sockaddr_in));
 	switch (fid->fclass) {
 	case FI_CLASS_EP:
 	case FI_CLASS_SEP:
 		sock_ep = container_of(fid, struct sock_ep, ep.fid);
 		if (sock_ep->attr->is_enabled == 0)
 			return -FI_EOPBADSTATE;
+
+		len = MIN(*addrlen, ofi_sizeofaddr(&sock_ep->attr->src_addr->sa));
 		memcpy(addr, sock_ep->attr->src_addr, len);
+		*addrlen = ofi_sizeofaddr(&sock_ep->attr->src_addr->sa);
 		break;
 	case FI_CLASS_PEP:
 		sock_pep = container_of(fid, struct sock_pep, pep.fid);
 		if (!sock_pep->name_set)
 			return -FI_EOPBADSTATE;
+
+		len = MIN(*addrlen, ofi_sizeofaddr(&sock_pep->src_addr.sa));
 		memcpy(addr, &sock_pep->src_addr, len);
+		*addrlen = ofi_sizeofaddr(&sock_pep->src_addr.sa);
 		break;
 	default:
 		SOCK_LOG_ERROR("Invalid argument\n");
 		return -FI_EINVAL;
 	}
 
-	*addrlen = sizeof(struct sockaddr_in);
-	return (len == sizeof(struct sockaddr_in)) ? 0 : -FI_ETOOSMALL;
+	return (len == *addrlen) ? 0 : -FI_ETOOSMALL;
 }
 
 static int sock_pep_create_listener(struct sock_pep *pep)
 {
 	int ret;
 	socklen_t addr_size;
-	struct sockaddr_in addr;
-	struct addrinfo *s_res = NULL, *p;
-	struct addrinfo hints;
-	char sa_ip[INET_ADDRSTRLEN];
-	char sa_port[NI_MAXSERV];
 
-	pep->cm.do_listen = 1;
-	memset(&hints, 0, sizeof(hints));
-	hints.ai_family = AF_INET;
-	hints.ai_socktype = SOCK_STREAM;
-	hints.ai_flags = AI_PASSIVE;
+	pep->cm.sock = ofi_socket(pep->src_addr.sa.sa_family,
+				  SOCK_STREAM, IPPROTO_TCP);
+	if (pep->cm.sock == INVALID_SOCKET)
+		return -ofi_sockerr();
 
-	memcpy(sa_ip, inet_ntoa(pep->src_addr.sin_addr), INET_ADDRSTRLEN);
-	sprintf(sa_port, "%d", ntohs(pep->src_addr.sin_port));
-	sa_ip[INET_ADDRSTRLEN - 1] = '\0';
-	sa_port[NI_MAXSERV - 1] = '\0';
+	sock_set_sockopts(pep->cm.sock, SOCK_OPTS_NONBLOCK);
 
-	ret = getaddrinfo(sa_ip, sa_port, &hints, &s_res);
+	ret = bind(pep->cm.sock, &pep->src_addr.sa,
+		   ofi_sizeofaddr(&pep->src_addr.sa));
 	if (ret) {
-		SOCK_LOG_ERROR("no available AF_INET address service:%s, %s\n",
-			       sa_port, gai_strerror(ret));
-		return -FI_EINVAL;
-	}
-
-	SOCK_LOG_DBG("binding pep listener to %s\n", sa_port);
-	for (p = s_res; p; p = p->ai_next) {
-		pep->cm.sock = ofi_socket(p->ai_family, p->ai_socktype,
-				     p->ai_protocol);
-		if (pep->cm.sock >= 0) {
-			sock_set_sockopts(pep->cm.sock, SOCK_OPTS_NONBLOCK);
-			if (!bind(pep->cm.sock, s_res->ai_addr, s_res->ai_addrlen))
-				break;
-			SOCK_LOG_ERROR("failed to bind listener: %s\n",
-				       strerror(ofi_sockerr()));
-			ofi_close_socket(pep->cm.sock);
-			pep->cm.sock = -1;
-		}
-	}
-
-	freeaddrinfo(s_res);
-	if (pep->cm.sock < 0) {
-		SOCK_LOG_ERROR("failed to create listener: %s\n",
+		SOCK_LOG_ERROR("failed to bind listener: %s\n",
 			       strerror(ofi_sockerr()));
-		return -FI_EIO;
-	}
-
-	if (pep->src_addr.sin_port == 0) {
-		addr_size = sizeof(addr);
-		if (getsockname(pep->cm.sock, (struct sockaddr *)&addr, &addr_size))
-			return -FI_EINVAL;
-		pep->src_addr.sin_port = addr.sin_port;
-		sprintf(sa_port, "%d", ntohs(pep->src_addr.sin_port));
+		ret = -ofi_sockerr();
+		goto err;
 	}
 
-	if (pep->src_addr.sin_addr.s_addr == 0) {
-		ret = sock_get_src_addr_from_hostname(&pep->src_addr, sa_port);
-		if (ret)
-			return -FI_EINVAL;
+	addr_size = sizeof(pep->src_addr);
+	if (ofi_getsockname(pep->cm.sock, &pep->src_addr.sa, &addr_size) ==
+	    SOCKET_ERROR) {
+		ret = -ofi_sockerr();
+		goto err;
 	}
 
 	if (listen(pep->cm.sock, sock_cm_def_map_sz)) {
 		SOCK_LOG_ERROR("failed to listen socket: %s\n",
 			       strerror(ofi_sockerr()));
-		return -ofi_sockerr();
+		ret = -ofi_sockerr();
+		goto err;
 	}
 
+	pep->cm.do_listen = 1;
 	pep->name_set = 1;
-	SOCK_LOG_DBG("Listener thread bound to %s:%d\n",
-		     sa_ip, ntohs(pep->src_addr.sin_port));
 	return 0;
+err:
+	if (pep->cm.sock) {
+		ofi_close_socket(pep->cm.sock);
+		pep->cm.sock = INVALID_SOCKET;
+	}
+
+	return ret;
 }
 
 static int sock_ep_cm_setname(fid_t fid, void *addr, size_t addrlen)
@@ -360,7 +335,7 @@ static int sock_ep_cm_setname(fid_t fid, void *addr, size_t addrlen)
 	struct sock_ep *sock_ep = NULL;
 	struct sock_pep *sock_pep = NULL;
 
-	if (addrlen != sizeof(struct sockaddr_in))
+	if (!addrlen || addrlen != ofi_sizeofaddr(addr))
 		return -FI_EINVAL;
 
 	switch (fid->fclass) {
@@ -389,10 +364,10 @@ static int sock_ep_cm_getpeer(struct fid_ep *ep, void *addr, size_t *addrlen)
 	size_t len;
 
 	sock_ep = container_of(ep, struct sock_ep, ep);
-	len = MIN(*addrlen, sizeof(struct sockaddr_in));
+	len = MIN(*addrlen, ofi_sizeofaddr(&sock_ep->attr->dest_addr->sa));
 	memcpy(addr, sock_ep->attr->dest_addr, len);
-	*addrlen = sizeof(struct sockaddr_in);
-	return (len == sizeof(struct sockaddr_in)) ? 0 : -FI_ETOOSMALL;
+	*addrlen = ofi_sizeofaddr(&sock_ep->attr->dest_addr->sa);
+	return (len == *addrlen) ? 0 : -FI_ETOOSMALL;
 }
 
 static int sock_cm_send(int fd, const void *buf, int len)
@@ -431,106 +406,175 @@ static int sock_cm_recv(int fd, void *buf, int len)
 	return 0;
 }
 
-static void sock_ep_wait_shutdown(struct sock_ep *ep)
+static void sock_ep_cm_monitor_handle(struct sock_ep_cm_head *cm_head,
+                                      struct sock_conn_req_handle *handle,
+                                      uint32_t events)
 {
-	int ret, do_report = 0;
-	char tmp = 0;
-	struct pollfd poll_fds[2];
-	struct sock_conn_hdr msg;
-	struct fi_eq_cm_entry cm_entry = {0};
+	int ret;
 
-	poll_fds[0].fd = ep->attr->cm.sock;
-	poll_fds[1].fd = ep->attr->cm.signal_fds[1];
-	poll_fds[0].events = poll_fds[1].events = POLLIN;
+	fastlock_acquire(&cm_head->signal_lock);
+	if (handle->monitored)
+		goto unlock;
 
-	while (*((volatile int*) &ep->attr->cm.do_listen)) {
-		ret = poll(poll_fds, 2, -1);
-		if (ret > 0) {
-			if (poll_fds[1].revents & POLLIN) {
-				ret = ofi_read_socket(ep->attr->cm.signal_fds[1], &tmp, 1);
-				if (ret != 1) {
-					SOCK_LOG_DBG("Invalid signal\n");
-					break;
-				}
-				continue;
-			}
-		} else {
-			break;
-		}
+	/* Mark the handle as monitored before adding it to the pollset */
+	handle->monitored = 1;
+	ret = fi_epoll_add(cm_head->emap, handle->sock_fd,
+	                   events, handle);
+	if (ret) {
+		SOCK_LOG_ERROR("failed to monitor fd %d: %d\n",
+		               handle->sock_fd, ret);
+		handle->monitored = 0;
+	} else {
+		fd_signal_set(&cm_head->signal);
+	}
+unlock:
+	fastlock_release(&cm_head->signal_lock);
+}
 
-		if (sock_cm_recv(ep->attr->cm.sock, &msg, sizeof(msg)))
-			break;
+static void
+sock_ep_cm_unmonitor_handle_locked(struct sock_ep_cm_head *cm_head,
+                                   struct sock_conn_req_handle *handle,
+                                   int close_socket)
+{
+	int ret;
 
-		if (msg.type == SOCK_CONN_SHUTDOWN)
-			break;
+	if (handle->monitored) {
+		ret = fi_epoll_del(cm_head->emap, handle->sock_fd);
+		if (ret)
+			SOCK_LOG_ERROR("failed to unmonitor fd %d: %d\n",
+			               handle->sock_fd, ret);
+		handle->monitored = 0;
+	}
+
+	/* Multiple threads might call sock_ep_cm_unmonitor_handle() at the
+	 * same time. Some caution is required to prevent a socket from being
+	 * close concurrently, which could cause an unexpected socket to be
+	 * closed by mistake. */
+	if (close_socket && handle->sock_fd != INVALID_SOCKET) {
+		ofi_close_socket(handle->sock_fd);
+		handle->sock_fd = INVALID_SOCKET;
 	}
+}
+
+static void sock_ep_cm_unmonitor_handle(struct sock_ep_cm_head *cm_head,
+                                       struct sock_conn_req_handle *handle,
+                                       int close_socket)
+{
+	fastlock_acquire(&cm_head->signal_lock);
+	sock_ep_cm_unmonitor_handle_locked(cm_head, handle, close_socket);
+	fastlock_release(&cm_head->signal_lock);
+}
+
+static void sock_ep_cm_shutdown_report(struct sock_ep *ep, int send_shutdown)
+{
+	struct fi_eq_cm_entry cm_entry = {0};
+	struct sock_conn_hdr msg = {0};
+	enum sock_cm_state old_state;
 
 	fastlock_acquire(&ep->attr->cm.lock);
-	if (ep->attr->cm.is_connected) {
-		do_report = 1;
-		ep->attr->cm.is_connected = 0;
+	old_state = ep->attr->cm.state;
+	switch (ep->attr->cm.state) {
+	case SOCK_CM_STATE_REQUESTED:
+	/* fallthrough */
+	case SOCK_CM_STATE_CONNECTED:
+		ep->attr->cm.state = SOCK_CM_STATE_DISCONNECTED;
+		break;
+	case SOCK_CM_STATE_DISCONNECTED:
+		/* Nothing to do, already disconnected */
+		break;
+	default:
+		assert(0);
+		break;
 	}
 	fastlock_release(&ep->attr->cm.lock);
 
-	if (do_report) {
+	switch (old_state) {
+	case SOCK_CM_STATE_CONNECTED:
+		if (send_shutdown) {
+			msg.type = SOCK_CONN_SHUTDOWN;
+			if (sock_cm_send(ep->attr->cm.sock, &msg, sizeof(msg)))
+				SOCK_LOG_DBG("failed to send shutdown msg\n");
+		}
+
 		cm_entry.fid = &ep->ep.fid;
 		SOCK_LOG_DBG("reporting FI_SHUTDOWN\n");
 		if (sock_eq_report_event(ep->attr->eq, FI_SHUTDOWN,
 					 &cm_entry, sizeof(cm_entry), 0))
 			SOCK_LOG_ERROR("Error in writing to EQ\n");
+		break;
+	case SOCK_CM_STATE_REQUESTED:
+		SOCK_LOG_DBG("reporting FI_REJECT\n");
+		if (sock_eq_report_error(ep->attr->eq, &ep->ep.fid, NULL, 0,
+					 FI_ECONNREFUSED, -FI_ECONNREFUSED,
+					 NULL, 0))
+			SOCK_LOG_ERROR("Error in writing to EQ\n");
+		break;
+
+	case SOCK_CM_STATE_DISCONNECTED:
+		/* Nothing to do, already disconnected */
+		break;
+	default:
+		assert(0);
+		break;
 	}
-	ofi_close_socket(ep->attr->cm.sock);
+}
+
+static void sock_ep_cm_shutdown_handler(struct sock_ep_cm_head *cm_head,
+                                        struct sock_conn_hdr *hdr,
+                                        struct sock_conn_req_handle *handle)
+{
+	struct sock_ep *ep = handle->ep;
+	assert(ep);
+
+	assert(hdr->type == SOCK_CONN_SHUTDOWN);
+	sock_ep_cm_shutdown_report(ep, 0);
+	sock_ep_cm_unmonitor_handle_locked(cm_head, handle, 1);
 }
 
 static void sock_ep_cm_report_connect_fail(struct sock_ep *ep,
 					   void *param, size_t paramlen)
 {
-	SOCK_LOG_DBG("reporting FI_REJECT\n");
-	if (sock_eq_report_error(ep->attr->eq, &ep->ep.fid, NULL, 0,
-				 FI_ECONNREFUSED, -FI_ECONNREFUSED,
-				 param, paramlen))
-		SOCK_LOG_ERROR("Error in writing to EQ\n");
+	int do_report = 0;
+
+	fastlock_acquire(&ep->attr->cm.lock);
+	if (ep->attr->cm.state == SOCK_CM_STATE_REQUESTED) {
+		do_report = 1;
+		ep->attr->cm.state = SOCK_CM_STATE_DISCONNECTED;
+	}
+	fastlock_release(&ep->attr->cm.lock);
+
+	if (do_report) {
+		SOCK_LOG_DBG("reporting FI_REJECT\n");
+		if (sock_eq_report_error(ep->attr->eq, &ep->ep.fid, NULL, 0,
+					 FI_ECONNREFUSED, -FI_ECONNREFUSED,
+					 param, paramlen))
+			SOCK_LOG_ERROR("Error in writing to EQ\n");
+	}
 }
 
-static void *sock_ep_cm_connect_handler(void *data)
+/* Caller must hold `cm_head::signal_lock` */
+static void sock_ep_cm_add_to_msg_list(struct sock_ep_cm_head *cm_head,
+				       struct sock_conn_req_handle *handle)
 {
-	int sock_fd, ret;
-	struct sock_conn_req_handle *handle = data;
-	struct sock_conn_req *req = handle->req;
-	struct sock_conn_hdr response;
+	dlist_insert_tail(&handle->entry, &cm_head->msg_list);
+	fd_signal_set(&cm_head->signal);
+}
+
+static void sock_ep_cm_connect_handler(struct sock_ep_cm_head *cm_head,
+                                       struct sock_conn_hdr *hdr,
+                                       struct sock_conn_req_handle *handle)
+{
+	int sock_fd = handle->sock_fd;
 	struct sock_ep *ep = handle->ep;
 	void *param = NULL;
 	struct fi_eq_cm_entry *cm_entry = NULL;
 	int cm_data_sz, response_port;
 
-	sock_fd = ofi_socket(AF_INET, SOCK_STREAM, 0);
-	if (sock_fd < 0) {
-		SOCK_LOG_ERROR("no socket\n");
-		sock_ep_cm_report_connect_fail(handle->ep, NULL, 0);
-		goto out;
-	}
-
-	ofi_straddr_dbg(&sock_prov, FI_LOG_EP_CTRL, "Connecting to address",
-			&handle->dest_addr);
-	sock_set_sockopts(sock_fd, SOCK_OPTS_KEEPALIVE);
-	ret = connect(sock_fd, (struct sockaddr *)&handle->dest_addr,
-		      sizeof(handle->dest_addr));
-	if (ret < 0) {
-		SOCK_LOG_ERROR("connect failed : %s\n",
-			       strerror(ofi_sockerr()));
-		goto err;
-	}
-
-	if (sock_cm_send(sock_fd, req, sizeof(*req)))
-		goto err;
-	if (handle->paramlen && sock_cm_send(sock_fd, handle->cm_data, handle->paramlen))
-		goto err;
-
-	if (sock_cm_recv(sock_fd, &response, sizeof(response)))
-		goto err;
+	assert(hdr->type == SOCK_CONN_ACCEPT
+	       || hdr->type == SOCK_CONN_REJECT);
 
-	cm_data_sz = ntohs(response.cm_data_sz);
-	response_port = ntohs(response.port);
+	cm_data_sz = ntohs(hdr->cm_data_sz);
+	response_port = ntohs(hdr->port);
 	if (cm_data_sz) {
 		param = calloc(1, cm_data_sz);
 		if (!param)
@@ -540,9 +584,9 @@ static void *sock_ep_cm_connect_handler(void *data)
 			goto err;
 	}
 
-	if (response.type == SOCK_CONN_REJECT) {
+	if (hdr->type == SOCK_CONN_REJECT) {
 		sock_ep_cm_report_connect_fail(handle->ep, param, cm_data_sz);
-		ofi_close_socket(sock_fd);
+		sock_ep_cm_unmonitor_handle_locked(cm_head, handle, 1);
 	} else {
 		cm_entry = calloc(1, sizeof(*cm_entry) + SOCK_EP_MAX_CM_DATA_SZ);
 		if (!cm_entry)
@@ -550,8 +594,7 @@ static void *sock_ep_cm_connect_handler(void *data)
 
 		cm_entry->fid = &ep->ep.fid;
 		memcpy(&cm_entry->data, param, cm_data_sz);
-		ep->attr->cm.is_connected = 1;
-		ep->attr->cm.do_listen = 1;
+		ep->attr->cm.state = SOCK_CM_STATE_CONNECTED;
 		ep->attr->cm.sock = sock_fd;
 		ep->attr->msg_dest_port = response_port;
 		SOCK_LOG_DBG("got accept - port: %d\n", response_port);
@@ -560,26 +603,43 @@ static void *sock_ep_cm_connect_handler(void *data)
 		if (sock_eq_report_event(ep->attr->eq, FI_CONNECTED, cm_entry,
 					 sizeof(*cm_entry) + cm_data_sz, 0))
 			SOCK_LOG_ERROR("Error in writing to EQ\n");
-		sock_ep_wait_shutdown(ep);
 	}
 	goto out;
 err:
 	SOCK_LOG_ERROR("io failed : %s\n", strerror(ofi_sockerr()));
 	sock_ep_cm_report_connect_fail(handle->ep, NULL, 0);
-	ofi_close_socket(sock_fd);
+	sock_ep_cm_unmonitor_handle_locked(cm_head, handle, 1);
+	handle->ep->attr->info.handle = NULL;
+	/* Register handle for later deletion */
+	handle->state = SOCK_CONN_HANDLE_DELETED;
+	fastlock_acquire(&cm_head->signal_lock);
+	sock_ep_cm_add_to_msg_list(cm_head, handle);
+	fastlock_release(&cm_head->signal_lock);
 out:
 	free(param);
 	free(cm_entry);
-	free(handle->req);
-	free(handle);
-	return NULL;
+}
+
+static struct sock_conn_req_handle *sock_ep_cm_new_handle(void)
+{
+	struct sock_conn_req_handle *handle;
+
+	handle = calloc(1, sizeof(*handle));
+	if (handle) {
+		pthread_mutex_init(&handle->finalized_mutex, NULL);
+		pthread_cond_init(&handle->finalized_cond, NULL);
+		handle->state = SOCK_CONN_HANDLE_ACTIVE;
+	}
+	return handle;
 }
 
 static int sock_ep_cm_connect(struct fid_ep *ep, const void *addr,
 			      const void *param, size_t paramlen)
 {
 	struct sock_conn_req *req = NULL;
+	struct sock_ep_cm_head *cm_head = NULL;
 	struct sock_conn_req_handle *handle = NULL;
+	int sock_fd, ret;
 	struct sock_ep *_ep;
 	struct sock_eq *_eq;
 
@@ -596,23 +656,28 @@ static int sock_ep_cm_connect(struct fid_ep *ep, const void *addr,
 		if (!_ep->attr->dest_addr)
 			return -FI_ENOMEM;
 	}
-	memcpy(_ep->attr->dest_addr, addr, sizeof(*_ep->attr->dest_addr));
+	memcpy(_ep->attr->dest_addr, addr, ofi_sizeofaddr(addr));
 
 	req = calloc(1, sizeof(*req));
 	if (!req)
 		return -FI_ENOMEM;
 
-	handle = calloc(1, sizeof(*handle));
-	if (!handle)
-		goto out;
+	handle = sock_ep_cm_new_handle();
+	if (!handle) {
+		ret = -FI_ENOMEM;
+		goto err;
+	}
 
 	req->hdr.type = SOCK_CONN_REQ;
 	req->hdr.port = htons(_ep->attr->msg_src_port);
 	req->hdr.cm_data_sz = htons(paramlen);
 	req->caps = _ep->attr->info.caps;
-	memcpy(&req->src_addr, _ep->attr->src_addr, sizeof(req->src_addr));
-	memcpy(&handle->dest_addr, addr, sizeof(handle->dest_addr));
+	memcpy(&req->src_addr, _ep->attr->src_addr,
+	       ofi_sizeofaddr(&_ep->attr->src_addr->sa));
+	memcpy(&handle->dest_addr, addr, ofi_sizeofaddr(addr));
 
+	cm_head = &_ep->attr->domain->cm_head;
+	_ep->attr->info.handle = (void*) handle;
 	handle->ep = _ep;
 	handle->req = req;
 	if (paramlen) {
@@ -620,67 +685,59 @@ static int sock_ep_cm_connect(struct fid_ep *ep, const void *addr,
 		memcpy(handle->cm_data, param, paramlen);
 	}
 
-	if (_ep->attr->cm.listener_thread &&
-	    pthread_join(_ep->attr->cm.listener_thread, NULL))
-		SOCK_LOG_DBG("failed to join cm listener\n");
-
-	if (pthread_create(&_ep->attr->cm.listener_thread, NULL,
-			   sock_ep_cm_connect_handler, handle)) {
-		SOCK_LOG_ERROR("failed to create cm thread\n");
-		goto out;
+	sock_fd = ofi_socket(handle->dest_addr.sa.sa_family, SOCK_STREAM, 0);
+	if (sock_fd < 0) {
+		SOCK_LOG_ERROR("no socket\n");
+		ret = -ofi_sockerr();
+		goto err;
 	}
-	return 0;
-out:
-	free(req);
-	free(handle);
-	return -FI_ENOMEM;
-}
-
-static void *sock_cm_accept_handler(void *data)
-{
-	int ret;
-	struct sock_conn_hdr reply;
-	struct sock_conn_req_handle *hreq = data;
-	struct sock_ep_attr *ep_attr;
-	struct fi_eq_cm_entry cm_entry;
-
-	ep_attr = hreq->ep->attr;
-	ep_attr->msg_dest_port = ntohs(hreq->req->hdr.port);
 
-	reply.type = SOCK_CONN_ACCEPT;
-	reply.port = htons(ep_attr->msg_src_port);
-	reply.cm_data_sz = htons(hreq->paramlen);
-	ret = sock_cm_send(hreq->sock_fd, &reply, sizeof(reply));
-	if (ret) {
-		SOCK_LOG_ERROR("failed to reply\n");
-		return NULL;
+	ofi_straddr_dbg(&sock_prov, FI_LOG_EP_CTRL, "Connecting to address",
+			&handle->dest_addr);
+	sock_set_sockopts(sock_fd, SOCK_OPTS_KEEPALIVE);
+	ret = connect(sock_fd, &handle->dest_addr.sa,
+		      ofi_sizeofaddr(&handle->dest_addr.sa));
+	if (ret < 0) {
+		SOCK_LOG_ERROR("connect failed : %s\n",
+			       strerror(ofi_sockerr()));
+		ret = -ofi_sockerr();
+		goto close_socket;
 	}
 
-	if (hreq->paramlen && sock_cm_send(hreq->sock_fd, hreq->cm_data, hreq->paramlen)) {
-		SOCK_LOG_ERROR("failed to send userdata\n");
-		return NULL;
+	ret = sock_cm_send(sock_fd, req, sizeof(*req));
+	if (ret)
+		goto close_socket;
+
+	if (handle->paramlen) {
+		ret = sock_cm_send(sock_fd, handle->cm_data, handle->paramlen);
+		if (ret)
+			goto close_socket;
 	}
 
-	cm_entry.fid = &hreq->ep->ep.fid;
-	SOCK_LOG_DBG("reporting FI_CONNECTED\n");
-	if (sock_eq_report_event(ep_attr->eq, FI_CONNECTED, &cm_entry,
-				 sizeof(cm_entry), 0))
-		SOCK_LOG_ERROR("Error in writing to EQ\n");
-	ep_attr->cm.is_connected = 1;
-	ep_attr->cm.do_listen = 1;
-	ep_attr->cm.sock = hreq->sock_fd;
-	sock_ep_wait_shutdown(hreq->ep);
+	/* Monitor the connection */
+	_ep->attr->cm.state = SOCK_CM_STATE_REQUESTED;
+	handle->sock_fd = sock_fd;
+	sock_ep_cm_monitor_handle(cm_head, handle, FI_EPOLL_IN);
 
-	if (pthread_join(hreq->req_handler, NULL))
-		SOCK_LOG_DBG("failed to join req-handler\n");
-	free(hreq->req);
-	free(hreq);
-	return NULL;
+	return 0;
+close_socket:
+	SOCK_LOG_ERROR("io failed : %s\n", strerror(errno));
+	ofi_close_socket(sock_fd);
+err:
+	_ep->attr->info.handle = NULL;
+	free(req);
+	free(handle);
+	return ret;
 }
 
 static int sock_ep_cm_accept(struct fid_ep *ep, const void *param, size_t paramlen)
 {
+	int ret;
+	struct sock_ep_cm_head *cm_head = NULL;
 	struct sock_conn_req_handle *handle;
+	struct sock_ep_attr *ep_attr;
+	struct fi_eq_cm_entry cm_entry;
+	struct sock_conn_hdr reply;
 	struct sock_ep *_ep;
 
 	_ep = container_of(ep, struct sock_ep, ep);
@@ -699,49 +756,55 @@ static int sock_ep_cm_accept(struct fid_ep *ep, const void *param, size_t paraml
 
 	handle->ep = _ep;
 	handle->paramlen = 0;
-	handle->is_accepted = 1;
+	handle->state = SOCK_CONN_HANDLE_ACCEPTED;
 	if (paramlen) {
 		handle->paramlen = paramlen;
 		memcpy(handle->cm_data, param, paramlen);
 	}
+	cm_head = &_ep->attr->domain->cm_head;
+	ep_attr = handle->ep->attr;
+	ep_attr->msg_dest_port = ntohs(handle->req->hdr.port);
 
-	if (_ep->attr->cm.listener_thread &&
-	    pthread_join(_ep->attr->cm.listener_thread, NULL))
-		SOCK_LOG_DBG("failed to join cm listener\n");
+	reply.type = SOCK_CONN_ACCEPT;
+	reply.port = htons(ep_attr->msg_src_port);
+	reply.cm_data_sz = htons(handle->paramlen);
+	ret = sock_cm_send(handle->sock_fd, &reply, sizeof(reply));
+	if (ret) {
+		SOCK_LOG_ERROR("failed to reply\n");
+		return ret;
+	}
 
-	if (pthread_create(&_ep->attr->cm.listener_thread, NULL,
-			   sock_cm_accept_handler, handle)) {
-		SOCK_LOG_ERROR("Couldnt create accept handler\n");
-		return -FI_ENOMEM;
+	if (handle->paramlen) {
+		ret = sock_cm_send(handle->sock_fd, handle->cm_data, handle->paramlen);
+		if (ret) {
+			SOCK_LOG_ERROR("failed to send userdata\n");
+			return ret;
+		}
 	}
+	/* Monitor the handle prior to report the event */
+	sock_ep_cm_monitor_handle(cm_head, handle, FI_EPOLL_IN);
+	sock_ep_enable(ep);
+
+	cm_entry.fid = &handle->ep->ep.fid;
+	SOCK_LOG_DBG("reporting FI_CONNECTED\n");
+	if (sock_eq_report_event(ep_attr->eq, FI_CONNECTED, &cm_entry,
+				 sizeof(cm_entry), 0))
+		SOCK_LOG_ERROR("Error in writing to EQ\n");
+	ep_attr->cm.state = SOCK_CM_STATE_CONNECTED;
+	ep_attr->cm.sock = handle->sock_fd;
+
 	return 0;
 }
 
 static int sock_ep_cm_shutdown(struct fid_ep *ep, uint64_t flags)
 {
 	struct sock_ep *_ep;
-	struct fi_eq_cm_entry cm_entry = {0};
-	struct sock_conn_hdr msg = {0};
-	char c = 0;
 
 	_ep = container_of(ep, struct sock_ep, ep);
-	fastlock_acquire(&_ep->attr->cm.lock);
-	if (_ep->attr->cm.is_connected) {
-		msg.type = SOCK_CONN_SHUTDOWN;
-		if (sock_cm_send(_ep->attr->cm.sock, &msg, sizeof(msg)))
-			SOCK_LOG_DBG("failed to send shutdown msg\n");
-		_ep->attr->cm.is_connected = 0;
-		_ep->attr->cm.do_listen = 0;
-		if (ofi_write_socket(_ep->attr->cm.signal_fds[0], &c, 1) != 1)
-			SOCK_LOG_DBG("Failed to signal\n");
-
-		cm_entry.fid = &_ep->ep.fid;
-		SOCK_LOG_DBG("reporting FI_SHUTDOWN\n");
-		if (sock_eq_report_event(_ep->attr->eq, FI_SHUTDOWN,
-					 &cm_entry, sizeof(cm_entry), 0))
-			SOCK_LOG_ERROR("Error in writing to EQ\n");
-	}
-	fastlock_release(&_ep->attr->cm.lock);
+	sock_ep_cm_shutdown_report(_ep, 1);
+
+	ofi_close_socket(_ep->attr->cm.sock);
+	_ep->attr->cm.sock = INVALID_SOCKET;
 	sock_ep_disable(ep);
 	return 0;
 }
@@ -858,9 +921,10 @@ static int sock_pep_fi_close(fid_t fid)
 		SOCK_LOG_DBG("pthread join failed\n");
 	}
 
+	sock_ep_cm_stop_thread(&pep->cm_head);
+
 	ofi_close_socket(pep->cm.signal_fds[0]);
 	ofi_close_socket(pep->cm.signal_fds[1]);
-	fastlock_destroy(&pep->cm.lock);
 
 	free(pep);
 	return 0;
@@ -893,15 +957,107 @@ static struct fi_info *sock_ep_msg_get_info(struct sock_pep *pep,
 			    &hints, &pep->src_addr, &req->src_addr);
 }
 
-static void *sock_pep_req_handler(void *data)
+void sock_ep_cm_signal(struct sock_ep_cm_head *cm_head)
+{
+	fastlock_acquire(&cm_head->signal_lock);
+	fd_signal_set(&cm_head->signal);
+	fastlock_release(&cm_head->signal_lock);
+}
+
+static void sock_ep_cm_process_rejected(struct sock_ep_cm_head *cm_head,
+                                        struct sock_conn_req_handle *hreq)
+{
+	struct sock_conn_hdr reply;
+
+	reply.type = SOCK_CONN_REJECT;
+	reply.cm_data_sz = htons(hreq->paramlen);
+
+	SOCK_LOG_DBG("sending reject message\n");
+	if (sock_cm_send(hreq->sock_fd, &reply, sizeof(reply))) {
+		SOCK_LOG_ERROR("failed to reply\n");
+		goto free_handle;
+	}
+
+	if (hreq->paramlen && sock_cm_send(hreq->sock_fd, hreq->cm_data,
+					   hreq->paramlen)) {
+		SOCK_LOG_ERROR("failed to send userdata\n");
+		goto free_handle;
+	}
+
+free_handle:
+	sock_ep_cm_unmonitor_handle(cm_head, hreq, 1);
+	free(hreq->req);
+	free(hreq);
+}
+
+static void sock_ep_cm_process_deleted(struct sock_ep_cm_head *cm_head,
+                                       struct sock_conn_req_handle *hreq)
+{
+	free(hreq->req);
+	free(hreq);
+}
+
+static void sock_ep_cm_process_finalizing(struct sock_ep_cm_head *cm_head,
+                                          struct sock_conn_req_handle *hreq)
+{
+	sock_ep_cm_unmonitor_handle(cm_head, hreq, 1);
+
+	pthread_mutex_lock(&hreq->finalized_mutex);
+	hreq->state = SOCK_CONN_HANDLE_FINALIZED;
+	pthread_cond_signal(&hreq->finalized_cond);
+	pthread_mutex_unlock(&hreq->finalized_mutex);
+}
+
+static struct sock_conn_req_handle *
+sock_ep_cm_pop_from_msg_list(struct sock_ep_cm_head *cm_head)
+{
+	struct dlist_entry *entry;
+	struct sock_conn_req_handle *hreq = NULL;
+
+	fastlock_acquire(&cm_head->signal_lock);
+	if (!dlist_empty(&cm_head->msg_list)) {
+		entry = cm_head->msg_list.next;
+		dlist_remove(entry);
+		hreq = container_of(entry, struct sock_conn_req_handle, entry);
+	}
+	fastlock_release(&cm_head->signal_lock);
+	return hreq;
+}
+
+static void
+sock_ep_cm_check_closing_rejected_list(struct sock_ep_cm_head *cm_head)
+{
+	struct sock_conn_req_handle *hreq;
+
+	while ((hreq = sock_ep_cm_pop_from_msg_list(cm_head)) != NULL) {
+		switch (hreq->state) {
+		case SOCK_CONN_HANDLE_REJECTED:
+			sock_ep_cm_process_rejected(cm_head, hreq);
+			break;
+		case SOCK_CONN_HANDLE_FINALIZING:
+			sock_ep_cm_process_finalizing(cm_head, hreq);
+			break;
+		case SOCK_CONN_HANDLE_DELETED:
+			sock_ep_cm_process_deleted(cm_head, hreq);
+			break;
+		default:
+			assert(0);
+			break;
+		}
+	}
+}
+
+static void sock_pep_req_handler(struct sock_ep_cm_head *cm_head,
+                                 struct sock_conn_hdr *hdr,
+                                 struct sock_conn_req_handle *handle)
 {
 	int ret, entry_sz;
 	struct fi_info *info;
 	struct sock_conn_req *conn_req = NULL;
 	struct fi_eq_cm_entry *cm_entry = NULL;
-	struct sock_conn_req_handle *handle = data;
 	int req_cm_data_sz;
-	char c = 0;
+
+	assert(hdr->type == SOCK_CONN_REQ);
 
 	conn_req = calloc(1, sizeof(*conn_req) + SOCK_EP_MAX_CM_DATA_SZ);
 	if (!conn_req) {
@@ -909,7 +1065,11 @@ static void *sock_pep_req_handler(void *data)
 		goto err;
 	}
 
-	ret = sock_cm_recv(handle->sock_fd, conn_req, sizeof(*conn_req));
+	memcpy(&conn_req->hdr, hdr, sizeof(*hdr));
+
+	ret = sock_cm_recv(handle->sock_fd,
+	                   &conn_req->src_addr,
+	                   sizeof(*conn_req) - sizeof(struct sock_conn_hdr));
 	if (ret) {
 		SOCK_LOG_ERROR("IO failed\n");
 		goto err;
@@ -926,16 +1086,15 @@ static void *sock_pep_req_handler(void *data)
 	}
 
 	info = sock_ep_msg_get_info(handle->pep, conn_req);
-	if (info == NULL) {
+	if (!info) {
 		handle->paramlen = 0;
-		fastlock_acquire(&handle->pep->cm.lock);
-		dlist_insert_tail(&handle->entry, &handle->pep->cm.msg_list);
-		fastlock_release(&handle->pep->cm.lock);
+		handle->state = SOCK_CONN_HANDLE_REJECTED;
+		/* `cm_head::signal_lock` has already been held
+		 * in `sock_ep_cm_thread` function */
+		sock_ep_cm_add_to_msg_list(cm_head, handle);
 
-		if (ofi_write_socket(handle->pep->cm.signal_fds[0], &c, 1) != 1)
-			SOCK_LOG_DBG("Failed to signal\n");
 		free(conn_req);
-		return NULL;
+		return;
 	}
 
 	cm_entry = calloc(1, sizeof(*cm_entry) + req_cm_data_sz);
@@ -953,54 +1112,19 @@ static void *sock_pep_req_handler(void *data)
 	cm_entry->info->handle = &handle->handle;
 	memcpy(cm_entry->data, conn_req->cm_data, req_cm_data_sz);
 
+	sock_ep_cm_unmonitor_handle_locked(cm_head, handle, 0);
+
 	SOCK_LOG_DBG("reporting conn-req to EQ\n");
 	if (sock_eq_report_event(handle->pep->eq, FI_CONNREQ, cm_entry, entry_sz, 0))
 		SOCK_LOG_ERROR("Error in writing to EQ\n");
 
 	free(cm_entry);
-	return NULL;
+	return;
 err:
 	ofi_close_socket(handle->sock_fd);
 	free(cm_entry);
 	free(conn_req);
 	free(handle);
-	return NULL;
-}
-
-static void sock_pep_check_msg_list(struct sock_pep *pep)
-{
-	struct dlist_entry *entry;
-	struct sock_conn_req_handle *hreq;
-	struct sock_conn_hdr reply;
-
-	fastlock_acquire(&pep->cm.lock);
-	while (!dlist_empty(&pep->cm.msg_list)) {
-		entry = pep->cm.msg_list.next;
-		dlist_remove(entry);
-		hreq = container_of(entry, struct sock_conn_req_handle, entry);
-
-		reply.type = SOCK_CONN_REJECT;
-		reply.cm_data_sz = htons(hreq->paramlen);
-
-		SOCK_LOG_DBG("sending reject message\n");
-		if (sock_cm_send(hreq->sock_fd, &reply, sizeof(reply))) {
-			SOCK_LOG_ERROR("failed to reply\n");
-			break;
-		}
-
-		if (hreq->paramlen && sock_cm_send(hreq->sock_fd, hreq->cm_data,
-						   hreq->paramlen)) {
-			SOCK_LOG_ERROR("failed to send userdata\n");
-			break;
-		}
-
-		if (pthread_join(hreq->req_handler, NULL))
-			SOCK_LOG_DBG("failed to join req-handler\n");
-		ofi_close_socket(hreq->sock_fd);
-		free(hreq->req);
-		free(hreq);
-	}
-	fastlock_release(&pep->cm.lock);
 }
 
 static void *sock_pep_listener_thread(void *data)
@@ -1023,7 +1147,6 @@ static void *sock_pep_listener_thread(void *data)
 				ret = ofi_read_socket(pep->cm.signal_fds[1], &tmp, 1);
 				if (ret != 1)
 					SOCK_LOG_DBG("Invalid signal\n");
-				sock_pep_check_msg_list(pep);
 				continue;
 			}
 		} else {
@@ -1037,7 +1160,7 @@ static void *sock_pep_listener_thread(void *data)
 		}
 
 		sock_set_sockopts(conn_fd, SOCK_OPTS_KEEPALIVE);
-		handle = calloc(1, sizeof(*handle));
+		handle = sock_ep_cm_new_handle();
 		if (!handle) {
 			SOCK_LOG_ERROR("cannot allocate memory\n");
 			ofi_close_socket(conn_fd);
@@ -1047,12 +1170,8 @@ static void *sock_pep_listener_thread(void *data)
 		handle->sock_fd = conn_fd;
 		handle->pep = pep;
 
-		if (pthread_create(&handle->req_handler, NULL,
-				   sock_pep_req_handler, handle)) {
-			SOCK_LOG_ERROR("failed to create req handler\n");
-			ofi_close_socket(conn_fd);
-			free(handle);
-		}
+		/* Monitor the connection */
+		sock_ep_cm_monitor_handle(&pep->cm_head, handle, FI_EPOLL_IN);
 	}
 
 	SOCK_LOG_DBG("PEP listener thread exiting\n");
@@ -1077,6 +1196,11 @@ static int sock_pep_listen(struct fid_pep *pep)
 	if (_pep->cm.listener_thread)
 		return 0;
 
+	if (sock_ep_cm_start_thread(&_pep->cm_head)) {
+		SOCK_LOG_ERROR("Couldn't create listener thread\n");
+		return -FI_EINVAL;
+	}
+
 	if (!_pep->cm.do_listen && sock_pep_create_listener(_pep)) {
 		SOCK_LOG_ERROR("Failed to create pep thread\n");
 		return -FI_EINVAL;
@@ -1091,12 +1215,13 @@ static int sock_pep_reject(struct fid_pep *pep, fid_t handle,
 	struct sock_conn_req_handle *hreq;
 	struct sock_conn_req *req;
 	struct sock_pep *_pep;
-	char c = 0;
+	struct sock_ep_cm_head *cm_head;
 
 	_pep = container_of(pep, struct sock_pep, pep);
 	hreq = container_of(handle, struct sock_conn_req_handle, handle);
 	req = hreq->req;
-	if (!req || hreq->handle.fclass != FI_CLASS_CONNREQ || hreq->is_accepted)
+	if (!req || hreq->handle.fclass != FI_CLASS_CONNREQ ||
+	    hreq->state == SOCK_CONN_HANDLE_ACCEPTED)
 		return -FI_EINVAL;
 
 	hreq->paramlen = 0;
@@ -1105,12 +1230,11 @@ static int sock_pep_reject(struct fid_pep *pep, fid_t handle,
 		hreq->paramlen = paramlen;
 	}
 
-	fastlock_acquire(&_pep->cm.lock);
-	dlist_insert_tail(&hreq->entry, &_pep->cm.msg_list);
-	fastlock_release(&_pep->cm.lock);
-
-	if (ofi_write_socket(_pep->cm.signal_fds[0], &c, 1) != 1)
-		SOCK_LOG_DBG("Failed to signal\n");
+	cm_head = &_pep->cm_head;
+	hreq->state = SOCK_CONN_HANDLE_REJECTED;
+	fastlock_acquire(&cm_head->signal_lock);
+	sock_ep_cm_add_to_msg_list(cm_head, hreq);
+	fastlock_release(&cm_head->signal_lock);
 	return 0;
 }
 
@@ -1192,10 +1316,20 @@ int sock_msg_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
 				info->src_addrlen);
 		} else {
 			memset(&hints, 0, sizeof(hints));
-			hints.ai_family = AF_INET;
 			hints.ai_socktype = SOCK_STREAM;
-
-			ret = getaddrinfo("localhost", NULL, &hints, &result);
+			hints.ai_family = ofi_get_sa_family(info);
+			if (!hints.ai_family)
+				hints.ai_family = AF_INET;
+
+			if (hints.ai_family == AF_INET) {
+				ret = getaddrinfo("127.0.0.1", NULL, &hints,
+						  &result);
+			} else if (hints.ai_family == AF_INET6) {
+				ret = getaddrinfo("::1", NULL, &hints, &result);
+			} else {
+				ret = getaddrinfo("localhost", NULL, &hints,
+						  &result);
+			}
 			if (ret) {
 				ret = -FI_EINVAL;
 				SOCK_LOG_DBG("getaddrinfo failed!\n");
@@ -1218,14 +1352,12 @@ int sock_msg_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
 	}
 
 	fd_set_nonblock(_pep->cm.signal_fds[1]);
-	dlist_init(&_pep->cm.msg_list);
 
 	_pep->pep.fid.fclass = FI_CLASS_PEP;
 	_pep->pep.fid.context = context;
 	_pep->pep.fid.ops = &sock_pep_fi_ops;
 	_pep->pep.cm = &sock_pep_cm_ops;
 	_pep->pep.ops = &sock_pep_ops;
-	fastlock_init(&_pep->cm.lock);
 
 	_pep->sock_fab = container_of(fabric, struct sock_fabric, fab_fid);
 	*pep = &_pep->pep;
@@ -1235,3 +1367,158 @@ err:
 	return ret;
 }
 
+static void sock_ep_cm_handle_rx(struct sock_ep_cm_head *cm_head,
+                                struct sock_conn_req_handle *handle)
+{
+	struct sock_conn_hdr hdr;
+
+	if (sock_cm_recv(handle->sock_fd, &hdr, sizeof(hdr))) {
+		SOCK_LOG_ERROR("io failed for fd %d\n", handle->sock_fd);
+		if (handle->ep) {
+			sock_ep_cm_shutdown_report(handle->ep, 0);
+		}
+
+		sock_ep_cm_unmonitor_handle_locked(cm_head, handle, 1);
+		return;
+	}
+
+	switch(hdr.type) {
+	case SOCK_CONN_REQ:
+		sock_pep_req_handler(cm_head, &hdr, handle);
+		break;
+	case SOCK_CONN_ACCEPT:
+	case SOCK_CONN_REJECT:
+		sock_ep_cm_connect_handler(cm_head, &hdr, handle);
+		break;
+	case SOCK_CONN_SHUTDOWN:
+		sock_ep_cm_shutdown_handler(cm_head, &hdr, handle);
+		break;
+	default:
+		SOCK_LOG_ERROR("Unexpected message type %d\n", hdr.type);
+		break;
+	}
+}
+
+static void *sock_ep_cm_thread(void *arg)
+{
+	int num_fds, i;
+	struct sock_ep_cm_head *cm_head = arg;
+	void *ep_contexts[SOCK_EPOLL_WAIT_EVENTS];
+	struct sock_conn_req_handle *handle;
+
+	while (cm_head->do_listen) {
+		sock_ep_cm_check_closing_rejected_list(cm_head);
+
+		num_fds = fi_epoll_wait(cm_head->emap, ep_contexts,
+		                        SOCK_EPOLL_WAIT_EVENTS, -1);
+		if (num_fds < 0) {
+			SOCK_LOG_ERROR("poll failed : %s\n", strerror(errno));
+			continue;
+		}
+
+		fastlock_acquire(&cm_head->signal_lock);
+		for (i = 0; i < num_fds; i++) {
+			handle = ep_contexts[i];
+
+			if (handle == NULL) { /* Signal event */
+				fd_signal_reset(&cm_head->signal);
+				continue;
+			}
+
+			/* ep_contexts[] may report multiple events for the same handle.
+			 * Suppose we received 2 elements for 1 handle: the first will
+			 * unmonitor the handle, then the second event will have
+			 * handle->monitored set to 0
+			 */
+			if (!handle->monitored) {
+				assert(handle->sock_fd == INVALID_SOCKET);
+				continue;
+			}
+
+			assert(handle->sock_fd != INVALID_SOCKET);
+			sock_ep_cm_handle_rx(cm_head, handle);
+		}
+		fastlock_release(&cm_head->signal_lock);
+	}
+	return NULL;
+}
+
+
+int sock_ep_cm_start_thread(struct sock_ep_cm_head *cm_head)
+{
+	assert(cm_head->do_listen == 0);
+
+	fastlock_init(&cm_head->signal_lock);
+	dlist_init(&cm_head->msg_list);
+
+	int ret = fi_epoll_create(&cm_head->emap);
+	if (ret < 0) {
+		SOCK_LOG_ERROR("failed to create epoll set\n");
+		goto err1;
+	}
+
+	ret = fd_signal_init(&cm_head->signal);
+	if (ret < 0) {
+		ret = -errno;
+		SOCK_LOG_ERROR("failed to init signal\n");
+		goto err2;
+	}
+
+	ret = fi_epoll_add(cm_head->emap,
+	                   cm_head->signal.fd[FI_READ_FD],
+	                   FI_EPOLL_IN, NULL);
+	if (ret != 0){
+		SOCK_LOG_ERROR("failed to add signal fd to epoll\n");
+		goto err3;
+	}
+
+	cm_head->do_listen = 1;
+	ret = pthread_create(&cm_head->listener_thread, 0,
+	                     sock_ep_cm_thread, cm_head);
+	if (ret) {
+		SOCK_LOG_ERROR("failed to create conn listener thread\n");
+		goto err3;
+	}
+	return 0;
+
+err3:
+	cm_head->do_listen = 0;
+	fd_signal_free(&cm_head->signal);
+err2:
+	fi_epoll_close(cm_head->emap);
+err1:
+	return ret;
+}
+
+void sock_ep_cm_wait_handle_finalized(struct sock_ep_cm_head *cm_head,
+                                      struct sock_conn_req_handle *handle)
+{
+	handle->state = SOCK_CONN_HANDLE_FINALIZING;
+	fastlock_acquire(&cm_head->signal_lock);
+	sock_ep_cm_add_to_msg_list(cm_head, handle);
+	fastlock_release(&cm_head->signal_lock);
+
+	pthread_mutex_lock(&handle->finalized_mutex);
+	while (handle->state != SOCK_CONN_HANDLE_FINALIZED)
+		fi_wait_cond(&handle->finalized_cond,
+				&handle->finalized_mutex, -1);
+	pthread_mutex_unlock(&handle->finalized_mutex);
+}
+
+void sock_ep_cm_stop_thread(struct sock_ep_cm_head *cm_head)
+{
+	if (cm_head->do_listen == 0)
+		return;
+
+	cm_head->do_listen = 0;
+
+	sock_ep_cm_signal(cm_head);
+
+	if (cm_head->listener_thread &&
+			pthread_join(cm_head->listener_thread, NULL)) {
+		SOCK_LOG_DBG("pthread join failed\n");
+	}
+	fi_epoll_close(cm_head->emap);
+	fd_signal_free(&cm_head->signal);
+	fastlock_destroy(&cm_head->signal_lock);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_fabric.c
index f99eaa37a..ba991b374 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_fabric.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_fabric.c
@@ -60,6 +60,7 @@ int sock_pe_waittime = SOCK_PE_WAITTIME;
 const char sock_fab_name[] = "IP";
 const char sock_dom_name[] = "sockets";
 const char sock_prov_name[] = "sockets";
+int sock_conn_timeout = SOCK_CM_DEF_TIMEOUT;
 int sock_conn_retry = SOCK_CM_DEF_RETRY;
 int sock_cm_def_map_sz = SOCK_CMAP_DEF_SZ;
 int sock_av_def_sz = SOCK_AV_DEF_SZ;
@@ -276,6 +277,7 @@ int sock_verify_info(uint32_t version, const struct fi_info *hints)
 	case FI_FORMAT_UNSPEC:
 	case FI_SOCKADDR:
 	case FI_SOCKADDR_IN:
+	case FI_SOCKADDR_IN6:
 		break;
 	default:
 		SOCK_LOG_DBG("Unsupported address format\n");
@@ -349,6 +351,7 @@ static void sock_read_default_params()
 {
 	if (!read_default_params) {
 		fi_param_get_int(&sock_prov, "pe_waittime", &sock_pe_waittime);
+		fi_param_get_int(&sock_prov, "conn_timeout", &sock_conn_timeout);
 		fi_param_get_int(&sock_prov, "max_conn_retry", &sock_conn_retry);
 		fi_param_get_int(&sock_prov, "def_conn_map_sz", &sock_cm_def_map_sz);
 		fi_param_get_int(&sock_prov, "def_av_sz", &sock_av_def_sz);
@@ -393,30 +396,32 @@ static int sock_fabric(struct fi_fabric_attr *attr,
 	return 0;
 }
 
-int sock_get_src_addr(struct sockaddr_in *dest_addr,
-		      struct sockaddr_in *src_addr)
+int sock_get_src_addr(union ofi_sock_ip *dest_addr,
+		      union ofi_sock_ip *src_addr)
 {
 	int sock, ret;
 	socklen_t len;
 
-	sock = ofi_socket(AF_INET, SOCK_DGRAM, 0);
+	sock = ofi_socket(dest_addr->sa.sa_family, SOCK_DGRAM, 0);
 	if (sock < 0)
 		return -ofi_sockerr();
 
-	len = sizeof(*dest_addr);
-	ret = connect(sock, (struct sockaddr *) dest_addr, len);
+	len = ofi_sizeofaddr(&dest_addr->sa);
+	ret = connect(sock, &dest_addr->sa, len);
 	if (ret) {
 		SOCK_LOG_DBG("Failed to connect udp socket\n");
-		ret = sock_get_src_addr_from_hostname(src_addr, NULL);
+		ret = sock_get_src_addr_from_hostname(src_addr, NULL,
+						      dest_addr->sa.sa_family);
 		goto out;
 	}
 
-	ret = getsockname(sock, (struct sockaddr *) src_addr, &len);
-	src_addr->sin_port = 0;
+	ret = getsockname(sock, &src_addr->sa, &len);
+	ofi_addr_set_port(&src_addr->sa, 0);
 	if (ret) {
 		SOCK_LOG_DBG("getsockname failed\n");
 		ret = -ofi_sockerr();
 	}
+
 out:
 	ofi_close_socket(sock);
 	return ret;
@@ -442,13 +447,13 @@ static int sock_ep_getinfo(uint32_t version, const char *node,
 			   struct fi_info **info)
 {
 	struct addrinfo ai, *rai = NULL;
-	struct sockaddr_in *src_addr = NULL, *dest_addr = NULL;
-	struct sockaddr_in sin;
+	union ofi_sock_ip *src_addr = NULL, *dest_addr = NULL;
+	union ofi_sock_ip sip;
 	int ret;
 
 	memset(&ai, 0, sizeof(ai));
-	ai.ai_family = AF_INET;
 	ai.ai_socktype = SOCK_STREAM;
+	ai.ai_family = ofi_get_sa_family(hints);
 	if (flags & FI_NUMERICHOST)
 		ai.ai_flags |= AI_NUMERICHOST;
 
@@ -459,7 +464,7 @@ static int sock_ep_getinfo(uint32_t version, const char *node,
 			SOCK_LOG_DBG("getaddrinfo failed!\n");
 			return -FI_ENODATA;
 		}
-		src_addr = (struct sockaddr_in *) rai->ai_addr;
+		src_addr = (union ofi_sock_ip *) rai->ai_addr;
 		if (hints && hints->dest_addr)
 			dest_addr = hints->dest_addr;
 	} else {
@@ -469,7 +474,7 @@ static int sock_ep_getinfo(uint32_t version, const char *node,
 				SOCK_LOG_DBG("getaddrinfo failed!\n");
 				return -FI_ENODATA;
 			}
-			dest_addr = (struct sockaddr_in *) rai->ai_addr;
+			dest_addr = (union ofi_sock_ip *) rai->ai_addr;
 		} else if (hints) {
 			dest_addr = hints->dest_addr;
 		}
@@ -479,16 +484,19 @@ static int sock_ep_getinfo(uint32_t version, const char *node,
 	}
 
 	if (dest_addr && !src_addr) {
-		ret = sock_get_src_addr(dest_addr, &sin);
+		ret = sock_get_src_addr(dest_addr, &sip);
 		if (!ret)
-			src_addr = &sin;
+			src_addr = &sip;
 	}
 
-	if (src_addr)
-		SOCK_LOG_DBG("src_addr: %s\n", inet_ntoa(src_addr->sin_addr));
-	if (dest_addr)
-		SOCK_LOG_DBG("dest_addr: %s\n", inet_ntoa(dest_addr->sin_addr));
-
+	if (dest_addr) {
+		ofi_straddr_log(&sock_prov, FI_LOG_INFO, FI_LOG_CORE,
+				"dest addr: ", dest_addr);
+	}
+	if (src_addr) {
+		ofi_straddr_log(&sock_prov, FI_LOG_INFO, FI_LOG_CORE,
+				"src addr: ", src_addr);
+	}
 	switch (ep_type) {
 	case FI_EP_MSG:
 		ret = sock_msg_fi_info(version, src_addr, dest_addr, hints, info);
@@ -513,14 +521,32 @@ static int sock_ep_getinfo(uint32_t version, const char *node,
 	return ret;
 }
 
-void sock_insert_loopback_addr(struct slist *addr_list)
+static void sock_insert_loopback_addr(struct slist *addr_list)
 {
 	struct sock_host_list_entry *addr_entry;
 
 	addr_entry = calloc(1, sizeof(struct sock_host_list_entry));
 	if (!addr_entry)
 		return;
-	strncpy(addr_entry->hostname, "127.0.0.1", sizeof(addr_entry->hostname));
+
+	addr_entry->ipaddr.sin.sin_family = AF_INET;
+	addr_entry->ipaddr.sin.sin_addr.s_addr = INADDR_LOOPBACK;
+	ofi_straddr_log(&sock_prov, FI_LOG_INFO, FI_LOG_CORE,
+			"available addr: ", &addr_entry->ipaddr);
+
+	strncpy(addr_entry->ipstr, "127.0.0.1", sizeof(addr_entry->ipstr));
+	slist_insert_tail(&addr_entry->entry, addr_list);
+
+	addr_entry = calloc(1, sizeof(struct sock_host_list_entry));
+	if (!addr_entry)
+		return;
+
+	addr_entry->ipaddr.sin6.sin6_family = AF_INET6;
+	addr_entry->ipaddr.sin6.sin6_addr = in6addr_loopback;
+	ofi_straddr_log(&sock_prov, FI_LOG_INFO, FI_LOG_CORE,
+			"available addr: ", &addr_entry->ipaddr);
+
+	strncpy(addr_entry->ipstr, "::1", sizeof(addr_entry->ipstr));
 	slist_insert_tail(&addr_entry->entry, addr_list);
 }
 
@@ -531,7 +557,7 @@ void sock_get_list_of_addr(struct slist *addr_list)
 	struct sock_host_list_entry *addr_entry;
 	struct ifaddrs *ifaddrs, *ifa;
 
-	fi_param_get_str(&sock_prov, "interface_name", &sock_interface_name);
+	fi_param_get_str(&sock_prov, "iface", &sock_interface_name);
 
 	ret = ofi_getifaddrs(&ifaddrs);
 	if (!ret) {
@@ -550,9 +576,11 @@ void sock_get_list_of_addr(struct slist *addr_list)
 			}
 		}
 		for (ifa = ifaddrs; ifa != NULL; ifa = ifa->ifa_next) {
-			if (ifa->ifa_addr == NULL || !(ifa->ifa_flags & IFF_UP) ||
-			     (ifa->ifa_addr->sa_family != AF_INET) ||
-			     !strcmp(ifa->ifa_name, "lo"))
+			if (ifa->ifa_addr == NULL ||
+			    !(ifa->ifa_flags & IFF_UP) ||
+			    (ifa->ifa_flags & IFF_LOOPBACK) ||
+			    ((ifa->ifa_addr->sa_family != AF_INET) &&
+			     (ifa->ifa_addr->sa_family != AF_INET6)))
 				continue;
 			if (sock_interface_name &&
 			    strncmp(sock_interface_name, ifa->ifa_name,
@@ -560,14 +588,21 @@ void sock_get_list_of_addr(struct slist *addr_list)
 				SOCK_LOG_DBG("Skip (%s) interface\n", ifa->ifa_name);
 				continue;
 			}
+
 			addr_entry = calloc(1, sizeof(struct sock_host_list_entry));
 			if (!addr_entry)
 				continue;
-			ret = getnameinfo(ifa->ifa_addr, sizeof(struct sockaddr_in),
-					  addr_entry->hostname, sizeof(addr_entry->hostname),
-					  NULL, 0, NI_NUMERICHOST);
-			if (ret) {
-				SOCK_LOG_DBG("getnameinfo failed: %d\n", ret);
+
+			memcpy(&addr_entry->ipaddr, ifa->ifa_addr,
+			       ofi_sizeofaddr(ifa->ifa_addr));
+			ofi_straddr_log(&sock_prov, FI_LOG_INFO, FI_LOG_CORE,
+					"available addr: ", ifa->ifa_addr);
+
+			if (!inet_ntop(ifa->ifa_addr->sa_family,
+					ofi_get_ipaddr(ifa->ifa_addr),
+					addr_entry->ipstr,
+					sizeof(addr_entry->ipstr))) {
+				SOCK_LOG_DBG("inet_ntop failed: %d\n", errno);
 				free(addr_entry);
 				continue;
 			}
@@ -581,8 +616,48 @@ void sock_get_list_of_addr(struct slist *addr_list)
 #elif defined HAVE_MIB_IPADDRTABLE
 void sock_get_list_of_addr(struct slist *addr_list)
 {
-	sock_get_ip_addr_table(addr_list);
+	struct sock_host_list_entry *addr_entry;
+	DWORD i;
+	MIB_IPADDRTABLE _iptbl;
+	MIB_IPADDRTABLE *iptbl = &_iptbl;
+	ULONG ips = 1;
+	ULONG res;
+
+	res = GetIpAddrTable(iptbl, &ips, 0);
+	if (res == ERROR_INSUFFICIENT_BUFFER) {
+		iptbl = malloc(ips);
+		if (!iptbl)
+			return;
+
+		res = GetIpAddrTable(iptbl, &ips, 0);
+	}
+
+	if (res != NO_ERROR)
+		goto out;
+
+	for (i = 0; i < iptbl->dwNumEntries; i++) {
+		if (iptbl->table[i].dwAddr &&
+		    (iptbl->table[i].dwAddr != ntohl(INADDR_LOOPBACK))) {
+			addr_entry = calloc(1, sizeof(*addr_entry));
+			if (!addr_entry)
+				break;
+
+			addr_entry->ipaddr.sin.sin_family = AF_INET;
+			addr_entry->ipaddr.sin.sin_addr.s_addr =
+						iptbl->table[i].dwAddr;
+			inet_ntop(AF_INET, &iptbl->table[i].dwAddr,
+				  addr_entry->ipstr,
+				  sizeof(addr_entry->ipstr));
+			slist_insert_tail(&addr_entry->entry, addr_list);
+		}
+	}
+
+	// Always add loopback address at the end
 	sock_insert_loopback_addr(addr_list);
+
+out:
+	if (iptbl != &_iptbl)
+		free(iptbl);
 }
 #else
 void sock_get_list_of_addr(struct slist *addr_list)
@@ -591,6 +666,14 @@ void sock_get_list_of_addr(struct slist *addr_list)
 }
 #endif
 
+static void sock_init_addrlist(void)
+{
+	fastlock_acquire(&sock_list_lock);
+	if (slist_empty(&sock_addr_list))
+		sock_get_list_of_addr(&sock_addr_list);
+	fastlock_release(&sock_list_lock);
+}
+
 int sock_node_getinfo(uint32_t version, const char *node, const char *service,
 		      uint64_t flags, const struct fi_info *hints, struct fi_info **info,
 		      struct fi_info **tail)
@@ -655,28 +738,26 @@ static int sock_match_src_addr(struct slist_entry *entry, const void *src_addr)
 	struct sock_host_list_entry *host_entry;
 	host_entry = container_of(entry, struct sock_host_list_entry, entry);
 
-        return (strcmp(host_entry->hostname, (char *) src_addr) == 0);
+        return ofi_equals_ipaddr(&host_entry->ipaddr.sa, src_addr);
 }
 
-static int sock_addr_matches_interface(struct slist *addr_list, struct sockaddr_in *src_addr)
+static int sock_addr_matches_interface(struct slist *addr_list,
+				       struct sockaddr *src_addr)
 {
 	struct slist_entry *entry;
 
 	/* Always match if it's localhost */
-	if (ofi_is_loopback_addr((struct sockaddr *)src_addr))
+	if (ofi_is_loopback_addr(src_addr))
 		return 1;
 
-	entry = slist_find_first_match(addr_list, sock_match_src_addr,
-					inet_ntoa(src_addr->sin_addr));
-
+	entry = slist_find_first_match(addr_list, sock_match_src_addr, src_addr);
 	return entry ? 1 : 0;
 }
 
 static int sock_node_matches_interface(struct slist *addr_list, const char *node)
 {
-	struct sockaddr_in addr = { 0 };
+	union ofi_sock_ip addr;
 	struct addrinfo *rai = NULL, ai = {
-		.ai_family = AF_INET,
 		.ai_socktype = SOCK_STREAM,
 	};
 
@@ -684,10 +765,16 @@ static int sock_node_matches_interface(struct slist *addr_list, const char *node
 		SOCK_LOG_DBG("getaddrinfo failed!\n");
 		return -FI_EINVAL;
 	}
-	addr = *(struct sockaddr_in *)rai->ai_addr;
+	if (rai->ai_addrlen > sizeof(addr)) {
+		freeaddrinfo(rai);
+		return -FI_EINVAL;
+	}
+
+	memset(&addr, 0, sizeof addr);
+	memcpy(&addr, rai->ai_addr, rai->ai_addrlen);
 	freeaddrinfo(rai);
 
-	return sock_addr_matches_interface(addr_list, &addr);
+	return sock_addr_matches_interface(addr_list, &addr.sa);
 }
 
 static void sock_free_addr_list(struct slist *addr_list)
@@ -713,12 +800,12 @@ static int sock_getinfo(uint32_t version, const char *node, const char *service,
 	struct fi_info *tail;
 
 	if (!(flags & FI_SOURCE) && hints && hints->src_addr &&
-	    (hints->src_addrlen != sizeof(struct sockaddr_in)))
+	    (hints->src_addrlen != ofi_sizeofaddr(hints->src_addr)))
 		return -FI_ENODATA;
 
 	if (((!node && !service) || (flags & FI_SOURCE)) &&
 	    hints && hints->dest_addr &&
-	    (hints->dest_addrlen != sizeof(struct sockaddr_in)))
+	    (hints->dest_addrlen != ofi_sizeofaddr(hints->dest_addr)))
 		return -FI_ENODATA;
 
 	ret = sock_verify_info(version, hints);
@@ -726,11 +813,12 @@ static int sock_getinfo(uint32_t version, const char *node, const char *service,
 		return ret;
 
 	ret = 1;
+	sock_init_addrlist();
 	if ((flags & FI_SOURCE) && node) {
 		ret = sock_node_matches_interface(&sock_addr_list, node);
 	} else if (hints && hints->src_addr) {
 		ret = sock_addr_matches_interface(&sock_addr_list,
-						  (struct sockaddr_in *)hints->src_addr);
+						  hints->src_addr);
 	}
 	if (!ret) {
 		SOCK_LOG_ERROR("Couldn't find a match with local interfaces\n");
@@ -747,7 +835,7 @@ static int sock_getinfo(uint32_t version, const char *node, const char *service,
 	(void) prev; /* Makes compiler happy */
 	slist_foreach(&sock_addr_list, entry, prev) {
 		host_entry = container_of(entry, struct sock_host_list_entry, entry);
-		node = host_entry->hostname;
+		node = host_entry->ipstr;
 		flags |= FI_SOURCE;
 		ret = sock_node_getinfo(version, node, service, flags, hints, info, &tail);
 		if (ret) {
@@ -769,7 +857,7 @@ static void fi_sockets_fini(void)
 struct fi_provider sock_prov = {
 	.name = sock_prov_name,
 	.version = FI_VERSION(SOCK_MAJOR_VERSION, SOCK_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = sock_getinfo,
 	.fabric = sock_fabric,
 	.cleanup = fi_sockets_fini
@@ -784,6 +872,9 @@ SOCKETS_INI
 	fi_param_define(&sock_prov, "pe_waittime", FI_PARAM_INT,
 			"How many milliseconds to spin while waiting for progress");
 
+	fi_param_define(&sock_prov, "conn_timeout", FI_PARAM_INT,
+			"How many milliseconds to wait for one connection establishment");
+
 	fi_param_define(&sock_prov, "max_conn_retry", FI_PARAM_INT,
 			"Number of connection retries before reporting as failure");
 
@@ -815,7 +906,7 @@ SOCKETS_INI
 	fi_param_define(&sock_prov, "keepalive_probes", FI_PARAM_INT,
 			"Maximum number of keepalive probes sent before dropping the connection");
 
-	fi_param_define(&sock_prov, "interface_name", FI_PARAM_STRING,
+	fi_param_define(&sock_prov, "iface", FI_PARAM_STRING,
 			"Specify interface name");
 
 	fastlock_init(&sock_list_lock);
@@ -826,8 +917,6 @@ SOCKETS_INI
 	SOCK_EP_RDM_CAP |= OFI_RMA_PMEM;
 	SOCK_EP_MSG_SEC_CAP |= OFI_RMA_PMEM;
 	SOCK_EP_MSG_CAP |= OFI_RMA_PMEM;
-	/* Returns loopback address if no other interfaces are available */
-	sock_get_list_of_addr(&sock_addr_list);
 #if ENABLE_DEBUG
 	fi_param_define(&sock_prov, "dgram_drop_rate", FI_PARAM_INT,
 			"Drop every Nth dgram frame (debug only)");
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_msg.c
index 2e69d7672..0d09300b8 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_msg.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_msg.c
@@ -262,8 +262,9 @@ ssize_t sock_ep_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
 	}
 
 	sock_tx_ctx_write_op_send(tx_ctx, &tx_op, flags, (uintptr_t) msg->context,
-			msg->addr, (uintptr_t) msg->msg_iov[0].iov_base,
-			ep_attr, conn);
+				  msg->addr, (uintptr_t) ((msg->iov_count > 0) ?
+				  msg->msg_iov[0].iov_base : NULL),
+				  ep_attr, conn);
 
 	if (flags & FI_REMOTE_CQ_DATA)
 		sock_tx_ctx_write(tx_ctx, &msg->data, sizeof(msg->data));
@@ -605,9 +606,10 @@ ssize_t sock_ep_tsendmsg(struct fid_ep *ep,
 	}
 
 	sock_tx_ctx_write_op_tsend(tx_ctx, &tx_op, flags,
-			(uintptr_t) msg->context, msg->addr,
-			(uintptr_t) msg->msg_iov[0].iov_base,
-			ep_attr, conn, msg->tag);
+				   (uintptr_t) msg->context, msg->addr,
+				   (uintptr_t) ((msg->iov_count > 0) ?
+				    msg->msg_iov[0].iov_base : NULL),
+				    ep_attr, conn, msg->tag);
 
 	if (flags & FI_REMOTE_CQ_DATA)
 		sock_tx_ctx_write(tx_ctx, &msg->data, sizeof(msg->data));
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_progress.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_progress.c
index 19d046fa4..bab5c3cac 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_progress.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/sockets/src/sock_progress.c
@@ -867,7 +867,8 @@ static void sock_pe_do_atomic(void *cmp, void *dst, void *src,
 	if (op >= OFI_SWAP_OP_START) {
 		ofi_atomic_swap_handlers[op - OFI_SWAP_OP_START][datatype](dst,
 			src, cmp, tmp_result, cnt);
-		memcpy(cmp, tmp_result, ofi_datatype_size(datatype) * cnt);
+                if (cmp != NULL)
+			memcpy(cmp, tmp_result, ofi_datatype_size(datatype) * cnt);
 	} else if (fetch) {
 		ofi_atomic_readwrite_handlers[op][datatype](dst, src,
 			cmp /*results*/, cnt);
@@ -1450,32 +1451,25 @@ static int sock_pe_process_rx_conn_msg(struct sock_pe *pe,
 	uint64_t len, data_len;
 	struct sock_ep_attr *ep_attr;
 	struct sock_conn_map *map;
-	struct sockaddr_in *addr;
+	union ofi_sock_ip *addr;
 	struct sock_conn *conn;
 	uint64_t index;
 
 	if (!pe_entry->comm_addr) {
-		pe_entry->comm_addr = calloc(1, sizeof(struct sockaddr_in));
+		pe_entry->comm_addr = calloc(1, sizeof(union ofi_sock_ip));
 		if (!pe_entry->comm_addr)
 			return -FI_ENOMEM;
 	}
 
 	len = sizeof(struct sock_msg_hdr);
-	data_len = sizeof(struct sockaddr_in);
+	data_len = sizeof(union ofi_sock_ip);
 	if (sock_pe_recv_field(pe_entry, pe_entry->comm_addr, data_len, len)) {
 		return 0;
 	}
 
-	SOCK_LOG_DBG("got conn msg from %s:%d\n",
-		inet_ntoa(((struct sockaddr_in *)&pe_entry->conn->addr)->sin_addr),
-		ntohs(((struct sockaddr_in *)&pe_entry->conn->addr)->sin_port));
-	SOCK_LOG_DBG("on behalf of %s:%d\n",
-		inet_ntoa(((struct sockaddr_in *)pe_entry->comm_addr)->sin_addr),
-		ntohs(((struct sockaddr_in *)pe_entry->comm_addr)->sin_port));
-
 	ep_attr = pe_entry->conn->ep_attr;
 	map = &ep_attr->cmap;
-	addr = (struct sockaddr_in *) pe_entry->comm_addr;
+	addr = pe_entry->comm_addr;
 	pe_entry->conn->addr = *addr;
 
 	index = (ep_attr->ep_type == FI_EP_MSG) ? 0 : sock_av_get_addr_index(ep_attr->av, addr);
@@ -2283,7 +2277,7 @@ void sock_pe_signal(struct sock_pe *pe)
 void sock_pe_poll_add(struct sock_pe *pe, int fd)
 {
         fastlock_acquire(&pe->signal_lock);
-        if (fi_epoll_add(pe->epoll_set, fd, NULL))
+        if (fi_epoll_add(pe->epoll_set, fd, FI_EPOLL_IN, NULL))
 			SOCK_LOG_ERROR("failed to add to epoll set: %d\n", fd);
         fastlock_release(&pe->signal_lock);
 }
@@ -2731,7 +2725,8 @@ struct sock_pe *sock_pe_init(struct sock_domain *domain)
 
 		if (fd_set_nonblock(pe->signal_fds[SOCK_SIGNAL_RD_FD]) ||
 		    fi_epoll_add(pe->epoll_set,
-				 pe->signal_fds[SOCK_SIGNAL_RD_FD], NULL))
+				 pe->signal_fds[SOCK_SIGNAL_RD_FD],
+				 FI_EPOLL_IN, NULL))
 			goto err5;
 
 		pe->do_progress = 1;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/Makefile.include
index 7965a64b1..983ee13e6 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/Makefile.include
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/Makefile.include
@@ -4,8 +4,11 @@ _tcp_files = \
 	prov/tcp/src/tcpx_attr.c	\
 	prov/tcp/src/tcpx_conn_mgr.c	\
 	prov/tcp/src/tcpx_domain.c	\
+	prov/tcp/src/tcpx_rma.c		\
 	prov/tcp/src/tcpx_ep.c		\
+	prov/tcp/src/tcpx_shared_ctx.c	\
 	prov/tcp/src/tcpx_cq.c		\
+	prov/tcp/src/tcpx_eq.c		\
 	prov/tcp/src/tcpx_init.c	\
 	prov/tcp/src/tcpx_progress.c	\
 	prov/tcp/src/tcpx_comm.c	\
@@ -22,8 +25,8 @@ src_libfabric_la_SOURCES += $(_tcp_files)
 src_libfabric_la_LIBADD += $(tcp_shm_LIBS)
 endif !HAVE_TCP_DL
 
-#prov_install_man_pages += man/man7/fi_tcp.7
+prov_install_man_pages += man/man7/fi_tcp.7
 
 endif HAVE_TCP
 
-#prov_dist_man_pages += man/man7/fi_tcp.7
+prov_dist_man_pages += man/man7/fi_tcp.7
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx.h
index 4148c7f39..67159f887 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx.h
@@ -65,116 +65,49 @@
 #define TCPX_MAJOR_VERSION 0
 #define TCPX_MINOR_VERSION 1
 
-
-extern struct fi_provider	tcpx_prov;
-extern struct util_prov		tcpx_util_prov;
-extern struct fi_info		tcpx_info;
-struct tcpx_fabric;
-struct tcpx_domain;
-struct tcpx_pe_entry;
-struct tcpx_progress;
-struct tcpx_ep;
-struct tcpx_op_send;
-
-#define TCPX_NO_COMPLETION	(1ULL << 63)
-
-#define POLL_MGR_FREE		(1 << 0)
-#define POLL_MGR_DEL		(1 << 1)
-#define POLL_MGR_ACK		(1 << 2)
-
 #define TCPX_MAX_CM_DATA_SIZE	(1<<8)
-#define TCPX_PE_COMM_BUFF_SZ	(1<<10)
-#define TCPX_MAX_SOCK_REQS	(1<<10)
-#define TCPX_PE_MAX_ENTRIES	(128)
 #define TCPX_IOV_LIMIT		(4)
 #define TCPX_MAX_INJECT_SZ	(64)
-#define TCPX_MAX_EPOLL_EVENTS	(100)
-#define TCPX_MAX_EP_RB_SIZE     (1024*sizeof(struct tcpx_op_send))
-
-int tcpx_create_fabric(struct fi_fabric_attr *attr,
-		       struct fid_fabric **fabric,
-		       void *context);
-
-int tcpx_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
-		    struct fid_pep **pep, void *context);
-
-int tcpx_domain_open(struct fid_fabric *fabric, struct fi_info *info,
-		     struct fid_domain **domain, void *context);
-
-
-int tcpx_endpoint(struct fid_domain *domain, struct fi_info *info,
-		  struct fid_ep **ep_fid, void *context);
 
+#define MAX_EPOLL_EVENTS	100
+#define STAGE_BUF_SIZE		512
 
-int tcpx_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
-		 struct fid_cq **cq_fid, void *context);
-
-int tcpx_conn_mgr_init(struct tcpx_fabric *tcpx_fabric);
-void tcpx_conn_mgr_close(struct tcpx_fabric *tcpx_fabric);
-int tcpx_recv_msg(struct tcpx_pe_entry *pe_entry);
-int tcpx_send_msg(struct tcpx_pe_entry *pe_entry);
-void posted_rx_find(struct tcpx_pe_entry *pe_entry);
-int tcpx_progress_init(struct tcpx_progress *progress);
-int tcpx_progress_close(struct tcpx_progress *progress);
-struct tcpx_pe_entry *pe_entry_alloc(struct tcpx_progress *progress);
-void pe_entry_release(struct tcpx_pe_entry *pe_entry);
-void tcpx_progress(struct util_ep *util_ep);
-
-enum tcpx_xfer_states {
-	TCPX_XFER_IDLE,
-	TCPX_XFER_STARTED,
-	TCPX_XFER_HDR_SENT,
-	TCPX_XFER_FLUSH_COMM_BUF,
-	TCPX_XFER_HDR_RECVD,
-	TCPX_XFER_COMPLETE,
-};
+extern struct fi_provider	tcpx_prov;
+extern struct util_prov		tcpx_util_prov;
+extern struct fi_info		tcpx_info;
+struct tcpx_xfer_entry;
+struct tcpx_ep;
 
 enum tcpx_xfer_op_codes {
 	TCPX_OP_MSG_SEND,
 	TCPX_OP_MSG_RECV,
+	TCPX_OP_MSG_RESP,
+	TCPX_OP_WRITE,
+	TCPX_OP_REMOTE_WRITE,
+	TCPX_OP_READ_REQ,
+	TCPX_OP_READ_RSP,
+	TCPX_OP_REMOTE_READ,
+	TCPX_OP_CODE_MAX,
 };
 
-enum tcpx_xfer_field {
-	TCPX_MSG_HDR_FIELD,
-	TCPX_DATA_FIELD,
+enum tcpx_cm_event_type {
+	SERVER_SOCK_ACCEPT,
+	CLIENT_SEND_CONNREQ,
+	SERVER_RECV_CONNREQ,
+	SERVER_SEND_CM_ACCEPT,
+	CLIENT_RECV_CONNRESP,
 };
 
-enum poll_fd_type {
-	CONNECT_SOCK,
-	PASSIVE_SOCK,
-	ACCEPT_SOCK,
-};
-
-enum poll_fd_state {
-	ESTABLISH_CONN,
-	RCV_RESP,
-	CONNECT_DONE,
-};
-
-struct poll_fd_info {
+struct tcpx_cm_context {
 	fid_t			fid;
-	struct dlist_entry	entry;
-	int			flags;
-	enum poll_fd_type	type;
-	enum poll_fd_state	state;
+	enum tcpx_cm_event_type	type;
 	size_t			cm_data_sz;
 	char			cm_data[TCPX_MAX_CM_DATA_SIZE];
 };
 
-struct poll_fd_mgr {
-	struct fd_signal	signal;
-	struct dlist_entry	list;
-	fastlock_t		lock;
-	int			run;
-
-	struct pollfd		*poll_fds;
-	struct poll_fd_info	*poll_info;
-	int			nfds;
-	int			max_nfds;
-};
-
 struct tcpx_conn_handle {
 	struct fid		handle;
+	struct tcpx_pep		*pep;
 	SOCKET			conn_fd;
 };
 
@@ -182,50 +115,153 @@ struct tcpx_pep {
 	struct util_pep 	util_pep;
 	struct fi_info		info;
 	SOCKET			sock;
-	struct poll_fd_info	poll_info;
+	struct tcpx_cm_context	cm_ctx;
+};
+
+enum tcpx_cm_state {
+	TCPX_EP_CONNECTING,
+	TCPX_EP_CONNECTED,
+	TCPX_EP_SHUTDOWN,
+	TCPX_EP_ERROR,
+};
+
+struct tcpx_msg_hdr {
+	struct ofi_op_hdr	hdr;
+	size_t			rma_iov_cnt;
+	union {
+		struct fi_rma_iov	rma_iov[TCPX_IOV_LIMIT];
+		struct fi_rma_ioc	rma_ioc[TCPX_IOV_LIMIT];
+	};
+};
+
+struct tcpx_rx_detect {
+	struct tcpx_msg_hdr	hdr;
+	uint64_t		done_len;
+};
+
+struct tcpx_rx_ctx {
+	struct fid_ep		rx_fid;
+	struct slist		rx_queue;
+	struct util_buf_pool	*buf_pool;
+	fastlock_t		lock;
+};
+
+typedef int (*tcpx_rx_process_fn_t)(struct tcpx_xfer_entry *rx_entry);
+typedef void (*tcpx_ep_progress_func_t)(struct tcpx_ep *ep);
+typedef int (*tcpx_get_rx_func_t)(struct tcpx_ep *ep);
+
+struct stage_buf {
+	uint8_t			buf[STAGE_BUF_SIZE];
+	size_t			size;
+	size_t			len;
+	size_t			off;
 };
 
 struct tcpx_ep {
 	struct util_ep		util_ep;
 	SOCKET			conn_fd;
+	struct tcpx_rx_detect	rx_detect;
+	struct tcpx_xfer_entry	*cur_rx_entry;
+	tcpx_rx_process_fn_t 	cur_rx_proc_fn;
 	struct dlist_entry	ep_entry;
-	struct dlist_entry	rx_queue;
-	struct dlist_entry	tx_queue;
+	struct slist		rx_queue;
+	struct slist		tx_queue;
+	struct slist		tx_rsp_pend_queue;
+	struct slist		rma_read_queue;
+	struct tcpx_rx_ctx	*srx_ctx;
+	enum tcpx_cm_state	cm_state;
+	/* lock for protecting tx/rx queues,rma list,cm_state*/
+	fastlock_t		lock;
+	tcpx_ep_progress_func_t progress_func;
+	tcpx_get_rx_func_t	get_rx_entry[ofi_op_write + 1];
+	struct stage_buf	stage_buf;
+	bool			send_ready_monitor;
 };
 
 struct tcpx_fabric {
 	struct util_fabric	util_fabric;
-	struct poll_fd_mgr	poll_mgr;
-	pthread_t		conn_mgr_thread;
 };
 
 struct tcpx_msg_data {
-	size_t		iov_cnt;
-	union {
-		struct iovec		iov[TCPX_IOV_LIMIT+1];
-		struct fi_rma_iov	rma_iov[TCPX_IOV_LIMIT+1];
-		struct fi_rma_ioc	ram_ioc[TCPX_IOV_LIMIT+1];
-	};
+	size_t			iov_cnt;
+	struct iovec		iov[TCPX_IOV_LIMIT+1];
 	uint8_t			inject[TCPX_MAX_INJECT_SZ];
 };
 
-struct tcpx_pe_entry {
-	struct ofi_op_hdr	msg_hdr;
+struct tcpx_xfer_entry {
+	struct slist_entry	entry;
+	struct tcpx_msg_hdr	msg_hdr;
 	struct tcpx_msg_data	msg_data;
-	struct dlist_entry	entry;
 	struct tcpx_ep		*ep;
 	uint64_t		flags;
 	void			*context;
 	uint64_t		done_len;
 };
 
-struct tcpx_progress {
-	struct util_buf_pool	*pe_entry_pool;
-};
-
 struct tcpx_domain {
 	struct util_domain	util_domain;
-	struct tcpx_progress	progress;
 };
 
+struct tcpx_buf_pool {
+	struct util_buf_pool	*pool;
+	enum tcpx_xfer_op_codes	op_type;
+};
+
+struct tcpx_cq {
+	struct util_cq		util_cq;
+	/* buf_pools protected by util.cq_lock */
+	struct tcpx_buf_pool	buf_pools[TCPX_OP_CODE_MAX];
+};
+
+int tcpx_create_fabric(struct fi_fabric_attr *attr,
+		       struct fid_fabric **fabric,
+		       void *context);
+
+int tcpx_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
+		    struct fid_pep **pep, void *context);
+
+int tcpx_domain_open(struct fid_fabric *fabric, struct fi_info *info,
+		     struct fid_domain **domain, void *context);
+
+
+int tcpx_endpoint(struct fid_domain *domain, struct fi_info *info,
+		  struct fid_ep **ep_fid, void *context);
+
+
+int tcpx_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
+		 struct fid_cq **cq_fid, void *context);
+void tcpx_cq_report_completion(struct util_cq *cq,
+			       struct tcpx_xfer_entry *xfer_entry,
+			       int err);
+
+int tcpx_recv_msg_data(struct tcpx_xfer_entry *recv_entry);
+int tcpx_send_msg(struct tcpx_xfer_entry *tx_entry);
+int tcpx_recv_hdr(SOCKET sock, struct stage_buf *sbuf,
+		  struct tcpx_rx_detect *rx_detect);
+int tcpx_read_to_buffer(SOCKET sock, struct stage_buf *stage_buf);
+
+struct tcpx_xfer_entry *tcpx_xfer_entry_alloc(struct tcpx_cq *cq,
+					      enum tcpx_xfer_op_codes type);
+void tcpx_xfer_entry_release(struct tcpx_cq *tcpx_cq,
+			     struct tcpx_xfer_entry *xfer_entry);
+
+void tcpx_progress(struct util_ep *util_ep);
+void tcpx_ep_progress(struct tcpx_ep *ep);
+int tcpx_ep_shutdown_report(struct tcpx_ep *ep, fid_t fid);
+int tcpx_cq_wait_ep_add(struct tcpx_ep *ep);
+void tcpx_cq_wait_ep_del(struct tcpx_ep *ep);
+void tcpx_tx_queue_insert(struct tcpx_ep *tcpx_ep,
+			  struct tcpx_xfer_entry *tx_entry);
+
+void tcpx_conn_mgr_run(struct util_eq *eq);
+int tcpx_eq_wait_try_func(void *arg);
+int tcpx_eq_create(struct fid_fabric *fabric_fid, struct fi_eq_attr *attr,
+		   struct fid_eq **eq_fid, void *context);
+
+int tcpx_get_rx_entry_op_invalid(struct tcpx_ep *tcpx_ep);
+int tcpx_get_rx_entry_op_msg(struct tcpx_ep *tcpx_ep);
+int tcpx_get_rx_entry_op_read_req(struct tcpx_ep *tcpx_ep);
+int tcpx_get_rx_entry_op_write(struct tcpx_ep *tcpx_ep);
+int tcpx_get_rx_entry_op_read_rsp(struct tcpx_ep *tcpx_ep);
+
 #endif //_TCP_H_
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_attr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_attr.c
index 596e80699..ceecac7b8 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_attr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_attr.c
@@ -33,17 +33,31 @@
 #include "tcpx.h"
 
 
+#define TCPX_DOMAIN_CAPS (FI_LOCAL_COMM | FI_REMOTE_COMM)
+#define TCPX_EP_CAPS	 (FI_MSG | FI_RMA | FI_RMA_PMEM)
+#define TCPX_TX_CAPS	 (FI_SEND | FI_WRITE | FI_READ)
+#define TCPX_RX_CAPS	 (FI_RECV | FI_REMOTE_READ | FI_REMOTE_WRITE)
+
+
+#define TCPX_MSG_ORDER (FI_ORDER_RAR | FI_ORDER_RAW | FI_ORDER_RAS |	\
+			FI_ORDER_WAW | FI_ORDER_WAS |			\
+			FI_ORDER_SAW | FI_ORDER_SAS)
+
+
 static struct fi_tx_attr tcpx_tx_attr = {
-	.caps = FI_MSG | FI_SEND,
+	.caps = TCPX_EP_CAPS | TCPX_TX_CAPS,
 	.comp_order = FI_ORDER_STRICT,
+	.msg_order = TCPX_MSG_ORDER,
 	.inject_size = 64,
 	.size = 1024,
-	.iov_limit = TCPX_IOV_LIMIT
+	.iov_limit = TCPX_IOV_LIMIT,
+	.rma_iov_limit = TCPX_IOV_LIMIT,
 };
 
 static struct fi_rx_attr tcpx_rx_attr = {
-	.caps = FI_MSG | FI_RECV,
+	.caps = TCPX_EP_CAPS | TCPX_RX_CAPS,
 	.comp_order = FI_ORDER_STRICT,
+	.msg_order = TCPX_MSG_ORDER,
 	.total_buffered_recv = 0,
 	.size = 1024,
 	.iov_limit = TCPX_IOV_LIMIT
@@ -55,21 +69,27 @@ static struct fi_ep_attr tcpx_ep_attr = {
 	.protocol_version = 0,
 	.max_msg_size = SIZE_MAX,
 	.tx_ctx_cnt = 1,
-	.rx_ctx_cnt = 1
+	.rx_ctx_cnt = 1,
+	.max_order_raw_size = SIZE_MAX,
+	.max_order_waw_size = SIZE_MAX,
 };
 
 static struct fi_domain_attr tcpx_domain_attr = {
 	.name = "tcp",
+	.caps = TCPX_DOMAIN_CAPS,
 	.threading = FI_THREAD_SAFE,
 	.control_progress = FI_PROGRESS_AUTO,
 	.data_progress = FI_PROGRESS_AUTO,
 	.resource_mgmt = FI_RM_ENABLED,
+	.mr_mode = FI_MR_SCALABLE | FI_MR_BASIC,
+	.mr_key_size = sizeof(uint64_t),
 	.av_type = FI_AV_UNSPEC,
-	.mr_mode = 0,
+	.cq_data_size = sizeof(uint64_t),
 	.cq_cnt = 256,
 	.ep_cnt = 8192,
 	.tx_ctx_cnt = 8192,
 	.rx_ctx_cnt = 8192,
+	.max_ep_srx_ctx = 128,
 	.max_ep_tx_ctx = 1,
 	.max_ep_rx_ctx = 1
 };
@@ -80,7 +100,7 @@ static struct fi_fabric_attr tcpx_fabric_attr = {
 };
 
 struct fi_info tcpx_info = {
-	.caps = FI_MSG | FI_SEND | FI_RECV,
+	.caps = TCPX_DOMAIN_CAPS | TCPX_EP_CAPS | TCPX_TX_CAPS | TCPX_RX_CAPS,
 	.addr_format = FI_SOCKADDR,
 	.tx_attr = &tcpx_tx_attr,
 	.rx_attr = &tcpx_rx_attr,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_comm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_comm.c
index ce10666db..19eb3a1e5 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_comm.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_comm.c
@@ -37,76 +37,125 @@
 #include <ofi_iov.h>
 #include "tcpx.h"
 
-int tcpx_send_msg(struct tcpx_pe_entry *pe_entry)
+int tcpx_send_msg(struct tcpx_xfer_entry *tx_entry)
 {
 	ssize_t bytes_sent;
+	struct msghdr msg = {0};
 
-	bytes_sent = ofi_writev_socket(pe_entry->ep->conn_fd,
-				       pe_entry->msg_data.iov,
-				       pe_entry->msg_data.iov_cnt);
+	msg.msg_iov = tx_entry->msg_data.iov;
+	msg.msg_iovlen = tx_entry->msg_data.iov_cnt;
+
+	bytes_sent = ofi_sendmsg_tcp(tx_entry->ep->conn_fd,
+	                             &msg, MSG_NOSIGNAL);
 	if (bytes_sent < 0)
-		return -errno;
+		return ofi_sockerr() == EPIPE ? -FI_ENOTCONN : -ofi_sockerr();
 
-	if (pe_entry->done_len < ntohll(pe_entry->msg_hdr.size)) {
-		ofi_consume_iov(pe_entry->msg_data.iov,
-				&pe_entry->msg_data.iov_cnt,
+	tx_entry->done_len += bytes_sent;
+	if (tx_entry->done_len < ntohll(tx_entry->msg_hdr.hdr.size)) {
+		ofi_consume_iov(tx_entry->msg_data.iov,
+				&tx_entry->msg_data.iov_cnt,
 				bytes_sent);
+		return -FI_EAGAIN;
 	}
-
-	pe_entry->done_len += bytes_sent;
 	return FI_SUCCESS;
 }
 
-static int tcpx_recv_msg_hdr(struct tcpx_pe_entry *pe_entry)
+static ssize_t tcpx_read_from_buffer(struct stage_buf *sbuf,
+				     uint8_t *buf, size_t len)
+{
+	size_t rem_size;
+	ssize_t ret;
+
+	assert(sbuf->len >= sbuf->off);
+	rem_size = sbuf->len - sbuf->off;
+	assert(rem_size);
+	ret = (rem_size >= len)? len : rem_size;
+	memcpy(buf, &sbuf->buf[sbuf->off], ret);
+	sbuf->off += ret;
+	return ret;
+}
+
+int tcpx_recv_hdr(SOCKET sock, struct stage_buf *sbuf,
+		  struct tcpx_rx_detect *rx_detect)
 {
+	void *rem_buf;
+	size_t rem_len;
 	ssize_t bytes_recvd;
-	void *rem_hdr_buf;
-	size_t rem_hdr_len;
 
-	rem_hdr_buf = (uint8_t *)&pe_entry->msg_hdr + pe_entry->done_len;
-	rem_hdr_len = sizeof(pe_entry->msg_hdr) - pe_entry->done_len;
+	rem_buf = (uint8_t *) &rx_detect->hdr + rx_detect->done_len;
+	rem_len = sizeof(rx_detect->hdr) - rx_detect->done_len;
 
-	bytes_recvd = ofi_recv_socket(pe_entry->ep->conn_fd,
-				      rem_hdr_buf, rem_hdr_len, 0);
+	if (sbuf->len != sbuf->off) {
+		bytes_recvd = tcpx_read_from_buffer(sbuf, rem_buf, rem_len);
+	} else {
+		bytes_recvd = ofi_recv_socket(sock, rem_buf, rem_len, 0);
+	}
 	if (bytes_recvd <= 0)
-		return (bytes_recvd)? -errno: -FI_ENOTCONN;
-
-	pe_entry->done_len += bytes_recvd;
+		return (bytes_recvd)? -ofi_sockerr(): -FI_ENOTCONN;
 
-	if (pe_entry->done_len < sizeof(pe_entry->msg_hdr))
-		return -FI_EAGAIN;
+	rx_detect->done_len += bytes_recvd;
+	return (rem_len == bytes_recvd)? FI_SUCCESS : -FI_EAGAIN;
+}
 
-	pe_entry->msg_hdr.op_data = TCPX_OP_MSG_RECV;
-	return ofi_truncate_iov(pe_entry->msg_data.iov,
-				&pe_entry->msg_data.iov_cnt,
-				(ntohll(pe_entry->msg_hdr.size) -
-				 sizeof(pe_entry->msg_hdr)));
+static ssize_t tcpx_readv_from_buffer(struct stage_buf *sbuf,
+				      struct iovec *iov,
+				      int iov_cnt)
+{
+	ssize_t ret = 0;
+	size_t bytes_read;
+	int i;
+
+	if (iov_cnt == 1)
+		return tcpx_read_from_buffer(sbuf, iov[0].iov_base,
+					     iov[0].iov_len);
+
+	for (i = 0; i < iov_cnt; i++) {
+		bytes_read = tcpx_read_from_buffer(sbuf, iov[i].iov_base,
+						   iov[i].iov_len);
+		ret += bytes_read;
+		if ((bytes_read < iov[i].iov_len) ||
+		    !(sbuf->len - sbuf->off))
+			break;
+	}
+	return ret;
 }
 
-int tcpx_recv_msg(struct tcpx_pe_entry *pe_entry)
+int tcpx_recv_msg_data(struct tcpx_xfer_entry *rx_entry)
 {
 	ssize_t bytes_recvd;
-	int ret;
 
-	if (pe_entry->done_len < sizeof(pe_entry->msg_hdr)) {
-		ret = tcpx_recv_msg_hdr(pe_entry);
-		if (ret)
-			return ret;
+	if (rx_entry->ep->stage_buf.len != rx_entry->ep->stage_buf.off) {
+		bytes_recvd = tcpx_readv_from_buffer(&rx_entry->ep->stage_buf,
+						rx_entry->msg_data.iov,
+						rx_entry->msg_data.iov_cnt);
+	 }else {
+		bytes_recvd = ofi_readv_socket(rx_entry->ep->conn_fd,
+					       rx_entry->msg_data.iov,
+					       rx_entry->msg_data.iov_cnt);
 	}
-
-	bytes_recvd = ofi_readv_socket(pe_entry->ep->conn_fd,
-				       pe_entry->msg_data.iov,
-				       pe_entry->msg_data.iov_cnt);
 	if (bytes_recvd <= 0)
-		return (bytes_recvd)? -errno: -FI_ENOTCONN;
-
+		return (bytes_recvd)? -ofi_sockerr(): -FI_ENOTCONN;
 
-	if (pe_entry->done_len < ntohll(pe_entry->msg_hdr.size)) {
-		ofi_consume_iov(pe_entry->msg_data.iov,
-				&pe_entry->msg_data.iov_cnt,
+	rx_entry->done_len += bytes_recvd;
+	if (rx_entry->done_len < ntohll(rx_entry->msg_hdr.hdr.size)) {
+		ofi_consume_iov(rx_entry->msg_data.iov,
+				&rx_entry->msg_data.iov_cnt,
 				bytes_recvd);
+		return -FI_EAGAIN;
 	}
+	return FI_SUCCESS;
+}
+
+int tcpx_read_to_buffer(SOCKET sock, struct stage_buf *stage_buf)
+{
+	int bytes_recvd;
+
+	bytes_recvd = ofi_recv_socket(sock, stage_buf->buf,
+				      stage_buf->size, 0);
+	if (bytes_recvd <= 0)
+		return (bytes_recvd)? -ofi_sockerr(): -FI_ENOTCONN;
 
-	pe_entry->done_len += bytes_recvd;
+	stage_buf->len = bytes_recvd;
+	stage_buf->off = 0;
 	return FI_SUCCESS;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_conn_mgr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_conn_mgr.c
index 54f1349e5..ffe7ea76c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_conn_mgr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_conn_mgr.c
@@ -38,157 +38,31 @@
 #include <sys/types.h>
 #include <ofi_util.h>
 
-static int poll_fd_resize(struct poll_fd_mgr *poll_mgr, int size)
-{
-	struct pollfd *new_poll_fds;
-	struct poll_fd_info *new_poll_info;
-
-	new_poll_fds = calloc(size, sizeof(*new_poll_fds));
-	if (!new_poll_fds)
-		return -FI_ENOMEM;
-
-	new_poll_info = calloc(size, sizeof(*new_poll_info));
-	if (!new_poll_info) {
-		free(new_poll_fds);
-		return -FI_ENOMEM;
-	}
-
-	if (poll_mgr->max_nfds) {
-		memcpy(new_poll_fds, poll_mgr->poll_fds,
-		       poll_mgr->max_nfds * sizeof(*new_poll_fds));
-		free(poll_mgr->poll_fds);
-
-		memcpy(new_poll_info, poll_mgr->poll_info,
-		       poll_mgr->max_nfds * sizeof(*new_poll_info));
-		free(poll_mgr->poll_info);
-	}
-
-	poll_mgr->poll_fds = new_poll_fds;
-	poll_mgr->poll_info = new_poll_info;
-	poll_mgr->max_nfds = size;
-
-	return 0;
-}
-
-static void poll_fds_swap_del_last(struct poll_fd_mgr *poll_mgr, int index)
-{
-	poll_mgr->poll_fds[index] = poll_mgr->poll_fds[(poll_mgr->nfds) - 1];
-	poll_mgr->poll_info[index] = poll_mgr->poll_info[(poll_mgr->nfds) - 1];
-	poll_mgr->nfds--;
-}
-
-static int poll_fds_find_dup(struct poll_fd_mgr *poll_mgr,
-			     struct poll_fd_info *fd_info_entry)
-{
-	struct tcpx_ep *tcpx_ep;
-	struct tcpx_pep *tcpx_pep;
-	int i;
-
-	for (i = 1 ; i < poll_mgr->nfds ; i++) {
-		switch (fd_info_entry->fid->fclass) {
-		case FI_CLASS_EP:
-			tcpx_ep = container_of(fd_info_entry->fid, struct tcpx_ep,
-					       util_ep.ep_fid.fid);
-			if (poll_mgr->poll_fds[i].fd == tcpx_ep->conn_fd)
-				return i;
-			break;
-		case FI_CLASS_PEP:
-			tcpx_pep = container_of(fd_info_entry->fid, struct tcpx_pep,
-						util_pep.pep_fid.fid);
-			if (poll_mgr->poll_fds[i].fd == tcpx_pep->sock)
-				return i;
-			break;
-		default:
-			continue;
-		}
-	}
-	return -1;
-}
 
-static int poll_fds_add_item(struct poll_fd_mgr *poll_mgr,
-			     struct poll_fd_info *poll_info)
+static int read_cm_data(SOCKET fd, struct tcpx_cm_context *cm_ctx,
+			struct ofi_ctrl_hdr *hdr)
 {
-	struct tcpx_ep *tcpx_ep;
-	struct tcpx_pep *tcpx_pep;
-	int ret;
-
-	if (poll_mgr->nfds >= poll_mgr->max_nfds) {
-		ret = poll_fd_resize(poll_mgr, poll_mgr->max_nfds << 1);
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-			"memory allocation failed\n");
-		return ret;
-	}
-
-	poll_mgr->poll_info[poll_mgr->nfds] = *poll_info;
-	poll_mgr->poll_fds[poll_mgr->nfds].revents = 0;
-
-	switch (poll_mgr->poll_info[poll_mgr->nfds].type) {
-	case CONNECT_SOCK:
-	case ACCEPT_SOCK:
-		tcpx_ep = container_of(poll_info->fid, struct tcpx_ep,
-				       util_ep.ep_fid.fid);
-		poll_mgr->poll_fds[poll_mgr->nfds].fd = tcpx_ep->conn_fd;
-		poll_mgr->poll_fds[poll_mgr->nfds].events = POLLOUT;
-		break;
-	case PASSIVE_SOCK:
-		tcpx_pep = container_of(poll_info->fid, struct tcpx_pep,
-					util_pep.pep_fid.fid);
-
-		poll_mgr->poll_fds[poll_mgr->nfds].fd = tcpx_pep->sock;
-		poll_mgr->poll_fds[poll_mgr->nfds].events = POLLIN;
-		break;
-	default:
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-			"invalid fd\n");
-		return -FI_EINVAL;
-	}
-	poll_mgr->nfds++;
-	return 0;
-}
+	cm_ctx->cm_data_sz = ntohs(hdr->seg_size);
+	if (cm_ctx->cm_data_sz) {
+		size_t data_sz = MIN(cm_ctx->cm_data_sz,
+				     TCPX_MAX_CM_DATA_SIZE);
+		ssize_t ret = ofi_recv_socket(fd, cm_ctx->cm_data,
+					      data_sz, MSG_WAITALL);
+		if ((size_t) ret != data_sz)
+			return -FI_EIO;
+		cm_ctx->cm_data_sz = data_sz;
 
-static int handle_poll_list(struct poll_fd_mgr *poll_mgr)
-{
-	struct poll_fd_info *poll_item;
-	int ret = FI_SUCCESS;
-	int id = 0;
-
-	fastlock_acquire(&poll_mgr->lock);
-	while (!dlist_empty(&poll_mgr->list)) {
-		poll_item = container_of(poll_mgr->list.next,
-					 struct poll_fd_info, entry);
-		dlist_remove_init(&poll_item->entry);
-
-		if (poll_item->flags & POLL_MGR_DEL) {
-			id = poll_fds_find_dup(poll_mgr, poll_item);
-			assert(id > 0);
-			if (id <= 0) {
-				ret = -FI_EINVAL;
-				goto err;
-			}
-
-			poll_fds_swap_del_last(poll_mgr, id);
-			poll_item->flags |= POLL_MGR_ACK;
-		} else {
-			assert(poll_fds_find_dup(poll_mgr, poll_item) < 0);
-			ret = poll_fds_add_item(poll_mgr, poll_item);
-			if (ret) {
-				FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-					"Failed to add fd to event polling\n");
-			}
+		if (OFI_UNLIKELY(cm_ctx->cm_data_sz >
+					TCPX_MAX_CM_DATA_SIZE)) {
+			ofi_discard_socket(fd, cm_ctx->cm_data_sz -
+					   TCPX_MAX_CM_DATA_SIZE);
 		}
-
-		if (poll_item->flags & POLL_MGR_FREE)
-			free(poll_item);
-		else
-			poll_item->flags |= POLL_MGR_ACK;
 	}
-err:
-	fastlock_release(&poll_mgr->lock);
-	return ret;
+	return FI_SUCCESS;
 }
 
 static int rx_cm_data(SOCKET fd, struct ofi_ctrl_hdr *hdr,
-		      int type, struct poll_fd_info *poll_info)
+		      int type, struct tcpx_cm_context *cm_ctx)
 {
 	ssize_t ret;
 
@@ -197,26 +71,17 @@ static int rx_cm_data(SOCKET fd, struct ofi_ctrl_hdr *hdr,
 	if (ret != sizeof(*hdr))
 		return -FI_EIO;
 
-	if (hdr->type != type)
-		return -FI_ECONNREFUSED;
-
 	if (hdr->version != OFI_CTRL_VERSION)
 		return -FI_ENOPROTOOPT;
 
-	poll_info->cm_data_sz = ntohs(hdr->seg_size);
-	if (poll_info->cm_data_sz) {
-		if (poll_info->cm_data_sz > TCPX_MAX_CM_DATA_SIZE)
-			return -FI_EINVAL;
-
-		ret = ofi_recv_socket(fd, poll_info->cm_data,
-				      poll_info->cm_data_sz, MSG_WAITALL);
-		if ((size_t) ret != poll_info->cm_data_sz)
-			return -FI_EIO;
+	ret = read_cm_data(fd, cm_ctx, hdr);
+	if (hdr->type != type) {
+		ret = -FI_ECONNREFUSED;
 	}
-	return FI_SUCCESS;
+	return ret;
 }
 
-static int tx_cm_data(SOCKET fd, uint8_t type, struct poll_fd_info *poll_info)
+static int tx_cm_data(SOCKET fd, uint8_t type, struct tcpx_cm_context *cm_ctx)
 {
 	struct ofi_ctrl_hdr hdr;
 	ssize_t ret;
@@ -224,336 +89,381 @@ static int tx_cm_data(SOCKET fd, uint8_t type, struct poll_fd_info *poll_info)
 	memset(&hdr, 0, sizeof(hdr));
 	hdr.version = OFI_CTRL_VERSION;
 	hdr.type = type;
-	hdr.seg_size = htons((uint16_t) poll_info->cm_data_sz);
+	hdr.seg_size = htons((uint16_t) cm_ctx->cm_data_sz);
 
 	ret = ofi_send_socket(fd, &hdr, sizeof(hdr), MSG_NOSIGNAL);
 	if (ret != sizeof(hdr))
 		return -FI_EIO;
 
-	if (poll_info->cm_data_sz) {
-		ret = ofi_send_socket(fd, poll_info->cm_data,
-				      poll_info->cm_data_sz, MSG_NOSIGNAL);
-		if ((size_t) ret != poll_info->cm_data_sz)
+	if (cm_ctx->cm_data_sz) {
+		ret = ofi_send_socket(fd, cm_ctx->cm_data,
+				      cm_ctx->cm_data_sz, MSG_NOSIGNAL);
+		if ((size_t) ret != cm_ctx->cm_data_sz)
 			return -FI_EIO;
 	}
 	return FI_SUCCESS;
 }
 
-static int send_conn_req(struct poll_fd_mgr *poll_mgr,
-			 struct poll_fd_info *poll_info,
-			 struct tcpx_ep *ep,
-			 int index)
+static int tcpx_ep_msg_xfer_enable(struct tcpx_ep *ep)
 {
-	socklen_t len;
-	int status, ret = FI_SUCCESS;
-
-	assert(poll_mgr->poll_fds[index].revents == POLLOUT);
+	int ret;
 
-	len = sizeof(status);
-	ret = getsockopt(ep->conn_fd, SOL_SOCKET, SO_ERROR, (char *) &status, &len);
-	if (ret < 0 || status) {
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "connection failure\n");
-		return (ret < 0)? -errno : status;
+	fastlock_acquire(&ep->lock);
+	if (ep->cm_state != TCPX_EP_CONNECTING) {
+		fastlock_release(&ep->lock);
+		return -FI_EINVAL;
 	}
+	ep->progress_func = tcpx_ep_progress;
+	ret = fi_fd_nonblock(ep->conn_fd);
+	if (ret)
+		goto err;
+
+	ret = tcpx_cq_wait_ep_add(ep);
+	if (ret)
+		goto err;
 
-	ret = tx_cm_data(ep->conn_fd, ofi_ctrl_connreq, poll_info);
+	ep->cm_state = TCPX_EP_CONNECTED;
+err:
+	fastlock_release(&ep->lock);
 	return ret;
 }
 
-static int proc_conn_resp(struct poll_fd_mgr *poll_mgr,
-			  struct poll_fd_info *poll_info,
-			  struct tcpx_ep *ep,
-			  int index)
+static int proc_conn_resp(struct tcpx_cm_context *cm_ctx,
+			  struct tcpx_ep *ep)
 {
 	struct ofi_ctrl_hdr conn_resp;
 	struct fi_eq_cm_entry *cm_entry;
+	ssize_t len;
 	int ret = FI_SUCCESS;
 
-	assert(poll_mgr->poll_fds[index].revents == POLLIN);
-	ret = rx_cm_data(ep->conn_fd, &conn_resp, ofi_ctrl_connresp, poll_info);
+	ret = rx_cm_data(ep->conn_fd, &conn_resp, ofi_ctrl_connresp, cm_ctx);
 	if (ret)
 		return ret;
 
-	cm_entry = calloc(1, sizeof(*cm_entry) + poll_info->cm_data_sz);
-	if (!cm_entry) {
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "mem alloc failed\n");
+	cm_entry = calloc(1, sizeof(*cm_entry) + cm_ctx->cm_data_sz);
+	if (!cm_entry)
 		return -FI_ENOMEM;
-	}
 
-	cm_entry->fid = poll_info->fid;
-	memcpy(cm_entry->data, poll_info->cm_data, poll_info->cm_data_sz);
+	cm_entry->fid = cm_ctx->fid;
+	memcpy(cm_entry->data, cm_ctx->cm_data, cm_ctx->cm_data_sz);
 
-	ret = (int) fi_eq_write(&ep->util_ep.eq->eq_fid, FI_CONNECTED, cm_entry,
-				sizeof(*cm_entry) + poll_info->cm_data_sz, 0);
-	if (ret < 0) {
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "Error writing to EQ\n");
+	ret = tcpx_ep_msg_xfer_enable(ep);
+	if (ret)
+		goto err;
+
+	len = fi_eq_write(&ep->util_ep.eq->eq_fid, FI_CONNECTED, cm_entry,
+			  sizeof(*cm_entry) + cm_ctx->cm_data_sz, 0);
+	if (len < 0) {
+		ret = (int) len;
 		goto err;
 	}
-	ret = fi_fd_nonblock(ep->conn_fd);
 err:
 	free(cm_entry);
 	return ret;
 }
 
-static void handle_connect(struct poll_fd_mgr *poll_mgr,
-			   int index)
+int tcpx_eq_wait_try_func(void *arg)
+{
+	return FI_SUCCESS;
+}
+
+static void client_recv_connresp(struct util_wait *wait,
+				 struct tcpx_cm_context *cm_ctx)
 {
+	struct fi_eq_err_entry err_entry = { 0 };
 	struct tcpx_ep *ep;
-	struct poll_fd_info *poll_info = &poll_mgr->poll_info[index];
+	ssize_t ret;
+
+	assert(cm_ctx->fid->fclass == FI_CLASS_EP);
+	ep = container_of(cm_ctx->fid, struct tcpx_ep, util_ep.ep_fid.fid);
+
+	ret = ofi_wait_fd_del(wait, ep->conn_fd);
+	if (ret) {
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+			"Could not remove fd from wait\n");
+		goto err;
+	}
+
+	ret = proc_conn_resp(cm_ctx, ep);
+	if (ret)
+		goto err;
+
+	FI_DBG(&tcpx_prov, FI_LOG_EP_CTRL, "Received Accept from server\n");
+	free(cm_ctx);
+	return;
+err:
+	err_entry.fid = cm_ctx->fid;
+	err_entry.context = cm_ctx->fid->context;
+	err_entry.err = -ret;
+	if (cm_ctx->cm_data_sz) {
+		err_entry.err_data = calloc(1, cm_ctx->cm_data_sz);
+		if (OFI_LIKELY(err_entry.err_data != NULL)) {
+			memcpy(err_entry.err_data, cm_ctx->cm_data,
+			       cm_ctx->cm_data_sz);
+			err_entry.err_data_size = cm_ctx->cm_data_sz;
+		}
+	}
+	FI_DBG(&tcpx_prov, FI_LOG_EP_CTRL,
+	       "fi_eq_write the conn refused %"PRId64"\n", ret);
+	free(cm_ctx);
+	/* `err_entry.err_data` must live until it is passed to user */
+	ret = fi_eq_write(&ep->util_ep.eq->eq_fid, FI_NOTIFY,
+			  &err_entry, sizeof(err_entry), UTIL_FLAG_ERROR);
+	if (OFI_UNLIKELY(ret < 0)) {
+		free(err_entry.err_data);
+	}
+}
+
+static void server_send_cm_accept(struct util_wait *wait,
+				  struct tcpx_cm_context *cm_ctx)
+{
+	struct fi_eq_cm_entry cm_entry = {0};
 	struct fi_eq_err_entry err_entry;
+	struct tcpx_ep *ep;
 	int ret;
 
-	assert(poll_info->fid->fclass == FI_CLASS_EP);
-	ep = container_of(poll_info->fid, struct tcpx_ep, util_ep.ep_fid.fid);
+	assert(cm_ctx->fid->fclass == FI_CLASS_EP);
+	ep = container_of(cm_ctx->fid, struct tcpx_ep, util_ep.ep_fid.fid);
 
-	switch (poll_info->state) {
-	case ESTABLISH_CONN:
-		ret = send_conn_req(poll_mgr, poll_info, ep, index);
-		if (ret)
-			goto err;
+	ret = tx_cm_data(ep->conn_fd, ofi_ctrl_connresp, cm_ctx);
+	if (ret)
+		goto err;
 
-		poll_info->state = RCV_RESP;
-		poll_mgr->poll_fds[index].events = POLLIN;
-		break;
-	case RCV_RESP:
-		ret = proc_conn_resp(poll_mgr, poll_info, ep, index);
-		if (ret)
-			goto err;
+	cm_entry.fid =  cm_ctx->fid;
+	ret = (int) fi_eq_write(&ep->util_ep.eq->eq_fid, FI_CONNECTED,
+				&cm_entry, sizeof(cm_entry), 0);
+	if (ret < 0) {
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "Error writing to EQ\n");
+	}
 
-		poll_info->state = CONNECT_DONE;
-		break;
-	default:
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "Invalid connection state\n");
-		ret = -FI_EINVAL;
+	ret = ofi_wait_fd_del(wait, ep->conn_fd);
+	if (ret) {
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+			"Could not remove fd from wait\n");
 		goto err;
 	}
+
+	ret = tcpx_ep_msg_xfer_enable(ep);
+	if (ret)
+		goto err;
+
+	FI_DBG(&tcpx_prov, FI_LOG_EP_CTRL, "Connection Accept Successful\n");
+	free(cm_ctx);
 	return;
 err:
 	memset(&err_entry, 0, sizeof err_entry);
-	err_entry.fid = poll_info->fid;
-	err_entry.context = poll_info->fid->context;
+	err_entry.fid = cm_ctx->fid;
+	err_entry.context = cm_ctx->fid->context;
 	err_entry.err = -ret;
 
-	poll_info->state = CONNECT_DONE;
-	fi_eq_write(&ep->util_ep.eq->eq_fid, FI_SHUTDOWN,
+	free(cm_ctx);
+	fi_eq_write(&ep->util_ep.eq->eq_fid, FI_NOTIFY,
 		    &err_entry, sizeof(err_entry), UTIL_FLAG_ERROR);
 }
 
-static void handle_connreq(struct poll_fd_mgr *poll_mgr,
-			   struct poll_fd_info *poll_info)
+static void server_recv_connreq(struct util_wait *wait,
+				struct tcpx_cm_context *cm_ctx)
 {
 	struct tcpx_conn_handle *handle;
-	struct tcpx_pep *pep;
 	struct fi_eq_cm_entry *cm_entry;
 	struct ofi_ctrl_hdr conn_req;
-	SOCKET sock;
 	int ret;
 
-	assert(poll_info->fid->fclass == FI_CLASS_PEP);
-	pep = container_of(poll_info->fid, struct tcpx_pep, util_pep.pep_fid.fid);
+	assert(cm_ctx->fid->fclass == FI_CLASS_CONNREQ);
 
-	sock = accept(pep->sock, NULL, 0);
-	if (sock < 0) {
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "accept error: %d\n",
-			ofi_sockerr());
-		return;
-	}
-	ret = rx_cm_data(sock, &conn_req, ofi_ctrl_connreq, poll_info);
-	if (ret) {
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "cm data recv failed \n");
-		goto err1;
-	}
+	handle  = container_of(cm_ctx->fid,
+			       struct tcpx_conn_handle,
+			       handle);
 
-	handle = calloc(1, sizeof(*handle));
-	if (!handle)
+	ret = rx_cm_data(handle->conn_fd, &conn_req, ofi_ctrl_connreq, cm_ctx);
+	if (ret)
 		goto err1;
 
-	cm_entry = calloc(1, sizeof(*cm_entry) + poll_info->cm_data_sz);
+	cm_entry = calloc(1, sizeof(*cm_entry) + cm_ctx->cm_data_sz);
 	if (!cm_entry)
-		goto err2;
+		goto err1;
 
-	handle->conn_fd = sock;
-	cm_entry->fid = poll_info->fid;
-	cm_entry->info = fi_dupinfo(&pep->info);
+	cm_entry->fid = &handle->pep->util_pep.pep_fid.fid;
+	cm_entry->info = fi_dupinfo(&handle->pep->info);
 	if (!cm_entry->info)
-		goto err3;
+		goto err2;
 
 	cm_entry->info->handle = &handle->handle;
-	memcpy(cm_entry->data, poll_info->cm_data, poll_info->cm_data_sz);
+	memcpy(cm_entry->data, cm_ctx->cm_data, cm_ctx->cm_data_sz);
 
-	ret = (int) fi_eq_write(&pep->util_pep.eq->eq_fid, FI_CONNREQ, cm_entry,
-				sizeof(*cm_entry) + poll_info->cm_data_sz, 0);
+	ret = (int) fi_eq_write(&handle->pep->util_pep.eq->eq_fid, FI_CONNREQ, cm_entry,
+				sizeof(*cm_entry) + cm_ctx->cm_data_sz, 0);
 	if (ret < 0) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "Error writing to EQ\n");
-		goto err4;
+		goto err3;
 	}
-
+	ret = ofi_wait_fd_del(wait, handle->conn_fd);
+	if (ret)
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+			"fd deletion from ofi_wait failed\n");
 	free(cm_entry);
+	free(cm_ctx);
 	return;
-err4:
-	fi_freeinfo(cm_entry->info);
 err3:
-	free(cm_entry);
+	fi_freeinfo(cm_entry->info);
 err2:
-	free(handle);
+	free(cm_entry);
 err1:
-	ofi_close_socket(sock);
+	ofi_wait_fd_del(wait, handle->conn_fd);
+	ofi_close_socket(handle->conn_fd);
+	free(cm_ctx);
+	free(handle);
 }
 
-static void handle_accept_conn(struct poll_fd_mgr *poll_mgr,
-			       struct poll_fd_info *poll_info)
+static void client_send_connreq(struct util_wait *wait,
+				struct tcpx_cm_context *cm_ctx)
 {
-	struct fi_eq_cm_entry cm_entry;
-	struct fi_eq_err_entry err_entry;
 	struct tcpx_ep *ep;
-	int ret;
+	struct fi_eq_err_entry err_entry;
+	socklen_t len;
+	int status, ret = FI_SUCCESS;
 
-	assert(poll_info->fid->fclass == FI_CLASS_EP);
-	ep = container_of(poll_info->fid, struct tcpx_ep, util_ep.ep_fid.fid);
+	FI_DBG(&tcpx_prov, FI_LOG_EP_CTRL, "client send connreq\n");
+	assert(cm_ctx->fid->fclass == FI_CLASS_EP);
 
-	ret = tx_cm_data(ep->conn_fd, ofi_ctrl_connresp, poll_info);
+	ep = container_of(cm_ctx->fid, struct tcpx_ep, util_ep.ep_fid.fid);
+
+	len = sizeof(status);
+	ret = getsockopt(ep->conn_fd, SOL_SOCKET, SO_ERROR, (char *) &status, &len);
+	if (ret < 0 || status) {
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "connection failure\n");
+		ret = (ret < 0)? -ofi_sockerr() : status;
+		goto err;
+	}
+
+	ret = tx_cm_data(ep->conn_fd, ofi_ctrl_connreq, cm_ctx);
 	if (ret)
 		goto err;
 
-	cm_entry.fid =  poll_info->fid;
+	ret = ofi_wait_fd_del(wait, ep->conn_fd);
+	if (ret)
+		goto err;
 
-	ret = (int) fi_eq_write(&ep->util_ep.eq->eq_fid, FI_CONNECTED,
-				&cm_entry, sizeof(cm_entry), 0);
-	if (ret < 0) {
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "Error writing to EQ\n");
-	}
+	cm_ctx->type = CLIENT_RECV_CONNRESP;
+	ret = ofi_wait_fd_add(wait, ep->conn_fd, FI_EPOLL_IN,
+			      tcpx_eq_wait_try_func, NULL, cm_ctx);
+	if (ret)
+		goto err;
 
-	ret = fi_fd_nonblock(ep->conn_fd);
+	wait->signal(wait);
 	return;
 err:
 	memset(&err_entry, 0, sizeof err_entry);
-	err_entry.fid = poll_info->fid;
-	err_entry.context = poll_info->fid->context;
-	err_entry.err = ret;
+	err_entry.fid = cm_ctx->fid;
+	err_entry.context = cm_ctx->fid->context;
+	err_entry.err = -ret;
 
-	fi_eq_write(&ep->util_ep.eq->eq_fid, FI_SHUTDOWN,
+	free(cm_ctx);
+	fi_eq_write(&ep->util_ep.eq->eq_fid, FI_NOTIFY,
 		    &err_entry, sizeof(err_entry), UTIL_FLAG_ERROR);
 }
 
-static void handle_fd_events(struct poll_fd_mgr *poll_mgr)
+static void server_sock_accept(struct util_wait *wait,
+			       struct tcpx_cm_context *cm_ctx)
 {
-	int i;
+	struct tcpx_conn_handle *handle;
+	struct tcpx_pep *pep;
+	SOCKET sock;
+	int ret;
 
-	/* Process the fd array from end to start.  This allows us to handle
-	 * removing entries from the array. Also ignore the signal fd at index 0.
-	 */
-	for (i = poll_mgr->nfds-1; i > 0; i--) {
-		if (!poll_mgr->poll_fds[i].revents)
-			continue;
+	FI_DBG(&tcpx_prov, FI_LOG_EP_CTRL, "Received Connreq\n");
+	assert(cm_ctx->fid->fclass == FI_CLASS_PEP);
+	pep = container_of(cm_ctx->fid, struct tcpx_pep,
+			   util_pep.pep_fid.fid);
 
-		switch (poll_mgr->poll_info[i].type) {
-		case CONNECT_SOCK:
-			handle_connect(poll_mgr, i);
-
-			if (poll_mgr->poll_info[i].state == CONNECT_DONE)
-				poll_fds_swap_del_last(poll_mgr, i);
-			break;
-		case PASSIVE_SOCK:
-			handle_connreq(poll_mgr, &poll_mgr->poll_info[i]);
-			break;
-		case ACCEPT_SOCK:
-			handle_accept_conn(poll_mgr, &poll_mgr->poll_info[i]);
-			poll_fds_swap_del_last(poll_mgr, i);
-			break;
-		default:
-			FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-				"should never end up here\n");
-		}
+	sock = accept(pep->sock, NULL, 0);
+	if (sock < 0) {
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+			"accept error: %d\n", ofi_sockerr());
+		return;
 	}
-}
 
-static void *tcpx_conn_mgr_thread(void *data)
-{
-	struct tcpx_fabric *tcpx_fabric = (struct tcpx_fabric *) data;
-	struct poll_fd_mgr *poll_mgr = &tcpx_fabric->poll_mgr;
-	int ret;
-
-	ret = poll_fd_resize(poll_mgr, 64);
-	if (ret) {
+	handle = calloc(1, sizeof(*handle));
+	if (!handle) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-			"poll_fd memory alloc failed\n");
-		return NULL;
+			"cannot allocate memory \n");
+		goto err1;
 	}
 
-	poll_mgr->poll_fds[0].fd = poll_mgr->signal.fd[FI_READ_FD];
-	poll_mgr->poll_fds[0].events = POLLIN;
-	poll_mgr->nfds = 1;
+	cm_ctx = calloc(1, sizeof(*cm_ctx));
+	if (!cm_ctx)
+		goto err2;
 
-	while (poll_mgr->run) {
-		ret = poll(poll_mgr->poll_fds, poll_mgr->nfds, -1);
-		if (ret < 0) {
-			FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-				"Poll failed\n");
-			break;
-		}
+	handle->conn_fd = sock;
+	handle->handle.fclass = FI_CLASS_CONNREQ;
+	handle->pep = pep;
+	cm_ctx->fid = &handle->handle;
+	cm_ctx->type = SERVER_RECV_CONNREQ;
+
+	ret = ofi_wait_fd_add(wait, sock, FI_EPOLL_IN,
+			      tcpx_eq_wait_try_func,
+			      NULL, (void *) cm_ctx);
+	if (ret)
+		goto err3;
+	wait->signal(wait);
+	return;
+err3:
+	free(cm_ctx);
+err2:
+	free(handle);
+err1:
+	ofi_close_socket(sock);
+}
 
-		if (poll_mgr->poll_fds[0].revents & POLLIN) {
-			fd_signal_reset(&poll_mgr->signal);
-			if (handle_poll_list(poll_mgr)) {
-				FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-					"fd list add or remove failed\n");
-			}
-		}
-		handle_fd_events(poll_mgr);
+static void process_cm_ctx(struct util_wait *wait,
+			   struct tcpx_cm_context *cm_ctx)
+{
+	switch (cm_ctx->type) {
+	case SERVER_SOCK_ACCEPT:
+		server_sock_accept(wait,cm_ctx);
+		break;
+	case CLIENT_SEND_CONNREQ:
+		client_send_connreq(wait, cm_ctx);
+		break;
+	case SERVER_RECV_CONNREQ:
+		server_recv_connreq(wait, cm_ctx);
+		break;
+	case SERVER_SEND_CM_ACCEPT:
+		server_send_cm_accept(wait, cm_ctx);
+		break;
+	case CLIENT_RECV_CONNRESP:
+		client_recv_connresp(wait, cm_ctx);
+		break;
+	default:
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+			"should never end up here\n");
 	}
-	return NULL;
 }
 
-void tcpx_conn_mgr_close(struct tcpx_fabric *tcpx_fabric)
+void tcpx_conn_mgr_run(struct util_eq *eq)
 {
-	struct poll_fd_info *poll_info;
+	struct util_wait_fd *wait_fd;
+	void *wait_contexts[MAX_EPOLL_EVENTS];
+	int num_fds = 0, i;
 
-	tcpx_fabric->poll_mgr.run = 0;
-	fd_signal_set(&tcpx_fabric->poll_mgr.signal);
+	assert(eq->wait != NULL);
 
-	if (tcpx_fabric->conn_mgr_thread &&
-	    pthread_join(tcpx_fabric->conn_mgr_thread, NULL)) {
-		FI_DBG(&tcpx_prov, FI_LOG_FABRIC,
-		       "cm thread failed to join\n");
-	}
+	wait_fd = container_of(eq->wait, struct util_wait_fd,
+			       util_wait);
 
-	while (!dlist_empty(&tcpx_fabric->poll_mgr.list)) {
-		poll_info = container_of(tcpx_fabric->poll_mgr.list.next,
-					 struct poll_fd_info, entry);
-		dlist_remove(&poll_info->entry);
-		assert(poll_info->flags & POLL_MGR_FREE);
-		free(poll_info);
-	}
-
-	fastlock_destroy(&tcpx_fabric->poll_mgr.lock);
-	fd_signal_free(&tcpx_fabric->poll_mgr.signal);
-}
-
-int tcpx_conn_mgr_init(struct tcpx_fabric *tcpx_fabric)
-{
-	int ret;
+	num_fds = fi_epoll_wait(wait_fd->epoll_fd, wait_contexts,
+				MAX_EPOLL_EVENTS, 0);
+	if (num_fds < 0)
+		return;
 
-	dlist_init(&tcpx_fabric->poll_mgr.list);
-	fastlock_init(&tcpx_fabric->poll_mgr.lock);
-	ret = fd_signal_init(&tcpx_fabric->poll_mgr.signal);
-	if (ret) {
-		FI_WARN(&tcpx_prov, FI_LOG_FABRIC,"signal init failed\n");
-		goto err;
-	}
+	for ( i = 0; i < num_fds; i++) {
 
-	tcpx_fabric->poll_mgr.run = 1;
-	ret = pthread_create(&tcpx_fabric->conn_mgr_thread, 0,
-			     tcpx_conn_mgr_thread, (void *) tcpx_fabric);
-	if (ret) {
-		FI_WARN(&tcpx_prov, FI_LOG_FABRIC,
-			"Failed creating tcpx connection manager thread");
+		/* skip wake up signals */
+		if (&wait_fd->util_wait.wait_fid.fid == wait_contexts[i])
+			continue;
 
-		goto err1;
+		process_cm_ctx(eq->wait,
+			       (struct tcpx_cm_context *)
+			       wait_contexts[i]);
 	}
-	return 0;
-err1:
-	fd_signal_free(&tcpx_fabric->poll_mgr.signal);
-err:
-	fastlock_destroy(&tcpx_fabric->poll_mgr.lock);
-	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_cq.c
index e73578314..bad43f56e 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_cq.c
@@ -35,45 +35,229 @@
 
 #include "tcpx.h"
 
+#define TCPX_DEF_CQ_SIZE (1024)
+
+static void tcpx_buf_pools_destroy(struct tcpx_buf_pool *buf_pools)
+{
+	int i;
+
+	for (i = 0; i < TCPX_OP_CODE_MAX; i++)
+		util_buf_pool_destroy(buf_pools[i].pool);
+}
+
 static int tcpx_cq_close(struct fid *fid)
 {
 	int ret;
-	struct util_cq *cq;
+	struct tcpx_cq *tcpx_cq;
 
-	cq = container_of(fid, struct util_cq, cq_fid.fid);
-	ret = ofi_cq_cleanup(cq);
+	tcpx_cq = container_of(fid, struct tcpx_cq, util_cq.cq_fid.fid);
+	tcpx_buf_pools_destroy(tcpx_cq->buf_pools);
+	ret = ofi_cq_cleanup(&tcpx_cq->util_cq);
 	if (ret)
 		return ret;
-	free(cq);
+
+	free(tcpx_cq);
 	return 0;
 }
 
+struct tcpx_xfer_entry *tcpx_xfer_entry_alloc(struct tcpx_cq *tcpx_cq,
+					      enum tcpx_xfer_op_codes type)
+{
+	struct tcpx_xfer_entry *xfer_entry;
+
+	tcpx_cq->util_cq.cq_fastlock_acquire(&tcpx_cq->util_cq.cq_lock);
+
+	/* optimization: don't allocate queue_entry when cq is full */
+	if (ofi_cirque_isfull(tcpx_cq->util_cq.cirq)) {
+		tcpx_cq->util_cq.cq_fastlock_release(&tcpx_cq->util_cq.cq_lock);
+		return NULL;
+	}
+
+	xfer_entry = util_buf_alloc(tcpx_cq->buf_pools[type].pool);
+	if (!xfer_entry) {
+		tcpx_cq->util_cq.cq_fastlock_release(&tcpx_cq->util_cq.cq_lock);
+		FI_INFO(&tcpx_prov, FI_LOG_DOMAIN,"failed to get buffer\n");
+		return NULL;
+	}
+	tcpx_cq->util_cq.cq_fastlock_release(&tcpx_cq->util_cq.cq_lock);
+	return xfer_entry;
+}
+
+void tcpx_xfer_entry_release(struct tcpx_cq *tcpx_cq,
+			     struct tcpx_xfer_entry *xfer_entry)
+{
+	if (xfer_entry->ep->cur_rx_entry == xfer_entry) {
+		xfer_entry->ep->cur_rx_entry = NULL;
+	}
+	tcpx_cq->util_cq.cq_fastlock_acquire(&tcpx_cq->util_cq.cq_lock);
+	util_buf_release(tcpx_cq->buf_pools[xfer_entry->msg_hdr.hdr.op_data].pool,
+			 xfer_entry);
+	tcpx_cq->util_cq.cq_fastlock_release(&tcpx_cq->util_cq.cq_lock);
+}
+
+void tcpx_cq_report_completion(struct util_cq *cq,
+			       struct tcpx_xfer_entry *xfer_entry,
+			       int err)
+{
+	struct fi_cq_err_entry err_entry;
+
+	if (!(xfer_entry->flags & FI_COMPLETION))
+		return;
+
+	if (err) {
+		err_entry.op_context = xfer_entry->context;
+		err_entry.flags = xfer_entry->flags;
+		err_entry.len = 0;
+		err_entry.buf = NULL;
+		err_entry.data = ntohll(xfer_entry->msg_hdr.hdr.data);
+		err_entry.tag = 0;
+		err_entry.olen = 0;
+		err_entry.err = err;
+		err_entry.prov_errno = ofi_sockerr();
+		err_entry.err_data = NULL;
+		err_entry.err_data_size = 0;
+
+		ofi_cq_write_error(cq, &err_entry);
+	} else {
+		ofi_cq_write(cq, xfer_entry->context,
+			     xfer_entry->flags, 0, NULL,
+			     ntohll(xfer_entry->msg_hdr.hdr.data), 0);
+
+		if (cq->wait)
+			ofi_cq_signal(&cq->cq_fid);
+	}
+}
+
+static int tcpx_cq_control(struct fid *fid, int command, void *arg)
+{
+	struct util_cq *cq;
+	int ret;
+
+	cq = container_of(fid, struct util_cq, cq_fid.fid);
+
+	switch(command) {
+	case FI_GETWAIT:
+		if (!cq->wait)
+			return -FI_ENOSYS;
+
+		ret = fi_control(&cq->wait->wait_fid.fid,
+				 command, arg);
+		if (ret)
+			return ret;
+
+		return FI_SUCCESS;
+	default:
+		return -FI_ENOSYS;
+	}
+}
+
 static struct fi_ops tcpx_cq_fi_ops = {
 	.size = sizeof(struct fi_ops),
 	.close = tcpx_cq_close,
 	.bind = fi_no_bind,
-	.control = fi_no_control,
+	.control = tcpx_cq_control,
 	.ops_open = fi_no_ops_open,
 };
 
+/* Using this function to preset some values of buffers managed by util_buf_pool api.
+ * Note that the util_buf_pool uses first sizeof(slist_entry) bytes in every buffer
+ * internally for keeping buf list. So don't try to set those values. They won't stick
+ */
+static int tcpx_buf_pool_init(void *pool_ctx, void *addr,
+			      size_t len, void **context)
+{
+	struct tcpx_buf_pool *pool = (struct tcpx_buf_pool *)pool_ctx;
+	struct tcpx_xfer_entry *xfer_entry;
+	int i;
+
+	for (i = 0; i < pool->pool->attr.chunk_cnt; i++) {
+		xfer_entry = (struct tcpx_xfer_entry *)
+			((char *)addr + i * pool->pool->entry_sz);
+
+		xfer_entry->msg_hdr.hdr.version = OFI_CTRL_VERSION;
+		xfer_entry->msg_hdr.hdr.op_data = pool->op_type;
+		switch (pool->op_type) {
+		case TCPX_OP_MSG_RECV:
+		case TCPX_OP_MSG_SEND:
+		case TCPX_OP_MSG_RESP:
+			xfer_entry->msg_hdr.hdr.op = ofi_op_msg;
+			break;
+		case TCPX_OP_WRITE:
+		case TCPX_OP_REMOTE_WRITE:
+			xfer_entry->msg_hdr.hdr.op = ofi_op_write;
+			break;
+		case TCPX_OP_READ_REQ:
+			xfer_entry->msg_hdr.hdr.op = ofi_op_read_req;
+			xfer_entry->msg_hdr.hdr.size =
+				htonll(sizeof(xfer_entry->msg_hdr));
+			break;
+		case TCPX_OP_READ_RSP:
+			xfer_entry->msg_hdr.hdr.op = ofi_op_read_rsp;
+			break;
+		case TCPX_OP_REMOTE_READ:
+			break;
+		default:
+			assert(0);
+			break;
+		}
+	}
+	return FI_SUCCESS;
+}
+
+static int tcpx_buf_pools_create(struct tcpx_buf_pool *buf_pools)
+{
+	int i, ret;
+
+	for (i = 0; i < TCPX_OP_CODE_MAX; i++) {
+		buf_pools[i].op_type = i;
+
+		ret = util_buf_pool_create_ex(&buf_pools[i].pool,
+					      sizeof(struct tcpx_xfer_entry),
+					      16, 0, 1024, tcpx_buf_pool_init,
+					      NULL, &buf_pools[i]);
+		if (ret) {
+			FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+				"Unable to create buf pool\n");
+			goto err;
+		}
+	}
+	return 0;
+err:
+	while (i--) {
+		util_buf_pool_destroy(buf_pools[i].pool);
+	}
+	return -FI_ENOMEM;
+}
+
 int tcpx_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
 		 struct fid_cq **cq_fid, void *context)
 {
 	int ret;
-	struct util_cq *cq;
+	struct tcpx_cq *tcpx_cq;
 
-	cq = calloc(1, sizeof(*cq));
-	if (!cq)
+	tcpx_cq = calloc(1, sizeof(*tcpx_cq));
+	if (!tcpx_cq)
 		return -FI_ENOMEM;
 
-	ret = ofi_cq_init(&tcpx_prov, domain, attr, cq,
-			   &ofi_cq_progress, context);
-	if (ret) {
-		free(cq);
-		return ret;
-	}
+	if (!attr->size)
+		attr->size = TCPX_DEF_CQ_SIZE;
+
+	ret = tcpx_buf_pools_create(tcpx_cq->buf_pools);
+	if (ret)
+		goto free_cq;
 
-	*cq_fid = &cq->cq_fid;
+	ret = ofi_cq_init(&tcpx_prov, domain, attr, &tcpx_cq->util_cq,
+			  &ofi_cq_progress, context);
+	if (ret)
+		goto destroy_pool;
+
+	*cq_fid = &tcpx_cq->util_cq.cq_fid;
 	(*cq_fid)->fid.ops = &tcpx_cq_fi_ops;
 	return 0;
+
+destroy_pool:
+	tcpx_buf_pools_destroy(tcpx_cq->buf_pools);
+free_cq:
+	free(tcpx_cq);
+	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_domain.c
index c1e3031ca..70f3f6429 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_domain.c
@@ -34,18 +34,82 @@
 #include <string.h>
 
 #include "tcpx.h"
+extern struct fi_ops_msg tcpx_srx_msg_ops;
 
+static int tcpx_srx_ctx_close(struct fid *fid)
+{
+	struct tcpx_rx_ctx *srx_ctx;
+	struct slist_entry *entry;
+	struct tcpx_xfer_entry *xfer_entry;
+
+	srx_ctx = container_of(fid, struct tcpx_rx_ctx,
+			       rx_fid.fid);
+
+	while (!slist_empty(&srx_ctx->rx_queue)) {
+		entry = slist_remove_head(&srx_ctx->rx_queue);
+		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
+		util_buf_release(srx_ctx->buf_pool, xfer_entry);
+	}
+
+	fastlock_destroy(&srx_ctx->lock);
+	free(srx_ctx);
+	return FI_SUCCESS;
+}
+
+static struct fi_ops fi_ops_srx_ctx = {
+	.size = sizeof(struct fi_ops),
+	.close = tcpx_srx_ctx_close,
+	.bind = fi_no_bind,
+	.control = fi_no_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static int tcpx_srx_ctx(struct fid_domain *domain, struct fi_rx_attr *attr,
+		 struct fid_ep **rx_ep, void *context)
+{
+	struct tcpx_rx_ctx *srx_ctx;
+	int ret = FI_SUCCESS;
+
+	srx_ctx = calloc(1, sizeof(*srx_ctx));
+	if (!srx_ctx)
+		return -FI_ENOMEM;
+
+	srx_ctx->rx_fid.fid.fclass = FI_CLASS_SRX_CTX;
+	srx_ctx->rx_fid.fid.context = context;
+	srx_ctx->rx_fid.fid.ops = &fi_ops_srx_ctx;
+
+	srx_ctx->rx_fid.msg = &tcpx_srx_msg_ops;
+	slist_init(&srx_ctx->rx_queue);
+
+	ret = fastlock_init(&srx_ctx->lock);
+	if (ret)
+		goto err1;
+
+	ret = util_buf_pool_create(&srx_ctx->buf_pool,
+				   sizeof(struct tcpx_xfer_entry),
+				   16, 0, 1024);
+	if (ret)
+		goto err2;
+
+	*rx_ep = &srx_ctx->rx_fid;
+	return FI_SUCCESS;
+err2:
+	fastlock_destroy(&srx_ctx->lock);
+err1:
+	free(srx_ctx);
+	return ret;
+}
 
 static struct fi_ops_domain tcpx_domain_ops = {
 	.size = sizeof(struct fi_ops_domain),
-	.av_open = ip_av_create,
+	.av_open = ofi_ip_av_create,
 	.cq_open = tcpx_cq_open,
 	.endpoint = tcpx_endpoint,
 	.scalable_ep = fi_no_scalable_ep,
 	.cntr_open = fi_no_cntr_open,
 	.poll_open = fi_poll_create,
 	.stx_ctx = fi_no_stx_context,
-	.srx_ctx = fi_no_srx_context,
+	.srx_ctx = tcpx_srx_ctx,
 	.query_atomic = fi_no_query_atomic,
 };
 
@@ -57,10 +121,6 @@ static int tcpx_domain_close(fid_t fid)
 	tcpx_domain = container_of(fid, struct tcpx_domain,
 				   util_domain.domain_fid.fid);
 
-	ret = tcpx_progress_close(&tcpx_domain->progress);
-	if (ret)
-		return ret;
-
 	ret = ofi_domain_close(&tcpx_domain->util_domain);
 	if (ret)
 		return ret;
@@ -77,6 +137,13 @@ static struct fi_ops tcpx_domain_fi_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
+static struct fi_ops_mr tcpx_domain_fi_ops_mr = {
+	.size = sizeof(struct fi_ops_mr),
+	.reg = ofi_mr_reg,
+	.regv = ofi_mr_regv,
+	.regattr = ofi_mr_regattr,
+};
+
 int tcpx_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 		     struct fid_domain **domain, void *context)
 {
@@ -93,22 +160,15 @@ int tcpx_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 
 	ret = ofi_domain_init(fabric, info, &tcpx_domain->util_domain, context);
 	if (ret)
-		goto err1;
+		goto err;
 
 	*domain = &tcpx_domain->util_domain.domain_fid;
 	(*domain)->fid.ops = &tcpx_domain_fi_ops;
 	(*domain)->ops = &tcpx_domain_ops;
-
-	ret = tcpx_progress_init(&tcpx_domain->progress);
-	if (ret)
-		goto err2;
+	(*domain)->mr = &tcpx_domain_fi_ops_mr;
 
 	return 0;
-err2:
-	if (ofi_domain_close(&tcpx_domain->util_domain))
-		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN,
-			"ofi_domain_close failed\n");
-err1:
+err:
 	free(tcpx_domain);
 	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_ep.c
index 23a93807b..86b3b4c1e 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_ep.c
@@ -49,20 +49,61 @@
 #include <arpa/inet.h>
 #include <netdb.h>
 
+extern struct fi_ops_rma tcpx_rma_ops;
+
+static inline struct tcpx_xfer_entry *
+tcpx_alloc_recv_entry(struct tcpx_ep *tcpx_ep)
+{
+	struct tcpx_xfer_entry *recv_entry;
+	struct tcpx_cq *tcpx_cq;
+
+	tcpx_cq = container_of(tcpx_ep->util_ep.rx_cq, struct tcpx_cq,
+			       util_cq);
+
+	recv_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_MSG_RECV);
+	if (recv_entry) {
+		recv_entry->ep = tcpx_ep;
+		recv_entry->done_len = 0;
+	}
+	return recv_entry;
+}
+
+static inline struct tcpx_xfer_entry *
+tcpx_alloc_send_entry(struct tcpx_ep *tcpx_ep)
+{
+	struct tcpx_xfer_entry *send_entry;
+	struct tcpx_cq *tcpx_cq;
+
+	tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq,
+			       util_cq);
+
+	send_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_MSG_SEND);
+	if (send_entry) {
+		send_entry->ep = tcpx_ep;
+		send_entry->done_len = 0;
+	}
+	return send_entry;
+}
+
+static inline void tcpx_queue_recv(struct tcpx_ep *tcpx_ep,
+				   struct tcpx_xfer_entry *recv_entry)
+{
+	fastlock_acquire(&tcpx_ep->lock);
+	slist_insert_tail(&recv_entry->entry, &tcpx_ep->rx_queue);
+	fastlock_release(&tcpx_ep->lock);
+}
+
 static ssize_t tcpx_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
 			    uint64_t flags)
 {
-	struct tcpx_domain *tcpx_domain;
-	struct tcpx_pe_entry *recv_entry;
+	struct tcpx_xfer_entry *recv_entry;
 	struct tcpx_ep *tcpx_ep;
 
 	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
-	tcpx_domain = container_of(tcpx_ep->util_ep.domain,
-				   struct tcpx_domain, util_domain);
 
-	assert(msg->iov_count < TCPX_IOV_LIMIT);
+	assert(msg->iov_count <= TCPX_IOV_LIMIT);
 
-	recv_entry = pe_entry_alloc(&tcpx_domain->progress);
+	recv_entry = tcpx_alloc_recv_entry(tcpx_ep);
 	if (!recv_entry)
 		return -FI_EAGAIN;
 
@@ -70,201 +111,283 @@ static ssize_t tcpx_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
 	memcpy(&recv_entry->msg_data.iov[0], &msg->msg_iov[0],
 	       msg->iov_count * sizeof(struct iovec));
 
-	recv_entry->ep = tcpx_ep;
-	recv_entry->flags = flags;
+	recv_entry->flags = ((tcpx_ep->util_ep.rx_op_flags & FI_COMPLETION) |
+			     flags | FI_MSG | FI_RECV);
 	recv_entry->context = msg->context;
-	recv_entry->done_len = 0;
 
-	dlist_insert_tail(&recv_entry->entry, &tcpx_ep->rx_queue);
+	tcpx_queue_recv(tcpx_ep, recv_entry);
 	return FI_SUCCESS;
 }
 
 static ssize_t tcpx_recv(struct fid_ep *ep, void *buf, size_t len, void *desc,
 			 fi_addr_t src_addr, void *context)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
+	struct tcpx_xfer_entry *recv_entry;
+	struct tcpx_ep *tcpx_ep;
 
-	msg_iov.iov_base = buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.desc = &desc;
-	msg.iov_count = 1;
-	msg.addr = src_addr;
-	msg.context = context;
-	msg.data = 0;
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+
+	recv_entry = tcpx_alloc_recv_entry(tcpx_ep);
+	if (!recv_entry)
+		return -FI_EAGAIN;
 
-	return tcpx_recvmsg(ep, &msg, 0);
+	recv_entry->msg_data.iov_cnt = 1;
+	recv_entry->msg_data.iov[0].iov_base = buf;
+	recv_entry->msg_data.iov[0].iov_len = len;
+
+	recv_entry->flags = ((tcpx_ep->util_ep.rx_op_flags & FI_COMPLETION) |
+			     FI_MSG | FI_RECV);
+	recv_entry->context = context;
+
+	tcpx_queue_recv(tcpx_ep, recv_entry);
+	return FI_SUCCESS;
 }
 
 static ssize_t tcpx_recvv(struct fid_ep *ep, const struct iovec *iov, void **desc,
 			  size_t count, fi_addr_t src_addr, void *context)
 {
-	struct fi_msg msg;
+	struct tcpx_xfer_entry *recv_entry;
+	struct tcpx_ep *tcpx_ep;
+
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
 
-	msg.msg_iov = iov;
-	msg.desc = desc;
-	msg.iov_count = count;
-	msg.addr = src_addr;
-	msg.context = context;
-	msg.data = 0;
-	return tcpx_recvmsg(ep, &msg, 0);
+	assert(count <= TCPX_IOV_LIMIT);
+
+	recv_entry = tcpx_alloc_recv_entry(tcpx_ep);
+	if (!recv_entry)
+		return -FI_EAGAIN;
+
+	recv_entry->msg_data.iov_cnt = count;
+	memcpy(recv_entry->msg_data.iov, iov, count * sizeof(*iov));
+
+	recv_entry->flags = ((tcpx_ep->util_ep.rx_op_flags & FI_COMPLETION) |
+			     FI_MSG | FI_RECV);
+	recv_entry->context = context;
+
+	tcpx_queue_recv(tcpx_ep, recv_entry);
+	return FI_SUCCESS;
 }
 
 static ssize_t tcpx_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
 			    uint64_t flags)
 {
 	struct tcpx_ep *tcpx_ep;
-	struct tcpx_domain *tcpx_domain;
-	struct tcpx_pe_entry *send_entry;
+	struct tcpx_cq *tcpx_cq;
+	struct tcpx_xfer_entry *tx_entry;
 	uint64_t data_len;
-	int ret = FI_SUCCESS;
 
 	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
-	tcpx_domain = container_of(tcpx_ep->util_ep.domain,
-				   struct tcpx_domain, util_domain);
+	tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq,
+			       util_cq);
 
-	send_entry = pe_entry_alloc(&tcpx_domain->progress);
-	if (!send_entry)
-		return -FI_ENOMEM;
-
-	if (msg->iov_count > TCPX_IOV_LIMIT) {
-		ret = -FI_EINVAL;
-		goto err;
-	}
+	tx_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_MSG_SEND);
+	if (!tx_entry)
+		return -FI_EAGAIN;
 
+	assert(msg->iov_count <= TCPX_IOV_LIMIT);
 	data_len = ofi_total_iov_len(msg->msg_iov, msg->iov_count);
+	assert(!(flags & FI_INJECT) || (data_len <= TCPX_MAX_INJECT_SZ));
+	tx_entry->msg_hdr.hdr.size = htonll(data_len + sizeof(tx_entry->msg_hdr));
+	tx_entry->msg_hdr.hdr.flags = 0;
 
-	if (flags & FI_INJECT) {
-		if (data_len > TCPX_MAX_INJECT_SZ)
-			return -FI_EINVAL;
-	}
-	send_entry->msg_hdr.version = OFI_CTRL_VERSION;
-	send_entry->msg_hdr.op = ofi_op_msg;
-	send_entry->msg_hdr.op_data = TCPX_OP_MSG_SEND;
-	send_entry->msg_hdr.size = htonll(data_len + sizeof(send_entry->msg_hdr));
-
-	send_entry->msg_data.iov[0].iov_base = (void *) &send_entry->msg_hdr;
-	send_entry->msg_data.iov[0].iov_len = sizeof(send_entry->msg_hdr);
-	send_entry->msg_data.iov_cnt = msg->iov_count + 1;
+	tx_entry->msg_data.iov[0].iov_base = (void *) &tx_entry->msg_hdr;
+	tx_entry->msg_data.iov[0].iov_len = sizeof(tx_entry->msg_hdr);
+	tx_entry->msg_data.iov_cnt = msg->iov_count + 1;
 
 	if (flags & FI_INJECT) {
 		ofi_copy_iov_buf(msg->msg_iov, msg->iov_count, 0,
-				 send_entry->msg_data.inject,
+				 tx_entry->msg_data.inject,
 				 data_len,
 				 OFI_COPY_IOV_TO_BUF);
 
-		send_entry->msg_data.iov[1].iov_base = (void *)send_entry->msg_data.inject;
-		send_entry->msg_data.iov[1].iov_len = data_len;
-		send_entry->msg_data.iov_cnt = 2;
+		tx_entry->msg_data.iov[1].iov_base = (void *)tx_entry->msg_data.inject;
+		tx_entry->msg_data.iov[1].iov_len = data_len;
+		tx_entry->msg_data.iov_cnt = 2;
 	} else {
-		memcpy(&send_entry->msg_data.iov[1], &msg->msg_iov[0],
+		memcpy(&tx_entry->msg_data.iov[1], &msg->msg_iov[0],
 		       msg->iov_count * sizeof(struct iovec));
 
 	}
 
+	tx_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			    flags | FI_MSG | FI_SEND);
+
 	if (flags & FI_REMOTE_CQ_DATA) {
-		send_entry->msg_hdr.flags |= OFI_REMOTE_CQ_DATA;
-		send_entry->msg_hdr.data = htonll(msg->data);
+		tx_entry->msg_hdr.hdr.flags |= OFI_REMOTE_CQ_DATA;
+		tx_entry->msg_hdr.hdr.data = htonll(msg->data);
+	}
+
+	if (flags & (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)) {
+		tx_entry->msg_hdr.hdr.flags |= OFI_DELIVERY_COMPLETE;
+		tx_entry->flags &= ~FI_COMPLETION;
 	}
 
-	send_entry->msg_hdr.flags = htonl(send_entry->msg_hdr.flags);
-	send_entry->ep = tcpx_ep;
-	send_entry->context = msg->context;
-	send_entry->done_len = 0;
+	tx_entry->msg_hdr.hdr.flags = htonl(tx_entry->msg_hdr.hdr.flags);
+	tx_entry->ep = tcpx_ep;
+	tx_entry->context = msg->context;
+	tx_entry->done_len = 0;
 
-	dlist_insert_tail(&send_entry->entry, &tcpx_ep->tx_queue);
+	fastlock_acquire(&tcpx_ep->lock);
+	tcpx_tx_queue_insert(tcpx_ep, tx_entry);
+	fastlock_release(&tcpx_ep->lock);
 	return FI_SUCCESS;
-err:
-	pe_entry_release(send_entry);
-	return ret;
 }
 
 static ssize_t tcpx_send(struct fid_ep *ep, const void *buf, size_t len, void *desc,
 			 fi_addr_t dest_addr, void *context)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_xfer_entry *tx_entry;
 
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.desc = &desc;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.context = context;
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+
+	tx_entry = tcpx_alloc_send_entry(tcpx_ep);
+	if (!tx_entry)
+		return -FI_EAGAIN;
 
-	return tcpx_sendmsg(ep, &msg, 0);
+	tx_entry->msg_hdr.hdr.size = htonll(len + sizeof(tx_entry->msg_hdr));
+	tx_entry->msg_data.iov[0].iov_base = (void *) &tx_entry->msg_hdr;
+	tx_entry->msg_data.iov[0].iov_len = sizeof(tx_entry->msg_hdr);
+	tx_entry->msg_data.iov[1].iov_base = (void *) buf;
+	tx_entry->msg_data.iov[1].iov_len = len;
+	tx_entry->msg_data.iov_cnt = 2;
+	tx_entry->context = context;
+	tx_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			   FI_MSG | FI_SEND);
+
+	tx_entry->msg_hdr.hdr.flags = 0;
+	fastlock_acquire(&tcpx_ep->lock);
+	tcpx_tx_queue_insert(tcpx_ep, tx_entry);
+	fastlock_release(&tcpx_ep->lock);
+	return FI_SUCCESS;
 }
 
 static ssize_t tcpx_sendv(struct fid_ep *ep, const struct iovec *iov, void **desc,
 			  size_t count, fi_addr_t dest_addr, void *context)
 {
-	struct fi_msg msg;
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_xfer_entry *tx_entry;
+	uint64_t data_len;
 
-	msg.msg_iov = iov;
-	msg.desc = desc;
-	msg.iov_count = count;
-	msg.addr = dest_addr;
-	msg.context = context;
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+
+	tx_entry = tcpx_alloc_send_entry(tcpx_ep);
+	if (!tx_entry)
+		return -FI_EAGAIN;
 
-	return tcpx_sendmsg(ep, &msg, 0);
+	assert(count <= TCPX_IOV_LIMIT);
+	data_len = ofi_total_iov_len(iov, count);
+	tx_entry->msg_hdr.hdr.size = htonll(data_len + sizeof(tx_entry->msg_hdr));
+	tx_entry->msg_data.iov[0].iov_base = (void *) &tx_entry->msg_hdr;
+	tx_entry->msg_data.iov[0].iov_len = sizeof(tx_entry->msg_hdr);
+	tx_entry->msg_data.iov_cnt = count + 1;
+	memcpy(&tx_entry->msg_data.iov[1], &iov[0],
+	       count * sizeof(struct iovec));
+
+	tx_entry->msg_hdr.hdr.flags = 0;
+	tx_entry->context = context;
+	tx_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			   FI_MSG | FI_SEND);
+
+	fastlock_acquire(&tcpx_ep->lock);
+	tcpx_tx_queue_insert(tcpx_ep, tx_entry);
+	fastlock_release(&tcpx_ep->lock);
+	return FI_SUCCESS;
 }
 
 
 static ssize_t tcpx_inject(struct fid_ep *ep, const void *buf, size_t len,
 			   fi_addr_t dest_addr)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_xfer_entry *tx_entry;
+
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
 
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
-	msg.msg_iov = &msg_iov;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.context = NULL;
+	tx_entry = tcpx_alloc_send_entry(tcpx_ep);
+	if (!tx_entry)
+		return -FI_EAGAIN;
 
-	return tcpx_sendmsg(ep, &msg, FI_INJECT | TCPX_NO_COMPLETION);
+	assert(len <= TCPX_MAX_INJECT_SZ);
+	tx_entry->msg_hdr.hdr.size = htonll(len + sizeof(tx_entry->msg_hdr));
+	tx_entry->msg_data.iov[0].iov_base = (void *) &tx_entry->msg_hdr;
+	tx_entry->msg_data.iov[0].iov_len = sizeof(tx_entry->msg_hdr);
+	memcpy(tx_entry->msg_data.inject, (char *) buf, len);
+	tx_entry->msg_data.iov[1].iov_base = (void *)tx_entry->msg_data.inject;
+	tx_entry->msg_data.iov[1].iov_len = len;
+	tx_entry->msg_data.iov_cnt = 2;
+
+	tx_entry->msg_hdr.hdr.flags = 0;
+	tx_entry->flags = FI_MSG | FI_SEND;
+
+	fastlock_acquire(&tcpx_ep->lock);
+	tcpx_tx_queue_insert(tcpx_ep, tx_entry);
+	fastlock_release(&tcpx_ep->lock);
+	return FI_SUCCESS;
 }
 
 static ssize_t tcpx_senddata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
 			     uint64_t data, fi_addr_t dest_addr, void *context)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_xfer_entry *tx_entry;
+
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+
+	tx_entry = tcpx_alloc_send_entry(tcpx_ep);
+	if (!tx_entry)
+		return -FI_EAGAIN;
 
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
+	tx_entry->msg_hdr.hdr.size = htonll(len + sizeof(tx_entry->msg_hdr));
+	tx_entry->msg_data.iov[0].iov_base = (void *) &tx_entry->msg_hdr;
+	tx_entry->msg_data.iov[0].iov_len = sizeof(tx_entry->msg_hdr);
+	tx_entry->msg_data.iov[1].iov_base = (void *) buf;
+	tx_entry->msg_data.iov[1].iov_len = len;
+	tx_entry->msg_data.iov_cnt = 2;
 
-	msg.msg_iov = &msg_iov;
-	msg.desc = NULL;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.context = NULL;
-	msg.data = data;
+	tx_entry->msg_hdr.hdr.flags = htonl(OFI_REMOTE_CQ_DATA);
+	tx_entry->msg_hdr.hdr.data = htonll(data);
 
-	return tcpx_sendmsg(ep, &msg, FI_REMOTE_CQ_DATA);
+	tx_entry->context = context;
+	tx_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			   FI_MSG | FI_SEND);
+
+	fastlock_acquire(&tcpx_ep->lock);
+	tcpx_tx_queue_insert(tcpx_ep, tx_entry);
+	fastlock_release(&tcpx_ep->lock);
+	return FI_SUCCESS;
 }
 
 static ssize_t tcpx_injectdata(struct fid_ep *ep, const void *buf, size_t len,
 			       uint64_t data, fi_addr_t dest_addr)
 {
-	struct fi_msg msg;
-	struct iovec msg_iov;
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_xfer_entry *tx_entry;
+
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+
+	tx_entry = tcpx_alloc_send_entry(tcpx_ep);
+	if (!tx_entry)
+		return -FI_EAGAIN;
 
-	msg_iov.iov_base = (void *) buf;
-	msg_iov.iov_len = len;
+	assert(len <= TCPX_MAX_INJECT_SZ);
+	tx_entry->msg_hdr.hdr.size = htonll(len + sizeof(tx_entry->msg_hdr));
 
-	msg.msg_iov = &msg_iov;
-	msg.desc = NULL;
-	msg.iov_count = 1;
-	msg.addr = dest_addr;
-	msg.context = NULL;
-	msg.data = 0;
+	tx_entry->msg_data.iov[0].iov_base = (void *) &tx_entry->msg_hdr;
+	tx_entry->msg_data.iov[0].iov_len = sizeof(tx_entry->msg_hdr);
+	memcpy(tx_entry->msg_data.inject, (char *) buf, len);
+	tx_entry->msg_data.iov[1].iov_base = (void *)tx_entry->msg_data.inject;
+	tx_entry->msg_data.iov[1].iov_len = len;
+	tx_entry->msg_data.iov_cnt = 2;
 
-	return tcpx_sendmsg(ep, &msg, FI_REMOTE_CQ_DATA | FI_INJECT |
-			    TCPX_NO_COMPLETION);
+	tx_entry->msg_hdr.hdr.flags = htonl(OFI_REMOTE_CQ_DATA);
+	tx_entry->msg_hdr.hdr.data = htonll(data);
+	tx_entry->flags = FI_MSG | FI_SEND ;
+
+	fastlock_acquire(&tcpx_ep->lock);
+	tcpx_tx_queue_insert(tcpx_ep, tx_entry);
+	fastlock_release(&tcpx_ep->lock);
+	return FI_SUCCESS;
 }
 
 static struct fi_ops_msg tcpx_msg_ops = {
@@ -305,19 +428,14 @@ static int tcpx_ep_connect(struct fid_ep *ep, const void *addr,
 			   const void *param, size_t paramlen)
 {
 	struct tcpx_ep *tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
-	struct poll_fd_info *fd_info;
-	struct util_fabric *util_fabric;
-	struct tcpx_fabric *tcpx_fabric;
+	struct tcpx_cm_context *cm_ctx;
 	int ret;
 
-	util_fabric = tcpx_ep->util_ep.domain->fabric;
-	tcpx_fabric = container_of(util_fabric, struct tcpx_fabric, util_fabric);
-
 	if (!addr || !tcpx_ep->conn_fd || paramlen > TCPX_MAX_CM_DATA_SIZE)
 		return -FI_EINVAL;
 
-	fd_info = calloc(1, sizeof(*fd_info));
-	if (!fd_info) {
+	cm_ctx = calloc(1, sizeof(*cm_ctx));
+	if (!cm_ctx) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
 			"cannot allocate memory \n");
 		return -FI_ENOMEM;
@@ -325,91 +443,163 @@ static int tcpx_ep_connect(struct fid_ep *ep, const void *addr,
 
 	ret = connect(tcpx_ep->conn_fd, (struct sockaddr *) addr,
 		      (socklen_t) ofi_sizeofaddr(addr));
-	if (ret && errno != FI_EINPROGRESS) {
-		free(fd_info);
-		return -errno;
+	if (ret && ofi_sockerr() != FI_EINPROGRESS) {
+		ret =  -ofi_sockerr();
+		goto err;
 	}
 
-	fd_info->fid = &tcpx_ep->util_ep.ep_fid.fid;
-	fd_info->flags = POLL_MGR_FREE;
-	fd_info->type = CONNECT_SOCK;
-	fd_info->state = ESTABLISH_CONN;
+	cm_ctx->fid = &tcpx_ep->util_ep.ep_fid.fid;
+	cm_ctx->type = CLIENT_SEND_CONNREQ;
 
 	if (paramlen) {
-		fd_info->cm_data_sz = paramlen;
-		memcpy(fd_info->cm_data, param, paramlen);
+		cm_ctx->cm_data_sz = paramlen;
+		memcpy(cm_ctx->cm_data, param, paramlen);
 	}
 
-	fastlock_acquire(&tcpx_fabric->poll_mgr.lock);
-	dlist_insert_tail(&fd_info->entry, &tcpx_fabric->poll_mgr.list);
-	fastlock_release(&tcpx_fabric->poll_mgr.lock);
-	fd_signal_set(&tcpx_fabric->poll_mgr.signal);
+	ret = ofi_wait_fd_add(tcpx_ep->util_ep.eq->wait, tcpx_ep->conn_fd,
+			      FI_EPOLL_OUT, tcpx_eq_wait_try_func, NULL,cm_ctx);
+	if (ret)
+		goto err;
+
+	tcpx_ep->util_ep.eq->wait->signal(tcpx_ep->util_ep.eq->wait);
 	return 0;
+err:
+	free(cm_ctx);
+	return ret;
 }
 
 static int tcpx_ep_accept(struct fid_ep *ep, const void *param, size_t paramlen)
 {
 	struct tcpx_ep *tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
-	struct poll_fd_info *fd_info;
-	struct util_fabric *util_fabric;
-	struct tcpx_fabric *tcpx_fabric;
-
-	util_fabric = tcpx_ep->util_ep.domain->fabric;
-	tcpx_fabric = container_of(util_fabric, struct tcpx_fabric, util_fabric);
+	struct tcpx_cm_context *cm_ctx;
+	int ret;
 
 	if (tcpx_ep->conn_fd == INVALID_SOCKET)
 		return -FI_EINVAL;
 
-	fd_info = calloc(1, sizeof(*fd_info));
-	if (!fd_info) {
+	cm_ctx = calloc(1, sizeof(*cm_ctx));
+	if (!cm_ctx) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
 			"cannot allocate memory \n");
 		return -FI_ENOMEM;
 	}
 
-	fd_info->fid = &tcpx_ep->util_ep.ep_fid.fid;
-	fd_info->flags = POLL_MGR_FREE;
-	fd_info->type = ACCEPT_SOCK;
+	cm_ctx->fid = &tcpx_ep->util_ep.ep_fid.fid;
+	cm_ctx->type = SERVER_SEND_CM_ACCEPT;
 	if (paramlen) {
-		fd_info->cm_data_sz = paramlen;
-		memcpy(fd_info->cm_data, param, paramlen);
+		cm_ctx->cm_data_sz = paramlen;
+		memcpy(cm_ctx->cm_data, param, paramlen);
 	}
 
-	fastlock_acquire(&tcpx_fabric->poll_mgr.lock);
-	dlist_insert_tail(&fd_info->entry, &tcpx_fabric->poll_mgr.list);
-	fastlock_release(&tcpx_fabric->poll_mgr.lock);
-	fd_signal_set(&tcpx_fabric->poll_mgr.signal);
+	ret = ofi_wait_fd_add(tcpx_ep->util_ep.eq->wait, tcpx_ep->conn_fd,
+			      FI_EPOLL_OUT, tcpx_eq_wait_try_func, NULL, cm_ctx);
+	if (ret) {
+		free(cm_ctx);
+		return ret;
+	}
+	tcpx_ep->util_ep.eq->wait->signal(tcpx_ep->util_ep.eq->wait);
 	return 0;
 }
 
 static int tcpx_ep_shutdown(struct fid_ep *ep, uint64_t flags)
 {
 	struct tcpx_ep *tcpx_ep;
-	struct fi_eq_cm_entry eq_entry;
 	int ret;
 
 	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
 
 	ret = ofi_shutdown(tcpx_ep->conn_fd, SHUT_RDWR);
-	if (ret && errno != ENOTCONN) {
+	if (ret && ofi_sockerr() != ENOTCONN) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_DATA, "ep shutdown unsuccessful\n");
-		return -errno;
 	}
 
-	eq_entry.fid = &ep->fid;
-	ret = fi_eq_write(&tcpx_ep->util_ep.eq->eq_fid, FI_SHUTDOWN,
-			  &eq_entry, sizeof(eq_entry), 0);
-	if (ret < 0) {
+	fastlock_acquire(&tcpx_ep->lock);
+	ret = tcpx_ep_shutdown_report(tcpx_ep, &ep->fid);
+	fastlock_release(&tcpx_ep->lock);
+	if (ret) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_DATA, "Error writing to EQ\n");
 	}
+
+	return ret;
+}
+
+static int tcpx_pep_sock_create(struct tcpx_pep *pep)
+{
+	int ret, af;
+
+	switch (pep->info.addr_format) {
+	case FI_SOCKADDR:
+	case FI_SOCKADDR_IN:
+	case FI_SOCKADDR_IN6:
+		af = ((struct sockaddr *)pep->info.src_addr)->sa_family;
+		break;
+	default:
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+			"invalid source address format\n");
+		return -FI_EINVAL;
+	}
+
+	pep->sock = ofi_socket(af, SOCK_STREAM, 0);
+	if (pep->sock == INVALID_SOCKET) {
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+			"failed to create listener: %s\n",
+			strerror(ofi_sockerr()));
+		return -FI_EIO;
+	}
+
+	ret = tcpx_setup_socket(pep->sock);
+	if (ret) {
+		goto err;
+	}
+
+	ret = bind(pep->sock, pep->info.src_addr,
+		   (socklen_t) pep->info.src_addrlen);
+	if (ret) {
+		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+			"failed to bind listener: %s\n",
+			strerror(ofi_sockerr()));
+		goto err;
+	}
 	return FI_SUCCESS;
+err:
+	ofi_close_socket(pep->sock);
+	pep->sock = INVALID_SOCKET;
+	return ret;
+}
+
+static int tcpx_ep_getname(fid_t fid, void *addr, size_t *addrlen)
+{
+	struct tcpx_ep *tcpx_ep;
+	size_t addrlen_in = *addrlen;
+	int ret;
+
+	tcpx_ep = container_of(fid, struct tcpx_ep, util_ep.ep_fid);
+	ret = ofi_getsockname(tcpx_ep->conn_fd, addr, (socklen_t *)addrlen);
+	if (ret)
+		return -ofi_sockerr();
+
+	return (addrlen_in < *addrlen)? -FI_ETOOSMALL: FI_SUCCESS;
+}
+
+static int tcpx_ep_getpeer(struct fid_ep *ep, void *addr, size_t *addrlen)
+{
+	struct tcpx_ep *tcpx_ep;
+	size_t addrlen_in = *addrlen;
+	int ret;
+
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+	ret = ofi_getpeername(tcpx_ep->conn_fd, addr, (socklen_t *)addrlen);
+	if (ret)
+		return -ofi_sockerr();
+
+	return (addrlen_in < *addrlen)? -FI_ETOOSMALL: FI_SUCCESS;
 }
 
 static struct fi_ops_cm tcpx_cm_ops = {
 	.size = sizeof(struct fi_ops_cm),
 	.setname = fi_no_setname,
-	.getname = fi_no_getname,
-	.getpeer = fi_no_getpeer,
+	.getname = tcpx_ep_getname,
+	.getpeer = tcpx_ep_getpeer,
 	.connect = tcpx_ep_connect,
 	.listen = fi_no_listen,
 	.accept = tcpx_ep_accept,
@@ -418,39 +608,65 @@ static struct fi_ops_cm tcpx_cm_ops = {
 	.join = fi_no_join,
 };
 
-static void tcpx_ep_tx_rx_queues_release(struct tcpx_ep *ep,
-					 struct tcpx_progress *progress)
+static void tcpx_ep_tx_rx_queues_release(struct tcpx_ep *ep)
 {
-	struct dlist_entry *entry;
-	struct tcpx_pe_entry *pe_entry;
+	struct slist_entry *entry;
+	struct tcpx_xfer_entry *xfer_entry;
+	struct tcpx_cq *tcpx_cq;
+
+	fastlock_acquire(&ep->lock);
+	while (!slist_empty(&ep->tx_queue)) {
+		entry = ep->tx_queue.head;
+		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
+		slist_remove_head(&ep->tx_queue);
+		tcpx_cq = container_of(xfer_entry->ep->util_ep.tx_cq,
+				       struct tcpx_cq, util_cq);
+		tcpx_xfer_entry_release(tcpx_cq, xfer_entry);
+	}
+
+	while (!slist_empty(&ep->rx_queue)) {
+		entry = ep->rx_queue.head;
+		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
+		slist_remove_head(&ep->rx_queue);
+		tcpx_cq = container_of(xfer_entry->ep->util_ep.rx_cq,
+				       struct tcpx_cq, util_cq);
+		tcpx_xfer_entry_release(tcpx_cq, xfer_entry);
+	}
 
-	while (!dlist_empty(&ep->tx_queue)) {
-		entry = ep->tx_queue.next;
-		pe_entry = container_of(entry, struct tcpx_pe_entry, entry);
-		dlist_remove(entry);
-		pe_entry_release(pe_entry);
+	while (!slist_empty(&ep->rma_read_queue)) {
+		entry = ep->rma_read_queue.head;
+		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
+		slist_remove_head(&ep->rma_read_queue);
+		tcpx_cq = container_of(xfer_entry->ep->util_ep.tx_cq,
+				       struct tcpx_cq, util_cq);
+		tcpx_xfer_entry_release(tcpx_cq, xfer_entry);
 	}
 
-	while (!dlist_empty(&ep->rx_queue)) {
-		entry = ep->rx_queue.next;
-		pe_entry = container_of(entry, struct tcpx_pe_entry, entry);
-		dlist_remove(entry);
-		pe_entry_release(pe_entry);
+	while (!slist_empty(&ep->tx_rsp_pend_queue)) {
+		entry = ep->tx_rsp_pend_queue.head;
+		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
+		slist_remove_head(&ep->tx_rsp_pend_queue);
+		tcpx_cq = container_of(xfer_entry->ep->util_ep.tx_cq,
+				       struct tcpx_cq, util_cq);
+		tcpx_xfer_entry_release(tcpx_cq, xfer_entry);
 	}
+
+	fastlock_release(&ep->lock);
 }
 
 static int tcpx_ep_close(struct fid *fid)
 {
-	struct tcpx_ep *ep;
-	struct tcpx_domain *tcpx_domain;
+	struct tcpx_ep *ep = container_of(fid, struct tcpx_ep,
+					  util_ep.ep_fid.fid);
 
-	ep = container_of(fid, struct tcpx_ep, util_ep.ep_fid.fid);
-	tcpx_domain = container_of(ep->util_ep.domain,
-				   struct tcpx_domain, util_domain);
+	tcpx_ep_tx_rx_queues_release(ep);
+	tcpx_cq_wait_ep_del(ep);
+	if (ep->util_ep.eq->wait)
+		ofi_wait_fd_del(ep->util_ep.eq->wait, ep->conn_fd);
 
-	tcpx_ep_tx_rx_queues_release(ep, &tcpx_domain->progress);
 	ofi_close_socket(ep->conn_fd);
 	ofi_endpoint_close(&ep->util_ep);
+	fastlock_destroy(&ep->lock);
 
 	free(ep);
 	return 0;
@@ -473,10 +689,18 @@ static int tcpx_ep_ctrl(struct fid *fid, int command, void *arg)
 }
 static int tcpx_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 {
-	struct util_ep *util_ep;
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_rx_ctx *rx_ctx;
+
+	tcpx_ep = container_of(fid, struct tcpx_ep, util_ep.ep_fid.fid);
+
+	if (bfid->fclass == FI_CLASS_SRX_CTX) {
+		rx_ctx = container_of(bfid, struct tcpx_rx_ctx, rx_fid.fid);
+		tcpx_ep->srx_ctx = rx_ctx;
+		return FI_SUCCESS;
+	}
 
-	util_ep = container_of(fid, struct util_ep, ep_fid.fid);
-	return ofi_ep_bind(util_ep, bfid, flags);
+	return ofi_ep_bind(&tcpx_ep->util_ep, bfid, flags);
 }
 
 static struct fi_ops tcpx_ep_fi_ops = {
@@ -518,12 +742,17 @@ static struct fi_ops_ep tcpx_ep_ops = {
 	.tx_size_left = fi_no_tx_size_left,
 };
 
+static void tcpx_empty_progress(struct tcpx_ep *ep)
+{
+}
+
 int tcpx_endpoint(struct fid_domain *domain, struct fi_info *info,
 		  struct fid_ep **ep_fid, void *context)
 {
 	struct tcpx_ep *ep;
+	struct tcpx_pep *pep;
 	struct tcpx_conn_handle *handle;
-	int af, ret;
+	int ret;
 
 	ep = calloc(1, sizeof(*ep));
 	if (!ep)
@@ -535,37 +764,61 @@ int tcpx_endpoint(struct fid_domain *domain, struct fi_info *info,
 		goto err1;
 
 	if (info->handle) {
-		handle = container_of(info->handle, struct tcpx_conn_handle,
-				      handle);
-		ep->conn_fd = handle->conn_fd;
-		free(handle);
+		if (((fid_t) info->handle)->fclass == FI_CLASS_PEP) {
+			pep = container_of(info->handle, struct tcpx_pep,
+					   util_pep.pep_fid.fid);
+
+			ep->conn_fd = pep->sock;
+			pep->sock = INVALID_SOCKET;
+		} else {
+			handle = container_of(info->handle,
+					      struct tcpx_conn_handle, handle);
+			ep->conn_fd = handle->conn_fd;
+			free(handle);
+
+			ret = tcpx_setup_socket(ep->conn_fd);
+			if (ret)
+				goto err3;
+		}
 	} else {
-		if (info->src_addr)
-			af = ((const struct sockaddr *) info->src_addr)->sa_family;
-		else if (info->dest_addr)
-			af = ((const struct sockaddr *) info->dest_addr)->sa_family;
-		else
-			af = ofi_get_sa_family(info->addr_format);
-
-		ep->conn_fd = ofi_socket(af, SOCK_STREAM, 0);
+		ep->conn_fd = ofi_socket(ofi_get_sa_family(info), SOCK_STREAM, 0);
 		if (ep->conn_fd == INVALID_SOCKET) {
-			ret = -errno;
+			ret = -ofi_sockerr();
 			goto err2;
 		}
+
+		ret = tcpx_setup_socket(ep->conn_fd);
+		if (ret)
+			goto err3;
 	}
-	ret = tcpx_setup_socket(ep->conn_fd);
+
+	ep->cm_state = TCPX_EP_CONNECTING;
+	ep->progress_func = tcpx_empty_progress;
+	ret = fastlock_init(&ep->lock);
 	if (ret)
 		goto err3;
 
-	dlist_init(&ep->rx_queue);
-	dlist_init(&ep->tx_queue);
+	ep->stage_buf.size = STAGE_BUF_SIZE;
+	ep->stage_buf.len = 0;
+	ep->stage_buf.off = 0;
+
+	slist_init(&ep->rx_queue);
+	slist_init(&ep->tx_queue);
+	slist_init(&ep->rma_read_queue);
+	slist_init(&ep->tx_rsp_pend_queue);
 
 	*ep_fid = &ep->util_ep.ep_fid;
 	(*ep_fid)->fid.ops = &tcpx_ep_fi_ops;
 	(*ep_fid)->ops = &tcpx_ep_ops;
 	(*ep_fid)->cm = &tcpx_cm_ops;
 	(*ep_fid)->msg = &tcpx_msg_ops;
+	(*ep_fid)->rma = &tcpx_rma_ops;
 
+	ep->get_rx_entry[ofi_op_msg] = tcpx_get_rx_entry_op_msg;
+	ep->get_rx_entry[ofi_op_tagged] = tcpx_get_rx_entry_op_invalid;
+	ep->get_rx_entry[ofi_op_read_req] = tcpx_get_rx_entry_op_read_req;
+	ep->get_rx_entry[ofi_op_read_rsp] = tcpx_get_rx_entry_op_read_rsp;
+	ep->get_rx_entry[ofi_op_write] =tcpx_get_rx_entry_op_write;
 	return 0;
 err3:
 	ofi_close_socket(ep->conn_fd);
@@ -579,25 +832,12 @@ err1:
 static int tcpx_pep_fi_close(struct fid *fid)
 {
 	struct tcpx_pep *pep;
-	struct tcpx_fabric *tcpx_fabric;
 
 	pep = container_of(fid, struct tcpx_pep, util_pep.pep_fid.fid);
+	if (pep->util_pep.eq)
+		ofi_wait_fd_del(pep->util_pep.eq->wait, pep->sock);
 
-	tcpx_fabric = container_of(pep->util_pep.fabric, struct tcpx_fabric,
-				   util_fabric);
-
-	/* It's possible to close the PEP before adding completes */
-	fastlock_acquire(&tcpx_fabric->poll_mgr.lock);
-	pep->poll_info.flags = POLL_MGR_DEL;
-	if (pep->poll_info.entry.next == pep->poll_info.entry.prev)
-		dlist_insert_tail(&pep->poll_info.entry, &tcpx_fabric->poll_mgr.list);
-
-	fastlock_release(&tcpx_fabric->poll_mgr.lock);
-	fd_signal_set(&tcpx_fabric->poll_mgr.signal);
-
-	while (!(pep->poll_info.flags & POLL_MGR_ACK))
-		sleep(0);
-
+	ofi_close_socket(pep->sock);
 	ofi_pep_close(&pep->util_pep);
 	free(pep);
 	return 0;
@@ -628,48 +868,88 @@ static struct fi_ops tcpx_pep_fi_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
+static int tcpx_pep_setname(fid_t fid, void *addr, size_t addrlen)
+{
+	struct tcpx_pep *tcpx_pep;
+
+	if ((addrlen != sizeof(struct sockaddr_in)) &&
+	    (addrlen != sizeof(struct sockaddr_in6)))
+		return -FI_EINVAL;
+
+	tcpx_pep = container_of(fid, struct tcpx_pep,
+				util_pep.pep_fid);
+
+	if (tcpx_pep->sock != INVALID_SOCKET) {
+		ofi_close_socket(tcpx_pep->sock);
+		tcpx_pep->sock = INVALID_SOCKET;
+	}
+
+	if (tcpx_pep->info.src_addr) {
+		free(tcpx_pep->info.src_addr);
+		tcpx_pep->info.src_addrlen = 0;
+	}
+
+
+	tcpx_pep->info.src_addr = mem_dup(addr, addrlen);
+	if (!tcpx_pep->info.src_addr)
+		return -FI_ENOMEM;
+	tcpx_pep->info.src_addrlen = addrlen;
+
+	return tcpx_pep_sock_create(tcpx_pep);
+}
+
+static int tcpx_pep_getname(fid_t fid, void *addr, size_t *addrlen)
+{
+	struct tcpx_pep *tcpx_pep;
+	size_t addrlen_in = *addrlen;
+	int ret;
+
+	tcpx_pep = container_of(fid, struct tcpx_pep, util_pep.pep_fid);
+	ret = ofi_getsockname(tcpx_pep->sock, addr, (socklen_t *)addrlen);
+	if (ret)
+		return -ofi_sockerr();
+
+	return (addrlen_in < *addrlen)? -FI_ETOOSMALL: FI_SUCCESS;
+}
+
 static int tcpx_pep_listen(struct fid_pep *pep)
 {
 	struct tcpx_pep *tcpx_pep;
-	struct tcpx_fabric *tcpx_fabric;
+	int ret;
 
 	tcpx_pep = container_of(pep,struct tcpx_pep, util_pep.pep_fid);
-	tcpx_fabric = container_of(tcpx_pep->util_pep.fabric,
-				   struct tcpx_fabric, util_fabric);
 
 	if (listen(tcpx_pep->sock, SOMAXCONN)) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
 			"socket listen failed\n");
-		return -errno;
+		return -ofi_sockerr();
 	}
 
-	fastlock_acquire(&tcpx_fabric->poll_mgr.lock);
-	dlist_insert_tail(&tcpx_pep->poll_info.entry, &tcpx_fabric->poll_mgr.list);
-	fastlock_release(&tcpx_fabric->poll_mgr.lock);
-	fd_signal_set(&tcpx_fabric->poll_mgr.signal);
+	ret = ofi_wait_fd_add(tcpx_pep->util_pep.eq->wait, tcpx_pep->sock,
+			      FI_EPOLL_IN, tcpx_eq_wait_try_func,
+			      NULL, &tcpx_pep->cm_ctx);
 
-	return 0;
+	tcpx_pep->util_pep.eq->wait->signal(tcpx_pep->util_pep.eq->wait);
+	return ret;
 }
 
 static int tcpx_pep_reject(struct fid_pep *pep, fid_t handle,
-		    const void *param, size_t paramlen)
+			   const void *param, size_t paramlen)
 {
 	struct ofi_ctrl_hdr hdr;
 	struct tcpx_conn_handle *tcpx_handle;
+	int ret;
 
 	tcpx_handle = container_of(handle, struct tcpx_conn_handle, handle);
 
 	memset(&hdr, 0, sizeof(hdr));
 	hdr.version = OFI_CTRL_VERSION;
 	hdr.type = ofi_ctrl_nack;
-	hdr.seg_size = paramlen;
+	hdr.seg_size = htons((uint16_t) paramlen);
 
-	ofi_send_socket(tcpx_handle->conn_fd, &hdr,
-			sizeof(hdr), 0);
-
-	if (paramlen)
-		ofi_send_socket(tcpx_handle->conn_fd, param,
-				paramlen, 0);
+	ret = ofi_sendall_socket(tcpx_handle->conn_fd, &hdr, sizeof(hdr));
+	if (!ret && paramlen)
+		(void) ofi_sendall_socket(tcpx_handle->conn_fd, param, paramlen);
 
 	ofi_shutdown(tcpx_handle->conn_fd, SHUT_RDWR);
 	return ofi_close_socket(tcpx_handle->conn_fd);
@@ -677,8 +957,8 @@ static int tcpx_pep_reject(struct fid_pep *pep, fid_t handle,
 
 static struct fi_ops_cm tcpx_pep_cm_ops = {
 	.size = sizeof(struct fi_ops_cm),
-	.setname = fi_no_setname,
-	.getname = fi_no_getname,
+	.setname = tcpx_pep_setname,
+	.getname = tcpx_pep_getname,
 	.getpeer = fi_no_getpeer,
 	.connect = fi_no_connect,
 	.listen = tcpx_pep_listen,
@@ -726,15 +1006,11 @@ int tcpx_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
 		    struct fid_pep **pep, void *context)
 {
 	struct tcpx_pep *_pep;
-	struct addrinfo hints, *result, *iter;
-	char sa_ip[INET_ADDRSTRLEN] = {0};
-	char sa_port[NI_MAXSERV] = {0};
 	int ret;
 
 	if (!info) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,"invalid info\n");
 		return -FI_EINVAL;
-
 	}
 
 	ret = tcpx_verify_info(fabric->api_version, info);
@@ -749,89 +1025,25 @@ int tcpx_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
 	if (ret)
 		goto err1;
 
+	_pep->util_pep.pep_fid.fid.ops = &tcpx_pep_fi_ops;
+	_pep->util_pep.pep_fid.cm = &tcpx_pep_cm_ops;
+	_pep->util_pep.pep_fid.ops = &tcpx_pep_ops;
+
+
 	_pep->info = *info;
-	_pep->poll_info.fid = &_pep->util_pep.pep_fid.fid;
-	_pep->poll_info.type = PASSIVE_SOCK;
-	_pep->poll_info.flags = 0;
-	_pep->poll_info.cm_data_sz = 0;
-	dlist_init(&_pep->poll_info.entry);
+	_pep->cm_ctx.fid = &_pep->util_pep.pep_fid.fid;
+	_pep->cm_ctx.type = SERVER_SOCK_ACCEPT;
+	_pep->cm_ctx.cm_data_sz = 0;
 	_pep->sock = INVALID_SOCKET;
 
-	memset(&hints, 0, sizeof(hints));
-	hints.ai_family = AF_INET;
-	hints.ai_socktype = SOCK_STREAM;
-	hints.ai_flags = AI_PASSIVE;
+	*pep = &_pep->util_pep.pep_fid;
 
 	if (info->src_addr) {
-		switch (info->addr_format) {
-		case FI_SOCKADDR:
-		case FI_SOCKADDR_IN:
-		case FI_SOCKADDR_IN6:
-			ret = getnameinfo(info->src_addr,
-					  (socklen_t) info->src_addrlen,
-					  sa_ip, INET_ADDRSTRLEN,
-					  sa_port, NI_MAXSERV, 0);
-			if (ret) {
-				FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-					"pep initialization failed\n");
-				goto err2;
-			}
-			break;
-		default:
-			FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-				"invalid source address format\n");
-			ret = -FI_EINVAL;
+		ret = tcpx_pep_sock_create(_pep);
+		if (ret)
 			goto err2;
-		}
-		ret = getaddrinfo(sa_ip, sa_port, &hints, &result);
-	} else {
-		ret = getaddrinfo("localhost", NULL, &hints, &result);
-	}
-
-	if (ret) {
-		ret = -FI_EINVAL;
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,"getaddrinfo failed");
-		goto err2;
-	}
-
-	for (iter = result; iter; iter = iter->ai_next) {
-		_pep->sock = ofi_socket(iter->ai_family, iter->ai_socktype,
-					iter->ai_protocol);
-		if (_pep->sock == INVALID_SOCKET)
-			continue;
-
-		ret = tcpx_setup_socket(_pep->sock);
-		if (ret) {
-			ofi_close_socket(_pep->sock);
-			_pep->sock = INVALID_SOCKET;
-			continue;
-		}
-
-		if (bind(_pep->sock, result->ai_addr,
-			 (socklen_t) result->ai_addrlen)) {
-			FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-				"failed to bind listener: %s\n", strerror(errno));
-			ofi_close_socket(_pep->sock);
-			_pep->sock = INVALID_SOCKET;
-		} else {
-			break;
-		}
 	}
-	freeaddrinfo(result);
-
-	if (_pep->sock == INVALID_SOCKET) {
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-			"failed to create listener: %s\n", strerror(errno));
-		ret = -FI_EIO;
-		goto err2;
-	}
-
-	_pep->util_pep.pep_fid.fid.ops = &tcpx_pep_fi_ops;
-	_pep->util_pep.pep_fid.cm = &tcpx_pep_cm_ops;
-	_pep->util_pep.pep_fid.ops = &tcpx_pep_ops;
-
-	*pep = &_pep->util_pep.pep_fid;
-	return 0;
+	return FI_SUCCESS;
 err2:
 	ofi_pep_close(&_pep->util_pep);
 err1:
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_eq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_eq.c
new file mode 100644
index 000000000..8e7b16b5d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_eq.c
@@ -0,0 +1,99 @@
+/*
+ * Copyright (c) 2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdlib.h>
+#include <string.h>
+
+#include "tcpx.h"
+
+static ssize_t tcpx_eq_read(struct fid_eq *eq_fid, uint32_t *event,
+			    void *buf, size_t len, uint64_t flags)
+{
+	struct util_eq *eq;
+
+	eq = container_of(eq_fid, struct util_eq, eq_fid);
+
+	fastlock_acquire(&eq->lock);
+	if (slist_empty(&eq->list)) {
+		fastlock_release(&eq->lock);
+		tcpx_conn_mgr_run(eq);
+	} else {
+		fastlock_release(&eq->lock);
+	}
+	return ofi_eq_read(eq_fid, event, buf, len, flags);
+}
+
+static struct fi_ops_eq tcpx_eq_ops = {
+	.size = sizeof(struct fi_ops_eq),
+	.read = tcpx_eq_read,
+	.readerr = ofi_eq_readerr,
+	.sread = ofi_eq_sread,
+	.write = ofi_eq_write,
+	.strerror = ofi_eq_strerror,
+};
+
+int tcpx_eq_create(struct fid_fabric *fabric_fid, struct fi_eq_attr *attr,
+		   struct fid_eq **eq_fid, void *context)
+{
+	struct util_eq *eq;
+	struct fi_wait_attr wait_attr;
+	struct fid_wait *wait;
+	int ret;
+
+	ret = ofi_eq_create(fabric_fid, attr, eq_fid, context);
+	if (ret) {
+		FI_WARN(&tcpx_prov, FI_LOG_EQ,
+			"EQ creation failed\n");
+		return ret;
+	}
+
+	eq = container_of(*eq_fid, struct util_eq, eq_fid);
+	eq->eq_fid.ops	= &tcpx_eq_ops;
+
+	if (!eq->wait) {
+		memset(&wait_attr, 0, sizeof wait_attr);
+		wait_attr.wait_obj = FI_WAIT_FD;
+		ret = fi_wait_open(fabric_fid, &wait_attr, &wait);
+		if (ret) {
+			FI_WARN(&tcpx_prov, FI_LOG_EQ,
+				"opening wait failed\n");
+			goto err;
+		}
+		eq->internal_wait = 1;
+		eq->wait = container_of(wait, struct util_wait,
+					wait_fid);
+	}
+	return 0;
+err:
+	fi_close(&eq->eq_fid.fid);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_fabric.c
index 8e8fbddd2..3ff1b87f1 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_fabric.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_fabric.c
@@ -45,7 +45,7 @@ struct fi_ops_fabric tcpx_fabric_ops = {
 	.size = sizeof(struct fi_ops_fabric),
 	.domain = tcpx_domain_open,
 	.passive_ep = tcpx_passive_ep,
-	.eq_open = ofi_eq_create,
+	.eq_open = tcpx_eq_create,
 	.wait_open = ofi_wait_fd_open,
 	.trywait = ofi_trywait
 };
@@ -58,7 +58,6 @@ static int tcpx_fabric_close(fid_t fid)
 	tcpx_fabric = container_of(fid, struct tcpx_fabric,
 				   util_fabric.fabric_fid.fid);
 
-	tcpx_conn_mgr_close(tcpx_fabric);
 	ret = ofi_fabric_close(&tcpx_fabric->util_fabric);
 	if (ret)
 		return ret;
@@ -87,21 +86,14 @@ int tcpx_create_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
 
 	ret = ofi_fabric_init(&tcpx_prov, tcpx_info.fabric_attr, attr,
 			      &tcpx_fabric->util_fabric, context);
-	if (ret)
-		goto err;
+	if (ret) {
+		free(tcpx_fabric);
+		return ret;
+	}
 
 	*fabric = &tcpx_fabric->util_fabric.fabric_fid;
 	(*fabric)->fid.ops = &tcpx_fabric_fi_ops;
 	(*fabric)->ops = &tcpx_fabric_ops;
 
-	ret = tcpx_conn_mgr_init(tcpx_fabric);
-	if (ret)
-		goto err1;
-
 	return 0;
-err1:
-	ofi_fabric_close(&tcpx_fabric->util_fabric);
-err:
-	free(tcpx_fabric);
-	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_init.c
index e40182e8e..78b532e83 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_init.c
@@ -44,12 +44,15 @@
 #if HAVE_GETIFADDRS
 static void tcpx_getinfo_ifs(struct fi_info **info)
 {
+	char *tcpx_interface_name = NULL;
 	struct ifaddrs *ifaddrs, *ifa;
 	struct fi_info *head, *tail, *cur, *loopback;
 	size_t addrlen;
 	uint32_t addr_format;
 	int ret;
 
+	fi_param_get_str(&tcpx_prov, "iface", &tcpx_interface_name);
+
 	ret = ofi_getifaddrs(&ifaddrs);
 	if (ret)
 		return;
@@ -58,6 +61,18 @@ static void tcpx_getinfo_ifs(struct fi_info **info)
 	for (ifa = ifaddrs; ifa != NULL; ifa = ifa->ifa_next) {
 		if (ifa->ifa_addr == NULL || !(ifa->ifa_flags & IFF_UP))
 			continue;
+		if (tcpx_interface_name) {
+			if (strncmp(tcpx_interface_name, ifa->ifa_name,
+				    strlen(tcpx_interface_name)) != 0) {
+				FI_DBG(&tcpx_prov, FI_LOG_CORE,
+				       "Skip (%s) interface\n", ifa->ifa_name);
+				continue;
+			} else {
+				FI_DBG(&tcpx_prov, FI_LOG_CORE,
+				       "Matching interface (%s) found\n",
+				       ifa->ifa_name);
+			}
+		}
 
 		switch (ifa->ifa_addr->sa_family) {
 		case AF_INET:
@@ -107,18 +122,17 @@ static void tcpx_getinfo_ifs(struct fi_info **info)
 			assert(!tail->next);
 			tail->next = loopback;
 		}
-
-		fi_freeinfo(*info);
-		*info = head;
 	}
+	fi_freeinfo(*info);
+	*info = head;
 }
 #else
 #define tcpx_getinfo_ifs(info) do{ } while(0)
 #endif
 
 static int tcpx_getinfo(uint32_t version, const char *node, const char *service,
-			 uint64_t flags, const struct fi_info *hints,
-			 struct fi_info **info)
+			uint64_t flags, const struct fi_info *hints,
+			struct fi_info **info)
 {
 	int ret;
 
@@ -141,7 +155,7 @@ static void fi_tcp_fini(void)
 struct fi_provider tcpx_prov = {
 	.name = "tcp",
 	.version = FI_VERSION(TCPX_MAJOR_VERSION,TCPX_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = tcpx_getinfo,
 	.fabric = tcpx_create_fabric,
 	.cleanup = fi_tcp_fini,
@@ -149,5 +163,11 @@ struct fi_provider tcpx_prov = {
 
 TCP_INI
 {
+#if HAVE_TCP_DL
+	ofi_pmem_init();
+#endif
+	fi_param_define(&tcpx_prov, "iface", FI_PARAM_STRING,
+			"Specify interface name");
+
 	return &tcpx_prov;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_progress.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_progress.c
index 08c383f48..39088c9ec 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_progress.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_progress.c
@@ -42,155 +42,642 @@
 #include <ofi_util.h>
 #include <ofi_iov.h>
 
-int tcpx_progress_close(struct tcpx_progress *progress)
+static void tcpx_cq_report_xfer_fail(struct tcpx_ep *tcpx_ep, int err)
 {
-	util_buf_pool_destroy(progress->pe_entry_pool);
+	struct slist_entry *entry;
+	struct tcpx_xfer_entry *tx_entry;
+	struct tcpx_cq *tcpx_cq;
+
+	while (!slist_empty(&tcpx_ep->tx_rsp_pend_queue)) {
+		entry = slist_remove_head(&tcpx_ep->tx_rsp_pend_queue);
+		tx_entry = container_of(entry, struct tcpx_xfer_entry, entry);
+		tcpx_cq_report_completion(tx_entry->ep->util_ep.tx_cq,
+					  tx_entry, -err);
+
+		tcpx_cq = container_of(tx_entry->ep->util_ep.tx_cq,
+				       struct tcpx_cq, util_cq);
+		tcpx_xfer_entry_release(tcpx_cq, tx_entry);
+	}
+}
+
+static void tcpx_report_error(struct tcpx_ep *tcpx_ep, int err)
+{
+	struct fi_eq_err_entry err_entry = {0};
+
+	tcpx_cq_report_xfer_fail(tcpx_ep, err);
+	err_entry.fid = &tcpx_ep->util_ep.ep_fid.fid;
+	err_entry.context = tcpx_ep->util_ep.ep_fid.fid.context;
+	err_entry.err = -err;
+
+	fi_eq_write(&tcpx_ep->util_ep.eq->eq_fid, FI_NOTIFY,
+		    &err_entry, sizeof(err_entry), UTIL_FLAG_ERROR);
+}
+
+int tcpx_ep_shutdown_report(struct tcpx_ep *ep, fid_t fid)
+{
+	struct fi_eq_cm_entry cm_entry = {0};
+	ssize_t len;
+
+	if (ep->cm_state == TCPX_EP_SHUTDOWN)
+		return FI_SUCCESS;
+	tcpx_cq_report_xfer_fail(ep, -FI_ENOTCONN);
+	ep->cm_state = TCPX_EP_SHUTDOWN;
+	cm_entry.fid = fid;
+	len =  fi_eq_write(&ep->util_ep.eq->eq_fid, FI_SHUTDOWN,
+			   &cm_entry, sizeof(cm_entry), 0);
+	if (len < 0)
+		return (int) len;
+
 	return FI_SUCCESS;
 }
 
-struct tcpx_pe_entry *pe_entry_alloc(struct tcpx_progress *progress)
+void process_tx_entry(struct tcpx_xfer_entry *tx_entry)
 {
-	struct tcpx_pe_entry *pe_entry;
+	struct tcpx_cq *tcpx_cq;
+	int ret;
 
-	pe_entry = util_buf_alloc(progress->pe_entry_pool);
-	if (!pe_entry) {
-		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN,"failed to get buffer\n");
-		return NULL;
+	ret = tcpx_send_msg(tx_entry);
+	if (OFI_SOCK_TRY_SND_RCV_AGAIN(-ret))
+		return;
+
+	if (!ret)
+		goto done;
+
+	FI_WARN(&tcpx_prov, FI_LOG_DOMAIN, "msg send failed\n");
+
+	if (ret == -FI_ENOTCONN)
+		tcpx_ep_shutdown_report(tx_entry->ep,
+					&tx_entry->ep->util_ep.ep_fid.fid);
+done:
+	tcpx_cq_report_completion(tx_entry->ep->util_ep.tx_cq,
+				  tx_entry, -ret);
+	slist_remove_head(&tx_entry->ep->tx_queue);
+
+	if (ntohl(tx_entry->msg_hdr.hdr.flags) &
+	    (OFI_DELIVERY_COMPLETE | OFI_COMMIT_COMPLETE)) {
+		tx_entry->flags |= FI_COMPLETION;
+		slist_insert_tail(&tx_entry->entry,
+				  &tx_entry->ep->tx_rsp_pend_queue);
+		return;
 	}
-	memset(pe_entry, 0, sizeof(*pe_entry));
-	return pe_entry;
+
+	tcpx_cq = container_of(tx_entry->ep->util_ep.tx_cq,
+			       struct tcpx_cq, util_cq);
+	tcpx_xfer_entry_release(tcpx_cq, tx_entry);
 }
 
-static void report_pe_entry_completion(struct tcpx_pe_entry *pe_entry, int err)
+static int tcpx_prepare_rx_entry_resp(struct tcpx_xfer_entry *rx_entry)
 {
-	struct fi_cq_err_entry err_entry;
-	struct tcpx_ep *ep = pe_entry->ep;
-	struct util_cq *cq = NULL;
-	struct util_cntr *cntr = NULL;
+	struct tcpx_cq *tcpx_rx_cq, *tcpx_tx_cq;
+	struct tcpx_xfer_entry *resp_entry;
+
+	tcpx_tx_cq = container_of(rx_entry->ep->util_ep.tx_cq,
+			       struct tcpx_cq, util_cq);
+
+	resp_entry = tcpx_xfer_entry_alloc(tcpx_tx_cq, TCPX_OP_MSG_RESP);
+	if (!resp_entry)
+		return -FI_EAGAIN;
+
+	resp_entry->msg_data.iov[0].iov_base = (void *) &resp_entry->msg_hdr;
+	resp_entry->msg_data.iov[0].iov_len = sizeof(resp_entry->msg_hdr);
+	resp_entry->msg_data.iov_cnt = 1;
+
+	resp_entry->msg_hdr.hdr.op = ofi_op_msg;
+	resp_entry->msg_hdr.hdr.size = htonll(sizeof(resp_entry->msg_hdr));
+
+	resp_entry->flags = 0;
+	resp_entry->context = NULL;
+	resp_entry->done_len = 0;
+	resp_entry->ep = rx_entry->ep;
+	tcpx_tx_queue_insert(resp_entry->ep, resp_entry);
+
+	tcpx_cq_report_completion(rx_entry->ep->util_ep.rx_cq,
+				  rx_entry, 0);
+	slist_remove_head(&rx_entry->ep->rx_queue);
+	tcpx_rx_cq = container_of(rx_entry->ep->util_ep.rx_cq,
+			       struct tcpx_cq, util_cq);
+	tcpx_xfer_entry_release(tcpx_rx_cq, rx_entry);
+	return FI_SUCCESS;
+}
 
-	if (pe_entry->flags & TCPX_NO_COMPLETION) {
-		return;
+static int process_rx_entry(struct tcpx_xfer_entry *rx_entry)
+{
+	struct tcpx_cq *tcpx_cq;
+	int ret;
+
+	ret = tcpx_recv_msg_data(rx_entry);
+	if (OFI_SOCK_TRY_SND_RCV_AGAIN(-ret))
+		return ret;
+
+	if (!ret)
+		goto done;
+
+	FI_WARN(&tcpx_prov, FI_LOG_DOMAIN, "msg recv Failed ret = %d\n", ret);
+
+	if (ret == -FI_ENOTCONN)
+		tcpx_ep_shutdown_report(rx_entry->ep,
+					&rx_entry->ep->util_ep.ep_fid.fid);
+done:
+	if (ntohl(rx_entry->msg_hdr.hdr.flags) & OFI_DELIVERY_COMPLETE) {
+
+		if (tcpx_prepare_rx_entry_resp(rx_entry))
+			rx_entry->ep->cur_rx_proc_fn = tcpx_prepare_rx_entry_resp;
+
+		return FI_SUCCESS;
 	}
 
-	switch (pe_entry->msg_hdr.op_data) {
-	case TCPX_OP_MSG_SEND:
-		cq = ep->util_ep.tx_cq;
-		cntr = ep->util_ep.tx_cntr;
-		break;
-	case TCPX_OP_MSG_RECV:
-		cq = ep->util_ep.rx_cq;
-		cntr = ep->util_ep.rx_cntr;
-		break;
-	default:
+	tcpx_cq_report_completion(rx_entry->ep->util_ep.rx_cq,
+				  rx_entry, -ret);
+	tcpx_cq = container_of(rx_entry->ep->util_ep.rx_cq,
+			       struct tcpx_cq, util_cq);
+	tcpx_xfer_entry_release(tcpx_cq, rx_entry);
+	return FI_SUCCESS;
+}
 
-		return;
+static int process_srx_entry(struct tcpx_xfer_entry *rx_entry)
+{
+	int ret;
+
+	ret = tcpx_recv_msg_data(rx_entry);
+	if (OFI_SOCK_TRY_SND_RCV_AGAIN(-ret))
+		return ret;
+
+	if (ret) {
+		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN,
+			"msg recv Failed ret = %d\n", ret);
+
+		tcpx_ep_shutdown_report(rx_entry->ep,
+					&rx_entry->ep->util_ep.ep_fid.fid);
 	}
 
-	if (cq && err) {
-		err_entry.op_context = pe_entry->context;
-		err_entry.flags = pe_entry->flags;
-		err_entry.len = 0;
-		err_entry.buf = NULL;
-		err_entry.data = pe_entry->msg_hdr.data;
-		err_entry.tag = 0;
-		err_entry.olen = 0;
-		err_entry.err = err;
-		err_entry.prov_errno = errno;
-		err_entry.err_data = NULL;
-		err_entry.err_data_size = 0;
+	if ((ntohl(rx_entry->msg_hdr.hdr.flags) &
+	     OFI_DELIVERY_COMPLETE) && !ret) {
+		if (tcpx_prepare_rx_entry_resp(rx_entry))
+			rx_entry->ep->cur_rx_proc_fn = tcpx_prepare_rx_entry_resp;
 
-		ofi_cq_write_error(cq, &err_entry);
-	} else if (cq) {
-		ofi_cq_write(cq, pe_entry->context,
-			     pe_entry->flags, 0, NULL,
-			     pe_entry->msg_hdr.data, 0);
+		return FI_SUCCESS;
 	}
 
-	if (cntr && err) {
-		cntr->cntr_fid.ops->adderr(&cntr->cntr_fid, 1);
-	}else if (cntr) {
-		cntr->cntr_fid.ops->add(&cntr->cntr_fid, 1);
+	tcpx_cq_report_completion(rx_entry->ep->util_ep.rx_cq,
+				  rx_entry, -ret);
+
+	/* release the shared entry */
+	if (rx_entry->ep->cur_rx_entry == rx_entry) {
+		rx_entry->ep->cur_rx_entry = NULL;
 	}
+
+	fastlock_acquire(&rx_entry->ep->srx_ctx->lock);
+	util_buf_release(rx_entry->ep->srx_ctx->buf_pool, rx_entry);
+	fastlock_release(&rx_entry->ep->srx_ctx->lock);
+	return FI_SUCCESS;
 }
 
-void pe_entry_release(struct tcpx_pe_entry *pe_entry)
+static int tcpx_prepare_rx_write_resp(struct tcpx_xfer_entry *rx_entry)
 {
-	struct tcpx_domain *domain;
+	struct tcpx_cq *tcpx_rx_cq, *tcpx_tx_cq;
+	struct tcpx_xfer_entry *resp_entry;
+
+	tcpx_tx_cq = container_of(rx_entry->ep->util_ep.tx_cq,
+			       struct tcpx_cq, util_cq);
+
+	resp_entry = tcpx_xfer_entry_alloc(tcpx_tx_cq, TCPX_OP_MSG_RESP);
+	if (!resp_entry)
+		return -FI_EAGAIN;
+
+	resp_entry->msg_data.iov[0].iov_base = (void *) &resp_entry->msg_hdr;
+	resp_entry->msg_data.iov[0].iov_len = sizeof(resp_entry->msg_hdr);
+	resp_entry->msg_data.iov_cnt = 1;
+
+	resp_entry->msg_hdr.hdr.op = ofi_op_msg;
+	resp_entry->msg_hdr.hdr.size = htonll(sizeof(resp_entry->msg_hdr));
+
+	resp_entry->flags &= ~FI_COMPLETION;
+	resp_entry->context = NULL;
+	resp_entry->done_len = 0;
+	resp_entry->ep = rx_entry->ep;
+	tcpx_tx_queue_insert(resp_entry->ep, resp_entry);
+
+	tcpx_cq_report_completion(rx_entry->ep->util_ep.rx_cq,
+				  rx_entry, 0);
+	tcpx_rx_cq = container_of(rx_entry->ep->util_ep.rx_cq,
+			       struct tcpx_cq, util_cq);
+	tcpx_xfer_entry_release(tcpx_rx_cq, rx_entry);
+	return FI_SUCCESS;
+}
+
+static void tcpx_pmem_commit(struct tcpx_xfer_entry *rx_entry)
+{
+	int i;
 
-	domain = container_of(pe_entry->ep->util_ep.domain,
-			      struct tcpx_domain, util_domain);
+	if (!ofi_pmem_commit)
+		return ;
 
-	memset(&pe_entry->msg_hdr, 0, sizeof(pe_entry->msg_hdr));
-	dlist_remove(&pe_entry->entry);
-	memset(pe_entry, 0, sizeof(*pe_entry));
-	util_buf_release(domain->progress.pe_entry_pool, pe_entry);
+	for (i = 0; i < rx_entry->msg_hdr.rma_iov_cnt; i++) {
+		(*ofi_pmem_commit)((const void *) (uintptr_t)
+				   rx_entry->msg_hdr.rma_iov[i].addr,
+				   rx_entry->msg_hdr.rma_iov[i].len);
+	}
 }
 
-static void process_tx_pe_entry(struct tcpx_pe_entry *pe_entry)
+static int process_rx_remote_write_entry(struct tcpx_xfer_entry *rx_entry)
 {
-	uint64_t total_len = ntohll(pe_entry->msg_hdr.size);
+	struct tcpx_cq *tcpx_cq;
+	uint32_t flags;
 	int ret;
 
-	ret = tcpx_send_msg(pe_entry);
+	ret = tcpx_recv_msg_data(rx_entry);
 	if (OFI_SOCK_TRY_SND_RCV_AGAIN(-ret))
-		return;
+		return ret;
 
-	if (ret) {
-		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN, "msg send failed\n");
-		report_pe_entry_completion(pe_entry, ret);
-		pe_entry_release(pe_entry);
-		return;
-	}
+	if (!ret)
+		goto done;
+
+	FI_WARN(&tcpx_prov, FI_LOG_DOMAIN, "msg recv Failed ret = %d\n", ret);
+
+	if (ret == -FI_ENOTCONN)
+		tcpx_ep_shutdown_report(rx_entry->ep,
+					&rx_entry->ep->util_ep.ep_fid.fid);
+done:
+	flags = ntohl(rx_entry->msg_hdr.hdr.flags) &
+		(OFI_DELIVERY_COMPLETE | OFI_COMMIT_COMPLETE);
 
-	if (pe_entry->done_len == total_len) {
-		report_pe_entry_completion(pe_entry, 0);
-		pe_entry_release(pe_entry);
+	if (flags) {
+		if (flags & OFI_COMMIT_COMPLETE)
+			tcpx_pmem_commit(rx_entry);
+
+		if (tcpx_prepare_rx_write_resp(rx_entry))
+			rx_entry->ep->cur_rx_proc_fn = tcpx_prepare_rx_write_resp;
+
+		return FI_SUCCESS;
 	}
+	tcpx_cq_report_completion(rx_entry->ep->util_ep.rx_cq,
+				  rx_entry, -ret);
+	tcpx_cq = container_of(rx_entry->ep->util_ep.rx_cq,
+			       struct tcpx_cq, util_cq);
+	tcpx_xfer_entry_release(tcpx_cq, rx_entry);
+	return FI_SUCCESS;
 }
 
-static void process_rx_pe_entry(struct tcpx_pe_entry *pe_entry)
+static int process_rx_read_entry(struct tcpx_xfer_entry *rx_entry)
 {
+	struct tcpx_cq *tcpx_cq;
 	int ret;
 
-	ret = tcpx_recv_msg(pe_entry);
+	ret = tcpx_recv_msg_data(rx_entry);
 	if (OFI_SOCK_TRY_SND_RCV_AGAIN(-ret))
-		return;
+		return ret;
+
+	if (!ret)
+		goto done;
+
+	FI_WARN(&tcpx_prov, FI_LOG_DOMAIN, "msg recv Failed ret = %d\n", ret);
+
+	if (ret == -FI_ENOTCONN)
+		tcpx_ep_shutdown_report(rx_entry->ep,
+					&rx_entry->ep->util_ep.ep_fid.fid);
+done:
+	tcpx_cq_report_completion(rx_entry->ep->util_ep.tx_cq,
+				  rx_entry, -ret);
+	slist_remove_head(&rx_entry->ep->rma_read_queue);
+	tcpx_cq = container_of(rx_entry->ep->util_ep.tx_cq,
+			       struct tcpx_cq, util_cq);
+	tcpx_xfer_entry_release(tcpx_cq, rx_entry);
+	return FI_SUCCESS;
+}
+
+static void tcpx_copy_rma_iov_to_msg_iov(struct tcpx_xfer_entry *xfer_entry)
+{
+	int i;
+
+	xfer_entry->msg_data.iov_cnt = xfer_entry->msg_hdr.rma_iov_cnt;
+	for ( i = 0 ; i < xfer_entry->msg_hdr.rma_iov_cnt ; i++ ) {
+		xfer_entry->msg_data.iov[i].iov_base =
+			(void *) xfer_entry->msg_hdr.rma_iov[i].addr;
+		xfer_entry->msg_data.iov[i].iov_len =
+			xfer_entry->msg_hdr.rma_iov[i].len;
+	}
+}
+
+static int tcpx_prepare_rx_remote_read_resp(struct tcpx_xfer_entry *resp_entry)
+{
+	int i;
+
+	resp_entry->msg_data.iov[0].iov_base = (void *) &resp_entry->msg_hdr;
+	resp_entry->msg_data.iov[0].iov_len = sizeof(resp_entry->msg_hdr);
+	resp_entry->msg_data.iov_cnt = 1 + resp_entry->msg_hdr.rma_iov_cnt;
+
+	resp_entry->msg_hdr.hdr.size = resp_entry->msg_data.iov[0].iov_len;
+	for ( i = 0 ; i < resp_entry->msg_hdr.rma_iov_cnt ; i++ ) {
+		resp_entry->msg_data.iov[i+1].iov_base =
+			(void *) (uintptr_t)resp_entry->msg_hdr.rma_iov[i].addr;
+		resp_entry->msg_data.iov[i+1].iov_len =
+			resp_entry->msg_hdr.rma_iov[i].len;
+		resp_entry->msg_hdr.hdr.size +=
+			resp_entry->msg_data.iov[i+1].iov_len;
+	}
+
+	resp_entry->msg_hdr.hdr.op = ofi_op_read_rsp;
+	resp_entry->msg_hdr.hdr.size =
+		htonll(resp_entry->msg_hdr.hdr.size);
+
+	resp_entry->flags &= ~FI_COMPLETION;
+	resp_entry->context = NULL;
+	resp_entry->done_len = 0;
+
+	tcpx_tx_queue_insert(resp_entry->ep, resp_entry);
+	resp_entry->ep->cur_rx_entry = NULL;
+	return FI_SUCCESS;
+}
+
+static int tcpx_validate_rx_rma_data(struct tcpx_xfer_entry *rx_entry,
+				     uint64_t access)
+{
+	struct ofi_mr_map *map = &rx_entry->ep->util_ep.domain->mr_map;
+	struct fi_rma_iov *rma_iov = rx_entry->msg_hdr.rma_iov;
+	int i, ret;
+
+	for ( i = 0 ; i < rx_entry->msg_hdr.rma_iov_cnt ; i++) {
+		ret = ofi_mr_map_verify(map,
+					(uintptr_t *)&rma_iov[i].addr,
+					rma_iov[i].len,
+					rma_iov[i].key,
+					access, NULL);
+		if (ret) {
+			FI_DBG(&tcpx_prov, FI_LOG_EP_DATA,
+			       "invalid rma iov received\n");
+			return -FI_EINVAL;
+		}
+	}
+	return FI_SUCCESS;
+}
+
+int tcpx_get_rx_entry_op_invalid(struct tcpx_ep *tcpx_ep)
+{
+	return -FI_EINVAL;
+}
+
+int tcpx_get_rx_entry_op_msg(struct tcpx_ep *tcpx_ep)
+{
+	struct tcpx_xfer_entry *rx_entry;
+	struct tcpx_xfer_entry *tx_entry;
+	struct slist_entry *entry;
+	struct tcpx_cq *tcpx_cq;
+	struct tcpx_rx_detect *rx_detect = &tcpx_ep->rx_detect;
+	int ret;
+
+	tcpx_cq = container_of(tcpx_ep->util_ep.rx_cq,
+			       struct tcpx_cq, util_cq);
+
+	if (rx_detect->hdr.hdr.op_data == TCPX_OP_MSG_RESP) {
+		assert(!slist_empty(&tcpx_ep->tx_rsp_pend_queue));
+		entry = tcpx_ep->tx_rsp_pend_queue.head;
+		tx_entry = container_of(entry, struct tcpx_xfer_entry,
+					entry);
+
+		tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq,
+				       util_cq);
+		tcpx_cq_report_completion(tx_entry->ep->util_ep.tx_cq,
+					  tx_entry, 0);
+
+		slist_remove_head(&tx_entry->ep->tx_rsp_pend_queue);
+		tcpx_xfer_entry_release(tcpx_cq, tx_entry);
+		rx_detect->done_len = 0;
+		return -FI_EAGAIN;
+	}
+
+	if (tcpx_ep->srx_ctx){
+		tcpx_ep->cur_rx_proc_fn = process_srx_entry;
+		fastlock_acquire(&tcpx_ep->srx_ctx->lock);
+		if (slist_empty(&tcpx_ep->srx_ctx->rx_queue)) {
+			fastlock_release(&tcpx_ep->srx_ctx->lock);
+			return -FI_EAGAIN;
+		}
+
+		entry = slist_remove_head(&tcpx_ep->srx_ctx->rx_queue);
+		fastlock_release(&tcpx_ep->srx_ctx->lock);
+
+	} else {
+		if (slist_empty(&tcpx_ep->rx_queue))
+			return -FI_EAGAIN;
+
+		tcpx_ep->cur_rx_proc_fn = process_rx_entry;
+		entry = slist_remove_head(&tcpx_ep->rx_queue);
+	}
 
+	rx_entry = container_of(entry, struct tcpx_xfer_entry,
+				entry);
+
+	rx_entry->msg_hdr = rx_detect->hdr;
+	rx_entry->ep = tcpx_ep;
+	rx_entry->msg_hdr.hdr.op_data = TCPX_OP_MSG_RECV;
+	rx_entry->done_len = sizeof(rx_detect->hdr);
+	if (tcpx_ep->srx_ctx)
+		rx_entry->flags |= tcpx_ep->util_ep.rx_op_flags & FI_COMPLETION;
+
+	if (ntohl(rx_detect->hdr.hdr.flags) & OFI_REMOTE_CQ_DATA)
+		rx_entry->flags |= FI_REMOTE_CQ_DATA;
+
+	ret = ofi_truncate_iov(rx_entry->msg_data.iov,
+			       &rx_entry->msg_data.iov_cnt,
+			       (ntohll(rx_entry->msg_hdr.hdr.size) -
+				sizeof(rx_entry->msg_hdr)));
 	if (ret) {
-		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN, "msg recv Failed ret = %d\n", ret);
-		report_pe_entry_completion(pe_entry, ret);
-		pe_entry_release(pe_entry);
-		return;
+		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN,
+			"posted rx buffer size is not big enough\n");
+		tcpx_cq_report_completion(rx_entry->ep->util_ep.rx_cq,
+					  rx_entry, -ret);
+		tcpx_xfer_entry_release(tcpx_cq, rx_entry);
+		return ret;
 	}
 
-	if (pe_entry->done_len &&
-	    pe_entry->done_len == ntohll(pe_entry->msg_hdr.size)) {
-		report_pe_entry_completion(pe_entry, 0);
-		pe_entry_release(pe_entry);
+	rx_detect->done_len = 0;
+	tcpx_ep->cur_rx_entry = rx_entry;
+	return FI_SUCCESS;
+}
+
+int tcpx_get_rx_entry_op_read_req(struct tcpx_ep *tcpx_ep)
+{
+	struct tcpx_xfer_entry *rx_entry;
+	struct tcpx_cq *tcpx_cq;
+	int ret;
+
+	tcpx_cq = container_of(tcpx_ep->util_ep.rx_cq,
+			       struct tcpx_cq, util_cq);
+
+	rx_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_REMOTE_READ);
+	if (!rx_entry)
+		return -FI_EAGAIN;
+
+	rx_entry->msg_hdr = tcpx_ep->rx_detect.hdr;
+	rx_entry->msg_hdr.hdr.op_data =	TCPX_OP_REMOTE_READ;
+	rx_entry->ep = tcpx_ep;
+	rx_entry->done_len = sizeof(tcpx_ep->rx_detect.hdr);
+
+	ret = tcpx_validate_rx_rma_data(rx_entry, FI_REMOTE_READ);
+	if (ret) {
+		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN,
+			"invalid rma data\n");
+		tcpx_xfer_entry_release(tcpx_cq, rx_entry);
+		return ret;
 	}
+
+	tcpx_ep->rx_detect.done_len = 0;
+	tcpx_ep->cur_rx_entry = rx_entry;
+	tcpx_ep->cur_rx_proc_fn = tcpx_prepare_rx_remote_read_resp;
+	return FI_SUCCESS;
 }
 
-static void process_pe_lists(struct tcpx_ep *ep)
+int tcpx_get_rx_entry_op_write(struct tcpx_ep *tcpx_ep)
 {
-	struct tcpx_pe_entry *pe_entry;
-	struct dlist_entry *entry;
+	struct tcpx_xfer_entry *rx_entry;
+	struct tcpx_cq *tcpx_cq;
+	int ret;
+
+	tcpx_cq = container_of(tcpx_ep->util_ep.rx_cq,
+			       struct tcpx_cq, util_cq);
+
+	rx_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_REMOTE_WRITE);
+	if (!rx_entry)
+		return -FI_EAGAIN;
+
+	rx_entry->flags = 0;
+	if (ntohl(tcpx_ep->rx_detect.hdr.hdr.flags) & OFI_REMOTE_CQ_DATA)
+		rx_entry->flags = (FI_COMPLETION |
+				   FI_REMOTE_CQ_DATA | FI_REMOTE_WRITE);
+
+	rx_entry->msg_hdr = tcpx_ep->rx_detect.hdr;
+	rx_entry->msg_hdr.hdr.op_data = TCPX_OP_REMOTE_WRITE;
+	rx_entry->ep = tcpx_ep;
+	rx_entry->done_len = sizeof(tcpx_ep->rx_detect.hdr);
+
+	ret = tcpx_validate_rx_rma_data(rx_entry, FI_REMOTE_WRITE);
+	if (ret) {
+		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN,
+			"invalid rma data\n");
+		tcpx_xfer_entry_release(tcpx_cq, rx_entry);
+		return ret;
+	}
+
+	tcpx_copy_rma_iov_to_msg_iov(rx_entry);
+	tcpx_ep->rx_detect.done_len = 0;
+	tcpx_ep->cur_rx_entry = rx_entry;
+	tcpx_ep->cur_rx_proc_fn = process_rx_remote_write_entry;
+	return FI_SUCCESS;
+
+}
+
+int tcpx_get_rx_entry_op_read_rsp(struct tcpx_ep *tcpx_ep)
+{
+	struct tcpx_xfer_entry *rx_entry;
+	struct slist_entry *entry;
 
-	if (dlist_empty(&ep->rx_queue))
-		goto tx_pe_list;
+	if (slist_empty(&tcpx_ep->rma_read_queue))
+		return -FI_EINVAL;
 
-	entry = ep->rx_queue.next;
-	pe_entry = container_of(entry, struct tcpx_pe_entry,
+	entry = tcpx_ep->rma_read_queue.head;
+	rx_entry = container_of(entry, struct tcpx_xfer_entry,
 				entry);
-	process_rx_pe_entry(pe_entry);
 
-tx_pe_list:
-	if (dlist_empty(&ep->tx_queue))
-		return ;
+	rx_entry->msg_hdr = tcpx_ep->rx_detect.hdr;
+	rx_entry->msg_hdr.hdr.op_data = TCPX_OP_READ_RSP;
+	rx_entry->done_len = sizeof(tcpx_ep->rx_detect.hdr);
 
-	entry = ep->tx_queue.next;
-	pe_entry = container_of(entry, struct tcpx_pe_entry,
+	tcpx_ep->rx_detect.done_len = 0;
+	tcpx_ep->cur_rx_entry = rx_entry;
+	tcpx_ep->cur_rx_proc_fn = process_rx_read_entry;
+	return FI_SUCCESS;
+}
+
+static void tcpx_process_stage_buffer(struct tcpx_ep *ep)
+{
+	int ret;
+
+	while (ep->stage_buf.len != ep->stage_buf.off) {
+		if (!ep->cur_rx_entry) {
+			ret = tcpx_recv_hdr(ep->conn_fd, &ep->stage_buf,
+					    &ep->rx_detect);
+			if (OFI_SOCK_TRY_SND_RCV_AGAIN(-ret))
+				return;
+
+			if (ret)
+				goto err1;
+
+			ret = ep->get_rx_entry[ep->rx_detect.hdr.hdr.op](ep);
+			if (ret == -FI_EAGAIN)
+				return;
+			if (ret)
+				goto err2;
+		}
+		assert(ep->cur_rx_proc_fn != NULL);
+		ep->cur_rx_proc_fn(ep->cur_rx_entry);
+	}
+	return;
+err2:
+	tcpx_report_error(ep, ret);
+	return;
+err1:
+	if (ret == -FI_ENOTCONN)
+		tcpx_ep_shutdown_report(ep, &ep->util_ep.ep_fid.fid);
+}
+
+static void tcpx_process_rx_msg(struct tcpx_ep *ep)
+{
+	int ret;
+
+	if (!ep->cur_rx_entry) {
+		if (ep->stage_buf.len == ep->stage_buf.off) {
+			ret = tcpx_read_to_buffer(ep->conn_fd, &ep->stage_buf);
+			if (ret && !OFI_SOCK_TRY_SND_RCV_AGAIN(-ret))
+				goto err1;
+
+			tcpx_process_stage_buffer(ep);
+			return;
+		}
+
+		ret = tcpx_recv_hdr(ep->conn_fd, &ep->stage_buf,
+				    &ep->rx_detect);
+		if (OFI_SOCK_TRY_SND_RCV_AGAIN(-ret))
+			return;
+
+		if (ret)
+			goto err1;
+
+		ret = ep->get_rx_entry[ep->rx_detect.hdr.hdr.op](ep);
+		if (ret == -FI_EAGAIN)
+			return;
+		if (ret)
+			goto err2;
+	}
+
+	assert(ep->cur_rx_proc_fn != NULL);
+	ep->cur_rx_proc_fn(ep->cur_rx_entry);
+	return;
+err2:
+	tcpx_report_error(ep, ret);
+	return;
+err1:
+	if (ret == -FI_ENOTCONN)
+		tcpx_ep_shutdown_report(ep, &ep->util_ep.ep_fid.fid);
+}
+
+static void process_tx_queue(struct tcpx_ep *ep)
+{
+	struct tcpx_xfer_entry *tx_entry;
+	struct slist_entry *entry;
+
+	if (slist_empty(&ep->tx_queue))
+		return;
+
+	entry = ep->tx_queue.head;
+	tx_entry = container_of(entry, struct tcpx_xfer_entry,
 				entry);
-	process_tx_pe_entry(pe_entry);
+	process_tx_entry(tx_entry);
+}
+
+void tcpx_ep_progress(struct tcpx_ep *ep)
+{
+	tcpx_process_rx_msg(ep);
+	process_tx_queue(ep);
 }
 
 void tcpx_progress(struct util_ep *util_ep)
@@ -198,13 +685,83 @@ void tcpx_progress(struct util_ep *util_ep)
 	struct tcpx_ep *ep;
 
 	ep = container_of(util_ep, struct tcpx_ep, util_ep);
-	process_pe_lists(ep);
+	fastlock_acquire(&ep->lock);
+	ep->progress_func(ep);
+	fastlock_release(&ep->lock);
 	return;
 }
 
-int tcpx_progress_init(struct tcpx_progress *progress)
+static int tcpx_try_func(void *util_ep)
+{
+	uint32_t events;
+	struct util_wait_fd *wait_fd;
+	struct tcpx_ep *ep;
+	int ret;
+
+	ep = container_of(util_ep, struct tcpx_ep, util_ep);
+	wait_fd = container_of(((struct util_ep *)util_ep)->rx_cq->wait,
+			       struct util_wait_fd, util_wait);
+
+	fastlock_acquire(&ep->lock);
+	if (!slist_empty(&ep->tx_queue) && !ep->send_ready_monitor) {
+		ep->send_ready_monitor = true;
+		events = FI_EPOLL_IN | FI_EPOLL_OUT;
+		goto epoll_mod;
+	} else if (slist_empty(&ep->tx_queue) && ep->send_ready_monitor) {
+		ep->send_ready_monitor = false;
+		events = FI_EPOLL_IN;
+		goto epoll_mod;
+	}
+	fastlock_release(&ep->lock);
+	return FI_SUCCESS;
+
+epoll_mod:
+	ret = fi_epoll_mod(wait_fd->epoll_fd, ep->conn_fd, events, NULL);
+	if (ret)
+		FI_WARN(&tcpx_prov, FI_LOG_EP_DATA,
+			"invalid op type\n");
+	fastlock_release(&ep->lock);
+	return ret;
+}
+
+int tcpx_cq_wait_ep_add(struct tcpx_ep *ep)
+{
+	if (!ep->util_ep.rx_cq->wait)
+		return FI_SUCCESS;
+
+	return ofi_wait_fd_add(ep->util_ep.rx_cq->wait,
+			       ep->conn_fd, FI_EPOLL_IN,
+			       tcpx_try_func, (void *)&ep->util_ep,
+			       NULL);
+}
+
+void tcpx_cq_wait_ep_del(struct tcpx_ep *ep)
 {
-	return util_buf_pool_create(&progress->pe_entry_pool,
-				    sizeof(struct tcpx_pe_entry),
-				    16, 0, 1024);
+	fastlock_acquire(&ep->lock);
+	if (ep->cm_state == TCPX_EP_CONNECTING) {
+		goto out;
+	}
+
+	if (ep->util_ep.rx_cq->wait) {
+		ofi_wait_fd_del(ep->util_ep.rx_cq->wait, ep->conn_fd);
+	}
+out:
+	fastlock_release(&ep->lock);
+}
+
+void tcpx_tx_queue_insert(struct tcpx_ep *tcpx_ep,
+			  struct tcpx_xfer_entry *tx_entry)
+{
+	int empty;
+	struct util_wait *wait = tcpx_ep->util_ep.tx_cq->wait;
+
+	empty = slist_empty(&tcpx_ep->tx_queue);
+	slist_insert_tail(&tx_entry->entry, &tcpx_ep->tx_queue);
+
+	if (empty) {
+		process_tx_entry(tx_entry);
+
+		if (!slist_empty(&tcpx_ep->tx_queue) && wait)
+			wait->signal(wait);
+	}
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_rma.c
new file mode 100644
index 000000000..532f2a335
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_rma.c
@@ -0,0 +1,397 @@
+/*
+ * Copyright (c) 2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *	   Redistribution and use in source and binary forms, with or
+ *	   without modification, are permitted provided that the following
+ *	   conditions are met:
+ *
+ *		- Redistributions of source code must retain the above
+ *		  copyright notice, this list of conditions and the following
+ *		  disclaimer.
+ *
+ *		- Redistributions in binary form must reproduce the above
+ *		  copyright notice, this list of conditions and the following
+ *		  disclaimer in the documentation and/or other materials
+ *		  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <rdma/fi_errno.h>
+#include "rdma/fi_eq.h"
+#include "ofi_iov.h"
+#include <ofi_prov.h>
+#include "tcpx.h"
+
+#include <sys/types.h>
+#include <sys/socket.h>
+#include <ifaddrs.h>
+#include <net/if.h>
+#include <netinet/tcp.h>
+#include <netinet/in.h>
+#include <ofi_util.h>
+#include <unistd.h>
+#include <string.h>
+#include <poll.h>
+#include <arpa/inet.h>
+#include <netdb.h>
+
+static void tcpx_rma_read_send_entry_fill(struct tcpx_xfer_entry *send_entry,
+					  struct tcpx_ep *tcpx_ep,
+					  const struct fi_msg_rma *msg)
+{
+	memcpy(send_entry->msg_hdr.rma_iov, msg->rma_iov,
+	       msg->rma_iov_count * sizeof(msg->rma_iov[0]));
+	send_entry->msg_hdr.rma_iov_cnt = msg->rma_iov_count;
+
+	send_entry->msg_data.iov[0].iov_base = (void *) &send_entry->msg_hdr;
+	send_entry->msg_data.iov[0].iov_len = sizeof(send_entry->msg_hdr);
+	send_entry->msg_data.iov_cnt = 1;
+	send_entry->ep = tcpx_ep;
+	send_entry->done_len = 0;
+	send_entry->flags = 0;
+}
+
+static void tcpx_rma_read_recv_entry_fill(struct tcpx_xfer_entry *recv_entry,
+					  struct tcpx_ep *tcpx_ep,
+					  const struct fi_msg_rma *msg,
+					  uint64_t flags)
+{
+	memcpy(&recv_entry->msg_data.iov[0], &msg->msg_iov[0],
+	       msg->iov_count * sizeof(struct iovec));
+
+	recv_entry->msg_data.iov_cnt = msg->iov_count;
+	recv_entry->ep = tcpx_ep;
+	recv_entry->context = msg->context;
+	recv_entry->done_len = 0;
+	recv_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			     flags | FI_RMA | FI_READ);
+}
+
+static ssize_t tcpx_rma_readmsg(struct fid_ep *ep, const struct fi_msg_rma *msg,
+				uint64_t flags)
+{
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_cq *tcpx_cq;
+	struct tcpx_xfer_entry *send_entry;
+	struct tcpx_xfer_entry *recv_entry;
+
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+	tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq,
+			       util_cq);
+
+	assert(msg->iov_count <= TCPX_IOV_LIMIT);
+	assert(msg->rma_iov_count <= TCPX_IOV_LIMIT);
+
+	send_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_READ_REQ);
+	if (!send_entry)
+		return -FI_EAGAIN;
+
+	recv_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_READ_RSP);
+	if (!recv_entry) {
+		tcpx_xfer_entry_release(tcpx_cq, send_entry);
+		return -FI_EAGAIN;
+	}
+	tcpx_rma_read_send_entry_fill(send_entry, tcpx_ep, msg);
+	tcpx_rma_read_recv_entry_fill(recv_entry, tcpx_ep, msg, flags);
+
+	fastlock_acquire(&tcpx_ep->lock);
+	slist_insert_tail(&recv_entry->entry, &tcpx_ep->rma_read_queue);
+	tcpx_tx_queue_insert(tcpx_ep, send_entry);
+	fastlock_release(&tcpx_ep->lock);
+	return FI_SUCCESS;
+}
+
+static ssize_t tcpx_rma_read(struct fid_ep *ep, void *buf, size_t len, void *desc,
+			     fi_addr_t src_addr, uint64_t addr, uint64_t key, void *context)
+{
+	struct iovec msg_iov = {
+		.iov_base = (void *)buf,
+		.iov_len = len,
+	};
+	struct fi_rma_iov rma_iov = {
+		.addr = addr,
+		.key = key,
+		.len = len,
+	};
+	struct fi_msg_rma msg = {
+		.msg_iov = &msg_iov,
+		.desc = &desc,
+		.iov_count = 1,
+		.rma_iov_count = 1,
+		.rma_iov = &rma_iov,
+		.addr = src_addr,
+		.context = context,
+		.data = 0,
+	};
+
+	return tcpx_rma_readmsg(ep, &msg, 0);
+}
+
+static ssize_t tcpx_rma_readv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+			      size_t count, fi_addr_t src_addr, uint64_t addr, uint64_t key,
+			      void *context)
+{
+	struct fi_rma_iov rma_iov = {
+		.addr = addr,
+		.len = ofi_total_iov_len(iov, count),
+		.key = key,
+	};
+	struct fi_msg_rma msg = {
+		.msg_iov = iov,
+		.desc = desc,
+		.iov_count = count,
+		.rma_iov_count = 1,
+		.rma_iov = &rma_iov,
+		.addr = src_addr,
+		.context = context,
+		.data = 0,
+	};
+
+	return tcpx_rma_readmsg(ep, &msg, 0);
+}
+
+static ssize_t tcpx_rma_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg,
+				 uint64_t flags)
+{
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_cq *tcpx_cq;
+	struct tcpx_xfer_entry *send_entry;
+	uint64_t data_len;
+
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+	tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq,
+			       util_cq);
+
+	send_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_WRITE);
+	if (!send_entry)
+		return -FI_EAGAIN;
+
+	assert(msg->iov_count <= TCPX_IOV_LIMIT);
+	assert(msg->rma_iov_count <= TCPX_IOV_LIMIT);
+
+	data_len = ofi_total_iov_len(msg->msg_iov, msg->iov_count);
+
+	assert(!(flags & FI_INJECT) || (data_len <= TCPX_MAX_INJECT_SZ));
+
+	send_entry->msg_hdr.hdr.size = htonll(data_len + sizeof(send_entry->msg_hdr));
+	send_entry->msg_hdr.hdr.flags = 0;
+
+	memcpy(send_entry->msg_hdr.rma_iov, msg->rma_iov,
+	       msg->rma_iov_count * sizeof(msg->rma_iov[0]));
+	send_entry->msg_hdr.rma_iov_cnt = msg->rma_iov_count;
+
+	send_entry->msg_data.iov[0].iov_base = (void *) &send_entry->msg_hdr;
+	send_entry->msg_data.iov[0].iov_len = sizeof(send_entry->msg_hdr);
+	send_entry->msg_data.iov_cnt = msg->iov_count + 1;
+
+	if (flags & FI_INJECT) {
+		ofi_copy_iov_buf(msg->msg_iov, msg->iov_count, 0,
+				 send_entry->msg_data.inject,
+				 data_len,
+				 OFI_COPY_IOV_TO_BUF);
+
+		send_entry->msg_data.iov[1].iov_base = (void *)send_entry->msg_data.inject;
+		send_entry->msg_data.iov[1].iov_len = data_len;
+		send_entry->msg_data.iov_cnt++;
+	} else {
+		memcpy(&send_entry->msg_data.iov[1], &msg->msg_iov[0],
+		       msg->iov_count * sizeof(struct iovec));
+	}
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		send_entry->msg_hdr.hdr.flags |= OFI_REMOTE_CQ_DATA;
+		send_entry->msg_hdr.hdr.data = htonll(msg->data);
+	}
+
+	send_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			     flags | FI_RMA | FI_WRITE);
+
+	if (flags & (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)) {
+		send_entry->flags &= ~FI_COMPLETION;
+		send_entry->msg_hdr.hdr.flags |= OFI_DELIVERY_COMPLETE;
+	}
+
+	if (flags & FI_COMMIT_COMPLETE) {
+		send_entry->flags &= ~FI_COMPLETION;
+		send_entry->msg_hdr.hdr.flags |= OFI_COMMIT_COMPLETE;
+	}
+
+	send_entry->msg_hdr.hdr.flags = htonl(send_entry->msg_hdr.hdr.flags);
+	send_entry->ep = tcpx_ep;
+	send_entry->context = msg->context;
+	send_entry->done_len = 0;
+
+	fastlock_acquire(&tcpx_ep->lock);
+	tcpx_tx_queue_insert(tcpx_ep, send_entry);
+	fastlock_release(&tcpx_ep->lock);
+	return FI_SUCCESS;
+}
+
+static ssize_t tcpx_rma_write(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+			      fi_addr_t dest_addr, uint64_t addr, uint64_t key, void *context)
+{
+	struct iovec msg_iov = {
+		.iov_base = (void *)buf,
+		.iov_len = len,
+	};
+	struct fi_rma_iov rma_iov = {
+		.addr = addr,
+		.key = key,
+		.len = len,
+	};
+	struct fi_msg_rma msg = {
+		.msg_iov = &msg_iov,
+		.desc = &desc,
+		.iov_count = 1,
+		.rma_iov_count = 1,
+		.rma_iov = &rma_iov,
+		.addr = dest_addr,
+		.context = context,
+		.data = 0,
+	};
+
+	return tcpx_rma_writemsg(ep, &msg, 0);
+}
+
+static ssize_t tcpx_rma_writev(struct fid_ep *ep, const struct iovec *iov, void **desc,
+			       size_t count, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			       void *context)
+{
+	struct fi_rma_iov rma_iov = {
+		.addr = addr,
+		.key = key,
+		.len = ofi_total_iov_len(iov, count),
+	};
+	struct fi_msg_rma msg = {
+		.msg_iov = iov,
+		.desc = desc,
+		.iov_count = count,
+		.rma_iov_count = 1,
+		.rma_iov = &rma_iov,
+		.addr = dest_addr,
+		.context = context,
+		.data = 0,
+	};
+
+	return tcpx_rma_writemsg(ep, &msg, 0);
+}
+
+
+static ssize_t tcpx_rma_writedata(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+				  uint64_t data, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+				  void *context)
+{
+	struct iovec msg_iov = {
+		.iov_base = (void *)buf,
+		.iov_len = len,
+	};
+	struct fi_rma_iov rma_iov = {
+		.addr = addr,
+		.key = key,
+		.len = len,
+	};
+	struct fi_msg_rma msg = {
+		.desc = &desc,
+		.iov_count = 1,
+		.rma_iov_count = 1,
+		.rma_iov = &rma_iov,
+		.msg_iov = &msg_iov,
+		.addr = dest_addr,
+		.context = context,
+		.data = data,
+	};
+
+	return tcpx_rma_writemsg(ep, &msg, FI_REMOTE_CQ_DATA);
+}
+
+static ssize_t tcpx_rma_inject_common(struct fid_ep *ep, const void *buf,
+				      size_t len, uint64_t data,
+				      fi_addr_t dest_addr, uint64_t addr,
+				      uint64_t key, uint64_t flags)
+{
+	struct tcpx_ep *tcpx_ep;
+	struct tcpx_cq *tcpx_cq;
+	struct tcpx_xfer_entry *send_entry;
+
+	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
+	tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq,
+			       util_cq);
+
+	send_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_WRITE);
+	if (!send_entry)
+		return -FI_EAGAIN;
+
+	assert(len <= TCPX_MAX_INJECT_SZ);
+	send_entry->msg_hdr.hdr.size = htonll(len + sizeof(send_entry->msg_hdr));
+	send_entry->msg_hdr.hdr.flags = 0;
+
+	send_entry->msg_hdr.rma_iov[0].addr = addr;
+	send_entry->msg_hdr.rma_iov[0].key = key;
+	send_entry->msg_hdr.rma_iov[0].len = len;
+	send_entry->msg_hdr.rma_iov_cnt = 1;
+
+	send_entry->msg_data.iov[0].iov_base = (void *) &send_entry->msg_hdr;
+	send_entry->msg_data.iov[0].iov_len = sizeof(send_entry->msg_hdr);
+
+	memcpy(send_entry->msg_data.inject, (uint8_t *)buf, len);
+	send_entry->msg_data.iov[1].iov_base = (void *)send_entry->msg_data.inject;
+	send_entry->msg_data.iov[1].iov_len = len;
+
+	send_entry->msg_data.iov_cnt = 2;
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		send_entry->msg_hdr.hdr.flags |= OFI_REMOTE_CQ_DATA;
+		send_entry->msg_hdr.hdr.data = htonll(data);
+	}
+
+	send_entry->msg_hdr.hdr.flags = htonl(send_entry->msg_hdr.hdr.flags);
+	send_entry->ep = tcpx_ep;
+	send_entry->done_len = 0;
+
+	fastlock_acquire(&tcpx_ep->lock);
+	tcpx_tx_queue_insert(tcpx_ep, send_entry);
+	fastlock_release(&tcpx_ep->lock);
+	return FI_SUCCESS;
+}
+
+static ssize_t tcpx_rma_inject(struct fid_ep *ep, const void *buf, size_t len,
+			       fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	return tcpx_rma_inject_common(ep, buf, len, dest_addr,
+				      0, addr, key, FI_INJECT);
+}
+
+static ssize_t tcpx_rma_injectdata(struct fid_ep *ep, const void *buf, size_t len,
+				   uint64_t data, fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	return tcpx_rma_inject_common(ep, buf, len, dest_addr,
+				      data, addr, key,
+				      FI_INJECT | FI_REMOTE_CQ_DATA);
+}
+
+struct fi_ops_rma tcpx_rma_ops = {
+	.size = sizeof(struct fi_ops_rma),
+	.read = tcpx_rma_read,
+	.readv = tcpx_rma_readv,
+	.readmsg = tcpx_rma_readmsg,
+	.write = tcpx_rma_write,
+	.writev = tcpx_rma_writev,
+	.writemsg = tcpx_rma_writemsg,
+	.inject = tcpx_rma_inject,
+	.writedata = tcpx_rma_writedata,
+	.injectdata = tcpx_rma_injectdata,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_shared_ctx.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_shared_ctx.c
new file mode 100644
index 000000000..c64a82a7d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/tcp/src/tcpx_shared_ctx.c
@@ -0,0 +1,141 @@
+/*
+ * Copyright (c) 2018 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *	   Redistribution and use in source and binary forms, with or
+ *	   without modification, are permitted provided that the following
+ *	   conditions are met:
+ *
+ *		- Redistributions of source code must retain the above
+ *		  copyright notice, this list of conditions and the following
+ *		  disclaimer.
+ *
+ *		- Redistributions in binary form must reproduce the above
+ *		  copyright notice, this list of conditions and the following
+ *		  disclaimer in the documentation and/or other materials
+ *		  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+#include <rdma/fi_errno.h>
+#include <ofi_prov.h>
+#include "tcpx.h"
+
+#include <sys/types.h>
+#include <ofi_util.h>
+#include <unistd.h>
+
+static inline struct tcpx_xfer_entry *
+tcpx_srx_ctx_rx_entry_alloc(struct tcpx_rx_ctx *srx_ctx)
+{
+	struct tcpx_xfer_entry *recv_entry;
+
+	fastlock_acquire(&srx_ctx->lock);
+	recv_entry = util_buf_alloc(srx_ctx->buf_pool);
+	if (recv_entry)
+		recv_entry->done_len = 0;
+
+	fastlock_release(&srx_ctx->lock);
+	return recv_entry;
+}
+
+static ssize_t tcpx_srx_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
+				uint64_t flags)
+{
+	struct tcpx_xfer_entry *recv_entry;
+	struct tcpx_rx_ctx *srx_ctx;
+
+	srx_ctx = container_of(ep, struct tcpx_rx_ctx, rx_fid);
+	assert(msg->iov_count <= TCPX_IOV_LIMIT);
+
+	recv_entry = tcpx_srx_ctx_rx_entry_alloc(srx_ctx);
+	if (!recv_entry)
+		return -FI_EAGAIN;
+
+	recv_entry->msg_data.iov_cnt = msg->iov_count;
+	memcpy(&recv_entry->msg_data.iov[0], &msg->msg_iov[0],
+	       msg->iov_count * sizeof(struct iovec));
+
+	recv_entry->flags = flags | FI_MSG | FI_RECV;
+	recv_entry->context = msg->context;
+
+	fastlock_acquire(&srx_ctx->lock);
+	slist_insert_tail(&recv_entry->entry, &srx_ctx->rx_queue);
+	fastlock_release(&srx_ctx->lock);
+	return FI_SUCCESS;
+}
+
+static ssize_t tcpx_srx_recv(struct fid_ep *ep, void *buf, size_t len, void *desc,
+			     fi_addr_t src_addr, void *context)
+{
+	struct tcpx_xfer_entry *recv_entry;
+	struct tcpx_rx_ctx *srx_ctx;
+
+	srx_ctx = container_of(ep, struct tcpx_rx_ctx, rx_fid);
+
+	recv_entry = tcpx_srx_ctx_rx_entry_alloc(srx_ctx);
+	if (!recv_entry)
+		return -FI_EAGAIN;
+
+	recv_entry->msg_data.iov_cnt = 1;
+	recv_entry->msg_data.iov[0].iov_base = buf;
+	recv_entry->msg_data.iov[0].iov_len = len;
+
+	recv_entry->flags = FI_MSG | FI_RECV;
+	recv_entry->context = context;
+
+	fastlock_acquire(&srx_ctx->lock);
+	slist_insert_tail(&recv_entry->entry, &srx_ctx->rx_queue);
+	fastlock_release(&srx_ctx->lock);
+	return FI_SUCCESS;
+}
+
+static ssize_t tcpx_srx_recvv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+			      size_t count, fi_addr_t src_addr, void *context)
+{
+	struct tcpx_xfer_entry *recv_entry;
+	struct tcpx_rx_ctx *srx_ctx;
+
+	srx_ctx = container_of(ep, struct tcpx_rx_ctx, rx_fid);
+	assert(count <= TCPX_IOV_LIMIT);
+
+	recv_entry = tcpx_srx_ctx_rx_entry_alloc(srx_ctx);
+	if (!recv_entry)
+		return -FI_EAGAIN;
+
+	recv_entry->msg_data.iov_cnt = count;
+	memcpy(recv_entry->msg_data.iov, iov, count * sizeof(*iov));
+
+	recv_entry->flags = FI_MSG | FI_RECV;
+	recv_entry->context = context;
+
+	fastlock_acquire(&srx_ctx->lock);
+	slist_insert_tail(&recv_entry->entry, &srx_ctx->rx_queue);
+	fastlock_release(&srx_ctx->lock);
+	return FI_SUCCESS;
+}
+
+struct fi_ops_msg tcpx_srx_msg_ops = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = tcpx_srx_recv,
+	.recvv = tcpx_srx_recvv,
+	.recvmsg = tcpx_srx_recvmsg,
+	.send = fi_no_msg_send,
+	.sendv = fi_no_msg_sendv,
+	.sendmsg = fi_no_msg_sendmsg,
+	.inject = fi_no_msg_inject,
+	.senddata = fi_no_msg_senddata,
+	.injectdata = fi_no_msg_injectdata,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_cq.c
index af7f4424a..7a0c75588 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_cq.c
@@ -52,7 +52,7 @@ static struct fi_ops udpx_cq_fi_ops = {
 	.size = sizeof(struct fi_ops),
 	.close = udpx_cq_close,
 	.bind = fi_no_bind,
-	.control = fi_no_control,
+	.control = ofi_cq_control,
 	.ops_open = fi_no_ops_open,
 };
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_domain.c
index 1f82b7b13..a40e8f25b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_domain.c
@@ -38,7 +38,7 @@
 
 static struct fi_ops_domain udpx_domain_ops = {
 	.size = sizeof(struct fi_ops_domain),
-	.av_open = ip_av_create,
+	.av_open = ofi_ip_av_create,
 	.cq_open = udpx_cq_open,
 	.endpoint = udpx_endpoint,
 	.scalable_ep = fi_no_scalable_ep,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_ep.c
index 59a44da1e..2a1145f1c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_ep.c
@@ -42,7 +42,7 @@ static int udpx_setname(fid_t fid, void *addr, size_t addrlen)
 	int ret;
 
 	ep = container_of(fid, struct udpx_ep, util_ep.ep_fid.fid);
-	FI_DBG(&udpx_prov, FI_LOG_EP_CTRL, "%s\n", ofi_hex_str(addr, addrlen));
+	ofi_straddr_dbg(&udpx_prov, FI_LOG_EP_CTRL, "bind addr: ", addr);
 	ret = bind(ep->sock, addr, (socklen_t)addrlen);
 	if (ret) {
 		FI_WARN(&udpx_prov, FI_LOG_EP_CTRL, "bind %d (%s)\n",
@@ -252,7 +252,7 @@ static void udpx_rx_src_comp(struct udpx_ep *ep, void *context, uint64_t flags,
 			     size_t len, void *buf, void *addr)
 {
 	ep->util_ep.rx_cq->src[ofi_cirque_windex(ep->util_ep.rx_cq->cirq)] =
-			ip_av_get_index(ep->util_ep.av, addr);
+			ofi_ip_av_get_fi_addr(ep->util_ep.av, addr);
 	udpx_rx_comp(ep, context, flags, len, buf, addr);
 }
 
@@ -293,7 +293,7 @@ static void udpx_ep_progress(struct util_ep *util_ep)
 	hdr.msg_iov = entry->iov;
 	hdr.msg_iovlen = entry->iov_count;
 
-	ret = recvmsg(ep->sock, &hdr, 0);
+	ret = ofi_recvmsg_udp(ep->sock, &hdr, 0);
 	if (ret >= 0) {
 		ep->rx_comp(ep, entry->context, 0, ret, NULL, &addr);
 		ofi_cirque_discard(ep->rxq);
@@ -374,8 +374,9 @@ out:
 static const void *
 udpx_dest_addr(struct udpx_ep *ep, fi_addr_t addr, uint64_t flags)
 {
-	return (flags & FI_MULTICAST) ? (const void *) (uintptr_t) addr :
-					ip_av_get_addr(ep->util_ep.av, (int)addr);
+	return (flags & FI_MULTICAST) ?
+	       (const void *) (uintptr_t) addr :
+	       ofi_ip_av_get_addr(ep->util_ep.av, (int)addr);
 }
 
 static size_t
@@ -416,7 +417,7 @@ static ssize_t udpx_send(struct fid_ep *ep_fid, const void *buf, size_t len,
 	struct udpx_ep *ep;
 
 	ep = container_of(ep_fid, struct udpx_ep, util_ep.ep_fid.fid);
-	return udpx_sendto(ep, buf, len, ip_av_get_addr(ep->util_ep.av, (int)dest_addr),
+	return udpx_sendto(ep, buf, len, ofi_ip_av_get_addr(ep->util_ep.av, (int)dest_addr),
 			   ep->util_ep.av->addrlen, context);
 }
 
@@ -453,7 +454,7 @@ static ssize_t udpx_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
 		goto out;
 	}
 
-	ret = sendmsg(ep->sock, &hdr, 0);
+	ret = ofi_sendmsg_udp(ep->sock, &hdr, 0);
 	if (ret >= 0) {
 		ep->tx_comp(ep, msg->context);
 		ret = 0;
@@ -501,7 +502,7 @@ static ssize_t udpx_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
 
 	ep = container_of(ep_fid, struct udpx_ep, util_ep.ep_fid.fid);
 	ret = ofi_sendto_socket(ep->sock, buf, len, 0,
-				ip_av_get_addr(ep->util_ep.av, (int)dest_addr),
+				ofi_ip_av_get_addr(ep->util_ep.av, (int)dest_addr),
 				(socklen_t)ep->util_ep.av->addrlen);
 	return ret == (ssize_t)len ? 0 : -errno;
 }
@@ -604,7 +605,7 @@ static int udpx_ep_bind_cq(struct udpx_ep *ep, struct util_cq *cq,
 			wait = container_of(cq->wait,
 					    struct util_wait_fd, util_wait);
 			ret = fi_epoll_add(wait->epoll_fd, (int)ep->sock,
-					   &ep->util_ep.ep_fid.fid);
+					   FI_EPOLL_IN, &ep->util_ep.ep_fid.fid);
 			if (ret)
 				return ret;
 		} else {
@@ -660,22 +661,30 @@ static int udpx_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 static void udpx_bind_src_addr(struct udpx_ep *ep)
 {
 	int ret;
-	struct addrinfo ai, *rai = NULL;
+	struct addrinfo ai, *rai = NULL, *cur_ai;
 	char hostname[HOST_NAME_MAX];
 
 	memset(&ai, 0, sizeof(ai));
-	ai.ai_family = AF_INET;
 	ai.ai_socktype = SOCK_DGRAM;
 
-	ofi_getnodename(hostname, sizeof(hostname));
-	ret = getaddrinfo(hostname, NULL, &ai, &rai);
+	ret = gethostname(hostname, sizeof(hostname));
+	ret = getaddrinfo(ret ? "127.0.0.1" : hostname, NULL, &ai, &rai);
 	if (ret) {
 		FI_WARN(&udpx_prov, FI_LOG_EP_CTRL,
 			"getaddrinfo failed\n");
 		return;
 	}
 
-	ret = udpx_setname(&ep->util_ep.ep_fid.fid, rai->ai_addr, rai->ai_addrlen);
+	for (cur_ai = rai; cur_ai && cur_ai->ai_family != AF_INET;
+	     cur_ai = cur_ai->ai_next)
+		;
+
+	if (cur_ai) {
+		ret = udpx_setname(&ep->util_ep.ep_fid.fid, cur_ai->ai_addr,
+				   cur_ai->ai_addrlen);
+	} else {
+		ret = -FI_EADDRNOTAVAIL;
+	}
 	if (ret) {
 		FI_WARN(&udpx_prov, FI_LOG_EP_CTRL, "failed to set addr\n");
 	}
@@ -763,13 +772,11 @@ int udpx_endpoint(struct fid_domain *domain, struct fi_info *info,
 	ret = ofi_endpoint_init(domain, &udpx_util_prov, info, &ep->util_ep,
 				context, udpx_ep_progress);
 	if (ret)
-		goto err;
+		goto err1;
 
 	ret = udpx_ep_init(ep, info);
-	if (ret) {
-		free(ep);
-		return ret;
-	}
+	if (ret)
+		goto err2;
 
 	*ep_fid = &ep->util_ep.ep_fid;
 	(*ep_fid)->fid.ops = &udpx_ep_fi_ops;
@@ -779,7 +786,9 @@ int udpx_endpoint(struct fid_domain *domain, struct fi_info *info,
 			 &udpx_msg_mcast_ops : &udpx_msg_ops;
 
 	return 0;
-err:
+err2:
+	ofi_endpoint_close(&ep->util_ep);
+err1:
 	free(ep);
 	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_init.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_init.c
index 0b0e7635c..3e00f9241 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_init.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/udp/src/udpx_init.c
@@ -137,7 +137,7 @@ static void udpx_fini(void)
 struct fi_provider udpx_prov = {
 	.name = "UDP",
 	.version = FI_VERSION(UDPX_MAJOR_VERSION, UDPX_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = udpx_getinfo,
 	.fabric = udpx_fabric,
 	.cleanup = udpx_fini
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/usnic/src/usdf_fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/usnic/src/usdf_fabric.c
index ba2625c7a..390ce41c0 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/usnic/src/usdf_fabric.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/usnic/src/usdf_fabric.c
@@ -341,6 +341,80 @@ static int validate_modebits(uint32_t version, const struct fi_info *hints,
 	return FI_SUCCESS;
 }
 
+static int usdf_alloc_fid_nic(struct fi_info *fi,
+			struct usd_device_attrs *dap)
+{
+	int ret;
+	struct fid_nic *nic = NULL;
+	struct fi_device_attr *da = NULL;
+	struct fi_link_attr *la = NULL;
+
+	nic = ofi_nic_dup(NULL);
+	if (!nic)
+		goto nomem;
+
+	da = nic->device_attr;
+	da->name = strdup(dap->uda_devname);
+	if (!da->name)
+		goto nomem;
+	ret = asprintf(&da->device_id, "%s (%s)",
+		usd_devid_to_pid(dap->uda_vendor_id,
+				dap->uda_device_id),
+		usd_devid_to_nicname(dap->uda_vendor_id,
+				dap->uda_device_id));
+	if (ret < 0)
+		goto nomem;
+	ret = asprintf(&da->device_version, "0x%x", dap->uda_vendor_part_id);
+	if (ret < 0)
+		goto nomem;
+	ret = asprintf(&da->vendor_id, "0x%x", dap->uda_vendor_id);
+	if (ret < 0)
+		goto nomem;
+	da->driver = strdup("usnic_verbs");
+	if (!da->driver)
+		goto nomem;
+	da->firmware = strdup(dap->uda_firmware);
+	if (!da->firmware)
+		goto nomem;
+
+	// usnic does not currently expose PCI bus information, so we
+	// set the bus type to unknown.
+	nic->bus_attr->bus_type = FI_BUS_UNKNOWN;
+
+	la = nic->link_attr;
+
+	socklen_t size = INET_ADDRSTRLEN;
+	la->address = calloc(1, size);
+	if (!la->address)
+		goto nomem;
+	inet_ntop(AF_INET, &dap->uda_ipaddr_be, la->address, size);
+	la->mtu = dap->uda_mtu;
+	la->speed = dap->uda_bandwidth;
+	switch (dap->uda_link_state) {
+	case USD_LINK_UP:
+		la->state = FI_LINK_UP;
+		break;
+	case USD_LINK_DOWN:
+		la->state = FI_LINK_DOWN;
+		break;
+	default:
+		la->state = FI_LINK_UNKNOWN;
+		break;
+	}
+	la->network_type = strdup("Ethernet");
+	if (!la->network_type)
+		goto nomem;
+
+	fi->nic = nic;
+
+	return FI_SUCCESS;
+
+nomem:
+	if (nic)
+		fi_close(&nic->fid);
+	return -FI_ENOMEM;
+}
+
 static int usdf_fill_info_dgram(
 	uint32_t version,
 	const struct fi_info *hints,
@@ -419,6 +493,10 @@ static int usdf_fill_info_dgram(
 	if (ret)
 		goto fail;
 
+	ret = usdf_alloc_fid_nic(fi, dap);
+	if (ret)
+		goto fail;
+
 	/* add to tail of list */
 	if (*fi_first == NULL) {
 		*fi_first = fi;
@@ -508,6 +586,10 @@ static int usdf_fill_info_msg(
 	if (ret)
 		goto fail;
 
+	ret = usdf_alloc_fid_nic(fi, dap);
+	if (ret)
+		goto fail;
+
 	/* add to tail of list */
 	if (*fi_first == NULL) {
 		*fi_first = fi;
@@ -595,6 +677,10 @@ static int usdf_fill_info_rdm(
 	if (ret)
 		goto fail;
 
+	ret = usdf_alloc_fid_nic(fi, dap);
+	if (ret)
+		goto fail;
+
 	/* add to tail of list */
 	if (*fi_first == NULL) {
 		*fi_first = fi;
@@ -1162,7 +1248,7 @@ static void usdf_fini(void)
 struct fi_provider usdf_ops = {
 	.name = USDF_PROV_NAME,
 	.version = USDF_PROV_VERSION,
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = usdf_getinfo,
 	.fabric = usdf_fabric_open,
 	.cleanup =  usdf_fini
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/usnic/src/usnic_direct/usd_ib_sysfs.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/usnic/src/usnic_direct/usd_ib_sysfs.c
index 9871a1feb..b9ddddea4 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/usnic/src/usnic_direct/usd_ib_sysfs.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/usnic/src/usnic_direct/usd_ib_sysfs.c
@@ -69,8 +69,8 @@ usd_ib_get_devlist(
     DIR *class_dir;
     struct dirent *dent;
     struct stat sbuf;
-    char dev_path[PATH_MAX];
-    char ibdev_path[PATH_MAX];
+    char *dev_path = NULL;
+    char *ibdev_path = NULL;
     char ibdev_buf[32];
     struct usd_ib_dev *idp;
     struct usd_ib_dev *last_idp;
@@ -90,14 +90,17 @@ usd_ib_get_devlist(
     last_idp = NULL;
     fd = -1;
     while ((dent = readdir(class_dir)) != NULL) {
-
         /* skip "." and ".." */
         if (dent->d_name[0] == '.')
             continue;
 
         /* build path to entry */
-        snprintf(dev_path, sizeof(dev_path), "%s/%s", class_path,
-                 dent->d_name);
+        if (asprintf(&dev_path, "%s/%s", class_path,
+                     dent->d_name) <= 0) {
+            rc = -errno;
+            usd_perror("failed to asprintf");
+            goto out;
+        }
 
         /* see if it's a dir */
         rc = stat(dev_path, &sbuf);
@@ -112,7 +115,11 @@ usd_ib_get_devlist(
             continue;
 
         /* read the ibdev */
-        snprintf(ibdev_path, sizeof(ibdev_path), "%s/ibdev", dev_path);
+        if (asprintf(&ibdev_path, "%s/ibdev", dev_path) <= 0) {
+            rc = -errno;
+            usd_perror(ibdev_path);
+            goto out;
+        }
         fd = open(ibdev_path, O_RDONLY);
         if (fd == -1) {
             usd_perror(ibdev_path);
@@ -156,11 +163,17 @@ usd_ib_get_devlist(
             idp->id_next = NULL;
             last_idp = idp;
         }
+        free(dev_path);
+        dev_path = NULL;
+        free(ibdev_path);
+        ibdev_path = NULL;
     }
     rc = 0;
 
 out:
     /* clean up */
+    free(dev_path);
+    free(ibdev_path);
     if (class_dir != NULL) {
         closedir(class_dir);
     }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_atomic.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_atomic.c
index 87d433645..a41905543 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_atomic.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_atomic.c
@@ -1,5 +1,6 @@
 /*
  * Copyright (c) 2013-2017 Intel Corporation. All rights reserved.
+ * Copyright (c) 2018 Cray Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -32,7 +33,6 @@
 
 #include "ofi_atomic.h"
 
-
 static const size_t ofi_datatype_size_table[] = {
 	[FI_INT8]   = sizeof(int8_t),
 	[FI_UINT8]  = sizeof(uint8_t),
@@ -59,10 +59,60 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 	return ofi_datatype_size_table[datatype];
 }
 
-
 /*
  * Basic atomic operations
  */
+#ifdef HAVE_BUILTIN_MM_ATOMICS
+
+#define OFI_OP_MIN(type,dst,src)	(dst) > (src)
+#define OFI_OP_MAX(type,dst,src)	(dst) < (src)
+#define OFI_OP_SUM(type,dst,src)	(dst) + (src)
+#define OFI_OP_PROD(type,dst,src)	(dst) * (src)
+#define OFI_OP_LOR(type,dst,src)	(dst) || (src)
+#define OFI_OP_LAND(type,dst,src)	(dst) && (src)
+
+#define OFI_OP_BOR(type,dst,src)	\
+		__atomic_fetch_or(&(dst), (src), __ATOMIC_SEQ_CST)
+#define OFI_OP_BAND(type,dst,src)	\
+		__atomic_fetch_and(&(dst), (src), __ATOMIC_SEQ_CST)
+#define OFI_OP_LXOR(type,dst,src)	\
+		((dst) && !(src)) || (!(dst) && (src))
+#define OFI_OP_BXOR(type,dst,src)	\
+		__atomic_fetch_xor(&(dst), (src), __ATOMIC_SEQ_CST)
+#define OFI_OP_WRITE(type,dst,src)	\
+		__atomic_store(&(dst), &(src), __ATOMIC_SEQ_CST)
+
+#define OFI_OP_READ(type,dst,res)	\
+		__atomic_load(&(dst), &(res), __ATOMIC_SEQ_CST)
+#define OFI_OP_READWRITE(type,dst,src,res)	\
+		__atomic_exchange(&(dst), &(src), &(res), __ATOMIC_SEQ_CST)
+
+#define OFI_OP_CSWAP_EQ(type,dst,src,cmp)	\
+		__atomic_compare_exchange(&(dst),&(cmp),&(src),0,	\
+					  __ATOMIC_SEQ_CST, __ATOMIC_SEQ_CST)
+#define OFI_OP_CSWAP_NE(type,dst,src,cmp)	((cmp) != (dst))
+#define OFI_OP_CSWAP_LE(type,dst,src,cmp)	((cmp) <= (dst))
+#define OFI_OP_CSWAP_LT(type,dst,src,cmp)	((cmp) <  (dst))
+#define OFI_OP_CSWAP_GE(type,dst,src,cmp)	((cmp) >= (dst))
+#define OFI_OP_CSWAP_GT(type,dst,src,cmp)	((cmp) >  (dst))
+#define OFI_OP_MSWAP(type,dst,src,cmp)		\
+		(((src) & (cmp)) | ((dst) & ~(cmp)))
+
+/* Need special handlers for OFI complex datatypes for portability */
+#define OFI_OP_SUM_COMPLEX(type,dst,src)  ofi_complex_sum_##type(dst,src)
+#define OFI_OP_PROD_COMPLEX(type,dst,src) ofi_complex_prod_##type(dst,src)
+#define OFI_OP_LOR_COMPLEX(type,dst,src)  ofi_complex_lor_##type(dst,src)
+#define OFI_OP_LAND_COMPLEX(type,dst,src) ofi_complex_land_##type(dst,src)
+#define OFI_OP_LXOR_COMPLEX(type,dst,src) ofi_complex_lxor_##type(dst,src)
+#define OFI_OP_CSWAP_EQ_COMPLEX(type,dst,src,cmp)	\
+		__atomic_compare_exchange(&(dst),&(cmp),&(src),0,	\
+					  __ATOMIC_SEQ_CST, __ATOMIC_SEQ_CST)
+#define OFI_OP_CSWAP_NE_COMPLEX(type,dst,src,cmp)	\
+			(!ofi_complex_eq_##type(dst,cmp))
+
+#define OFI_OP_READWRITE_COMPLEX	OFI_OP_READWRITE
+
+#else /* HAVE_BUILTIN_MM_ATOMICS */
 
 #define OFI_OP_MIN(type,dst,src)   if ((dst) > (src)) (dst) = (src)
 #define OFI_OP_MAX(type,dst,src)   if ((dst) < (src)) (dst) = (src)
@@ -74,15 +124,15 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 #define OFI_OP_BAND(type,dst,src)  (dst) &= (src)
 #define OFI_OP_LXOR(type,dst,src)  (dst) = ((dst) && !(src)) || (!(dst) && (src))
 #define OFI_OP_BXOR(type,dst,src)  (dst) ^= (src)
-#define OFI_OP_READ(type,dst,src)  /* src unused, dst is written to result */
+#define OFI_OP_READ(type,dst,src)  (dst)
 #define OFI_OP_WRITE(type,dst,src) (dst) = (src)
 
-#define OFI_OP_CSWAP_EQ(type,dst,src,cmp) if ((dst) == (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_NE(type,dst,src,cmp) if ((dst) != (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_LE(type,dst,src,cmp) if ((dst) <= (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_LT(type,dst,src,cmp) if ((dst) <  (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_GE(type,dst,src,cmp) if ((dst) >= (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_GT(type,dst,src,cmp) if ((dst) >  (cmp)) (dst) = (src)
+#define OFI_OP_CSWAP_EQ(type,dst,src,cmp) if ((cmp) == (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_NE(type,dst,src,cmp) if ((cmp) != (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_LE(type,dst,src,cmp) if ((cmp) <= (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_LT(type,dst,src,cmp) if ((cmp) <  (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_GE(type,dst,src,cmp) if ((cmp) >= (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_GT(type,dst,src,cmp) if ((cmp) >  (dst)) (dst) = (src)
 #define OFI_OP_MSWAP(type,dst,src,cmp)    (dst) = (((src) & (cmp)) | \
 						   ((dst) & ~(cmp)))
 
@@ -92,14 +142,14 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 #define OFI_OP_LOR_COMPLEX(type,dst,src)  (dst) = ofi_complex_lor_##type(dst,src)
 #define OFI_OP_LAND_COMPLEX(type,dst,src) (dst) = ofi_complex_land_##type(dst,src)
 #define OFI_OP_LXOR_COMPLEX(type,dst,src) (dst) = ofi_complex_lxor_##type(dst,src)
-#define OFI_OP_READ_COMPLEX		  OFI_OP_READ
-#define OFI_OP_WRITE_COMPLEX		  OFI_OP_WRITE
-
 #define OFI_OP_CSWAP_EQ_COMPLEX(type,dst,src,cmp) \
 			if (ofi_complex_eq_##type(dst,cmp)) (dst) = (src)
 #define OFI_OP_CSWAP_NE_COMPLEX(type,dst,src,cmp) \
 			if (!ofi_complex_eq_##type(dst,cmp)) (dst) = (src)
+#endif /* HAVE_BUILTIN_MM_ATOMICS */
 
+#define OFI_OP_READ_COMPLEX		OFI_OP_READ
+#define OFI_OP_WRITE_COMPLEX		OFI_OP_WRITE
 
 /********************************
  * ATOMIC TYPE function templates
@@ -112,8 +162,6 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
  * WRITE
  */
 #define OFI_DEF_WRITE_NAME(op, type) ofi_write_## op ##_## type,
-#define OFI_DEF_WRITE_COMPLEX_NAME(op, type) ofi_write_## op ##_## type,
-
 #define OFI_DEF_WRITE_FUNC(op, type)					\
 	static void ofi_write_## op ##_## type				\
 		(void *dst, const void *src, size_t cnt)		\
@@ -121,10 +169,14 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 		size_t i;						\
 		type *d = (dst);					\
 		const type *s = (src);					\
-		for (i = 0; i < cnt; i++)				\
-			op(type, d[i], s[i]);				\
+		type temp_s;						\
+		for (i = 0; i < cnt; i++) {				\
+			temp_s = s[i];					\
+			op(type, d[i], temp_s);				\
+		}							\
 	}
 
+#define OFI_DEF_WRITE_COMPLEX_NAME(op, type) ofi_write_## op ##_## type,
 #define OFI_DEF_WRITE_COMPLEX_FUNC(op, type)				\
 	static void ofi_write_## op ##_## type				\
 		(void *dst, const void *src, size_t cnt)		\
@@ -132,26 +184,112 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 		size_t i;						\
 		ofi_complex_##type *d = (dst);				\
 		const ofi_complex_##type *s = (src);			\
-		for (i = 0; i < cnt; i++)				\
-			op(type, d[i], s[i]);				\
+		ofi_complex_##type temp_s;				\
+		for (i = 0; i < cnt; i++) {				\
+			temp_s = s[i];					\
+			op(type, d[i], temp_s);				\
+		}							\
+	}
+
+#ifdef HAVE_BUILTIN_MM_ATOMICS
+
+#define OFI_DEF_WRITEEXT_NAME(op, type) ofi_write_## op ##_## type,
+#define OFI_DEF_WRITEEXT_FUNC(op, type)					\
+	static void ofi_write_## op ##_## type				\
+		(void *dst, const void *src, size_t cnt)		\
+	{								\
+		type target;						\
+		type val;						\
+		size_t i;						\
+		type *d = (dst);					\
+		const type *s = (src);					\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			success = 0;					\
+			do {						\
+				target = d[i];				\
+				val = op(type, d[i], s[i]);		\
+				success = __atomic_compare_exchange(	\
+						&d[i],&target,&val,0,	\
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+			} while (!success);				\
+		}							\
+	}
+
+#define OFI_DEF_WRITEEXT_CMP_NAME(op, type) ofi_write_## op ##_## type,
+#define OFI_DEF_WRITEEXT_CMP_FUNC(op, type)				\
+	static void ofi_write_## op ##_## type				\
+		(void *dst, const void *src, size_t cnt)		\
+	{								\
+		type target;						\
+		size_t i;						\
+		type *d = (dst);					\
+		const type *s = (src);					\
+		type temp_s;						\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			do {						\
+				success = 1;				\
+				target = d[i];				\
+				if (op(type, d[i], s[i])) {		\
+					temp_s = s[i];			\
+					success = __atomic_compare_exchange( \
+						&d[i],&target,&temp_s, 0, \
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+				}					\
+			} while (!success);				\
+		}							\
+	}
+
+#define OFI_DEF_WRITEEXT_COMPLEX_NAME(op, type) ofi_write_## op ##_## type,
+#define OFI_DEF_WRITEEXT_COMPLEX_FUNC(op, type)				\
+	static void ofi_write_## op ##_## type				\
+		(void *dst, const void *src, size_t cnt)		\
+	{								\
+		ofi_complex_##type target;				\
+		ofi_complex_##type val;					\
+		ofi_complex_##type *d = (dst);				\
+		const ofi_complex_##type *s = (src);			\
+		size_t i;						\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			success = 0;					\
+			do {						\
+				target = d[i];				\
+				val = op(type, d[i], s[i]);		\
+				success = __atomic_compare_exchange(	\
+						&d[i],&target,&val,0,	\
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+			} while (!success);				\
+		}							\
 	}
 
+#endif /* HAVE BUILTIN_MM_ATOMICS */
+
 /*
  * READ (fetch)
  */
 #define OFI_DEF_READ_NAME(op, type) ofi_read_## op ##_## type,
 #define OFI_DEF_READ_COMPLEX_NAME(op, type) ofi_read_## op ##_## type,
 
+#ifdef HAVE_BUILTIN_MM_ATOMICS
+
 #define OFI_DEF_READ_FUNC(op, type)					\
 	static void ofi_read_## op ##_## type				\
-		(void *dst, const void *src, void *res, size_t cnt) 	\
+		(void *dst, const void *src, void *res, size_t cnt)	\
 	{								\
 		size_t i;						\
 		type *d = (dst);					\
 		type *r = (res);					\
 		OFI_UNUSED(src);					\
 		for (i = 0; i < cnt; i++)				\
-			r[i] = d[i];					\
+			op(type, d[i], r[i]);				\
 	}
 
 #define OFI_DEF_READ_COMPLEX_FUNC(op, type)				\
@@ -163,15 +301,44 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 		ofi_complex_##type *r = (res);				\
 		OFI_UNUSED(src);					\
 		for (i = 0; i < cnt; i++)				\
-			r[i] = d[i];					\
+			op(type, d[i], r[i]);				\
+	}
+
+#else /* HAVE_BUILTIN_MM_ATOMICS */
+
+#define OFI_DEF_READ_FUNC(op, type)					\
+	static void ofi_read_## op ##_## type				\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		size_t i;						\
+		type *d = (dst);					\
+		type *r = (res);					\
+		OFI_UNUSED(src);					\
+		for (i = 0; i < cnt; i++)				\
+			r[i] = op(type, d[i], r[i]);			\
+	}
+
+#define OFI_DEF_READ_COMPLEX_FUNC(op, type)				\
+	static void ofi_read_## op ##_## type				\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		size_t i;						\
+		ofi_complex_##type *d = (dst);				\
+		ofi_complex_##type *r = (res);				\
+		OFI_UNUSED(src);					\
+		for (i = 0; i < cnt; i++)				\
+			r[i] = op(type, d[i], s[i]);			\
 	}
 
+#endif /* HAVE_BUILTIN_MM_ATOMICS */
+
 /*
  * READWRITE (fetch-write)
  */
-#define OFI_DEF_READWRITE_NAME(op, type) ofi_readwrite_## op ##_## type,
-#define OFI_DEF_READWRITE_COMPLEX_NAME(op, type) ofi_readwrite_## op ##_## type,
 
+#ifdef HAVE_BUILTIN_MM_ATOMICS
+
+#define OFI_DEF_READWRITE_NAME(op, type) ofi_readwrite_## op ##_## type,
 #define OFI_DEF_READWRITE_FUNC(op, type)				\
 	static void ofi_readwrite_## op ##_## type			\
 		(void *dst, const void *src, void *res, size_t cnt)	\
@@ -180,41 +347,333 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 		type *d = (dst);					\
 		const type *s = (src);					\
 		type *r = (res);					\
+		type temp_s;						\
+		for (i = 0; i < cnt; i++) {				\
+			temp_s = s[i];					\
+			r[i] = op(type, d[i], temp_s);			\
+		}							\
+	}
+
+#define OFI_DEF_READWRITEEXT_NAME(op, type) ofi_readwrite_## op ##_## type,
+#define OFI_DEF_READWRITEEXT_FUNC(op, type)				\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		type target;						\
+		type val;						\
+		size_t i;						\
+		type *d = (dst);					\
+		type *r = (res);					\
+		const type *s = (src);					\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			success = 0;					\
+			do {						\
+				target = d[i];				\
+				val = op(type, d[i], s[i]);		\
+				success = __atomic_compare_exchange(	\
+						&d[i],&target,&val,0,	\
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+			} while (!success);				\
+			r[i] = target;					\
+		}							\
+	}
+
+#define OFI_DEF_READWRITEEXT_CMP_NAME(op, type) ofi_readwrite_## op ##_## type,
+#define OFI_DEF_READWRITEEXT_CMP_FUNC(op, type)				\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		type target;						\
+		size_t i;						\
+		type *d = (dst);					\
+		type *r = (res);					\
+		const type *s = (src);					\
+		type temp_s;						\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			do {						\
+				target = d[i];				\
+				success = 1;				\
+				if (op(type, d[i], s[i])) {		\
+					temp_s = s[i];		\
+					success = __atomic_compare_exchange( \
+						&d[i],&target,&temp_s, 0, \
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+				}					\
+			} while (!success);				\
+			r[i] = target;					\
+		}							\
+	}
+
+#define OFI_DEF_EXCHANGE_NAME(op, type) ofi_readwrite_## op ##_## type,
+#define OFI_DEF_EXCHANGE_FUNC(op, type)					\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		size_t i;						\
+		type *d = dst;						\
+		const type *s = src;					\
+		type *r = res;						\
+		type temp_s;						\
+		for (i = 0; i < cnt; i++) {				\
+			temp_s = s[i];					\
+			op(type, d[i], temp_s, r[i]);			\
+		}							\
+	}
+
+#define OFI_DEF_READWRITE_COMPLEX_NAME(op, type) ofi_readwrite_## op ##_## type,
+#define OFI_DEF_READWRITE_COMPLEX_FUNC(op, type)			\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		ofi_complex_##type *d = dst;				\
+		const ofi_complex_##type *s = src;			\
+		ofi_complex_##type *r = res;				\
+		ofi_complex_##type temp_s;				\
+		size_t i;						\
+		for (i = 0; i < cnt; i++) {				\
+			temp_s = s[i];					\
+			r[i] = op(type, d[i], temp_s);			\
+		}							\
+	}
+
+#define OFI_DEF_READWRITEEXT_COMPLEX_NAME(op, type) ofi_readwrite_## op ##_## type,
+#define OFI_DEF_READWRITEEXT_COMPLEX_FUNC(op, type)			\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		ofi_complex_##type target;				\
+		ofi_complex_##type val;					\
+		ofi_complex_##type *d = dst;				\
+		ofi_complex_##type *r = res;				\
+		const ofi_complex_##type *s = src;			\
+		size_t i;						\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			success = 0;					\
+			do {						\
+				target = d[i];				\
+				val = op(type, d[i], s[i]);		\
+				success = __atomic_compare_exchange(	\
+						&d[i],&target,&val,0,	\
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+			} while (!success);				\
+			r[i] = target;					\
+		}							\
+	}
+
+#define OFI_DEF_EXCHANGE_COMPLEX_NAME(op, type) ofi_readwrite_## op ##_## type,
+#define OFI_DEF_EXCHANGE_COMPLEX_FUNC(op, type)				\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		ofi_complex_##type *d = dst;				\
+		const ofi_complex_##type *s = src;			\
+		ofi_complex_##type *r = res;				\
+		ofi_complex_##type temp_s;				\
+		size_t i;						\
+		for (i = 0; i < cnt; i++) {				\
+			temp_s = s[i];					\
+			op(type, d[i], temp_s, r[i]);			\
+		}							\
+	}
+
+#else /* HAVE_BUILTIN_MM_ATOMICS */
+
+#define OFI_DEF_READWRITE_NAME(op, type) ofi_readwrite_## op ##_## type,
+#define OFI_DEF_READWRITE_FUNC(op, type)				\
+	static void ofi_readwrite_## op ##_## type			\
+		(void *dst, const void *src, void *res, size_t cnt)	\
+	{								\
+		size_t i;						\
+		type *d = dst;						\
+		const type *s = src;					\
+		type *r = res;						\
 		for (i = 0; i < cnt; i++) {				\
 			r[i] = d[i];					\
 			op(type, d[i], s[i]);				\
 		}							\
 	}
 
+#define OFI_DEF_READWRITE_COMPLEX_NAME(op, type) ofi_readwrite_## op ##_## type,
 #define OFI_DEF_READWRITE_COMPLEX_FUNC(op, type)			\
 	static void ofi_readwrite_## op ##_## type			\
 		(void *dst, const void *src, void *res, size_t cnt)	\
 	{								\
 		size_t i;						\
-		ofi_complex_##type *d = (dst);				\
-		const ofi_complex_##type *s = (src);			\
-		ofi_complex_##type *r = (res);				\
+		ofi_complex_##type *d = dst;				\
+		const ofi_complex_##type *s = src;			\
+		ofi_complex_##type *r = res;				\
 		for (i = 0; i < cnt; i++) {				\
 			r[i] = d[i];					\
 			op(type, d[i], s[i]);				\
 		}							\
 	}
 
+#endif /* HAVE_BUILTIN_MM_ATOMICS */
+
 /*
  * CSWAP
  */
+#ifdef HAVE_BUILTIN_MM_ATOMICS
+
 #define OFI_DEF_CSWAP_NAME(op, type) ofi_cswap_## op ##_## type,
+#define OFI_DEF_CSWAP_FUNC(op, type)					\
+	static void ofi_cswap_## op ##_## type				\
+		(void *dst, const void *src, const void *cmp,		\
+		 void *res, size_t cnt)					\
+	{								\
+		size_t i;						\
+		type *d = dst;						\
+		const type *s = src;					\
+		const type *c = cmp;					\
+		type *r = res;						\
+		type temp_c;						\
+		type temp_s;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			temp_c = c[i];					\
+			temp_s = s[i];					\
+			/* We never use weak operations */		\
+			(void) op(type, d[i], temp_s, temp_c);		\
+			/* If d[i] != temp_c then d[i] -> temp_c */	\
+			r[i] = temp_c;					\
+		}							\
+	}
+
+#define OFI_DEF_CSWAPEXT_NAME(op, type) ofi_cswap_## op ##_## type,
+#define OFI_DEF_CSWAPEXT_FUNC(op, type)					\
+	static void ofi_cswap_## op ##_## type				\
+		(void *dst, const void *src, const void *cmp,		\
+		 void *res, size_t cnt)					\
+	{								\
+		type target;						\
+		size_t i;						\
+		type *d = dst;						\
+		type *r = res;						\
+		const type *c = cmp;					\
+		const type *s = src;					\
+		type val;						\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			success = 0;					\
+			do {						\
+				target = d[i];				\
+				val = op(type, d[i], s[i], c[i]);	\
+				success = __atomic_compare_exchange(	\
+						&d[i],&target,&val, 0,	\
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+			} while (!success);				\
+			r[i] = target;					\
+		}							\
+	}
+
+#define OFI_DEF_CSWAPEXT_CMP_NAME(op, type) ofi_cswap_## op ##_## type,
+#define OFI_DEF_CSWAPEXT_CMP_FUNC(op, type)				\
+	static void ofi_cswap_## op ##_## type				\
+		(void *dst, const void *src, const void *cmp,		\
+		 void *res, size_t cnt)					\
+	{								\
+		type target;						\
+		size_t i;						\
+		type *d = dst;						\
+		type *r = res;						\
+		const type *c = cmp;					\
+		const type *s = src;					\
+		type temp_s;						\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			do {						\
+				success = 1;				\
+				target = d[i];				\
+				if (op(type, d[i], s[i], c[i])) {	\
+					temp_s = s[i];			\
+					success = __atomic_compare_exchange( \
+						&d[i],&target,&temp_s, 0, \
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+				}					\
+			} while (!success);				\
+			r[i] = target;					\
+		}							\
+	}
+
 #define OFI_DEF_CSWAP_COMPLEX_NAME(op, type) ofi_cswap_## op ##_## type,
+#define OFI_DEF_CSWAP_COMPLEX_FUNC(op, type)				\
+	static void ofi_cswap_## op ##_## type				\
+		(void *dst, const void *src, const void *cmp,		\
+		 void *res, size_t cnt)					\
+	{								\
+		ofi_complex_##type *d = dst;				\
+		const ofi_complex_##type *s = src;			\
+		const ofi_complex_##type *c = cmp;			\
+		ofi_complex_##type *r = res;				\
+		ofi_complex_##type temp_c;				\
+		ofi_complex_##type temp_s;				\
+		size_t i;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			temp_c = c[i];					\
+			temp_s = s[i];					\
+			(void) op(type, d[i], temp_s, temp_c);		\
+			/* If d[i] != temp_c then d[i] -> temp_c */	\
+			r[i] = temp_c;					\
+		}							\
+	}
 
+#define OFI_DEF_CSWAPEXT_CMP_COMPLEX_NAME(op, type) ofi_cswap_## op ##_## type,
+#define OFI_DEF_CSWAPEXT_CMP_COMPLEX_FUNC(op, type)			\
+	static void ofi_cswap_## op ##_## type				\
+		(void *dst, const void *src, const void *cmp,		\
+		 void *res, size_t cnt)					\
+	{								\
+		ofi_complex_##type target;				\
+		ofi_complex_##type *d = dst;				\
+		ofi_complex_##type *r = res;				\
+		const ofi_complex_##type *c = cmp;			\
+		const ofi_complex_##type *s = src;			\
+		ofi_complex_##type temp_s;				\
+		size_t i;						\
+		int success;						\
+									\
+		for (i = 0; i < cnt; i++) {				\
+			do {						\
+				success = 1;				\
+				target = d[i];				\
+				if (op(type, d[i], s[i], c[i])) {	\
+					temp_s = s[i];			\
+					success = __atomic_compare_exchange( \
+						&d[i],&target,&temp_s, 0, \
+						__ATOMIC_SEQ_CST,	\
+						__ATOMIC_SEQ_CST);	\
+				}					\
+			} while (!success);				\
+			r[i] = target;					\
+		}							\
+	}
+
+#else /* HAVE_BUILTIN_MM_ATOMICS */
+
+#define OFI_DEF_CSWAP_NAME(op, type) ofi_cswap_## op ##_## type,
 #define OFI_DEF_CSWAP_FUNC(op, type)					\
 	static void ofi_cswap_## op ##_## type				\
 		(void *dst, const void *src, const void *cmp,		\
 		 void *res, size_t cnt)					\
 	{								\
 		size_t i;						\
-		type *d = (dst);					\
-		const type *s = (src);					\
-		const type *c = (cmp);					\
+		type *d = dst;						\
+		const type *s = src;					\
+		const type *c = cmp;					\
 		type *r = (res);					\
 		for (i = 0; i < cnt; i++) {				\
 			r[i] = d[i];					\
@@ -222,22 +681,24 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 		}							\
 	}
 
+#define OFI_DEF_CSWAP_COMPLEX_NAME(op, type) ofi_cswap_## op ##_## type,
 #define OFI_DEF_CSWAP_COMPLEX_FUNC(op, type)				\
 	static void ofi_cswap_## op ##_## type				\
 		(void *dst, const void *src, const void *cmp,		\
 		 void *res, size_t cnt)					\
 	{								\
 		size_t i;						\
-		ofi_complex_##type *d = (dst);				\
-		const ofi_complex_##type *s = (src);			\
-		const ofi_complex_##type *c = (cmp);			\
-		ofi_complex_##type *r = (res);				\
+		ofi_complex_##type *d = dst;				\
+		const ofi_complex_##type *s = src;			\
+		const ofi_complex_##type *c = cmp;			\
+		ofi_complex_##type *r = res;				\
 		for (i = 0; i < cnt; i++) {				\
 			r[i] = d[i];					\
 			op(type, d[i], s[i], c[i]);			\
 		}							\
 	}
 
+#endif /* HAVE_BUILTIN_MM_ATOMICS */
 
 /*********************************************************************
  * Macros create atomic functions for each operation for each datatype
@@ -251,6 +712,25 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
  *            The latter is needed to populate the dispatch table
  * op - OFI_OP_XXX function should perform (e.g. OFI_OP_MIN)
  */
+#define OFI_DEFINE_INT_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint64_t)			\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME
+
+#ifdef HAVE_BUILTIN_MM_ATOMICS
+
+/* Only support 8 byte and under datatypes */
 #define OFI_DEFINE_ALL_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int8_t)			\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint8_t)			\
@@ -263,9 +743,9 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, float)			\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, double)			\
 	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, float)	\
-	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, double)\
-	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, long_double)		\
-	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, long_double)
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_NOOP_##FUNCNAME
 
 #define OFI_DEFINE_REALNO_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int8_t)			\
@@ -280,10 +760,12 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, double)			\
 	OFI_DEF_NOOP_##FUNCNAME						\
 	OFI_DEF_NOOP_##FUNCNAME						\
-	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, long_double)		\
+	OFI_DEF_NOOP_##FUNCNAME						\
 	OFI_DEF_NOOP_##FUNCNAME
 
-#define OFI_DEFINE_INT_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
+#else /* HAVE_BUILTIN_MM_ATOMICS */
+
+#define OFI_DEFINE_ALL_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int8_t)			\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint8_t)			\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int16_t)			\
@@ -292,13 +774,128 @@ size_t ofi_datatype_size(enum fi_datatype datatype)
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint32_t)			\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int64_t)			\
 	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, float)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, double)			\
+	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, float)	\
+	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, double)\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, long_double)		\
+	OFI_DEF_##ATOMICTYPE##_COMPLEX_##FUNCNAME(op ##_COMPLEX, long_double)
+
+#define OFI_DEFINE_REALNO_HANDLERS(ATOMICTYPE, FUNCNAME, op)		\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint8_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint16_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint32_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, int64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, uint64_t)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, float)			\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, double)			\
 	OFI_DEF_NOOP_##FUNCNAME						\
 	OFI_DEF_NOOP_##FUNCNAME						\
-	OFI_DEF_NOOP_##FUNCNAME						\
-	OFI_DEF_NOOP_##FUNCNAME						\
-	OFI_DEF_NOOP_##FUNCNAME						\
+	OFI_DEF_##ATOMICTYPE##_##FUNCNAME(op, long_double)		\
 	OFI_DEF_NOOP_##FUNCNAME
 
+#endif /* HAVE_BUILTIN_MM_ATOMICS */
+
+#define OFI_OP_NOT_SUPPORTED(op)	NULL, NULL, NULL, NULL, NULL,	\
+			NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL
+
+#ifdef HAVE_BUILTIN_MM_ATOMICS
+
+/**********************
+ * Compiler built-in atomics write dispatch table
+ **********************/
+
+OFI_DEFINE_REALNO_HANDLERS(WRITEEXT_CMP, FUNC, OFI_OP_MIN)
+OFI_DEFINE_REALNO_HANDLERS(WRITEEXT_CMP, FUNC, OFI_OP_MAX)
+OFI_DEFINE_ALL_HANDLERS(WRITEEXT, FUNC, OFI_OP_SUM)
+OFI_DEFINE_ALL_HANDLERS(WRITEEXT, FUNC, OFI_OP_PROD)
+OFI_DEFINE_ALL_HANDLERS(WRITEEXT, FUNC, OFI_OP_LOR)
+OFI_DEFINE_ALL_HANDLERS(WRITEEXT, FUNC, OFI_OP_LAND)
+OFI_DEFINE_INT_HANDLERS(WRITE, FUNC, OFI_OP_BOR)
+OFI_DEFINE_INT_HANDLERS(WRITE, FUNC, OFI_OP_BAND)
+OFI_DEFINE_ALL_HANDLERS(WRITEEXT, FUNC, OFI_OP_LXOR)
+OFI_DEFINE_INT_HANDLERS(WRITE, FUNC, OFI_OP_BXOR)
+OFI_DEFINE_ALL_HANDLERS(WRITE, FUNC, OFI_OP_WRITE)
+
+void (*ofi_atomic_write_handlers[OFI_WRITE_OP_LAST][FI_DATATYPE_LAST])
+	(void *dst, const void *src, size_t cnt) =
+{
+	{ OFI_DEFINE_REALNO_HANDLERS(WRITEEXT_CMP, NAME, OFI_OP_MIN) },
+	{ OFI_DEFINE_REALNO_HANDLERS(WRITEEXT_CMP, NAME, OFI_OP_MAX) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITEEXT, NAME, OFI_OP_SUM) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITEEXT, NAME, OFI_OP_PROD) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITEEXT, NAME, OFI_OP_LOR) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITEEXT, NAME, OFI_OP_LAND) },
+	{ OFI_DEFINE_INT_HANDLERS(WRITE, NAME, OFI_OP_BOR) },
+	{ OFI_DEFINE_INT_HANDLERS(WRITE, NAME, OFI_OP_BAND) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITEEXT, NAME, OFI_OP_LXOR) },
+	{ OFI_DEFINE_INT_HANDLERS(WRITE, NAME, OFI_OP_BXOR) },
+	{ OFI_OP_NOT_SUPPORTED(FI_ATOMIC_READ) },
+	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_WRITE) },
+};
+
+/***************************
+ * Compiler built-in atomics read-write dispatch table
+ ***************************/
+
+OFI_DEFINE_REALNO_HANDLERS(READWRITEEXT_CMP, FUNC, OFI_OP_MIN)
+OFI_DEFINE_REALNO_HANDLERS(READWRITEEXT_CMP, FUNC, OFI_OP_MAX)
+OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, FUNC, OFI_OP_SUM)
+OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, FUNC, OFI_OP_PROD)
+OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, FUNC, OFI_OP_LOR)
+OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, FUNC, OFI_OP_LAND)
+OFI_DEFINE_INT_HANDLERS(READWRITE, FUNC, OFI_OP_BOR)
+OFI_DEFINE_INT_HANDLERS(READWRITE, FUNC, OFI_OP_BAND)
+OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, FUNC, OFI_OP_LXOR)
+OFI_DEFINE_INT_HANDLERS(READWRITE, FUNC, OFI_OP_BXOR)
+OFI_DEFINE_ALL_HANDLERS(READ, FUNC, OFI_OP_READ)
+OFI_DEFINE_ALL_HANDLERS(EXCHANGE, FUNC, OFI_OP_READWRITE)
+
+void (*ofi_atomic_readwrite_handlers[OFI_READWRITE_OP_LAST][FI_DATATYPE_LAST])
+	(void *dst, const void *src, void *res, size_t cnt) =
+{
+	{ OFI_DEFINE_REALNO_HANDLERS(READWRITEEXT_CMP, NAME, OFI_OP_MIN) },
+	{ OFI_DEFINE_REALNO_HANDLERS(READWRITEEXT_CMP, NAME, OFI_OP_MAX) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, NAME, OFI_OP_SUM) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, NAME, OFI_OP_PROD) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, NAME, OFI_OP_LOR) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, NAME, OFI_OP_LAND) },
+	{ OFI_DEFINE_INT_HANDLERS(READWRITE, NAME, OFI_OP_BOR) },
+	{ OFI_DEFINE_INT_HANDLERS(READWRITE, NAME, OFI_OP_BAND) },
+	{ OFI_DEFINE_ALL_HANDLERS(READWRITEEXT, NAME, OFI_OP_LXOR) },
+	{ OFI_DEFINE_INT_HANDLERS(READWRITE, NAME, OFI_OP_BXOR) },
+	{ OFI_DEFINE_ALL_HANDLERS(READ, NAME, OFI_OP_READ) },
+	{ OFI_DEFINE_ALL_HANDLERS(EXCHANGE, NAME, OFI_OP_READWRITE) },
+};
+
+/*****************************
+ * Compiler built-in atomics compare-swap dispatch table
+ *****************************/
+
+OFI_DEFINE_ALL_HANDLERS(CSWAP, FUNC, OFI_OP_CSWAP_EQ)
+OFI_DEFINE_ALL_HANDLERS(CSWAPEXT_CMP, FUNC, OFI_OP_CSWAP_NE)
+OFI_DEFINE_REALNO_HANDLERS(CSWAPEXT_CMP, FUNC, OFI_OP_CSWAP_LE)
+OFI_DEFINE_REALNO_HANDLERS(CSWAPEXT_CMP, FUNC, OFI_OP_CSWAP_LT)
+OFI_DEFINE_REALNO_HANDLERS(CSWAPEXT_CMP, FUNC, OFI_OP_CSWAP_GE)
+OFI_DEFINE_REALNO_HANDLERS(CSWAPEXT_CMP, FUNC, OFI_OP_CSWAP_GT)
+OFI_DEFINE_INT_HANDLERS(CSWAPEXT, FUNC, OFI_OP_MSWAP)
+
+void (*ofi_atomic_swap_handlers[OFI_SWAP_OP_LAST][FI_DATATYPE_LAST])
+	(void *dst, const void *src, const void *cmp, void *res, size_t cnt) =
+{
+	{ OFI_DEFINE_ALL_HANDLERS(CSWAP, NAME, OFI_OP_CSWAP_EQ) },
+	{ OFI_DEFINE_ALL_HANDLERS(CSWAPEXT_CMP, NAME, OFI_OP_CSWAP_NE) },
+	{ OFI_DEFINE_REALNO_HANDLERS(CSWAPEXT_CMP, NAME, OFI_OP_CSWAP_LE) },
+	{ OFI_DEFINE_REALNO_HANDLERS(CSWAPEXT_CMP, NAME, OFI_OP_CSWAP_LT) },
+	{ OFI_DEFINE_REALNO_HANDLERS(CSWAPEXT_CMP, NAME, OFI_OP_CSWAP_GE) },
+	{ OFI_DEFINE_REALNO_HANDLERS(CSWAPEXT_CMP, NAME, OFI_OP_CSWAP_GT) },
+	{ OFI_DEFINE_INT_HANDLERS(CSWAPEXT, NAME, OFI_OP_MSWAP) },
+};
+
+#else /* HAVE_BUILTIN_MM_ATOMICS */
 
 /**********************
  * Write dispatch table
@@ -329,12 +926,10 @@ void (*ofi_atomic_write_handlers[OFI_WRITE_OP_LAST][FI_DATATYPE_LAST])
 	{ OFI_DEFINE_INT_HANDLERS(WRITE, NAME, OFI_OP_BAND) },
 	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_LXOR) },
 	{ OFI_DEFINE_INT_HANDLERS(WRITE, NAME, OFI_OP_BXOR) },
-	 /* no-op: FI_ATOMIC_READ */
-	{ NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL},
+	{ OFI_OP_NOT_SUPPORTED(FI_ATOMIC_READ) },
 	{ OFI_DEFINE_ALL_HANDLERS(WRITE, NAME, OFI_OP_WRITE) },
 };
 
-
 /***************************
  * Read-write dispatch table
  ***************************/
@@ -369,7 +964,6 @@ void (*ofi_atomic_readwrite_handlers[OFI_READWRITE_OP_LAST][FI_DATATYPE_LAST])
 	{ OFI_DEFINE_ALL_HANDLERS(READWRITE, NAME, OFI_OP_WRITE) },
 };
 
-
 /*****************************
  * Compare-swap dispatch table
  *****************************/
@@ -394,6 +988,7 @@ void (*ofi_atomic_swap_handlers[OFI_SWAP_OP_LAST][FI_DATATYPE_LAST])
 	{ OFI_DEFINE_INT_HANDLERS(CSWAP, NAME, OFI_OP_MSWAP) },
 };
 
+#endif /* HAVE_BUILTIN_MM_ATOMICS */
 
 int ofi_atomic_valid(const struct fi_provider *prov,
 		     enum fi_datatype datatype, enum fi_op op, uint64_t flags)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_attr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_attr.c
index 4ed9c14b8..219ed770a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_attr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_attr.c
@@ -33,6 +33,7 @@
 
 #include <stdio.h>
 
+#include <shared/ofi_str.h>
 #include <ofi_util.h>
 
 #define OFI_MSG_CAPS	(FI_SEND | FI_RECV)
@@ -40,7 +41,7 @@
 
 static int fi_valid_addr_format(uint32_t prov_format, uint32_t user_format)
 {
-	if (user_format == FI_FORMAT_UNSPEC)
+	if (user_format == FI_FORMAT_UNSPEC || prov_format == FI_FORMAT_UNSPEC)
 		return 1;
 
 	switch (prov_format) {
@@ -89,52 +90,43 @@ char *ofi_strdup_append(const char *head, const char *tail)
 	return str;
 }
 
-static int ofi_has_util_prefix(const char *str)
+int ofi_exclude_prov_name(char **prov_name_list, const char *util_prov_name)
 {
-	return !strncasecmp(str, OFI_UTIL_PREFIX, strlen(OFI_UTIL_PREFIX));
-}
+	char *exclude, *name, *temp;
 
-const char *ofi_util_name(const char *str, size_t *len)
-{
-	char *delim;
+	exclude = malloc(strlen(util_prov_name) + 2);
+	if (!exclude)
+		return -FI_ENOMEM;
 
-	delim = strchr(str, OFI_NAME_DELIM);
-	if (delim) {
-		if (ofi_has_util_prefix(delim + 1)) {
-			*len = strlen(delim + 1);
-			return delim + 1;
-		} else if (ofi_has_util_prefix(str)) {
-			*len = delim - str;
-			return str;
-		}
-	} else if (ofi_has_util_prefix(str)) {
-		*len = strlen(str);
-		return str;
-	}
-	*len = 0;
-	return NULL;
-}
+	exclude[0] = '^';
+	strcpy(&exclude[1], util_prov_name);
 
-const char *ofi_core_name(const char *str, size_t *len)
-{
-	char *delim;
+	if (!*prov_name_list)
+		goto out;
 
-	delim = strchr(str, OFI_NAME_DELIM);
-	if (delim) {
-		if (!ofi_has_util_prefix(delim + 1)) {
-			*len = strlen(delim + 1);
-			return delim + 1;
-		} else if (!ofi_has_util_prefix(str)) {
-			*len = delim - str;
-			return str;
-		}
-	} else if (!ofi_has_util_prefix(str)) {
-		*len = strlen(str);
-		return str;
-	}
-	*len = 0;
-	return NULL;
+	name = strdup(*prov_name_list);
+	if (!name)
+		goto err1;
+
+	ofi_rm_substr_delim(name, util_prov_name, OFI_NAME_DELIM);
 
+	if (strlen(name)) {
+		temp = ofi_strdup_append(name, exclude);
+		if (!temp)
+			goto err2;
+		free(exclude);
+		exclude = temp;
+	}
+	free(name);
+	free(*prov_name_list);
+out:
+	*prov_name_list = exclude;
+	return 0;
+err2:
+	free(name);
+err1:
+	free(exclude);
+	return -FI_ENOMEM;
 }
 
 static int ofi_dup_addr(const struct fi_info *info, struct fi_info *dup)
@@ -163,8 +155,7 @@ static int ofi_info_to_core(uint32_t version, const struct fi_provider *prov,
 			    ofi_alter_info_t info_to_core,
 			    struct fi_info **core_hints)
 {
-	const char *core_name;
-	size_t len;
+	int ret = -FI_ENOMEM;
 
 	if (!(*core_hints = fi_allocinfo()))
 		return -FI_ENOMEM;
@@ -190,17 +181,18 @@ static int ofi_info_to_core(uint32_t version, const struct fi_provider *prov,
 		}
 
 		if (util_info->fabric_attr->prov_name) {
-			core_name = ofi_core_name(util_info->fabric_attr->
-						  prov_name, &len);
-			if (core_name) {
-				(*core_hints)->fabric_attr->prov_name =
-					strndup(core_name, len);
-				if (!(*core_hints)->fabric_attr->prov_name) {
-					FI_WARN(prov, FI_LOG_FABRIC,
-						"Unable to alloc prov name\n");
-					goto err;
-				}
+			(*core_hints)->fabric_attr->prov_name =
+				strdup(util_info->fabric_attr->prov_name);
+			if (!(*core_hints)->fabric_attr->prov_name) {
+				FI_WARN(prov, FI_LOG_FABRIC,
+					"Unable to alloc prov name\n");
+				goto err;
 			}
+			ret = ofi_exclude_prov_name(
+					&(*core_hints)->fabric_attr->prov_name,
+					prov->name);
+			if (ret)
+				goto err;
 		}
 	}
 
@@ -217,7 +209,7 @@ static int ofi_info_to_core(uint32_t version, const struct fi_provider *prov,
 
 err:
 	fi_freeinfo(*core_hints);
-	return -FI_ENOMEM;
+	return ret;
 }
 
 static int ofi_info_to_util(uint32_t version, const struct fi_provider *prov,
@@ -335,28 +327,34 @@ int ofix_getinfo(uint32_t version, const char *node, const char *service,
 }
 
 /* Caller should use only fabric_attr in returned core_info */
-int ofi_get_core_info_fabric(struct fi_fabric_attr *util_attr,
+int ofi_get_core_info_fabric(const struct fi_provider *prov,
+			     const struct fi_fabric_attr *util_attr,
 			     struct fi_info **core_info)
 {
 	struct fi_info hints;
-	const char *core_name;
-	size_t len;
 	int ret;
 
-	core_name = ofi_core_name(util_attr->prov_name, &len);
-	if (!core_name)
+	/* ofix_getinfo() would append utility provider name after core / lower
+	 * layer provider name */
+	if (!strstr(util_attr->prov_name, prov->name))
 		return -FI_ENODATA;
 
 	memset(&hints, 0, sizeof hints);
 	if (!(hints.fabric_attr = calloc(1, sizeof(*hints.fabric_attr))))
 		return -FI_ENOMEM;
 
-	hints.fabric_attr->name = util_attr->name;
-	hints.fabric_attr->api_version = util_attr->api_version;
-	if (!(hints.fabric_attr->prov_name = strndup(core_name, len))) {
+	hints.fabric_attr->prov_name = strdup(util_attr->prov_name);
+	if (!hints.fabric_attr->prov_name) {
 		ret = -FI_ENOMEM;
 		goto out;
 	}
+
+	ret = ofi_exclude_prov_name(&hints.fabric_attr->prov_name, prov->name);
+	if (ret)
+		goto out;
+
+	hints.fabric_attr->name = util_attr->name;
+	hints.fabric_attr->api_version = util_attr->api_version;
 	hints.mode = ~0;
 
 	ret = fi_getinfo(util_attr->api_version, NULL, NULL, OFI_CORE_PROV_ONLY,
@@ -621,6 +619,20 @@ int ofi_check_domain_attr(const struct fi_provider *prov, uint32_t api_version,
 	return 0;
 }
 
+static int ofi_check_ep_type(const struct fi_provider *prov,
+			     const struct fi_ep_attr *prov_attr,
+			     const struct fi_ep_attr *user_attr)
+{
+	if ((user_attr->type != FI_EP_UNSPEC) &&
+	    (prov_attr->type != FI_EP_UNSPEC) &&
+	    (user_attr->type != prov_attr->type)) {
+		FI_INFO(prov, FI_LOG_CORE, "Unsupported endpoint type\n");
+		FI_INFO_CHECK(prov, prov_attr, user_attr, type, FI_TYPE_EP_TYPE);
+		return -FI_ENODATA;
+	}
+	return 0;
+}
+
 int ofi_check_ep_attr(const struct util_prov *util_prov, uint32_t api_version,
 		      const struct fi_info *prov_info,
 		      const struct fi_info *user_info)
@@ -628,13 +640,11 @@ int ofi_check_ep_attr(const struct util_prov *util_prov, uint32_t api_version,
 	const struct fi_ep_attr *prov_attr = prov_info->ep_attr;
 	const struct fi_ep_attr *user_attr = user_info->ep_attr;
 	const struct fi_provider *prov = util_prov->prov;
+	int ret;
 
-	if ((user_attr->type != FI_EP_UNSPEC) &&
-	    (user_attr->type != prov_attr->type)) {
-		FI_INFO(prov, FI_LOG_CORE, "Unsupported endpoint type\n");
-		FI_INFO_CHECK(prov, prov_attr, user_attr, type, FI_TYPE_EP_TYPE);
-		return -FI_ENODATA;
-	}
+	ret = ofi_check_ep_type(prov, prov_attr, user_attr);
+	if (ret)
+		return ret;
 
 	if ((user_attr->protocol != FI_PROTO_UNSPEC) &&
 	    (user_attr->protocol != prov_attr->protocol)) {
@@ -975,6 +985,15 @@ int ofi_check_info(const struct util_prov *util_prov,
 	if (!user_info)
 		return 0;
 
+	/* Check oft-used endpoint type attribute first to avoid any other
+	 * unnecessary check */
+	if (user_info->ep_attr) {
+		ret = ofi_check_ep_type(prov, prov_info->ep_attr,
+					user_info->ep_attr);
+		if (ret)
+			return ret;
+	}
+
 	if (user_info->caps & ~(prov_info->caps)) {
 		FI_INFO(prov, FI_LOG_CORE, "Unsupported capabilities\n");
 		FI_INFO_CHECK(prov, prov_info, user_info, caps, FI_TYPE_CAPS);
@@ -992,6 +1011,8 @@ int ofi_check_info(const struct util_prov *util_prov,
 	if (!fi_valid_addr_format(prov_info->addr_format,
 				  user_info->addr_format)) {
 		FI_INFO(prov, FI_LOG_CORE, "address format not supported\n");
+		FI_INFO_CHECK(prov, prov_info, user_info, addr_format,
+			      FI_TYPE_ADDR_FORMAT);
 		return -FI_ENODATA;
 	}
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_av.c
index af319f44b..5e9fd129b 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_av.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_av.c
@@ -56,8 +56,6 @@ enum {
 	UTIL_DEFAULT_AV_SIZE = 1024,
 };
 
-static int ofi_cmap_move_handle_to_peer_list(struct util_cmap *cmap, int index);
-
 static int fi_get_src_sockaddr(const struct sockaddr *dest_addr, size_t dest_addrlen,
 			       struct sockaddr **src_addr, size_t *src_addrlen)
 {
@@ -104,7 +102,7 @@ out:
 
 }
 
-void ofi_getnodename(char *buf, int buflen)
+void ofi_getnodename(uint16_t sa_family, char *buf, int buflen)
 {
 	int ret;
 	struct addrinfo ai, *rai = NULL;
@@ -115,7 +113,7 @@ void ofi_getnodename(char *buf, int buflen)
 	buf[buflen - 1] = '\0';
 	if (ret == 0) {
 		memset(&ai, 0, sizeof(ai));
-		ai.ai_family = AF_INET;
+		ai.ai_family = sa_family  ? sa_family : AF_INET;
 		ret = getaddrinfo(buf, NULL, &ai, &rai);
 		if (!ret) {
 			freeaddrinfo(rai);
@@ -127,11 +125,18 @@ void ofi_getnodename(char *buf, int buflen)
 	ret = ofi_getifaddrs(&ifaddrs);
 	if (!ret) {
 		for (ifa = ifaddrs; ifa != NULL; ifa = ifa->ifa_next) {
-			if (ifa->ifa_addr == NULL || !(ifa->ifa_flags & IFF_UP) ||
-			     (ifa->ifa_addr->sa_family != AF_INET))
+			if (ifa->ifa_addr == NULL || !(ifa->ifa_flags & IFF_UP))
+				continue;
+
+			if (sa_family) {
+				if (ifa->ifa_addr->sa_family != sa_family)
+					continue;
+			} else if ((ifa->ifa_addr->sa_family != AF_INET) &&
+				   (ifa->ifa_addr->sa_family != AF_INET6)) {
 				continue;
+			}
 
-			ret = getnameinfo(ifa->ifa_addr, sizeof(struct sockaddr_in),
+			ret = getnameinfo(ifa->ifa_addr, ofi_sizeofaddr(ifa->ifa_addr),
 				  	  buf, buflen, NULL, 0, NI_NUMERICHOST);
 			buf[buflen - 1] = '\0';
 			if (ret == 0) {
@@ -142,7 +147,7 @@ void ofi_getnodename(char *buf, int buflen)
 		freeifaddrs(ifaddrs);
 	}
 #endif
-	/* no reasonable address found, try loopback */
+	/* no reasonable address found, use ipv4 loopback */
 	strncpy(buf, "127.0.0.1", buflen);
 	buf[buflen - 1] = '\0';
 }
@@ -163,7 +168,7 @@ int ofi_get_src_addr(uint32_t addr_format,
 	}
 }
 
-static int fi_get_sockaddr(int sa_family, uint64_t flags,
+static int fi_get_sockaddr(int *sa_family, uint64_t flags,
 			   const char *node, const char *service,
 			   struct sockaddr **addr, size_t *addrlen)
 {
@@ -171,7 +176,7 @@ static int fi_get_sockaddr(int sa_family, uint64_t flags,
 	int ret;
 
 	memset(&hints, 0, sizeof hints);
-	hints.ai_family = sa_family;
+	hints.ai_family = *sa_family;
 	hints.ai_socktype = SOCK_STREAM;
 	if (flags & FI_SOURCE)
 		hints.ai_flags = AI_PASSIVE;
@@ -186,6 +191,7 @@ static int fi_get_sockaddr(int sa_family, uint64_t flags,
 		goto out;
 	}
 
+	*sa_family = ai->ai_family;
 	*addrlen = ai->ai_addrlen;
 out:
 	freeaddrinfo(ai);
@@ -202,19 +208,29 @@ void ofi_get_str_addr(const char *node, const char *service,
 	*addrlen = strlen(node) + 1;
 }
 
-int ofi_get_addr(uint32_t addr_format, uint64_t flags,
+int ofi_get_addr(uint32_t *addr_format, uint64_t flags,
 		const char *node, const char *service,
 		void **addr, size_t *addrlen)
 {
-	switch (addr_format) {
+	int sa_family, ret;
+
+	switch (*addr_format) {
 	case FI_SOCKADDR:
-		return fi_get_sockaddr(0, flags, node, service,
-				       (struct sockaddr **) addr, addrlen);
+		sa_family = 0;
+		ret = fi_get_sockaddr(&sa_family, flags, node, service,
+				      (struct sockaddr **) addr, addrlen);
+		if (ret)
+			return ret;
+		*addr_format = sa_family == AF_INET ?
+			       FI_SOCKADDR_IN : FI_SOCKADDR_IN6;
+		return 0;
 	case FI_SOCKADDR_IN:
-		return fi_get_sockaddr(AF_INET, flags, node, service,
+		sa_family = AF_INET;
+		return fi_get_sockaddr(&sa_family, flags, node, service,
 				       (struct sockaddr **) addr, addrlen);
 	case FI_SOCKADDR_IN6:
-		return fi_get_sockaddr(AF_INET6, flags, node, service,
+		sa_family = AF_INET6;
+		return fi_get_sockaddr(&sa_family, flags, node, service,
 				       (struct sockaddr **) addr, addrlen);
 	case FI_ADDR_STR:
 		ofi_get_str_addr(node, service, (char **) addr, addrlen);
@@ -224,27 +240,14 @@ int ofi_get_addr(uint32_t addr_format, uint64_t flags,
 	}
 }
 
-static void *util_av_get_data(struct util_av *av, int index)
-{
-	return (char *) av->data + (index * av->addrlen);
-}
-
-void *ofi_av_get_addr(struct util_av *av, int index)
-{
-	FI_DBG(av->prov, FI_LOG_AV, "get[%d]:%s\n", index,
-		ofi_hex_str(util_av_get_data(av, index), av->addrlen));
-	return util_av_get_data(av, index);
-}
-
-static void util_av_set_data(struct util_av *av, int index,
-			     const void *data, size_t len)
+void *ofi_av_get_addr(struct util_av *av, fi_addr_t fi_addr)
 {
-	FI_DBG(av->prov, FI_LOG_AV, "set[%d]:%s\n", index,
-		ofi_hex_str(data, len));
-	memcpy(util_av_get_data(av, index), data, len);
+	struct util_av_entry *entry =
+		util_buf_get_by_index(av->av_entry_pool, fi_addr);
+	return entry->addr;
 }
 
-static int fi_verify_av_insert(struct util_av *av, uint64_t flags)
+int ofi_verify_av_insert(struct util_av *av, uint64_t flags)
 {
 	if ((av->flags & FI_EVENT) && !av->eq) {
 		FI_WARN(av->prov, FI_LOG_AV, "no EQ bound to AV\n");
@@ -262,230 +265,79 @@ static int fi_verify_av_insert(struct util_av *av, uint64_t flags)
 /*
  * Must hold AV lock
  */
-static int util_av_hash_insert(struct util_av_hash *hash, int slot,
-			       int index, int *table_slot)
+int ofi_av_insert_addr(struct util_av *av, const void *addr, fi_addr_t *fi_addr)
 {
-	int entry, i;
-
-	if (slot < 0 || slot >= hash->slots)
-		return -FI_EINVAL;
+	struct util_av_entry *entry = NULL;
 
-	if (hash->table[slot].index == UTIL_NO_ENTRY) {
-		hash->table[slot].index = index;
-		if (table_slot)
-			*table_slot = slot;
+	HASH_FIND(hh, av->hash, addr, av->addrlen, entry);
+	if (entry) {
+		if (fi_addr)
+			*fi_addr = util_get_buf_index(av->av_entry_pool, entry);
+		ofi_atomic_inc32(&entry->use_cnt);
 		return 0;
+	} else {
+		entry = util_buf_indexed_alloc(av->av_entry_pool);
+		if (!entry)
+			return -FI_ENOMEM;
+		if (fi_addr)
+			*fi_addr = util_get_buf_index(av->av_entry_pool, entry);
+		memcpy(entry->addr, addr, av->addrlen);
+		ofi_atomic_initialize32(&entry->use_cnt, 1);
+		HASH_ADD(hh, av->hash, addr, av->addrlen, entry);
 	}
-
-	if (hash->free_list == UTIL_NO_ENTRY)
-		return -FI_ENOSPC;
-
-	entry = hash->free_list;
-	hash->free_list = hash->table[hash->free_list].next;
-
-	for (i = slot; hash->table[i].next != UTIL_NO_ENTRY; )
-		i = hash->table[i].next;
-
-	hash->table[i].next = entry;
-	if (table_slot)
-		*table_slot = i;
-	hash->table[entry].index = index;
-	hash->table[entry].next = UTIL_NO_ENTRY;
 	return 0;
 }
 
-/* Caller must hold `av::lock` */
-static inline
-int util_av_lookup_index(struct util_av *av, const void *addr,
-			 int slot, int *table_slot)
+int ofi_av_elements_iter(struct util_av *av, ofi_av_apply_func apply, void *arg)
 {
-	int i, ret = -FI_ENODATA;
-
-	if (av->hash.table[slot].index == UTIL_NO_ENTRY) {
-		FI_DBG(av->prov, FI_LOG_AV, "no entry at slot (%d)\n", slot);
-		goto out;
-	}
-
-	for (i = slot; i != UTIL_NO_ENTRY; i = av->hash.table[i].next) {
-		if (!memcmp(ofi_av_get_addr(av, av->hash.table[i].index), addr,
-			    av->addrlen)) {
-			ret = av->hash.table[i].index;
-			if (table_slot)
-				*table_slot = i;
-			FI_DBG(av->prov, FI_LOG_AV, "entry at index (%d)\n", ret);
-			break;
-		}
-	}
-out:
-	FI_DBG(av->prov, FI_LOG_AV, "%d\n", ret);
-	return ret;
-}
-
-/*
- * Must hold AV lock
- */
-int ofi_av_insert_addr(struct util_av *av, const void *addr, int slot, int *index)
-{
-	struct dlist_entry *av_entry;
-	struct util_ep *ep;
+	struct util_av_entry *av_entry = NULL, *av_entry_tmp = NULL;
 	int ret;
 
-	if (OFI_UNLIKELY(av->free_list == UTIL_NO_ENTRY)) {
-		FI_WARN(av->prov, FI_LOG_AV, "AV is full\n");
-		return -FI_ENOSPC;
-	}
-
-	if (av->flags & OFI_AV_HASH) {
-		int table_slot;
-
-		if (OFI_UNLIKELY(slot < 0 || slot >= av->hash.slots)) {
-			FI_WARN(av->prov, FI_LOG_AV, "invalid slot (%d)\n", slot);
-			return -FI_EINVAL;
-		}
-		ret = util_av_lookup_index(av, addr, slot, &table_slot);
-		if (ret != -FI_ENODATA) {
-			*index = ret;
-			ofi_atomic_inc32(&av->hash.table[table_slot].use_cnt);
-			return 0;
-		}
-		ret = util_av_hash_insert(&av->hash, slot, av->free_list,
-					  &table_slot);
-		if (ret) {
-			FI_WARN(av->prov, FI_LOG_AV,
-				"failed to insert addr into hash table\n");
+	HASH_ITER(hh, av->hash, av_entry, av_entry_tmp) {
+		ret = apply(av, av_entry->addr,
+			    util_get_buf_index(av->av_entry_pool, av_entry),
+			    arg);
+		if (OFI_UNLIKELY(ret))
 			return ret;
-		}
-		ofi_atomic_inc32(&av->hash.table[table_slot].use_cnt);
-	}
-
-	*index = av->free_list;
-	av->free_list = *(int *) util_av_get_data(av, av->free_list);
-	util_av_set_data(av, *index, addr, av->addrlen);
-
-	dlist_foreach(&av->ep_list, av_entry) {
-		ep = container_of(av_entry, struct util_ep, av_entry);
-		if (ep->cmap)
-			ofi_cmap_update(ep->cmap, addr, (fi_addr_t)(*index));
 	}
 	return 0;
 }
 
-static inline int
-util_av_hash_lookup_table_slot(struct util_av_hash *hash, int slot, int index)
-{
-	int i;
-
-	if (hash->table[slot].index == index) {
-		return slot;
-	} else {
-		for (i = slot; hash->table[i].index != index; )
-			i = hash->table[i].next;
-		return i;
-	}
-}
-
 /*
  * Must hold AV lock
  */
-static void util_av_hash_remove(struct util_av_hash *hash, int slot, int index)
+int ofi_av_remove_addr(struct util_av *av, fi_addr_t fi_addr)
 {
-	int table_slot, slot_next;
+	struct util_av_entry *av_entry =
+		util_buf_get_by_index(av->av_entry_pool, fi_addr);
+	if (!av_entry)
+		return -FI_ENOENT;
 
-	if (OFI_UNLIKELY(slot < 0 || slot >= hash->slots))
-		return;
-
-	table_slot = util_av_hash_lookup_table_slot(hash, slot, index);
-	if (table_slot == slot) {
-		if (hash->table[table_slot].next == UTIL_NO_ENTRY) {
-			hash->table[table_slot].index = UTIL_NO_ENTRY;
-			return;
-		}
-	}
-
-	slot_next = hash->table[slot].next;
-	hash->table[slot] = hash->table[slot_next];
+	if (ofi_atomic_dec32(&av_entry->use_cnt))
+		return FI_SUCCESS;
 
-	hash->table[slot_next].next = hash->free_list;
-	hash->free_list = slot_next;
+	HASH_DELETE(hh, av->hash, av_entry);
+	util_buf_indexed_release(av->av_entry_pool, av_entry);
+	return 0;
 }
 
-/*
- * Must hold AV lock
- */
-int ofi_av_remove_addr(struct util_av *av, int slot, int index)
+fi_addr_t ofi_av_lookup_fi_addr(struct util_av *av, const void *addr)
 {
-	struct util_ep *ep;
-	int *entry, *next, i;
-	int ret = 0;
-
-	if (OFI_UNLIKELY(index < 0 || (size_t)index > av->count)) {
-		FI_WARN(av->prov, FI_LOG_AV, "index out of range\n");
-		return -FI_EINVAL;
-	}
+	struct util_av_entry *entry = NULL;
 
-	if (av->flags & FI_SOURCE) {
-		int table_slot;
-
-		if (OFI_UNLIKELY(slot < 0 || slot >= av->hash.slots)) {
-			FI_WARN(av->prov, FI_LOG_AV, "invalid slot (%d)\n", slot);
-			return -FI_EINVAL;
-		}
-
-		table_slot = util_av_hash_lookup_table_slot(&av->hash, slot, index);
-		if (ofi_atomic_dec32(&av->hash.table[table_slot].use_cnt))
-			return FI_SUCCESS;
-	}
-
-	/* This should stay at top */
-	dlist_foreach_container(&av->ep_list, struct util_ep, ep, av_entry) {
-		if (ep->cmap && ep->cmap->handles_av[index]) {
-			/* TODO this is not optimal. Replace this with something
-			 * more deterministic: delete handle if we know that peer
-			 * isn't actively communicating with us
-			 */
-			ret = ofi_cmap_move_handle_to_peer_list(ep->cmap, index);
-			if (ret) {
-				FI_WARN(av->prov, FI_LOG_DOMAIN, "Unable to move"
-					" handle to peer list. Deleting it.\n");
-				ofi_cmap_del_handle(ep->cmap->handles_av[index]);
-				return ret;
-			}
-		}
-	}
-
-	if (av->flags & OFI_AV_HASH)
-		util_av_hash_remove(&av->hash, slot, index);
-
-	entry = util_av_get_data(av, index);
-	if (av->free_list == UTIL_NO_ENTRY || index < av->free_list) {
-		*entry = av->free_list;
-		av->free_list = index;
-	} else {
-		i = av->free_list;
-		for (next = util_av_get_data(av, i); index > *next;) {
-			i = *next;
-			next = util_av_get_data(av, i);
-		}
-		util_av_set_data(av, index, next, sizeof index);
-		*next = index;
-	}
+	fastlock_acquire(&av->lock);
+	HASH_FIND(hh, av->hash, addr, av->addrlen, entry);
+	fastlock_release(&av->lock);
 
-	return ret;
+	return entry ? util_get_buf_index(av->av_entry_pool, entry) :
+		       FI_ADDR_NOTAVAIL;
 }
 
-int ofi_av_lookup_index(struct util_av *av, const void *addr, int slot)
+static void *
+ofi_av_lookup_addr(struct util_av *av, fi_addr_t fi_addr, size_t *addrlen)
 {
-	int ret;
-
-	if (slot < 0 || slot >= av->hash.slots) {
-		FI_WARN(av->prov, FI_LOG_AV, "invalid slot (%d)\n", slot);
-		return -FI_EINVAL;
-	}
-
-	fastlock_acquire(&av->lock);
-	ret = util_av_lookup_index(av, addr, slot, NULL);
-	fastlock_release(&av->lock);
-	return ret;
+	*addrlen = av->addrlen;
+	return ofi_av_get_addr(av, fi_addr);
 }
 
 int ofi_av_bind(struct fid *av_fid, struct fid *eq_fid, uint64_t flags)
@@ -510,7 +362,13 @@ int ofi_av_bind(struct fid *av_fid, struct fid *eq_fid, uint64_t flags)
 	return 0;
 }
 
-int ofi_av_close(struct util_av *av)
+static void util_av_close(struct util_av *av)
+{
+	HASH_CLEAR(hh, av->hash);
+	util_buf_pool_destroy(av->av_entry_pool);
+}
+
+int ofi_av_close_lightweight(struct util_av *av)
 {
 	if (ofi_atomic_get32(&av->ref)) {
 		FI_WARN(av->prov, FI_LOG_AV, "AV is busy\n");
@@ -522,35 +380,55 @@ int ofi_av_close(struct util_av *av)
 
 	ofi_atomic_dec32(&av->domain->ref);
 	fastlock_destroy(&av->lock);
-	/* TODO: unmap data? */
-	free(av->data);
+
 	return 0;
 }
 
-static void util_av_hash_init(struct util_av_hash *hash)
+int ofi_av_close(struct util_av *av)
 {
-	int i;
+	int ret = ofi_av_close_lightweight(av);
+	if (ret)
+		return ret;
+	util_av_close(av);
+	return 0;
+}
 
-	for (i = 0; i < hash->slots; i++) {
-		hash->table[i].index = UTIL_NO_ENTRY;
-		hash->table[i].next = UTIL_NO_ENTRY;
-		ofi_atomic_initialize32(&hash->table[i].use_cnt, 0);
+static int util_verify_av_util_attr(struct util_domain *domain,
+				    const struct util_av_attr *util_attr)
+{
+	if (util_attr->flags) {
+		FI_WARN(domain->prov, FI_LOG_AV, "invalid internal flags\n");
+		return -FI_EINVAL;
 	}
 
-	hash->free_list = hash->slots;
-	for (i = hash->slots; i < hash->total_count; i++) {
-		hash->table[i].index = UTIL_NO_ENTRY;
-		hash->table[i].next = i + 1;
-		ofi_atomic_initialize32(&hash->table[i].use_cnt, 0);
-	}
-	hash->table[hash->total_count - 1].next = UTIL_NO_ENTRY;
+	return 0;
 }
 
 static int util_av_init(struct util_av *av, const struct fi_av_attr *attr,
 			const struct util_av_attr *util_attr)
 {
-	int *entry, i, ret = 0;
+	int ret = 0;
 	size_t max_count;
+	struct util_buf_attr pool_attr = {
+		.size		= util_attr->addrlen +
+				  sizeof(struct util_av_entry),
+		.alignment	= 16,
+		.max_cnt	= 0,
+		/* Don't use track of buffer, because user can close
+		 * the AV without prior deletion of addresses */
+		.track_used	= 0,
+		.indexing	= {
+			.used		= 1,
+			.ordered	= 1,
+		},
+	};
+
+	/* TODO: Handle FI_READ */
+	/* TODO: Handle mmap - shared AV */
+
+	ret = util_verify_av_util_attr(av->domain, util_attr);
+	if (ret)
+		return ret;
 
 	if (attr->count) {
 		max_count = attr->count;
@@ -559,51 +437,25 @@ static int util_av_init(struct util_av *av, const struct fi_av_attr *attr,
 			max_count = UTIL_DEFAULT_AV_SIZE;
 	}
 
-	ofi_atomic_initialize32(&av->ref, 0);
-	fastlock_init(&av->lock);
-	av->count = max_count ? max_count : UTIL_DEFAULT_AV_SIZE;
-	av->count = roundup_power_of_two(av->count);
-	av->addrlen = util_attr->addrlen;
-	av->flags = util_attr->flags | attr->flags;
-
+	av->count = roundup_power_of_two(max_count ?
+					 max_count :
+					 UTIL_DEFAULT_AV_SIZE);
 	FI_INFO(av->prov, FI_LOG_AV, "AV size %zu\n", av->count);
 
-	/* TODO: Handle FI_READ */
-	/* TODO: Handle mmap - shared AV */
-
-	if (util_attr->flags & OFI_AV_HASH) {
-		av->hash.slots = av->count;
-		if (util_attr->overhead)
-			av->hash.total_count = av->count + util_attr->overhead;
-		else
-			av->hash.total_count = av->count * 2;
-		FI_INFO(av->prov, FI_LOG_AV,
-		       "OFI_AV_HASH requested, hash size %u\n", av->hash.total_count);
-	}
-
-	av->data = malloc((av->count * util_attr->addrlen) +
-			  (av->hash.total_count * sizeof(*av->hash.table)));
-	if (!av->data)
-		return -FI_ENOMEM;
-
-	for (i = 0; i < (int)av->count - 1; i++) {
-		entry = util_av_get_data(av, i);
-		*entry = i + 1;
-	}
-	entry = util_av_get_data(av, av->count - 1);
-	*entry = UTIL_NO_ENTRY;
+	av->addrlen = util_attr->addrlen;
+	av->flags = util_attr->flags | attr->flags;
+	av->hash = NULL;
 
-	if (util_attr->flags & OFI_AV_HASH) {
-		av->hash.table = util_av_get_data(av, av->count);
-		util_av_hash_init(&av->hash);
-	}
+	pool_attr.chunk_cnt = av->count;
+	ret = util_buf_pool_create_attr(&pool_attr, &av->av_entry_pool);
+	if (ret)
+		return ret;
 
 	return ret;
 }
 
 static int util_verify_av_attr(struct util_domain *domain,
-			       const struct fi_av_attr *attr,
-			       const struct util_av_attr *util_attr)
+			       const struct fi_av_attr *attr)
 {
 	switch (attr->type) {
 	case FI_AV_MAP:
@@ -629,34 +481,21 @@ static int util_verify_av_attr(struct util_domain *domain,
 		return -FI_EINVAL;
 	}
 
-	if (util_attr->flags & ~(OFI_AV_HASH)) {
-		FI_WARN(domain->prov, FI_LOG_AV, "invalid internal flags\n");
-		return -FI_EINVAL;
-	}
-
-	if (util_attr->addrlen < sizeof(int)) {
-		FI_WARN(domain->prov, FI_LOG_AV, "unsupported address size\n");
-		return -FI_ENOSYS;
-	}
-
 	return 0;
 }
 
-int ofi_av_init(struct util_domain *domain, const struct fi_av_attr *attr,
-	       const struct util_av_attr *util_attr,
-	       struct util_av *av, void *context)
+int ofi_av_init_lightweight(struct util_domain *domain, const struct fi_av_attr *attr,
+			    struct util_av *av, void *context)
 {
 	int ret;
 
-	ret = util_verify_av_attr(domain, attr, util_attr);
+	ret = util_verify_av_attr(domain, attr);
 	if (ret)
 		return ret;
 
 	av->prov = domain->prov;
-	ret = util_av_init(av, attr, util_attr);
-	if (ret)
-		return ret;
-
+	ofi_atomic_initialize32(&av->ref, 0);
+	fastlock_init(&av->lock);
 	av->av_fid.fid.fclass = FI_CLASS_AV;
 	/*
 	 * ops set by provider
@@ -670,52 +509,24 @@ int ofi_av_init(struct util_domain *domain, const struct fi_av_attr *attr,
 	return 0;
 }
 
-
-/*************************************************************************
- *
- * AV for IP addressing
- *
- *************************************************************************/
-
-static int ip_av_slot(struct util_av *av, const struct sockaddr *sa)
+int ofi_av_init(struct util_domain *domain, const struct fi_av_attr *attr,
+		const struct util_av_attr *util_attr,
+		struct util_av *av, void *context)
 {
-	uint32_t host;
-	uint16_t port;
-
-	if (!sa)
-		return UTIL_NO_ENTRY;
-
-	switch (((struct sockaddr *) sa)->sa_family) {
-	case AF_INET:
-		host = (uint16_t) ntohl(((struct sockaddr_in *) sa)->
-					sin_addr.s_addr);
-		port = ntohs(((struct sockaddr_in *) sa)->sin_port);
-		break;
-	case AF_INET6:
-		host = (uint16_t) ((struct sockaddr_in6 *) sa)->
-					sin6_addr.s6_addr[15];
-		port = ntohs(((struct sockaddr_in6 *) sa)->sin6_port);
-		break;
-	default:
-		assert(0);
-		return UTIL_NO_ENTRY;
-	}
-
-	/* TODO: Find a good hash function */
-	FI_DBG(av->prov, FI_LOG_AV, "slot %d\n",
-		((host << 16) | port) % av->hash.slots);
-	return ((host << 16) | port) % av->hash.slots;
-}
+	int ret = ofi_av_init_lightweight(domain, attr, av, context);
+	if (ret)
+		return ret;
 
-int ip_av_get_index(struct util_av *av, const void *addr)
-{
-	return ofi_av_lookup_index(av, addr, ip_av_slot(av, addr));
+	ret = util_av_init(av, attr, util_attr);
+	if (ret)
+		return ret;
+	return ret;
 }
 
 void ofi_av_write_event(struct util_av *av, uint64_t data,
 			int err, void *context)
 {
-	struct fi_eq_err_entry entry;
+	struct fi_eq_err_entry entry = { 0 };
 	size_t size;
 	ssize_t ret;
 	uint64_t flags;
@@ -741,6 +552,17 @@ void ofi_av_write_event(struct util_av *av, uint64_t data,
 		FI_WARN(av->prov, FI_LOG_AV, "error writing to EQ\n");
 }
 
+/*************************************************************************
+ *
+ * AV for IP addressing
+ *
+ *************************************************************************/
+
+fi_addr_t ofi_ip_av_get_fi_addr(struct util_av *av, const void *addr)
+{
+	return ofi_av_lookup_fi_addr(av, addr);
+}
+
 static int ip_av_valid_addr(struct util_av *av, const void *addr)
 {
 	const struct sockaddr_in *sin = addr;
@@ -760,11 +582,12 @@ static int ip_av_valid_addr(struct util_av *av, const void *addr)
 static int ip_av_insert_addr(struct util_av *av, const void *addr,
 			     fi_addr_t *fi_addr, void *context)
 {
-	int ret, index = -1;
+	int ret;
+	fi_addr_t fi_addr_ret;
 
 	if (ip_av_valid_addr(av, addr)) {
 		fastlock_acquire(&av->lock);
-		ret = ofi_av_insert_addr(av, addr, ip_av_slot(av, addr), &index);
+		ret = ofi_av_insert_addr(av, addr, &fi_addr_ret);
 		fastlock_release(&av->lock);
 	} else {
 		ret = -FI_EADDRNOTAVAIL;
@@ -772,7 +595,7 @@ static int ip_av_insert_addr(struct util_av *av, const void *addr,
 	}
 
 	if (fi_addr)
-		*fi_addr = !ret ? index : FI_ADDR_NOTAVAIL;
+		*fi_addr = !ret ? fi_addr_ret : FI_ADDR_NOTAVAIL;
 
 	ofi_straddr_dbg(av->prov, FI_LOG_AV, "av_insert addr", addr);
 	if (fi_addr)
@@ -782,21 +605,12 @@ static int ip_av_insert_addr(struct util_av *av, const void *addr,
 	return ret;
 }
 
-static int ip_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
-			fi_addr_t *fi_addr, uint64_t flags, void *context)
+int ofi_ip_av_insertv(struct util_av *av, const void *addr, size_t addrlen,
+		      size_t count, fi_addr_t *fi_addr, void *context)
 {
-	struct util_av *av;
 	int ret, success_cnt = 0;
 	size_t i;
-	size_t addrlen;
 
-	av = container_of(av_fid, struct util_av, av_fid);
-	ret = fi_verify_av_insert(av, flags);
-	if (ret)
-		return ret;
-
-	addrlen = ((struct sockaddr *) addr)->sa_family == AF_INET ?
-		  sizeof(struct sockaddr_in) : sizeof(struct sockaddr_in6);
 	FI_DBG(av->prov, FI_LOG_AV, "inserting %zu addresses\n", count);
 	for (i = 0; i < count; i++) {
 		ret = ip_av_insert_addr(av, (const char *) addr + i * addrlen,
@@ -817,35 +631,19 @@ static int ip_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
 	return ret;
 }
 
-static int ip_av_insert_svc(struct util_av *av, const char *node,
-			    const char *service, fi_addr_t *fi_addr,
-			    void *context)
+int ofi_ip_av_insert(struct fid_av *av_fid, const void *addr, size_t count,
+		     fi_addr_t *fi_addr, uint64_t flags, void *context)
 {
-	struct addrinfo hints, *ai;
+	struct util_av *av;
 	int ret;
 
-	FI_INFO(av->prov, FI_LOG_AV, "inserting %s-%s\n", node, service);
-
-	memset(&hints, 0, sizeof hints);
-	hints.ai_socktype = SOCK_DGRAM;
-	switch (av->domain->addr_format) {
-	case FI_SOCKADDR_IN:
-		hints.ai_family = AF_INET;
-		break;
-	case FI_SOCKADDR_IN6:
-		hints.ai_family = AF_INET6;
-		break;
-	default:
-		break;
-	}
-
-	ret = getaddrinfo(node, service, &hints, &ai);
+	av = container_of(av_fid, struct util_av, av_fid);
+	ret = ofi_verify_av_insert(av, flags);
 	if (ret)
 		return ret;
 
-	ret = ip_av_insert_addr(av, ai->ai_addr, fi_addr, context);
-	freeaddrinfo(ai);
-	return ret;
+	return ofi_ip_av_insertv(av, addr, ofi_sizeofaddr(addr),
+				 count, fi_addr, context);
 }
 
 static int ip_av_insertsvc(struct fid_av *av, const char *node,
@@ -855,79 +653,98 @@ static int ip_av_insertsvc(struct fid_av *av, const char *node,
 	return fi_av_insertsym(av, node, 1, service, 1, fi_addr, flags, context);
 }
 
-static int ip_av_insert_ip4sym(struct util_av *av,
-			       struct in_addr ip, size_t ipcnt,
-			       uint16_t port, size_t portcnt,
-			       fi_addr_t *fi_addr, void *context)
+/* Caller should free *addr */
+static int
+ip_av_ip4sym_getaddr(struct util_av *av, struct in_addr ip, size_t ipcnt,
+		     uint16_t port, size_t portcnt, void **addr, size_t *addrlen)
 {
-	struct sockaddr_in sin;
-	int fi, ret, success_cnt = 0;
-	size_t i, p;
-
-	memset(&sin, 0, sizeof sin);
-	sin.sin_family = AF_INET;
-
-	for (i = 0, fi = 0; i < ipcnt; i++) {
-		/* TODO: should we skip addresses x.x.x.0 and x.x.x.255? */
-		sin.sin_addr.s_addr = htonl(ntohl(ip.s_addr) + i);
-
-		for (p = 0; p < portcnt; p++, fi++) {
-			sin.sin_port = htons(port + p);
-			ret = ip_av_insert_addr(av, &sin, fi_addr ?
-						&fi_addr[fi] : NULL, context);
-			if (!ret)
-				success_cnt++;
-			else if (av->eq)
-				ofi_av_write_event(av, fi, -ret, context);
+	struct sockaddr_in *sin;
+	int count = ipcnt * portcnt;
+	size_t i, p, k;
+
+	*addrlen = sizeof(*sin);
+	sin = calloc(count, *addrlen);
+	if (!sin)
+		return -FI_ENOMEM;
+
+	for (i = 0, k = 0; i < ipcnt; i++) {
+		for (p = 0; p < portcnt; p++, k++) {
+			sin[k].sin_family = AF_INET;
+			/* TODO: should we skip addresses x.x.x.0 and x.x.x.255? */
+			sin[k].sin_addr.s_addr = htonl(ntohl(ip.s_addr) + i);
+			sin[k].sin_port = htons(port + p);
 		}
 	}
-
-	return success_cnt;
+	*addr = sin;
+	return count;
 }
 
-static int ip_av_insert_ip6sym(struct util_av *av,
-			       struct in6_addr ip, size_t ipcnt,
-			       uint16_t port, size_t portcnt,
-			       fi_addr_t *fi_addr, void *context)
+/* Caller should free *addr */
+static int
+ip_av_ip6sym_getaddr(struct util_av *av, struct in6_addr ip, size_t ipcnt,
+		     uint16_t port, size_t portcnt, void **addr, size_t *addrlen)
 {
-	struct sockaddr_in6 sin6;
-	int j, fi, ret, success_cnt = 0;
-	size_t i, p;
-
-	memset(&sin6, 0, sizeof sin6);
-	sin6.sin6_family = AF_INET6;
-	sin6.sin6_addr = ip;
-
-	for (i = 0, fi = 0; i < ipcnt; i++) {
-		for (p = 0; p < portcnt; p++, fi++) {
-			sin6.sin6_port = htons(port + p);
-			ret = ip_av_insert_addr(av, &sin6, fi_addr ?
-						&fi_addr[fi] : NULL, context);
-			if (!ret)
-				success_cnt++;
-			else if (av->eq)
-				ofi_av_write_event(av, fi, -ret, context);
-		}
+	struct sockaddr_in6 *sin6, sin6_temp;
+	int j, count = ipcnt * portcnt;
+	size_t i, p, k;
+
+	*addrlen = sizeof(*sin6);
+	sin6 = calloc(count, *addrlen);
+	if (!sin6)
+		return -FI_ENOMEM;
+
+	sin6_temp.sin6_addr = ip;
 
+	for (i = 0, k = 0; i < ipcnt; i++) {
+		for (p = 0; p < portcnt; p++, k++) {
+			sin6[k].sin6_family = AF_INET6;
+			sin6[k].sin6_addr = sin6_temp.sin6_addr;
+			sin6[k].sin6_port = htons(port + p);
+		}
 		/* TODO: should we skip addresses x::0 and x::255? */
 		for (j = 15; j >= 0; j--) {
-			if (++sin6.sin6_addr.s6_addr[j] < 255)
+			if (++sin6_temp.sin6_addr.s6_addr[j] < 255)
 				break;
 		}
 	}
-
-	return success_cnt;
+	*addr = sin6;
+	return count;
 }
 
-static int ip_av_insert_nodesym(struct util_av *av,
-				const char *node, size_t nodecnt,
-				const char *service, size_t svccnt,
-				fi_addr_t *fi_addr, void *context)
+/* Caller should free *addr */
+static int ip_av_nodesym_getaddr(struct util_av *av, const char *node,
+				 size_t nodecnt, const char *service,
+				 size_t svccnt, void **addr, size_t *addrlen)
 {
+	struct addrinfo hints, *ai;
+	void *addr_temp;
 	char name[FI_NAME_MAX];
 	char svc[FI_NAME_MAX];
 	size_t name_len, n, s;
-	int fi, ret, name_index, svc_index, success_cnt = 0;
+	int ret, name_index, svc_index, count = nodecnt * svccnt;
+
+	memset(&hints, 0, sizeof hints);
+
+	hints.ai_socktype = SOCK_DGRAM;
+	switch (av->domain->addr_format) {
+	case FI_SOCKADDR_IN:
+		hints.ai_family = AF_INET;
+		*addrlen = sizeof(struct sockaddr_in);
+		break;
+	case FI_SOCKADDR_IN6:
+		hints.ai_family = AF_INET6;
+		*addrlen = sizeof(struct sockaddr_in6);
+		break;
+	default:
+		FI_INFO(av->prov, FI_LOG_AV, "Unknown address format!\n");
+		return -FI_EINVAL;
+	}
+
+	*addr = calloc(nodecnt * svccnt, *addrlen);
+	if (!*addr)
+		return -FI_ENOMEM;
+
+	addr_temp = *addr;
 
 	for (name_len = strlen(node); isdigit(node[name_len - 1]); )
 		name_len--;
@@ -936,7 +753,7 @@ static int ip_av_insert_nodesym(struct util_av *av,
 	name_index = atoi(node + name_len);
 	svc_index = atoi(service);
 
-	for (n = 0, fi = 0; n < nodecnt; n++) {
+	for (n = 0; n < nodecnt; n++) {
 		if (nodecnt == 1) {
 			strncpy(name, node, sizeof(name) - 1);
 			name[FI_NAME_MAX - 1] = '\0';
@@ -945,7 +762,7 @@ static int ip_av_insert_nodesym(struct util_av *av,
 				 "%zu", name_index + n);
 		}
 
-		for (s = 0; s < svccnt; s++, fi++) {
+		for (s = 0; s < svccnt; s++) {
 			if (svccnt == 1) {
 				strncpy(svc, service, sizeof(svc) - 1);
 				svc[FI_NAME_MAX - 1] = '\0';
@@ -953,33 +770,33 @@ static int ip_av_insert_nodesym(struct util_av *av,
 				snprintf(svc, sizeof(svc) - 1,
 					 "%zu", svc_index + s);
 			}
+			FI_INFO(av->prov, FI_LOG_AV, "resolving %s:%s for AV "
+				"insert\n", node, service);
+
+			ret = getaddrinfo(node, service, &hints, &ai);
+			if (ret)
+				goto err;
 
-			ret = ip_av_insert_svc(av, name, svc, fi_addr ?
-					       &fi_addr[fi] : NULL, context);
-			if (!ret)
-				success_cnt++;
-			else if (av->eq)
-				ofi_av_write_event(av, fi, -ret, context);
+			memcpy(addr_temp, ai->ai_addr, *addrlen);
+			addr_temp = (char *)addr_temp + *addrlen;
+			freeaddrinfo(ai);
 		}
 	}
-
-	return success_cnt;
+	return count;
+err:
+	free(*addr);
+	return ret;
 }
 
-static int ip_av_insertsym(struct fid_av *av_fid, const char *node, size_t nodecnt,
-			   const char *service, size_t svccnt, fi_addr_t *fi_addr,
-			   uint64_t flags, void *context)
+/* Caller should free *addr */
+int ofi_ip_av_sym_getaddr(struct util_av *av, const char *node,
+			  size_t nodecnt, const char *service,
+			  size_t svccnt, void **addr, size_t *addrlen)
 {
-	struct util_av *av;
 	struct in6_addr ip6;
 	struct in_addr ip4;
 	int ret;
 
-	av = container_of(av_fid, struct util_av, av_fid);
-	ret = fi_verify_av_insert(av, flags);
-	if (ret)
-		return ret;
-
 	if (strlen(node) >= FI_NAME_MAX || strlen(service) >= FI_NAME_MAX) {
 		FI_WARN(av->prov, FI_LOG_AV,
 			"node or service name is too long\n");
@@ -989,38 +806,54 @@ static int ip_av_insertsym(struct fid_av *av_fid, const char *node, size_t nodec
 	ret = inet_pton(AF_INET, node, &ip4);
 	if (ret == 1) {
 		FI_INFO(av->prov, FI_LOG_AV, "insert symmetric IPv4\n");
-		ret = ip_av_insert_ip4sym(av, ip4, nodecnt,
+		return ip_av_ip4sym_getaddr(av, ip4, nodecnt,
 					  (uint16_t) strtol(service, NULL, 0),
-					  svccnt, fi_addr, context);
-		goto out;
+					  svccnt, addr, addrlen);
 	}
 
 	ret = inet_pton(AF_INET6, node, &ip6);
 	if (ret == 1) {
 		FI_INFO(av->prov, FI_LOG_AV, "insert symmetric IPv6\n");
-		ret = ip_av_insert_ip6sym(av, ip6, nodecnt,
+		return ip_av_ip6sym_getaddr(av, ip6, nodecnt,
 					  (uint16_t) strtol(service, NULL, 0),
-					  svccnt, fi_addr, context);
-		goto out;
+					  svccnt, addr, addrlen);
 	}
 
 	FI_INFO(av->prov, FI_LOG_AV, "insert symmetric host names\n");
-	ret = ip_av_insert_nodesym(av, node, nodecnt, service, svccnt,
-				  fi_addr, context);
+	return ip_av_nodesym_getaddr(av, node, nodecnt, service,
+				     svccnt, addr, addrlen);
+}
 
-out:
-	if (av->eq) {
-		ofi_av_write_event(av, ret, 0, context);
-		ret = 0;
-	}
+static int ip_av_insertsym(struct fid_av *av_fid, const char *node,
+			   size_t nodecnt, const char *service, size_t svccnt,
+			   fi_addr_t *fi_addr, uint64_t flags, void *context)
+{
+	struct util_av *av;
+	void *addr;
+	size_t addrlen;
+	int ret, count;
+
+	av = container_of(av_fid, struct util_av, av_fid);
+	ret = ofi_verify_av_insert(av, flags);
+	if (ret)
+		return ret;
+
+	count = ofi_ip_av_sym_getaddr(av, node, nodecnt, service,
+				      svccnt, &addr, &addrlen);
+	if (count <= 0)
+		return count;
+
+	ret = ofi_ip_av_insertv(av, addr, addrlen, count,
+				fi_addr, context);
+	free(addr);
 	return ret;
 }
 
-static int ip_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr, size_t count,
-			uint64_t flags)
+int ofi_ip_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr,
+		     size_t count, uint64_t flags)
 {
 	struct util_av *av;
-	int i, slot, index, ret;
+	int i, ret;
 
 	av = container_of(av_fid, struct util_av, av_fid);
 	if (flags) {
@@ -1035,52 +868,46 @@ static int ip_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr, size_t count,
 	 * Thus, we walk through the array backwards.
 	 */
 	for (i = count - 1; i >= 0; i--) {
-		index = (int) fi_addr[i];
-		slot = ip_av_slot(av, ip_av_get_addr(av, index));
 		fastlock_acquire(&av->lock);
-		ret = ofi_av_remove_addr(av, slot, index);
+		ret = ofi_av_remove_addr(av, fi_addr[i]);
 		fastlock_release(&av->lock);
 		if (ret) {
 			FI_WARN(av->prov, FI_LOG_AV,
-				"removal of fi_addr %d failed\n", index);
+				"removal of fi_addr %"PRIu64" failed\n",
+				fi_addr[i]);
 		}
 	}
 	return 0;
 }
 
-static int ip_av_lookup(struct fid_av *av_fid, fi_addr_t fi_addr, void *addr,
-			size_t *addrlen)
+int ofi_ip_av_lookup(struct fid_av *av_fid, fi_addr_t fi_addr,
+		     void *addr, size_t *addrlen)
 {
-	struct util_av *av;
-	int index;
-
-	av = container_of(av_fid, struct util_av, av_fid);
-	index = (int) fi_addr;
-	if (index < 0 || (size_t)index > av->count) {
-		FI_WARN(av->prov, FI_LOG_AV, "unknown address\n");
-		return -FI_EINVAL;
-	}
-
-	memcpy(addr, ip_av_get_addr(av, index),
-	       MIN(*addrlen, av->addrlen));
+	struct util_av *av =
+		container_of(av_fid, struct util_av, av_fid);
+	size_t av_addrlen;
+	void *av_addr = ofi_av_lookup_addr(av, fi_addr, &av_addrlen);
+	
+	memcpy(addr, av_addr, MIN(*addrlen, av_addrlen));
 	*addrlen = av->addrlen;
+
 	return 0;
 }
 
-static const char *ip_av_straddr(struct fid_av *av, const void *addr, char *buf,
-				 size_t *len)
+const char *
+ofi_ip_av_straddr(struct fid_av *av, const void *addr, char *buf, size_t *len)
 {
 	return ofi_straddr(buf, len, FI_SOCKADDR, addr);
 }
 
 static struct fi_ops_av ip_av_ops = {
 	.size = sizeof(struct fi_ops_av),
-	.insert = ip_av_insert,
+	.insert = ofi_ip_av_insert,
 	.insertsvc = ip_av_insertsvc,
 	.insertsym = ip_av_insertsym,
-	.remove = ip_av_remove,
-	.lookup = ip_av_lookup,
-	.straddr = ip_av_straddr,
+	.remove = ofi_ip_av_remove,
+	.lookup = ofi_ip_av_lookup,
+	.straddr = ofi_ip_av_straddr,
 };
 
 static int ip_av_close(struct fid *av_fid)
@@ -1104,8 +931,8 @@ static struct fi_ops ip_av_fi_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
-int ip_av_create_flags(struct fid_domain *domain_fid, struct fi_av_attr *attr,
-		       struct fid_av **av, void *context, int flags)
+int ofi_ip_av_create_flags(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+			   struct fid_av **av, void *context, int flags)
 {
 	struct util_domain *domain;
 	struct util_av_attr util_attr;
@@ -1118,7 +945,6 @@ int ip_av_create_flags(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 	else
 		util_attr.addrlen = sizeof(struct sockaddr_in6);
 
-	util_attr.overhead = attr->count >> 1;
 	util_attr.flags = flags;
 
 	if (attr->type == FI_AV_UNSPEC)
@@ -1140,520 +966,8 @@ int ip_av_create_flags(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 	return 0;
 }
 
-int ip_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
-		 struct fid_av **av, void *context)
-{
-	struct util_domain *domain = container_of(domain_fid, struct util_domain,
-						  domain_fid);
-
-	return ip_av_create_flags(domain_fid, attr, av, context,
-				  (domain->info_domain_caps & FI_SOURCE) ?
-				  OFI_AV_HASH : 0);
-}
-
-/*
- * Connection map
- */
-
-/* Caller should hold cmap->lock */
-static void util_cmap_set_key(struct util_cmap_handle *handle)
-{
-	handle->key = ofi_idx2key(&handle->cmap->key_idx,
-		ofi_idx_insert(&handle->cmap->handles_idx, handle));
-}
-
-/* Caller should hold cmap->lock */
-static void util_cmap_clear_key(struct util_cmap_handle *handle)
-{
-	int index = ofi_key2idx(&handle->cmap->key_idx, handle->key);
-
-	if (!ofi_idx_is_valid(&handle->cmap->handles_idx, index))
-		FI_WARN(handle->cmap->av->prov, FI_LOG_AV, "Invalid key!\n");
-	else
-		ofi_idx_remove(&handle->cmap->handles_idx, index);
-}
-
-struct util_cmap_handle *ofi_cmap_key2handle(struct util_cmap *cmap, uint64_t key)
-{
-	struct util_cmap_handle *handle;
-
-	fastlock_acquire(&cmap->lock);
-	if (!(handle = ofi_idx_lookup(&cmap->handles_idx,
-				      ofi_key2idx(&cmap->key_idx, key)))) {
-		FI_WARN(cmap->av->prov, FI_LOG_AV, "Invalid key!\n");
-	} else {
-		if (handle->key != key) {
-			FI_WARN(cmap->av->prov, FI_LOG_AV,
-				"handle->key not matching given key\n");
-			handle = NULL;
-		}
-	}
-	fastlock_release(&cmap->lock);
-	return handle;
-}
-
-/* Caller must hold cmap->lock */
-static void util_cmap_init_handle(struct util_cmap_handle *handle,
-				  struct util_cmap *cmap,
-				  enum util_cmap_state state,
-				  fi_addr_t fi_addr,
-				  struct util_cmap_peer *peer)
-{
-	handle->cmap = cmap;
-	handle->state = state;
-	util_cmap_set_key(handle);
-	handle->fi_addr = fi_addr;
-	handle->peer = peer;
-}
-
-static int util_cmap_match_peer(struct dlist_entry *entry, const void *addr)
-{
-	struct util_cmap_peer *peer;
-
-	peer = container_of(entry, struct util_cmap_peer, entry);
-	return !memcmp(peer->addr, addr, peer->handle->cmap->av->addrlen);
-}
-
-/* Caller must hold cmap->lock */
-static int util_cmap_del_handle(struct util_cmap_handle *handle)
-{
-	struct util_cmap *cmap = handle->cmap;
-	int ret;
-
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-	       "Deleting connection handle: %p\n", handle);
-	if (handle->peer) {
-		dlist_remove(&handle->peer->entry);
-		free(handle->peer);
-		handle->peer = NULL;
-	} else {
-		cmap->handles_av[handle->fi_addr] = 0;
-	}
-	util_cmap_clear_key(handle);
-
-	handle->state = CMAP_SHUTDOWN;
-	/* Signal event handler thread to delete the handle. This is required
-	 * so that the event handler thread handles any pending events for this
-	 * ep correctly. Handle would be freed finally after processing the
-	 * events */
-	ret = cmap->attr.signal(cmap->ep, handle, OFI_CMAP_FREE);
-	if (ret) {
-		FI_WARN(cmap->av->prov, FI_LOG_FABRIC,
-			"Unable to signal event handler thread\n");
-		return ret;
-	}
-	return 0;
-}
-
-void ofi_cmap_del_handle(struct util_cmap_handle *handle)
-{
-	struct util_cmap *cmap = handle->cmap;
-	fastlock_acquire(&cmap->lock);
-	util_cmap_del_handle(handle);
-	fastlock_release(&cmap->lock);
-}
-
-/* Caller must hold cmap->lock */
-int util_cmap_alloc_handle(struct util_cmap *cmap, fi_addr_t fi_addr,
-			   enum util_cmap_state state,
-			   struct util_cmap_handle **handle)
-{
-	*handle = cmap->attr.alloc();
-	if (!*handle)
-		return -FI_ENOMEM;
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Allocated handle: %p for "
-	       "fi_addr: %" PRIu64 "\n", *handle, fi_addr);
-	util_cmap_init_handle(*handle, cmap, state, fi_addr, NULL);
-	cmap->handles_av[fi_addr] = *handle;
-	return 0;
-}
-
-/* Caller must hold cmap->lock */
-static int util_cmap_alloc_handle_peer(struct util_cmap *cmap, void *addr,
-				       enum util_cmap_state state,
-				       struct util_cmap_handle **handle)
-{
-	struct util_cmap_peer *peer;
-
-	peer = calloc(1, sizeof(*peer) + cmap->av->addrlen);
-	if (!peer)
-		return -FI_ENOMEM;
-	*handle = cmap->attr.alloc();
-	if (!*handle) {
-		free(peer);
-		return -FI_ENOMEM;
-	}
-	ofi_straddr_dbg(cmap->av->prov, FI_LOG_AV, "Allocated handle for addr",
-			addr);
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "handle: %p\n", *handle);
-	util_cmap_init_handle(*handle, cmap, state, FI_ADDR_UNSPEC, peer);
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Adding handle to peer list\n");
-	peer->handle = *handle;
-	memcpy(peer->addr, addr, cmap->av->addrlen);
-	dlist_insert_tail(&peer->entry, &cmap->peer_list);
-	return 0;
-}
-
-/* Caller must hold cmap->lock */
-static struct util_cmap_handle *
-util_cmap_get_handle_peer(struct util_cmap *cmap, const void *addr)
+int ofi_ip_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+		     struct fid_av **av, void *context)
 {
-	struct util_cmap_peer *peer;
-	struct dlist_entry *entry;
-
-	entry = dlist_find_first_match(&cmap->peer_list, util_cmap_match_peer,
-				       addr);
-	if (!entry)
-		return NULL;
-	ofi_straddr_dbg(cmap->av->prov, FI_LOG_AV, "handle found in peer list"
-			" for addr", addr);
-	peer = container_of(entry, struct util_cmap_peer, entry);
-	return peer->handle;
-}
-
-static int ofi_cmap_move_handle_to_peer_list(struct util_cmap *cmap, int index)
-{
-	struct util_cmap_handle *handle = cmap->handles_av[index];
-	int ret = 0;
-
-	fastlock_acquire(&cmap->lock);
-	if (!handle)
-		goto unlock;
-
-	handle->peer = calloc(1, sizeof(*handle->peer) + cmap->av->addrlen);
-	if (!handle->peer) {
-		ret = -FI_ENOMEM;
-		goto unlock;
-	}
-	handle->peer->handle = handle;
-	memcpy(handle->peer->addr, ofi_av_get_addr(cmap->av, index),
-	       cmap->av->addrlen);
-	dlist_insert_tail(&handle->peer->entry, &cmap->peer_list);
-unlock:
-	fastlock_release(&cmap->lock);
-	return ret;
-}
-
-/* Caller must hold cmap->lock */
-static void util_cmap_move_handle(struct util_cmap_handle *handle,
-				  fi_addr_t fi_addr)
-{
-	dlist_remove(&handle->peer->entry);
-	free(handle->peer);
-	handle->peer = NULL;
-	handle->fi_addr = fi_addr;
-	handle->cmap->handles_av[fi_addr] = handle;
-}
-
-void ofi_cmap_update(struct util_cmap *cmap, const void *addr, fi_addr_t fi_addr)
-{
-	struct util_cmap_handle *handle;
-
-	fastlock_acquire(&cmap->lock);
-	handle = util_cmap_get_handle_peer(cmap, addr);
-	if (!handle)
-		goto out;
-	util_cmap_move_handle(handle, fi_addr);
-	cmap->av_updated = 1;
-out:
-	fastlock_release(&cmap->lock);
-}
-
-/* Caller must hold cmap->lock */
-struct util_cmap_handle *
-util_cmap_get_handle(struct util_cmap *cmap, fi_addr_t fi_addr)
-{
-	if (fi_addr > cmap->av->count) {
-		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL, "Invalid fi_addr\n");
-		return NULL;
-	}
-	return cmap->handles_av[fi_addr];
-}
-
-void ofi_cmap_process_shutdown(struct util_cmap *cmap,
-			       struct util_cmap_handle *handle)
-{
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-		"Processing shutdown for handle: %p\n", handle);
-	fastlock_acquire(&cmap->lock);
-	if (handle->state > CMAP_SHUTDOWN) {
-		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL,
-			"Invalid handle on shutdown event\n");
-	} else if (handle->state != CMAP_SHUTDOWN) {
-		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Got remote shutdown\n");
-		util_cmap_del_handle(handle);
-	} else {
-		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Got local shutdown\n");
-	}
-	fastlock_release(&cmap->lock);
-}
-
-/* Caller must hold cmap->lock */
-void ofi_cmap_process_connect(struct util_cmap *cmap,
-			      struct util_cmap_handle *handle,
-			      uint64_t *remote_key)
-{
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-		"Processing connect for handle: %p\n", handle);
-	handle->state = CMAP_CONNECTED;
-	if (remote_key)
-		handle->remote_key = *remote_key;
-}
-
-void ofi_cmap_process_reject(struct util_cmap *cmap,
-			     struct util_cmap_handle *handle)
-{
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-		"Processing reject for handle: %p\n", handle);
-	fastlock_acquire(&cmap->lock);
-	switch (handle->state) {
-	case CMAP_CONNREQ_RECV:
-	case CMAP_CONNECTED:
-		/* Handle is being re-used for incoming connection request */
-		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-			"Connection handle is being re-used. Ignoring reject\n");
-		break;
-	case CMAP_CONNREQ_SENT:
-		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-			"Deleting connection handle\n");
-		util_cmap_del_handle(handle);
-		break;
-	case CMAP_SHUTDOWN:
-		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-			"Connection handle already being deleted\n");
-		break;
-	default:
-		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL, "Invalid cmap state: "
-			"%d when receiving connection reject\n", handle->state);
-		assert(0);
-	}
-	fastlock_release(&cmap->lock);
-}
-
-int ofi_cmap_process_connreq(struct util_cmap *cmap, void *addr,
-			     struct util_cmap_handle **handle_ret)
-{
-	struct util_cmap_handle *handle;
-	int ret = 0, index, cmp;
-
-	ofi_straddr_dbg(cmap->av->prov, FI_LOG_EP_CTRL,
-			"Processing connreq for addr", addr);
-
-	index = ip_av_get_index(cmap->av, addr);
-
-	fastlock_acquire(&cmap->lock);
-	if (index < 0)
-		handle = util_cmap_get_handle_peer(cmap, addr);
-	else
-		handle = util_cmap_get_handle(cmap, (fi_addr_t)index);
-
-	if (!handle) {
-		if (index < 0)
-			ret = util_cmap_alloc_handle_peer(cmap, addr,
-							  CMAP_CONNREQ_RECV,
-							  &handle);
-		else
-			ret = util_cmap_alloc_handle(cmap, (fi_addr_t)index,
-						     CMAP_CONNREQ_RECV,
-						     &handle);
-		if (ret)
-			goto unlock;
-	}
-
-	switch (handle->state) {
-	case CMAP_CONNECTED:
-		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-			"Connection already present.\n");
-		ret = -FI_EALREADY;
-		break;
-	case CMAP_CONNREQ_SENT:
-		ofi_straddr_dbg(cmap->av->prov, FI_LOG_EP_CTRL, "local_name",
-				cmap->attr.name);
-		ofi_straddr_dbg(cmap->av->prov, FI_LOG_EP_CTRL, "remote_name",
-				addr);
-
-		cmp = ofi_addr_cmp(cmap->av->prov, addr, cmap->attr.name);
-
-		if (cmp < 0) {
-			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-				"Remote name lower than local name.\n");
-			ret = -FI_EALREADY;
-			break;
-		} else if (cmp > 0) {
-			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-				"Re-using handle: %p to accept remote "
-				"connection\n", handle);
-			/* Re-use handle. If it receives FI_REJECT the handle
-			 * would not be deleted in this state */
-			handle->cmap->attr.close(handle);
-		} else {
-			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-				"Endpoint connects to itself\n");
-			ret = util_cmap_alloc_handle_peer(cmap, addr,
-							  CMAP_CONNREQ_RECV,
-							  &handle);
-			if (ret)
-				goto unlock;
-			assert(index >= 0 && index != FI_ADDR_NOTAVAIL);
-			handle->fi_addr = index;
-		}
-		/* Fall through */
-	case CMAP_CONNREQ_RECV:
-		*handle_ret = handle;
-		break;
-	default:
-		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL,
-		       "Invalid cmap state\n");
-		assert(0);
-		ret = -FI_EOPBADSTATE;
-	}
-unlock:
-	fastlock_release(&cmap->lock);
-	return ret;
-}
-
-/* Caller must hold `cmap::lock` */
-int ofi_cmap_handle_connect(struct util_cmap *cmap, fi_addr_t fi_addr,
-			    struct util_cmap_handle *handle)
-{
-	int ret;
-
-	if (handle->state == CMAP_CONNECTED)
-		return FI_SUCCESS;
-
-	switch (handle->state) {
-	case CMAP_IDLE:
-		ret = cmap->attr.connect(cmap->ep, handle,
-					 ofi_av_get_addr(cmap->av, fi_addr),
-					 cmap->av->addrlen);
-		if (ret) {
-			util_cmap_del_handle(handle);
-			return ret;
-		}
-		handle->state = CMAP_CONNREQ_SENT;
-		ret = -FI_EAGAIN;
-		// TODO sleep on event fd instead of busy polling
-		break;
-	case CMAP_CONNREQ_SENT:
-	case CMAP_CONNREQ_RECV:
-	case CMAP_ACCEPT:
-	case CMAP_SHUTDOWN:
-		ret = -FI_EAGAIN;
-		break;
-	default:
-		FI_WARN(cmap->av->prov, FI_LOG_EP_CTRL,
-			"Invalid cmap handle state\n");
-		assert(0);
-		ret = -FI_EOPBADSTATE;
-	}
-	return ret;
-}
-
-int ofi_cmap_get_handle(struct util_cmap *cmap, fi_addr_t fi_addr,
-			struct util_cmap_handle **handle_ret)
-{
-	int ret;
-
-	fastlock_acquire(&cmap->lock);
-	*handle_ret = ofi_cmap_acquire_handle(cmap, fi_addr);
-	if (OFI_UNLIKELY(!*handle_ret)) {
-		ret = -FI_EAGAIN;
-		goto unlock;
-	}
-	
-	ret = ofi_cmap_handle_connect(cmap, fi_addr, *handle_ret);
-unlock:
-	fastlock_release(&cmap->lock);
-	return ret;
-}
-
-static int util_cmap_event_handler_close(struct util_cmap *cmap)
-{
-	int ret;
-
-	ret = cmap->attr.signal(cmap->ep, NULL, OFI_CMAP_EXIT);
-	if (ret) {
-		FI_WARN(cmap->av->prov, FI_LOG_FABRIC,
-			"Unable to signal event handler thread\n");
-		return ret;
-	}
-	/* Release lock so that event handler thread could process shutdown events */
-	fastlock_release(&cmap->lock);
-	ret = pthread_join(cmap->event_handler_thread, NULL);
-	fastlock_acquire(&cmap->lock);
-	if (ret) {
-		FI_WARN(cmap->av->prov, FI_LOG_FABRIC,
-			"Unable to join event handler thread\n");
-		return ret;
-	}
-	return 0;
-}
-
-void ofi_cmap_free(struct util_cmap *cmap)
-{
-	struct util_cmap_peer *peer;
-	struct dlist_entry *entry;
-	size_t i;
-
-	fastlock_acquire(&cmap->lock);
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL, "Closing cmap\n");
-	for (i = 0; i < cmap->av->count; i++) {
-		if (cmap->handles_av[i])
-			util_cmap_del_handle(cmap->handles_av[i]);
-	}
-	while(!dlist_empty(&cmap->peer_list)) {
-		entry = cmap->peer_list.next;
-		peer = container_of(entry, struct util_cmap_peer, entry);
-		util_cmap_del_handle(peer->handle);
-	}
-	util_cmap_event_handler_close(cmap);
-	free(cmap->handles_av);
-	free(cmap->attr.name);
-	fastlock_release(&cmap->lock);
-	fastlock_destroy(&cmap->lock);
-	free(cmap);
-}
-
-struct util_cmap *ofi_cmap_alloc(struct util_ep *ep,
-				 struct util_cmap_attr *attr)
-{
-	struct util_cmap *cmap;
-
-	cmap = calloc(1, sizeof *cmap);
-	if (!cmap)
-		return NULL;
-
-	cmap->ep = ep;
-	cmap->av = ep->av;
-
-	cmap->handles_av = calloc(cmap->av->count, sizeof(*cmap->handles_av));
-	if (!cmap->handles_av)
-		goto err1;
-
-	cmap->attr = *attr;
-	cmap->attr.name = mem_dup(attr->name, ep->av->addrlen);
-	if (!cmap->attr.name)
-		goto err2;
-
-	memset(&cmap->handles_idx, 0, sizeof(cmap->handles_idx));
-	ofi_key_idx_init(&cmap->key_idx, UTIL_CMAP_IDX_BITS);
-
-	dlist_init(&cmap->peer_list);
-	fastlock_init(&cmap->lock);
-
-	if (pthread_create(&cmap->event_handler_thread, 0,
-			   cmap->attr.event_handler, ep)) {
-		FI_WARN(ep->av->prov, FI_LOG_FABRIC,
-			"Unable to create msg_cm_listener_thread\n");
-		goto err3;
-	}
-	return cmap;
-err3:
-	fastlock_destroy(&cmap->lock);
-	free(cmap->attr.name);
-err2:
-	free(cmap->handles_av);
-err1:
-	free(cmap);
-	return NULL;
+	return ofi_ip_av_create_flags(domain_fid, attr, av, context, 0);
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_buf.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_buf.c
index b5f1682de..2d468f848 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_buf.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_buf.c
@@ -1,5 +1,6 @@
 /*
  * Copyright (c) 2016 Intel Corporation. All rights reserved.
+ * Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -38,25 +39,17 @@
 #include <ofi.h>
 #include <ofi_osd.h>
 
-static inline void util_buf_set_region(union util_buf *buf,
-				       struct util_buf_region *region,
-				       struct util_buf_pool *pool)
-{
-	struct util_buf_footer *buf_ftr;
-	if (util_buf_use_ftr(pool)) {
-		buf_ftr = (struct util_buf_footer *) ((char *) buf + pool->data_sz);
-		buf_ftr->region = region;
-	}
-}
 
 int util_buf_grow(struct util_buf_pool *pool)
 {
+	void *buf;
 	int ret;
 	size_t i;
-	union util_buf *util_buf;
 	struct util_buf_region *buf_region;
+	ssize_t hp_size;
+	struct util_buf_footer *buf_ftr;
 
-	if (pool->max_cnt && pool->num_allocated >= pool->max_cnt) {
+	if (pool->attr.max_cnt && pool->num_allocated >= pool->attr.max_cnt) {
 		return -1;
 	}
 
@@ -64,107 +57,230 @@ int util_buf_grow(struct util_buf_pool *pool)
 	if (!buf_region)
 		return -1;
 
-	ret = ofi_memalign((void **)&buf_region->mem_region, pool->alignment,
-			     pool->chunk_cnt * pool->entry_sz);
-	if (ret)
-		goto err;
+	buf_region->pool = pool;
+	dlist_init(&buf_region->buf_list);
+
+	if (pool->attr.is_mmap_region) {
+		hp_size = ofi_get_hugepage_size();
+		if (hp_size < 0)
+			goto err1;
+
+		buf_region->size = fi_get_aligned_sz(pool->attr.chunk_cnt *
+						     pool->entry_sz, hp_size);
+
+		ret = ofi_alloc_hugepage_buf((void **)&buf_region->mem_region,
+					     buf_region->size);
+		if (ret) {
+			FI_DBG(&core_prov, FI_LOG_CORE,
+			       "Huge page allocation failed: %s\n",
+			       fi_strerror(-ret));
+
+			if (pool->num_allocated > 0)
+				goto err1;
+
+			pool->attr.is_mmap_region = 0;
+		}
+	}
+
+	if (!pool->attr.is_mmap_region) {
+		buf_region->size = pool->attr.chunk_cnt * pool->entry_sz;
+
+		ret = ofi_memalign((void **)&buf_region->mem_region,
+				   pool->attr.alignment, buf_region->size);
+		if (ret)
+			goto err1;
+	}
 
-	if (pool->alloc_hndlr) {
-		ret = pool->alloc_hndlr(pool->ctx, buf_region->mem_region,
-					pool->chunk_cnt * pool->entry_sz,
-					&buf_region->context);
+	if (pool->attr.alloc_hndlr) {
+		ret = pool->attr.alloc_hndlr(pool->attr.ctx,
+					     buf_region->mem_region,
+					     buf_region->size,
+					     &buf_region->context);
 		if (ret)
-			goto err;
+			goto err2;
 	}
 
-	for (i = 0; i < pool->chunk_cnt; i++) {
-		util_buf = (union util_buf *)
-			(buf_region->mem_region + i * pool->entry_sz);
-		util_buf_set_region(util_buf, buf_region, pool);
-		slist_insert_tail(&util_buf->entry, &pool->buf_list);
+	if (!(pool->regions_cnt % UTIL_BUF_POOL_REGION_CHUNK_CNT)) {
+		struct util_buf_region **new_table =
+			realloc(pool->regions_table,
+				(pool->regions_cnt +
+				 UTIL_BUF_POOL_REGION_CHUNK_CNT) *
+				sizeof(*pool->regions_table));
+		if (!new_table)
+			goto err3;
+		pool->regions_table = new_table;
 	}
+	pool->regions_table[pool->regions_cnt] = buf_region;
+	pool->regions_cnt++;
 
-	slist_insert_tail(&buf_region->entry, &pool->region_list);
-	pool->num_allocated += pool->chunk_cnt;
+	for (i = 0; i < pool->attr.chunk_cnt; i++) {
+		buf = (buf_region->mem_region + i * pool->entry_sz);
+		buf_ftr = util_buf_get_ftr(pool, buf);
+
+		if (pool->attr.init) {
+#if ENABLE_DEBUG
+			if (!pool->attr.indexing.ordered) {
+				buf_ftr->entry.slist.next = (void *) OFI_MAGIC_64;
+
+				pool->attr.init(pool->attr.ctx, buf);
+
+				assert(buf_ftr->entry.slist.next == (void *) OFI_MAGIC_64);
+			} else {
+				buf_ftr->entry.dlist.next = (void *) OFI_MAGIC_64;
+				buf_ftr->entry.dlist.prev = (void *) OFI_MAGIC_64;
+
+				pool->attr.init(pool->attr.ctx, buf);
+
+				assert((buf_ftr->entry.dlist.next == (void *) OFI_MAGIC_64) &&
+				       (buf_ftr->entry.dlist.prev == (void *) OFI_MAGIC_64));
+			}
+#else
+			pool->attr.init(pool->attr.ctx, buf);
+#endif
+		}
+
+		buf_ftr->region = buf_region;
+		buf_ftr->index = pool->num_allocated + i;
+		if (!pool->attr.indexing.ordered) {
+			slist_insert_tail(&buf_ftr->entry.slist,
+					  &pool->list.buffers);
+		} else {
+			dlist_insert_tail(&buf_ftr->entry.dlist,
+					  &buf_region->buf_list);
+		}
+	}
+
+	if (pool->attr.indexing.ordered) {
+		dlist_insert_tail(&buf_region->entry,
+				  &pool->list.regions);
+	}
+
+	pool->num_allocated += pool->attr.chunk_cnt;
 	return 0;
-err:
+err3:
+	if (pool->attr.free_hndlr)
+	    pool->attr.free_hndlr(pool->attr.ctx, buf_region->context);
+err2:
+	ofi_freealign(buf_region->mem_region);
+err1:
 	free(buf_region);
 	return -1;
 }
 
-int util_buf_pool_create_ex(struct util_buf_pool **buf_pool,
-			    size_t size, size_t alignment,
-			    size_t max_cnt, size_t chunk_cnt,
-			    util_buf_region_alloc_hndlr alloc_hndlr,
-			    util_buf_region_free_hndlr free_hndlr,
-			    void *pool_ctx)
+int util_buf_pool_create_attr(struct util_buf_attr *attr,
+			      struct util_buf_pool **buf_pool)
 {
 	size_t entry_sz;
+	ssize_t hp_size;
 
 	(*buf_pool) = calloc(1, sizeof(**buf_pool));
 	if (!*buf_pool)
 		return -FI_ENOMEM;
 
-	(*buf_pool)->alloc_hndlr = alloc_hndlr;
-	(*buf_pool)->free_hndlr = free_hndlr;
-	(*buf_pool)->data_sz = size;
-	(*buf_pool)->alignment = alignment;
-	(*buf_pool)->max_cnt = max_cnt;
-	(*buf_pool)->chunk_cnt = chunk_cnt;
-	(*buf_pool)->ctx = pool_ctx;
+	(*buf_pool)->attr = *attr;
 
-	entry_sz = util_buf_use_ftr(*buf_pool) ?
-		(size + sizeof(struct util_buf_footer)) : size;
-	(*buf_pool)->entry_sz = fi_get_aligned_sz(entry_sz, alignment);
+	entry_sz = (attr->size + sizeof(struct util_buf_footer));
+	(*buf_pool)->entry_sz = fi_get_aligned_sz(entry_sz, attr->alignment);
 
-	slist_init(&(*buf_pool)->buf_list);
-	slist_init(&(*buf_pool)->region_list);
+	hp_size = ofi_get_hugepage_size();
 
-	if (util_buf_grow(*buf_pool)) {
-		free(*buf_pool);
-		return -FI_ENOMEM;
-	}
-	return FI_SUCCESS;
-}
+	if ((*buf_pool)->attr.chunk_cnt * (*buf_pool)->entry_sz < hp_size)
+		(*buf_pool)->attr.is_mmap_region = 0;
+	else
+		(*buf_pool)->attr.is_mmap_region = 1;
 
-#if ENABLE_DEBUG
-void *util_buf_get(struct util_buf_pool *pool)
-{
-	struct slist_entry *entry;
-	struct util_buf_footer *buf_ftr;
+	if (!(*buf_pool)->attr.indexing.ordered)
+		slist_init(&(*buf_pool)->list.buffers);
+	else
+		dlist_init(&(*buf_pool)->list.regions);
 
-	entry = slist_remove_head(&pool->buf_list);
-	buf_ftr = (struct util_buf_footer *) ((char *) entry + pool->data_sz);
-	buf_ftr->region->num_used++;
-	return entry;
+	return FI_SUCCESS;
 }
 
-void util_buf_release(struct util_buf_pool *pool, void *buf)
+int util_buf_pool_create_ex(struct util_buf_pool **buf_pool,
+			    size_t size, size_t alignment,
+			    size_t max_cnt, size_t chunk_cnt,
+			    util_buf_region_alloc_hndlr alloc_hndlr,
+			    util_buf_region_free_hndlr free_hndlr,
+			    void *pool_ctx)
 {
-	union util_buf *util_buf = buf;
-	struct util_buf_footer *buf_ftr;
-
-	buf_ftr = (struct util_buf_footer *) ((char *) buf + pool->data_sz);
-	buf_ftr->region->num_used--;
-	slist_insert_head(&util_buf->entry, &pool->buf_list);
+	struct util_buf_attr attr = {
+		.size		= size,
+		.alignment 	= alignment,
+		.max_cnt	= max_cnt,
+		.chunk_cnt	= chunk_cnt,
+		.alloc_hndlr	= alloc_hndlr,
+		.free_hndlr	= free_hndlr,
+		.ctx		= pool_ctx,
+		.track_used	= 1,
+		.indexing	= {
+			.used		= 1,
+			.ordered	= 0,
+		},
+	};
+	return util_buf_pool_create_attr(&attr, buf_pool);
 }
-#endif
 
 void util_buf_pool_destroy(struct util_buf_pool *pool)
 {
-	struct slist_entry *entry;
 	struct util_buf_region *buf_region;
+	int ret;
+	size_t i;
 
-	while (!slist_empty(&pool->region_list)) {
-		entry = slist_remove_head(&pool->region_list);
-		buf_region = container_of(entry, struct util_buf_region, entry);
+	for (i = 0; i < pool->regions_cnt; i++) {
+		buf_region = pool->regions_table[i];
 #if ENABLE_DEBUG
-		assert(buf_region->num_used == 0);
+		if (pool->attr.track_used)
+			assert(buf_region->num_used == 0);
 #endif
-		if (pool->free_hndlr)
-			pool->free_hndlr(pool->ctx, buf_region->context);
-		ofi_freealign(buf_region->mem_region);
+		if (pool->attr.free_hndlr)
+			pool->attr.free_hndlr(pool->attr.ctx, buf_region->context);
+		if (pool->attr.is_mmap_region) {
+			ret = ofi_free_hugepage_buf(buf_region->mem_region,
+						    buf_region->size);
+			if (ret) {
+				FI_DBG(&core_prov, FI_LOG_CORE,
+				       "Huge page free failed: %s\n",
+				       fi_strerror(-ret));
+				assert(0);
+			}
+		} else {
+			ofi_freealign(buf_region->mem_region);
+		}
+
 		free(buf_region);
 	}
+	free(pool->regions_table);
 	free(pool);
 }
+
+int util_buf_is_lower(struct dlist_entry *item, const void *arg)
+{
+	struct util_buf_footer *buf_ftr1 =
+		container_of((struct dlist_entry *)arg,
+			     struct util_buf_footer, entry.dlist);
+	struct util_buf_footer *buf_ftr2 =
+		container_of(item, struct util_buf_footer, entry.dlist);
+	return (buf_ftr1->index < buf_ftr2->index);
+}
+
+int util_buf_region_is_lower(struct dlist_entry *item, const void *arg)
+{
+	struct util_buf_region *buf_region1 =
+		container_of((struct dlist_entry *)arg,
+			     struct util_buf_region, entry);
+	struct util_buf_region *buf_region2 =
+		container_of(item, struct util_buf_region, entry);
+	struct util_buf_footer *buf_region1_head =
+		container_of(buf_region1->buf_list.next,
+			     struct util_buf_footer, entry.dlist);
+	struct util_buf_footer *buf_region2_head =
+		container_of(buf_region2->buf_list.next,
+			     struct util_buf_footer, entry.dlist);
+	size_t buf_region1_index =
+		(size_t)(buf_region1_head->index / buf_region1->pool->attr.chunk_cnt);
+	size_t buf_region2_index =
+		(size_t)(buf_region2_head->index / buf_region2->pool->attr.chunk_cnt);
+
+	return (buf_region1_index < buf_region2_index);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_cq.c
index 1963f38c4..9a0d4d9d6 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_cq.c
@@ -38,22 +38,58 @@
 
 #define UTIL_DEF_CQ_SIZE (1024)
 
+/* Caller must hold `cq_lock` */
+int ofi_cq_write_overflow(struct util_cq *cq, void *context, uint64_t flags, size_t len,
+			  void *buf, uint64_t data, uint64_t tag, fi_addr_t src)
+{
+	struct util_cq_oflow_err_entry *entry;
+
+	assert(ofi_cirque_isfull(cq->cirq));
+
+	if (!(entry = calloc(1, sizeof(*entry))))
+		return -FI_ENOMEM;
+
+	entry->parent_comp = ofi_cirque_tail(cq->cirq);
+	entry->parent_comp->flags |= UTIL_FLAG_OVERFLOW;
+
+	entry->comp.op_context = context;
+	entry->comp.flags = flags;
+	entry->comp.len = len;
+	entry->comp.buf = buf;
+	entry->comp.data = data;
+	entry->comp.tag = tag;
+
+	entry->src = src;
+	slist_insert_tail(&entry->list_entry, &cq->oflow_err_list);
+
+	return 0;
+}
+
 int ofi_cq_write_error(struct util_cq *cq,
 		       const struct fi_cq_err_entry *err_entry)
 {
-	struct util_cq_err_entry *entry;
+	struct util_cq_oflow_err_entry *entry;
 	struct fi_cq_tagged_entry *comp;
 
+	assert(err_entry->err);
+
 	if (!(entry = calloc(1, sizeof(*entry))))
 		return -FI_ENOMEM;
 
-	entry->err_entry = *err_entry;
-	fastlock_acquire(&cq->cq_lock);
-	slist_insert_tail(&entry->list_entry, &cq->err_list);
-	comp = ofi_cirque_tail(cq->cirq);
-	comp->flags = UTIL_FLAG_ERROR;
-	ofi_cirque_commit(cq->cirq);
-	fastlock_release(&cq->cq_lock);
+	entry->comp = *err_entry;
+	cq->cq_fastlock_acquire(&cq->cq_lock);
+	slist_insert_tail(&entry->list_entry, &cq->oflow_err_list);
+
+	if (OFI_UNLIKELY(ofi_cirque_isfull(cq->cirq))) {
+		comp = ofi_cirque_tail(cq->cirq);
+		comp->flags |= (UTIL_FLAG_ERROR | UTIL_FLAG_OVERFLOW);
+		entry->parent_comp = ofi_cirque_tail(cq->cirq);
+	} else {
+		comp = ofi_cirque_tail(cq->cirq);
+		comp->flags = UTIL_FLAG_ERROR;
+		ofi_cirque_commit(cq->cirq);
+	}
+	cq->cq_fastlock_release(&cq->cq_lock);
 	if (cq->wait)
 		cq->wait->signal(cq->wait);
 	return 0;
@@ -89,32 +125,6 @@ int ofi_cq_write_error_trunc(struct util_cq *cq, void *context, uint64_t flags,
 	return ofi_cq_write_error(cq, &err_entry);
 }
 
-int ofi_cq_write(struct util_cq *cq, void *context, uint64_t flags, size_t len,
-		 void *buf, uint64_t data, uint64_t tag)
-{
-	struct fi_cq_tagged_entry *comp;
-	int ret = 0;
-
-	fastlock_acquire(&cq->cq_lock);
-	if (ofi_cirque_isfull(cq->cirq)) {
-		FI_DBG(cq->domain->prov, FI_LOG_CQ, "util_cq cirq is full!\n");
-		ret = -FI_EAGAIN;
-		goto out;
-	}
-
-	comp = ofi_cirque_tail(cq->cirq);
-	comp->op_context = context;
-	comp->flags = flags;
-	comp->len = len;
-	comp->buf = buf;
-	comp->data = data;
-	comp->tag = tag;
-	ofi_cirque_commit(cq->cirq);
-out:
-	fastlock_release(&cq->cq_lock);
-	return ret;
-}
-
 int ofi_check_cq_attr(const struct fi_provider *prov,
 		      const struct fi_cq_attr *attr)
 {
@@ -191,8 +201,37 @@ static void util_cq_read_tagged(void **dst, void *src)
 	*(char **)dst += sizeof(struct fi_cq_tagged_entry);
 }
 
+static inline
+void util_cq_read_oflow_entry(struct util_cq *cq,
+			      struct util_cq_oflow_err_entry *oflow_entry,
+			      struct fi_cq_tagged_entry *cirq_entry,
+			      void **buf, fi_addr_t *src_addr, ssize_t i)
+{
+	if (src_addr && cq->src) {
+		src_addr[i] = cq->src[ofi_cirque_rindex(cq->cirq)];
+		cq->src[ofi_cirque_rindex(cq->cirq)] = oflow_entry->src;
+	}
+	cq->read_entry(buf, cirq_entry);
+	cirq_entry->op_context = oflow_entry->comp.op_context;
+	cirq_entry->flags = oflow_entry->comp.flags;
+	cirq_entry->len = oflow_entry->comp.len;
+	cirq_entry->buf = oflow_entry->comp.buf;
+	cirq_entry->data = oflow_entry->comp.data;
+	cirq_entry->tag = oflow_entry->comp.tag;
+}
+
+static inline
+void util_cq_read_entry(struct util_cq *cq, struct fi_cq_tagged_entry *entry,
+			void **buf, fi_addr_t *src_addr, ssize_t i)
+{
+	if (src_addr && cq->src)
+		src_addr[i] = cq->src[ofi_cirque_rindex(cq->cirq)];
+	cq->read_entry(buf, entry);
+	ofi_cirque_discard(cq->cirq);
+}
+
 ssize_t ofi_cq_readfrom(struct fid_cq *cq_fid, void *buf, size_t count,
-		fi_addr_t *src_addr)
+			fi_addr_t *src_addr)
 {
 	struct util_cq *cq;
 	struct fi_cq_tagged_entry *entry;
@@ -200,11 +239,11 @@ ssize_t ofi_cq_readfrom(struct fid_cq *cq_fid, void *buf, size_t count,
 
 	cq = container_of(cq_fid, struct util_cq, cq_fid);
 
-	fastlock_acquire(&cq->cq_lock);
-	if (ofi_cirque_isempty(cq->cirq)) {
-		fastlock_release(&cq->cq_lock);
+	cq->cq_fastlock_acquire(&cq->cq_lock);
+	if (ofi_cirque_isempty(cq->cirq) || !count) {
+		cq->cq_fastlock_release(&cq->cq_lock);
 		cq->progress(cq);
-		fastlock_acquire(&cq->cq_lock);
+		cq->cq_fastlock_acquire(&cq->cq_lock);
 		if (ofi_cirque_isempty(cq->cirq)) {
 			i = -FI_EAGAIN;
 			goto out;
@@ -216,18 +255,55 @@ ssize_t ofi_cq_readfrom(struct fid_cq *cq_fid, void *buf, size_t count,
 
 	for (i = 0; i < (ssize_t)count; i++) {
 		entry = ofi_cirque_head(cq->cirq);
-		if (entry->flags & UTIL_FLAG_ERROR) {
-			if (!i)
-				i = -FI_EAVAIL;
-			break;
+		if (OFI_UNLIKELY(entry->flags & (UTIL_FLAG_ERROR |
+						 UTIL_FLAG_OVERFLOW))) {
+			if (entry->flags & UTIL_FLAG_ERROR) {
+				struct util_cq_oflow_err_entry *oflow_err_entry =
+						container_of(cq->oflow_err_list.head,
+							     struct util_cq_oflow_err_entry,
+							     list_entry);
+				if (oflow_err_entry->comp.err) {
+					/* This handles case when the head of oflow_err_list is
+					 * an error entry.
+					 *
+					 * NOTE: if this isn't an error entry, we have to handle
+					 * overflow entries and then the error entries to ensure
+					 * ordering. */
+					if (!i)
+						i = -FI_EAVAIL;
+					break;
+				}
+			}
+			if (entry->flags & UTIL_FLAG_OVERFLOW) {
+				assert(!slist_empty(&cq->oflow_err_list));
+				struct util_cq_oflow_err_entry *oflow_entry =
+					container_of(cq->oflow_err_list.head,
+						     struct util_cq_oflow_err_entry,
+						     list_entry);
+				if (oflow_entry->parent_comp != entry) {
+					/* Handle case when all overflow/error CQ entries were read
+					 * for particular CIRQ entry */
+					entry->flags &= ~(UTIL_FLAG_OVERFLOW | UTIL_FLAG_ERROR);
+				} else {
+					uint64_t service_flags =
+						(entry->flags & (UTIL_FLAG_OVERFLOW | UTIL_FLAG_ERROR));
+					slist_remove_head(&cq->oflow_err_list);
+
+					entry->flags &= ~(service_flags);
+					util_cq_read_oflow_entry(cq, oflow_entry, entry,
+								 &buf, src_addr, i);
+					/* To ensure checking of overflow CQ entries once again */
+					if (!slist_empty(&cq->oflow_err_list))
+						entry->flags |= service_flags;
+					free(oflow_entry);
+					continue;
+				}
+			}
 		}
-		if (src_addr && cq->src)
-			src_addr[i] = cq->src[ofi_cirque_rindex(cq->cirq)];
-		cq->read_entry(&buf, entry);
-		ofi_cirque_discard(cq->cirq);
+		util_cq_read_entry(cq, entry, &buf, src_addr, i);
 	}
 out:
-	fastlock_release(&cq->cq_lock);
+	cq->cq_fastlock_release(&cq->cq_lock);
 	return i;
 }
 
@@ -237,11 +313,12 @@ ssize_t ofi_cq_read(struct fid_cq *cq_fid, void *buf, size_t count)
 }
 
 ssize_t ofi_cq_readerr(struct fid_cq *cq_fid, struct fi_cq_err_entry *buf,
-		uint64_t flags)
+		       uint64_t flags)
 {
 	struct util_cq *cq;
-	struct util_cq_err_entry *err;
+	struct util_cq_oflow_err_entry *err;
 	struct slist_entry *entry;
+	struct fi_cq_tagged_entry *cirq_entry;
 	char *err_buf_save;
 	size_t err_data_size;
 	uint32_t api_version;
@@ -250,35 +327,56 @@ ssize_t ofi_cq_readerr(struct fid_cq *cq_fid, struct fi_cq_err_entry *buf,
 	cq = container_of(cq_fid, struct util_cq, cq_fid);
 	api_version = cq->domain->fabric->fabric_fid.api_version;
 
-	fastlock_acquire(&cq->cq_lock);
+	cq->cq_fastlock_acquire(&cq->cq_lock);
 	if (ofi_cirque_isempty(cq->cirq) ||
 	    !(ofi_cirque_head(cq->cirq)->flags & UTIL_FLAG_ERROR)) {
 		ret = -FI_EAGAIN;
 		goto unlock;
 	}
 
-	ofi_cirque_discard(cq->cirq);
-	entry = slist_remove_head(&cq->err_list);
-	err = container_of(entry, struct util_cq_err_entry, list_entry);
+	entry = slist_remove_head(&cq->oflow_err_list);
+	err = container_of(entry, struct util_cq_oflow_err_entry, list_entry);
 	if ((FI_VERSION_GE(api_version, FI_VERSION(1, 5))) && buf->err_data_size) {
-		err_data_size = MIN(buf->err_data_size, err->err_entry.err_data_size);
-		memcpy(buf->err_data, err->err_entry.err_data, err_data_size);
+		err_data_size = MIN(buf->err_data_size, err->comp.err_data_size);
+		memcpy(buf->err_data, err->comp.err_data, err_data_size);
 		err_buf_save = buf->err_data;
-		*buf = err->err_entry;
+		*buf = err->comp;
 		buf->err_data = err_buf_save;
 		buf->err_data_size = err_data_size;
 	} else {
-		memcpy(buf, &err->err_entry, sizeof(struct fi_cq_err_entry_1_0));
+		memcpy(buf, &err->comp, sizeof(struct fi_cq_err_entry_1_0));
 	}
+
+	cirq_entry = ofi_cirque_head(cq->cirq);
+	if (!(cirq_entry->flags & UTIL_FLAG_OVERFLOW)) {
+		ofi_cirque_discard(cq->cirq);
+	} else if (!slist_empty(&cq->oflow_err_list)) {
+		struct util_cq_oflow_err_entry *oflow_entry =
+			container_of(cq->oflow_err_list.head,
+				     struct util_cq_oflow_err_entry,
+				     list_entry);
+		if (oflow_entry->parent_comp != cirq_entry) {
+			/* The normal CQ entry were used to report error due to
+			 * out of space in the circular queue. We have to unset
+			 * UTIL_FLAG_ERROR and UTIL_FLAG_OVERFLOW flags */
+			cirq_entry->flags &= ~(UTIL_FLAG_ERROR | UTIL_FLAG_OVERFLOW);
+		}
+		/* If the next entry in the oflow_err_list use the same entry from CIRQ to
+		 * report error/overflow, don't unset UTIL_FLAG_ERRO and UTIL_FLAG_OVERFLOW
+		 * flags to ensure the next round of handling overflow/error entries */
+	} else {
+		cirq_entry->flags &= ~(UTIL_FLAG_ERROR | UTIL_FLAG_OVERFLOW);
+	}
+
 	ret = 1;
 	free(err);
 unlock:
-	fastlock_release(&cq->cq_lock);
+	cq->cq_fastlock_release(&cq->cq_lock);
 	return ret;
 }
 
 ssize_t ofi_cq_sreadfrom(struct fid_cq *cq_fid, void *buf, size_t count,
-		fi_addr_t *src_addr, const void *cond, int timeout)
+			 fi_addr_t *src_addr, const void *cond, int timeout)
 {
 	struct util_cq *cq;
 	uint64_t start;
@@ -318,12 +416,9 @@ ssize_t ofi_cq_sread(struct fid_cq *cq_fid, void *buf, size_t count,
 
 int ofi_cq_signal(struct fid_cq *cq_fid)
 {
-	struct util_cq *cq;
-
-	cq = container_of(cq_fid, struct util_cq, cq_fid);
-	assert(cq->wait);
+	struct util_cq *cq = container_of(cq_fid, struct util_cq, cq_fid);
 	ofi_atomic_set32(&cq->signaled, 1);
-	cq->wait->signal(cq->wait);
+	util_cq_signal(cq);
 	return 0;
 }
 
@@ -346,18 +441,15 @@ static struct fi_ops_cq util_cq_ops = {
 
 int ofi_cq_cleanup(struct util_cq *cq)
 {
-	struct util_cq_err_entry *err;
+	struct util_cq_oflow_err_entry *err;
 	struct slist_entry *entry;
 
 	if (ofi_atomic_get32(&cq->ref))
 		return -FI_EBUSY;
 
-	fastlock_destroy(&cq->cq_lock);
-	fastlock_destroy(&cq->ep_list_lock);
-
-	while (!slist_empty(&cq->err_list)) {
-		entry = slist_remove_head(&cq->err_list);
-		err = container_of(entry, struct util_cq_err_entry, list_entry);
+	while (!slist_empty(&cq->oflow_err_list)) {
+		entry = slist_remove_head(&cq->oflow_err_list);
+		err = container_of(entry, struct util_cq_oflow_err_entry, list_entry);
 		free(err);
 	}
 
@@ -370,10 +462,27 @@ int ofi_cq_cleanup(struct util_cq *cq)
 
 	ofi_atomic_dec32(&cq->domain->ref);
 	util_comp_cirq_free(cq->cirq);
+	fastlock_destroy(&cq->cq_lock);
+	fastlock_destroy(&cq->ep_list_lock);
 	free(cq->src);
 	return 0;
 }
 
+int ofi_cq_control(struct fid *fid, int command, void *arg)
+{
+	struct util_cq *cq = container_of(fid, struct util_cq, cq_fid.fid);
+
+	switch (command) {
+	case FI_GETWAIT:
+		if (!cq->wait)
+			return -FI_ENODATA;
+		return fi_control(&cq->wait->wait_fid.fid, FI_GETWAIT, arg);
+	default:
+		FI_INFO(cq->wait->prov, FI_LOG_CQ, "Unsupported command\n");
+		return -FI_ENOSYS;
+	}
+}
+
 static int util_cq_close(struct fid *fid)
 {
 	struct util_cq *cq;
@@ -392,7 +501,7 @@ static struct fi_ops util_cq_fi_ops = {
 	.size = sizeof(struct fi_ops),
 	.close = util_cq_close,
 	.bind = fi_no_bind,
-	.control = fi_no_control,
+	.control = ofi_cq_control,
 	.ops_open = fi_no_ops_open,
 };
 
@@ -410,7 +519,15 @@ static int fi_cq_init(struct fid_domain *domain, struct fi_cq_attr *attr,
 	dlist_init(&cq->ep_list);
 	fastlock_init(&cq->ep_list_lock);
 	fastlock_init(&cq->cq_lock);
-	slist_init(&cq->err_list);
+	if (cq->domain->threading == FI_THREAD_COMPLETION ||
+	    (cq->domain->threading == FI_THREAD_DOMAIN)) {
+		cq->cq_fastlock_acquire = ofi_fastlock_acquire_noop;
+		cq->cq_fastlock_release = ofi_fastlock_release_noop;
+	} else {
+		cq->cq_fastlock_acquire = ofi_fastlock_acquire;
+		cq->cq_fastlock_release = ofi_fastlock_release;
+	}
+	slist_init(&cq->oflow_err_list);
 	cq->read_entry = read_entry;
 
 	cq->cq_fid.fid.fclass = FI_CLASS_CQ;
@@ -473,14 +590,14 @@ void ofi_cq_progress(struct util_cq *cq)
 	struct fid_list_entry *fid_entry;
 	struct dlist_entry *item;
 
-	fastlock_acquire(&cq->ep_list_lock);
+	cq->cq_fastlock_acquire(&cq->ep_list_lock);
 	dlist_foreach(&cq->ep_list, item) {
 		fid_entry = container_of(item, struct fid_list_entry, entry);
 		ep = container_of(fid_entry->fid, struct util_ep, ep_fid.fid);
 		ep->progress(ep);
 
 	}
-	fastlock_release(&cq->ep_list_lock);
+	cq->cq_fastlock_release(&cq->ep_list_lock);
 }
 
 int ofi_cq_init(const struct fi_provider *prov, struct fid_domain *domain,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_domain.c
index bfbe6280a..2a7d8de11 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_domain.c
@@ -86,6 +86,8 @@ static int util_domain_init(struct util_domain *domain,
 	domain->addr_format = info->addr_format;
 	domain->av_type = info->domain_attr->av_type;
 	domain->name = strdup(info->domain_attr->name);
+	domain->threading = info->domain_attr->threading;
+	domain->data_progress = info->domain_attr->data_progress;
 	return domain->name ? 0 : -FI_ENOMEM;
 }
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_ep.c
index 710d95f29..aa9478bac 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_ep.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_ep.c
@@ -116,31 +116,37 @@ int ofi_ep_bind_cntr(struct util_ep *ep, struct util_cntr *cntr, uint64_t flags)
 
 	if (flags & FI_TRANSMIT) {
 		ep->tx_cntr = cntr;
+		ep->tx_cntr_inc = ofi_cntr_inc;
 		ofi_atomic_inc32(&cntr->ref);
 	}
 
 	if (flags & FI_RECV) {
 		ep->rx_cntr = cntr;
+		ep->rx_cntr_inc = ofi_cntr_inc;
 		ofi_atomic_inc32(&cntr->ref);
 	}
 
 	if (flags & FI_READ) {
 		ep->rd_cntr = cntr;
+		ep->rd_cntr_inc = ofi_cntr_inc;
 		ofi_atomic_inc32(&cntr->ref);
 	}
 
 	if (flags & FI_WRITE) {
 		ep->wr_cntr = cntr;
+		ep->wr_cntr_inc = ofi_cntr_inc;
 		ofi_atomic_inc32(&cntr->ref);
 	}
 
 	if (flags & FI_REMOTE_READ) {
 		ep->rem_rd_cntr = cntr;
+		ep->rem_rd_cntr_inc = ofi_cntr_inc;
 		ofi_atomic_inc32(&cntr->ref);
 	}
 
 	if (flags & FI_REMOTE_WRITE) {
 		ep->rem_wr_cntr = cntr;
+		ep->rem_wr_cntr_inc = ofi_cntr_inc;
 		ofi_atomic_inc32(&cntr->ref);
 	}
 
@@ -206,17 +212,33 @@ int ofi_endpoint_init(struct fid_domain *domain, const struct util_prov *util_pr
 	ep->progress = progress;
 	ep->tx_op_flags = info->tx_attr->op_flags;
 	ep->rx_op_flags = info->rx_attr->op_flags;
+	ep->inject_op_flags =
+		((info->tx_attr->op_flags &
+		  ~(FI_COMPLETION | FI_INJECT_COMPLETE |
+		    FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)) | FI_INJECT);
+	ep->tx_cntr_inc 	= ofi_cntr_inc_noop;
+	ep->rx_cntr_inc 	= ofi_cntr_inc_noop;
+	ep->rd_cntr_inc 	= ofi_cntr_inc_noop;
+	ep->wr_cntr_inc 	= ofi_cntr_inc_noop;
+	ep->rem_rd_cntr_inc 	= ofi_cntr_inc_noop;
+	ep->rem_wr_cntr_inc 	= ofi_cntr_inc_noop;
+	ep->type = info->ep_attr->type;
 	ofi_atomic_inc32(&util_domain->ref);
 	if (util_domain->eq)
 		ofi_ep_bind_eq(ep, util_domain->eq);
 	fastlock_init(&ep->lock);
+	if (ep->domain->threading != FI_THREAD_SAFE) {
+		ep->lock_acquire = ofi_fastlock_acquire_noop;
+		ep->lock_release = ofi_fastlock_release_noop;
+	} else {
+		ep->lock_acquire = ofi_fastlock_acquire;
+		ep->lock_release = ofi_fastlock_release;
+	}
 	return 0;
 }
 
 int ofi_endpoint_close(struct util_ep *util_ep)
 {
-	fastlock_destroy(&util_ep->lock);
-
 	if (util_ep->tx_cq) {
 		fid_list_remove(&util_ep->tx_cq->ep_list,
 				&util_ep->tx_cq->ep_list_lock,
@@ -284,5 +306,6 @@ int ofi_endpoint_close(struct util_ep *util_ep)
 	if (util_ep->eq)
 		ofi_atomic_dec32(&util_ep->eq->ref);
 	ofi_atomic_dec32(&util_ep->domain->ref);
+	fastlock_destroy(&util_ep->lock);
 	return 0;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_eq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_eq.c
index 19202948c..390993c06 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_eq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_eq.c
@@ -36,12 +36,43 @@
 #include <ofi_enosys.h>
 #include <ofi_util.h>
 
+void ofi_eq_handle_err_entry(uint32_t api_version, uint64_t flags,
+			     struct fi_eq_err_entry *err_entry,
+			     struct fi_eq_err_entry *user_err_entry)
+{
+	if ((FI_VERSION_GE(api_version, FI_VERSION(1, 5)))
+	    && user_err_entry->err_data && user_err_entry->err_data_size) {
+		void *err_data = user_err_entry->err_data;
+		size_t err_data_size = MIN(err_entry->err_data_size,
+					   user_err_entry->err_data_size);
+
+		memcpy(err_data, err_entry->err_data, err_data_size);
+
+		*user_err_entry = *err_entry;
+		user_err_entry->err_data = err_data;
+		user_err_entry->err_data_size = err_data_size;
+
+		if (!(flags & FI_PEEK)) {
+			free(err_entry->err_data);
+			err_entry->err_data = NULL;
+			err_entry->err_data_size = 0;
+		}
+	} else {
+		*user_err_entry = *err_entry;
+	}
+
+	if (!(flags & FI_PEEK)) {
+		err_entry->err = 0;
+		err_entry->prov_errno = 0;
+	}
+}
 
-static ssize_t util_eq_read(struct fid_eq *eq_fid, uint32_t *event,
-			    void *buf, size_t len, uint64_t flags)
+ssize_t ofi_eq_read(struct fid_eq *eq_fid, uint32_t *event,
+		    void *buf, size_t len, uint64_t flags)
 {
 	struct util_eq *eq;
 	struct util_event *entry;
+	struct fi_eq_err_entry *err_entry;
 	ssize_t ret;
 
 	eq = container_of(eq_fid, struct util_eq, eq_fid);
@@ -64,8 +95,23 @@ static ssize_t util_eq_read(struct fid_eq *eq_fid, uint32_t *event,
 	if (event)
 		*event = entry->event;
 	if (buf) {
-		ret = MIN(len, (size_t)entry->size);
-		memcpy(buf, entry->data, ret);
+		if (flags & UTIL_FLAG_ERROR) {
+			free(eq->saved_err_data);
+			eq->saved_err_data = NULL;
+
+			assert((size_t) entry->size == sizeof(*err_entry));
+			err_entry = (struct fi_eq_err_entry *) entry->data;
+
+			ofi_eq_handle_err_entry(eq->fabric->fabric_fid.api_version,
+						flags, err_entry, buf);
+			ret = (ssize_t) entry->size;
+
+			if (!(flags & FI_PEEK))
+				eq->saved_err_data = err_entry->err_data;
+		} else {
+			ret = MIN(len, (size_t)entry->size);
+			memcpy(buf, entry->data, ret);
+		}
 	}  else {
 		ret = 0;
 	}
@@ -79,22 +125,21 @@ out:
 	return ret;
 }
 
-static ssize_t util_eq_readerr(struct fid_eq *eq_fid, struct fi_eq_err_entry *buf,
-			       uint64_t flags)
+ssize_t ofi_eq_readerr(struct fid_eq *eq_fid, struct fi_eq_err_entry *buf,
+		       uint64_t flags)
 {
-
-	return util_eq_read(eq_fid, NULL, buf, sizeof(*buf),
-			    flags | UTIL_FLAG_ERROR);
+	return fi_eq_read(eq_fid, NULL, buf, sizeof(*buf),
+			  flags | UTIL_FLAG_ERROR);
 }
 
-static ssize_t util_eq_write(struct fid_eq *eq_fid, uint32_t event,
-			     const void *buf, size_t len, uint64_t flags)
+ssize_t ofi_eq_write(struct fid_eq *eq_fid, uint32_t event,
+		     const void *buf, size_t len, uint64_t flags)
 {
 	struct util_eq *eq;
 	struct util_event *entry;
 
 	eq = container_of(eq_fid, struct util_eq, eq_fid);
-	entry = malloc(sizeof(*entry) + len);
+	entry = calloc(1, sizeof(*entry) + len);
 	if (!entry)
 		return -FI_ENOMEM;
 
@@ -113,8 +158,8 @@ static ssize_t util_eq_write(struct fid_eq *eq_fid, uint32_t event,
 	return len;
 }
 
-static ssize_t util_eq_sread(struct fid_eq *eq_fid, uint32_t *event, void *buf,
-			     size_t len, int timeout, uint64_t flags)
+ssize_t ofi_eq_sread(struct fid_eq *eq_fid, uint32_t *event, void *buf,
+		     size_t len, int timeout, uint64_t flags)
 {
 	struct util_eq *eq;
 
@@ -128,8 +173,8 @@ static ssize_t util_eq_sread(struct fid_eq *eq_fid, uint32_t *event, void *buf,
 	return fi_eq_read(eq_fid, event, buf, len, flags);
 }
 
-static const char *util_eq_strerror(struct fid_eq *eq_fid, int prov_errno,
-				    const void *err_data, char *buf, size_t len)
+const char *ofi_eq_strerror(struct fid_eq *eq_fid, int prov_errno,
+			    const void *err_data, char *buf, size_t len)
 {
 	return (buf && len) ? strncpy(buf, strerror(prov_errno), len) :
 			      fi_strerror(prov_errno);
@@ -185,11 +230,11 @@ static int util_eq_close(struct fid *fid)
 
 static struct fi_ops_eq util_eq_ops = {
 	.size = sizeof(struct fi_ops_eq),
-	.read = util_eq_read,
-	.readerr = util_eq_readerr,
-	.sread = util_eq_sread,
-	.write = util_eq_write,
-	.strerror = util_eq_strerror,
+	.read = ofi_eq_read,
+	.readerr = ofi_eq_readerr,
+	.sread = ofi_eq_sread,
+	.write = ofi_eq_write,
+	.strerror = ofi_eq_strerror,
 };
 
 static struct fi_ops util_eq_fi_ops = {
@@ -318,4 +363,3 @@ int ofi_eq_create(struct fid_fabric *fabric_fid, struct fi_eq_attr *attr,
 	*eq_fid = &eq->eq_fid;
 	return 0;
 }
-
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_main.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_main.c
index 06b5ffacb..69273ac3f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_main.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_main.c
@@ -192,7 +192,7 @@ int util_getinfo(const struct util_prov *util_prov, uint32_t version,
 		}
 
 		if (flags & FI_SOURCE) {
-			ret = ofi_get_addr((*info)->addr_format, flags,
+			ret = ofi_get_addr(&(*info)->addr_format, flags,
 					  node, service, &(*info)->src_addr,
 					  &(*info)->src_addrlen);
 			if (ret) {
@@ -204,7 +204,7 @@ int util_getinfo(const struct util_prov *util_prov, uint32_t version,
 		} else {
 			if (node || service) {
 				copy_dest = 0;
-				ret = ofi_get_addr((*info)->addr_format,
+				ret = ofi_get_addr(&(*info)->addr_format,
 						   flags, node, service,
 						   &(*info)->dest_addr,
 						   &(*info)->dest_addrlen);
@@ -225,6 +225,7 @@ int util_getinfo(const struct util_prov *util_prov, uint32_t version,
 					goto err;
 				}
 				(*info)->src_addrlen = hints->src_addrlen;
+				(*info)->addr_format = hints->addr_format;
 			}
 		}
 
@@ -236,6 +237,7 @@ int util_getinfo(const struct util_prov *util_prov, uint32_t version,
 				goto err;
 			}
 			(*info)->dest_addrlen = hints->dest_addrlen;
+			(*info)->addr_format = hints->addr_format;
 		}
 
 		if ((*info)->dest_addr && !(*info)->src_addr) {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_mem_monitor.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_mem_monitor.c
index 585fb36fd..d26b2ef4f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_mem_monitor.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_mem_monitor.c
@@ -78,13 +78,13 @@ int ofi_monitor_subscribe(struct ofi_notification_queue *nq,
 	dlist_init(&subscription->entry);
 
 	subscription->nq = nq;
-	subscription->addr = addr;
-	subscription->len = len;
+	subscription->iov.iov_base = addr;
+	subscription->iov.iov_len = len;
 	fastlock_acquire(&nq->lock);
 	nq->refcnt++;
 	fastlock_release(&nq->lock);
 
-	ret = nq->monitor->subscribe(nq->monitor, addr, len, subscription);
+	ret = nq->monitor->subscribe(nq->monitor, subscription);
 	if (OFI_UNLIKELY(ret)) {
 		FI_WARN(&core_prov, FI_LOG_MR,
 			"Failed (ret = %d) to monitor addr=%p len=%zu",
@@ -100,48 +100,20 @@ void ofi_monitor_unsubscribe(struct ofi_subscription *subscription)
 {
 	FI_DBG(&core_prov, FI_LOG_MR,
 	       "unsubscribing addr=%p len=%zu subscription=%p\n",
-	       subscription->addr, subscription->len, subscription);
+	       subscription->iov.iov_base, subscription->iov.iov_len, subscription);
 	subscription->nq->monitor->unsubscribe(subscription->nq->monitor,
-					       subscription->addr,
-					       subscription->len,
 					       subscription);
 	fastlock_acquire(&subscription->nq->lock);
-	dlist_init(&subscription->entry);
+	if (!dlist_empty(&subscription->entry))
+		dlist_remove_init(&subscription->entry);
 	subscription->nq->refcnt--;
 	fastlock_release(&subscription->nq->lock);
 }
 
-static void util_monitor_read_events(struct ofi_mem_monitor *monitor)
-{
-	struct ofi_subscription *subscription;
-
-	do {
-		subscription = monitor->get_event(monitor);
-		if (!subscription) {
-			FI_DBG(&core_prov, FI_LOG_MR,
-			       "no more events to be read\n");
-			break;
-		}
-
-		FI_DBG(&core_prov, FI_LOG_MR,
-		       "found event, context=%p, addr=%p, len=%zu nq=%p\n",
-		       subscription, subscription->addr,
-		       subscription->len, subscription->nq);
-
-		fastlock_acquire(&subscription->nq->lock);
-		if (dlist_empty(&subscription->entry))
-			dlist_insert_tail(&subscription->entry,
-					   &subscription->nq->list);
-		fastlock_release(&subscription->nq->lock);
-	} while (1);
-}
-
 struct ofi_subscription *ofi_monitor_get_event(struct ofi_notification_queue *nq)
 {
 	struct ofi_subscription *subscription;
 
-	util_monitor_read_events(nq->monitor);
-
 	fastlock_acquire(&nq->lock);
 	if (!dlist_empty(&nq->list)) {
 		dlist_pop_front(&nq->list, struct ofi_subscription,
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_mr_cache.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_mr_cache.c
index 8de4c6b73..84bc28df2 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_mr_cache.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_mr_cache.c
@@ -65,30 +65,28 @@ static int util_mr_find_overlap(void *a, void *b)
 static void util_mr_free_entry(struct ofi_mr_cache *cache,
 			       struct ofi_mr_entry *entry)
 {
-	FI_DBG(cache->domain->prov, FI_LOG_MR, "free %p (len: %zu)\n",
+	FI_DBG(cache->domain->prov, FI_LOG_MR, "free %p (len: %" PRIu64 ")\n",
 	       entry->iov.iov_base, entry->iov.iov_len);
 
 	assert(!entry->cached);
 	if (entry->subscribed) {
 		ofi_monitor_unsubscribe(&entry->subscription);
+		entry->subscribed = 0;
 	}
 	cache->delete_region(cache, entry);
 	assert((cache->cached_cnt != 0) &&
 	       (((ssize_t)cache->cached_size - (ssize_t)entry->iov.iov_len) >= 0));
 	cache->cached_cnt--;
 	cache->cached_size -= entry->iov.iov_len;
-	free(entry);
+	
+	util_buf_release(cache->entry_pool, entry);
 }
 
 static void util_mr_uncache_entry(struct ofi_mr_cache *cache,
 				  struct ofi_mr_entry *entry)
 {
-	RbtIterator iter;
-
 	assert(entry->cached);
-	iter = rbtFind(cache->mr_tree, &entry->iov);
-	assert(iter);
-	rbtErase(cache->mr_tree, iter);
+	cache->mr_storage.erase(&cache->mr_storage, entry);
 	entry->cached = 0;
 }
 
@@ -121,7 +119,7 @@ bool ofi_mr_cache_flush(struct ofi_mr_cache *cache)
 	dlist_pop_front(&cache->lru_list, struct ofi_mr_entry,
 			entry, lru_entry);
 	dlist_init(&entry->lru_entry);
-	FI_DBG(cache->domain->prov, FI_LOG_MR, "flush %p (len: %zu)\n",
+	FI_DBG(cache->domain->prov, FI_LOG_MR, "flush %p (len: %" PRIu64 ")\n",
 	       entry->iov.iov_base, entry->iov.iov_len);
 
 	util_mr_uncache_entry(cache, entry);
@@ -131,7 +129,7 @@ bool ofi_mr_cache_flush(struct ofi_mr_cache *cache)
 
 void ofi_mr_cache_delete(struct ofi_mr_cache *cache, struct ofi_mr_entry *entry)
 {
-	FI_DBG(cache->domain->prov, FI_LOG_MR, "delete %p (len: %zu)\n",
+	FI_DBG(cache->domain->prov, FI_LOG_MR, "delete %p (len: %" PRIu64 ")\n",
 	       entry->iov.iov_base, entry->iov.iov_len);
 	cache->delete_cnt++;
 
@@ -152,13 +150,13 @@ util_mr_cache_create(struct ofi_mr_cache *cache, const struct iovec *iov,
 {
 	int ret;
 
-	FI_DBG(cache->domain->prov, FI_LOG_MR, "create %p (len: %zu)\n",
+	FI_DBG(cache->domain->prov, FI_LOG_MR, "create %p (len: %" PRIu64 ")\n",
 	       iov->iov_base, iov->iov_len);
 
 	util_mr_cache_process_events(cache);
 
-	*entry = calloc(1, sizeof(**entry) + cache->entry_data_size);
-	if (!*entry)
+	*entry = util_buf_alloc(cache->entry_pool);
+	if (OFI_UNLIKELY(!*entry))
 		return -FI_ENOMEM;
 
 	(*entry)->iov = *iov;
@@ -166,8 +164,14 @@ util_mr_cache_create(struct ofi_mr_cache *cache, const struct iovec *iov,
 
 	ret = cache->add_region(cache, *entry);
 	if (ret) {
-		free(*entry);
-		return ret;
+		while (ret && ofi_mr_cache_flush(cache)) {
+			ret = cache->add_region(cache, *entry);
+		}
+		if (ret) {
+			assert(!ofi_mr_cache_flush(cache));
+			util_buf_release(cache->entry_pool, *entry);
+			return ret;
+		}
 	}
 
 	cache->cached_size += iov->iov_len;
@@ -175,17 +179,18 @@ util_mr_cache_create(struct ofi_mr_cache *cache, const struct iovec *iov,
 	    (cache->cached_size > cache->max_cached_size)) {
 		(*entry)->cached = 0;
 	} else {
+		if (cache->mr_storage.insert(&cache->mr_storage,
+					     &(*entry)->iov, *entry)) {
+			ret = -FI_ENOMEM;
+			goto err;
+		}
+		(*entry)->cached = 1;
+
 		ret = ofi_monitor_subscribe(&cache->nq, iov->iov_base, iov->iov_len,
 					    &(*entry)->subscription);
 		if (ret)
 			goto err;
 		(*entry)->subscribed = 1;
-
-		if (rbtInsert(cache->mr_tree, &(*entry)->iov, *entry)) {
-			ret = -FI_ENOMEM;
-			goto err;
-		}
-		(*entry)->cached = 1;
 	}
 
 	return 0;
@@ -197,42 +202,40 @@ err:
 
 static int
 util_mr_cache_merge(struct ofi_mr_cache *cache, const struct fi_mr_attr *attr,
-		    RbtIterator iter, struct ofi_mr_entry **entry)
+		    struct ofi_mr_entry *old_entry, struct ofi_mr_entry **entry)
 {
 	struct iovec iov, *old_iov;
-	struct ofi_mr_entry *old_entry;
 
 	iov = *attr->mr_iov;
 	do {
-		rbtKeyValue(cache->mr_tree, iter, (void **) &old_iov,
-			    (void **) &old_entry);
-
 		FI_DBG(cache->domain->prov, FI_LOG_MR,
-		       "merging %p (len: %zu) with %p (len: %zu)\n",
+		       "merging %p (len: %" PRIu64 ") with %p (len: %" PRIu64 ")\n",
 		       iov.iov_base, iov.iov_len,
 		       old_entry->iov.iov_base, old_entry->iov.iov_len);
+		old_iov = &old_entry->iov;
 
 		iov.iov_len = ((uintptr_t)
 			MAX(ofi_iov_end(&iov), ofi_iov_end(old_iov))) -
 			((uintptr_t) MIN(iov.iov_base, old_iov->iov_base));
 		iov.iov_base = MIN(iov.iov_base, old_iov->iov_base);
-		FI_DBG(cache->domain->prov, FI_LOG_MR, "merged %p (len: %zu)\n",
+		FI_DBG(cache->domain->prov, FI_LOG_MR, "merged %p (len: %" PRIu64 ")\n",
 		       iov.iov_base, iov.iov_len);
 
-		rbtErase(cache->mr_tree, iter);
+		if (old_entry->subscribed) {
+			/* old entry will be removed as soon as `use_cnt == 0`.
+			 * unsubscribe from the entry */
+			ofi_monitor_unsubscribe(&old_entry->subscription);
+			old_entry->subscribed = 0;
+		}
+		cache->mr_storage.erase(&cache->mr_storage, old_entry);
 		old_entry->cached = 0;
 
 		if (old_entry->use_cnt == 0) {
 			dlist_remove_init(&old_entry->lru_entry);
 			util_mr_free_entry(cache, old_entry); 
-		} else if (old_entry->subscribed) {
-			/* old entry will be removed as soon as `use_cnt == 0`.
-			 * unsubscribe from the entry */
-			ofi_monitor_unsubscribe(&old_entry->subscription);
-			old_entry->subscribed = 0;
 		}
 
-	} while ((iter = rbtFind(cache->mr_tree, &iov)));
+	} while ((old_entry = cache->mr_storage.find(&cache->mr_storage, &iov)));
 
 	return util_mr_cache_create(cache, &iov, attr->access, entry);
 }
@@ -240,13 +243,10 @@ util_mr_cache_merge(struct ofi_mr_cache *cache, const struct fi_mr_attr *attr,
 int ofi_mr_cache_search(struct ofi_mr_cache *cache, const struct fi_mr_attr *attr,
 			struct ofi_mr_entry **entry)
 {
-	RbtIterator iter;
-	struct iovec *iov;
-
 	util_mr_cache_process_events(cache);
 
 	assert(attr->iov_count == 1);
-	FI_DBG(cache->domain->prov, FI_LOG_MR, "search %p (len: %zu)\n",
+	FI_DBG(cache->domain->prov, FI_LOG_MR, "search %p (len: %" PRIu64 ")\n",
 	       attr->mr_iov->iov_base, attr->mr_iov->iov_len);
 	cache->search_cnt++;
 
@@ -255,17 +255,15 @@ int ofi_mr_cache_search(struct ofi_mr_cache *cache, const struct fi_mr_attr *att
 	       ofi_mr_cache_flush(cache))
 		;
 
-	iter = rbtFind(cache->mr_tree, (void *) attr->mr_iov);
-	if (!iter) {
+	*entry = cache->mr_storage.find(&cache->mr_storage, attr->mr_iov);
+	if (!*entry) {
 		return util_mr_cache_create(cache, attr->mr_iov,
 					    attr->access, entry);
 	}
 
-	rbtKeyValue(cache->mr_tree, iter, (void **) &iov, (void **) entry);
-
 	/* This branch is always false if the merging entries wasn't requested */
-	if (!ofi_iov_within(attr->mr_iov, iov))
-		return util_mr_cache_merge(cache, attr, iter, entry);
+	if (!ofi_iov_within(attr->mr_iov, &(*entry)->iov))
+		return util_mr_cache_merge(cache, attr, *entry, entry);
 
 	cache->hit_cnt++;
 	if ((*entry)->use_cnt++ == 0)
@@ -292,23 +290,99 @@ void ofi_mr_cache_cleanup(struct ofi_mr_cache *cache)
 		dlist_remove_init(&entry->lru_entry);
 		util_mr_free_entry(cache, entry);
 	}
-	rbtDelete(cache->mr_tree);
+	cache->mr_storage.destroy(&cache->mr_storage);
 	ofi_monitor_del_queue(&cache->nq);
 	ofi_atomic_dec32(&cache->domain->ref);
+	util_buf_pool_destroy(cache->entry_pool);
 	assert(cache->cached_cnt == 0);
 	assert(cache->cached_size == 0);
 }
 
-int ofi_mr_cache_init(struct util_domain *domain, struct ofi_mem_monitor *monitor,
+static void ofi_mr_rbt_storage_destroy(struct ofi_mr_storage *storage)
+{
+	rbtDelete((RbtHandle)storage->storage);
+}
+
+static struct ofi_mr_entry *ofi_mr_rbt_storage_find(struct ofi_mr_storage *storage,
+						    const struct iovec *key)
+{
+	struct ofi_mr_entry *entry;
+	RbtIterator iter = rbtFind((RbtHandle)storage->storage, (void *)key);
+	if (OFI_UNLIKELY(!iter))
+		return iter;
+
+	rbtKeyValue(storage->storage, iter, (void *)&key, (void *)&entry);
+	return entry;
+}
+
+static int ofi_mr_rbt_storage_insert(struct ofi_mr_storage *storage,
+				     struct iovec *key,
+				     struct ofi_mr_entry *entry)
+{
+	int ret = rbtInsert((RbtHandle)storage->storage,
+			    (void *)&entry->iov, (void *)entry);
+	if (ret != RBT_STATUS_OK) {
+		switch (ret) {
+		case RBT_STATUS_MEM_EXHAUSTED:
+			return -FI_ENOMEM;
+		case RBT_STATUS_DUPLICATE_KEY:
+			return -FI_EALREADY;
+		default:
+			return -FI_EAVAIL;
+		}
+	}
+	return ret;
+}
+
+static int ofi_mr_rbt_storage_erase(struct ofi_mr_storage *storage,
+				    struct ofi_mr_entry *entry)
+{
+	RbtIterator iter = rbtFind(storage->storage, &entry->iov);
+	assert(iter);
+	return (rbtErase((RbtHandle)storage->storage, iter) != RBT_STATUS_OK) ?
+	       -FI_EAVAIL : 0;
+}
+
+static int ofi_mr_cache_init_rbt_storage(struct ofi_mr_cache *cache)
+{
+	cache->mr_storage.storage = rbtNew(cache->merge_regions ?
+					   util_mr_find_overlap :
+					   util_mr_find_within);
+	if (!cache->mr_storage.storage)
+		return -FI_ENOMEM;
+	cache->mr_storage.destroy = ofi_mr_rbt_storage_destroy;
+	cache->mr_storage.find = ofi_mr_rbt_storage_find;
+	cache->mr_storage.insert = ofi_mr_rbt_storage_insert;
+	cache->mr_storage.erase = ofi_mr_rbt_storage_erase;
+	return 0;
+}
+
+static int ofi_mr_cache_init_storage(struct ofi_mr_cache *cache)
+{
+	switch (cache->mr_storage.type) {
+	case OFI_MR_STORAGE_DEFAULT:
+	case OFI_MR_STORAGE_RBT:
+		return ofi_mr_cache_init_rbt_storage(cache);
+	case OFI_MR_STORAGE_USER:
+		if (!(cache->mr_storage.storage &&
+		      cache->mr_storage.destroy && cache->mr_storage.find &&
+		      cache->mr_storage.insert && cache->mr_storage.erase))
+			return -FI_EINVAL;
+		break;
+	}
+	return 0;
+}
+
+int ofi_mr_cache_init(struct util_domain *domain,
+		      struct ofi_mem_monitor *monitor,
 		      struct ofi_mr_cache *cache)
 {
+	int ret;
 	assert(cache->add_region && cache->delete_region);
 
-	cache->mr_tree = rbtNew(cache->merge_regions ?
-				util_mr_find_overlap :
-				util_mr_find_within);
-	if (!cache->mr_tree)
-		return -FI_ENOMEM;
+	ret = ofi_mr_cache_init_storage(cache);
+	if (ret)
+		return ret;
 
 	cache->domain = domain;
 	ofi_atomic_inc32(&domain->ref);
@@ -323,5 +397,17 @@ int ofi_mr_cache_init(struct util_domain *domain, struct ofi_mem_monitor *monito
 	cache->hit_cnt = 0;
 	ofi_monitor_add_queue(monitor, &cache->nq);
 
+	ret = util_buf_pool_create(&cache->entry_pool,
+				   sizeof(struct ofi_mr_entry) +
+				   cache->entry_data_size,
+				   16, 0, cache->max_cached_cnt);
+	if (ret)
+		goto err;
+
 	return 0;
+err:
+	ofi_atomic_dec32(&cache->domain->ref);
+	ofi_monitor_del_queue(&cache->nq);
+	cache->mr_storage.destroy(&cache->mr_storage);
+	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_ns.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_ns.c
index f78807447..eb4edd81d 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_ns.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_ns.c
@@ -168,8 +168,10 @@ static int util_ns_process_cmd(struct util_ns *ns, struct util_ns_cmd *cmd,
 	case OFI_UTIL_NS_DEL:
 		io_len = ns->name_len + ns->service_len;
 		io_buf = calloc(io_len, 1);
-		if (!io_buf)
-			return -FI_ENOMEM;
+		if (!io_buf) {
+			ret = -FI_ENOMEM;
+			goto out;
+		}
 
 		ret = ofi_recvall_socket(sock, io_buf, io_len);
 		if (!ret) {
@@ -185,8 +187,10 @@ static int util_ns_process_cmd(struct util_ns *ns, struct util_ns_cmd *cmd,
 	case OFI_UTIL_NS_QUERY:
 		io_len = ns->service_len;
 		io_buf = calloc(cmd_len + ns->service_len + ns->name_len, 1);
-		if (!io_buf)
-			return -FI_ENOMEM;
+		if (!io_buf) {
+			ret = -FI_ENOMEM;
+			goto out;
+		}
 
 		memcpy(io_buf, cmd, cmd_len);
 		cmd = io_buf;
@@ -212,10 +216,15 @@ static int util_ns_process_cmd(struct util_ns *ns, struct util_ns_cmd *cmd,
 
 	default:
 		assert(0);
-		return -FI_ENODATA;
+		ret = -FI_ENODATA;
+		goto out;
 	}
 
 	free(io_buf);
+
+out:
+	FI_INFO(&core_prov, FI_LOG_CORE,
+		"Name server processed command - returned %d (%s)\n", ret, fi_strerror(-ret));
 	return ret;
 }
 
@@ -356,8 +365,11 @@ int ofi_ns_add_local_name(struct util_ns *ns, void *service, void *name)
 		.op = OFI_UTIL_NS_ADD,
 	};
 
-	if (!ns->is_initialized)
+	if (!ns->is_initialized) {
+		FI_WARN(&core_prov, FI_LOG_CORE,
+			"Cannot add local name - name server uninitialized\n");
 		return -FI_EINVAL;
+	}
 
 	write_buf = calloc(cmd_len + ns->service_len + ns->name_len, 1);
 	if (!write_buf) {
@@ -539,6 +551,7 @@ err3:
 err2:
 	rbtDelete(ns->map);
 err1:
+	FI_WARN(&core_prov, FI_LOG_CORE, "Error starting name server\n");
 	ofi_atomic_dec32(&ns->ref);
 	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_shm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_shm.c
index 75882ad9e..161277cbf 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_shm.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_shm.c
@@ -64,7 +64,7 @@ int smr_create(const struct fi_provider *prov, struct smr_map *map,
 	inject_pool_offset = resp_queue_offset + sizeof(struct smr_resp_queue) +
 			sizeof(struct smr_resp) * attr->tx_count;
 	peer_addr_offset = inject_pool_offset + sizeof(struct smr_inject_pool) +
-			sizeof(struct smr_inject_buf) * attr->rx_count;
+			sizeof(struct smr_inject_pool_entry) * attr->rx_count;
 	name_offset = peer_addr_offset + sizeof(struct smr_addr) * SMR_MAX_PEERS;
 	total_size = name_offset + strlen(attr->name) + 1;
 	total_size = roundup_power_of_two(total_size);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_wait.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_wait.c
index 7497e403c..088dc160c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_wait.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/util/src/util_wait.c
@@ -181,8 +181,8 @@ out:
 	return ret;
 }
 
-int ofi_wait_fd_add(struct util_wait *wait, int fd, ofi_wait_fd_try_func try,
-		    void *arg, void *context)
+int ofi_wait_fd_add(struct util_wait *wait, int fd, uint32_t events,
+		    ofi_wait_fd_try_func try, void *arg, void *context)
 {
 	struct ofi_wait_fd_entry *fd_entry;
 	struct dlist_entry *entry;
@@ -201,7 +201,7 @@ int ofi_wait_fd_add(struct util_wait *wait, int fd, ofi_wait_fd_try_func try,
 		goto out;
 	}
 
-	ret = fi_epoll_add(wait_fd->epoll_fd, fd, context);
+	ret = fi_epoll_add(wait_fd->epoll_fd, fd, events, context);
 	if (ret) {
 		FI_WARN(wait->prov, FI_LOG_FABRIC, "Unable to add fd to epoll\n");
 		goto out;
@@ -311,6 +311,7 @@ static int util_wait_fd_control(struct fid *fid, int command, void *arg)
 static int util_wait_fd_close(struct fid *fid)
 {
 	struct util_wait_fd *wait;
+	struct ofi_wait_fd_entry *fd_entry;
 	int ret;
 
 	wait = container_of(fid, struct util_wait_fd, util_wait.wait_fid.fid);
@@ -318,12 +319,19 @@ static int util_wait_fd_close(struct fid *fid)
 	if (ret)
 		return ret;
 
-	assert(dlist_empty(&wait->fd_list));
-	fastlock_destroy(&wait->lock);
+	fastlock_acquire(&wait->lock);
+	while (!dlist_empty(&wait->fd_list)) {
+		dlist_pop_front(&wait->fd_list, struct ofi_wait_fd_entry,
+				fd_entry, entry);
+		fi_epoll_del(wait->epoll_fd, fd_entry->fd);
+		free(fd_entry);
+	}
+	fastlock_release(&wait->lock);
 
 	fi_epoll_del(wait->epoll_fd, wait->signal.fd[FI_READ_FD]);
 	fd_signal_free(&wait->signal);
 	fi_epoll_close(wait->epoll_fd);
+	fastlock_destroy(&wait->lock);
 	free(wait);
 	return 0;
 }
@@ -393,7 +401,7 @@ int ofi_wait_fd_open(struct fid_fabric *fabric_fid, struct fi_wait_attr *attr,
 		goto err3;
 
 	ret = fi_epoll_add(wait->epoll_fd, wait->signal.fd[FI_READ_FD],
-			   &wait->util_wait.wait_fid.fid);
+	                   FI_EPOLL_IN, &wait->util_wait.wait_fid.fid);
 	if (ret)
 		goto err4;
 
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/Makefile.include b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/Makefile.include
index bdef9bbf2..e133d129a 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/Makefile.include
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/Makefile.include
@@ -3,33 +3,19 @@ _verbs_files =							\
 	prov/verbs/src/fi_verbs.h				\
 	prov/verbs/src/fi_verbs.c				\
 	prov/verbs/src/verbs_cm.c				\
+	prov/verbs/src/verbs_cm_xrc.c				\
 	prov/verbs/src/verbs_cq.c				\
-	prov/verbs/src/verbs_srq.c				\
 	prov/verbs/src/verbs_domain.c				\
+	prov/verbs/src/verbs_domain_xrc.c			\
 	prov/verbs/src/verbs_mr.c				\
 	prov/verbs/src/verbs_eq.c				\
 	prov/verbs/src/verbs_info.c				\
-	prov/verbs/src/verbs_msg_ep.c				\
-	prov/verbs/src/ep_rdm/verbs_av_ep_rdm.c			\
-	prov/verbs/src/ep_rdm/verbs_cq_ep_rdm.c			\
-	prov/verbs/src/ep_rdm/verbs_ep_rdm.c			\
-	prov/verbs/src/ep_rdm/verbs_queuing.h			\
-	prov/verbs/src/ep_rdm/verbs_rdm_cm.c			\
-	prov/verbs/src/ep_rdm/verbs_rdm_cntr.c			\
-	prov/verbs/src/ep_rdm/verbs_rdm_msg.c			\
-	prov/verbs/src/ep_rdm/verbs_rdm_rma.c			\
-	prov/verbs/src/ep_rdm/verbs_rdm.h			\
-	prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm_states.h	\
-	prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm_states.c	\
-	prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm.c		\
-	prov/verbs/src/ep_rdm/verbs_utils.c			\
-	prov/verbs/src/ep_rdm/verbs_utils.h			\
-	prov/verbs/src/ep_dgram/verbs_dgram.h			\
-	prov/verbs/src/ep_dgram/verbs_dgram_ep.c		\
-	prov/verbs/src/ep_dgram/verbs_dgram_ep_msg.c		\
-	prov/verbs/src/ep_dgram/verbs_dgram_cq.c		\
-	prov/verbs/src/ep_dgram/verbs_dgram_cntr.c		\
-	prov/verbs/src/ep_dgram/verbs_dgram_av.c
+	prov/verbs/src/verbs_ep.c				\
+	prov/verbs/src/verbs_msg.c				\
+	prov/verbs/src/verbs_rma.c				\
+	prov/verbs/src/verbs_dgram_ep_msg.c			\
+	prov/verbs/src/verbs_dgram_av.c				\
+	prov/verbs/src/ofi_verbs_priv.h
 
 if HAVE_VERBS_DL
 pkglib_LTLIBRARIES += libverbs-fi.la
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/configure.m4 b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/configure.m4
index 326688dfe..2ae8f8f69 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/configure.m4
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/configure.m4
@@ -65,6 +65,16 @@ AC_DEFUN([FI_VERBS_CONFIGURE],[
 			   [Experimental verbs features support])],
 		[])
 
+	#See if we have XRC support
+	VERBS_HAVE_XRC=0
+	AS_IF([test $verbs_ibverbs_happy -eq 1],[
+		AC_CHECK_DECL([IBV_QPT_XRC_SEND],
+			[VERBS_HAVE_XRC=1],[],
+			[#include <infiniband/verbs.h>])
+		])
+	AC_DEFINE_UNQUOTED([VERBS_HAVE_XRC],[$VERBS_HAVE_XRC],
+		[Whether infiniband/verbs.h has XRC support or not])
+
 	# Technically, verbs_ibverbs_CPPFLAGS and
 	# verbs_rdmacm_CPPFLAGS could be different, but it is highly
 	# unlikely that they ever will be.  So only list
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram.h
deleted file mode 100644
index 007fcd5fa..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram.h
+++ /dev/null
@@ -1,280 +0,0 @@
-/*
- * Copyright (c) 2017 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#ifndef _OFI_VERBS_DGRAM_H_
-#define _OFI_VERBS_DGRAM_H_
-
-#if HAVE_CONFIG_H
-#  include <config.h>
-#endif /* HAVE_CONFIG_H */
-
-#include "../fi_verbs.h"
-#include <inttypes.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif /* __cplusplus */
-
-/* Verbs-DGRAM Pool functionality */
-struct fi_ibv_dgram_buf_pool;
-
-typedef void(*fi_ibv_dgram_pool_entry_cancel_hndlr) (struct fi_ibv_dgram_buf_pool *);
-
-struct fi_ibv_dgram_buf_pool {
-	struct util_buf_pool	*pool;
-	struct dlist_entry	buf_list;
-
-	fi_ibv_dgram_pool_entry_cancel_hndlr cancel_hndlr;
-};
-
-typedef int(*handle_wr_cb)(struct util_cq *util_cq,
-			   struct util_cntr *util_cntr,
-			   struct ibv_wc *wc);
-
-struct fi_ibv_dgram_wr_entry_hdr {
-	struct dlist_entry		entry;
-	void				*desc;
-	struct fi_ibv_dgram_ep		*ep;
-	int32_t				comp_unsignaled_cnt;
-	void				*context;
-	uint64_t			flags;
-	handle_wr_cb			suc_cb;
-	handle_wr_cb			err_cb;
-};
-
-struct fi_ibv_dgram_pool_attr {
-	size_t	count;
-	size_t	size;
-	void	*pool_ctx;
-
-	fi_ibv_dgram_pool_entry_cancel_hndlr cancel_hndlr;
-
-	util_buf_region_alloc_hndlr	alloc_hndlr;
-	util_buf_region_free_hndlr	free_hndlr;
-};
-
-/*
- * The Global Routing Header (GRH) of the incoming message
- * will be placed in the first 40 bytes of the buffer(s)
- * in the scatter list.
- * @note If no GRH is present in the incoming message,
- *       then the first bytes will be undefined.
- * This means that in all cases, the actual data of the
- * incoming message will start at an offset of 40 bytes
- * into the buffer(s) in the scatter list.
- */
-
-struct fi_ibv_dgram_wr_entry {
-	struct fi_ibv_dgram_wr_entry_hdr	hdr;
-	char					grh_buf[];
-};
-
-#define VERBS_DGRAM_GRH_LENGTH	40
-#define VERBS_DGRAM_WR_ENTRY_SIZE					\
-	(sizeof(struct fi_ibv_dgram_wr_entry) + VERBS_DGRAM_GRH_LENGTH)
-
-static inline struct fi_ibv_dgram_wr_entry_hdr*
-fi_ibv_dgram_wr_entry_get(struct fi_ibv_dgram_buf_pool *pool)
-{
-	struct fi_ibv_dgram_wr_entry_hdr *buf;
-	void *mr = NULL;
-
-	buf = util_buf_alloc_ex(pool->pool, &mr);
-	if (OFI_UNLIKELY(!buf))
-		return NULL;
-	buf->desc = fi_mr_desc((struct fid_mr *)mr);
-	dlist_insert_tail(&buf->entry, &pool->buf_list);
-
-	return buf;
-}
-
-static inline void
-fi_ibv_dgram_wr_entry_release(struct fi_ibv_dgram_buf_pool *pool,
-			      struct fi_ibv_dgram_wr_entry_hdr *buf)
-{
-	dlist_remove(&buf->entry);
-	util_buf_release(pool->pool, buf);
-}
-
-static inline void
-fi_ibv_dgram_mr_buf_close(void *pool_ctx, void *context)
-{
-	/* We would get a (fid_mr *) in context, but
-	 * it is safe to cast it into (fid *) */
-	fi_close((struct fid *)context);
-}
-
-static inline int
-fi_ibv_dgram_mr_buf_reg(void *pool_ctx, void *addr,
-			size_t len, void **context)
-{
-	int ret;
-	struct fid_mr *mr;
-	struct fid_domain *domain = (struct fid_domain *)pool_ctx;
-
-	ret = fi_mr_reg(domain, addr, len, FI_SEND | FI_RECV,
-			0, 0, 0, &mr, NULL);
-	*context = mr;
-	return ret;
-}
-
-static inline void
-fi_ibv_dgram_pool_wr_entry_cancel(struct fi_ibv_dgram_buf_pool *pool)
-{
-	struct dlist_entry *entry;
-	struct fi_ibv_dgram_wr_entry_hdr *buf;
-	entry = pool->buf_list.next;
-	buf = container_of(entry, struct fi_ibv_dgram_wr_entry_hdr,
-			   entry);
-	fi_ibv_dgram_wr_entry_release(pool, buf);
-}
-
-static inline void
-fi_ibv_dgram_pool_destroy(struct fi_ibv_dgram_buf_pool *pool)
-{
-	if (pool->cancel_hndlr) {
-		while (!dlist_empty(&pool->buf_list))
-			pool->cancel_hndlr(pool);
-	}
-
-	util_buf_pool_destroy(pool->pool);
-}
-
-static inline int
-fi_ibv_dgram_pool_create(struct fi_ibv_dgram_pool_attr *attr,
-			 struct fi_ibv_dgram_buf_pool *pool)
-{
-	int ret = util_buf_pool_create_ex(&pool->pool, attr->size,
-					  16, 0, attr->count,
-					  attr->alloc_hndlr,
-					  attr->free_hndlr,
-					  attr->pool_ctx);
-	if (ret) {
-		VERBS_WARN(FI_LOG_EP_DATA,
-			   "Unable to create buf pool\n");
-		return ret;
-	}
-	pool->cancel_hndlr = attr->cancel_hndlr;
-	dlist_init(&pool->buf_list);
-
-	return FI_SUCCESS;
-}
-/* ~Verbs UD Pool functionality */
-
-struct fi_ibv_dgram_cq {
-	struct util_cq	util_cq;
-	struct ibv_cq	*ibv_cq;
-};
-
-struct fi_ibv_dgram_av {
-	struct util_av	util_av;
-};
-
-struct fi_ibv_dgram_eq {
-	struct util_eq	util_eq;
-};
-
-struct fi_ibv_dgram_cntr {
-	struct util_cntr	util_cntr;
-};
-
-struct fi_ibv_dgram_av_entry {
-	struct ofi_ib_ud_ep_name	*addr;
-	struct ibv_ah			*ah;
-};
-
-struct fi_ibv_dgram_ep {
-	struct util_ep			util_ep;
-	struct ibv_qp			*ibv_qp;
-	struct fi_info			*info;
-	struct fi_ibv_dgram_av		*av;
-	struct fi_ibv_domain		*domain;
-	struct fi_ibv_dgram_buf_pool	grh_pool;
-	struct ofi_ib_ud_ep_name	ep_name;
-	int				service;
-	int				ep_flags;
-	int32_t				max_unsignaled_send_cnt;
-	ofi_atomic32_t			unsignaled_send_cnt;
-};
-
-extern struct fi_ops_msg fi_ibv_dgram_msg_ops;
-
-static inline struct fi_ibv_dgram_av_entry*
-fi_ibv_dgram_av_lookup_av_entry(struct fi_ibv_dgram_av *av, int index)
-{
-	assert((index >= 0) && ((size_t)index < av->util_av.count));
-	return ofi_av_get_addr(&av->util_av, index);
-}
-
-static inline
-int fi_ibv_dgram_is_completion(uint64_t cq_flags, uint64_t op_flags)
-{
-	if ((op_flags & FI_COMPLETION) ||
-	    (op_flags & (FI_INJECT_COMPLETE	|
-			 FI_TRANSMIT_COMPLETE	|
-			 FI_DELIVERY_COMPLETE)))
-		return 1;
-	else if (op_flags & FI_INJECT)
-		return 0;
-	else if (!(cq_flags & FI_SELECTIVE_COMPLETION))
-		return 1;
-	return 0;
-}
-
-int fi_ibv_dgram_rx_cq_comp(struct util_cq *util_cq,
-			    struct util_cntr *util_cntr,
-			    struct ibv_wc *wc);
-int fi_ibv_dgram_tx_cq_comp(struct util_cq *util_cq,
-			    struct util_cntr *util_cntr,
-			    struct ibv_wc *wc);
-int fi_ibv_dgram_tx_cq_report_error(struct util_cq *util_cq,
-				    struct util_cntr *util_cntr,
-				    struct ibv_wc *wc);
-int fi_ibv_dgram_rx_cq_report_error(struct util_cq *util_cq,
-				    struct util_cntr *util_cntr,
-				    struct ibv_wc *wc);
-int fi_ibv_dgram_tx_cq_no_action(struct util_cq *util_cq,
-				 struct util_cntr *util_cntr,
-				 struct ibv_wc *wc);
-int fi_ibv_dgram_rx_cq_no_action(struct util_cq *util_cq,
-				 struct util_cntr *util_cntr,
-				 struct ibv_wc *wc);
-
-void fi_ibv_dgram_recv_cq_progress(struct util_ep *util_ep);
-void fi_ibv_dgram_send_cq_progress(struct util_ep *util_ep);
-void fi_ibv_dgram_send_recv_cq_progress(struct util_ep *util_ep);
-
-#ifdef __cplusplus
-}
-#endif /* __cplusplus */
-
-#endif /* _OFI_VERBS_UD_H_ */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_av.c
deleted file mode 100644
index 30c0becba..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_av.c
+++ /dev/null
@@ -1,344 +0,0 @@
-/*
- * Copyright (c) 2017 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "verbs_dgram.h"
-
-const size_t fi_ibv_dgram_av_entry_size = sizeof(struct fi_ibv_dgram_av_entry);
-
-/* TODO: find more deterministic hash function */
-static inline int
-fi_ibv_dgram_av_slot(struct util_av *av, const struct ofi_ib_ud_ep_name *ep_name)
-{
-	return (ep_name->gid.global.subnet_prefix + ep_name->lid + ep_name->qpn)
-		% av->hash.slots;
-}
-
-static inline int fi_ibv_dgram_av_is_addr_valid(struct fi_ibv_dgram_av *av,
-						const void *addr)
-{
-	const struct ofi_ib_ud_ep_name *check_name = addr;
-	return (check_name->lid > 0);
-}
-
-static inline
-int fi_ibv_dgram_verify_av_insert(struct util_av *av, uint64_t flags)
-{
-	if ((av->flags & FI_EVENT) && !av->eq) {
-		VERBS_WARN(FI_LOG_AV, "No EQ bound to AV\n");
-		return -FI_ENOEQ;
-	}
-
-	if (flags & ~(FI_MORE)) {
-		VERBS_WARN(FI_LOG_AV, "Unsupported flags\n");
-		return -FI_ENOEQ;
-	}
-
-	return FI_SUCCESS;
-}
-
-static int fi_ibv_dgram_av_insert_addr(struct fi_ibv_dgram_av *av,
-				       const void *addr,
-				       fi_addr_t *fi_addr,
-				       void *context)
-{
-	int ret, index = -1;
-	struct fi_ibv_domain *domain;
-	struct ofi_ib_ud_ep_name *ep_name;
-	struct ibv_ah *ah;
-
-	domain = container_of(&av->util_av.domain->domain_fid,
-			      struct fi_ibv_domain,
-			      util_domain.domain_fid);
-	if (!domain) {
-		ret = -FI_EINVAL;
-		goto fn1;
-	}
-
-	if (fi_ibv_dgram_av_is_addr_valid(av, addr)) {
-		struct fi_ibv_dgram_av_entry av_entry;
-		struct ibv_ah_attr ah_attr = {
-			.is_global     = 0,
-			.dlid          = ((struct ofi_ib_ud_ep_name *)addr)->lid,
-			.sl            = ((struct ofi_ib_ud_ep_name *)addr)->sl,
-			.src_path_bits = 0,
-			.port_num      = 1,
-		};
-		ep_name = calloc(1, sizeof(*ep_name));
-		if (OFI_UNLIKELY(!ep_name)) {
-			ret = -FI_ENOMEM;
-			goto fn1;
-		}
-		memcpy(ep_name, addr, sizeof(*ep_name));
-		if (ep_name->gid.global.interface_id) {
-			ah_attr.is_global = 1;
-			ah_attr.grh.hop_limit = 64;
-			ah_attr.grh.dgid = ep_name->gid;
-			ah_attr.grh.sgid_index = 0;
-		}
-		ah = ibv_create_ah(domain->pd, &ah_attr);
-		if (!ah) {
-			ret = -errno;
-			VERBS_WARN(FI_LOG_AV, "Unable to create "
-				   "Address Handle, errno - %d\n", errno);
-			goto fn2;
-		}
-
-		av_entry.ah = ah;
-		av_entry.addr = ep_name;
-
-		ret = ofi_av_insert_addr(&av->util_av, &av_entry,
-					 fi_ibv_dgram_av_slot(&av->util_av, ep_name),
-					 &index);
-		if (ret)
-			goto fn3;
-		if (fi_addr)
-			*fi_addr = index;
-	} else {
-		ret = -FI_EADDRNOTAVAIL;
-		VERBS_WARN(FI_LOG_AV, "Invalid address\n");
-		goto fn1;
-	}
-
-	return ret;
-fn3:
-	ibv_destroy_ah(ah);
-fn2:
-	free(ep_name);
-fn1:
-	if (fi_addr)
-		*fi_addr = FI_ADDR_NOTAVAIL;
-	return ret;
-}
-
-static int fi_ibv_dgram_av_insert(struct fid_av *av_fid, const void *addr,
-				  size_t count, fi_addr_t *fi_addr,
-				  uint64_t flags, void *context)
-{
-	struct fi_ibv_dgram_av *av;
-	int ret, success_cnt = 0;
-	size_t i;
-
-	assert(av_fid->fid.fclass == FI_CLASS_AV);
-	if (av_fid->fid.fclass != FI_CLASS_AV)
-		return -FI_EINVAL;
-
-	av = container_of(av_fid, struct fi_ibv_dgram_av, util_av.av_fid);
-	if (!av)
-		return -FI_EINVAL;
-	ret = fi_ibv_dgram_verify_av_insert(&av->util_av, flags);
-	if (ret)
-		return ret;
-
-	VERBS_DBG(FI_LOG_AV, "Inserting %"PRIu64" addresses\n", count);
-	for (i = 0; i < count; i++) {
-		ret = fi_ibv_dgram_av_insert_addr(
-				av, (struct ofi_ib_ud_ep_name *)addr + i,
-				fi_addr ? &fi_addr[i] : NULL, context);
-		if (!ret)
-			success_cnt++;
-		else if (av->util_av.eq)
-			ofi_av_write_event(&av->util_av, i, -ret, context);
-	}
-
-	VERBS_DBG(FI_LOG_AV, "%"PRIu64" addresses successful\n", count);
-	if (av->util_av.eq) {
-		ofi_av_write_event(&av->util_av, success_cnt, 0, context);
-		ret = 0;
-	} else {
-		ret = success_cnt;
-	}
-	return ret;
-}
-
-static int fi_ibv_dgram_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr,
-				  size_t count, uint64_t flags)
-{
-	struct fi_ibv_dgram_av *av;
-	int ret, slot, i, index;
-
-	assert(av_fid->fid.fclass == FI_CLASS_AV);
-	if (av_fid->fid.fclass != FI_CLASS_AV)
-		return -FI_EINVAL;
-
-	av = container_of(av_fid, struct fi_ibv_dgram_av, util_av.av_fid);
-	if (!av)
-		return -FI_EINVAL;
-	ret = fi_ibv_dgram_verify_av_insert(&av->util_av, flags);
-	if (ret)
-		return ret;
-
-	for (i = count - 1; i >= 0; i--) {
-		struct fi_ibv_dgram_av_entry *av_entry;
-		struct ofi_ib_ud_ep_name *ep_name;
-
-		index = (int)fi_addr[i];
-		av_entry = ofi_av_get_addr(&av->util_av, index);
-		if (!av_entry) {
-			VERBS_WARN(FI_LOG_AV, "Unable to find address\n");
-			return -FI_ENOENT;
-		}
-		ret = ibv_destroy_ah(av_entry->ah);
-		if (ret)
-			VERBS_WARN(FI_LOG_AV,
-				   "AH Destroying of fi_addr %d failed "
-				   "with status - %d\n", index, ret);
-		ep_name = av_entry->addr;
-		slot = fi_ibv_dgram_av_slot(&av->util_av, av_entry->addr);
-		fastlock_acquire(&av->util_av.lock);
-		ret = ofi_av_remove_addr(&av->util_av, slot, index);
-		fastlock_release(&av->util_av.lock);
-		if (ret)
-			VERBS_WARN(FI_LOG_AV,
-				   "Removal of fi_addr %d failed\n",
-				   index);
-		free(ep_name);
-	}
-	return FI_SUCCESS;
-}
-
-static inline
-int fi_ibv_dgram_av_lookup(struct fid_av *av_fid, fi_addr_t fi_addr,
-			   void *addr, size_t *addrlen)
-{
-	struct fi_ibv_dgram_av *av;
-	struct fi_ibv_dgram_av_entry *av_entry;
-
-	assert(av_fid->fid.fclass == FI_CLASS_AV);
-	if (av_fid->fid.fclass != FI_CLASS_AV)
-		return -FI_EINVAL;
-
-	av = container_of(av_fid, struct fi_ibv_dgram_av, util_av.av_fid);
-	if (!av)
-		return -FI_EINVAL;
-
-	av_entry = fi_ibv_dgram_av_lookup_av_entry(av, (int)fi_addr);
-	if (!av_entry)
-		return -FI_ENOENT;
-
-	memcpy(addr, av_entry->addr, MIN(*addrlen, av->util_av.addrlen));
-	*addrlen = av->util_av.addrlen;
-	return FI_SUCCESS;
-}
-
-static inline
-const char *fi_ibv_dgram_av_straddr(struct fid_av *av, const void *addr,
-				    char *buf, size_t *len)
-{
-	return ofi_straddr(buf, len, FI_ADDR_IB_UD, addr);
-}
-
-static int fi_ibv_dgram_av_close(struct fid *av_fid)
-{
-	int ret;
-	struct fi_ibv_dgram_av *av;
-
-	assert(av_fid->fclass == FI_CLASS_AV);
-	if (av_fid->fclass != FI_CLASS_AV)
-		return -FI_EINVAL;
-
-	av = container_of(av_fid, struct fi_ibv_dgram_av, util_av.av_fid.fid);
-	if (!av)
-		return -FI_EINVAL;
-
-	ret = ofi_av_close(&av->util_av);
-	if (ret)
-		return ret;
-
-	free(av);
-
-	return FI_SUCCESS;
-}
-
-static struct fi_ops fi_ibv_dgram_fi_ops = {
-	.size		= sizeof(fi_ibv_dgram_fi_ops),
-	.close		= fi_ibv_dgram_av_close,
-	.bind		= ofi_av_bind,
-	.control	= fi_no_control,
-	.ops_open	= fi_no_ops_open,
-};
-
-static struct fi_ops_av fi_ibv_dgram_av_ops = {
-	.size		= sizeof(fi_ibv_dgram_av_ops),
-	.insert		= fi_ibv_dgram_av_insert,
-	.insertsvc	= fi_no_av_insertsvc,
-	.insertsym	= fi_no_av_insertsym,
-	.remove		= fi_ibv_dgram_av_remove,
-	.lookup		= fi_ibv_dgram_av_lookup,
-	.straddr	= fi_ibv_dgram_av_straddr,
-};
-
-int fi_ibv_dgram_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
-			 struct fid_av **av_fid, void *context)
-{
-	struct fi_ibv_domain *domain;
-	struct fi_ibv_dgram_av *av;
-	int ret;
-
-	if (!attr || domain_fid->fid.fclass != FI_CLASS_DOMAIN)
-		return -FI_EINVAL;
-
-	av = calloc(1, sizeof(*av));
-	if (!av)
-		return -FI_ENOMEM;
-
-	domain = container_of(domain_fid, struct fi_ibv_domain,
-			      util_domain.domain_fid);
-	if (!domain) {
-		ret = -FI_EINVAL;
-		goto err1;
-	}
-
-	assert(domain->ep_type == FI_EP_DGRAM);
-	
-	struct util_av_attr util_attr = {
-		.overhead = attr->count >> 1,
-		.flags = OFI_AV_HASH,
-		.addrlen = sizeof(struct fi_ibv_dgram_av_entry),
-	};
-
-	if (attr->type == FI_AV_UNSPEC)
-		attr->type = FI_AV_MAP;
-
-	ret = ofi_av_init(&domain->util_domain, attr, &util_attr,
-			  &av->util_av, context);
-	if (ret)
-		goto err1;
-
-	*av_fid = &av->util_av.av_fid;
-	(*av_fid)->fid.ops = &fi_ibv_dgram_fi_ops;
-	(*av_fid)->ops = &fi_ibv_dgram_av_ops;
-
-	return FI_SUCCESS;
-err1:
-	free(av);
-	return ret;
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_cq.c
deleted file mode 100644
index f34026812..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_cq.c
+++ /dev/null
@@ -1,385 +0,0 @@
-/*
- * Copyright (c) 2017 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "verbs_dgram.h"
-
-static inline
-int fi_ibv_dgram_cq_cntr_comp(struct util_cq *util_cq,
-			      struct util_cntr *util_cntr,
-			      struct ibv_wc *wc)
-{
-	struct fi_cq_tagged_entry *comp;
-	int ret = FI_SUCCESS;
-	struct fi_ibv_dgram_wr_entry *wr_entry =
-		(struct fi_ibv_dgram_wr_entry *)(uintptr_t)wc->wr_id;
-
-	if (util_cntr)
-		util_cntr->cntr_fid.ops->add(&util_cntr->cntr_fid, 1);
-
-	fastlock_acquire(&util_cq->cq_lock);
-	if (OFI_UNLIKELY(ofi_cirque_isfull(util_cq->cirq))) {
-		VERBS_DBG(FI_LOG_CQ, "util_cq cirq is full!\n");
-		ret = -FI_EAGAIN;
-		goto out;
-	}
-
-	comp = ofi_cirque_tail(util_cq->cirq);
-	comp->op_context = wr_entry->hdr.context;
-	comp->flags = wr_entry->hdr.flags;
-	comp->len = (uint64_t)wc->byte_len;
-	comp->buf = NULL;
-	if (wc->wc_flags & IBV_WC_WITH_IMM)
-		comp->data = ntohl(wc->imm_data);
-	ofi_cirque_commit(util_cq->cirq);
-	fi_ibv_dgram_wr_entry_release(
-		&wr_entry->hdr.ep->grh_pool,
-		(struct fi_ibv_dgram_wr_entry_hdr *)wr_entry
-	);
-out:
-	fastlock_release(&util_cq->cq_lock);
-	return ret;
-}
-
-static inline
-int fi_ibv_dgram_cq_cntr_report_error(struct util_cq *util_cq,
-				      struct util_cntr *util_cntr,
-				      struct ibv_wc *wc)
-{
-	struct fi_cq_err_entry err_entry = {
-		.err 		= EIO,
-		.prov_errno	= wc->status,
-		.err_data_size	= sizeof(wc->vendor_err),
-		.err_data	= (void *)&wc->vendor_err,
-	};
-	struct fi_cq_tagged_entry *comp;
-	struct fi_ibv_dgram_wr_entry *wr_entry =
-		(struct fi_ibv_dgram_wr_entry *)(uintptr_t)wc->wr_id;
-	struct util_cq_err_entry *err = calloc(1, sizeof(*err));
-	if (!err) {
-		VERBS_WARN(FI_LOG_CQ, "Unable to allocate "
-				      "util_cq_err_entry\n");
-		goto out;
-	}
-
-	err_entry.op_context = wr_entry->hdr.context;
-	err_entry.flags = wr_entry->hdr.flags;
-	err->err_entry = err_entry;
-
-	if (util_cntr)
-		util_cntr->cntr_fid.ops->adderr(&util_cntr->cntr_fid, 1);
-
-	fastlock_acquire(&util_cq->cq_lock);
-	slist_insert_tail(&err->list_entry, &util_cq->err_list);
-
-	/* Signal that there is err entry */
-	comp = ofi_cirque_tail(util_cq->cirq);
-	comp->flags = UTIL_FLAG_ERROR;
-	ofi_cirque_commit(util_cq->cirq);
-
-	fastlock_release(&util_cq->cq_lock);
-
-out:
-	fi_ibv_dgram_wr_entry_release(
-		&wr_entry->hdr.ep->grh_pool,
-		(struct fi_ibv_dgram_wr_entry_hdr *)wr_entry
-	);
-
-	return FI_SUCCESS;
-}
-
-int fi_ibv_dgram_rx_cq_comp(struct util_cq *util_cq,
-			    struct util_cntr *util_cntr,
-			    struct ibv_wc *wc)
-{
-	return fi_ibv_dgram_cq_cntr_comp(util_cq, util_cntr, wc);
-}
-
-int fi_ibv_dgram_tx_cq_comp(struct util_cq *util_cq,
-			    struct util_cntr *util_cntr,
-			    struct ibv_wc *wc)
-{
-	struct fi_ibv_dgram_wr_entry *wr_entry =
-		(struct fi_ibv_dgram_wr_entry *)(uintptr_t)wc->wr_id;
-
-	ofi_atomic_sub32(&wr_entry->hdr.ep->unsignaled_send_cnt,
-			 wr_entry->hdr.ep->max_unsignaled_send_cnt);
-
-	return fi_ibv_dgram_cq_cntr_comp(util_cq, util_cntr, wc);
-}
-
-int fi_ibv_dgram_tx_cq_report_error(struct util_cq *util_cq,
-				    struct util_cntr *util_cntr,
-				    struct ibv_wc *wc)
-{
-	struct fi_ibv_dgram_wr_entry *wr_entry =
-		(struct fi_ibv_dgram_wr_entry *)(uintptr_t)wc->wr_id;
-
-	ofi_atomic_sub32(&wr_entry->hdr.ep->unsignaled_send_cnt,
-			 wr_entry->hdr.ep->max_unsignaled_send_cnt);
-
-	return fi_ibv_dgram_cq_cntr_report_error(util_cq, util_cntr, wc);
-}
-
-int fi_ibv_dgram_rx_cq_report_error(struct util_cq *util_cq,
-				    struct util_cntr *util_cntr,
-				    struct ibv_wc *wc)
-{
-	return fi_ibv_dgram_cq_cntr_report_error(util_cq, util_cntr, wc);
-}
-
-int fi_ibv_dgram_tx_cq_no_action(struct util_cq *util_cq,
-				 struct util_cntr *util_cntr,
-				 struct ibv_wc *wc)
-{
-	struct fi_ibv_dgram_wr_entry *wr_entry =
-		(struct fi_ibv_dgram_wr_entry *)(uintptr_t)wc->wr_id;
-	
-
-	ofi_atomic_sub32(&wr_entry->hdr.ep->unsignaled_send_cnt,
-			 wr_entry->hdr.ep->max_unsignaled_send_cnt);
-
-	fi_ibv_dgram_wr_entry_release(
-		&wr_entry->hdr.ep->grh_pool,
-		(struct fi_ibv_dgram_wr_entry_hdr *)wr_entry
-	);
-
-	return FI_SUCCESS;
-}
-
-int fi_ibv_dgram_rx_cq_no_action(struct util_cq *util_cq,
-				 struct util_cntr *util_cntr,
-				 struct ibv_wc *wc)
-{
-	struct fi_ibv_dgram_wr_entry *wr_entry =
-		(struct fi_ibv_dgram_wr_entry *)(uintptr_t)wc->wr_id;
-
-	fi_ibv_dgram_wr_entry_release(
-		&wr_entry->hdr.ep->grh_pool,
-		(struct fi_ibv_dgram_wr_entry_hdr *)wr_entry
-	);
-
-	return FI_SUCCESS;
-}
-
-static inline
-void fi_ibv_dgram_cq_handle_wc(struct util_cq *util_cq,
-			       struct util_cntr *util_cntr,
-			       struct ibv_wc *wc)
-{
-	struct fi_ibv_dgram_wr_entry *wr_entry =
-		(struct fi_ibv_dgram_wr_entry *)(uintptr_t)wc->wr_id;
-	if (OFI_LIKELY(wc->status == IBV_WC_SUCCESS))
-		wr_entry->hdr.suc_cb(util_cq, util_cntr, wc);
-	else
-		wr_entry->hdr.err_cb(util_cq, util_cntr, wc);
-}
-
-void fi_ibv_dgram_recv_cq_progress(struct util_ep *util_ep)
-{
-	struct fi_ibv_dgram_cq *cq;
-	int num_ent, i;
-	struct ibv_wc *wcs = alloca(fi_ibv_gl_data.cqread_bunch_size *
-				    sizeof(struct ibv_wc));
-
-	cq = container_of(&util_ep->rx_cq->cq_fid, struct fi_ibv_dgram_cq,
-			  util_cq.cq_fid);
-
-	num_ent = ibv_poll_cq(cq->ibv_cq,
-			      fi_ibv_gl_data.cqread_bunch_size,
-			      wcs);
-	for (i = 0; i < num_ent; i++)
-		fi_ibv_dgram_cq_handle_wc(util_ep->rx_cq,
-					  util_ep->rx_cntr,
-					  &wcs[i]);
-}
-
-void fi_ibv_dgram_send_cq_progress(struct util_ep *util_ep)
-{
-	struct fi_ibv_dgram_cq *cq;
-	int num_ent, i;
-	struct ibv_wc *wcs = alloca(fi_ibv_gl_data.cqread_bunch_size *
-				    sizeof(struct ibv_wc));
-
-	cq = container_of(&util_ep->tx_cq->cq_fid, struct fi_ibv_dgram_cq,
-			  util_cq.cq_fid);
-
-	num_ent = ibv_poll_cq(cq->ibv_cq,
-			      fi_ibv_gl_data.cqread_bunch_size,
-			      wcs);
-	for (i = 0; i < num_ent; i++)
-		fi_ibv_dgram_cq_handle_wc(util_ep->tx_cq,
-					  util_ep->tx_cntr,
-					  &wcs[i]);
-}
-
-void fi_ibv_dgram_send_recv_cq_progress(struct util_ep *util_ep)
-{
-	struct fi_ibv_dgram_cq *tx_cq, *rx_cq;
-	int num_ent, i;
-	struct ibv_wc *wcs = alloca(fi_ibv_gl_data.cqread_bunch_size *
-				    sizeof(struct ibv_wc));
-
-	tx_cq = container_of(&util_ep->tx_cq->cq_fid, struct fi_ibv_dgram_cq,
-			     util_cq.cq_fid);
-	rx_cq = container_of(&util_ep->rx_cq->cq_fid, struct fi_ibv_dgram_cq,
-			     util_cq.cq_fid);
-
-	/* Poll Transmit events */
-	num_ent = ibv_poll_cq(tx_cq->ibv_cq,
-			      fi_ibv_gl_data.cqread_bunch_size,
-			      wcs);
-	for (i = 0; i < num_ent; i++)
-		fi_ibv_dgram_cq_handle_wc(util_ep->tx_cq,
-					  util_ep->tx_cntr,
-					  &wcs[i]);
-
-	/* Poll Receive events */
-	num_ent = ibv_poll_cq(rx_cq->ibv_cq,
-			      fi_ibv_gl_data.cqread_bunch_size,
-			      wcs);
-	for (i = 0; i < num_ent; i++)
-		fi_ibv_dgram_cq_handle_wc(util_ep->rx_cq,
-					  util_ep->rx_cntr,
-					  &wcs[i]);
-}
-
-static inline
-const char *fi_ibv_dgram_cq_strerror(struct fid_cq *cq_fid, int prov_errno,
-				     const void *err_data, char *buf, size_t len)
-{
-	if (buf && len)
-		strncpy(buf, ibv_wc_status_str(prov_errno), len);
-	return ibv_wc_status_str(prov_errno);
-}
-
-static int fi_ibv_dgram_cq_close(fid_t cq_fid)
-{
-	int ret = FI_SUCCESS;
-	struct fi_ibv_dgram_cq *cq;
-	struct fi_ibv_domain *domain;
-
-	cq = container_of(cq_fid, struct fi_ibv_dgram_cq, util_cq.cq_fid.fid);
-	if (!cq)
-		return -FI_EINVAL;
-
-	domain = container_of(cq->util_cq.domain, struct fi_ibv_domain,
-			      util_domain.domain_fid);
-	if (!domain)
-		return -FI_EINVAL;
-
-	ret = ofi_cq_cleanup(&cq->util_cq);
-	if (ret)
-		return ret;
-
-	if (ibv_destroy_cq(cq->ibv_cq)) {
-		VERBS_WARN(FI_LOG_CQ,
-			   "unable to destroy completion queue "
-			   "(errno %d)\n", errno);
-		ret = -errno;
-	}
-
-	free(cq);
-
-	return ret;
-}
-
-static struct fi_ops fi_ibv_dgram_fi_ops = {
-	.size		= sizeof(fi_ibv_dgram_fi_ops),
-	.close		= fi_ibv_dgram_cq_close,
-	.bind		= fi_no_bind,
-	.control	= fi_no_control,
-	.ops_open	= fi_no_ops_open,
-};
-
-static struct fi_ops_cq fi_ibv_dgram_cq_ops = {
-	.size		= sizeof(fi_ibv_dgram_cq_ops),
-	.read		= ofi_cq_read,
-	.readfrom	= ofi_cq_readfrom,
-	.readerr	= ofi_cq_readerr,
-	.sread		= ofi_cq_sread,
-	.sreadfrom	= ofi_cq_sreadfrom,
-	.signal		= ofi_cq_signal,
-	.strerror	= fi_ibv_dgram_cq_strerror
-};
-
-int fi_ibv_dgram_cq_open(struct fid_domain *domain_fid, struct fi_cq_attr *attr,
-			 struct fid_cq **cq_fid, void *context)
-{
-	struct fi_ibv_dgram_cq *cq;
-	struct fi_ibv_domain *domain;
-	int ret;
-	size_t cq_size;
-
-	cq = calloc(1, sizeof(*cq));
-	if (!cq)
-		return -FI_ENOMEM;
-
-	domain = container_of(domain_fid, struct fi_ibv_domain,
-			      util_domain.domain_fid);
-	if (!domain || (domain->ep_type != FI_EP_DGRAM)) {
-		ret = -FI_EINVAL;
-		goto err1;
-	}
-
-	assert(domain->ep_type == FI_EP_DGRAM);
-
-	ret = ofi_cq_init(&fi_ibv_prov, domain_fid, attr,
-			  &cq->util_cq, &ofi_cq_progress,
-			  context);
-	if (ret)
-		goto err1;
-
-	cq_size = attr->size ?
-		  attr->size : MIN(VERBS_DEF_CQ_SIZE,
-				   domain->info->domain_attr->cq_cnt);
-
-	cq->ibv_cq = ibv_create_cq(domain->verbs, cq_size, cq,
-					   NULL, attr->signaling_vector);
-	if (!cq->ibv_cq) {
-		VERBS_WARN(FI_LOG_CQ,
-			   "unable to create completion queue for "
-			   "transsmission (errno %d)\n", errno);
-		ret = -errno;
-		goto err2;
-	}
-
-	*cq_fid = &cq->util_cq.cq_fid;
-	(*cq_fid)->fid.ops = &fi_ibv_dgram_fi_ops;
-	(*cq_fid)->ops = &fi_ibv_dgram_cq_ops;
-
-	return ret;
-err2:
-	ofi_cq_cleanup(&cq->util_cq);
-err1:
-	free(cq);
-	return ret;
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_ep.c
deleted file mode 100644
index 6bffba5a6..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_ep.c
+++ /dev/null
@@ -1,476 +0,0 @@
-/*
- * Copyright (c) 2017 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "verbs_dgram.h"
-
-static int fi_ibv_dgram_ep_enable(struct fid_ep *ep_fid)
-{
-	struct fi_ibv_dgram_ep *ep;
-	struct fi_ibv_dgram_cq *tx_cq = NULL, *rx_cq = NULL;
-	struct fi_ibv_fabric *fab;
-	int ret = FI_SUCCESS;
-	union ibv_gid gid;
-	uint16_t p_key;
-
-	assert(ep_fid->fid.fclass == FI_CLASS_EP);
-	if (ep_fid->fid.fclass != FI_CLASS_EP)
-		return -FI_EINVAL;
-
-	ep = container_of(ep_fid, struct fi_ibv_dgram_ep, util_ep.ep_fid);
-	if (!ep)
-		return -FI_EINVAL;
-
-	if (!ep->util_ep.rx_cq && !ep->util_ep.tx_cq) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
-			   "a send or receive completion queue\n");
-		return -FI_ENOCQ;
-	}
-
-	if (!ep->util_ep.tx_cq && ofi_send_allowed(ep->util_ep.caps)) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
-			   "a send completion queue when it has transmit "
-			   "capabilities enabled (FI_SEND or FI_TRANSMIT).\n");
-		return -FI_ENOCQ;
-	} else if (ep->util_ep.tx_cq) {
-		tx_cq = container_of(&ep->util_ep.tx_cq->cq_fid,
-				     struct fi_ibv_dgram_cq,
-				     util_cq.cq_fid);
-	}
-
-	if (!ep->util_ep.rx_cq && ofi_recv_allowed(ep->util_ep.caps)) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
-			   "a receive completion queue when it has receive "
-			   "capabilities enabled. (FI_RECV)\n");
-		return -FI_ENOCQ;
-	} else {
-		rx_cq = container_of(&ep->util_ep.rx_cq->cq_fid,
-				     struct fi_ibv_dgram_cq,
-				     util_cq.cq_fid);
-	}
-
-	const struct fi_info *info = ep->info;
-	struct ibv_qp_init_attr init_attr = {
-		.send_cq 	= tx_cq ? tx_cq->ibv_cq : NULL,
-		.recv_cq 	= rx_cq ? rx_cq->ibv_cq : NULL,
-		.cap 		= {
-			.max_send_wr		= info->tx_attr->size,
-		       	.max_recv_wr		= info->rx_attr->size,
-		       	.max_send_sge		= info->tx_attr->iov_limit,
-		       	.max_recv_sge		= info->rx_attr->iov_limit,
-			.max_inline_data	= info->tx_attr->inject_size,
-	       	},
-	       	.qp_type 	= IBV_QPT_UD,
-       	};
-
-	ep->ibv_qp = ibv_create_qp(ep->domain->pd, &init_attr);
-	if (!ep->ibv_qp) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to create IBV "
-			   "Queue Pair\n");
-		return -errno;
-	}
-
-	struct ibv_qp_attr attr = {
-		.qp_state = IBV_QPS_INIT,
-		.pkey_index = 0,
-		.port_num = 1,
-		.qkey = 0x11111111,
-	};
-
-	ret = ibv_modify_qp(ep->ibv_qp, &attr,
-			    IBV_QP_STATE |
-			    IBV_QP_PKEY_INDEX |
-			    IBV_QP_PORT |
-			    IBV_QP_QKEY);
-	if (ret) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to modify QP state "
-			   "to INIT\n");
-		return -errno;
-	}
-
-	memset(&attr, 0, sizeof(attr));
-	attr.qp_state = IBV_QPS_RTR;
-	ret = ibv_modify_qp(ep->ibv_qp, &attr,
-			    IBV_QP_STATE);
-	if (ret) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to modify QP state "
-			   "to RTR\n");
-		return -errno;
-	}
-
-	if (tx_cq) {
-		memset(&attr, 0, sizeof(attr));
-		attr.qp_state = IBV_QPS_RTS;
-		attr.sq_psn = 0xffffff;
-		ret = ibv_modify_qp(ep->ibv_qp, &attr,
-				    IBV_QP_STATE |
-				    IBV_QP_SQ_PSN);
-		if (ret) {
-			VERBS_WARN(FI_LOG_EP_CTRL, "Unable to modify QP state "
-				   "to RTS\n");
-			return -errno;
-		}
-	}
-
-	if (ibv_query_gid(ep->domain->verbs, 1, 0, &gid)) {
-		VERBS_WARN(FI_LOG_EP_CTRL,
-			   "Unable to query GID, errno = %d",
-			   errno);
-		return -errno;
-	}
-
-	if (ibv_query_pkey(ep->domain->verbs, 1, 0, &p_key)) {
-		VERBS_WARN(FI_LOG_EP_CTRL,
-			   "Unable to query P_Key, errno = %d",
-			   errno);
-		return -errno;
-	}
-
-	struct ibv_port_attr port_attr;
-	if (ibv_query_port(ep->domain->verbs, 1, &port_attr)) {
-		VERBS_WARN(FI_LOG_EP_CTRL,
-			   "Unable to query port attributes, errno = %d",
-			   errno);
-		return -errno;
-	}
-
-	ep->ep_name.lid = port_attr.lid;
-	ep->ep_name.sl = port_attr.sm_sl;
-	ep->ep_name.gid = gid;
-	ep->ep_name.qpn = ep->ibv_qp->qp_num;
-	ep->ep_name.pkey = p_key;
-
-	fab = container_of(&ep->util_ep.domain->fabric->fabric_fid,
-			   struct fi_ibv_fabric, util_fabric.fabric_fid.fid);
-
-	ofi_ns_add_local_name(&fab->name_server,
-			      &ep->service, &ep->ep_name);
-
-	return ret;
-}
-
-static int fi_ibv_dgram_ep_control(fid_t ep_fid, int command, void *arg)
-{
-	struct fi_ibv_dgram_ep *ep;
-
-	assert(ep_fid->fclass == FI_CLASS_EP);
-	if (ep_fid->fclass != FI_CLASS_EP)
-		return -FI_EINVAL;
-
-	ep = container_of(ep_fid, struct fi_ibv_dgram_ep, util_ep.ep_fid.fid);
-	if (!ep)
-		return -FI_EINVAL;
-
-	switch (command) {
-	case FI_ENABLE:
-		return fi_ibv_dgram_ep_enable(&ep->util_ep.ep_fid);
-	default:
-		return -FI_ENOSYS;
-	}
-}
-
-static int fi_ibv_dgram_ep_close(fid_t ep_fid)
-{
-	struct fi_ibv_dgram_ep *ep;
-	struct fi_ibv_fabric *fab;
-	int ret = FI_SUCCESS;
-
-	assert(ep_fid->fclass == FI_CLASS_EP);
-	if (ep_fid->fclass != FI_CLASS_EP)
-		return -FI_EINVAL;
-
-	ep = container_of(ep_fid, struct fi_ibv_dgram_ep, util_ep.ep_fid.fid);
-	if (!ep)
-		return -FI_EINVAL;
-
-	fab = container_of(&ep->util_ep.domain->fabric->fabric_fid,
-			   struct fi_ibv_fabric, util_fabric.fabric_fid.fid);
-
-	ofi_ns_del_local_name(&fab->name_server,
-			      &ep->service, &ep->ep_name);
-
-	fi_ibv_dgram_pool_destroy(&ep->grh_pool);
-
-	ret = ofi_endpoint_close(&ep->util_ep);
-	if (ret)
-		return ret;
-
-	ret = ibv_destroy_qp(ep->ibv_qp);
-	if (ret) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to destroy QP "
-			   "(errno = %d)\n", errno);
- 		ret = -errno;
-	}
-
-	free(ep);
-	return ret;
-}
-
-static int fi_ibv_dgram_ep_bind(fid_t ep_fid, struct fid *bfid, uint64_t flags)
-{
-	int ret = FI_SUCCESS;
-	struct fi_ibv_dgram_ep *ep;
-	struct fi_ibv_dgram_cq *cq;
-	struct fi_ibv_dgram_av *av;
-	struct fi_ibv_dgram_eq *eq;
-	struct fi_ibv_dgram_cntr *cntr;
-
-	assert(ep_fid->fclass == FI_CLASS_EP);
-	if (ep_fid->fclass != FI_CLASS_EP)
-		return -FI_EINVAL;
-
-	ep = container_of(ep_fid, struct fi_ibv_dgram_ep, util_ep.ep_fid.fid);
-	if (!ep)
-		return -FI_EINVAL;
-
-	ret = ofi_ep_bind_valid(&fi_ibv_prov, bfid, flags);
-	if (ret)
-		return ret;
-
-	switch (bfid->fclass) {
-	case FI_CLASS_CQ:
-		cq = container_of(bfid, struct fi_ibv_dgram_cq,
-				  util_cq.cq_fid.fid);
-		if (!cq)
-			return -FI_EINVAL;
-		if (flags & (FI_RECV | FI_TRANSMIT))
-			ep->util_ep.progress =
-				fi_ibv_dgram_send_recv_cq_progress;
-		else if (flags & FI_RECV)
-			ep->util_ep.progress = (ep->util_ep.tx_cq) ?
-				fi_ibv_dgram_send_recv_cq_progress :
-				fi_ibv_dgram_recv_cq_progress;
-		else if (flags & FI_TRANSMIT)
-			ep->util_ep.progress = (ep->util_ep.rx_cq) ?
-				fi_ibv_dgram_send_recv_cq_progress :
-				fi_ibv_dgram_send_cq_progress;
-		return ofi_ep_bind_cq(&ep->util_ep, &cq->util_cq, flags);
-	case FI_CLASS_EQ:
-		eq = container_of(bfid, struct fi_ibv_dgram_eq,
-				  util_eq.eq_fid.fid);
-		if (!eq)
-			return -FI_EINVAL;
-		return ofi_ep_bind_eq(&ep->util_ep, &eq->util_eq);
-		break;
-	case FI_CLASS_AV:
-		av = container_of(bfid, struct fi_ibv_dgram_av,
-				  util_av.av_fid.fid);
-		if (!av)
-			return -FI_EINVAL;
-		return ofi_ep_bind_av(&ep->util_ep, &av->util_av);
-	case FI_CLASS_CNTR:
-		cntr = container_of(bfid, struct fi_ibv_dgram_cntr,
-				    util_cntr.cntr_fid.fid);
-		if (!cntr)
-			return -FI_EINVAL;
-		return ofi_ep_bind_cntr(&ep->util_ep, &cntr->util_cntr, flags);
-	default:
-		return -FI_EINVAL;
-	}
-
-	return ret;
-}
-
-static int fi_ibv_dgram_ep_setname(fid_t ep_fid, void *addr, size_t addrlen)
-{
-	struct fi_ibv_dgram_ep *ep;
-	void *save_addr;
-	int ret = FI_SUCCESS;
-
-	if (ep_fid->fclass != FI_CLASS_EP)
-		return -FI_EINVAL;
-
-	ep = container_of(ep_fid, struct fi_ibv_dgram_ep, util_ep.ep_fid.fid);
-	if (!ep)
-		return -FI_EINVAL;
-
-	if (addrlen < ep->info->src_addrlen) {
-		VERBS_INFO(FI_LOG_EP_CTRL,
-			   "addrlen expected: %"PRIu64", got: %"PRIu64"\n",
-			   ep->info->src_addrlen, addrlen);
-		return -FI_ETOOSMALL;
-	}
-	/*
-	 * save previous address to be able make
-	 * a roll back on the previous one
-	 */
-	save_addr = ep->info->src_addr;
-
-	ep->info->src_addr = calloc(1, ep->info->src_addrlen);
-	if (!ep->info->src_addr) {
-		ep->info->src_addr = save_addr;
-		ret = -FI_ENOMEM;
-		goto err;
-	}
-
-	memcpy(ep->info->src_addr, addr, ep->info->src_addrlen);
-	memcpy(&ep->ep_name, addr, ep->info->src_addrlen);
-
-err:
-	ep->info->src_addr = save_addr;
-	return ret;
-	
-}
-
-static int fi_ibv_dgram_ep_getname(fid_t ep_fid, void *addr, size_t *addrlen)
-{
-	struct fi_ibv_dgram_ep *ep;
-
-	if (ep_fid->fclass != FI_CLASS_EP)
-		return -FI_EINVAL;
-
-	ep = container_of(ep_fid, struct fi_ibv_dgram_ep, util_ep.ep_fid.fid);
-	if (!ep)
-		return -FI_EINVAL;
-
-	if (*addrlen < sizeof(ep->ep_name)) {
-		*addrlen = sizeof(ep->ep_name);
-		VERBS_INFO(FI_LOG_EP_CTRL,
-			   "addrlen expected: %"PRIu64", got: %"PRIu64"\n",
-			   sizeof(ep->ep_name), *addrlen);
-		return -FI_ETOOSMALL;
-	}
-
-	memset(addr, 0, *addrlen);
-	memcpy(addr, &ep->ep_name, sizeof(ep->ep_name));
-	*addrlen = sizeof(ep->ep_name);
-
-	return FI_SUCCESS;
-}
-
-static struct fi_ops fi_ibv_dgram_fi_ops = {
-	.size = sizeof(fi_ibv_dgram_fi_ops),
-	.close = fi_ibv_dgram_ep_close,
-	.bind = fi_ibv_dgram_ep_bind,
-	.control = fi_ibv_dgram_ep_control,
-	.ops_open = fi_no_ops_open,
-};
-
-static struct fi_ops_cm fi_ibv_dgram_cm_ops = {
-	.size = sizeof(fi_ibv_dgram_cm_ops),
-	.setname = fi_ibv_dgram_ep_setname,
-	.getname = fi_ibv_dgram_ep_getname,
-	.getpeer = fi_no_getpeer,
-	.connect = fi_no_connect,
-	.listen = fi_no_listen,
-	.accept = fi_no_accept,
-	.reject = fi_no_reject,
-	.shutdown = fi_no_shutdown,
-	.join = fi_no_join,
-};
-
-static struct fi_ops_ep fi_ibv_dgram_ep_ops = {
-	.size = sizeof(fi_ibv_dgram_ep_ops),
-	.cancel = fi_no_cancel,
-	.getopt = fi_no_getopt,
-	.setopt = fi_no_setopt,
-	.tx_ctx = fi_no_tx_ctx,
-	.rx_ctx = fi_no_rx_ctx,
-	.rx_size_left = fi_no_rx_size_left,
-	.tx_size_left = fi_no_tx_size_left,
-};
-
-int fi_ibv_dgram_endpoint_open(struct fid_domain *domain_fid,
-			       struct fi_info *info,
-			       struct fid_ep **ep_fid,
-			       void *context)
-{
-	struct fi_ibv_dgram_ep *ep;
-	int ret = FI_SUCCESS;
-
-	assert(info && info->ep_attr && info->rx_attr && info->tx_attr);
-	assert(domain_fid);
-	assert(domain_fid->fid.fclass == FI_CLASS_DOMAIN);
-
-	if (!info || !info->ep_attr ||
-	    domain_fid->fid.fclass != FI_CLASS_DOMAIN)
-		return -FI_EINVAL;
-
-	ep = calloc(1, sizeof(*ep));
-	if (!ep)
-		return -FI_ENOMEM;
-
-	struct fi_ibv_dgram_pool_attr pool_attr = {
-		.count		= MIN(info->rx_attr->size, info->tx_attr->size),
-		.size		= VERBS_DGRAM_WR_ENTRY_SIZE,
-		.pool_ctx	= domain_fid,
-		.cancel_hndlr	= fi_ibv_dgram_pool_wr_entry_cancel,
-		.alloc_hndlr	= fi_ibv_dgram_mr_buf_reg,
-		.free_hndlr	= fi_ibv_dgram_mr_buf_close,
-	};
-
-	ret = fi_ibv_dgram_pool_create(&pool_attr, &ep->grh_pool);
-	if (ret)
-		goto err1;
-
-	/* Temporary solution */
-	struct fi_ibv_domain *domain;
-	domain = container_of(domain_fid, struct fi_ibv_domain,
-			      util_domain.domain_fid);
-	if (!domain) {
-		ret = -FI_EINVAL;
-		goto err2;
-	}
-
-	ret = ofi_endpoint_init(domain_fid, &fi_ibv_util_prov,
-				info, &ep->util_ep, context, NULL);
-	if (ret)
-		goto err2;
-
-	ep->info = fi_dupinfo(info);
-	if (!ep->info) {
-		ret = -FI_ENOMEM;
-		goto err3;
-	}
-	ep->domain = domain;
-	ep->service = (info->src_addr) ?
-			(((struct ofi_ib_ud_ep_name *)info->src_addr)->service) :
-			(((getpid() & 0x7FFF) << 16) + ((uintptr_t)ep & 0xFFFF));
-	
-	ofi_atomic_initialize32(&ep->unsignaled_send_cnt, 0);
-	ep->max_unsignaled_send_cnt = ep->info->tx_attr->size / 2;
-
-	*ep_fid = &ep->util_ep.ep_fid;
-	(*ep_fid)->cm = &fi_ibv_dgram_cm_ops;
-	(*ep_fid)->msg = &fi_ibv_dgram_msg_ops;
-	(*ep_fid)->fid.ops = &fi_ibv_dgram_fi_ops;
-	(*ep_fid)->ops = &fi_ibv_dgram_ep_ops;
-
-	return ret;
-err3:
-	ofi_endpoint_close(&ep->util_ep);
-err2:
-	fi_ibv_dgram_pool_destroy(&ep->grh_pool);
-err1:
-	free(ep);
-	return ret;
-}
-
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_ep_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_ep_msg.c
deleted file mode 100644
index d35832ade..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_dgram/verbs_dgram_ep_msg.c
+++ /dev/null
@@ -1,337 +0,0 @@
-/*
- * Copyright (c) 2017 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "verbs_dgram.h"
-
-static inline
-void fi_ibv_dgram_recv_setup(struct fi_ibv_dgram_wr_entry *wr_entry,
-			     struct ibv_recv_wr *wr)
-{
-	struct fi_ibv_dgram_ep *ep = wr_entry->hdr.ep;
-
-	if (fi_ibv_dgram_is_completion(ep->ep_flags,
-				       wr_entry->hdr.flags)) {
-		wr_entry->hdr.suc_cb = fi_ibv_dgram_rx_cq_comp;
-		wr_entry->hdr.err_cb = fi_ibv_dgram_rx_cq_report_error;
-	} else {
-		wr_entry->hdr.suc_cb = fi_ibv_dgram_rx_cq_no_action;
-		wr_entry->hdr.err_cb = fi_ibv_dgram_rx_cq_no_action;
-
-		fi_ibv_dgram_wr_entry_release(
-			&ep->grh_pool,
-			(struct fi_ibv_dgram_wr_entry_hdr *)wr_entry
-		);
-	}
-}
-
-static inline ssize_t
-fi_ibv_dgram_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
-		     uint64_t flags)
-{
-	struct fi_ibv_dgram_ep *ep;
-	struct ibv_recv_wr wr = { 0 };
-	struct ibv_sge *sge;
-	struct fi_ibv_dgram_wr_entry *wr_entry;
-	ssize_t i;
-
-	ep = container_of(ep_fid, struct fi_ibv_dgram_ep,
-			  util_ep.ep_fid.fid);
-	assert(ep && ep->util_ep.rx_cq);
-
-	wr_entry = (struct fi_ibv_dgram_wr_entry *)
-		fi_ibv_dgram_wr_entry_get(&ep->grh_pool);
-	if (OFI_UNLIKELY(!wr_entry))
-		return -FI_ENOMEM;
-
-	wr_entry->hdr.ep = ep;
-	wr_entry->hdr.context = msg->context;
-
-	wr.wr_id = (uintptr_t)wr_entry;
-	wr.next = NULL;
-
-	sge = alloca(sizeof(*sge) * msg->iov_count + 1);
-	sge[0].addr = (uintptr_t)(wr_entry->grh_buf);
-	sge[0].length = VERBS_DGRAM_GRH_LENGTH;
-	sge[0].lkey = (uint32_t)(uintptr_t)(wr_entry->hdr.desc);
-	for (i = 0; i < msg->iov_count; i++) {
-		sge[i + 1].addr = (uintptr_t)(msg->msg_iov[i].iov_base);
-		sge[i + 1].length = (uint32_t)(msg->msg_iov[i].iov_len);
-		sge[i + 1].lkey = (uint32_t)(uintptr_t)(msg->desc[i]);
-	}
-	wr.sg_list = sge;
-	wr.num_sge = msg->iov_count + 1;
-
-	fi_ibv_dgram_recv_setup(wr_entry, &wr);
-
-	return FI_IBV_INVOKE_POST(
-		recv, recv, ep->ibv_qp, &wr,
-		(fi_ibv_dgram_wr_entry_release(
-				&ep->grh_pool,
-				(struct fi_ibv_dgram_wr_entry_hdr *)
-				wr_entry)));
-}
-
-static inline ssize_t
-fi_ibv_dgram_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
-		   size_t count, fi_addr_t src_addr, void *context)
-{
-	struct fi_msg msg = {
-		.msg_iov	= iov,
-		.desc		= desc,
-		.iov_count	= count,
-		.addr		= src_addr,
-		.context	= context,
-	};
-
-	return fi_ibv_dgram_recvmsg(ep_fid, &msg, 0);
-}
-
-static inline ssize_t
-fi_ibv_dgram_recv(struct fid_ep *ep_fid, void *buf, size_t len,
-		  void *desc, fi_addr_t src_addr, void *context)
-{
-	struct iovec iov = {
-		.iov_base	= buf,
-		.iov_len	= len,
-	};
-
-	return fi_ibv_dgram_recvv(ep_fid, &iov, &desc,
-				  1, src_addr, context);
-}
-
-static inline
-void fi_ibv_dgram_send_setup(struct fi_ibv_dgram_wr_entry *wr_entry,
-			     struct ibv_send_wr *wr,
-			     size_t total_len)
-{
-	struct fi_ibv_dgram_ep *ep = wr_entry->hdr.ep;
-	int32_t unsignaled_cnt = ofi_atomic_inc32(&ep->unsignaled_send_cnt) + 1;
-
-	if (fi_ibv_dgram_is_completion(ep->ep_flags,
-				       wr_entry->hdr.flags)) {
-		wr->send_flags |= IBV_SEND_SIGNALED;
-		wr_entry->hdr.suc_cb = fi_ibv_dgram_tx_cq_comp;
-		wr_entry->hdr.err_cb = fi_ibv_dgram_tx_cq_report_error;
-		wr_entry->hdr.comp_unsignaled_cnt = unsignaled_cnt;
-	} else if (unsignaled_cnt == ep->max_unsignaled_send_cnt) {
-		wr->send_flags |= IBV_SEND_SIGNALED;
-		wr_entry->hdr.suc_cb = fi_ibv_dgram_tx_cq_no_action;
-		wr_entry->hdr.err_cb = fi_ibv_dgram_tx_cq_no_action;
-		wr_entry->hdr.comp_unsignaled_cnt = unsignaled_cnt;
-	} else {
-		/* No need other actions */
-		fi_ibv_dgram_wr_entry_release(
-			&ep->grh_pool,
-			(struct fi_ibv_dgram_wr_entry_hdr *)wr_entry
-		);
-	}
-
-	if ((wr_entry->hdr.flags & FI_INJECT) &&
-	    (total_len <= ep->info->tx_attr->inject_size))
-		wr->send_flags |= IBV_SEND_INLINE;
-}
-
-static inline ssize_t
-fi_ibv_dgram_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
-		     uint64_t flags)
-{
-	struct fi_ibv_dgram_ep *ep;
-	struct ibv_send_wr wr = { 0 };
-	struct ibv_sge *sge;
-	struct fi_ibv_dgram_wr_entry *wr_entry = NULL;
-	struct fi_ibv_dgram_av_entry *av_entry;
-	struct fi_ibv_dgram_av *av;
-	size_t total_len = 0, i;
-
-	assert(!(flags & FI_FENCE));
-
-	ep = container_of(ep_fid, struct fi_ibv_dgram_ep,
-			  util_ep.ep_fid.fid);
-	assert(ep && ep->util_ep.tx_cq);
-
-	wr_entry = (struct fi_ibv_dgram_wr_entry *)
-		fi_ibv_dgram_wr_entry_get(&ep->grh_pool);
-	if (OFI_UNLIKELY(!wr_entry))
-		return -FI_ENOMEM;
-
-	wr_entry->hdr.ep = ep;
-	wr_entry->hdr.context = msg->context;
-	wr_entry->hdr.flags = flags;
-
-	sge = alloca(sizeof(*sge) * msg->iov_count + 1);
-	sge[0].addr = (uintptr_t)(wr_entry->grh_buf);
-	sge[0].length = 0;
-	sge[0].lkey = (uint32_t)(uintptr_t)(wr_entry->hdr.desc);
-	if (msg->desc) {
-		for (i = 0; i < msg->iov_count; i++) {
-			sge[i + 1].addr = (uintptr_t)(msg->msg_iov[i].iov_base);
-			sge[i + 1].length = (uint32_t)(msg->msg_iov[i].iov_len);
-			sge[i + 1].lkey = (uint32_t)(uintptr_t)(msg->desc[i]);
-			total_len += msg->msg_iov[i].iov_len;
-		}
-	} else {
-		for (i = 0; i < msg->iov_count; i++) {
-			sge[i + 1].addr = (uintptr_t)(msg->msg_iov[i].iov_base);
-			sge[i + 1].length = (uint32_t)(msg->msg_iov[i].iov_len);
-			sge[i + 1].lkey = 0;
-			total_len += msg->msg_iov[i].iov_len;
-		}
-	}
-
-	wr.wr_id = (uintptr_t)wr_entry;
-	wr.next = NULL;
-	wr.sg_list = sge;
-	wr.num_sge = msg->iov_count + 1;
-
-	if (flags & FI_REMOTE_CQ_DATA) {
-		wr.opcode = IBV_WR_SEND_WITH_IMM;
-		wr.imm_data = htonl((uint32_t)msg->data);
-	} else {
-		wr.opcode = IBV_WR_SEND;
-	}
-
-	av = container_of(&ep->util_ep.av->av_fid, struct fi_ibv_dgram_av,
-			  util_av.av_fid);
-	av_entry = fi_ibv_dgram_av_lookup_av_entry(av, (int)msg->addr);
-	if (OFI_UNLIKELY(!av_entry)) {
-		fi_ibv_dgram_wr_entry_release(
-			&ep->grh_pool,
-			(struct fi_ibv_dgram_wr_entry_hdr *)wr_entry);
-		return -FI_ENOENT;
-	}
-
-	wr.wr.ud.ah = av_entry->ah;
-	wr.wr.ud.remote_qpn = av_entry->addr->qpn;
-	wr.wr.ud.remote_qkey = 0x11111111;
-
-	fi_ibv_dgram_send_setup(wr_entry, &wr, total_len);
-
-	return FI_IBV_INVOKE_POST(
-		send, send, ep->ibv_qp, &wr,
-			((wr.send_flags & IBV_SEND_SIGNALED)	?
-				fi_ibv_dgram_wr_entry_release(
-					&ep->grh_pool,
-					(struct fi_ibv_dgram_wr_entry_hdr *)
-						wr_entry)	:
-				NULL));
-}
-
-static inline ssize_t
-fi_ibv_dgram_sendv(struct fid_ep *ep_fid, const struct iovec *iov,
-		   void **desc, size_t count, fi_addr_t dest_addr,
-		   void *context)
-{
-	struct fi_msg msg = {
-		.msg_iov	= iov,
-		.desc		= desc,
-		.iov_count	= count,
-		.addr		= dest_addr,
-		.context	= context,
-	};
-
-	return fi_ibv_dgram_sendmsg(ep_fid, &msg, 0);
-}
-
-static inline ssize_t
-fi_ibv_dgram_senddata(struct fid_ep *ep_fid, const void *buf,
-		      size_t len, void *desc, uint64_t data,
-		      fi_addr_t dest_addr, void *context)
-{
-	struct iovec iov = {
-		.iov_base	= (void *)buf,
-		.iov_len	= len,
-	};
-
-	struct fi_msg msg = {
-		.msg_iov	= &iov,
-		.desc		= &desc,
-		.iov_count	= 1,
-		.addr		= dest_addr,
-		.context	= context,
-		.data		= data,
-	};
-
-	return fi_ibv_dgram_sendmsg(ep_fid, &msg, FI_REMOTE_CQ_DATA);
-}
-
-static inline ssize_t
-fi_ibv_dgram_send(struct fid_ep *ep_fid, const void *buf, size_t len,
-		  void *desc, fi_addr_t dest_addr, void *context)
-{
-	struct iovec iov = {
-		.iov_base	= (void *)buf,
-		.iov_len	= len,
-	};
-
-	return fi_ibv_dgram_sendv(ep_fid, &iov, &desc,
-				  1, dest_addr, context);
-}
-
-static inline ssize_t
-fi_ibv_dgram_injectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
-			uint64_t data, fi_addr_t dest_addr)
-{
-    struct iovec iov = {
-		.iov_base	= (void *)buf,
-		.iov_len	= len,
-	};
-
-	struct fi_msg msg = {
-		.msg_iov	= &iov,
-		.iov_count	= 1,
-		.addr		= dest_addr,
-		.data		= data,
-	};
-
-	return fi_ibv_dgram_sendmsg(ep_fid, &msg, FI_INJECT |
-						  FI_REMOTE_CQ_DATA);
-}
-
-static inline ssize_t
-fi_ibv_dgram_inject(struct fid_ep *ep_fid, const void *buf,
-		    size_t len, fi_addr_t dest_addr)
-{
-	return fi_ibv_dgram_injectdata(ep_fid, buf, len, 0, dest_addr);
-}
-
-struct fi_ops_msg fi_ibv_dgram_msg_ops = {
-	.size		= sizeof(fi_ibv_dgram_msg_ops),
-	.recv		= fi_ibv_dgram_recv,
-	.recvv		= fi_ibv_dgram_recvv,
-	.recvmsg	= fi_ibv_dgram_recvmsg,
-	.send		= fi_ibv_dgram_send,
-	.sendv		= fi_ibv_dgram_sendv,
-	.sendmsg	= fi_ibv_dgram_sendmsg,
-	.inject		= fi_ibv_dgram_inject,
-	.senddata	= fi_ibv_dgram_senddata,
-	.injectdata	= fi_ibv_dgram_injectdata,
-};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_av_ep_rdm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_av_ep_rdm.c
deleted file mode 100644
index 8e1926af1..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_av_ep_rdm.c
+++ /dev/null
@@ -1,701 +0,0 @@
-/*
- * Copyright (c) 2013-2016 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <arpa/inet.h>
-#include <sys/types.h>
-#include <sys/socket.h>
-#include <netdb.h>
-#include <ctype.h>
-
-#include "ofi.h"
-
-#include "verbs_rdm.h"
-
-
-extern struct fi_provider fi_ibv_prov;
-
-ssize_t
-fi_ibv_rdm_start_connection(struct fi_ibv_rdm_ep *ep, 
-			    struct fi_ibv_rdm_conn *conn)
-{
-	struct rdma_cm_id *id = NULL;
-	assert(ep->domain->rdm_cm->listener);
-
-	if (conn->state != FI_VERBS_CONN_ALLOCATED)
-		return FI_SUCCESS;
-
-	if (ep->is_closing) {
-		VERBS_INFO(FI_LOG_AV,
-			   "Attempt start connection with %s:%u when ep is closing\n",
-			   inet_ntoa(conn->addr.sin_addr),
-			   ntohs(conn->addr.sin_port));
-		return -FI_EOTHER;
-	}
-
-	conn->state = FI_VERBS_CONN_STARTED;
-	fi_ibv_rdm_conn_init_cm_role(conn, ep);
-
-	if (rdma_create_id(ep->domain->rdm_cm->ec, &id, conn, RDMA_PS_TCP)) {
-		VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_create_id\n", errno);
-		return -errno;
-	}
-
-	if (conn->cm_role == FI_VERBS_CM_ACTIVE || 
-	    conn->cm_role == FI_VERBS_CM_SELF)
-		conn->id[0] = id;
-
-	if (rdma_resolve_addr(id, NULL, (struct sockaddr *)&conn->addr, 30000)) {
-		VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_resolve_addr\n", errno);
-		return -errno;
-	}
-	return FI_SUCCESS;
-}
-
-/* Must call with `rdm_cm::cm_lock` held */
-ssize_t fi_ibv_rdm_start_overall_disconnection(struct fi_ibv_rdm_av_entry *av_entry)
-{
-	struct fi_ibv_rdm_conn *conn = NULL, *tmp = NULL;
-	ssize_t ret = FI_SUCCESS;
-	ssize_t err = FI_SUCCESS;
-
-	HASH_ITER(hh, av_entry->conn_hash, conn, tmp) {
-		ret = fi_ibv_rdm_start_disconnection(conn);
-		if (ret) {
-			VERBS_INFO(FI_LOG_AV, "Disconnection failed "
-				   "(%zd) for %p\n", ret, conn);
-			err = ret;
-		}
-		/*
-		 * do NOT remove entry of connection from HASH.
-		 * We will refer to the connection during
-		 * cleanup of the connections.
-		 */
-	}
-
-	return err;
-}
-
-ssize_t fi_ibv_rdm_start_disconnection(struct fi_ibv_rdm_conn *conn)
-{
-	ssize_t ret = FI_SUCCESS;
-
-	VERBS_INFO(FI_LOG_AV, "Closing connection %p, state %d\n",
-		   conn, conn->state);
-
-	if (conn->id[0]) {
-		if (rdma_disconnect(conn->id[0])) {
-			VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_disconnect\n", errno);
-			ret = -errno;
-		}
-	}
-
-	switch (conn->state) {
-	case FI_VERBS_CONN_ESTABLISHED:
-		conn->state = FI_VERBS_CONN_LOCAL_DISCONNECT;
-		break;
-	case FI_VERBS_CONN_REJECTED:
-		conn->state = FI_VERBS_CONN_CLOSED;
-		break;
-	case FI_VERBS_CONN_ALLOCATED:
-	case FI_VERBS_CONN_CLOSED:
-		break;
-	default:
-		VERBS_WARN(FI_LOG_EP_CTRL, "Unknown connection state: %d\n",
-			  (int)conn->state);
-		ret = -FI_EOTHER;
-	}
-
-	return ret;
-}
-
-static inline int fi_ibv_rdm_av_is_valid_address(struct sockaddr_in *addr)
-{
-	return addr->sin_family == AF_INET ? 1 : 0;
-}
-
-int fi_ibv_av_entry_alloc(struct fi_ibv_domain *domain,
-			  struct fi_ibv_rdm_av_entry **av_entry,
-			  void *addr)
-{
-	int ret = ofi_memalign((void**)av_entry,
-			       FI_IBV_MEM_ALIGNMENT,
-			       sizeof (**av_entry));
-	if (ret)
-		return -ret;
-	memset((*av_entry), 0, sizeof(**av_entry));
-	memcpy(&(*av_entry)->addr, addr, FI_IBV_RDM_DFLT_ADDRLEN);
-	HASH_ADD(hh, domain->rdm_cm->av_hash, addr,
-		 FI_IBV_RDM_DFLT_ADDRLEN, (*av_entry));
-	(*av_entry)->sends_outgoing = 0;
-	(*av_entry)->recv_preposted = 0;
-
-	return ret;
-}
-
-static int fi_ibv_rdm_av_insert(struct fid_av *av_fid, const void *addr,
-                                size_t count, fi_addr_t * fi_addr,
-                                uint64_t flags, void *context)
-{
-	struct fi_ibv_av *av = container_of(av_fid, struct fi_ibv_av, av_fid);
-	size_t i;
-	int failed = 0;
-	int ret = 0;
-	int *fi_errors = context;
-
-	if((av->flags & FI_EVENT) && !av->eq)
-		return -FI_ENOEQ;
-
-	if ((flags & FI_SYNC_ERR) && ((!context) || (flags & FI_EVENT)))
-		return -FI_EINVAL;
-	else if (flags & FI_SYNC_ERR)
-		memset(context, 0, sizeof(int) * count);
-
-	pthread_mutex_lock(&av->domain->rdm_cm->cm_lock);
-
-	if (av->used + count > av->count) {
-		const size_t new_av_count = av->used + count;
-		if (av->type == FI_AV_TABLE) {
-			void *p = realloc(av->domain->rdm_cm->av_table,
-					  (new_av_count *
-					  sizeof(*av->domain->rdm_cm->av_table)));
-			if (p) {
-				av->domain->rdm_cm->av_table = p;
-			}
-			else {
-				ret = -FI_ENOMEM;
-				goto out;
-			}
-		}
-		av->count = new_av_count;
-	}
-
-	for (i = 0; i < count; i++) {
-		struct fi_ibv_rdm_av_entry *av_entry = NULL;
-		void *addr_i = (uint8_t *) addr +
-			i * FI_IBV_RDM_DFLT_ADDRLEN;
-
-		if (flags & FI_SYNC_ERR)
-			fi_errors[i] = FI_SUCCESS;
-
-		if (!fi_ibv_rdm_av_is_valid_address(addr_i)) {
-			if (fi_addr)
-				fi_addr[i] = FI_ADDR_NOTAVAIL;
-
-			VERBS_INFO(FI_LOG_AV,
-				   "fi_av_insert: bad addr #%zu\n", i);
-
-			if (av->flags & FI_EVENT) {
-				/* due to limited functionality of
-				 * verbs EQ notify last failed element
-				 * only. */
-				/* TODO: what about utils EQ? */
-				struct fi_eq_err_entry err = {
-					.fid = &av->av_fid.fid,
-					.context = context,
-					.data = i,
-					.err = FI_EINVAL,
-					.prov_errno = FI_EINVAL
-				};
-				av->eq->err = err;
-			} else if (flags & FI_SYNC_ERR) {
-				fi_errors[i] = -FI_EADDRNOTAVAIL;
-			}
-
-			failed++;
-			continue;
-		}
-
-		HASH_FIND(hh, av->domain->rdm_cm->av_hash, addr_i,
-			  FI_IBV_RDM_DFLT_ADDRLEN, av_entry);
-
-		if (!av_entry) {
-			/* If addr_i is not found in HASH then we malloc it.
-			 * It could be found if the connection was initiated
-			 * by the remote side.
-			 */
-			ret = fi_ibv_av_entry_alloc(av->domain, &av_entry, addr_i);
-			if (ret)
-				goto out;
-		}
-
-		switch (av->type) {
-		case FI_AV_MAP:
-			if (fi_addr)
-				fi_addr[i] = (uintptr_t) (void *) av_entry;
-			break;
-		case FI_AV_TABLE:
-			if (fi_addr)
-				fi_addr[i] = av->used;
-			av->domain->rdm_cm->av_table[av->used] = av_entry;
-			break;
-		default:
-			assert(0);
-			break;
-		}
-
-		VERBS_INFO(FI_LOG_AV,
-			   "fi_av_insert: addr %s:%u; av_entry - %p\n",
-			   inet_ntoa(av_entry->addr.sin_addr),
-			   ntohs(av_entry->addr.sin_port), av_entry);
-
-		av->used++;
-	}
-	ret = count - failed;
-
-	if (av->flags & FI_EVENT) {
-		struct fi_eq_entry entry = {
-			.fid = &av->av_fid.fid,
-			.context = context,
-			.data = count - failed
-		};
-		fi_ibv_eq_write_event(
-			av->eq, FI_AV_COMPLETE, &entry, sizeof(entry));
-	}
-
-out:
-	pthread_mutex_unlock(&av->domain->rdm_cm->cm_lock);
-	return (av->flags & FI_EVENT) ? FI_SUCCESS : ret;
-}
-
-static int fi_ibv_rdm_av_insertsvc(struct fid_av *av_fid, const char *node,
-				   const char *service, fi_addr_t *fi_addr,
-				   uint64_t flags, void *context)
-{
-	struct addrinfo addrinfo_hints;
-	struct addrinfo *result = NULL;
-	int ret;
-
-	if (!node || !service) {
-		VERBS_WARN(FI_LOG_AV, "fi_av_insertsvc: %s provided\n",
-			   (!node ? (!service ? "node and service weren't" :
-						"node wasn't") :
-				    ("service wasn't")));
-		return -FI_EINVAL;
-	}
-
-	struct fi_ibv_av *av = container_of(av_fid, struct fi_ibv_av, av_fid);
-
-	memset(&addrinfo_hints, 0, sizeof(addrinfo_hints));
-	addrinfo_hints.ai_family = AF_INET;
-	ret = getaddrinfo(node, service, &addrinfo_hints, &result);
-	if (ret) {
-		if ((av->flags & FI_EVENT) && (av->eq)) {
-			struct fi_eq_entry entry = {
-				.fid = &av->av_fid.fid,
-				.context = context,
-				.data = 0
-			};
-			struct fi_eq_err_entry err = {
-				.fid = &av->av_fid.fid,
-				.context = context,
-				.data = 0,
-				.err = FI_EINVAL,
-				.prov_errno = FI_EINVAL
-			};
-			av->eq->err = err;
-
-			fi_ibv_eq_write_event(
-				av->eq, FI_AV_COMPLETE,
-				&entry, sizeof(entry));
-		}
-		return -ret;
-	}
-
-	ret = fi_ibv_rdm_av_insert(av_fid, (struct sockaddr_in *)result->ai_addr,
-				   1, fi_addr, flags, context);
-	freeaddrinfo(result);
-	return ret;
-}
-
-static int fi_ibv_rdm_av_insertsym(struct fid_av *av, const char *node,
-				   size_t nodecnt, const char *service,
-				   size_t svccnt, fi_addr_t *fi_addr,
-				   uint64_t flags, void *context)
-{
-	int ret = 0, success = 0, err_code = 0;
-	int var_port, var_host, len_port, len_host;
-	char base_host[FI_NAME_MAX] = {0};
-	char tmp_host[FI_NAME_MAX] = {0};
-	char tmp_port[FI_NAME_MAX] = {0};
-	int hostlen, offset = 0, fmt;
-	size_t i, j;
-
-	if (!node || !service || node[0] == '\0') {
-		VERBS_WARN(FI_LOG_AV, "fi_av_insertsym: %s provided\n",
-			   (!service ? (!node ? "node and service weren't" :
-						"service wasn't") :
-				    ("node wasn't")));
-		return -FI_EINVAL;
-	}
-
-	hostlen = strlen(node);
-	while (isdigit(*(node + hostlen - (offset + 1))))
-		offset++;
-
-	if (*(node + hostlen - offset) == '.')
-		fmt = 0;
-	else
-		fmt = offset;
-
-	assert((hostlen-offset) < FI_NAME_MAX);
-	strncpy(base_host, node, hostlen - (offset));
-	var_port = atoi(service);
-	var_host = atoi(node + hostlen - offset);
-
-	for (i = 0; i < nodecnt; i++) {
-		for (j = 0; j < svccnt; j++) {
-			int check_host = 0, check_port = 0;
-
-			len_host = snprintf(tmp_host, FI_NAME_MAX, "%s%0*d",
-					    base_host, fmt,
-					    var_host + (int)i);
-			len_port = snprintf(tmp_port, FI_NAME_MAX,  "%d",
-					    var_port + (int)j);
-
-			check_host = (len_host > 0 && len_host < FI_NAME_MAX);
-			check_port = (len_port > 0 && len_port < FI_NAME_MAX);
-
-			if (check_port && check_host) {
-				ret = fi_ibv_rdm_av_insertsvc(av, tmp_host,
-							      tmp_port, fi_addr,
-							      flags, context);
-				if (ret == 1)
-					success++;
-				else
-					err_code = ret;
-			} else {
-				VERBS_WARN(FI_LOG_AV,
-					   "fi_av_insertsym: %s is invalid\n",
-					   (!check_port ?
-					    (!check_host ?
-					     "node and service weren't" :
-					     "service wasn't") :
-					    ("node wasn't")));
-				err_code = FI_ETOOSMALL;
-			}
-		}
-	}
-	return ((success > 0) ? success : err_code);
-}
-
-static int fi_ibv_rdm_av_lookup(struct fid_av *av_fid, fi_addr_t fi_addr,
-				void *addr, size_t *addrlen)
-{
-	struct fi_ibv_av *av = container_of(av_fid, struct fi_ibv_av, av_fid);
-	struct fi_ibv_rdm_av_entry *av_entry = NULL;
-
-	if (fi_addr == FI_ADDR_NOTAVAIL)
-		return -FI_EINVAL;
-
-	if (av->type == FI_AV_MAP)
-		av_entry = (struct fi_ibv_rdm_av_entry *) fi_addr;
-	else /* (av->type == FI_AV_TABLE) */
-		av_entry = av->domain->rdm_cm->av_table[fi_addr];
-
-	memcpy(addr, &av_entry->addr, MIN(*addrlen, sizeof(av_entry->addr)));
-	*addrlen = sizeof(av_entry->addr);
-
-	return 0;
-}
-
-static int fi_ibv_rdm_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr,
-                                size_t count, uint64_t flags)
-{
-	struct fi_ibv_av *av = container_of(av_fid, struct fi_ibv_av, av_fid);
-	struct fi_ibv_rdm_av_entry *av_entry = NULL;
-	int ret = FI_SUCCESS;
-	int err = FI_SUCCESS;
-	size_t i;
-
-	if(av->flags & FI_EVENT && !av->eq)
-		return -FI_ENOEQ;
-
-	if (!fi_addr || (av->type != FI_AV_MAP && av->type != FI_AV_TABLE))
-		return -FI_EINVAL;
-
-	pthread_mutex_lock(&av->domain->rdm_cm->cm_lock);
-	for (i = 0; i < count; i++) {
-
-		if (fi_addr[i] == FI_ADDR_NOTAVAIL)
-			continue;
-
-		if (av->type == FI_AV_MAP)
-			av_entry = (struct fi_ibv_rdm_av_entry *)fi_addr[i];
-		else /* (av->type == FI_AV_TABLE) */
-			av_entry = av->domain->rdm_cm->av_table[fi_addr[i]];
-
-		VERBS_INFO(FI_LOG_AV, "av_remove conn - %p; addr %s:%u\n",
-			   av_entry, inet_ntoa(av_entry->addr.sin_addr),
-			   ntohs(av_entry->addr.sin_port));
-
-		err = fi_ibv_rdm_start_overall_disconnection(av_entry);
-		ret = (ret == FI_SUCCESS) ? err : ret;
-		/* do not destroy connection here because we may
-		 * get WC for this connection. just move connection
-		 * to list of av-removed objects to clean later */
-
-		/* TODO: add cleaning into av_insert */
-		HASH_DEL(av->domain->rdm_cm->av_hash, av_entry);
-		slist_insert_tail(&av_entry->removed_next,
-				  &av->domain->rdm_cm->av_removed_entry_head);
-	}
-	pthread_mutex_unlock(&av->domain->rdm_cm->cm_lock);
-	return ret;
-}
-
-static const char *fi_ibv_rdm_av_straddr(struct fid_av *av, const void *addr,
-					 char *buf, size_t *len)
-{
-	return ofi_straddr(buf, len, FI_SOCKADDR, addr);
-}
-
-static struct fi_ops_av fi_ibv_rdm_av_ops = {
-	.size = sizeof(struct fi_ops_av),
-	.insert = fi_ibv_rdm_av_insert,
-	.insertsvc = fi_ibv_rdm_av_insertsvc,
-	.insertsym = fi_ibv_rdm_av_insertsym,
-	.remove = fi_ibv_rdm_av_remove,
-	.lookup = fi_ibv_rdm_av_lookup,
-	.straddr = fi_ibv_rdm_av_straddr,
-};
-
-struct fi_ops_av *fi_ibv_rdm_set_av_ops(void)
-{
-	return &fi_ibv_rdm_av_ops;
-}
-
-static int fi_ibv_rdm_av_close(fid_t fid)
-{
-	struct fi_ibv_av *av = container_of(fid, struct fi_ibv_av, av_fid.fid);
-	free(av);
-	return 0;
-}
-
-static struct fi_ops fi_ibv_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = fi_ibv_rdm_av_close,
-	.bind = fi_no_bind,
-};
-
-static inline struct fi_ibv_rdm_av_entry *
-fi_ibv_rdm_av_tbl_idx_to_av_entry(struct fi_ibv_rdm_ep *ep, fi_addr_t addr)
-{
-	return (addr == FI_ADDR_UNSPEC) ? NULL :
-		ep->domain->rdm_cm->av_table[addr];
-}
-
-static inline struct fi_ibv_rdm_av_entry *
-fi_ibv_rdm_av_map_addr_to_av_entry(struct fi_ibv_rdm_ep *ep, fi_addr_t addr)
-{
-	return (struct fi_ibv_rdm_av_entry *)
-		(addr == FI_ADDR_UNSPEC ? NULL : (void *)(uintptr_t)addr);
-}
-
-static inline fi_addr_t
-fi_ibv_rdm_av_entry_to_av_tbl_idx(struct fi_ibv_rdm_ep *ep,
-				  struct fi_ibv_rdm_av_entry *av_entry)
-{
-	size_t i;
-
-	for (i = 0; i < ep->av->used; i++) {
-		if (ep->domain->rdm_cm->av_table[i] == av_entry) {
-			return i;
-		}
-	}
-
-	return FI_ADDR_UNSPEC;
-}
-
-static inline fi_addr_t
-fi_ibv_rdm_av_entry_to_av_map_addr(struct fi_ibv_rdm_ep *ep,
-				   struct fi_ibv_rdm_av_entry *av_entry)
-{
-	return (av_entry == NULL) ? FI_ADDR_UNSPEC :
-	       (fi_addr_t)(uintptr_t)av_entry;
-}
-
-static inline fi_addr_t
-fi_ibv_rdm_conn_to_av_tbl_idx(struct fi_ibv_rdm_ep *ep,
-			      struct fi_ibv_rdm_conn *conn)
-{
-	if (conn == NULL)
-		return FI_ADDR_UNSPEC;
-	return fi_ibv_rdm_av_entry_to_av_tbl_idx(ep, conn->av_entry);
-}
-
-static inline fi_addr_t
-fi_ibv_rdm_conn_to_av_map_addr(struct fi_ibv_rdm_ep *ep,
-			       struct fi_ibv_rdm_conn *conn)
-{
-    return fi_ibv_rdm_av_entry_to_av_map_addr(ep, conn->av_entry);
-}
-
-/* Must call with `rdm_cm::cm_lock` held */
-static inline struct fi_ibv_rdm_conn *
-fi_ibv_rdm_conn_entry_alloc(struct fi_ibv_rdm_av_entry *av_entry,
-			    struct fi_ibv_rdm_ep *ep)
-{
-	struct fi_ibv_rdm_conn *conn;
-
-	if (ofi_memalign((void**) &conn,
-			 FI_IBV_MEM_ALIGNMENT,
-			 sizeof(*conn)))
-		return NULL;
-	memset(conn, 0, sizeof(*conn));
-	memcpy(&conn->addr, &av_entry->addr,
-	       FI_IBV_RDM_DFLT_ADDRLEN);
-	conn->ep = ep;
-	conn->av_entry = av_entry;
-	conn->state = FI_VERBS_CONN_ALLOCATED;
-	dlist_init(&conn->postponed_requests_head);
-	HASH_ADD(hh, av_entry->conn_hash, ep,
-		 sizeof(struct fi_ibv_rdm_ep *), conn);
-
-	/* Initiates connection to the peer */
-	fi_ibv_rdm_start_connection(ep, conn);
-
-	return conn;
-}
-
-static inline struct fi_ibv_rdm_conn *
-fi_ibv_rdm_av_map_addr_to_conn_add_new_conn(struct fi_ibv_rdm_ep *ep,
-					    fi_addr_t addr)
-{
-	struct fi_ibv_rdm_av_entry *av_entry =
-		fi_ibv_rdm_av_map_addr_to_av_entry(ep, addr);
-	if (av_entry) {
-		struct fi_ibv_rdm_conn *conn;
-		pthread_mutex_lock(&ep->domain->rdm_cm->cm_lock);
-		HASH_FIND(hh, av_entry->conn_hash,
-			  &ep, sizeof(struct fi_ibv_rdm_ep *), conn);
-		if (OFI_UNLIKELY(!conn))
-			conn = fi_ibv_rdm_conn_entry_alloc(av_entry, ep);
-		pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-		return conn;
-	}
-
-	return NULL;
-}
-
-static inline struct fi_ibv_rdm_conn *
-fi_ibv_rdm_av_tbl_idx_to_conn_add_new_conn(struct fi_ibv_rdm_ep *ep,
-					   fi_addr_t addr)
-{
-	struct fi_ibv_rdm_av_entry *av_entry =
-		fi_ibv_rdm_av_tbl_idx_to_av_entry(ep, addr);
-	if (av_entry) {
-		struct fi_ibv_rdm_conn *conn;
-		pthread_mutex_lock(&ep->domain->rdm_cm->cm_lock);
-		HASH_FIND(hh, av_entry->conn_hash,
-			  &ep, sizeof(struct fi_ibv_rdm_ep *), conn);
-		if (OFI_UNLIKELY(!conn))
-			conn = fi_ibv_rdm_conn_entry_alloc(av_entry, ep);
-		pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-		return conn;
-	}
-
-	return NULL;
-}
-
-int fi_ibv_rdm_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
-			struct fid_av **av_fid, void *context)
-{
-	struct fi_ibv_domain *fid_domain;
-	struct fi_ibv_av *av;
-	size_t count = 64;
-
-	fid_domain = container_of(domain, struct fi_ibv_domain, util_domain.domain_fid);
-
-	if (!attr)
-		return -FI_EINVAL;
-
-	if (attr->name) {
-		VERBS_WARN(FI_LOG_AV,
-			   "Shared AV is not implemented\n");
-		return -FI_ENOSYS;
-	}
-
-	switch (attr->type) {
-	case FI_AV_UNSPEC:
-		attr->type = FI_AV_MAP;
-	case FI_AV_MAP:
-	case FI_AV_TABLE:
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	if (attr->count)
-		count = attr->count;
-
-	av = calloc(1, sizeof *av);
-	if (!av)
-		return -ENOMEM;
-
-	assert(fid_domain->ep_type == FI_EP_RDM);
-	av->domain = fid_domain;
-	av->type = attr->type;
-	av->count = count;
-	av->flags = attr->flags;
-	av->used = 0;
-
-	if (av->type == FI_AV_TABLE && av->count > 0) {
-		av->domain->rdm_cm->av_table =
-			calloc(av->count,
-			       sizeof(*av->domain->rdm_cm->av_table));
-		if (!av->domain->rdm_cm->av_table) {
-			free(av);
-			return -ENOMEM;
-		}
-	}
-
-	if (av->type == FI_AV_MAP) {
-		av->addr_to_av_entry = fi_ibv_rdm_av_map_addr_to_av_entry;
-		av->av_entry_to_addr = fi_ibv_rdm_av_entry_to_av_map_addr;
-		av->addr_to_conn = fi_ibv_rdm_av_map_addr_to_conn_add_new_conn;
-		av->conn_to_addr = fi_ibv_rdm_conn_to_av_map_addr;
-	} else /* if (av->type == FI_AV_TABLE) */ {
-		av->addr_to_av_entry = fi_ibv_rdm_av_tbl_idx_to_av_entry;
-		av->av_entry_to_addr = fi_ibv_rdm_av_entry_to_av_tbl_idx;
-		av->addr_to_conn = fi_ibv_rdm_av_tbl_idx_to_conn_add_new_conn;
-		av->conn_to_addr = fi_ibv_rdm_conn_to_av_tbl_idx;
-	}
-
-	av->av_fid.fid.fclass = FI_CLASS_AV;
-	av->av_fid.fid.context = context;
-	av->av_fid.fid.ops = &fi_ibv_fi_ops;
-
-	av->av_fid.ops = fi_ibv_rdm_set_av_ops();
-
-	*av_fid = &av->av_fid;
-	return 0;
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_cq_ep_rdm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_cq_ep_rdm.c
deleted file mode 100644
index e73199f76..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_cq_ep_rdm.c
+++ /dev/null
@@ -1,364 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <stdlib.h>
-
-#include <ofi_enosys.h>
-#include <ofi_list.h>
-#include "../fi_verbs.h"
-#include "verbs_queuing.h"
-
-static ssize_t fi_ibv_rdm_tagged_cq_readfrom(struct fid_cq *cq, void *buf,
-                                             size_t count, fi_addr_t * src_addr)
-{
-	struct fi_ibv_rdm_cq *_cq = 
-		container_of(cq, struct fi_ibv_rdm_cq, cq_fid);
-	size_t ret = 0;
-	struct fi_ibv_rdm_request *cq_entry =
-		count ? fi_ibv_rdm_take_first_from_cq(_cq) : NULL;;
-
-	for ( ; cq_entry; cq_entry = (ret < count) ?
-				     fi_ibv_rdm_take_first_from_cq(_cq) : NULL) {
-		VERBS_DBG(FI_LOG_CQ,
-			  "\t\t-> found in ready: %p op_ctx %p, len %lu, tag 0x%" PRIx64 "\n",
-			  cq_entry, cq_entry->context, cq_entry->len,
-			  cq_entry->minfo.tag);
-
-		src_addr[ret] =
-			_cq->ep->av->conn_to_addr(_cq->ep, cq_entry->minfo.conn);
-		_cq->read_entry(cq_entry, ret, buf);
-
-		if (cq_entry->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE) {
-			FI_IBV_RDM_DBG_REQUEST("to_pool: ", cq_entry, 
-						FI_LOG_DEBUG);
-			util_buf_release(
-				cq_entry->ep->fi_ibv_rdm_request_pool,
-				cq_entry);
-		} else {
-			cq_entry->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-		}
-		ret++;
-	}
-
-	if (ret == 0) {
-		if (fi_ibv_rdm_tagged_poll(_cq->ep) < 0)
-			VERBS_INFO(FI_LOG_CQ, "fi_ibv_rdm_tagged_poll failed\n");
-		if (!dlist_empty(&_cq->request_errcq))
-			ret = -FI_EAVAIL;
-	}
-
-	return !ret ? -FI_EAGAIN : ret;
-}
-
-static ssize_t fi_ibv_rdm_tagged_cq_read(struct fid_cq *cq, void *buf,
-                                         size_t count)
-{
-	struct fi_ibv_rdm_cq *_cq =
-		container_of(cq, struct fi_ibv_rdm_cq, cq_fid);
-	const size_t _count = _cq->read_bunch_size;
-	fi_addr_t addr[_count];
-
-	return fi_ibv_rdm_tagged_cq_readfrom(cq, buf, MIN(_count, count), addr);
-}
-
-static ssize_t fi_ibv_rdm_cq_sreadfrom(struct fid_cq *cq, void *buf,
-				       size_t count, fi_addr_t *src_addr,
-				       const void *cond, int timeout)
-{
-	size_t threshold = count;
-	uint64_t time_limit =
-		((timeout < 0) ? SIZE_MAX : (fi_gettime_ms() + timeout));
-	size_t counter = 0;
-	ssize_t ret = 0;
-	struct fi_ibv_rdm_cq *_cq = container_of(cq, struct fi_ibv_rdm_cq,
-						 cq_fid);
-	switch (_cq->wait_cond) {
-	case FI_CQ_COND_THRESHOLD:
-		threshold = MIN((uintptr_t) cond, threshold);
-	case FI_CQ_COND_NONE:
-		break;
-	default:
-		assert(0);
-		return -FI_EOTHER;
-	}
-
-	do {
-		ret = fi_ibv_rdm_tagged_cq_readfrom(cq,
-						    ((char *)buf +
-							(counter * _cq->entry_size)),
-						    threshold - counter,
-						    src_addr);
-		counter += (ret > 0) ? ret : 0;
-	} while ((ret >= 0 || ret == -FI_EAGAIN) &&
-		 (counter < threshold) &&
-		 (fi_gettime_ms() < time_limit));
-
-	if (counter != 0 && ret >= 0) {
-		ret = counter;
-	} else if (ret == 0) {
-		ret = -FI_EAGAIN;
-	}
-
-	return ret;
-}
-
-static ssize_t fi_ibv_rdm_cq_sread(struct fid_cq *cq, void *buf, size_t count,
-				   const void *cond, int timeout)
-{
-	struct fi_ibv_rdm_cq *_cq =
-		container_of(cq, struct fi_ibv_rdm_cq, cq_fid);
-	size_t chunk		= MIN(_cq->read_bunch_size, count);
-	uint64_t time_limit	= fi_gettime_ms() + timeout;
-	size_t rest		= count;
-	fi_addr_t addr[chunk];
-	ssize_t	ret;
-
-	do {
-		ret = fi_ibv_rdm_cq_sreadfrom(cq, buf, chunk, addr, cond,
-					      timeout);
-		if (ret > 0) {
-			rest -= ret;
-			chunk = MIN(chunk, rest);
-		}
-	} while (((ret >=0) && (rest != 0)) ||
-		 (timeout >= 0 && fi_gettime_ms() < time_limit));
-
-	return (count != rest) ? (count - rest) : ret;
-}
-
-static const char *
-fi_ibv_rdm_cq_strerror(struct fid_cq *eq, int prov_errno, const void *err_data,
-		       char *buf, size_t len)
-{
-	/* TODO: */
-	if (buf && len)
-		strncpy(buf, ibv_wc_status_str(prov_errno), len);
-	return ibv_wc_status_str(prov_errno);
-}
-
-static ssize_t
-fi_ibv_rdm_cq_readerr(struct fid_cq *cq_fid, struct fi_cq_err_entry *entry,
-                             uint64_t flags)
-{
-	ssize_t ret = 0;
-	uint32_t api_version;
-	struct fi_ibv_rdm_cq *cq =
-		container_of(cq_fid, struct fi_ibv_rdm_cq, cq_fid.fid);
-
-	struct fi_ibv_rdm_request *err_request = 
-		fi_ibv_rdm_take_first_from_errcq(cq);
-
-	if (err_request) {
-		entry->op_context = err_request->context;
-		entry->flags = (err_request->comp_flags & ~FI_COMPLETION);
-		entry->len = err_request->len;
-		entry->buf = err_request->unexp_rbuf;
-		entry->data = err_request->imm;
-		entry->tag = err_request->minfo.tag;
-		entry->olen = -1; /* TODO: */
-		entry->err = err_request->state.err;
-		entry->prov_errno = -err_request->state.err;
-
-		api_version = cq->domain->util_domain.fabric->fabric_fid.api_version;
-
-		if (!entry->err_data_size)
-			entry->err_data = NULL;
-		else if (FI_VERSION_GE(api_version, FI_VERSION(1, 5)))
-			entry->err_data_size = 0;
-
-		if (err_request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE) {
-			FI_IBV_RDM_DBG_REQUEST("to_pool: ", err_request,
-						FI_LOG_DEBUG);
-			util_buf_release(
-				err_request->ep->fi_ibv_rdm_request_pool,
-				err_request);
-		} else {
-			err_request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-		}
-
-		ret++;
-	} else {
-		return -FI_EAGAIN;
-	}
-
-	return ret;
-}
-
-static struct fi_ops_cq fi_ibv_rdm_cq_ops = {
-	.size = sizeof(struct fi_ops_cq),
-	.read = fi_ibv_rdm_tagged_cq_read,
-	.readfrom = fi_ibv_rdm_tagged_cq_readfrom,
-	.readerr = fi_ibv_rdm_cq_readerr,
-	.sread = fi_ibv_rdm_cq_sread,
-	.sreadfrom = fi_ibv_rdm_cq_sreadfrom,
-	.strerror = fi_ibv_rdm_cq_strerror
-};
-
-static int fi_ibv_rdm_cq_close(fid_t fid)
-{
-	struct fi_ibv_rdm_cq *cq =
-		container_of(fid, struct fi_ibv_rdm_cq, cq_fid.fid);
-
-	if(cq->ep) {
-		return -FI_EBUSY;
-	}
-
-	/* TODO: move queues & related pools cleanup from close EP */
-	/* fi_ibv_rdm_clean_queues(); */
-
-	free(cq);
-
-	return FI_SUCCESS;
-}
-
-static struct fi_ops fi_ibv_rdm_cq_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = fi_ibv_rdm_cq_close,
-	.bind = fi_no_bind,
-	.control = fi_no_control,
-	.ops_open = fi_no_ops_open,
-};
-
-static void fi_ibv_rdm_cq_read_context_entry(struct fi_ibv_rdm_request *cq_entry,
-					     int i, void *buf)
-{
-	struct fi_cq_entry *entry = buf;
-
-	entry[i].op_context = cq_entry->context;
-}
-
-static void fi_ibv_rdm_cq_read_msg_entry(struct fi_ibv_rdm_request *cq_entry,
-					 int i, void *buf)
-{
-	struct fi_cq_msg_entry *entry = buf;
-
-	entry[i].op_context = cq_entry->context;
-	entry[i].flags = (cq_entry->comp_flags & ~FI_COMPLETION);
-	entry[i].len = cq_entry->len;
-}
-
-static void fi_ibv_rdm_cq_read_data_entry(struct fi_ibv_rdm_request *cq_entry,
-					  int i, void *buf)
-{
-	struct fi_cq_data_entry *entry = buf;
-
-	entry[i].op_context = cq_entry->context;
-	entry[i].flags = (cq_entry->comp_flags & ~FI_COMPLETION);
-	entry[i].len = cq_entry->len;
-	entry[i].buf = (cq_entry->comp_flags & FI_TRANSMIT) ?
-			cq_entry->src_addr : cq_entry->dest_buf;
-	entry[i].data = cq_entry->imm;
-}
-
-static void fi_ibv_rdm_cq_read_tagged_entry(struct fi_ibv_rdm_request *cq_entry,
-					    int i, void *buf)
-{
-	struct fi_cq_tagged_entry *entry = buf;
-
-	entry[i].op_context = cq_entry->context;
-	entry[i].flags = (cq_entry->comp_flags & ~FI_COMPLETION);
-	entry[i].len = cq_entry->len;
-	entry[i].buf = (cq_entry->comp_flags & FI_TRANSMIT) ?
-			cq_entry->src_addr : cq_entry->dest_buf;
-	entry[i].data = cq_entry->imm;
-	entry[i].tag = cq_entry->minfo.tag;
-}
-
-int fi_ibv_rdm_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
-		   struct fid_cq **cq, void *context)
-{
-	struct fi_ibv_rdm_cq *_cq;
-	int ret;
-
-	_cq = calloc(1, sizeof *_cq);
-	if (!_cq)
-		return -FI_ENOMEM;
-
-	_cq->domain = container_of(domain, struct fi_ibv_domain,
-				   util_domain.domain_fid);
-	assert(_cq->domain->ep_type == FI_EP_RDM);
-
-	switch (attr->wait_obj) {
-	case FI_WAIT_NONE:
-	case FI_WAIT_UNSPEC:
-		break;
-	case FI_WAIT_SET:
-	case FI_WAIT_FD:
-	case FI_WAIT_MUTEX_COND:
-	default:
-		assert(0);
-		ret = -FI_ENOSYS;
-		goto err;
-	}
-
-	_cq->flags |= attr->flags;
-	_cq->wait_cond = attr->wait_cond;
-	_cq->cq_fid.fid.fclass = FI_CLASS_CQ;
-	_cq->cq_fid.fid.context = context;
-	_cq->cq_fid.fid.ops = &fi_ibv_rdm_cq_fi_ops;
-	_cq->cq_fid.ops = &fi_ibv_rdm_cq_ops;
-
-	switch (attr->format) {
-	case FI_CQ_FORMAT_CONTEXT:
-		_cq->entry_size = sizeof(struct fi_cq_entry);
-		_cq->read_entry = fi_ibv_rdm_cq_read_context_entry;
-		break;
-	case FI_CQ_FORMAT_MSG:
-		_cq->entry_size = sizeof(struct fi_cq_msg_entry);
-		_cq->read_entry = fi_ibv_rdm_cq_read_msg_entry;
-		break;
-	case FI_CQ_FORMAT_DATA:
-		_cq->entry_size = sizeof(struct fi_cq_data_entry);
-		_cq->read_entry = fi_ibv_rdm_cq_read_data_entry;
-		break;
-	case FI_CQ_FORMAT_UNSPEC:
-	case FI_CQ_FORMAT_TAGGED:
-		_cq->entry_size = sizeof(struct fi_cq_tagged_entry);
-		_cq->read_entry = fi_ibv_rdm_cq_read_tagged_entry;
-		break;
-	default:
-		ret = -FI_ENOSYS;
-		goto err;
-	}
-
-	dlist_init(&_cq->request_cq);
-	dlist_init(&_cq->request_errcq);
-
-	_cq->read_bunch_size = fi_ibv_gl_data.cqread_bunch_size;
-
-	*cq = &_cq->cq_fid;
-	return 0;
-
-err:
-	free(_cq);
-	return ret;
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_ep_rdm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_ep_rdm.c
deleted file mode 100644
index 96f8b6b67..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_ep_rdm.c
+++ /dev/null
@@ -1,633 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- * Copyright (c) 2015 Los Alamos National Security, LLC. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <stdlib.h>
-#include <arpa/inet.h>
-#include <rdma/rdma_cma.h>
-
-#include <ofi_list.h>
-#include <ofi_file.h>
-#include <ofi_enosys.h>
-#include "../fi_verbs.h"
-#include "verbs_queuing.h"
-#include "verbs_utils.h"
-
-
-extern struct fi_ops_tagged fi_ibv_rdm_tagged_ops;
-extern struct fi_ops_cm fi_ibv_rdm_tagged_ep_cm_ops;
-extern struct fi_provider fi_ibv_prov;
-extern struct fi_ops_msg fi_ibv_rdm_ep_msg_ops;
-extern struct fi_ops_rma fi_ibv_rdm_ep_rma_ops;
-
-static int fi_ibv_rdm_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
-{
-	struct fi_ibv_rdm_ep *ep;
-	struct fi_ibv_rdm_cq *cq;
-	struct fi_ibv_av *av;
-	struct fi_ibv_rdm_cntr *cntr;
-	int ret;
-
-	ep = container_of(fid, struct fi_ibv_rdm_ep, ep_fid.fid);
-	ret = ofi_ep_bind_valid(&fi_ibv_prov, bfid, flags);
-	if (ret)
-		return ret;
-
-	switch (bfid->fclass) {
-	case FI_CLASS_CQ:
-		cq = container_of(bfid, struct fi_ibv_rdm_cq, cq_fid);
-		if (ep->domain != cq->domain) {
-			return -FI_EINVAL;
-		}
-
-		if (flags & FI_RECV) {
-			if (ep->fi_rcq)
-				return -EINVAL;
-			ep->fi_rcq = cq;
-			ep->rx_selective_completion = 
-				(flags & FI_SELECTIVE_COMPLETION) ? 1 : 0;
-		}
-
-		if (flags & FI_SEND) {
-			if (ep->fi_scq)
-				return -EINVAL;
-			ep->fi_scq = cq;
-			ep->tx_selective_completion = 
-				(flags & FI_SELECTIVE_COMPLETION) ? 1 : 0;
-		}
-
-		/* TODO: this is wrong. CQ to EP is 1:n */
-		cq->ep = ep;
-		break;
-	case FI_CLASS_AV:
-		av = container_of(bfid, struct fi_ibv_av, av_fid.fid);
-		if (ep->domain != av->domain)
-			return -FI_EINVAL;
-		ep->av = av;
-		break;
-	case FI_CLASS_CNTR:
-		cntr = container_of(bfid, struct fi_ibv_rdm_cntr, fid.fid);
-		if (ep->domain != cntr->domain) {
-			return -FI_EINVAL;
-		}
-
-		if ((flags & FI_REMOTE_READ) || (flags & FI_REMOTE_WRITE)) {
-			return -FI_ENOSYS;
-		}
-
-		if (flags & FI_SEND) {
-			ep->send_cntr = cntr;
-			ofi_atomic_inc32(&ep->send_cntr->ep_ref);
-		}
-		if (flags & FI_RECV) {
-			ep->recv_cntr = cntr;
-			ofi_atomic_inc32(&ep->recv_cntr->ep_ref);
-		}
-		if (flags & FI_READ) {
-			ep->read_cntr = cntr;
-			ofi_atomic_inc32(&ep->read_cntr->ep_ref);
-		}
-		if (flags & FI_WRITE) {
-			ep->write_cntr = cntr;
-			ofi_atomic_inc32(&ep->write_cntr->ep_ref);
-		}
-
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	return 0;
-}
-
-static ssize_t fi_ibv_rdm_cancel(fid_t fid, void *ctx)
-{
-	struct fi_context *context = (struct fi_context *)ctx;
-	struct fi_ibv_rdm_ep *ep_rdm = 
-		container_of(fid, struct fi_ibv_rdm_ep, ep_fid);
-	int err = -FI_ENOENT;
-
-	if (!ep_rdm->domain)
-		return -EBADF;
-
-	if (!context)
-		return -EINVAL;
-
-	if (context->internal[0] == NULL)
-		return 0;
-
-	struct fi_ibv_rdm_request *request = context->internal[0];
-
-	VERBS_DBG(FI_LOG_EP_DATA,
-		  "ep_cancel, match %p, tag 0x%" PRIx64 ", len %" PRIu64 ", ctx %p\n",
-		  request, request->minfo.tag, request->len, request->context);
-
-	struct dlist_entry *found =
-		dlist_find_first_match(&ep_rdm->fi_ibv_rdm_posted_queue,
-					fi_ibv_rdm_req_match, request);
-	if (found) {
-		uint32_t posted_recvs;
-
-		assert(container_of(found, struct fi_ibv_rdm_request,
-				    queue_entry) == request);
-		request->context->internal[0] = NULL;
-		posted_recvs = fi_ibv_rdm_remove_from_posted_queue(request, ep_rdm);
-		(void)posted_recvs;
-		VERBS_DBG(FI_LOG_EP_DATA, "\t\t-> SUCCESS, post recv %"PRIu32"\n",
-			  posted_recvs);
-		err = 0;
-	} else {
-		request = fi_ibv_rdm_take_first_match_from_postponed_queue
-		    (fi_ibv_rdm_req_match, request, ep_rdm);
-		if (request) {
-			fi_ibv_rdm_remove_from_postponed_queue(request);
-			err = 0;
-		}
-	}
-
-	if (!err) {
-		fi_ibv_rdm_cntr_inc_err(ep_rdm->recv_cntr);
-
-		if (request->comp_flags & FI_COMPLETION) {
-			fi_ibv_rdm_move_to_errcq(ep_rdm->fi_rcq, request,
-						 FI_ECANCELED);
-		}
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-	}
-
-	return err;
-}
-
-static int fi_ibv_rdm_getopt(fid_t fid, int level, int optname, void *optval,
-			     size_t * optlen)
-{
-	struct fi_ibv_rdm_ep *ep_rdm = 
-		container_of(fid, struct fi_ibv_rdm_ep, ep_fid);
-
-	if (level != FI_OPT_ENDPOINT) {
-		return -FI_ENOPROTOOPT;
-	}
-
-	if (optname != FI_OPT_MIN_MULTI_RECV) {
-		return -FI_ENOPROTOOPT;
-	}
-
-	*(size_t *)optval = ep_rdm->min_multi_recv_size;
-	*optlen = sizeof(size_t);
-
-	return 0;
-}
-
-static int fi_ibv_rdm_setopt(fid_t fid, int level, int optname,
-			     const void *optval, size_t optlen)
-{
-	struct fi_ibv_rdm_ep *ep_rdm =
-		container_of(fid, struct fi_ibv_rdm_ep, ep_fid);
-
-	if (level != FI_OPT_ENDPOINT) {
-		return -FI_ENOPROTOOPT;
-	}
-
-	if (optname != FI_OPT_MIN_MULTI_RECV) {
-		return -FI_ENOPROTOOPT;
-	}
-
-	ep_rdm->min_multi_recv_size = *(size_t *)optval;
-	return 0;
-}
-
-static int fi_ibv_rdm_tagged_control(fid_t fid, int command, void *arg)
-{
-	switch (command) {
-	case FI_ENABLE:
-		return 0;
-	default:
-		return -FI_ENOSYS;
-	}
-
-	return 0;
-}
-
-struct fi_ops_ep fi_ibv_rdm_ep_base_ops = {
-	.size = sizeof(struct fi_ops_ep),
-	.cancel = fi_ibv_rdm_cancel,
-	.getopt = fi_ibv_rdm_getopt,
-	.setopt = fi_ibv_rdm_setopt,
-	.tx_ctx = fi_no_tx_ctx,
-	.rx_ctx = fi_no_rx_ctx,
-	.rx_size_left = fi_no_rx_size_left,
-	.tx_size_left = fi_no_tx_size_left,
-};
-
-static int fi_ibv_rdm_ep_match(struct slist_entry *item,
-			       const void *ep)
-{
-	const struct fi_ibv_rdm_ep *ep_obj = (struct fi_ibv_rdm_ep *)ep;
-	return (item == &ep_obj->list_entry);
-}
-
-static int fi_ibv_rdm_ep_close(fid_t fid)
-{
-	int ret = FI_SUCCESS;
-	int err = FI_SUCCESS;
-	struct fi_ibv_rdm_ep *ep =
-		container_of(fid, struct fi_ibv_rdm_ep, ep_fid.fid);
-	struct fi_ibv_rdm_av_entry *av_entry = NULL, *tmp = NULL;
-	struct slist_entry *item, *prev_item;
-	struct fi_ibv_rdm_conn *conn = NULL;
-
-	if (ep->fi_scq)
-		ep->fi_scq->ep = NULL;
-	if (ep->fi_rcq)
-		ep->fi_rcq->ep = NULL;
-
-	ep->is_closing = 1;
-
-	/* All posted sends are waiting local completions */
-	while (ep->posted_sends > 0 && ep->num_active_conns > 0)
-		fi_ibv_rdm_tagged_poll(ep);
-
-	if (ep->send_cntr) {
-		ofi_atomic_dec32(&ep->send_cntr->ep_ref);
-		ep->send_cntr = 0;
-	}
-
-	if (ep->recv_cntr) {
-		ofi_atomic_dec32(&ep->recv_cntr->ep_ref);
-		ep->recv_cntr = 0;
-	}
-
-	if (ep->read_cntr) {
-		ofi_atomic_dec32(&ep->read_cntr->ep_ref);
-		ep->read_cntr = 0;
-	}
-
-	if (ep->write_cntr) {
-		ofi_atomic_dec32(&ep->write_cntr->ep_ref);
-		ep->write_cntr = 0;
-	}
-
-	slist_remove_first_match(&ep->domain->ep_list,
-				 fi_ibv_rdm_ep_match, ep);
-
-	HASH_ITER(hh, ep->domain->rdm_cm->av_hash, av_entry, tmp) {
-		pthread_mutex_lock(&ep->domain->rdm_cm->cm_lock);
-		HASH_FIND(hh, av_entry->conn_hash, &ep,
-			  sizeof(struct fi_ibv_rdm_ep *), conn);
-		if (conn) {
-			switch (conn->state) {
-			case FI_VERBS_CONN_ALLOCATED:
-			case FI_VERBS_CONN_ESTABLISHED:
-				ret = fi_ibv_rdm_start_disconnection(conn);
-				pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-				break;
-			case FI_VERBS_CONN_STARTED:
-				pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-				/* No need to hold `rdm_cm::cm_lock` during
-				 * CM progressing of the EP */
-				while (conn->state != FI_VERBS_CONN_ESTABLISHED &&
-				       conn->state != FI_VERBS_CONN_REJECTED &&
-				       conn->state != FI_VERBS_CONN_CLOSED) {
-					ret = fi_ibv_rdm_cm_progress(ep);
-					if (ret) {
-						VERBS_INFO(FI_LOG_AV, 
-							   "cm progress failed\n");
-						break;
-					}
-				}
-				break;
-			default:
-				pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-				break;
-			}
-		} else {
-			pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-		}
-	}
-
-        /* ok, all connections are initiated to disconnect. now wait
-	 * till all connections are switch to state 'closed' */
-	HASH_ITER(hh, ep->domain->rdm_cm->av_hash, av_entry, tmp) {
-		pthread_mutex_lock(&ep->domain->rdm_cm->cm_lock);
-		HASH_FIND(hh, av_entry->conn_hash, &ep,
-			  sizeof(struct fi_ibv_rdm_ep *), conn);
-		pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-		if (conn) {
-			/* No need to hold `rdm_cm::cm_lock` during
-			 * polling of receive CQ */
-			while(conn->state != FI_VERBS_CONN_CLOSED &&
-			      conn->state != FI_VERBS_CONN_ALLOCATED) {
-				fi_ibv_rdm_tagged_poll_recv(ep);
-				err = fi_ibv_rdm_cm_progress(ep);
-				if (err) {
-					VERBS_INFO(FI_LOG_AV, "cm progress failed\n");
-					ret = (ret == FI_SUCCESS) ? err : ret;
-				}
-			}
-		}
-	}
-
-        /* now destroy all connections that wasn't removed from HASH */
-	HASH_ITER(hh, ep->domain->rdm_cm->av_hash, av_entry, tmp) {
-		pthread_mutex_lock(&ep->domain->rdm_cm->cm_lock);
-		HASH_FIND(hh, av_entry->conn_hash, &ep,
-			  sizeof(struct fi_ibv_rdm_ep *), conn);
-		if (conn) {
-			HASH_DEL(av_entry->conn_hash, conn);
-			pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-			/* No need to hold `rdm_cm::cm_lock` during
-			 * connection cleanup */
-			fi_ibv_rdm_conn_cleanup(conn);
-		} else {
-			pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-		}
-	}
-
-	/* now destroy all connection that was removed from HASH */
-	slist_foreach(&ep->domain->rdm_cm->av_removed_entry_head,
-		      item, prev_item) {
-		OFI_UNUSED(prev_item); /* Compiler complains about unused variable */
-		av_entry = container_of(item,
-					struct fi_ibv_rdm_av_entry,
-					removed_next);
-		pthread_mutex_lock(&ep->domain->rdm_cm->cm_lock);
-		HASH_FIND(hh, av_entry->conn_hash, &ep,
-			  sizeof(struct fi_ibv_rdm_ep *), conn);
-		if (conn) {
-			HASH_DEL(av_entry->conn_hash, conn);
-			pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-			/* No need to hold `rdm_cm::cm_lock` during
-			 * connection cleanup */
-			fi_ibv_rdm_conn_cleanup(conn);
-		} else {
-			pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-		}
-		/* do NOT free av_entry and do NOT remove from
-		 * the List of removed AV entries, becasue we need to
-		 * remove remaining connections during domain closure */
-	}
-
-	/* TODO: MUST be removed in DOMAIN_CLOSE */
-	/*assert(HASH_COUNT(av_entry->conn_hash) == 0 &&
-	       av_entry->conn_hash == NULL);*/
-	free(ep->domain->rdm_cm->av_table);
-
-	VERBS_INFO(FI_LOG_AV, "DISCONNECT complete\n");
-	assert(ep->scq && ep->rcq);
-	if (ibv_destroy_cq(ep->scq)) {
-		VERBS_INFO_ERRNO(FI_LOG_AV, "ep->scq: ibv_destroy_cq failed",
-				 errno);
-		ret = (ret == FI_SUCCESS) ? -errno : ret;
-	}
-
-	if (ibv_destroy_cq(ep->rcq)) {
-		VERBS_INFO_ERRNO(FI_LOG_AV, "ep->rcq: ibv_destroy_cq failed",
-				 errno);
-		ret = (ret == FI_SUCCESS) ? -errno : ret;
-	}
-
-	rdma_freeaddrinfo(ep->rai);
-
-	/* TODO: move queues & related pools cleanup to close CQ*/
-	fi_ibv_rdm_clean_queues(ep);
-
-	util_buf_pool_destroy(ep->fi_ibv_rdm_request_pool);
-	util_buf_pool_destroy(ep->fi_ibv_rdm_multi_request_pool);
-	util_buf_pool_destroy(ep->fi_ibv_rdm_extra_buffers_pool);
-	util_buf_pool_destroy(ep->fi_ibv_rdm_postponed_pool);
-
-	fi_freeinfo(ep->info);
-
-	free(ep);
-
-	return ret;
-}
-
-struct fi_ops fi_ibv_rdm_ep_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = fi_ibv_rdm_ep_close,
-	.bind = fi_ibv_rdm_ep_bind,
-	.control = fi_ibv_rdm_tagged_control,
-	.ops_open = fi_no_ops_open,
-};
-
-int fi_ibv_rdm_open_ep(struct fid_domain *domain, struct fi_info *info,
-			struct fid_ep **ep, void *context)
-{
-	struct fi_ibv_domain *_domain = 
-		container_of(domain, struct fi_ibv_domain, util_domain.domain_fid);
-	int ret = 0;
-
-	if (!info || !info->ep_attr || !info->domain_attr ||
-	    strncmp(_domain->verbs->device->name, info->domain_attr->name,
-		    strlen(_domain->verbs->device->name)))
-	{
-		return -FI_EINVAL;
-	}
-
-	struct fi_ibv_rdm_ep *_ep;
-	_ep = calloc(1, sizeof *_ep);
-	if (!_ep)
-		return -FI_ENOMEM;
-
-	_ep->info = fi_dupinfo(info);
-	if (!_ep->info) {
-		ret = -FI_ENOMEM;
-		goto err1;
-	}
-	_ep->domain = _domain;
-	_ep->ep_fid.fid.fclass = FI_CLASS_EP;
-	_ep->ep_fid.fid.context = context;
-	_ep->ep_fid.fid.ops = &fi_ibv_rdm_ep_ops;
-	_ep->ep_fid.ops = &fi_ibv_rdm_ep_base_ops;
-	_ep->ep_fid.cm = &fi_ibv_rdm_tagged_ep_cm_ops;
-	_ep->ep_fid.msg = &fi_ibv_rdm_ep_msg_ops;
-	_ep->ep_fid.rma = &fi_ibv_rdm_ep_rma_ops;
-	_ep->ep_fid.tagged = &fi_ibv_rdm_tagged_ops;
-	_ep->tx_selective_completion = 0;
-	_ep->rx_selective_completion = 0;
-	_ep->n_buffs = fi_ibv_gl_data.rdm.buffer_num;
-
-	VERBS_INFO(FI_LOG_EP_CTRL, "inject_size: %zu\n",
-		   info->tx_attr->inject_size);
-
-	_ep->rndv_threshold = info->tx_attr->inject_size;
-	_ep->iov_per_rndv_thr =
-		(_ep->rndv_threshold / sizeof(struct iovec));
-	VERBS_INFO(FI_LOG_EP_CTRL, "rndv_threshold: %d\n",
-		   _ep->rndv_threshold);
-
-	_ep->buff_len = rdm_buffer_size(info->tx_attr->inject_size);
-	VERBS_INFO(FI_LOG_EP_CTRL, "buff_len: %d\n", _ep->buff_len);
-
-	_ep->tx_op_flags = info->tx_attr->op_flags;
-	_ep->rx_op_flags = info->rx_attr->op_flags;
-	_ep->min_multi_recv_size = (_ep->rx_op_flags & FI_MULTI_RECV) ?
-				   info->tx_attr->inject_size : 0;
-	_ep->rndv_seg_size = fi_ibv_gl_data.rdm.rndv_seg_size;
-	_ep->rq_wr_depth = info->rx_attr->size;
-	/* one more outstanding slot for releasing eager buffers */
-	_ep->sq_wr_depth = _ep->n_buffs + 1;
-	if (!strncmp(fi_ibv_gl_data.rdm.eager_send_opcode,
-		     "IBV_WR_RDMA_WRITE_WITH_IMM",
-		     strlen("IBV_WR_RDMA_WRITE_WITH_IMM"))) {
-		_ep->eopcode = IBV_WR_RDMA_WRITE_WITH_IMM;
-	} else if (!strncmp(fi_ibv_gl_data.rdm.eager_send_opcode,
-			    "IBV_WR_SEND",
-			    strlen("IBV_WR_SEND"))) {
-		_ep->eopcode = IBV_WR_SEND;
-	} else {
-		VERBS_INFO(FI_LOG_CORE,
-			   "Invalid value of rdm_eager_send_opcode\n");
-		ret = -FI_EINVAL;
-		goto err2;
-	}
-
-	switch (info->ep_attr->protocol) {
-	case FI_PROTO_IB_RDM:
-		if (_ep->eopcode != IBV_WR_RDMA_WRITE_WITH_IMM &&
-		    _ep->eopcode != IBV_WR_SEND) {
-			VERBS_INFO(FI_LOG_CORE,
-				   "Unsupported eager operation code\n");
-			ret = -FI_ENODATA;
-			goto err2;
-		}
-		break;
-	case FI_PROTO_IWARP_RDM:
-		if (_ep->eopcode != IBV_WR_SEND) {
-			VERBS_INFO(FI_LOG_CORE,
-				   "Unsupported eager operation code\n");
-			ret = -FI_ENODATA;
-			goto err1;
-		}
-		break;
-	default:
-		VERBS_INFO(FI_LOG_CORE, "Unsupported protocol\n");
-		ret = -FI_ENODATA;
-		goto err2;
-	}
-
-	ret = fi_ibv_get_rdma_rai(NULL, NULL, 0, info, &_ep->rai);
-	if (ret) {
-		goto err2;
-	}
-	ret = fi_ibv_rdm_cm_bind_ep(_ep->domain->rdm_cm, _ep);
-	if (ret) {
-		goto err2;
-	}
-
-	_ep->posted_sends = 0;
-	_ep->posted_recvs = 0;
-	_ep->recv_preposted_threshold = MAX(0.2 * _ep->rq_wr_depth, _ep->n_buffs);
-	VERBS_INFO(FI_LOG_EP_CTRL, "recv preposted threshold: %d\n",
-		   _ep->recv_preposted_threshold);
-
-	ret = util_buf_pool_create(&_ep->fi_ibv_rdm_request_pool,
-				   sizeof(struct fi_ibv_rdm_request),
-				   FI_IBV_MEM_ALIGNMENT, 0,
-				   FI_IBV_POOL_BUF_CNT);
-	if (ret)
-		goto err3;
-
-	ret = util_buf_pool_create(&_ep->fi_ibv_rdm_multi_request_pool,
-				   sizeof(struct fi_ibv_rdm_multi_request),
-				   FI_IBV_MEM_ALIGNMENT, 0,
-				   FI_IBV_POOL_BUF_CNT);
-	if (ret)
-		goto err3;
-
-	ret = util_buf_pool_create(&_ep->fi_ibv_rdm_postponed_pool,
-				   sizeof(struct fi_ibv_rdm_postponed_entry),
-				   FI_IBV_MEM_ALIGNMENT, 0,
-				   FI_IBV_POOL_BUF_CNT);
-	if (ret)
-		goto err3;
-
-	ret = util_buf_pool_create(&_ep->fi_ibv_rdm_extra_buffers_pool,
-				   _ep->buff_len, FI_IBV_MEM_ALIGNMENT,
-				   0, FI_IBV_POOL_BUF_CNT);
-	if (ret)
-		goto err3;
-
-	dlist_init(&_ep->fi_ibv_rdm_posted_queue);
-	dlist_init(&_ep->fi_ibv_rdm_postponed_queue);
-	dlist_init(&_ep->fi_ibv_rdm_unexp_queue);
-	dlist_init(&_ep->fi_ibv_rdm_multi_recv_list);
-
-	_ep->max_inline_rc =
-		fi_ibv_find_max_inline(_ep->domain->pd, _ep->domain->verbs, IBV_QPT_RC);
-
-	_ep->scq_depth = FI_IBV_RDM_TAGGED_DFLT_SCQ_SIZE;
-	_ep->rcq_depth = FI_IBV_RDM_TAGGED_DFLT_RCQ_SIZE;
-
-	_ep->scq = ibv_create_cq(_ep->domain->verbs, _ep->scq_depth, _ep,
-				 NULL, 0);
-	if (_ep->scq == NULL) {
-		VERBS_INFO_ERRNO(FI_LOG_EP_CTRL, "ibv_create_cq", errno);
-		ret = -FI_EOTHER;
-		goto err3;
-	}
-
-	_ep->rcq =
-	    ibv_create_cq(_ep->domain->verbs, _ep->rcq_depth, _ep, NULL, 0);
-	if (_ep->rcq == NULL) {
-		VERBS_INFO_ERRNO(FI_LOG_EP_CTRL, "ibv_create_cq", errno);
-		ret = -FI_EOTHER;
-		goto err4;
-	}
-
-	*ep = &_ep->ep_fid;
-
-	_ep->is_closing = 0;
-	fi_ibv_rdm_req_hndls_init();
-
-	slist_insert_tail(&_ep->list_entry, &_domain->ep_list);
-
-	return ret;
-err4:
-	if (ibv_destroy_cq(_ep->scq))
-		VERBS_INFO_ERRNO(FI_LOG_EP_CTRL, "ibv_destroy_cq", errno);
-err3:
-	if (_ep->fi_ibv_rdm_request_pool)
-		util_buf_pool_destroy(_ep->fi_ibv_rdm_request_pool);
-	if (_ep->fi_ibv_rdm_multi_request_pool)
-		util_buf_pool_destroy(_ep->fi_ibv_rdm_multi_request_pool);
-	if (_ep->fi_ibv_rdm_postponed_pool)
-		util_buf_pool_destroy(_ep->fi_ibv_rdm_postponed_pool);
-	if (_ep->fi_ibv_rdm_extra_buffers_pool)
-		util_buf_pool_destroy(_ep->fi_ibv_rdm_extra_buffers_pool);
-err2:
-	fi_freeinfo(_ep->info);
-err1:
-	free(_ep);
-	return ret;
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_queuing.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_queuing.h
deleted file mode 100644
index 6ac877e6c..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_queuing.h
+++ /dev/null
@@ -1,307 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#ifndef _VERBS_QUEING_H
-#define _VERBS_QUEING_H
-
-#include <stdlib.h>
-#include <ofi_list.h>
-#include "verbs_rdm.h"
-
-static inline void
-fi_ibv_rdm_move_to_cq(struct fi_ibv_rdm_cq *cq,
-		      struct fi_ibv_rdm_request *request)
-{
-	FI_IBV_RDM_DBG_REQUEST("move_to_cq: ", request, FI_LOG_DEBUG);
-	dlist_insert_tail(&request->queue_entry, &cq->request_cq);
-}
-
-static inline void
-fi_ibv_rdm_remove_from_cq(struct fi_ibv_rdm_request *request)
-{
-	FI_IBV_RDM_DBG_REQUEST("remove_from_cq: ", request, FI_LOG_DEBUG);
-	dlist_remove(&request->queue_entry);
-}
-
-static inline struct fi_ibv_rdm_request *
-fi_ibv_rdm_take_first_from_cq(struct fi_ibv_rdm_cq *cq)
-{
-	if (cq && !dlist_empty(&cq->request_cq)) {
-		struct fi_ibv_rdm_request *entry =
-			container_of(cq->request_cq.next,
-				     struct fi_ibv_rdm_request, queue_entry);
-		fi_ibv_rdm_remove_from_cq(entry);
-		return entry;
-	}
-	return NULL;
-}
-
-static inline void
-fi_ibv_rdm_move_to_errcq(struct fi_ibv_rdm_cq *cq,
-			 struct fi_ibv_rdm_request *request, ssize_t err)
-{
-	request->state.err = llabs(err);
-	FI_IBV_RDM_DBG_REQUEST("move_to_errcq: ", request, FI_LOG_DEBUG);
-	assert(request->context);
-	dlist_insert_tail(&request->queue_entry,
-			  &cq->request_errcq);
-}
-
-static inline void
-fi_ibv_rdm_remove_from_errcq(struct fi_ibv_rdm_request *request)
-{
-	FI_IBV_RDM_DBG_REQUEST("remove_from_errcq: ", request, FI_LOG_DEBUG);
-	dlist_remove(&request->queue_entry);
-}
-
-static inline struct fi_ibv_rdm_request *
-fi_ibv_rdm_take_first_from_errcq(struct fi_ibv_rdm_cq *cq)
-{
-	if (cq && !dlist_empty(&cq->request_errcq)) {
-		struct fi_ibv_rdm_request *entry =
-			container_of(cq->request_errcq.next,
-				     struct fi_ibv_rdm_request, queue_entry);
-		fi_ibv_rdm_remove_from_errcq(entry);
-		return entry;
-	}
-	return NULL;
-}
-
-static inline void
-fi_ibv_rdm_move_to_unexpected_queue(struct fi_ibv_rdm_request *request,
-				    struct fi_ibv_rdm_ep *ep)
-{
-	FI_IBV_RDM_DBG_REQUEST("move_to_unexpected_queue: ", request,
-				FI_LOG_DEBUG);
-	dlist_insert_tail(&request->queue_entry, &ep->fi_ibv_rdm_unexp_queue);
-#if ENABLE_DEBUG
-	request->minfo.conn->unexp_counter++;
-#endif // ENABLE_DEBUG
-}
-
-static inline void
-fi_ibv_rdm_remove_from_unexp_queue(struct fi_ibv_rdm_request *request)
-{
-	FI_IBV_RDM_DBG_REQUEST("remove_from_unexpected_queue: ", request,
-				FI_LOG_DEBUG);
-	dlist_remove(&request->queue_entry);
-}
-
-static inline struct fi_ibv_rdm_request *
-fi_ibv_rdm_take_first_from_unexp_queue(struct fi_ibv_rdm_ep *ep)
-{
-	if (!dlist_empty(&ep->fi_ibv_rdm_unexp_queue)) {
-		struct fi_ibv_rdm_request *entry =
-			container_of(ep->fi_ibv_rdm_unexp_queue.next,
-				     struct fi_ibv_rdm_request, queue_entry);
-		fi_ibv_rdm_remove_from_unexp_queue(entry);
-		return entry;
-	}
-	return NULL;
-}
-
-static inline void
-fi_ibv_rdm_move_to_posted_queue(struct fi_ibv_rdm_request *request,
-				struct fi_ibv_rdm_ep *ep)
-{
-	FI_IBV_RDM_DBG_REQUEST("move_to_posted_queue: ", request, FI_LOG_DEBUG);
-	dlist_insert_tail(&request->queue_entry, &ep->fi_ibv_rdm_posted_queue);
-	ep->posted_recvs++;
-#if ENABLE_DEBUG
-	if (request->minfo.conn) {
-		request->minfo.conn->exp_counter++;
-	}
-#endif // ENABLE_DEBUG
-}
-
-static inline uint32_t
-fi_ibv_rdm_remove_from_posted_queue(struct fi_ibv_rdm_request *request,
-				    struct fi_ibv_rdm_ep *ep)
-{
-	FI_IBV_RDM_DBG_REQUEST("remove_from_posted_queue: ", request,
-				FI_LOG_DEBUG);
-	dlist_remove(&request->queue_entry);
-	return ep->posted_recvs--;
-}
-
-static inline struct fi_ibv_rdm_request *
-fi_ibv_rdm_take_first_from_posted_queue(struct fi_ibv_rdm_ep* ep)
-{
-	if (!dlist_empty(&ep->fi_ibv_rdm_posted_queue)) {
-		struct fi_ibv_rdm_request *entry =
-			container_of(ep->fi_ibv_rdm_posted_queue.next,
-				     struct fi_ibv_rdm_request, queue_entry);
-		fi_ibv_rdm_remove_from_posted_queue(entry, ep);
-		return entry;
-	}
-	return NULL;
-}
-
-static inline int
-fi_ibv_rdm_move_to_postponed_queue(struct fi_ibv_rdm_request *request)
-{
-	FI_IBV_RDM_DBG_REQUEST("move_to_postponed_queue: ", request, 
-				FI_LOG_DEBUG);
-	assert(request && request->minfo.conn);
-
-	struct fi_ibv_rdm_conn *conn = request->minfo.conn;
-
-	if (dlist_empty(&conn->postponed_requests_head)) {
-		struct fi_ibv_rdm_postponed_entry *entry =
-			util_buf_alloc(conn->ep->fi_ibv_rdm_postponed_pool);
-		if (OFI_UNLIKELY(!entry)) {
-			VERBS_WARN(FI_LOG_EP_DATA, "Unable to alloc buffer");
-			return -FI_ENOMEM;
-		}
-
-		entry->conn = conn;	
-		conn->postponed_entry = entry;
-
-		dlist_insert_tail(&entry->queue_entry,
-				  &conn->ep->fi_ibv_rdm_postponed_queue);
-	}
-	dlist_insert_tail(&request->queue_entry,
-			  &conn->postponed_requests_head);
-
-	return FI_SUCCESS;
-}
-
-static inline void
-fi_ibv_rdm_remove_from_multi_recv_list(struct fi_ibv_rdm_multi_request *request,
-				       struct fi_ibv_rdm_ep *ep)
-{
-	dlist_remove(&request->list_entry);
-}
-
-static inline void
-fi_ibv_rdm_add_to_multi_recv_list(struct fi_ibv_rdm_multi_request *request,
-				  struct fi_ibv_rdm_ep *ep)
-{
-	dlist_insert_tail(&request->list_entry,
-			  &ep->fi_ibv_rdm_multi_recv_list);
-}
-
-static inline struct fi_ibv_rdm_multi_request *
-fi_ibv_rdm_take_first_from_multi_recv_list(struct fi_ibv_rdm_ep *ep)
-{
-	if (!dlist_empty(&ep->fi_ibv_rdm_multi_recv_list)) {
-		struct fi_ibv_rdm_multi_request *entry;
-		dlist_pop_front(&ep->fi_ibv_rdm_multi_recv_list,
-				struct fi_ibv_rdm_multi_request,
-				entry, list_entry);
-		return entry;
-	}
-	return NULL;
-}
-
-static inline void
-fi_ibv_rdm_remove_from_postponed_queue(struct fi_ibv_rdm_request *request)
-{
-	FI_IBV_RDM_DBG_REQUEST("remove_from_postponed_queue: ", request,
-				FI_LOG_DEBUG);
-
-	struct fi_ibv_rdm_conn *conn = request->minfo.conn;
-	assert(conn);
-	assert(!dlist_empty(&conn->postponed_requests_head));
-
-	/* 
-	 * remove from conn->postponed_requests_head at first
-	 * then if conn->postponed_requests_head is empty
-	 * clean fi_ibv_rdm_postponed_queue
-	 */
-
-	dlist_remove(&request->queue_entry);
-	request->queue_entry.next = request->queue_entry.prev = NULL;
-
-	if (dlist_empty(&conn->postponed_requests_head)) {
-		dlist_remove(&conn->postponed_entry->queue_entry);
-		conn->postponed_entry->queue_entry.next = 
-		conn->postponed_entry->queue_entry.prev = NULL;
-		conn->postponed_entry->conn = NULL;
-
-		util_buf_release(conn->ep->fi_ibv_rdm_postponed_pool,
-				 conn->postponed_entry);
-		conn->postponed_entry = NULL;
-	}
-}
-
-static inline struct fi_ibv_rdm_request *
-fi_ibv_rdm_take_first_from_postponed_queue(struct fi_ibv_rdm_ep *ep)
-{
-	if (!dlist_empty(&ep->fi_ibv_rdm_postponed_queue)) {
-		struct fi_ibv_rdm_postponed_entry *entry = 
-			container_of(ep->fi_ibv_rdm_postponed_queue.next,
-				struct fi_ibv_rdm_postponed_entry, queue_entry);
-
-		if (!dlist_empty(&entry->conn->postponed_requests_head)) {
-			struct dlist_entry *req_entry = 
-				entry->conn->postponed_requests_head.next;
-
-			struct fi_ibv_rdm_request *request =
-			    container_of(req_entry, struct fi_ibv_rdm_request,
-					 queue_entry);
-			fi_ibv_rdm_remove_from_postponed_queue(request);
-			return request;
-		}
-	}
-
-	return NULL;
-}
-
-static inline struct fi_ibv_rdm_request *
-fi_ibv_rdm_take_first_match_from_postponed_queue(dlist_func_t *match,
-						 const void *arg,
-						 struct fi_ibv_rdm_ep *ep)
-{
-	struct dlist_entry *i, *j;
-	dlist_foreach((&ep->fi_ibv_rdm_postponed_queue), i) {
-		 struct fi_ibv_rdm_postponed_entry *entry = 
-			container_of(i, struct fi_ibv_rdm_postponed_entry,
-				     queue_entry);
-
-		j = dlist_find_first_match((&entry->conn->postponed_requests_head),
-					   match, arg);
-		if (j) {
-			struct fi_ibv_rdm_request *request =
-				container_of(j, struct fi_ibv_rdm_request,
-					     queue_entry);
-			fi_ibv_rdm_remove_from_postponed_queue(request);
-			return request;
-		}
-	}
-
-	return NULL;
-}
-
-void fi_ibv_rdm_clean_queues(struct fi_ibv_rdm_ep* ep);
-
-#endif   // _VERBS_QUEING_H
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm.h
deleted file mode 100644
index ef4ba6985..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm.h
+++ /dev/null
@@ -1,746 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#ifndef _VERBS_RDM_H
-#define _VERBS_RDM_H
-
-#include <rdma/rdma_cma.h>
-#include <rdma/fi_atomic.h>
-#include <uthash.h>
-
-#include "../fi_verbs.h"
-#include "verbs_utils.h"
-#include "verbs_tagged_ep_rdm_states.h"
-
-#define FI_IBV_EP_TYPE_IS_RDM(_info)	\
-	(_info && _info->ep_attr && (_info->ep_attr->type == FI_EP_RDM))
-
-#define FI_IBV_RDM_ST_PKTTYPE_MASK  ((uint32_t) 0xFF)
-#define FI_IBV_RDM_EAGER_PKT		0
-#define FI_IBV_RDM_RNDV_RTS_PKT		1
-#define FI_IBV_RDM_RNDV_ACK_PKT		2
-#define FI_IBV_RDM_RMA_PKT		3
-#define FI_IBV_RDM_MSG_PKT		4
-#define FI_IBV_RDM_SET_PKTTYPE(dest, type) (dest |= type)
-#define FI_IBV_RDM_GET_PKTTYPE(value) (value & FI_IBV_RDM_ST_PKTTYPE_MASK)
-
-
-/* ------- SERVICE_TAG layout ---------
- * [ 24 bits - Unused at the moment ] [ 8 bits - pkt type ]
- *                                    IBV_RDM_ST_PKTYPE_MASK
- */
-
-/* WR - work request */
-#define FI_IBV_RDM_SERVICE_WR_MASK              ((uint64_t)0x1)
-#define FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(value)	\
-        (value & FI_IBV_RDM_SERVICE_WR_MASK)
-
-#define FI_IBV_RDM_PACK_WR(value)               ((uint64_t)(uintptr_t)(void *)value)
-#define FI_IBV_RDM_UNPACK_WR(value)             ((void *)(uintptr_t)value)
-
-#define FI_IBV_RDM_PACK_SERVICE_WR(value)					\
-        (((uint64_t)(uintptr_t)(void *)value) | FI_IBV_RDM_SERVICE_WR_MASK)
-
-#define FI_IBV_RDM_UNPACK_SERVICE_WR(value)				\
-        ((void *)(uintptr_t)(value & (~(FI_IBV_RDM_SERVICE_WR_MASK))))
-
-/* Send/Recv counters control */
-#define FI_IBV_RDM_INC_SIG_POST_COUNTERS(_connection, _ep)				\
-do {                                                                			\
-	(_connection)->av_entry->sends_outgoing++;					\
-	(_ep)->posted_sends++;								\
-	VERBS_DBG(FI_LOG_CQ, "SEND_COUNTER++, conn %p, sends_outgoing %"PRIu32"\n",	\
-		  _connection, (_connection)->av_entry->sends_outgoing);		\
-} while (0)
-
-#define FI_IBV_RDM_DEC_SIG_POST_COUNTERS(_connection, _ep)				\
-do {											\
-	(_connection)->av_entry->sends_outgoing--;					\
-	(_ep)->posted_sends--;								\
-	VERBS_DBG(FI_LOG_CQ, "SEND_COUNTER--, conn %p, sends_outgoing %"PRIu32"\n",	\
-		  _connection, (_connection)->av_entry->sends_outgoing);		\
-} while (0)
-
-#define OUTGOING_POST_LIMIT(_connection, _ep)					\
-	((_connection)->av_entry->sends_outgoing >= (_ep)->sq_wr_depth - 1)
-
-#define PEND_POST_LIMIT(_ep)						\
-	((_ep)->posted_sends > 0.5 * (_ep)->scq_depth)
-
-#define TSEND_RESOURCES_IS_BUSY(_connection, _ep)			\
-	(OUTGOING_POST_LIMIT(_connection, _ep) || PEND_POST_LIMIT(_ep))
-
-#define RMA_RESOURCES_IS_BUSY(_connection, _ep)				\
-	(OUTGOING_POST_LIMIT(_connection, _ep) || PEND_POST_LIMIT(_ep))
-
-#define GET_TX_COMP(ep_rdm)						\
-	(!ep_rdm->rx_selective_completion ||		\
-	(ep_rdm->rx_op_flags & FI_COMPLETION) ?		\
-	FI_COMPLETION : 0ULL)
-
-#define GET_TX_COMP_FLAG(ep_rdm, flag)			\
-	(!ep_rdm->rx_selective_completion ||		\
-	(ep_rdm->rx_op_flags & FI_COMPLETION) ?		\
-	FI_COMPLETION : (flags & FI_COMPLETION))
-
-struct fi_ibv_rdm_header {
-/*	uint64_t imm_data; TODO: not implemented */
-	uint64_t tag;
-	uint32_t service_tag;
-	uint32_t padding;
-};
-
-struct fi_ibv_rdm_rndv_header {
-	struct fi_ibv_rdm_header base;
-	uint64_t src_addr;
-	uint64_t id; /* pointer to request on sender side */
-	uint64_t total_len;
-	uint64_t mem_rkey;
-	uint32_t is_tagged;
-};
-
-struct fi_ibv_rdm_multi_request {
-	/* working request, will be renewed for every data arriving */
-	struct dlist_entry		list_entry;
-	struct fi_ibv_rdm_request	*prepost;
-	struct fi_ibv_rdm_ep		*ep;
-	uint8_t				*buf;
-	uint64_t			len;
-	uint64_t			offset;
-	uint64_t			min_size;
-};
-
-struct fi_ibv_rdm_request {
-
-	/* Accessors and match info */
-
-	/* Request can be an element of only one queue at the moment */
-	struct dlist_entry queue_entry;
-	/* multi recv handling */
-	struct fi_ibv_rdm_multi_request *parent;
-	struct {
-		enum fi_ibv_rdm_request_eager_state eager;
-		enum fi_ibv_rdm_request_rndv_state rndv;
-		ssize_t err; /* filled in case of moving to errcq */
-	} state;
-
-	struct fi_ibv_rdm_ep	*ep;
-	struct fi_ibv_rdm_minfo	minfo;
-
-	/* User data: buffers, lens, imm, context */
-
-	union {
-		void *src_addr;
-		void *dest_buf;
-		struct iovec *iovec_arr;
-	};
-
-	union {
-		void *exp_rbuf;
-		struct fi_ibv_rdm_buf *unexp_rbuf;
-		struct fi_ibv_rdm_buf *sbuf;
-		struct fi_ibv_rdm_buf *rmabuf;
-		struct iovec *rmaiovec_arr;
-	};
-
-	/*
-	 * iovec_arr is a mem pool entry if iov_count > 0
-	 * and must be freed properly
-	 */
-	uint64_t iov_count;
-	uint64_t len;
-	uint64_t rest_len;
-	uint64_t comp_flags;
-	struct fi_context *context;
-	uint32_t post_counter;
-	uint32_t imm;
-
-	union {
-		/* RNDV info */
-		struct {
-			/* pointer to request on sender side */
-			uint64_t id;
-			/* registered buffer on sender side */
-			void* remote_addr;
-			/* registered mr of local src_addr */
-			struct fi_ibv_mem_desc md;
-			uint64_t mr_rkey;
-		} rndv;
-		
-		/* RMA info */
-		struct {
-			struct fi_ibv_mem_desc md;
-			uint64_t mr_rkey;
-			uint64_t mr_lkey;
-			uint64_t remote_addr;
-			enum ibv_wr_opcode opcode;
-		} rma;
-	};
-};
-
-static inline void
-fi_ibv_rdm_zero_request(struct fi_ibv_rdm_request *request)
-{
-	memset(request, 0, sizeof(*request));
-}
-
-void fi_ibv_rdm_print_request(char *buf, struct fi_ibv_rdm_request *request);
-
-#define BUF_STATUS_FREE 	((uint16_t) 0)
-#define BUF_STATUS_BUSY 	((uint16_t) 1)
-#define BUF_STATUS_RECEIVED 	((uint16_t) 2)
-
-struct fi_ibv_rdm_buf_service_data {
-	volatile uint16_t status;
-	uint16_t seq_num;
-	int32_t pkt_len;
-};
-
-#define FI_IBV_RDM_BUFF_SERVICE_DATA_SIZE	\
-	(offsetof(struct fi_ibv_rdm_buf, header))
-
-struct fi_ibv_rdm_buf {
-	struct fi_ibv_rdm_buf_service_data service_data;
-	struct fi_ibv_rdm_header header;
-	uint64_t payload;
-};
-
-struct fi_ibv_rdm_cm {
-	struct rdma_event_channel*	ec;
-	struct rdma_cm_id*		listener;
-	int				is_bound;
-
-	/* av_hash has a sockaddr_in -> [ep - conn] associative */
-	struct fi_ibv_rdm_av_entry*	av_hash;
-	/* Used only for FI_AV_TABLE */
-	struct fi_ibv_rdm_av_entry**	av_table;
-
-	struct slist			av_removed_entry_head;
-	pthread_mutex_t			cm_lock;
-	pthread_t			cm_progress_thread;
-	int				cm_progress_timeout;
-	int				fi_ibv_rdm_tagged_cm_progress_running;
-};
-
-struct fi_ibv_rdm_cntr {
-	struct fid_cntr		fid;
-	struct fi_ibv_domain	*domain;
-	ofi_atomic32_t		ep_ref;
-	uint64_t		value;
-	struct fi_cntr_attr	attr;
-	uint64_t		err_count;
-};
-
-struct fi_ibv_rdm_ep {
-	struct fid_ep ep_fid;
-	struct fi_ibv_domain	*domain;
-	struct slist_entry	list_entry;
-	struct fi_ibv_rdm_cq	*fi_scq;
-	struct fi_ibv_rdm_cq	*fi_rcq;
-
-	struct fi_ibv_rdm_cntr	*send_cntr;
-	struct fi_ibv_rdm_cntr	*recv_cntr;
-	struct fi_ibv_rdm_cntr	*read_cntr;
-	struct fi_ibv_rdm_cntr	*write_cntr;
-
-	struct fi_info	*info;
-
-	struct util_buf_pool	*fi_ibv_rdm_request_pool;
-	struct util_buf_pool	*fi_ibv_rdm_multi_request_pool;
-	struct util_buf_pool	*fi_ibv_rdm_postponed_pool;
-	/*
-	 * extra buffer size equal eager buffer size,
-	 * it is used for any intermediate needs like
-	 * unexpected recv, pack/unpack noncontig messages, etc
-	 */
-	struct util_buf_pool	*fi_ibv_rdm_extra_buffers_pool;
-
-	struct dlist_entry	fi_ibv_rdm_posted_queue;
-	struct dlist_entry	fi_ibv_rdm_postponed_queue;
-	struct dlist_entry	fi_ibv_rdm_unexp_queue;
-	struct dlist_entry	fi_ibv_rdm_multi_recv_list;
-
-	size_t			addrlen;
-	struct rdma_addrinfo	*rai;
-	struct sockaddr_in	my_addr;
-
-	struct fi_ibv_av	*av;
-	int		tx_selective_completion;
-	int 		rx_selective_completion;
-	size_t 		min_multi_recv_size;
-	uint64_t 	tx_op_flags;
-	uint64_t 	rx_op_flags;
-
-	/*
-	 * ibv_post_send opcode for eager messaging.
-	 * It must generate work completion in receive CQ
-	 */
-	enum ibv_wr_opcode	eopcode;
-	struct ibv_cq		*scq;
-	struct ibv_cq		*rcq;
-
-	int	buff_len;
-	int	n_buffs;
-	int	rq_wr_depth;    // RQ depth
-	int	sq_wr_depth;    // SQ depth
-	uint32_t	posted_sends;
-	uint32_t	posted_recvs;
-	int	num_active_conns;
-	int	max_inline_rc;
-	int	rndv_threshold;
-	int	rndv_seg_size;
-	size_t	iov_per_rndv_thr;
-	int	scq_depth;
-	int	rcq_depth;
-
-	int	is_closing;
-	int	recv_preposted_threshold;
-};
-
-enum fi_rdm_cm_conn_state {
-	FI_VERBS_CONN_ALLOCATED,
-	FI_VERBS_CONN_STARTED,
-	FI_VERBS_CONN_REJECTED,
-	FI_VERBS_CONN_ESTABLISHED,
-	FI_VERBS_CONN_LOCAL_DISCONNECT,
-	FI_VERBS_CONN_CLOSED
-};
-
-enum fi_rdm_cm_role {
-	FI_VERBS_CM_UNDEFINED,
-	FI_VERBS_CM_ACTIVE,
-	FI_VERBS_CM_PASSIVE,
-	FI_VERBS_CM_SELF,
-};
-
-struct fi_ibv_rdm_av_entry {
-	/* association of conn and EPs */
-	struct fi_ibv_rdm_conn	*conn_hash;
-	struct sockaddr_in	addr;
-	uint32_t		sends_outgoing;
-	uint32_t		recv_preposted;
-	struct slist_entry	removed_next;
-	UT_hash_handle		hh;
-};
-
-struct fi_ibv_rdm_conn {
-
-	/* 
-	 * In normal case only qp[0] and id[0] are used.
-	 * qp[1] and id[1] are used for establishing connection to self
-	 * like passive side
-	 */
-	struct ibv_qp *qp[2];
-	struct rdma_cm_id *id[2];
-	struct sockaddr_in addr;
-	struct fi_ibv_rdm_ep *ep;
-	enum fi_rdm_cm_role cm_role;
-	enum fi_rdm_cm_conn_state state;
-
-	char *sbuf_mem_reg;
-	struct fi_ibv_rdm_buf *sbuf_head;
-	uint16_t sbuf_ack_status;
-
-	char *rbuf_mem_reg;
-	struct fi_ibv_rdm_buf *rbuf_head;
-
-	char *rmabuf_mem_reg;
-	struct fi_ibv_rdm_buf *rmabuf_head;
-
-	struct dlist_entry postponed_requests_head;
-	struct fi_ibv_rdm_postponed_entry *postponed_entry;
-
-	struct fi_ibv_mem_desc s_md;
-	struct fi_ibv_mem_desc r_md;
-	struct fi_ibv_mem_desc ack_md;
-	struct fi_ibv_mem_desc rma_md;
-
-	uint32_t remote_sbuf_rkey;
-	uint32_t remote_rbuf_rkey;
-
-	char *remote_sbuf_mem_reg;
-	char *remote_rbuf_mem_reg;
-	struct fi_ibv_rdm_buf *remote_sbuf_head;
-
-	/* counter for eager buffer releasing */
-	uint16_t recv_completions;
-	/* counter to control OOO behaviour, works in pair with recv_completions */
-	uint16_t recv_processed;
-
-	struct fi_ibv_rdm_av_entry *av_entry;
-	UT_hash_handle hh;
-#if ENABLE_DEBUG
-	size_t unexp_counter;
-	size_t exp_counter;
-#endif
-};
-
-struct fi_ibv_rdm_postponed_entry {
-	struct dlist_entry queue_entry;
-
-	struct fi_ibv_rdm_conn *conn;
-};
-
-struct fi_conn_priv_params {
-	char addr[FI_IBV_RDM_DFLT_ADDRLEN];
-
-	uint32_t rbuf_rkey;
-	uint32_t sbuf_rkey;
-	char *rbuf_mem_reg;
-	char *sbuf_mem_reg;
-};
-
-static inline void
-fi_ibv_rdm_set_buffer_status(struct fi_ibv_rdm_buf *buff, uint16_t status)
-{
-	buff->service_data.status = status;
-	if (status == BUF_STATUS_FREE) {
-		buff->service_data.pkt_len = 0;
-	}
-}
-
-static inline int
-fi_ibv_rdm_buffer_check_seq_num(struct fi_ibv_rdm_buf *buff, uint16_t seq_num)
-{
-	VERBS_DBG(FI_LOG_EP_DATA, "seq num: %d <-> %d\n",
-		buff->service_data.seq_num, seq_num);
-	return (seq_num == buff->service_data.seq_num);
-}
-
-static inline uintptr_t
-fi_ibv_rdm_get_remote_addr(struct fi_ibv_rdm_conn *conn,
-			   struct fi_ibv_rdm_buf *local_sbuff)
-{
-	return (uintptr_t) (conn->remote_rbuf_mem_reg +
-			    ((char *)local_sbuff - conn->sbuf_mem_reg));
-}
-
-static inline void
-fi_ibv_rdm_push_buff_pointer(char *area_start, size_t area_size,
-			     struct fi_ibv_rdm_buf **rdm_buff, size_t offset)
-{
-	char *buff = (char*)(*rdm_buff);
-	char *buff_tmp = buff + offset;
-
-	VERBS_DBG(FI_LOG_EP_DATA, "old_pointer: %p\n", buff);
-
-	buff = buff_tmp < (area_start + area_size) ? buff_tmp : area_start;
-	
-	VERBS_DBG(FI_LOG_EP_DATA, "new_pointer: %p\n", buff);
-
-	*rdm_buff = (struct fi_ibv_rdm_buf *)buff;
-}
-
-static inline void
-fi_ibv_rdm_push_sbuff_head(struct fi_ibv_rdm_conn *conn, 
-			   struct fi_ibv_rdm_ep *ep)
-{
-	fi_ibv_rdm_push_buff_pointer(conn->sbuf_mem_reg,
-				     ep->buff_len * ep->n_buffs,
-				     &conn->sbuf_head, ep->buff_len);
-}
-
-static inline void
-fi_ibv_rdm_push_rmabuff_head(struct fi_ibv_rdm_conn *conn,
-			     struct fi_ibv_rdm_ep *ep)
-{
-	fi_ibv_rdm_push_buff_pointer(conn->rmabuf_mem_reg,
-				     ep->buff_len * ep->n_buffs,
-				     &conn->rmabuf_head, ep->buff_len);
-}
-
-static inline struct fi_ibv_rdm_buf *
-fi_ibv_rdm_get_rmabuf(struct fi_ibv_rdm_conn *conn,
-		      struct fi_ibv_rdm_ep *ep, uint16_t seq_num)
-{
-	char *rmabuf = conn->rmabuf_mem_reg + (seq_num * ep->buff_len);
-	VERBS_DBG(FI_LOG_EP_DATA, "rma buf %d\n", seq_num);
-	return (struct fi_ibv_rdm_buf *) rmabuf;
-}
-
-static inline struct fi_ibv_rdm_buf *
-fi_ibv_rdm_get_rbuf(struct fi_ibv_rdm_conn *conn,
-		    struct fi_ibv_rdm_ep *ep, uint16_t seq_num)
-{
-	struct fi_ibv_rdm_buf *rbuf = (struct fi_ibv_rdm_buf *)
-		(conn->rbuf_mem_reg + (seq_num * ep->buff_len));
-
-	VERBS_DBG(FI_LOG_EP_DATA, "recv buf %d <-> %d\n",
-		seq_num, rbuf->service_data.seq_num);
-
-	return  rbuf;
-}
-
-static inline struct fi_ibv_rdm_buf *
-fi_ibv_rdm_get_sbuf(struct fi_ibv_rdm_conn *conn,
-		    struct fi_ibv_rdm_ep *ep, uint16_t seq_num)
-{
-	char *sbuf = conn->sbuf_mem_reg + (seq_num * ep->buff_len);
-	VERBS_DBG(FI_LOG_EP_DATA, "send buf %d\n", seq_num);
-	return (struct fi_ibv_rdm_buf *)sbuf;
-}
-
-static inline void
-fi_ibv_rdm_buffer_lists_init(struct fi_ibv_rdm_conn *conn,
-			     struct fi_ibv_rdm_ep *ep)
-{
-	int i;
-
-	conn->sbuf_head = (struct fi_ibv_rdm_buf *)conn->sbuf_mem_reg;
-	conn->rbuf_head = (struct fi_ibv_rdm_buf *)conn->rbuf_mem_reg;
-	conn->sbuf_ack_status = BUF_STATUS_FREE;
-
-	conn->rmabuf_head = (struct fi_ibv_rdm_buf *)conn->rmabuf_mem_reg;
-
-	for (i = 0; i < ep->n_buffs; ++i) {
-		fi_ibv_rdm_set_buffer_status(fi_ibv_rdm_get_sbuf(conn, ep, i),
-			BUF_STATUS_FREE);
-		fi_ibv_rdm_get_sbuf(conn, ep, i)->service_data.seq_num = i;
-
-		fi_ibv_rdm_set_buffer_status(fi_ibv_rdm_get_rbuf(conn, ep, i),
-			BUF_STATUS_FREE);
-		/* should be initialized by sender */
-		fi_ibv_rdm_get_rbuf(conn, ep, i)->service_data.seq_num = 
-			(uint16_t)(-1);
-
-		fi_ibv_rdm_set_buffer_status(fi_ibv_rdm_get_rmabuf(conn, ep, i),
-			BUF_STATUS_FREE);
-		fi_ibv_rdm_get_rmabuf(conn, ep, i)->service_data.seq_num = i;
-	}
-}
-
-static inline void fi_ibv_rdm_cntr_inc(struct fi_ibv_rdm_cntr *cntr)
-{
-	if (cntr) {
-		cntr->fid.ops->add(&cntr->fid, 1);
-	}
-}
-
-static inline void fi_ibv_rdm_cntr_inc_err(struct fi_ibv_rdm_cntr *cntr)
-{
-	if (cntr) {
-		cntr->err_count++;
-	}
-}
-
-int fi_ibv_rdm_tagged_poll(struct fi_ibv_rdm_ep *ep);
-int fi_ibv_rdm_tagged_poll_recv(struct fi_ibv_rdm_ep *ep);
-ssize_t fi_ibv_rdm_cm_progress(struct fi_ibv_rdm_ep *ep);
-ssize_t
-fi_ibv_rdm_start_overall_disconnection(struct fi_ibv_rdm_av_entry *av_entry);
-ssize_t fi_ibv_rdm_start_disconnection(struct fi_ibv_rdm_conn *conn);
-int fi_ibv_av_entry_alloc(struct fi_ibv_domain *domain,
-			  struct fi_ibv_rdm_av_entry **av_entry,
-			  void *addr);
-ssize_t fi_ibv_rdm_conn_cleanup(struct fi_ibv_rdm_conn *conn);
-ssize_t fi_ibv_rdm_overall_conn_cleanup(struct fi_ibv_rdm_av_entry *av_entry);
-ssize_t fi_ibv_rdm_start_connection(struct fi_ibv_rdm_ep *ep,
-				    struct fi_ibv_rdm_conn *conn);
-ssize_t fi_ibv_rdm_repost_receives(struct fi_ibv_rdm_conn *conn,
-				   struct fi_ibv_rdm_ep *ep,
-				   int num_to_post);
-int fi_ibv_rdm_tagged_open_ep(struct fid_domain *domain, struct fi_info *info,
-                              struct fid_ep **ep, void *context);
-int fi_ibv_rdm_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
-		   struct fid_cq **cq, void *context);
-
-int fi_ibv_rdm_tagged_prepare_send_request(struct fi_ibv_rdm_request *request,
-					   struct fi_ibv_rdm_ep *ep);
-int fi_ibv_rdm_prepare_rma_request(struct fi_ibv_rdm_request *request,
-				   struct fi_ibv_rdm_ep *ep);
-
-static inline struct fi_ibv_rdm_buf *
-fi_ibv_rdm_get_sbuf_head(struct fi_ibv_rdm_conn *conn, struct fi_ibv_rdm_ep *ep)
-{
-	assert(conn);
-
-#if ENABLE_DEBUG
-	{
-		int i;
-		char s[1024];
-		char *p = s;
-		sprintf(p, "N:%1d ", ep->n_buffs);
-		p += 4;
-		for (i = 0; i < ep->n_buffs; ++i, p += 4) {
-			struct fi_ibv_rdm_buf *buf = 
-				fi_ibv_rdm_get_sbuf(conn, ep, i);
-			sprintf(p, "%1d:%1d ", buf->service_data.seq_num,
-				buf->service_data.status);
-		}
-		VERBS_DBG(FI_LOG_EP_DATA,
-			"conn %p sbufs status before: %s\n", conn, s);
-	}
-#endif // ENABLE_DEBUG
-	struct fi_ibv_rdm_buf *sbuf = NULL;
-
-	if (conn->sbuf_head->service_data.status == BUF_STATUS_FREE) {
-
-		/* We have made whole circle. Reset buffer states */ 
-		if (conn->sbuf_head == fi_ibv_rdm_get_sbuf(conn, ep, 0)) {
-			do {
-				fi_ibv_rdm_set_buffer_status(conn->sbuf_head,
-					BUF_STATUS_FREE);
-				fi_ibv_rdm_push_sbuff_head(conn, ep);
-			} while (conn->sbuf_head != fi_ibv_rdm_get_sbuf(conn, ep, 0));
-		}
-
-		/* notification for receiver */
-		fi_ibv_rdm_set_buffer_status(conn->sbuf_head, BUF_STATUS_RECEIVED);
-
-		sbuf = conn->sbuf_head;
-		fi_ibv_rdm_push_sbuff_head(conn, ep);
-	}
-#if ENABLE_DEBUG
-	assert(sbuf ? (sbuf->service_data.status == BUF_STATUS_RECEIVED) : 1);
-	{
-		int i;
-		char s[1024];
-		char *p = s;
-		sprintf(p, "N:%1d ", ep->n_buffs);
-		p += 4;
-		for (i = 0; i < ep->n_buffs; ++i, p += 4) {
-			struct fi_ibv_rdm_buf *buf = 
-				fi_ibv_rdm_get_sbuf(conn, ep, i);
-			sprintf(p, "%1d:%1d ", buf->service_data.seq_num,
-				buf->service_data.status);
-		}
-		VERBS_DBG(FI_LOG_EP_DATA,
-			"conn %p sbufs status after:  %s\n", conn, s);
-	}
-
-	if (sbuf) {
-		VERBS_DBG(FI_LOG_EP_DATA, "sending pkt # %d\n",
-			  sbuf->service_data.seq_num);
-	}
-#endif // ENABLE_DEBUG
-
-	VERBS_DBG(FI_LOG_EP_DATA,
-		"conn %p sbuf allocated: %p, head: %p, begin: %p\n",
-		conn, sbuf, conn->sbuf_head, conn->sbuf_mem_reg);
-
-	return sbuf;
-}
-
-static inline void *
-fi_ibv_rdm_rma_get_buf_head(struct fi_ibv_rdm_conn *conn,
-			    struct fi_ibv_rdm_ep *ep)
-{
-	assert(conn);
-	void *buf = NULL;
-
-	if (conn->rmabuf_head->service_data.status == BUF_STATUS_FREE) {
-		fi_ibv_rdm_set_buffer_status(conn->rmabuf_head, BUF_STATUS_BUSY);
-		buf = conn->rmabuf_head;
-		fi_ibv_rdm_push_rmabuff_head(conn, ep);
-	}
-	return buf;
-}
-
-static inline int
-fi_ibv_rdm_check_connection(struct fi_ibv_rdm_conn *conn)
-{
-	return (conn->state == FI_VERBS_CONN_ESTABLISHED);
-}
-
-static inline struct fi_ibv_rdm_buf *
-fi_ibv_rdm_prepare_send_resources(struct fi_ibv_rdm_conn *conn)
-{
-	return (fi_ibv_rdm_check_connection(conn) &&
-		!TSEND_RESOURCES_IS_BUSY(conn, conn->ep)) ?
-		fi_ibv_rdm_get_sbuf_head(conn, conn->ep) : NULL;
-}
-
-static inline void *
-fi_ibv_rdm_rma_prepare_resources(struct fi_ibv_rdm_conn *conn)
-{
-	return (fi_ibv_rdm_check_connection(conn) &&
-		!TSEND_RESOURCES_IS_BUSY(conn, conn->ep)) ?
-		fi_ibv_rdm_rma_get_buf_head(conn, conn->ep) : NULL;
-}
-
-static inline int
-fi_ibv_rdm_process_send_wc(struct fi_ibv_rdm_ep *ep,
-			   struct ibv_wc *wc)
-{
-	if (wc->status != IBV_WC_SUCCESS) {
-		return 1;
-	}
-
-	if (FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wc->wr_id)) {
-		VERBS_DBG(FI_LOG_EP_DATA, "CQ COMPL: SEND -> 0x1\n");
-		struct fi_ibv_rdm_conn *conn =
-			(struct fi_ibv_rdm_conn *)
-			FI_IBV_RDM_UNPACK_SERVICE_WR(wc->wr_id);
-		FI_IBV_RDM_DEC_SIG_POST_COUNTERS(conn, ep);
-
-		return 0;
-	} else {
-		FI_IBV_DBG_OPCODE(wc->opcode, "SEND");
-		struct fi_ibv_rdm_request *request =
-			FI_IBV_RDM_UNPACK_WR(wc->wr_id);
-
-		struct fi_ibv_rdm_tagged_send_completed_data data =
-			{ .ep = ep };
-
-		return fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_POST_LC,
-					   &data);
-	}
-}
-
-static inline void
-fi_ibv_rdm_process_err_send_wc(struct fi_ibv_rdm_ep *ep,
-			       struct ibv_wc *wc)
-{
-	if (wc->status != IBV_WC_SUCCESS) {
-		struct fi_ibv_rdm_conn *conn;
-		if (FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wc->wr_id)) {
-			conn = FI_IBV_RDM_UNPACK_SERVICE_WR(wc->wr_id);
-		} else {
-			struct fi_ibv_rdm_request *req =
-				FI_IBV_RDM_UNPACK_WR(wc->wr_id);
-			conn = req->minfo.conn;
-			FI_IBV_RDM_DBG_REQUEST("to_pool: ", req,
-					       FI_LOG_DEBUG);
-			util_buf_release(ep->fi_ibv_rdm_request_pool, req);
-		}
-		VERBS_INFO(FI_LOG_EP_DATA, "got ibv_wc.status = %d:%s, "
-			   "pend_send: %"PRIu32", connection: %p, request = %p (%s)\n",
-			   wc->status,
-			   ibv_wc_status_str(wc->status),
-			   ep->posted_sends, conn,
-			   (void *)wc->wr_id,
-			   FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wc->wr_id) ?
-				"service" : "not service");
-	}
-}
-
-#endif /* _VERBS_RDM_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_cm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_cm.c
deleted file mode 100644
index a5ea208a0..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_cm.c
+++ /dev/null
@@ -1,839 +0,0 @@
-/*
- * Copyright (c) 2013-2017 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <malloc.h>
-#include <rdma/rdma_cma.h>
-#include <ofi_list.h>
-
-#include "../fi_verbs.h"
-#include "verbs_utils.h"
-#include "verbs_rdm.h"
-#include "verbs_queuing.h"
-
-extern struct fi_provider fi_ibv_prov;
-
-static inline ssize_t
-fi_ibv_rdm_batch_repost_receives(struct fi_ibv_rdm_conn *conn,
-				 struct fi_ibv_rdm_ep *ep, int num_to_post)
-{
-	const size_t idx = (conn->cm_role == FI_VERBS_CM_SELF) ? 1 : 0;
-	struct ibv_recv_wr *bad_wr = NULL;
-	struct ibv_recv_wr wr[num_to_post];
-	struct ibv_sge sge[num_to_post];
-	int i, last = num_to_post - 1;
-
-	/* IBV_WR_SEND opcode specific */
-	assert((num_to_post % ep->n_buffs) == 0);
-
-	assert(ep->eopcode == IBV_WR_SEND ||
-	       ep->eopcode == IBV_WR_RDMA_WRITE_WITH_IMM);
-
-	if (ep->eopcode == IBV_WR_SEND) {
-		if (last >= 0) {
-			sge[last].addr = (uint64_t)(uintptr_t)
-				fi_ibv_rdm_get_rbuf(conn, ep,
-						    last % ep->n_buffs);
-			sge[last].length = ep->buff_len;
-			sge[last].lkey =
-				fi_ibv_mr_internal_lkey(&conn->r_md);
-
-			wr[last].wr_id = (uintptr_t)conn;
-			wr[last].next = NULL;
-			wr[last].sg_list = &sge[last];
-			wr[last].num_sge = 1;
-		}
-		for (i = num_to_post - 2; i >= 0; i--) {
-			sge[i].addr = (uint64_t)(uintptr_t)
-				fi_ibv_rdm_get_rbuf(conn, ep,
-						    i % ep->n_buffs);
-			sge[i].length = ep->buff_len;
-			sge[i].lkey =
-				fi_ibv_mr_internal_lkey(&conn->r_md);
-
-			wr[i].wr_id = (uintptr_t)conn;
-			wr[i].next = &wr[i + 1];
-			wr[i].sg_list = &sge[i];
-			wr[i].num_sge = 1;
-		}
-	} else {
-		if (last >= 0) {
-			wr[last].wr_id = (uintptr_t)conn;
-			wr[last].next = NULL;
-			wr[last].sg_list = &sge[last];
-			wr[last].num_sge = 1;
-		}
-		for (i = num_to_post - 2; i >= 0; i--) {
-			wr[i].wr_id = (uintptr_t)conn;
-			wr[i].next = &wr[i + 1];
-			wr[i].sg_list = &sge[i];
-			wr[i].num_sge = 1;
-		}
-	}
-
-	if (ibv_post_recv(conn->qp[idx], wr, &bad_wr) == 0) {
-		conn->av_entry->recv_preposted += num_to_post;
-		return num_to_post;
-	}
-
-	VERBS_INFO(FI_LOG_EP_DATA, "Failed to post recv\n");
-	return -FI_ENOMEM;
-}
-
-ssize_t fi_ibv_rdm_repost_receives(struct fi_ibv_rdm_conn *conn,
-				   struct fi_ibv_rdm_ep *ep, int num_to_post)
-{
-	assert(num_to_post > 0);
-	const ssize_t batch_size = ep->n_buffs * 10;
-
-	ssize_t rest = num_to_post - (num_to_post % ep->n_buffs);
-	ssize_t count = 0;
-	while (rest) {
-		const ssize_t batch = MIN(rest, batch_size);
-		const ssize_t ret =
-			fi_ibv_rdm_batch_repost_receives(conn, ep, batch);
-
-		if (ret < 0) {
-			return ret;
-		}
-
-		count += ret;
-		rest -= ret;
-
-		assert(ret == batch);
-	}
-
-	return count;
-}
-
-static ssize_t
-fi_ibv_rdm_prepare_conn_memory(struct fi_ibv_rdm_ep *ep,
-			       struct fi_ibv_rdm_conn *conn)
-{
-	assert(conn->s_md.mr == NULL);
-	assert(conn->r_md.mr == NULL);
-
-	const size_t size = ep->buff_len * ep->n_buffs;
-	int ret;
-	void *ack_status = &conn->sbuf_ack_status;
-	
-	ret = fi_ibv_rdm_alloc_and_reg(ep, (void **)&conn->sbuf_mem_reg,
-				       size, &conn->s_md);
-	if (ret) {
-		assert(!ret);
-		goto s_err;
-	}
-
-	ret = fi_ibv_rdm_alloc_and_reg(ep, (void **)&conn->rbuf_mem_reg,
-				       size, &conn->r_md);
-	if (ret) {
-		assert(!ret);
-		goto r_err;
-	}
-
-	ret = fi_ibv_rdm_alloc_and_reg(ep, &ack_status,
-				       sizeof(conn->sbuf_ack_status),
-				       &conn->ack_md);
-	if (ret) {
-		assert(conn->ack_md.mr);
-		goto ack_err;
-	}
-
-	ret = fi_ibv_rdm_alloc_and_reg(ep, (void **)&conn->rmabuf_mem_reg,
-				       size, &conn->rma_md);
-	if (ret) {
-		assert(!ret);
-		goto rma_err;
-	}
-
-	fi_ibv_rdm_buffer_lists_init(conn, ep);
-
-	return FI_SUCCESS;
-
-/* Error handling */
-rma_err:
-	free(conn->rmabuf_mem_reg);
-ack_err: /*
-	  * Ack buffer is a part of connection structure, freeing is not needed
-	  */
-r_err:
-	free(conn->rbuf_mem_reg);
-s_err:
-	free(conn->sbuf_mem_reg);
-
-	/* The is a lack of host or HCA memory */
-	return -FI_ENOMEM;
-}
-
-static inline void
-fi_ibv_rdm_tagged_init_qp_attributes(struct ibv_qp_init_attr *qp_attr,
-				     struct fi_ibv_rdm_ep *ep)
-{
-	assert(ep->scq && ep->rcq);
-	memset(qp_attr, 0, sizeof(*qp_attr));
-	qp_attr->send_cq = ep->scq;
-	qp_attr->recv_cq = ep->rcq;
-	qp_attr->qp_type = IBV_QPT_RC;
-	qp_attr->cap.max_send_wr = ep->sq_wr_depth;
-	qp_attr->cap.max_recv_wr = ep->rq_wr_depth;
-	qp_attr->cap.max_send_sge = 1;
-	qp_attr->cap.max_recv_sge = 1;
-	qp_attr->cap.max_inline_data = ep->max_inline_rc;
-	qp_attr->sq_sig_all = 1;
-}
-
-static void
-fi_ibv_rdm_pack_cm_params(struct rdma_conn_param *cm_params,
-			  struct fi_conn_priv_params *priv,
-			  const struct fi_ibv_rdm_conn *conn,
-			  const struct fi_ibv_rdm_ep *ep)
-{
-	memset(cm_params, 0, sizeof(struct rdma_conn_param));
-	cm_params->responder_resources = 2;
-	cm_params->initiator_depth = 2;
-	cm_params->private_data = priv;
-
-	memcpy(priv->addr, &ep->my_addr, FI_IBV_RDM_DFLT_ADDRLEN);
-
-	if ((conn->cm_role != FI_VERBS_CM_SELF) &&
-	    conn->r_md.mr && conn->s_md.mr) {
-		cm_params->private_data_len = sizeof(*priv);
-
-		priv->rbuf_rkey = fi_ibv_mr_internal_rkey(
-			(struct fi_ibv_mem_desc *)&conn->r_md);
-		priv->rbuf_mem_reg = conn->rbuf_mem_reg;
-		priv->sbuf_rkey = fi_ibv_mr_internal_rkey(
-			(struct fi_ibv_mem_desc *)&conn->s_md);
-		priv->sbuf_mem_reg = conn->sbuf_mem_reg;
-	} else {
-		cm_params->private_data_len = FI_IBV_RDM_DFLT_ADDRLEN;
-	}
-}
-
-
-static void
-fi_ibv_rdm_unpack_cm_params(const struct rdma_conn_param *cm_param,
-			    struct fi_ibv_rdm_conn *conn,
-			    struct fi_ibv_rdm_ep *ep)
-{
-	const struct fi_conn_priv_params *priv = cm_param->private_data;
-
-	if (conn->cm_role == FI_VERBS_CM_SELF) {
-		if (conn->r_md.mr && conn->s_md.mr) {
-			memcpy(&conn->addr, &ep->my_addr,
-				FI_IBV_RDM_DFLT_ADDRLEN);
-			conn->remote_rbuf_rkey =
-				fi_ibv_mr_internal_rkey(&conn->r_md);
-			conn->remote_rbuf_mem_reg = conn->r_md.mr->addr;
-
-			conn->remote_sbuf_rkey =
-				fi_ibv_mr_internal_rkey(&conn->s_md);
-			conn->remote_sbuf_mem_reg = conn->s_md.mr->addr;
-
-			conn->remote_sbuf_head = (struct fi_ibv_rdm_buf *)
-				conn->remote_sbuf_mem_reg;
-		}
-	} else {
-		if (conn->state == FI_VERBS_CONN_ALLOCATED) {
-			memcpy(&conn->addr, priv->addr, FI_IBV_RDM_DFLT_ADDRLEN);
-		}
-
-		conn->remote_rbuf_rkey = priv->rbuf_rkey;
-		conn->remote_rbuf_mem_reg = priv->rbuf_mem_reg;
-		conn->remote_sbuf_rkey = priv->sbuf_rkey;
-		conn->remote_sbuf_mem_reg = priv->sbuf_mem_reg;
-
-		conn->remote_sbuf_head = (struct fi_ibv_rdm_buf *)
-			conn->remote_sbuf_mem_reg;
-	}
-}
-
-static ssize_t
-fi_ibv_rdm_process_addr_resolved(const struct rdma_cm_event *event,
-				 struct fi_ibv_rdm_ep *ep)
-{
-	ssize_t ret = FI_SUCCESS;
-	struct ibv_qp_init_attr qp_attr;
-	struct fi_ibv_rdm_conn *conn = event->id->context;
-	struct rdma_cm_id *id = event->id;
-
-	VERBS_INFO(FI_LOG_AV, "ADDR_RESOLVED conn %p, addr %s:%u\n",
-		   conn, inet_ntoa(conn->addr.sin_addr),
-		   ntohs(conn->addr.sin_port));
-
-	assert(id->verbs == ep->domain->verbs);
-
-	fi_ibv_rdm_tagged_init_qp_attributes(&qp_attr, ep);
-	if (rdma_create_qp(id, ep->domain->pd, &qp_attr)) {
-		VERBS_INFO_ERRNO(FI_LOG_AV,
-				 "rdma_create_qp failed\n", errno);
-		return -errno;
-	}
-
-	if (conn->cm_role == FI_VERBS_CM_PASSIVE)
-		goto resolve_route;
-
-	conn->qp[0] = id->qp;
-	assert(conn->id[0] == id);
-	if (conn->cm_role == FI_VERBS_CM_SELF)
-		goto resolve_route;
-
-	ret = fi_ibv_rdm_prepare_conn_memory(ep, conn);
-	if (ret != FI_SUCCESS)
-			goto err;
-
-	ret = fi_ibv_rdm_repost_receives(conn, ep, ep->rq_wr_depth);
-	if (ret < 0) {
-		VERBS_INFO(FI_LOG_AV, "repost receives failed\n");
-		goto err;
-	} else {
-		ret = FI_SUCCESS;
-	}
-
-resolve_route:
-	if (rdma_resolve_route(id, FI_IBV_RDM_CM_RESOLVEADDR_TIMEOUT)) {
-		VERBS_INFO(FI_LOG_AV, "rdma_resolve_route failed\n");
-		ret = -FI_EHOSTUNREACH;
-		goto err;
-	}
-
-	return ret;
-err:
-	rdma_destroy_qp(id);
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_process_connect_request(const struct rdma_cm_event *event,
-				   struct fi_ibv_rdm_ep *ep)
-{
-	struct ibv_qp_init_attr qp_attr;
-	struct rdma_conn_param cm_params;
-	struct fi_conn_priv_params priv;
-	struct fi_ibv_rdm_av_entry *av_entry = NULL;
-	struct rdma_cm_id *id = event->id;
-	struct fi_ibv_rdm_conn *conn;
-	ssize_t ret = FI_SUCCESS;
-
-	char *p = (char *) event->param.conn.private_data;
-
-	if (ep->is_closing) {
-		int rej_message = 0xdeadbeef;
-		if (rdma_reject(id, &rej_message, sizeof(rej_message))) {
-			VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_reject\n", errno);
-			ret = -errno;
-			if (rdma_destroy_id(id)) {
-				VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_destroy_id\n",
-						 errno);
-				ret = (ret == FI_SUCCESS) ? -errno : ret;
-			}
-		}
-		assert(ret == FI_SUCCESS);
-		return ret;
-	}
-
-	HASH_FIND(hh, ep->domain->rdm_cm->av_hash, p,
-		  FI_IBV_RDM_DFLT_ADDRLEN, av_entry);
-
-	if (!av_entry) {
-		ret = fi_ibv_av_entry_alloc(ep->domain, &av_entry, p);
-		if (ret)
-			return ret;
-
-		ret = ofi_memalign((void**)&conn,
-				   FI_IBV_MEM_ALIGNMENT,
-				   sizeof(*conn));
-		if (ret) {
-			ofi_freealign(av_entry);
-			return -ret;
-		}
-
-		memset(conn, 0, sizeof(*conn));
-		conn->av_entry = av_entry;
-		conn->ep = ep;
-		conn->state = FI_VERBS_CONN_ALLOCATED;
-		dlist_init(&conn->postponed_requests_head);
-		fi_ibv_rdm_unpack_cm_params(&event->param.conn, conn, ep);
-		fi_ibv_rdm_conn_init_cm_role(conn, ep);
-		HASH_ADD(hh, av_entry->conn_hash, ep,
-			 sizeof(struct fi_ibv_rdm_ep *), conn);
-
-		VERBS_INFO(FI_LOG_AV, "CONN REQUEST, NOT found in hash, "
-			   "new conn %p %d, addr %s:%u, HASH ADD\n",
-			   conn, conn->cm_role, inet_ntoa(conn->addr.sin_addr),
-			   ntohs(conn->addr.sin_port));
-	} else {
-		HASH_FIND(hh, av_entry->conn_hash, &ep,
-			  sizeof(struct fi_ibv_rdm_ep *), conn);
-		if (!conn) {
-			ret = ofi_memalign((void**)&conn,
-					   FI_IBV_MEM_ALIGNMENT,
-					   sizeof(*conn));
-			if (ret)
-				return -ret;
-			memset(conn, 0, sizeof(*conn));
-			conn->ep = ep;
-			conn->av_entry = av_entry;
-			dlist_init(&conn->postponed_requests_head);
-			conn->state = FI_VERBS_CONN_ALLOCATED;
-			memcpy(&conn->addr, &av_entry->addr, FI_IBV_RDM_DFLT_ADDRLEN);
-			HASH_ADD(hh, av_entry->conn_hash, ep,
-				 sizeof(struct fi_ibv_rdm_ep *), conn);
-		}
-		fi_ibv_rdm_conn_init_cm_role(conn, ep);
-		if (conn->cm_role != FI_VERBS_CM_ACTIVE) {
-			/*
-			 * Do it before rdma_create_qp since that call would
-			 * modify event->param.conn.private_data buffer
-			 */
-			fi_ibv_rdm_unpack_cm_params(&event->param.conn, conn,
-						    ep);
-		}
-
-		VERBS_INFO(FI_LOG_AV,
-			   "CONN REQUEST,  FOUND in hash, conn %p %d, addr %s:%u\n",
-			   conn, conn->cm_role, inet_ntoa(conn->addr.sin_addr),
-			   ntohs(conn->addr.sin_port));
-	}
-
-	if (conn->cm_role == FI_VERBS_CM_ACTIVE) {
-		int rej_message = 0xdeadbeef;
-		if (rdma_reject(id, &rej_message, sizeof(rej_message))) {
-			VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_reject\n", errno);
-			ret = -errno;
-			if (rdma_destroy_id(id)) {
-				VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_destroy_id\n",
-						 errno);
-				ret = (ret == FI_SUCCESS) ? -errno : ret;
-			}
-		}
-		if (conn->state == FI_VERBS_CONN_ALLOCATED) {
-			ret = fi_ibv_rdm_start_connection(ep, conn);
-			if (ret != FI_SUCCESS)
-				goto err;
-		}
-	} else {
-		assert(conn->state == FI_VERBS_CONN_ALLOCATED ||
-		       conn->state == FI_VERBS_CONN_STARTED);
-
-		const size_t idx = (conn->cm_role == FI_VERBS_CM_SELF) ? 1 : 0;
-
-		conn->state = FI_VERBS_CONN_STARTED;
-		assert (conn->id[idx] == NULL);
-		conn->id[idx] = id;
-
-		ret = fi_ibv_rdm_prepare_conn_memory(ep, conn);
-		if (ret != FI_SUCCESS)
-			goto err;
-
-		fi_ibv_rdm_tagged_init_qp_attributes(&qp_attr, ep);
-		if (rdma_create_qp(id, ep->domain->pd, &qp_attr)) {
-			ret = -errno;
-			goto err;
-		}
-		conn->qp[idx] = id->qp;
-
-		ret = fi_ibv_rdm_repost_receives(conn, ep, ep->rq_wr_depth);
-		if (ret < 0) {
-			VERBS_INFO(FI_LOG_AV, "repost receives failed\n");
-			goto err;
-		} else {
-			ret = FI_SUCCESS;
-		}
-
-		id->context = conn;
-
-		fi_ibv_rdm_pack_cm_params(&cm_params, &priv, conn, ep);
-
-		if (rdma_accept(id, &cm_params)) {
-			VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_accept\n", errno);
-			ret = -errno;
-			goto err;
-		}
-	}
-
-	return ret;
-err:
-	/* ret err code is already set here, just cleanup resources */
-	fi_ibv_rdm_conn_cleanup(conn);
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_process_route_resolved(const struct rdma_cm_event *event,
-				  struct fi_ibv_rdm_ep *ep)
-{
-	struct fi_ibv_rdm_conn *conn = event->id->context;
-	ssize_t ret = FI_SUCCESS;
-	struct rdma_conn_param cm_params;
-	struct fi_conn_priv_params priv;
-
-	fi_ibv_rdm_pack_cm_params(&cm_params, &priv, conn, ep);
-
-	VERBS_INFO(FI_LOG_AV,
-		"ROUTE RESOLVED, conn %p, addr %s:%u\n", conn,
-		inet_ntoa(conn->addr.sin_addr), ntohs(conn->addr.sin_port));
-
-	if (rdma_connect(event->id, &cm_params)) {
-		VERBS_INFO_ERRNO(FI_LOG_AV,
-				 "rdma_connect failed\n", errno);
-		ret = -errno;
-
-		assert(0);
-	}
-
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_process_event_established(const struct rdma_cm_event *event,
-				     struct fi_ibv_rdm_ep *ep)
-{
-	struct fi_ibv_rdm_conn *conn =
-		(struct fi_ibv_rdm_conn *)event->id->context;
-
-	if (conn->state != FI_VERBS_CONN_STARTED &&
-	    conn->cm_role != FI_VERBS_CM_SELF) {
-		VERBS_WARN(FI_LOG_AV, "Wrong state! state = %d, conn %p",
-			   conn->state, conn);
-		assert(0);
-		return -FI_ECONNABORTED;
-	}
-
-	if (conn->cm_role == FI_VERBS_CM_ACTIVE ||
-	    conn->cm_role == FI_VERBS_CM_SELF)
-	{
-		fi_ibv_rdm_unpack_cm_params(&event->param.conn, conn, ep);
-	}
-
-	VERBS_INFO(FI_LOG_AV, "CONN ESTABLISHED, conn %p, addr %s:%u\n",
-		   conn, inet_ntoa(conn->addr.sin_addr),
-		   ntohs(conn->addr.sin_port));
-
-	/* Do not count self twice */
-	if (conn->state != FI_VERBS_CONN_ESTABLISHED) {
-		ep->num_active_conns++;
-		conn->state = FI_VERBS_CONN_ESTABLISHED;
-	}
-	return FI_SUCCESS;
-}
-
-/* since the function is invoked only in the `fi_ibv_domain_close`
- * after CM progress thread is closed, it's unnecessary to call this
- * with `rdm_cm::cm_lock held` */
-ssize_t fi_ibv_rdm_overall_conn_cleanup(struct fi_ibv_rdm_av_entry *av_entry)
-{
-	struct fi_ibv_rdm_conn *conn = NULL, *tmp = NULL;
-	ssize_t ret = FI_SUCCESS;
-	ssize_t err = FI_SUCCESS;
-
-	HASH_ITER(hh, av_entry->conn_hash, conn, tmp) {
-		ret = fi_ibv_rdm_conn_cleanup(conn);
-		if (ret) {
-			VERBS_INFO(FI_LOG_AV, "Conn cleanup failed (%zd) "
-				   "for av_entry = %p", ret, av_entry);
-			err = ret;
-		}
-	}
-
-	return err;
-}
-
-ssize_t fi_ibv_rdm_conn_cleanup(struct fi_ibv_rdm_conn *conn)
-{
-	ssize_t ret = FI_SUCCESS;
-	ssize_t err = FI_SUCCESS;
-
-	VERBS_DBG(FI_LOG_AV, "conn %p, exp = %zu unexp = %zu\n", conn,
-		     conn->exp_counter, conn->unexp_counter);
-
-	if (conn->id[0]) {
-		if (conn->id[0]->qp)
-			rdma_destroy_qp(conn->id[0]);
-
-		if (rdma_destroy_id(conn->id[0])) {
-			VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_destroy_id\n", errno);
-			if (ret == FI_SUCCESS)
-				ret = -errno;
-		}
-		conn->id[0] = NULL;
-	}
-
-	if (conn->id[1]) {
-		assert(conn->cm_role == FI_VERBS_CM_SELF);
-		if (conn->id[1]->qp)
-			rdma_destroy_qp(conn->id[1]);
-
-		if (rdma_destroy_id(conn->id[1])) {
-			VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_destroy_id\n", errno);
-			if (ret == FI_SUCCESS)
-				ret = -errno;
-		}
-		conn->id[1] = NULL;
-	}
-
-	if (conn->s_md.mr) {
-		err = fi_ibv_rdm_dereg_and_free(&conn->s_md, &conn->sbuf_mem_reg);
-		if ((err != FI_SUCCESS) && (ret == FI_SUCCESS))
-			ret = err;
-	}
-	if (conn->r_md.mr) {
-		err = fi_ibv_rdm_dereg_and_free(&conn->r_md, &conn->rbuf_mem_reg);
-		if ((err != FI_SUCCESS) && (ret == FI_SUCCESS))
-			ret = err;
-	}
-	if (conn->ack_md.mr) {
-		ret = fi_ibv_rdm_dereg_and_free(&conn->ack_md, NULL);
-		if (ret) {
-			VERBS_WARN(FI_LOG_AV,
-				   "Unable to dereg MR, ret = %"PRId64"\n",
-				   ret);
-		}
-	}
-
-	if (conn->rma_md.mr) {
-		err = fi_ibv_rdm_dereg_and_free(&conn->rma_md,
-						&conn->rmabuf_mem_reg);
-		if ((err != FI_SUCCESS) && (ret == FI_SUCCESS))
-			ret = err;
-	}
-
-	ofi_freealign(conn);
-	return ret;
-}
-
-static int fi_ibv_rdm_poll_cq(struct fi_ibv_rdm_ep *ep)
-{
-	int i, ret = 0;
-	const int wc_count = ep->fi_scq->read_bunch_size;
-	struct ibv_wc wc[wc_count];
-
-	ret = ibv_poll_cq(ep->scq, wc_count, wc);
-	for (i = 0; i < ret; ++i)
-		if (fi_ibv_rdm_process_send_wc(ep, &wc[i]))
-			fi_ibv_rdm_process_err_send_wc(ep, &wc[i]);
-
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_process_event_disconnected(const struct rdma_cm_event *event,
-				      struct fi_ibv_rdm_ep *ep)
-{
-	struct fi_ibv_rdm_conn *conn = event->id->context;
-	int ret = 0;
-
-	ep->num_active_conns--;
-	conn->state = FI_VERBS_CONN_CLOSED;
-
-	VERBS_INFO(FI_LOG_AV,
-		   "Disconnected from conn %p, addr %s:%u\n",
-		   conn, inet_ntoa(conn->addr.sin_addr),
-		   ntohs(conn->addr.sin_port));
-
-	/* Retrieve CQ entries from send Completion Queue if any  */
-	do {
-		ret = fi_ibv_rdm_poll_cq(ep);
-	} while (ret > 0);
-
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_process_event_rejected(const struct rdma_cm_event *event,
-				  struct fi_ibv_rdm_ep *ep)
-
-{
-	struct fi_ibv_rdm_conn *conn = event->id->context;
-	ssize_t ret = FI_SUCCESS;
-	const int *pdata = event->param.conn.private_data;
-
-	if (ep->is_closing) {
-		conn->state = FI_VERBS_CONN_CLOSED;
-	} else if ((pdata && *pdata == 0xdeadbeef) ||
-		/*
-		 * TODO: this is a workaround of the case when private_data is not
-		 * arriving from rdma_reject call on iWarp devices
-		 */
-		   (conn->cm_role == FI_VERBS_CM_PASSIVE &&
-		    event->status == -ECONNREFUSED)) {
-		rdma_destroy_qp(event->id);
-
-		if (rdma_destroy_id(event->id)) {
-			VERBS_INFO_ERRNO(FI_LOG_AV, "rdma_destroy_id failed\n",
-					 errno);
-			if (ret == FI_SUCCESS)
-				ret = -errno;
-		}
-	} else {
-		VERBS_INFO(FI_LOG_AV,
-			   "Unexpected REJECT from conn %p, addr %s:%u, cm_role %d, "
-			   "msg len %d, msg %x, status %d, err %d\n",
-			   conn, inet_ntoa(conn->addr.sin_addr),
-			   ntohs(conn->addr.sin_port),
-			   conn->cm_role,
-			   event->param.conn.private_data_len,
-			   event->param.conn.private_data ?
-			   *(int *)event->param.conn.private_data : 0,
-			   event->status, errno);
-		conn->state = FI_VERBS_CONN_REJECTED;
-		return FI_SUCCESS;	
-	}
-
-	VERBS_INFO(FI_LOG_AV,
-		   "Rejected %s from conn %p, addr %s:%u, cm_role %d, status %d\n",
-		   (ep->is_closing ? "(not handled)" : ""),
-		   conn, inet_ntoa(conn->addr.sin_addr),
-		   ntohs(conn->addr.sin_port),
-		   conn->cm_role,
-		   event->status);
-	return ret;
-}
-
-static inline void
-fi_ibv_rdm_process_timewait_exit_event(const struct rdma_cm_event *event,
-				       struct fi_ibv_rdm_ep *ep)
-{
-	struct fi_ibv_rdm_conn *conn = event->id->context;
-	struct fi_ibv_rdm_request *request = NULL;
-
-	VERBS_INFO(FI_LOG_AV, "Handle TIMEWAIT Exit event "
-		   "from conn %p, addr %s:%u\n",
-		   conn, inet_ntoa(conn->addr.sin_addr),
-		   ntohs(conn->addr.sin_port));
-
-	/* Cleanup posted queue */
-	while (NULL !=
-		(request = fi_ibv_rdm_take_first_from_posted_queue(ep))) {
-		request->context->internal[0] = NULL;
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(ep->fi_ibv_rdm_request_pool, request);
-	}
-}
-
-/* Must call with `rdm_cm::cm_lock held` */
-static ssize_t
-fi_ibv_rdm_process_event(const struct rdma_cm_event *event, struct fi_ibv_rdm_ep *ep)
-{
-	ssize_t ret = FI_SUCCESS;
-	switch (event->event) {
-	case RDMA_CM_EVENT_ADDR_RESOLVED:
-		ret = fi_ibv_rdm_process_addr_resolved(event, ep);
-		break;
-	case RDMA_CM_EVENT_ROUTE_RESOLVED:
-		ret = fi_ibv_rdm_process_route_resolved(event, ep);
-		break;
-	case RDMA_CM_EVENT_ESTABLISHED:
-		ret = fi_ibv_rdm_process_event_established(event, ep);
-		break;
-	case RDMA_CM_EVENT_DISCONNECTED:
-		ret = fi_ibv_rdm_process_event_disconnected(event, ep);
-		break;
-	case RDMA_CM_EVENT_CONNECT_REQUEST:
-		ret = fi_ibv_rdm_process_connect_request(event, ep);
-		break;
-	case RDMA_CM_EVENT_REJECTED:
-		ret = fi_ibv_rdm_process_event_rejected(event, ep);
-		break;
-	case RDMA_CM_EVENT_TIMEWAIT_EXIT:
-		fi_ibv_rdm_process_timewait_exit_event(event, ep);
-		ret = FI_SUCCESS;
-		break;
-	case RDMA_CM_EVENT_ADDR_ERROR:
-		ret = -FI_EADDRNOTAVAIL;
-		goto print_err;
-	case RDMA_CM_EVENT_ROUTE_ERROR:
-		ret = -FI_EHOSTUNREACH;
-		goto print_err;
-	case RDMA_CM_EVENT_CONNECT_ERROR:
-		ret = -FI_ECONNREFUSED;
-		goto print_err;
-	case RDMA_CM_EVENT_UNREACHABLE:
-		ret = -FI_EADDRNOTAVAIL;
-		goto print_err;
-	default:
-		ret = -FI_ECONNABORTED;
-print_err:
-		VERBS_INFO(FI_LOG_AV, "got unexpected rdmacm event, %s\n",
-			   rdma_event_str(event->event));
-		break;
-	}
-
-	return ret;
-}
-
-ssize_t fi_ibv_rdm_cm_progress(struct fi_ibv_rdm_ep *ep)
-{
-	ssize_t ret;
-
-	do {
-		struct rdma_cm_event event_copy;
-		struct fi_conn_priv_params priv;
-		struct rdma_cm_event *event;
-
-		if (rdma_get_cm_event(ep->domain->rdm_cm->ec, &event)) {
-			if (errno == EAGAIN) {
-				usleep(ep->domain->rdm_cm->cm_progress_timeout);
-				ret = FI_SUCCESS;
-				break;
-			}
-
-			VERBS_INFO_ERRNO(FI_LOG_AV,
-					 "rdma_get_cm_event failed\n", errno);
-			ret = -errno;
-			break;
-		}
-
-		memcpy(&event_copy, event, sizeof(*event));
-		if (event->param.conn.private_data_len) {
-			size_t len = MIN(event->param.conn.private_data_len,
-					 sizeof(struct fi_conn_priv_params));
-
-			memcpy(&priv, event->param.conn.private_data, len);
-
-			event_copy.param.conn.private_data = &priv;
-			event_copy.param.conn.private_data_len = len;
-		}
-
-		if (rdma_ack_cm_event(event)) {
-			VERBS_INFO_ERRNO(FI_LOG_AV,
-					 "rdma_get_cm_event failed\n", errno);
-			ret = -errno;
-			break;
-		}
-
-		pthread_mutex_lock(&ep->domain->rdm_cm->cm_lock);
-		ret = fi_ibv_rdm_process_event(&event_copy, ep);
-		pthread_mutex_unlock(&ep->domain->rdm_cm->cm_lock);
-	} while (ret == FI_SUCCESS);
-
-	return ret;
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_cntr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_cntr.c
deleted file mode 100644
index bd763c983..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_cntr.c
+++ /dev/null
@@ -1,168 +0,0 @@
-/*
- * Copyright (c) 2013-2017 Intel Corporation, Inc.  All rights reserved.
- * Copyright (c) 2016 Cisco Systems, Inc. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "ofi_enosys.h"
-
-#include "verbs_rdm.h"
-
-
-static uint64_t fi_ibv_rdm_cntr_read(struct fid_cntr *cntr_fid)
-{
-	struct fi_ibv_rdm_cntr *cntr =
-		container_of(cntr_fid, struct fi_ibv_rdm_cntr, fid);
-	return cntr->value;
-}
-
-static uint64_t fi_ibv_rdm_cntr_readerr(struct fid_cntr *cntr_fid)
-{
-	struct fi_ibv_rdm_cntr *cntr =
-		container_of(cntr_fid, struct fi_ibv_rdm_cntr, fid);
-	return cntr->err_count;
-}
-
-static int fi_ibv_rdm_cntr_add(struct fid_cntr *cntr_fid, uint64_t value)
-{
-	struct fi_ibv_rdm_cntr *cntr =
-		container_of(cntr_fid, struct fi_ibv_rdm_cntr, fid);
-	cntr->value += value;
-	return 0;
-}
-
-static int fi_ibv_rdm_cntr_set(struct fid_cntr *cntr_fid, uint64_t value)
-{
-	struct fi_ibv_rdm_cntr *cntr =
-		container_of(cntr_fid, struct fi_ibv_rdm_cntr, fid);
-	cntr->value = value;
-	return 0;
-}
-
-static int fi_ibv_rdm_cntr_adderr(struct fid_cntr *cntr_fid, uint64_t value)
-{
-	struct fi_ibv_rdm_cntr *cntr =
-		container_of(cntr_fid, struct fi_ibv_rdm_cntr, fid);
-	cntr->err_count += value;
-	return 0;
-}
-
-static int fi_ibv_rdm_cntr_seterr(struct fid_cntr *cntr_fid, uint64_t value)
-{
-	struct fi_ibv_rdm_cntr *cntr =
-		container_of(cntr_fid, struct fi_ibv_rdm_cntr, fid);
-	cntr->err_count = value;
-	return 0;
-}
-
-static struct fi_ops_cntr fi_ibv_rdm_cntr_ops = {
-	.size = sizeof(struct fi_ops_cntr),
-	.read = fi_ibv_rdm_cntr_read,
-	.readerr = fi_ibv_rdm_cntr_readerr,
-	.add = fi_ibv_rdm_cntr_add,
-	.set = fi_ibv_rdm_cntr_set,
-	.wait = fi_no_cntr_wait,
-	.adderr = fi_ibv_rdm_cntr_adderr,
-	.seterr = fi_ibv_rdm_cntr_seterr,
-};
-
-static int fi_ibv_rdm_cntr_close(struct fid *fid)
-{
-	struct fi_ibv_rdm_cntr *cntr =
-		container_of(fid, struct fi_ibv_rdm_cntr, fid);
-
-	if (ofi_atomic_get32(&cntr->ep_ref) > 0) {
-		return -FI_EBUSY;
-	}
-
-	free(cntr);
-	return 0;
-}
-
-static struct fi_ops fi_ibv_rdm_cntr_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = fi_ibv_rdm_cntr_close,
-	.bind = fi_no_bind,
-	.control = fi_no_control,
-	.ops_open = fi_no_ops_open,
-};
-
-int fi_rbv_rdm_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
-			struct fid_cntr **cntr_fid, void *context)
-{
-	struct fi_ibv_rdm_cntr *cntr;
-
-	struct fi_ibv_domain *dom =
-		container_of(domain, struct fi_ibv_domain, util_domain.domain_fid);
-
-	if (attr) {
-		switch (attr->events) {
-		case FI_CNTR_EVENTS_COMP:
-			break;
-		default:
-			return -FI_ENOSYS;
-		}
-
-		switch (attr->wait_obj) {
-		case FI_WAIT_NONE:
-		case FI_WAIT_UNSPEC:
-			break;
-		case FI_WAIT_MUTEX_COND:
-		case FI_WAIT_SET:
-		case FI_WAIT_FD:
-		default:
-			return -FI_ENOSYS;
-		}
-
-		if (attr->flags) {
-			return -FI_EINVAL;
-		}
-	}
-
-	cntr = calloc(1, sizeof(*cntr));
-	if (!cntr)
-		return -FI_ENOMEM;
-
-	if (attr) {
-		assert(sizeof(cntr->attr) == sizeof(*attr));
-		memcpy(&cntr->attr, attr, sizeof(*attr));
-	}
-
-	cntr->fid.fid.fclass = FI_CLASS_CNTR;
-	cntr->fid.fid.context = context;
-	cntr->fid.fid.ops = &fi_ibv_rdm_cntr_fi_ops;
-	cntr->fid.ops = &fi_ibv_rdm_cntr_ops;
-	cntr->domain = dom;
-	ofi_atomic_initialize32(&cntr->ep_ref, 0);
-
-	*cntr_fid = &cntr->fid;
-
-	return FI_SUCCESS;
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_msg.c
deleted file mode 100644
index 69ee381d7..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_msg.c
+++ /dev/null
@@ -1,286 +0,0 @@
-/*
- * Copyright (c) 2013-2016 Intel Corporation, Inc.  All rights reserved.
- * Copyright (c) 2016 Cisco Systems, Inc. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "ofi_iov.h"
-#include "ofi_enosys.h"
-
-#include "verbs_rdm.h"
-
-static ssize_t fi_ibv_rdm_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
-				  uint64_t flags)
-{
-	ssize_t ret = FI_SUCCESS;
-	struct fi_ibv_rdm_ep *ep_rdm =
-		container_of(ep, struct fi_ibv_rdm_ep, ep_fid);
-
-	if (msg->iov_count > 1) {
-		assert(0);
-		return -FI_EMSGSIZE;
-	}
-
-	struct fi_ibv_rdm_conn *conn = ep_rdm->av->addr_to_conn(ep_rdm, msg->addr);
-
-	struct fi_ibv_rdm_tagged_recv_start_data recv_data = {
-		.peek_data = {
-			.minfo = {
-				.conn = conn,
-				.tag = 0,
-				.tagmask = 0,
-				.is_tagged = 0
-			},
-			.context = msg->context,
-			.flags = ep_rdm->rx_op_flags |
-				(ep_rdm->rx_selective_completion ? flags :
-				(flags | FI_COMPLETION))
-		},
-		.dest_addr =
-			(msg->iov_count) ? msg->msg_iov[0].iov_base : NULL,
-		.data_len = (msg->iov_count) ? msg->msg_iov[0].iov_len : 0,
-		.ep = ep_rdm
-	};
-	struct fi_ibv_rdm_request *request =
-		util_buf_alloc(ep_rdm->fi_ibv_rdm_request_pool);
-	if (OFI_UNLIKELY(!request))
-		return -FI_EAGAIN;
-
-	fi_ibv_rdm_zero_request(request);
-	request->ep = ep_rdm;
-	FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", request, FI_LOG_DEBUG);
-	ret = fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_RECV_START,
-				  &recv_data);
-
-	VERBS_DBG(FI_LOG_EP_DATA,
-		  "conn %p, len %zu, rbuf %p, fi_ctx %p, posted_recv %"PRIu32"\n",
-		  conn, recv_data.data_len, recv_data.dest_addr,
-		  msg->context, ep_rdm->posted_recvs);
-
-	if (!ret && !request->state.err)
-		ret = rdm_trecv_second_event(request, ep_rdm);
-
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_recvv(struct fid_ep *ep, const struct iovec *iov,
-		 void **desc, size_t count, fi_addr_t src_addr,
-		 void *context)
-{
-	const struct fi_msg msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = src_addr,
-		.context = context,
-		.data = 0
-	};
-
-	return fi_ibv_rdm_recvmsg(ep, &msg, 0ULL);
-}
-
-static ssize_t
-fi_ibv_rdm_recv(struct fid_ep *ep, void *buf, size_t len, void *desc,
-		fi_addr_t src_addr, void *context)
-{
-	const struct iovec iov = {
-		.iov_base = buf,
-		.iov_len = len
-	};
-	return fi_ibv_rdm_recvv(ep, &iov, &desc, 1, src_addr, context);
-}
-
-static ssize_t fi_ibv_rdm_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
-				  uint64_t flags)
-{
-	struct fi_ibv_rdm_ep *ep_rdm = 
-		container_of(ep, struct fi_ibv_rdm_ep, ep_fid);
-	size_t i;
-	struct fi_ibv_rdm_send_start_data sdata = {
-		.ep_rdm = ep_rdm,
-		.conn = ep_rdm->av->addr_to_conn(ep_rdm, msg->addr),
-		.data_len = ofi_total_iov_len(msg->msg_iov, msg->iov_count),
-		.context = msg->context,
-		.flags = FI_MSG | FI_SEND | GET_TX_COMP_FLAG(ep_rdm, flags),
-		.tag = 0,
-		.is_tagged = 0,
-		.buf.src_addr = NULL,
-		.iov_count = 0,
-		.imm = (uint32_t) 0,
-		.stype = IBV_RDM_SEND_TYPE_GEN,
-	};
-
-	switch (msg->iov_count) {
-	case 1:
-		sdata.buf.src_addr = msg->msg_iov[0].iov_base;
-		/* FALL THROUGH */
-	case 0:
-		break;
-	default:
-		/* TODO: 
-		 * extra allocation & memcpy can be optimized if it's possible
-		 * to send immediately
-		 */
-		if ((msg->iov_count > sdata.ep_rdm->iov_per_rndv_thr) ||
-		    (sdata.data_len > sdata.ep_rdm->rndv_threshold))
-			return -FI_EMSGSIZE;
-		sdata.buf.iovec_arr =
-			util_buf_alloc(ep_rdm->fi_ibv_rdm_extra_buffers_pool);
-		for (i = 0; i < msg->iov_count; i++) {
-			sdata.buf.iovec_arr[i].iov_base = msg->msg_iov[i].iov_base;
-			sdata.buf.iovec_arr[i].iov_len = msg->msg_iov[i].iov_len;
-		}
-		sdata.iov_count = msg->iov_count;
-		sdata.stype = IBV_RDM_SEND_TYPE_VEC;
-		break;
-	}
-
-	return fi_ibv_rdm_send_common(&sdata);
-}
-
-static ssize_t fi_ibv_rdm_sendv(struct fid_ep *ep, const struct iovec *iov,
-				void **desc, size_t count, fi_addr_t dest_addr,
-				void *context)
-{
-	struct fi_ibv_rdm_ep *ep_rdm =
-		container_of(ep, struct fi_ibv_rdm_ep, ep_fid);
-
-	const struct fi_msg msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = dest_addr,
-		.context = context,
-		.data = 0
-	};
-
-	return fi_ibv_rdm_sendmsg(ep, &msg, GET_TX_COMP(ep_rdm));
-}
-
-static ssize_t fi_ibv_rdm_send(struct fid_ep *ep, const void *buf, size_t len,
-			       void *desc, fi_addr_t dest_addr, void *context)
-{
-	const struct iovec iov = {
-		.iov_base = (void *)buf,
-		.iov_len = len
-	};
-	return fi_ibv_rdm_sendv(ep, &iov, &desc, 1, dest_addr, context);
-}
-
-static ssize_t fi_ibv_rdm_inject(struct fid_ep *ep_fid, const void *buf,
-				 size_t len, fi_addr_t dest_addr)
-{
-	struct fi_ibv_rdm_ep *ep =
-		container_of(ep_fid, struct fi_ibv_rdm_ep, ep_fid);
-	struct fi_ibv_rdm_conn *conn = ep->av->addr_to_conn(ep, dest_addr);
-	const size_t size = len + sizeof(struct fi_ibv_rdm_header);
-
-	if (OFI_UNLIKELY(len > ep->rndv_threshold)) {
-		assert(0);
-		return -FI_EMSGSIZE;
-	}
-
-	if (!conn->postponed_entry) {
-		struct fi_ibv_rdm_buf *sbuf = 
-			fi_ibv_rdm_prepare_send_resources(conn);
-		if (sbuf) {
-			struct ibv_send_wr *bad_wr = NULL;
-			struct ibv_sge sge = {
-				.addr = (uintptr_t)(void *)sbuf,
-				.length = size + FI_IBV_RDM_BUFF_SERVICE_DATA_SIZE,
-				.lkey = fi_ibv_mr_internal_lkey(&conn->s_md),
-			};
-			struct ibv_send_wr wr = {
-				.wr_id = FI_IBV_RDM_PACK_SERVICE_WR(conn),
-				.sg_list = &sge,
-				.num_sge = 1,
-				.wr.rdma.remote_addr = (uintptr_t)
-					fi_ibv_rdm_get_remote_addr(conn, sbuf),
-				.wr.rdma.rkey = conn->remote_rbuf_rkey,
-				.send_flags = (sge.length < ep->max_inline_rc)
-					       ? IBV_SEND_INLINE : 0,
-				.opcode = ep->eopcode,
-			};
-
-			sbuf->service_data.pkt_len = size;
-			sbuf->header.tag = 0;
-			sbuf->header.service_tag = 0;
-
-			FI_IBV_RDM_SET_PKTTYPE(sbuf->header.service_tag,
-					       FI_IBV_RDM_MSG_PKT);
-			memcpy(&sbuf->payload, buf, len);
-
-			FI_IBV_RDM_INC_SIG_POST_COUNTERS(conn, ep);
-			if (OFI_UNLIKELY(ibv_post_send(conn->qp[0], &wr, &bad_wr))) {
-				assert(0);
-				return -errno;
-			} else {
-				VERBS_DBG(FI_LOG_EP_DATA,
-					  "posted %d bytes, conn %p, len %zu\n",
-					  sge.length, conn, len);
-				return FI_SUCCESS;
-			}
-		}
-	}
-
-	fi_ibv_rdm_tagged_poll(ep);
-
-	return -FI_EAGAIN;
-}
-
-static ssize_t fi_ibv_rdm_senddata(struct fid_ep *ep, const void *buf,
-				   size_t len, void *desc, uint64_t data,
-				   fi_addr_t dest_addr, void *context)
-{
-	assert(0);
-	return -FI_ENOSYS;
-}
-
-static ssize_t fi_ibv_rdm_injectdata(struct fid_ep *ep, const void *buf,
-				     size_t len, uint64_t data,
-				     fi_addr_t dest_addr)
-{
-	assert(0);
-	return -FI_ENOSYS;
-}
-
-struct fi_ops_msg fi_ibv_rdm_ep_msg_ops = {
-	.size = sizeof(struct fi_ops_msg),
-	.recv = fi_ibv_rdm_recv,
-	.recvv = fi_ibv_rdm_recvv,
-	.recvmsg = fi_ibv_rdm_recvmsg,
-	.send = fi_ibv_rdm_send,
-	.sendv = fi_ibv_rdm_sendv,
-	.sendmsg = fi_ibv_rdm_sendmsg,
-	.inject = fi_ibv_rdm_inject,
-	.senddata = fi_ibv_rdm_senddata,
-	.injectdata = fi_ibv_rdm_injectdata
-};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_rma.c
deleted file mode 100644
index 2fd520b0c..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_rdm_rma.c
+++ /dev/null
@@ -1,346 +0,0 @@
-/*
- * Copyright (c) 2018 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <rdma/fi_errno.h>
-
-#include "config.h"
-
-#include "verbs_rdm.h"
-
-static inline ssize_t
-fi_ibv_rdm_ep_rma_preinit(void **desc, struct fi_ibv_rdm_buf **rdm_buf,
-			  size_t len, struct fi_ibv_rdm_conn *conn,
-			  struct fi_ibv_rdm_ep *ep)
-{
-	assert(desc && rdm_buf);
-
-	if (*desc == NULL && len < ep->rndv_threshold) {
-		*rdm_buf = fi_ibv_rdm_rma_prepare_resources(conn);
-		if (*rdm_buf)
-			*desc = (void *)(uintptr_t)
-				fi_ibv_mr_internal_lkey(&conn->rma_md);
-		else
-			goto again;
-	} else if (!fi_ibv_rdm_check_connection(conn) ||
-		   RMA_RESOURCES_IS_BUSY(conn, ep) ||
-		   conn->postponed_entry) {
-		goto again;
-	}
-
-	return FI_SUCCESS;
-again:
-	fi_ibv_rdm_tagged_poll(ep);
-	return -FI_EAGAIN;
-}
-
-static ssize_t
-fi_ibv_rdm_ep_rma_readmsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
-		uint64_t flags)
-{
-	struct fi_ibv_rdm_ep *ep =
-		container_of(ep_fid, struct fi_ibv_rdm_ep, ep_fid);
-	struct fi_ibv_rdm_conn *conn = ep->av->addr_to_conn(ep, msg->addr);
-	struct fi_ibv_rdm_rma_start_data start_data = {
-		.ep_rdm = ep,
-		.conn = conn,
-		.context = msg->context,
-		.flags = FI_RMA | FI_READ | GET_TX_COMP_FLAG(ep, flags),
-		.data_len = (uint64_t)msg->msg_iov[0].iov_len,
-		.rbuf = (uintptr_t)msg->rma_iov[0].addr,
-		.lbuf = (uintptr_t)msg->msg_iov[0].iov_base,
-		.mr_rkey = (uint64_t)(uintptr_t)(msg->rma_iov[0].key),
-		.mr_lkey = (uint64_t)(uintptr_t)(msg->desc ? msg->desc[0] : NULL),
-		.op_code = IBV_WR_RDMA_READ
-	};
-	struct fi_ibv_rma_post_ready_data post_ready_data = { .ep_rdm = ep };
-
-	struct fi_ibv_rdm_buf *rdm_buf = NULL;
-	ssize_t ret = FI_SUCCESS;
-	struct fi_ibv_rdm_request *request;
-
-	if(msg->iov_count != 1 || msg->rma_iov_count != 1) {
-		assert(0);
-		return -FI_EMSGSIZE;
-	}
-
-	ret = fi_ibv_rdm_ep_rma_preinit((void**)&start_data.mr_lkey, &rdm_buf,
-					msg->msg_iov[0].iov_len,
-					conn, ep);
-	if (ret) {
-		return ret;
-	}
-
-	request = util_buf_alloc(ep->fi_ibv_rdm_request_pool);
-	if (OFI_UNLIKELY(!request))
-		return -FI_EAGAIN;
-
-	fi_ibv_rdm_zero_request(request);
-	request->ep = ep;
-	FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", request, FI_LOG_DEBUG);
-
-	/* Initial state */
-	request->state.eager = FI_IBV_STATE_EAGER_BEGIN;
-	request->state.rndv  = FI_IBV_STATE_RNDV_NOT_USED;
-	request->state.err   = FI_SUCCESS;
-
-	request->minfo.is_tagged = 0;
-	request->rmabuf = rdm_buf;
-
-	fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_RMA_START, &start_data);
-
-	return fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_POST_READY,
-				   &post_ready_data);
-}
-
-static ssize_t
-fi_ibv_rdm_ep_rma_readv(struct fid_ep *ep, const struct iovec *iov, void **desc,
-		size_t count, fi_addr_t src_addr, uint64_t addr, uint64_t key,
-		void *context)
-{
-	struct fi_ibv_rdm_ep *ep_rdm = 
-		container_of(ep, struct fi_ibv_rdm_ep, ep_fid);
-
-	struct fi_rma_iov rma_iov = {
-		.addr = addr,
-		.len = 0,
-		.key = key
-	};
-
-	struct fi_msg_rma msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = src_addr,
-		.rma_iov = &rma_iov,
-		.rma_iov_count = 1,
-		.context = context,
-		.data = 0
-	};
-
-	size_t i;
-	for (i = 0; i < count; i++) {
-		rma_iov.len += iov[i].iov_len;
-	}
-
-	return fi_ibv_rdm_ep_rma_readmsg(ep, &msg, GET_TX_COMP(ep_rdm));
-}
-
-static ssize_t
-fi_ibv_rdm_ep_rma_read(struct fid_ep *ep_fid, void *buf, size_t len,
-		    void *desc, fi_addr_t src_addr,
-		    uint64_t addr, uint64_t key, void *context)
-{
-	const struct iovec iov = {
-		.iov_base = buf,
-		.iov_len = len
-	};
-
-	return fi_ibv_rdm_ep_rma_readv(ep_fid, &iov, &desc, 1, src_addr, addr,
-					key, context);
-}
-
-static ssize_t
-fi_ibv_rdm_ep_rma_writemsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
-		uint64_t flags)
-{
-	struct fi_ibv_rdm_ep *ep = container_of(ep_fid, struct fi_ibv_rdm_ep,
-						ep_fid);
-	struct fi_ibv_rdm_conn *conn = ep->av->addr_to_conn(ep, msg->addr);
-	struct fi_ibv_rdm_request *request = NULL;
-	struct fi_ibv_rdm_buf *rdm_buf = NULL;
-	ssize_t ret = FI_SUCCESS;
-
-	struct fi_ibv_rdm_rma_start_data start_data = {
-		.conn = conn,
-		.ep_rdm = ep,
-		.context = msg->context,
-		.flags = FI_RMA | FI_WRITE | (ep->tx_selective_completion ?
-			(flags & FI_COMPLETION) : FI_COMPLETION),
-		.data_len = (uint64_t)msg->msg_iov[0].iov_len,
-		.rbuf = msg->rma_iov[0].addr,
-		.lbuf = (uintptr_t)msg->msg_iov[0].iov_base,
-		.mr_rkey = msg->rma_iov[0].key,
-		.mr_lkey = (uint64_t)(uintptr_t)(msg->desc ? msg->desc[0] : NULL),
-		.op_code = IBV_WR_RDMA_WRITE
-	};
-
-	if(msg->iov_count != 1 && msg->rma_iov_count != 1) {
-		assert(0);
-		return -FI_EMSGSIZE;
-	}
-
-	ret = fi_ibv_rdm_ep_rma_preinit((void**)&start_data.mr_lkey, &rdm_buf,
-					msg->msg_iov[0].iov_len,
-					conn, ep);
-	if (ret) {
-		return ret;
-	}
-
-	request = util_buf_alloc(ep->fi_ibv_rdm_request_pool);
-	if (OFI_UNLIKELY(!request))
-		return -FI_EAGAIN;
-
-	fi_ibv_rdm_zero_request(request);
-	request->ep = ep;
-	/* Initial state */
-	request->state.eager = FI_IBV_STATE_EAGER_BEGIN;
-	request->state.rndv  = FI_IBV_STATE_RNDV_NOT_USED;
-	request->state.err   = FI_SUCCESS;
-	request->minfo.is_tagged = 0;
-	request->rmabuf = rdm_buf;
-
-	FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", request, FI_LOG_DEBUG);
-
-	fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_RMA_START, &start_data);
-
-	struct fi_ibv_rma_post_ready_data post_ready_data = { .ep_rdm = ep };
-
-	return fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_POST_READY,
-				   &post_ready_data);
-}
-
-static ssize_t
-fi_ibv_rdm_ep_rma_writev(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
-		size_t count, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
-		void *context)
-{
-	struct fi_rma_iov rma_iov = {
-		.addr = addr,
-		.len = 0,
-		.key = key
-	};
-
-	struct fi_msg_rma msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = dest_addr,
-		.rma_iov = &rma_iov,
-		.rma_iov_count = 1,
-		.context = context,
-		.data = 0
-	};
-
-	size_t i;
-	for (i = 0; i < count; i++) {
-		rma_iov.len += iov[i].iov_len;
-	}
-
-	struct fi_ibv_rdm_ep *ep_rdm =
-		container_of(ep_fid, struct fi_ibv_rdm_ep, ep_fid);
-
-	return fi_ibv_rdm_ep_rma_writemsg(ep_fid, &msg, GET_TX_COMP(ep_rdm));
-}
-
-static ssize_t
-fi_ibv_rdm_ep_rma_write(struct fid_ep *ep_fid, const void *buf, size_t len,
-			void *desc, fi_addr_t dest_addr, uint64_t addr,
-			uint64_t key, void *context)
-{
-	const struct iovec iov = {
-		.iov_base = (void *)buf,
-		.iov_len = len
-	};
-
-	return fi_ibv_rdm_ep_rma_writev(ep_fid, &iov, &desc, 1, dest_addr, addr,
-					key, context);
-}
-
-static ssize_t fi_ibv_rdm_ep_rma_inject_write(struct fid_ep *ep,
-					      const void *buf, size_t len,
-					      fi_addr_t dest_addr,
-					      uint64_t addr, uint64_t key)
-{
-	struct fi_ibv_rdm_ep *ep_rdm = container_of(ep, struct fi_ibv_rdm_ep,
-						    ep_fid);
-	struct fi_ibv_rdm_conn *conn = ep_rdm->av->addr_to_conn(ep_rdm, dest_addr);
-	struct fi_ibv_rdm_rma_start_data start_data = {
-		.conn = conn,
-		.ep_rdm = ep_rdm,
-		.flags = 0, /* inject does not generate completion */
-		.data_len = (uint64_t)len,
-		.rbuf = addr,
-		.lbuf = (uintptr_t)buf,
-		.mr_rkey = (uint64_t)key,
-		.mr_lkey = 0
-	};
-	ssize_t ret;
-	struct fi_ibv_rdm_request *request =
-		util_buf_alloc(ep_rdm->fi_ibv_rdm_request_pool);
-
-	if (OFI_UNLIKELY(!request))
-		return -FI_EAGAIN;
-
-	fi_ibv_rdm_zero_request(request);
-	request->ep = ep_rdm;
-	FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", request, FI_LOG_DEBUG);
-
-	/* Initial state */
-	request->state.eager = FI_IBV_STATE_EAGER_RMA_INJECT;
-	request->state.rndv  = FI_IBV_STATE_RNDV_NOT_USED;
-	request->state.err   = FI_SUCCESS;
-
-	request->minfo.is_tagged = 0;
-	ret = fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_RMA_START, &start_data);
-
-	switch (ret)
-	{
-	case FI_SUCCESS:
-		return ret;
-	case -FI_EAGAIN:
-		break;
-	default:
-		ret = -errno;
-		break;
-	}
-
-	FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-	util_buf_release(ep_rdm->fi_ibv_rdm_request_pool, request);
-
-	fi_ibv_rdm_tagged_poll(ep_rdm);
-
-	return ret;
-}
-
-struct fi_ops_rma fi_ibv_rdm_ep_rma_ops = {
-	.size		= sizeof(struct fi_ops_rma),
-	.read		= fi_ibv_rdm_ep_rma_read,
-	.readv		= fi_ibv_rdm_ep_rma_readv,
-	.readmsg	= fi_ibv_rdm_ep_rma_readmsg,
-	.write		= fi_ibv_rdm_ep_rma_write,
-	.writev		= fi_ibv_rdm_ep_rma_writev,
-	.writemsg	= fi_ibv_rdm_ep_rma_writemsg,
-	.inject		= fi_ibv_rdm_ep_rma_inject_write,
-	.writedata	= fi_no_rma_writedata,
-	.injectdata	= fi_no_rma_injectdata,
-};
-
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm.c
deleted file mode 100644
index fe15e93fe..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm.c
+++ /dev/null
@@ -1,729 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <prov/verbs/src/fi_verbs.h>
-
-#include <config.h>
-
-#include <ofi_list.h>
-#include <ofi_enosys.h>
-#include <ofi_iov.h>
-#include <rdma/fi_tagged.h>
-
-#include "verbs_queuing.h"
-#include "verbs_tagged_ep_rdm_states.h"
-
-static inline int fi_ibv_rdm_tagged_poll_send(struct fi_ibv_rdm_ep *ep);
-
-int
-fi_ibv_rdm_tagged_prepare_send_request(struct fi_ibv_rdm_request *request,
-				       struct fi_ibv_rdm_ep *ep)
-{
-#if ENABLE_DEBUG
-	int res = OUTGOING_POST_LIMIT(request->minfo.conn, ep);
-	if (res) {
-		FI_IBV_RDM_DBG_REQUEST
-			("failed because OUTGOING_POST_LIMIT", request,
-			FI_LOG_DEBUG);
-		return !res;
-	}
-	res = PEND_POST_LIMIT(ep);
-	if (res) {
-		FI_IBV_RDM_DBG_REQUEST
-			("failed because PEND_POST_LIMIT", request,
-			FI_LOG_DEBUG);
-		return !res;
-	}
-#endif // ENABLE_DEBUG
-	request->sbuf = fi_ibv_rdm_prepare_send_resources(request->minfo.conn);
-	return !!request->sbuf;
-}
-
-int
-fi_ibv_rdm_prepare_rma_request(struct fi_ibv_rdm_request *request,
-				struct fi_ibv_rdm_ep *ep)
-{
-	request->rmabuf =
-		fi_ibv_rdm_rma_prepare_resources(request->minfo.conn);
-	return !!request->rmabuf;
-}
-
-static int fi_ibv_rdm_tagged_getname(fid_t fid, void *addr, size_t * addrlen)
-{
-	struct fi_ibv_rdm_ep *ep;
-
-	if (fid->fclass == FI_CLASS_EP) {
- 		ep = container_of(fid, struct fi_ibv_rdm_ep, ep_fid);
-	} else {
-		VERBS_INFO(FI_LOG_EP_CTRL, "Invalid fid class: %zd\n",
-			  fid->fclass);
-		return -FI_EINVAL;
-	}
-
-	if (FI_IBV_RDM_DFLT_ADDRLEN > *addrlen) {
-		*addrlen = FI_IBV_RDM_DFLT_ADDRLEN;
-		return -FI_ETOOSMALL;
-	}
-
-	memset(addr, 0, *addrlen);
-	memcpy(addr, &ep->my_addr, FI_IBV_RDM_DFLT_ADDRLEN);
-	*addrlen = FI_IBV_RDM_DFLT_ADDRLEN;
-	ep->addrlen = FI_IBV_RDM_DFLT_ADDRLEN;
-
-	return 0;
-}
-
-static ssize_t
-fi_ibv_rdm_tagged_recvmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *msg,
-			  uint64_t flags)
-{
-	ssize_t ret = FI_SUCCESS;
-	struct fi_ibv_rdm_ep *ep_rdm =
-		container_of(ep_fid, struct fi_ibv_rdm_ep, ep_fid);
-	struct fi_ibv_rdm_conn *conn = ep_rdm->av->addr_to_conn(ep_rdm, msg->addr);
-
-	if (msg->iov_count > 1) {
-		assert(0);
-		return -FI_EMSGSIZE;
-	}
-
-	struct fi_ibv_rdm_tagged_recv_start_data recv_data = {
-		.peek_data = {
-			.minfo = {
-				.conn = conn,
-				.tag = msg->tag,
-				.tagmask = ~(msg->ignore),
-				.is_tagged = 1
-			},
-			.context = msg->context,
-			.flags = ep_rdm->rx_op_flags |
-				(ep_rdm->rx_selective_completion ? flags :
-				(flags | FI_COMPLETION))
-		},
-		.dest_addr =
-			(msg->iov_count) ? msg->msg_iov[0].iov_base : NULL,
-		.data_len = (msg->iov_count) ? msg->msg_iov[0].iov_len : 0,
-		.ep = ep_rdm
-	};
-
-	struct fi_ibv_rdm_request *request =
-		util_buf_alloc(ep_rdm->fi_ibv_rdm_request_pool);
-	if (OFI_UNLIKELY(!request))
-		return -FI_EAGAIN;
-	fi_ibv_rdm_zero_request(request);
-	request->ep = ep_rdm;
-	FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", request, FI_LOG_DEBUG);
-
-	if (flags & FI_PEEK) {
-		recv_data.peek_data.flags |= FI_COMPLETION;
-		ret = fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_RECV_PEEK,
-					  &recv_data);
-		if (ret == -FI_ENOMSG)
-			fi_ibv_rdm_tagged_poll(ep_rdm);
-	} else if (flags & FI_CLAIM) {
-		recv_data.peek_data.flags |= FI_COMPLETION;
-		ret = fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_RECV_START,
-					  &recv_data);
-		if (!ret)
-			ret = rdm_trecv_second_event(request, ep_rdm);
-	} else {
-		ret = fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_RECV_START,
-					  &recv_data);
-
-		VERBS_DBG(FI_LOG_EP_DATA,
-			  "fi_recvfrom: conn %p, tag 0x%" PRIx64 ", len %zu, rbuf %p, "
-			  "fi_ctx %p, posted_recv %"PRIu32"\n",
-			  conn, msg->tag, recv_data.data_len, recv_data.dest_addr,
-			  msg->context, ep_rdm->posted_recvs);
-
-		if (!ret && !request->state.err)
-			ret = rdm_trecv_second_event(request, ep_rdm);
-	}
-
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_tagged_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
-			size_t count, fi_addr_t src_addr, uint64_t tag,
-			uint64_t ignore, void *context)
-{
-	const struct fi_msg_tagged msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = src_addr,
-		.tag = tag,
-		.ignore = ignore,
-		.context = context,
-		.data = 0
-	};
-
-	return fi_ibv_rdm_tagged_recvmsg(ep_fid, &msg, 0ULL);
-}
-
-static ssize_t fi_ibv_rdm_tagged_recvfrom(struct fid_ep *ep_fid, void *buf,
-					  size_t len, void *desc,
-					  fi_addr_t src_addr, uint64_t tag,
-					  uint64_t ignore, void *context)
-{
-	const struct iovec iov = {
-		.iov_base = buf,
-		.iov_len = len
-	};
-
-	return fi_ibv_rdm_tagged_recvv(ep_fid, &iov, &desc, 1, src_addr, tag,
-					ignore, context);
-}
-
-static inline ssize_t 
-fi_ibv_rdm_tagged_inject(struct fid_ep *fid, const void *buf, size_t len, 
-			 fi_addr_t dest_addr, uint64_t tag)
-{
-	struct fi_ibv_rdm_ep *ep =
-		container_of(fid, struct fi_ibv_rdm_ep, ep_fid);
-	struct fi_ibv_rdm_conn *conn = ep->av->addr_to_conn(ep, dest_addr);
-	const size_t size = len + sizeof(struct fi_ibv_rdm_header);
-
-	if (OFI_UNLIKELY(len > ep->rndv_threshold)) {
-		assert(0);
-		return -FI_EMSGSIZE;
-	}
-
-	if (!conn->postponed_entry) {
-		struct fi_ibv_rdm_buf *sbuf = 
-			fi_ibv_rdm_prepare_send_resources(conn);
-		if (sbuf) {
-			struct ibv_send_wr *bad_wr = NULL;
-			struct ibv_sge sge = {
-				.addr = (uintptr_t)(void *)sbuf,
-				.length = size + FI_IBV_RDM_BUFF_SERVICE_DATA_SIZE,
-				.lkey = fi_ibv_mr_internal_lkey(&conn->s_md),
-			};
-			struct ibv_send_wr wr = {
-				.wr_id = FI_IBV_RDM_PACK_SERVICE_WR(conn),
-				.sg_list = &sge,
-				.num_sge = 1,
-				.wr.rdma.remote_addr = (uintptr_t)
-					fi_ibv_rdm_get_remote_addr(conn, sbuf),
-				.wr.rdma.rkey = conn->remote_rbuf_rkey,
-				.send_flags = (sge.length < ep->max_inline_rc)
-					       ? IBV_SEND_INLINE : 0,
-				.opcode = ep->eopcode,
-			};
-
-			sbuf->service_data.pkt_len = size;
-			sbuf->header.tag = tag;
-			sbuf->header.service_tag = 0;
-
-			FI_IBV_RDM_SET_PKTTYPE(sbuf->header.service_tag,
-					       FI_IBV_RDM_EAGER_PKT);
-			memcpy(&sbuf->payload, buf, len);
-
-			FI_IBV_RDM_INC_SIG_POST_COUNTERS(conn, ep);
-			if (OFI_UNLIKELY(ibv_post_send(conn->qp[0], &wr, &bad_wr))) {
-				assert(0);
-				return -errno;
-			} else {
-				VERBS_DBG(FI_LOG_EP_DATA,
-					  "posted %d bytes, conn %p, len %zu, tag 0x%" PRIx64 "\n",
-					  sge.length, conn, len, tag);
-				return FI_SUCCESS;
-			}
-		}
-	}
-
-	fi_ibv_rdm_tagged_poll(ep);
-
-	return -FI_EAGAIN;
-}
-
-static ssize_t fi_ibv_rdm_tagged_senddatato(struct fid_ep *fid, const void *buf,
-					    size_t len, void *desc,
-					    uint64_t data, fi_addr_t dest_addr,
-					    uint64_t tag, void *context)
-{
-	struct fi_ibv_rdm_ep *ep_rdm = 
-		container_of(fid, struct fi_ibv_rdm_ep, ep_fid);
-	struct fi_ibv_rdm_send_start_data sdata = {
-		.ep_rdm = container_of(fid, struct fi_ibv_rdm_ep, ep_fid),
-		.conn = ep_rdm->av->addr_to_conn(ep_rdm, dest_addr),
-		.data_len = len,
-		.context = context,
-		.flags = FI_TAGGED | FI_SEND | GET_TX_COMP(ep_rdm),
-		.tag = tag,
-		.is_tagged = 1,
-		.buf.src_addr = (void*)buf,
-		.iov_count = 0,
-		.imm = (uint32_t) data,
-		.stype = IBV_RDM_SEND_TYPE_GEN
-	};
-
-	return fi_ibv_rdm_send_common(&sdata);
-}
-
-static ssize_t fi_ibv_rdm_tagged_sendto(struct fid_ep *fid, const void *buf,
-					size_t len, void *desc,
-					fi_addr_t dest_addr, uint64_t tag,
-					void *context)
-{
-	return fi_ibv_rdm_tagged_senddatato(fid, buf, len, desc, 0, dest_addr,
-					    tag, context);
-}
-
-static ssize_t fi_ibv_rdm_tagged_sendmsg(struct fid_ep *ep,
-	const struct fi_msg_tagged *msg, uint64_t flags)
-{
-	struct fi_ibv_rdm_ep *ep_rdm =
-		container_of(ep, struct fi_ibv_rdm_ep, ep_fid);
-	size_t i;
-	struct fi_ibv_rdm_send_start_data sdata = {
-		.ep_rdm = ep_rdm,
-		.conn = ep_rdm->av->addr_to_conn(ep_rdm, msg->addr),
-		.data_len = ofi_total_iov_len(msg->msg_iov, msg->iov_count),
-		.context = msg->context,
-		.flags = FI_TAGGED | FI_SEND | GET_TX_COMP_FLAG(ep_rdm, flags),
-		.tag = msg->tag,
-		.is_tagged = 1,
-		.buf.src_addr = NULL,
-		.iov_count = 0,
-		.imm = (uint32_t) 0,
-		.stype = IBV_RDM_SEND_TYPE_GEN,
-	};
-
-	switch (msg->iov_count) {
-	case 1:
-		sdata.buf.src_addr = msg->msg_iov[0].iov_base;
-		/* FALL THROUGH  */
-	case 0:
-		break;
-	default:
-		/* TODO: 
-		 * extra allocation & memcpy can be optimized if it's possible
-		 * to send immediately
-		 */
-		if ((msg->iov_count > sdata.ep_rdm->iov_per_rndv_thr) ||
-		    (sdata.data_len > sdata.ep_rdm->rndv_threshold))
-			return -FI_EMSGSIZE;
-		sdata.buf.iovec_arr =
-			util_buf_alloc(ep_rdm->fi_ibv_rdm_extra_buffers_pool);
-		for (i = 0; i < msg->iov_count; i++) {
-			sdata.buf.iovec_arr[i].iov_base = msg->msg_iov[i].iov_base;
-			sdata.buf.iovec_arr[i].iov_len = msg->msg_iov[i].iov_len;
-		}
-		sdata.iov_count = msg->iov_count;
-		sdata.stype = IBV_RDM_SEND_TYPE_VEC;
-		break;
-	}
-
-	return fi_ibv_rdm_send_common(&sdata);
-}
-
-static ssize_t fi_ibv_rdm_tagged_sendv(struct fid_ep *ep,
-				       const struct iovec *iov, void **desc,
-				       size_t count, fi_addr_t dest_addr,
-				       uint64_t tag, void *context)
-{
-	struct fi_ibv_rdm_ep *ep_rdm = 
-		container_of(ep, struct fi_ibv_rdm_ep, ep_fid);
-
-	const struct fi_msg_tagged msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = dest_addr,
-		.tag = tag,
-		.ignore = 0,
-		.context = context,
-		.data = 0
-	};
-
-	return fi_ibv_rdm_tagged_sendmsg(ep, &msg, GET_TX_COMP(ep_rdm));
-}
-
-struct fi_ops_tagged fi_ibv_rdm_tagged_ops = {
-	.size = sizeof(struct fi_ops_tagged),
-	.recv = fi_ibv_rdm_tagged_recvfrom,
-	.recvv = fi_ibv_rdm_tagged_recvv,
-	.recvmsg = fi_ibv_rdm_tagged_recvmsg,
-	.send = fi_ibv_rdm_tagged_sendto,
-	.sendv = fi_ibv_rdm_tagged_sendv,
-	.sendmsg = fi_ibv_rdm_tagged_sendmsg,
-	.inject = fi_ibv_rdm_tagged_inject,
-	.senddata = fi_ibv_rdm_tagged_senddatato,
-	.injectdata = fi_no_tagged_injectdata
-};
-
-struct fi_ops_cm fi_ibv_rdm_tagged_ep_cm_ops = {
-	.size = sizeof(struct fi_ops_cm),
-	.getname = fi_ibv_rdm_tagged_getname,
-	.setname = fi_no_setname,
-	.getpeer = fi_no_getpeer,
-	.connect = fi_no_connect,
-	.listen = fi_no_listen,
-	.accept = fi_no_accept,
-	.reject = fi_no_reject,
-	.shutdown = fi_no_shutdown,
-	.join = fi_no_join,
-};
-
-static inline void
-fi_ibv_rdm_tagged_release_remote_sbuff(struct fi_ibv_rdm_conn *conn,
-					struct fi_ibv_rdm_ep *ep)
-{
-	struct ibv_send_wr *bad_wr = NULL;
-	struct ibv_sge sge = {
-		.addr = (uint64_t)&conn->sbuf_ack_status,
-		.length = sizeof(conn->sbuf_ack_status),
-		.lkey = fi_ibv_mr_internal_lkey(&conn->ack_md),
-	};
-	struct ibv_send_wr wr = {
-		.wr_id = FI_IBV_RDM_PACK_SERVICE_WR(conn),
-		.sg_list = &sge,
-		.num_sge = 1,
-		.wr.rdma.remote_addr = (uint64_t)
-			&conn->remote_sbuf_head->service_data.status,
-		.wr.rdma.rkey = conn->remote_sbuf_rkey,
-		.send_flags =
-			(sge.length < ep->max_inline_rc) ? IBV_SEND_INLINE : 0,
-		.opcode = IBV_WR_RDMA_WRITE,
-	};
-
-	FI_IBV_RDM_INC_SIG_POST_COUNTERS(conn, ep);
-	VERBS_DBG(FI_LOG_EP_DATA,
-		"posted %d bytes, remote sbuff released\n", sge.length);
-	int ret = ibv_post_send(conn->qp[0], &wr, &bad_wr);
-	if (ret) {
-		VERBS_INFO_ERRNO(FI_LOG_EP_DATA, "ibv_post_send", errno);
-		assert(0);
-	};
-
-	if (conn->av_entry->sends_outgoing > ep->n_buffs) {
-		fi_ibv_rdm_tagged_poll_send(ep);
-	}
-}
-
-static inline void
-fi_ibv_rdm_process_recv(struct fi_ibv_rdm_ep *ep, struct fi_ibv_rdm_conn *conn,
-			int arrived_len, struct fi_ibv_rdm_buf *rbuf)
-{
-	struct fi_ibv_rdm_request *request = NULL;
-
-	int pkt_type = FI_IBV_RDM_GET_PKTTYPE(rbuf->header.service_tag);
-
-	if (pkt_type == FI_IBV_RDM_RNDV_ACK_PKT) {
-		memcpy(&request, &rbuf->payload, sizeof(request));
-		assert(request);
-		VERBS_DBG(FI_LOG_EP_DATA,
-			"GOT RNDV ACK from conn %p, id %p\n", conn, request);
-	} else if (pkt_type != FI_IBV_RDM_RMA_PKT) {
-		struct fi_ibv_rdm_minfo minfo = {
-			.conn = conn,
-			.tag = rbuf->header.tag,
-			.tagmask = 0,
-			.is_tagged = (pkt_type == FI_IBV_RDM_MSG_PKT) ? 0 : 1
-		};
-
-		if (pkt_type == FI_IBV_RDM_RNDV_RTS_PKT) {
-			struct fi_ibv_rdm_rndv_header* h = (void *)&rbuf->header;
-			minfo.is_tagged = h->is_tagged;
-		}
-
-		struct dlist_entry *found_entry =
-			dlist_find_first_match(&ep->fi_ibv_rdm_posted_queue,
-						fi_ibv_rdm_req_match_by_info,
-						&minfo);
-
-		if (found_entry) {
-			struct fi_ibv_rdm_request *found_request =
-				container_of(found_entry,
-					     struct fi_ibv_rdm_request,
-					     queue_entry);
-
-			fi_ibv_rdm_remove_from_posted_queue(found_request, ep);
-
-			request = found_request;
-		} else {
-			request = util_buf_alloc(ep->fi_ibv_rdm_request_pool);
-			if (OFI_UNLIKELY(!request))
-				return;
-			fi_ibv_rdm_zero_request(request);
-			request->ep = ep;
-			FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", request,
-						FI_LOG_DEBUG);
-		}
-	}
-
-	/* RMA packets are not handled yet (without IMM) */
-	if (pkt_type != FI_IBV_RDM_RMA_PKT) {
-
-		struct fi_ibv_recv_got_pkt_preprocess_data p = {
-			.conn = conn,
-			.ep = ep,
-			.rbuf = rbuf,
-			.arrived_len = arrived_len,
-			.pkt_type = pkt_type,
-			.imm_data = 0 // TODO:
-		};
-
-		fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_RECV_GOT_PKT_PROCESS,
-				    &p);
-	}
-}
-
-static inline
-void check_and_repost_receives(struct fi_ibv_rdm_ep *ep,
-				struct fi_ibv_rdm_conn *conn)
-{
-	if (conn->av_entry->recv_preposted-- < ep->recv_preposted_threshold) {
-		int to_post = ep->rq_wr_depth - conn->av_entry->recv_preposted;
-		ssize_t res = fi_ibv_rdm_repost_receives(conn, ep, to_post);
-		if (res < 0) {
-			VERBS_INFO(FI_LOG_EP_DATA, "repost recv failed %zd\n", res);
-			/* TODO: err code propagation */
-			abort();
-		}
-		VERBS_DBG(FI_LOG_EP_DATA,
-			  "reposted_recvs, posted %d, local_credits %"PRIu32"\n",
-			  to_post, conn->av_entry->recv_preposted);
-	}
-	/* Since we want to print out here the remaining space for prepost,
-	 * we try to get up-to-date value of the `recv_preposted` */
-	VERBS_DBG(FI_LOG_EP_DATA, "conn %p remain prepost recvs %"PRIu32"\n",
-		  conn, conn->av_entry->recv_preposted);
-}
-
-static inline int 
-fi_ibv_rdm_process_recv_wc(struct fi_ibv_rdm_ep *ep, struct ibv_wc *wc)
-{
-	struct fi_ibv_rdm_conn *conn = (void *)wc->wr_id;
-
-	struct fi_ibv_rdm_buf *rbuf = 
-		fi_ibv_rdm_get_rbuf(conn, ep, conn->recv_processed);
-
-	FI_IBV_PREFETCH_ADDR(rbuf);
-
-	FI_IBV_DBG_OPCODE(wc->opcode, "RECV");
-
-	if (!FI_IBV_RDM_CHECK_RECV_WC(wc)) {
-		VERBS_DBG(FI_LOG_EP_DATA, "conn %p state %d, wc status %d\n",
-			  conn, conn->state, wc->status);
-		/* on QP error initiate disconnection procedure:
-		 * flush as many as possible preposted (and failed)
-		 * entries and after this set connection to 'closed' state */
-		if (!conn->av_entry->recv_preposted) {
-			VERBS_DBG(FI_LOG_EP_DATA, "no more preposted entries: "
-				"conn %p state %d\n",
-				conn, conn->state);
-			return 0;
-		}
-
-		conn->av_entry->recv_preposted--;
-		if (wc->status == IBV_WC_WR_FLUSH_ERR &&
-		    conn->state == FI_VERBS_CONN_ESTABLISHED) {
-			/*
-			 * It means that remote side initiated disconnection
-			 * and QP is flushed earlier then disconnect event was
-			 * handled or arrived. Just initiate disconnect to
-			 * opposite direction.
-			 */
-			fi_ibv_rdm_start_disconnection(conn);
-		} else {
-			VERBS_DBG(FI_LOG_EP_DATA, "%s recv WC",
-				  ((!ep->is_closing ||
-				   conn->state != FI_VERBS_CONN_ESTABLISHED) ?
-				   "Expected" : "Error"));
-			assert(!ep->is_closing ||
-			       conn->state != FI_VERBS_CONN_ESTABLISHED);
-		}
-		conn->state = FI_VERBS_CONN_CLOSED;
-	}
-	else {
-		check_and_repost_receives(ep, conn);
-	}
-
-	conn->recv_completions++;
-	if (conn->recv_completions & ep->n_buffs) {
-		conn->recv_completions = 0;
-	}
-
-	VERBS_DBG(FI_LOG_EP_DATA, "conn %p recv_completions %d\n",
-		conn, conn->recv_completions);
-
-	if ((rbuf->service_data.status == BUF_STATUS_RECEIVED) &&
-	    /* NOTE: Bi-direction RNDV messaging may cause "out-of-order"
-	     * consuming of pre-posts. These are RTS and ACK messages of
-	     * different requests. In this case we may check seq_num only if
-	     * send was posted with IBV_WR_RDMA_WRITE_WITH_IMM opcode because
-	     * the sender controls this. Otherwise, the sender with IBV_WR_SEND
-	     * opcode consumes pre-posted buffers in the same order as they were
-	     * pre-posted by recv. So, we should handle it as is.
-	     */
-	    (wc->opcode == IBV_WC_RECV_RDMA_WITH_IMM ?
-	    fi_ibv_rdm_buffer_check_seq_num(rbuf, conn->recv_processed) : 1))
-	{
-		do {
-			assert(rbuf->service_data.pkt_len > 0);
-
-			fi_ibv_rdm_process_recv(ep, conn, 
-				rbuf->service_data.pkt_len, rbuf);
-
-			VERBS_DBG(FI_LOG_EP_DATA, "processed: conn %p, pkt # %d\n",
-				conn, rbuf->service_data.seq_num);
-
-			fi_ibv_rdm_set_buffer_status(rbuf, BUF_STATUS_FREE);
-			rbuf->service_data.seq_num = (uint16_t)(-1);
-
-			conn->recv_processed++;
-			if (conn->recv_processed & ep->n_buffs) {
-				conn->recv_processed = 0;
-				fi_ibv_rdm_tagged_release_remote_sbuff(conn, ep);
-			}
-			VERBS_DBG(FI_LOG_EP_DATA, "conn %p recv_processed %d\n",
-				conn, conn->recv_processed);
-
-			rbuf = fi_ibv_rdm_get_rbuf(conn, ep, 
-				conn->recv_processed);
-
-		/* Do not process w/o completion! */
-		} while (conn->recv_processed != conn->recv_completions &&
-			 rbuf->service_data.status == BUF_STATUS_RECEIVED);
-	} else {
-		VERBS_DBG(FI_LOG_EP_DATA, "not processed: conn %p, status: %d\n",
-			conn, rbuf->service_data.status);
-	}
-
-	return 0;
-}
-
-int fi_ibv_rdm_tagged_poll_recv(struct fi_ibv_rdm_ep *ep)
-{
-	const int wc_count = ep->fi_rcq->read_bunch_size;
-	struct ibv_wc wc[wc_count];
-	int ret = 0;
-	int err = 0;
-	int i = 0;
-
-	do {
-		ret = ibv_poll_cq(ep->rcq, wc_count, wc);
-		for (i = 0; i < ret && !err; ++i) {
-			err = fi_ibv_rdm_process_recv_wc(ep, &wc[i]);
-		}
-	} while (!err && ret == wc_count);
-
-	if (!err && ret >= 0) {
-		return FI_SUCCESS;
-	}
-
-	/* error handling */
-
-	VERBS_INFO(FI_LOG_EP_DATA, "ibv_poll_cq returned %d\n", ret);
-
-	for(i = 0; i < ret; i++) {
-
-		if (wc[i].status != IBV_WC_SUCCESS) {
-			struct fi_ibv_rdm_conn *conn = (void *)wc[i].wr_id;
-
-			if ((wc[i].status == IBV_WC_WR_FLUSH_ERR) && conn &&
-			    (conn->state != FI_VERBS_CONN_ESTABLISHED))
-				return FI_SUCCESS;
-
-			VERBS_INFO(FI_LOG_EP_DATA, "got ibv_wc[%d].status = %d:%s\n",
-				i, wc[i].status, ibv_wc_status_str(wc[i].status));
-			return -FI_EOTHER;
-		}
-
-		if (wc[i].opcode != IBV_WC_RECV_RDMA_WITH_IMM &&
-		    wc[i].opcode != IBV_WC_RECV)
-		{
-			VERBS_INFO(FI_LOG_EP_DATA, "got ibv_wc[%d].opcode = %d\n",
-				i, wc[i].opcode);
-		}
-	}
-
-	return -FI_EOTHER;
-}
-
-static inline int fi_ibv_rdm_tagged_poll_send(struct fi_ibv_rdm_ep *ep)
-{
-	const int wc_count = ep->fi_scq->read_bunch_size;
-	struct ibv_wc wc[wc_count];
-	int ret = 0, err = 0, i;
-
-	if (ep->posted_sends > 0) {
-		do {
-			ret = ibv_poll_cq(ep->scq, wc_count, wc);
-			for (i = 0; i < ret && !err; ++i) {
-				err = fi_ibv_rdm_process_send_wc(ep, &wc[i]);
-			}
-		} while (!err && ret == wc_count);
-	}
-
-	if (err || ret < 0) {
-		goto wc_error;
-	}
-
-	struct fi_ibv_rdm_tagged_send_ready_data data = { .ep = ep };
-	struct dlist_entry *item;
-	dlist_foreach((&ep->fi_ibv_rdm_postponed_queue), item) {
-		if (fi_ibv_rdm_postponed_process(item, &data)) {
-			/* we can't process all postponed items till foreach */
-			/* implementation is not safety for removing during  */
-			/* iterating                                         */
-			break;
-		}
-	}
-
-	return FI_SUCCESS;
-
-wc_error:
-	if (ret < 0) {
-		VERBS_INFO(FI_LOG_EP_DATA, "ibv_poll_cq returned %d\n", ret);
-		assert(0);
-	}
-
-	for (i = 0; i < ret; i++)
-		fi_ibv_rdm_process_err_send_wc(ep, &wc[i]);
-
-	return -FI_EOTHER;
-}
-
-int fi_ibv_rdm_tagged_poll(struct fi_ibv_rdm_ep *ep)
-{
-	int ret = fi_ibv_rdm_tagged_poll_send(ep);
-	/* Only already posted sends should be processed during EP closing */
-	if (ret || ep->is_closing) {
-		return ret;
-	}
-
-	return fi_ibv_rdm_tagged_poll_recv(ep);
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm_states.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm_states.c
deleted file mode 100644
index 970766576..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm_states.c
+++ /dev/null
@@ -1,1846 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <inttypes.h>
-#include <stdlib.h>
-
-#include <ofi_list.h>
-#include "../fi_verbs.h"
-#include "verbs_rdm.h"
-#include "verbs_queuing.h"
-#include "verbs_tagged_ep_rdm_states.h"
-
-typedef ssize_t (*fi_ep_rdm_request_handler_t)
-	(struct fi_ibv_rdm_request *request, void *data);
-
-static fi_ep_rdm_request_handler_t
-	fi_ibv_rdm_req_hndl_arr [FI_IBV_STATE_EAGER_COUNT]
-				[FI_IBV_STATE_RNDV_COUNT]
-				[FI_IBV_EVENT_COUNT];
-
-#if ENABLE_DEBUG
-
-enum fi_ibv_rdm_hndl_req_log_state {
-	hndl_req_log_state_in = 0,
-	hndl_req_log_state_out = 10000
-};
-
-#define FI_IBV_RDM_HNDL_REQ_LOG_IN()						\
-enum fi_ibv_rdm_hndl_req_log_state state = hndl_req_log_state_in;		\
-do {										\
-	FI_IBV_RDM_DBG_REQUEST("\t> IN\t< ", request, FI_LOG_DEBUG);		\
-} while(0)
-
-#define FI_IBV_RDM_HNDL_REQ_LOG() do {						\
-	state++;								\
-	char prefix[128];							\
-	snprintf(prefix, 128, "\t> %d\t< ", state);				\
-	FI_IBV_RDM_DBG_REQUEST(prefix, request, FI_LOG_DEBUG);			\
-} while(0)
-
-#define FI_IBV_RDM_HNDL_REQ_LOG_OUT() do {					\
-	assert(state < hndl_req_log_state_out);					\
-	FI_IBV_RDM_DBG_REQUEST("\t> OUT\t< ", request, FI_LOG_DEBUG);		\
-} while(0)
-
-#else // ENABLE_DEBUG
-#define FI_IBV_RDM_HNDL_REQ_LOG_IN()
-#define FI_IBV_RDM_HNDL_REQ_LOG()
-#define FI_IBV_RDM_HNDL_REQ_LOG_OUT()
-#endif // ENABLE_DEBUG
-
-static ssize_t
-fi_ibv_rdm_init_send_request(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	ssize_t ret;
-	struct fi_ibv_rdm_send_start_data *p = data;
-	request->minfo.conn = p->conn;
-	request->minfo.tag = p->tag;
-	request->minfo.is_tagged = p->is_tagged;
-	request->iov_count = p->iov_count;
-
-	/* Indeed, both branches are the same, just for readability */
-	if (request->iov_count) {
-		request->iovec_arr = p->buf.iovec_arr;
-	} else {
-		request->src_addr = p->buf.src_addr;
-	}
-
-	request->sbuf = NULL;
-	request->len = p->data_len;
-	request->comp_flags = p->flags;
-	request->imm = p->imm;
-	request->context = p->context;
-	request->state.eager = FI_IBV_STATE_EAGER_BEGIN;
-	request->state.rndv =
-	    (p->data_len + sizeof(struct fi_ibv_rdm_header)
-	     <= p->ep_rdm->rndv_threshold)
-	    ? FI_IBV_STATE_RNDV_NOT_USED : FI_IBV_STATE_RNDV_SEND_BEGIN;
-
-	FI_IBV_RDM_HNDL_REQ_LOG();
-
-	ret = fi_ibv_rdm_move_to_postponed_queue(request);
-	if (ret)
-		return ret;
-	request->state.eager = FI_IBV_STATE_EAGER_SEND_POSTPONED;
-	if (request->state.rndv == FI_IBV_STATE_RNDV_SEND_BEGIN) {
-		request->state.rndv = FI_IBV_STATE_RNDV_SEND_WAIT4SEND;
-	}
-		
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_eager_send_ready(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert(request->state.eager == FI_IBV_STATE_EAGER_SEND_POSTPONED);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	fi_ibv_rdm_remove_from_postponed_queue(request);
-	struct fi_ibv_rdm_tagged_send_ready_data *p = data;
-
-	ssize_t ret = FI_SUCCESS;
-	struct ibv_sge sge;
-
-	struct fi_ibv_rdm_conn *conn = request->minfo.conn;
-	const int size = request->len + sizeof(struct fi_ibv_rdm_header);
-
-	assert(request->sbuf);
-
-	struct ibv_send_wr wr = { 0 };
-	struct ibv_send_wr *bad_wr = NULL;
-
-	wr.wr_id = FI_IBV_RDM_PACK_WR(request);
-	assert(FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wr.wr_id) == 0);
-	wr.sg_list = &sge;
-	wr.num_sge = 1;
-	wr.wr.rdma.remote_addr = fi_ibv_rdm_get_remote_addr(conn, request->sbuf);
-	wr.wr.rdma.rkey = conn->remote_rbuf_rkey;
-	wr.send_flags = 0;
-
-	sge.addr = (uintptr_t)request->sbuf;
-	sge.length = size + FI_IBV_RDM_BUFF_SERVICE_DATA_SIZE;
-	request->sbuf->service_data.pkt_len = size;
-
-	if (sge.length <= p->ep->max_inline_rc) {
-		wr.send_flags |= IBV_SEND_INLINE;
-	}
-
-	sge.lkey = fi_ibv_mr_internal_lkey(&conn->s_md);
-
-	wr.imm_data = 0;
-	wr.opcode = p->ep->eopcode;
-	struct fi_ibv_rdm_buf *sbuf = (struct fi_ibv_rdm_buf *)request->sbuf;
-	uint64_t *payload = &sbuf->payload;
-
-	sbuf->header.service_tag = 0;
-	if (request->minfo.is_tagged) {
-		sbuf->header.tag = request->minfo.tag;
-		FI_IBV_RDM_SET_PKTTYPE(sbuf->header.service_tag, FI_IBV_RDM_EAGER_PKT);
-	} else {
-		FI_IBV_RDM_SET_PKTTYPE(sbuf->header.service_tag, FI_IBV_RDM_MSG_PKT);
-	}
-
-	if (request->len > 0) {
-		if (request->iov_count == 0) {
-			memcpy(payload, request->src_addr, request->len);
-		} else {
-			size_t i;
-			for (i = 0; i < request->iov_count; i++) {
-				memcpy(payload, request->iovec_arr[i].iov_base,
-					request->iovec_arr[i].iov_len);
-				payload += request->iovec_arr[i].iov_len;
-			}
-		}
-	}
-
-	FI_IBV_RDM_INC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-	VERBS_DBG(FI_LOG_EP_DATA, "posted %d bytes, conn %p, tag 0x%" PRIx64 "\n",
-		  sge.length, request->minfo.conn, request->minfo.tag);
-
-	ret = ibv_post_send(conn->qp[0], &wr, &bad_wr);
-	if (ret) {
-		VERBS_INFO_ERRNO(FI_LOG_EP_DATA, "ibv_post_send", errno);
-		ret = -errno;
-		assert(0);
-	};
-
-	fi_ibv_rdm_cntr_inc(p->ep->send_cntr);
-
-	if (request->comp_flags & FI_COMPLETION) {
-		fi_ibv_rdm_move_to_cq(p->ep->fi_scq, request);
-		request->state.eager = FI_IBV_STATE_EAGER_SEND_WAIT4LC;
-	} else {
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_eager_send_lc(struct fi_ibv_rdm_request *request,
-				void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert(request->state.eager == FI_IBV_STATE_EAGER_SEND_WAIT4LC ||
-	       request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	VERBS_DBG(FI_LOG_EP_DATA, "conn %p, tag 0x%" PRIx64 ", len %" PRIu64 "\n",
-		  request->minfo.conn, request->minfo.tag, request->len);
-
-	struct fi_ibv_rdm_tagged_send_completed_data *p = data;
-	FI_IBV_RDM_DEC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-
-	if (request->iov_count) {
-		util_buf_release(
-			request->ep->fi_ibv_rdm_extra_buffers_pool,
-			request->iovec_arr);
-	}
-
-	if (request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE) {
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(request->ep->fi_ibv_rdm_request_pool,
-				 request);
-	} else {
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_rndv_rts_send_ready(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert(request->state.eager == FI_IBV_STATE_EAGER_SEND_POSTPONED);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_SEND_WAIT4SEND);
-	assert(request->sbuf);
-
-	VERBS_DBG(FI_LOG_EP_DATA, "conn %p, tag 0x%" PRIx64 ", len %" PRIu64 "\n",
-		  request->minfo.conn, request->minfo.tag, request->len);
-
-	fi_ibv_rdm_remove_from_postponed_queue(request);
-	struct fi_ibv_rdm_tagged_send_ready_data *p = data;
-	struct ibv_sge sge;
-	struct fi_ibv_rdm_conn *conn = request->minfo.conn;
-	struct fi_ibv_rdm_rndv_header *header = (void *)&request->sbuf->header;
-	struct ibv_send_wr wr = { 0 }, *bad_wr = NULL;
-	int ret;
-
-	wr.wr_id = FI_IBV_RDM_PACK_WR(request);
-	assert(FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wr.wr_id) == 0);
-	wr.sg_list = &sge;
-	wr.num_sge = 1;
-	wr.wr.rdma.remote_addr = (uintptr_t)
-		fi_ibv_rdm_get_remote_addr(conn, request->sbuf);
-	wr.wr.rdma.rkey = conn->remote_rbuf_rkey;
-	wr.send_flags = 0;
-	wr.opcode = p->ep->eopcode;
-	wr.imm_data = 0;
-
-	sge.addr = (uintptr_t)request->sbuf;
-	sge.length = FI_IBV_RDM_BUFF_SERVICE_DATA_SIZE + sizeof(*header);
-	sge.lkey = fi_ibv_mr_internal_lkey(&conn->s_md);
-	request->sbuf->service_data.pkt_len = sizeof(*header);
-
-	if (request->minfo.is_tagged) {
-		header->base.tag = request->minfo.tag;
-		header->is_tagged = 1;
-	} else {
-		header->is_tagged = 0;
-	}
-	header->base.service_tag = 0;
-	header->total_len = request->len;
-	header->src_addr = (uintptr_t)request->src_addr;
-
-	header->id = (uintptr_t)request;
-	request->rndv.id = (uintptr_t)request;
-
-	ret = p->ep->domain->internal_mr_reg(p->ep->domain,
-					     (void *)request->src_addr,
-					     request->len,
-					     FI_REMOTE_READ,
-					     &request->rndv.md);
-	if (ret) {
-		VERBS_WARN(FI_LOG_EP_DATA,
-			   "Unable to register MR, ret = %d", ret);
-		assert(0);
-		return ret;
-	}
-	header->mem_rkey = fi_ibv_mr_internal_rkey(&request->rndv.md);
-
-	FI_IBV_RDM_SET_PKTTYPE(header->base.service_tag,
-			       FI_IBV_RDM_RNDV_RTS_PKT);
-
-	VERBS_DBG(FI_LOG_EP_DATA,
-		  "fi_senddatato: RNDV conn %p, tag 0x%" PRIx64 ", len %"PRIu64", "
-		  "src_addr %p, rkey 0x%"PRIx64", fi_ctx %p, imm %d, post_sends %"PRIu32"\n",
-		  conn, request->minfo.tag, request->len, request->src_addr,
-		  header->mem_rkey, request->context, (int)wr.imm_data,
-		  p->ep->posted_sends);
-
-	FI_IBV_RDM_INC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-	VERBS_DBG(FI_LOG_EP_DATA, "posted %d bytes, conn %p, tag 0x%" PRIx64 "\n",
-		  sge.length, request->minfo.conn,
-		  request->minfo.tag);
-	ret = ibv_post_send(conn->qp[0], &wr, &bad_wr);
-	if (ret) {
-		VERBS_INFO_ERRNO(FI_LOG_EP_DATA, "ibv_post_send", errno);
-		assert(0);
-		return -errno;
-	};
-
-	request->state.eager = FI_IBV_STATE_EAGER_SEND_WAIT4LC;
-	request->state.rndv = FI_IBV_STATE_RNDV_SEND_WAIT4ACK;
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_rndv_rts_lc(struct fi_ibv_rdm_request *request,
-			      void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert(((request->state.eager == FI_IBV_STATE_EAGER_SEND_WAIT4LC) &&
-		(request->state.rndv == FI_IBV_STATE_RNDV_SEND_WAIT4ACK)) ||
-	       ((request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE) &&
-		(request->state.rndv == FI_IBV_STATE_RNDV_SEND_END)) ||
-	       ((request->state.eager == FI_IBV_STATE_EAGER_SEND_WAIT4LC) &&
-		(request->state.rndv == FI_IBV_STATE_RNDV_SEND_END)));
-	assert(request->minfo.conn);
-
-	VERBS_DBG(FI_LOG_EP_DATA, "conn %p, tag 0x%" PRIx64 ", len %" PRIu64 "\n",
-		  request->minfo.conn, request->minfo.tag,
-		  request->len);
-
-	struct fi_ibv_rdm_tagged_send_completed_data *p = data;
-
-	FI_IBV_RDM_DEC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-
-	if (request->state.eager == FI_IBV_STATE_EAGER_SEND_WAIT4LC) {
-		request->state.eager = FI_IBV_STATE_EAGER_SEND_END;
-	} else { /* (request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE) */
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(request->ep->fi_ibv_rdm_request_pool,
-				 request);
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_rndv_end(struct fi_ibv_rdm_request *request,
-			   void *data)
-{
-	struct fi_ibv_recv_got_pkt_preprocess_data *p = data;
-	int ret;
-
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert(request->state.eager == FI_IBV_STATE_EAGER_SEND_END ||
-	       (request->state.eager == FI_IBV_STATE_EAGER_SEND_WAIT4LC));
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_SEND_WAIT4ACK);
-
-	assert((sizeof(struct fi_ibv_rdm_request *) +
-		sizeof(struct fi_ibv_rdm_header)) == p->arrived_len);
-	assert(request->rndv.md.mr);
-	assert(p->rbuf);
-
-	ret = p->ep->domain->internal_mr_dereg(&request->rndv.md);
-	if (ret)
-		VERBS_INFO(FI_LOG_EP_DATA,
-			   "Unable to deregister MR, ret = %d", ret);
-
-	if (request->state.eager == FI_IBV_STATE_EAGER_SEND_END)
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-
-	request->state.rndv = FI_IBV_STATE_RNDV_SEND_END;
-	FI_IBV_RDM_HNDL_REQ_LOG();
-
-	fi_ibv_rdm_cntr_inc(p->ep->send_cntr);
-
-	if (request->comp_flags & FI_COMPLETION) {
-		fi_ibv_rdm_move_to_cq(p->ep->fi_scq, request);
-	} else if (request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE) {
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(
-			request->ep->fi_ibv_rdm_request_pool,
-			request);
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-
-	return FI_SUCCESS;
-}
-
-
-static inline ssize_t
-fi_ibv_rdm_copy_unexp_request(struct fi_ibv_rdm_request *request,
-			      struct fi_ibv_rdm_request *unexp)
-{
-	ssize_t ret = FI_SUCCESS;
-	if (request->len && (request->len < unexp->len)) {
-		VERBS_INFO(FI_LOG_EP_DATA,
-			   "RECV TRUNCATE, unexp len %" PRIu64 ", "
-			   "req->len=%" PRIu64 ", conn %p, tag 0x%" PRIx64 ", "
-			   "tagmask %" PRIx64 "\n",
-			   unexp->len, request->len, request->minfo.conn,
-			   request->minfo.tag, request->minfo.tagmask);
-
-		util_buf_release(
-			unexp->ep->fi_ibv_rdm_extra_buffers_pool,
-			unexp->unexp_rbuf);
-		ret = -FI_ETRUNC;
-		return ret;
-	}
-
-	request->minfo.conn = unexp->minfo.conn;
-	request->minfo.tag = unexp->minfo.tag;
-	request->minfo.is_tagged = unexp->minfo.is_tagged;
-	request->len = unexp->len;
-	request->rest_len = unexp->rest_len;
-	request->unexp_rbuf = unexp->unexp_rbuf;
-	request->state = unexp->state;
-
-	assert((request->state.eager == FI_IBV_STATE_EAGER_RECV_WAIT4RECV) ||
-	       (request->state.eager == FI_IBV_STATE_EAGER_RECV_CLAIMED));
-
-	VERBS_DBG(FI_LOG_EP_DATA, "found req: len = %" PRIu64 ", eager_state = %s, rndv_state = %s \n",
-		  unexp->len,
-		  fi_ibv_rdm_req_eager_state_to_str(unexp->state.eager),
-		  fi_ibv_rdm_req_rndv_state_to_str(unexp->state.rndv));
-
-	if (request->state.rndv != FI_IBV_STATE_RNDV_NOT_USED) {
-		assert(request->state.rndv == FI_IBV_STATE_RNDV_RECV_WAIT4RES);
-
-		request->rndv.mr_rkey = unexp->rndv.mr_rkey;
-		request->rndv.id = unexp->rndv.id;
-		request->rndv.remote_addr = unexp->rndv.remote_addr;
-	}
-
-	return ret;
-}
-
-/*
- * FI_MULTI_RECV path is implemented through a parent multi_request.
- * This is a kind of supervisor which keep another preposted request while multi
- * recv buffer has enough space for incoming data. The last prepost releases
- * the parent and sets FI_MULTI_RECV completion flag.
- */
-static struct fi_ibv_rdm_request *
-fi_ibv_rdm_repost_multi_recv(struct fi_ibv_rdm_request *request,
-			     size_t offset, struct fi_ibv_rdm_ep *ep)
-{
-	struct fi_ibv_rdm_multi_request *parent;
-	struct fi_ibv_rdm_request *prepost;
-
-	if (!(prepost = util_buf_alloc(ep->fi_ibv_rdm_request_pool))) {
-		VERBS_WARN(FI_LOG_EP_DATA, "Unable to allocate memory for "
-			   "multi recv prepost request\n");
-		return NULL;
-	}
-
-	fi_ibv_rdm_zero_request(prepost);
-	prepost->ep = ep;
-	FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", prepost, FI_LOG_DEBUG);
-	FI_IBV_RDM_DBG_REQUEST("repost from: ", request, FI_LOG_DEBUG);
-
-	parent = request->parent;
-	request->parent = NULL;
-	parent->prepost = prepost;
-	parent->offset += offset;
-
-	VERBS_DBG(FI_LOG_EP_DATA,
-		  "multi_recv parent: prepost %p, buf %p, len %" PRIu64
-		  ", offset %" PRIu64 " min_size %" PRIu64 "\n",
-		  parent->prepost, parent->buf, parent->len,
-		  parent->offset, parent->min_size);
-
-	prepost->parent = parent;
-	prepost->minfo = request->minfo;
-	prepost->dest_buf = parent->buf + parent->offset;
-
-	prepost->comp_flags = request->comp_flags;
-	prepost->len = parent->len - parent->offset;
-	if (prepost->len < parent->min_size) {
-		/* This is the last one, parent can be released */
-		prepost->comp_flags |= FI_MULTI_RECV;
-		util_buf_release(ep->fi_ibv_rdm_multi_request_pool, prepost->parent);
-		fi_ibv_rdm_remove_from_multi_recv_list(prepost->parent, ep);
-		prepost->parent = NULL;
-		FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", prepost, FI_LOG_DEBUG);
-	}
-	prepost->context = request->context;
-	prepost->context->internal[0] = (void *)prepost;
-
-	/* TODO: way for (RNDV) optimization is do registration only once */
-	//prepost->rndv = request->rndv;
-
-	prepost->state.eager = FI_IBV_STATE_EAGER_RECV_WAIT4PKT;
-	prepost->state.rndv = FI_IBV_STATE_RNDV_NOT_USED;
-	prepost->state.err = FI_SUCCESS;
-	fi_ibv_rdm_move_to_posted_queue(prepost, ep);
-	return prepost;
-}
-
-static inline ssize_t
-fi_ibv_rdm_try_unexp_recv(struct fi_ibv_rdm_request *request,
-			  struct fi_ibv_rdm_tagged_recv_start_data *rdata)
-{
-	struct dlist_entry *found_entry = NULL;
-	struct fi_ibv_rdm_request *found_request = NULL;
-	struct fi_ibv_rdm_request *repost = NULL;
-	ssize_t ret = FI_ENOMSG;
-
-	do {
-		found_entry =
-			dlist_find_first_match(&rdata->ep->fi_ibv_rdm_unexp_queue,
-					       fi_ibv_rdm_req_match_by_info3,
-					       &rdata->peek_data);
-		if (found_entry) {
-			ret = FI_SUCCESS;
-			found_request =
-				container_of(found_entry,
-					     struct fi_ibv_rdm_request,
-					     queue_entry);
-
-			fi_ibv_rdm_remove_from_unexp_queue(found_request);
-
-			if (request->parent) {
-				repost = fi_ibv_rdm_repost_multi_recv(request,
-					 found_request->len, rdata->ep);
-				if (!repost) {
-					ret = -FI_ENOMEM;
-					break;
-				}
-			}
-
-			ret = fi_ibv_rdm_copy_unexp_request(request, found_request);
-
-			assert((ret != FI_SUCCESS) ||
-				((rdata->peek_data.flags & FI_CLAIM) &&
-					(request->state.eager == 
-						FI_IBV_STATE_EAGER_RECV_CLAIMED) &&
-					(request->context == found_request->context)) ||
-			       (!(rdata->peek_data.flags & FI_CLAIM) && 
-					(request->state.eager == 
-						FI_IBV_STATE_EAGER_RECV_WAIT4RECV)));
-
-			FI_IBV_RDM_DBG_REQUEST("to_pool: ", found_request, FI_LOG_DEBUG);
-			util_buf_release(
-				found_request->ep->fi_ibv_rdm_request_pool,
-				found_request);
-
-			if (ret == FI_SUCCESS &&
-			    request->state.rndv == FI_IBV_STATE_RNDV_RECV_WAIT4RES) {
-				request->state.eager = FI_IBV_STATE_EAGER_RECV_END;
-				ret = fi_ibv_rdm_move_to_postponed_queue(request);
-				/* Will fail `while` check and return the result */
-			}
-		}
-	/* 
-	* Unexpected queue may contain several entries
-	* in case of multi recv, we need to handle them all
-	*/
-	} while (repost && repost->parent && found_entry && !ret);
-
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_init_recv_request(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	ssize_t ret = FI_SUCCESS;
-	struct fi_ibv_rdm_tagged_recv_start_data *p = data;
-
-	if (p->peek_data.flags & FI_MULTI_RECV) {
-		request->parent =
-			util_buf_alloc(request->ep->fi_ibv_rdm_multi_request_pool);
-		if (!request->parent) {
-			VERBS_WARN(FI_LOG_EP_DATA, "Unable to allocate memory "
-				   "for parent \n");
-			return -FI_ENOMEM;
-		}
-		fi_ibv_rdm_add_to_multi_recv_list(request->parent, request->ep);
-		request->parent->prepost = request;
-		request->parent->buf = p->dest_addr;
-		request->parent->len = p->data_len;
-		request->parent->offset = 0;
-		request->parent->min_size = p->ep->min_multi_recv_size;
-		VERBS_DBG(FI_LOG_EP_DATA, "conn %p, multi_recv %p, parent %p\n",
-			request->minfo.conn, request, request->parent);
-	}
-
-	request->minfo = p->peek_data.minfo;
-	request->context = p->peek_data.context;
-	request->context->internal[0] = (void *)request;
-	request->dest_buf = p->dest_addr;
-	request->len = p->data_len;
-	request->comp_flags =
-		(p->peek_data.minfo.is_tagged ? FI_TAGGED : FI_MSG ) | FI_RECV |
-		(p->peek_data.flags & FI_COMPLETION);
-	request->state.eager = FI_IBV_STATE_EAGER_RECV_WAIT4PKT;
-	request->state.rndv = FI_IBV_STATE_RNDV_NOT_USED;
-	request->state.err = FI_SUCCESS;
-
-	VERBS_DBG(FI_LOG_EP_DATA, "conn %p, tag 0x%" PRIx64 ", len %" PRIu64 "\n",
-		  request->minfo.conn, request->minfo.tag, request->len);
-
-	ret = fi_ibv_rdm_try_unexp_recv(request, p);
-	if (ret == FI_ENOMSG) {
-		fi_ibv_rdm_move_to_posted_queue(request, p->ep);
-		ret = FI_SUCCESS;
-	} else if (ret != FI_SUCCESS) {
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-
-		fi_ibv_rdm_cntr_inc_err(p->ep->recv_cntr);
-
-		if (request->comp_flags & FI_COMPLETION) {
-			fi_ibv_rdm_move_to_errcq(p->ep->fi_rcq, request, ret);
-		}
-		ret = FI_SUCCESS;
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_tagged_peek_request(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert(request->state.eager == FI_IBV_STATE_EAGER_BEGIN);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	ssize_t ret = FI_SUCCESS;
-
-	struct fi_ibv_rdm_tagged_recv_start_data *p = data;
-	struct fi_ibv_rdm_tagged_peek_data *peek_data = &p->peek_data;
-	struct dlist_entry *found_entry =
-		dlist_find_first_match(&p->ep->fi_ibv_rdm_unexp_queue,
-				       fi_ibv_rdm_req_match_by_info2,
-				       &peek_data->minfo);
-
-	/* TODO: to check behaviour for multi recv */
-	assert(!(peek_data->flags & FI_MULTI_RECV));
-
-	request->context = peek_data->context;
-	request->comp_flags = peek_data->flags;
-
-	if (found_entry) {
-		struct fi_ibv_rdm_request *found_request =
-			container_of(found_entry, struct fi_ibv_rdm_request,
-				     queue_entry);
-		assert(found_request);
-
-		ret = fi_ibv_rdm_copy_unexp_request(request, found_request);
-
-		if (ret) {
-			goto err;
-		}
-
-		if (peek_data->flags & FI_CLAIM) {
-			ret = fi_ibv_rdm_req_hndl(found_request,
-						  FI_IBV_EVENT_RECV_CLAIM,
-						  peek_data);
-
-			if (ret) {
-				goto err;
-			}
-		}
-
-		if (peek_data->flags & FI_DISCARD) {
-			ret = fi_ibv_rdm_req_hndl(found_request,
-						  FI_IBV_EVENT_RECV_DISCARD,
-						  NULL);
-
-			if (ret) {
-				goto err;
-			}
-		}
-
-		fi_ibv_rdm_cntr_inc(p->ep->recv_cntr);
-
-		if (request->comp_flags & FI_COMPLETION) {
-			request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-			fi_ibv_rdm_move_to_cq(p->ep->fi_rcq, request);
-		} else {
-			FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-			util_buf_release(
-				request->ep->fi_ibv_rdm_request_pool,
-				request);
-		}
-		
-		FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	} else {
-		ret = -FI_ENOMSG;
-		goto err;
-	}
-
-out:
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return ret;
-err:
-	request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-
-	fi_ibv_rdm_cntr_inc_err(p->ep->recv_cntr);
-
-	if (request->comp_flags & FI_COMPLETION) {
-		fi_ibv_rdm_move_to_errcq(p->ep->fi_rcq, request, ret);
-	}
-
-	ret = FI_SUCCESS;
-	goto out;
-}
-
-static ssize_t
-fi_ibv_rdm_init_unexp_recv_request(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert(request->state.eager == FI_IBV_STATE_EAGER_BEGIN);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	struct fi_ibv_recv_got_pkt_preprocess_data *p = data;
-	struct fi_ibv_rdm_buf *rbuf = p->rbuf;
-	ssize_t ret = FI_SUCCESS;
-
-	FI_IBV_RDM_HNDL_REQ_LOG();
-
-	switch (p->pkt_type) {
-	case FI_IBV_RDM_EAGER_PKT:
-	case FI_IBV_RDM_MSG_PKT:
-		FI_IBV_RDM_HNDL_REQ_LOG();
-
-		request->minfo.conn = p->conn;
-		request->minfo.tag = rbuf->header.tag;
-		request->minfo.is_tagged =
-			((p->pkt_type == FI_IBV_RDM_EAGER_PKT) ? 1 : 0);
-		request->len = 
-			p->arrived_len - sizeof(struct fi_ibv_rdm_header);
-		request->comp_flags =
-			(request->minfo.is_tagged ? FI_TAGGED :
-						    FI_MSG) | FI_RECV;
-		
-		assert(request->len <= p->ep->rndv_threshold);
-
-		if (request->len > 0) {
-			request->unexp_rbuf =
-				util_buf_alloc(request->ep->fi_ibv_rdm_extra_buffers_pool);
-			if (!request->unexp_rbuf) {
-				ret = -FI_ENOMEM;
-				VERBS_WARN(FI_LOG_EP_DATA,
-					   "Unable allocate memory from the pool "
-					   "for uenxpected buffer");
-				goto fn;
-			}
-			memcpy(request->unexp_rbuf, &rbuf->payload,
-			       request->len);
-		} else {
-			request->unexp_rbuf = NULL;
-		}
-		request->imm = p->imm_data;
-		request->state.eager = FI_IBV_STATE_EAGER_RECV_WAIT4RECV;
-		break;
-	case FI_IBV_RDM_RNDV_RTS_PKT:
-		FI_IBV_RDM_HNDL_REQ_LOG();
-		assert(p->arrived_len == sizeof(struct fi_ibv_rdm_rndv_header));
-		struct fi_ibv_rdm_rndv_header *h = (void *)&rbuf->header;
-
-		request->minfo.conn = p->conn;
-		request->minfo.tag = h->base.tag;
-		request->minfo.is_tagged = h->is_tagged;
-		request->rndv.id = (uintptr_t)h->id;
-		request->rndv.remote_addr = (void *)h->src_addr;
-		request->rndv.mr_rkey = h->mem_rkey;
-		request->len = h->total_len;
-		request->rest_len = h->total_len;
-		request->comp_flags = (h->is_tagged ? FI_TAGGED :
-						      FI_MSG) | FI_RECV;
-		request->imm = p->imm_data;
-		request->state.eager = FI_IBV_STATE_EAGER_RECV_WAIT4RECV;
-		request->state.rndv = FI_IBV_STATE_RNDV_RECV_WAIT4RES;
-		break;
-	default:
-		if (p->pkt_type == FI_IBV_RDM_RNDV_ACK_PKT) {
-			FI_IBV_RDM_DBG_REQUEST("Unexpected RNDV ack!!!",
-					       request, FI_LOG_INFO);
-		}
-
-		VERBS_INFO(FI_LOG_EP_DATA,
-			"Got unknown unexpected pkt: %" PRIu64 "\n",
-			p->pkt_type);
-		assert(0);
-		ret = -FI_EOTHER;
-	}
-
-	fi_ibv_rdm_move_to_unexpected_queue(request, p->ep);
-fn:
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_eager_recv_got_pkt(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	struct fi_ibv_recv_got_pkt_preprocess_data *p = data;
-	struct fi_ibv_rdm_buf *rbuf = p->rbuf;
-	ssize_t ret;
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RECV_WAIT4PKT);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	switch (p->pkt_type) {
-	case FI_IBV_RDM_EAGER_PKT:
-	case FI_IBV_RDM_MSG_PKT:
-	{
-		const size_t data_len = p->arrived_len - sizeof(rbuf->header);
-		assert(data_len <= p->ep->rndv_threshold);
-
-		if (request->parent) {
-			if (!fi_ibv_rdm_repost_multi_recv(request, data_len, p->ep))
-				return -FI_ENOMEM;
-			
-		}
-
-		if (request->len >= data_len) {
-			request->minfo.conn = p->conn;
-			request->minfo.tag = rbuf->header.tag;
-			request->minfo.is_tagged =
-				((p->pkt_type == FI_IBV_RDM_EAGER_PKT) ? 1 : 0);
-
-			request->len = data_len;
-			request->exp_rbuf = &rbuf->payload;
-			request->imm = p->imm_data;
-
-			if (request->dest_buf) {
-				assert(request->exp_rbuf);
-				memcpy(request->dest_buf,
-					request->exp_rbuf, request->len);
-			}
-
-			if (request->parent) {
-				if (!fi_ibv_rdm_repost_multi_recv(request, data_len,
-							     p->ep))
-					return -FI_ENOMEM;
-			}
-
-			fi_ibv_rdm_cntr_inc(p->ep->recv_cntr);
-
-			if (request->comp_flags & FI_COMPLETION) {
-				request->state.eager = 
-					FI_IBV_STATE_EAGER_READY_TO_FREE;
-				fi_ibv_rdm_move_to_cq(p->ep->fi_rcq, request);
-			} else {
-				FI_IBV_RDM_DBG_REQUEST("to_pool: ", request,
-							FI_LOG_DEBUG);
-				util_buf_release(
-					request->ep->fi_ibv_rdm_request_pool,
-					request);
-			}
-		} else {
-			VERBS_INFO(FI_LOG_EP_DATA,
-				   "%s: %d RECV TRUNCATE, data_len=%zu, "
-				   "posted_len=%" PRIu64 ", conn %p, tag 0x%" PRIx64 ", "
-				   "tagmask %" PRIx64 "\n",
-				   __FUNCTION__, __LINE__, data_len,
-				   request->len, request->minfo.conn,
-				   request->minfo.tag, request->minfo.tagmask);
-
-			if (request->parent) {
-				if (!fi_ibv_rdm_repost_multi_recv(request, data_len,
-							     p->ep))
-					return -FI_ENOMEM;
-			}
-
-			request->state.eager =
-				FI_IBV_STATE_EAGER_READY_TO_FREE;
-
-			fi_ibv_rdm_cntr_inc_err(p->ep->recv_cntr);
-
-			if (request->comp_flags & FI_COMPLETION) {
-				fi_ibv_rdm_move_to_errcq(p->ep->fi_rcq, request,
-							 FI_ETRUNC);
-			}
-		}
-
-		FI_IBV_RDM_HNDL_REQ_LOG();
-		break;
-	}
-	case FI_IBV_RDM_RNDV_RTS_PKT:
-	{
-		struct fi_ibv_rdm_rndv_header *rndv_header = 
-			(void *)&rbuf->header;
-
-		assert(p->arrived_len == sizeof(*rndv_header));
-
-		if (request->len < rndv_header->total_len) {
-			/* rndv protocol finalization requires memory
-			 * deregistration, entry in errcq will be generated
-			 * after acknowledgement in normal flow */
-			request->state.err = FI_ETRUNC;
-		}
-
-		request->minfo.conn = p->conn;
-		request->minfo.tag = rndv_header->base.tag;
-		request->minfo.is_tagged = rndv_header->is_tagged;
-		request->rndv.remote_addr = (void *)rndv_header->src_addr;
-		request->rndv.mr_rkey = rndv_header->mem_rkey;
-		request->len = rndv_header->total_len;
-		request->rest_len = rndv_header->total_len;
-		request->imm = p->imm_data;
-		request->rndv.id = rndv_header->id;
-
-		if (request->parent) {
-			if (!fi_ibv_rdm_repost_multi_recv(request,
-						     rndv_header->total_len,
-						     p->ep))
-				return -FI_ENOMEM;
-		}
-
-		ret = fi_ibv_rdm_move_to_postponed_queue(request);
-		if (ret)
-			return ret;
-
-		request->state.eager = FI_IBV_STATE_EAGER_RECV_END;
-		request->state.rndv = FI_IBV_STATE_RNDV_RECV_WAIT4RES;
-		FI_IBV_RDM_HNDL_REQ_LOG();
-		break;
-	}
-	default:
-		VERBS_INFO(FI_LOG_EP_DATA,
-			"Got unknown unexpected pkt: %" PRIu64 "\n",
-			p->pkt_type);
-		assert(0);
-		FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-		return -FI_EOTHER;
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_eager_recv_process_unexp_pkt(struct fi_ibv_rdm_request *request,
-					void *data)
-{
-	struct fi_ibv_recv_got_pkt_process_data *p = data;
-
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert((request->state.eager == FI_IBV_STATE_EAGER_RECV_WAIT4RECV) ||
-	       (request->state.eager == FI_IBV_STATE_EAGER_RECV_CLAIMED));
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	if (request->dest_buf && request->len != 0) {
-		memcpy(request->dest_buf, request->unexp_rbuf, request->len);
-	}
-
-	if (request->unexp_rbuf) {
-		util_buf_release(
-			request->ep->fi_ibv_rdm_extra_buffers_pool,
-			request->unexp_rbuf);
-		request->unexp_rbuf = NULL;
-	}
-
-	fi_ibv_rdm_cntr_inc(p->ep->recv_cntr);
-
-	if (request->comp_flags & FI_COMPLETION) {
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-		fi_ibv_rdm_move_to_cq(p->ep->fi_rcq, request);
-	} else {
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(request->ep->fi_ibv_rdm_request_pool,
-				 request);
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_tagged_recv_claim(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RECV_WAIT4RECV);
-	assert((request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED) ||
-	       (request->state.rndv == FI_IBV_STATE_RNDV_RECV_WAIT4RES));
-
-	ssize_t ret = FI_SUCCESS;
-	struct fi_ibv_rdm_tagged_peek_data *peek_data = data;
-	assert(peek_data->context);
-
-	request->state.eager = FI_IBV_STATE_EAGER_RECV_CLAIMED;
-	request->context = peek_data->context;
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_eager_recv_discard(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RECV_WAIT4RECV);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-	assert(data == NULL);
-
-	fi_ibv_rdm_remove_from_unexp_queue(request);
-
-	if (request->unexp_rbuf) {
-		util_buf_release(
-			request->ep->fi_ibv_rdm_extra_buffers_pool,
-			request->unexp_rbuf);
-		request->unexp_rbuf = NULL;
-	}
-
-	FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-	util_buf_release(request->ep->fi_ibv_rdm_request_pool,
-			 request);
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return FI_SUCCESS;
-}
-
-static inline ssize_t
-fi_ibv_rdm_rndv_read_reg_mr(struct fi_ibv_rdm_ep *ep,
-			    struct fi_ibv_rdm_request *request)
-{
-	return ep->domain->internal_mr_reg(ep->domain,
-					   (void *)request->src_addr,
-					   request->len,
-					   FI_REMOTE_READ,
-					   &request->rndv.md);
-}
-
-static ssize_t
-fi_ibv_rdm_rndv_recv_post_read(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RECV_END);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_RECV_WAIT4RES);
-
-	struct fi_ibv_rdm_tagged_send_ready_data *p = data;
-	const size_t offset = request->len - request->rest_len;
-	const size_t seg_cursize =
-		MIN(p->ep->rndv_seg_size, request->rest_len);
-	struct ibv_send_wr wr = { 0 };
-	struct ibv_send_wr *bad_wr = NULL;
-	struct ibv_sge sge;
-	ssize_t ret = FI_SUCCESS;
-
-	fi_ibv_rdm_remove_from_postponed_queue(request);
-	VERBS_DBG(FI_LOG_EP_DATA,
-		  "\t REQUEST: conn %p, tag 0x%" PRIx64
-		  ", len %" PRIu64 ", rest %" PRIu64
-		  ", dest_buf %p, src_addr %p, rkey 0x%"PRIx64"\n",
-		  request->minfo.conn, request->minfo.tag, request->len,
-		  request->rest_len, request->dest_buf,
-		  request->rndv.remote_addr, request->rndv.mr_rkey);
-
-	assert((request->minfo.conn->cm_role != FI_VERBS_CM_SELF) ||
-	       (request->rndv.remote_addr != request->dest_buf));
-
-	/* First segment */
-	if (offset == 0) {
-		ret = fi_ibv_rdm_rndv_read_reg_mr(p->ep, request);
-		if (ret) {
-			return ret;
-		}
-		request->post_counter = 0;
-	}
-
-	wr.wr_id = FI_IBV_RDM_PACK_WR(request);
-	assert(FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wr.wr_id) == 0);
-	wr.opcode = IBV_WR_RDMA_READ;
-	wr.sg_list = &sge;
-	wr.num_sge = 1;
-	wr.send_flags = 0;
-	wr.wr.rdma.remote_addr = (uintptr_t)
-		((char *)request->rndv.remote_addr + offset);
-	wr.wr.rdma.rkey = request->rndv.mr_rkey;
-
-	sge.addr = (uintptr_t)((char *)request->dest_buf + offset);
-	sge.length = (request->state.err == FI_SUCCESS ? seg_cursize : 0);
-	sge.lkey = fi_ibv_mr_internal_lkey(&request->rndv.md);
-
-	request->rest_len -= seg_cursize;
-	request->post_counter++;
-	FI_IBV_RDM_INC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-	VERBS_DBG(FI_LOG_EP_DATA, "posted %d bytes, conn %p, tag 0x%" PRIx64 "\n",
-		  sge.length, request->minfo.conn, request->minfo.tag);
-	ret = ibv_post_send(request->minfo.conn->qp[0], &wr, &bad_wr);
-	if (ret) {
-		VERBS_INFO_ERRNO(FI_LOG_EP_DATA, "ibv_post_send", errno);
-		assert(0);
-		return -errno;
-	};
-
-	if (request->rest_len && request->state.err == FI_SUCCESS) {
-		/* Move to postponed queue for the next iteration */
-		ret = fi_ibv_rdm_move_to_postponed_queue(request);
-	} else {
-		request->state.eager = FI_IBV_STATE_EAGER_RECV_END;
-		request->state.rndv = FI_IBV_STATE_RNDV_RECV_WAIT4LC;
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_rndv_recv_read_lc(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	struct fi_ibv_rdm_tagged_send_completed_data *p = data;
-	struct fi_ibv_rdm_conn *conn = request->minfo.conn;
-	struct fi_ibv_rdm_buf *sbuf = request->sbuf;
-	const int ack_size = 
-		sizeof(struct fi_ibv_rdm_header) + sizeof(request->rndv.id);
-	struct ibv_sge sge = {
-		.addr = (uintptr_t)sbuf,
-		.length = ack_size + FI_IBV_RDM_BUFF_SERVICE_DATA_SIZE,
-		.lkey = fi_ibv_mr_internal_lkey(&conn->s_md),
-	};
-	struct ibv_send_wr wr = {
-		.wr_id = FI_IBV_RDM_PACK_WR(request),
-		.opcode = p->ep->eopcode,
-		.sg_list = &sge,
-		.num_sge = 1,
-		.wr.rdma.remote_addr = 
-			(uintptr_t)fi_ibv_rdm_get_remote_addr(conn,
-							      request->sbuf),
-		.wr.rdma.rkey = conn->remote_rbuf_rkey,
-		.send_flags = (sge.length < p->ep->max_inline_rc) ?
-			       IBV_SEND_INLINE : 0,
-	};
-	struct ibv_send_wr *bad_wr = NULL;
-	ssize_t ret = FI_SUCCESS;
-
-	assert(request->len > (p->ep->rndv_threshold
-			       - sizeof(struct fi_ibv_rdm_header)));
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RECV_END);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_RECV_WAIT4LC ||
-	       request->state.rndv == FI_IBV_STATE_RNDV_RECV_WAIT4RES);
-	assert(FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wr.wr_id) == 0);
-
-	FI_IBV_RDM_DEC_SIG_POST_COUNTERS(conn, p->ep);
-	request->post_counter--;
-
-	if (request->rest_len || request->post_counter) {
-		FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-		return ret;
-	}
-
-	assert(request->sbuf);
-
-	sbuf->header.tag = 0;
-	sbuf->header.service_tag = 0;
-	FI_IBV_RDM_SET_PKTTYPE(sbuf->header.service_tag,
-			       FI_IBV_RDM_RNDV_ACK_PKT);
-	sbuf->service_data.pkt_len = ack_size;
-	memcpy(&sbuf->payload, &request->rndv.id, sizeof(request->rndv.id));
-
-	FI_IBV_RDM_INC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-	VERBS_DBG(FI_LOG_EP_DATA,
-		  "posted %d bytes, conn %p, tag 0x%" PRIx64 ", request %p\n",
-		  sge.length, request->minfo.conn, request->minfo.tag, request);
-	ret = ibv_post_send(conn->qp[0], &wr, &bad_wr);
-	if (ret == 0) {
-		assert(request->rndv.md.mr);
-		p->ep->domain->internal_mr_dereg(&request->rndv.md);
-		VERBS_DBG(FI_LOG_EP_DATA,
-			  "SENDING RNDV ACK: conn %p, sends_outgoing = %"PRIu32", "
-			  "post_sends = %"PRIu32"\n",
-			  conn, conn->av_entry->sends_outgoing,
-			  p->ep->posted_sends);
-	} else {
-		VERBS_INFO_ERRNO(FI_LOG_EP_DATA, "ibv_post_send", errno);
-		assert(0);
-		ret = -errno;
-		request->state.err = ret;
-	}
-	request->state.eager = FI_IBV_STATE_EAGER_SEND_WAIT4LC;
-	request->state.rndv = FI_IBV_STATE_RNDV_RECV_END;
-
-	if (request->state.err == FI_SUCCESS) {
-		fi_ibv_rdm_cntr_inc(p->ep->recv_cntr);
-
-		if (request->comp_flags & FI_COMPLETION) {
-			fi_ibv_rdm_move_to_cq(p->ep->fi_rcq, request);
-		}
-	} else {
-		fi_ibv_rdm_cntr_inc_err(p->ep->recv_cntr);
-
-		if (request->comp_flags & FI_COMPLETION) {
-			fi_ibv_rdm_move_to_errcq(p->ep->fi_rcq, request,
-						 request->state.err);
-		}
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_rndv_recv_ack_lc(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert(request->state.eager == FI_IBV_STATE_EAGER_SEND_WAIT4LC ||
-	       request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_RECV_END);
-
-	struct fi_ibv_rdm_tagged_send_completed_data *p = data;
-	FI_IBV_RDM_DEC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-
-	if (request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE) {
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(
-			request->ep->fi_ibv_rdm_request_pool,
-			request);
-	} else {
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-		request->state.rndv = FI_IBV_STATE_RNDV_RECV_END;
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_rma_init_request(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert(request->state.eager == FI_IBV_STATE_EAGER_BEGIN);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	struct fi_ibv_rdm_rma_start_data *p =
-		(struct fi_ibv_rdm_rma_start_data *)data;
-	ssize_t ret = FI_SUCCESS;
-	int lmr_access = 0;
-
-	request->context = p->context;
-	request->minfo.conn = p->conn;
-	request->len = p->data_len;
-	request->rest_len = p->data_len;
-	request->post_counter = 0;
-
-	request->rma.remote_addr = p->rbuf;
-	request->rma.mr_rkey = p->mr_rkey;
-	request->rma.mr_lkey = p->mr_lkey;
-	request->rma.opcode = p->op_code;
-	assert(!request->rma.md.mr);
-
-	request->comp_flags = p->flags;
-	if (p->op_code == IBV_WR_RDMA_READ) {
-		request->dest_buf = (void*)p->lbuf;
-		lmr_access |= FI_READ;
-	} else {
-		assert(p->op_code == IBV_WR_RDMA_WRITE);
-		lmr_access |= FI_WRITE;
-		request->src_addr = (void*)p->lbuf;
-	}
-
-	if (request->rmabuf && request->len >= p->ep_rdm->max_inline_rc) {
-		memcpy(&request->rmabuf->payload, request->src_addr,
-			request->len);
-	} else if (!request->rmabuf && !p->mr_lkey) {
-		ret = p->ep_rdm->domain->internal_mr_reg(p->ep_rdm->domain,
-							 (void *)p->lbuf, p->data_len,
-							 lmr_access,
-							 &request->rma.md);
-		if (!ret)
-			request->rma.mr_lkey =
-				fi_ibv_mr_internal_lkey(&request->rma.md);
-	}
-
-	request->state.eager = FI_IBV_STATE_EAGER_RMA_INITIALIZED;
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_rma_inject_request(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RMA_INJECT);
-	assert(request->state.rndv  == FI_IBV_STATE_RNDV_NOT_USED);
-
-
-	struct ibv_sge sge = { 0 };
-	struct ibv_send_wr wr = { 0 };
-	struct ibv_send_wr *bad_wr = NULL;
-	struct fi_ibv_rdm_rma_start_data *p = data;
-	int ret;
-
-	request->minfo.conn = p->conn;
-	request->len = p->data_len;
-	request->comp_flags = p->flags;
-	request->rmabuf = NULL;
-
-	wr.sg_list = &sge;
-	wr.num_sge = 1;
-	wr.wr.rdma.remote_addr = p->rbuf;
-	wr.wr.rdma.rkey = p->mr_rkey;
-	wr.send_flags = 0;
-	wr.wr_id = FI_IBV_RDM_PACK_WR(request);
-	assert(FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wr.wr_id) == 0);
-	wr.opcode = IBV_WR_RDMA_WRITE;
-	sge.length = request->len;
-	sge.addr = p->lbuf;
-
-	if ((request->len < p->ep_rdm->max_inline_rc) && 
-	    (!RMA_RESOURCES_IS_BUSY(request->minfo.conn, p->ep_rdm)) &&
-	    fi_ibv_rdm_check_connection(request->minfo.conn)) {
-		wr.send_flags |= IBV_SEND_INLINE;
-	} else if (fi_ibv_rdm_prepare_rma_request(request, p->ep_rdm)) {
-		memcpy(&request->rmabuf->payload, (void*)p->lbuf, p->data_len);
-		sge.addr = (uintptr_t)&request->rmabuf->payload;
-		sge.lkey = fi_ibv_mr_internal_rkey(
-				&request->minfo.conn->rma_md);
-	} else {
-		FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-		return -FI_EAGAIN;
-	}
-
-	FI_IBV_RDM_INC_SIG_POST_COUNTERS(request->minfo.conn, p->ep_rdm);
-
-	ret = ibv_post_send(request->minfo.conn->qp[0], &wr, &bad_wr);
-	request->state.eager = FI_IBV_STATE_EAGER_RMA_INJECT_WAIT4LC;
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-
-	return (ret == 0) ? FI_SUCCESS : -errno;
-}
-
-static ssize_t
-fi_ibv_rdm_rma_post_ready(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert((request->state.eager == FI_IBV_STATE_EAGER_RMA_INITIALIZED &&
-		request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED) ||
-	       (request->state.eager == FI_IBV_STATE_EAGER_RMA_POSTPONED &&
-		request->state.rndv == FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC));
-
-	int ret;
-	struct fi_ibv_rma_post_ready_data *p = data;
-	
-	const size_t offset = request->len - request->rest_len;
-	const size_t seg_cursize =
-		MIN(p->ep_rdm->rndv_seg_size, request->rest_len);
-
-	struct ibv_sge sge = { 0 };
-	struct ibv_send_wr wr = { 0 };
-	struct ibv_send_wr *bad_wr = NULL;
-
-	wr.wr_id = FI_IBV_RDM_PACK_WR(request);
-	assert(FI_IBV_RDM_CHECK_SERVICE_WR_FLAG(wr.wr_id) == 0);
-	wr.sg_list = &sge;
-	wr.num_sge = 1;
-	wr.wr.rdma.remote_addr = request->rma.remote_addr;
-	wr.wr.rdma.rkey = request->rma.mr_rkey;
-	wr.send_flags = 0;
-	wr.opcode = request->rma.opcode;
-
-	if (request->state.eager == FI_IBV_STATE_EAGER_RMA_POSTPONED) {
-		fi_ibv_rdm_remove_from_postponed_queue(request);
-		request->state.eager = FI_IBV_STATE_EAGER_RMA_INITIALIZED;
-	}
-
-	/* buffered operation */
-	if (request->rmabuf) {
-		if (request->rma.opcode == IBV_WR_RDMA_WRITE && 
-		    request->len < p->ep_rdm->max_inline_rc) {
-			wr.send_flags |= IBV_SEND_INLINE;
-			sge.addr = (uintptr_t)request->src_addr;
-		} else {
-			sge.addr = (uintptr_t)&request->rmabuf->payload;
-			sge.lkey = fi_ibv_mr_internal_lkey(
-					&request->minfo.conn->rma_md);
-		}
-		request->state.eager = FI_IBV_STATE_EAGER_RMA_WAIT4LC;
-	} else {
-		/* src_addr or dest_buf from an union
-		 *  for write or read properly */
-		sge.addr = ((uintptr_t)request->src_addr) + offset;
-		sge.lkey = request->rma.mr_lkey;
-		request->state.rndv = FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC;
-	}
-
-	sge.length = seg_cursize;
-
-	request->rest_len -= seg_cursize;
-	request->post_counter++;
-	FI_IBV_RDM_INC_SIG_POST_COUNTERS(request->minfo.conn, p->ep_rdm);
-
-	ret = ibv_post_send(request->minfo.conn->qp[0], &wr, &bad_wr);
-	if (request->rest_len && !ret) {
-		ret = fi_ibv_rdm_move_to_postponed_queue(request);
-		if (ret)
-			return ret;
-		request->state.eager = FI_IBV_STATE_EAGER_RMA_POSTPONED;
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-
-	return (!ret) ? FI_SUCCESS : -errno;
-}
-
-static ssize_t
-fi_ibv_rdm_rma_inject_lc(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RMA_INJECT_WAIT4LC);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	struct fi_ibv_rdm_tagged_send_completed_data *p = data;
-
-	FI_IBV_RDM_DEC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-	if (request->rmabuf) {
-		fi_ibv_rdm_set_buffer_status(request->rmabuf, BUF_STATUS_FREE);
-	} /* else inline flag was set */
-
-	FI_IBV_RDM_HNDL_REQ_LOG();
-
-	FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-	util_buf_release(request->ep->fi_ibv_rdm_request_pool,
-			 request);
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-
-	return FI_SUCCESS;
-}
-
-static ssize_t
-fi_ibv_rdm_rma_buffered_lc(struct fi_ibv_rdm_request *request, void *data)
-{
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RMA_WAIT4LC);
-	assert(request->state.rndv == FI_IBV_STATE_RNDV_NOT_USED);
-
-	struct fi_ibv_rdm_tagged_send_completed_data *p = data;
-	FI_IBV_RDM_DEC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-
-	assert(request->rmabuf);
-	if (request->rma.opcode == IBV_WR_RDMA_READ) {
-		memcpy(request->dest_buf, &request->rmabuf->payload, request->len);
-	}
-	fi_ibv_rdm_set_buffer_status(request->rmabuf, BUF_STATUS_FREE);
-
-	if (request->rma.opcode == IBV_WR_RDMA_READ) {
-		fi_ibv_rdm_cntr_inc(p->ep->read_cntr);
-	} else if (request->rma.opcode == IBV_WR_RDMA_WRITE) {
-		fi_ibv_rdm_cntr_inc(p->ep->write_cntr);
-	}
-
-	if (request->comp_flags & FI_COMPLETION) {
-		fi_ibv_rdm_move_to_cq(p->ep->fi_scq, request);
-	} else {
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-		FI_IBV_RDM_HNDL_REQ_LOG();
-	}
-
-	if (request->state.eager == FI_IBV_STATE_EAGER_READY_TO_FREE) {
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(
-			request->ep->fi_ibv_rdm_request_pool,
-			request);
-	} else {
-		request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return FI_SUCCESS;
-}
-
-
-static ssize_t
-fi_ibv_rdm_rma_zerocopy_lc(struct fi_ibv_rdm_request *request, void *data)
-{
-	ssize_t ret = FI_SUCCESS;
-	FI_IBV_RDM_HNDL_REQ_LOG_IN();
-
-	assert(request->state.eager == FI_IBV_STATE_EAGER_RMA_INITIALIZED ||
-		(request->state.eager == FI_IBV_STATE_EAGER_RMA_POSTPONED));
-	assert(request->state.rndv == FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC);
-	assert(!request->rmabuf);
-
-	VERBS_DBG(FI_LOG_EP_DATA, "conn %p, tag 0x%" PRIx64 ", len %" PRIu64 "\n",
-		  request->minfo.conn, request->minfo.tag, request->len);
-
-	struct fi_ibv_rdm_tagged_send_completed_data *p = data;
-	FI_IBV_RDM_DEC_SIG_POST_COUNTERS(request->minfo.conn, p->ep);
-	request->post_counter--;
-
-	if (request->rest_len == 0 && request->post_counter == 0) {
-		if (request->rma.md.mr)
-			ret = p->ep->domain->internal_mr_dereg(&request->rma.md);
-
-		if (request->rma.opcode == IBV_WR_RDMA_READ)
-			fi_ibv_rdm_cntr_inc(p->ep->read_cntr);
-		else if (request->rma.opcode == IBV_WR_RDMA_WRITE)
-			fi_ibv_rdm_cntr_inc(p->ep->write_cntr);
-
-		if (request->comp_flags & FI_COMPLETION) {
-			if (ret)
-				fi_ibv_rdm_move_to_errcq(p->ep->fi_scq, request, ret);
-			else
-				fi_ibv_rdm_move_to_cq(p->ep->fi_scq, request);
-			request->state.eager = FI_IBV_STATE_EAGER_READY_TO_FREE;
-			request->state.rndv = FI_IBV_STATE_ZEROCOPY_RMA_END;
-		} else {
-			FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-			util_buf_release(
-				request->ep->fi_ibv_rdm_request_pool,
-				request);
-		}
-	}
-
-	FI_IBV_RDM_HNDL_REQ_LOG_OUT();
-	return ret;
-}
-
-static ssize_t
-fi_ibv_rdm_req_hndl_err(struct fi_ibv_rdm_request *request, void *data)
-{
-	VERBS_INFO(FI_LOG_EP_DATA,
-		"\t> IN\t< eager_state = %s, rndv_state = %s, len = %lu\n",
-		fi_ibv_rdm_req_eager_state_to_str(request->state.eager),
-		fi_ibv_rdm_req_rndv_state_to_str(request->state.rndv),
-		request->len);
-
-	assert(0);
-	return -FI_EOTHER;
-}
-
-ssize_t fi_ibv_rdm_req_hndls_init(void)
-{
-	size_t i, j, k;
-
-	for (i = 0; i < FI_IBV_STATE_EAGER_COUNT; ++i) {
-		for (j = 0; j < FI_IBV_STATE_RNDV_COUNT; ++j) {
-			for (k = 0; k < FI_IBV_EVENT_COUNT; ++k) {
-				fi_ibv_rdm_req_hndl_arr[i][j][k] =
-					fi_ibv_rdm_req_hndl_err;
-			}
-		}
-	}
-
-	// EAGER_SEND stuff
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_BEGIN]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_SEND_START] =
-			fi_ibv_rdm_init_send_request;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_SEND_POSTPONED]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_POST_READY] =
-			fi_ibv_rdm_eager_send_ready;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_SEND_WAIT4LC]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_eager_send_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_READY_TO_FREE]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_eager_send_lc;
-
-	// EAGER_RECV stuff
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_BEGIN]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_START] =
-			fi_ibv_rdm_init_recv_request;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_BEGIN]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_PEEK] =
-			fi_ibv_rdm_tagged_peek_request;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_BEGIN]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_CLAIM] =
-			fi_ibv_rdm_tagged_recv_claim;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_BEGIN]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_GOT_PKT_PROCESS] =
-			fi_ibv_rdm_init_unexp_recv_request;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_WAIT4PKT]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_GOT_PKT_PROCESS] =
-			fi_ibv_rdm_eager_recv_got_pkt;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_WAIT4RECV]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_START] =
-			fi_ibv_rdm_eager_recv_process_unexp_pkt;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_WAIT4RECV]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_CLAIM] =
-			fi_ibv_rdm_tagged_recv_claim;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_CLAIMED]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_START] =
-			fi_ibv_rdm_eager_recv_process_unexp_pkt;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_WAIT4RECV]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RECV_DISCARD] =
-			fi_ibv_rdm_eager_recv_discard;
-
-	// RNDV_SEND stuff
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_BEGIN]
-		[FI_IBV_STATE_RNDV_SEND_BEGIN][FI_IBV_EVENT_SEND_START] =
-			fi_ibv_rdm_init_send_request;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_SEND_POSTPONED]
-		[FI_IBV_STATE_RNDV_SEND_WAIT4SEND][FI_IBV_EVENT_POST_READY] =
-			fi_ibv_rdm_rndv_rts_send_ready;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_SEND_WAIT4LC]
-		[FI_IBV_STATE_RNDV_SEND_WAIT4ACK][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rndv_rts_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_READY_TO_FREE]
-		[FI_IBV_STATE_RNDV_SEND_END][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rndv_rts_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_SEND_WAIT4LC]
-		[FI_IBV_STATE_RNDV_SEND_END][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rndv_rts_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_SEND_WAIT4LC]
-		[FI_IBV_STATE_RNDV_SEND_WAIT4ACK][FI_IBV_EVENT_RECV_GOT_PKT_PROCESS]
-			= fi_ibv_rdm_rndv_end;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_SEND_END]
-		[FI_IBV_STATE_RNDV_SEND_WAIT4ACK][FI_IBV_EVENT_RECV_GOT_PKT_PROCESS]
-			= fi_ibv_rdm_rndv_end;
-	
-	// RNDV_RECV stuff
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_BEGIN]
-		[FI_IBV_STATE_RNDV_RECV_BEGIN][FI_IBV_EVENT_RECV_START] =
-			fi_ibv_rdm_init_recv_request;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_WAIT4RECV]
-		[FI_IBV_STATE_RNDV_RECV_WAIT4RES][FI_IBV_EVENT_RECV_CLAIM] =
-			fi_ibv_rdm_tagged_recv_claim;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_END]
-		[FI_IBV_STATE_RNDV_RECV_WAIT4RES][FI_IBV_EVENT_POST_READY] =
-			fi_ibv_rdm_rndv_recv_post_read;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_END]
-		[FI_IBV_STATE_RNDV_RECV_WAIT4RES][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rndv_recv_read_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_END]
-		[FI_IBV_STATE_RNDV_RECV_WAIT4LC][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rndv_recv_read_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RECV_END]
-		[FI_IBV_STATE_RNDV_RECV_WAIT4LC][FI_IBV_EVENT_POST_READY] =
-			fi_ibv_rdm_rndv_recv_read_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_SEND_WAIT4LC]
-		[FI_IBV_STATE_RNDV_RECV_END][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rndv_recv_ack_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_READY_TO_FREE]
-		[FI_IBV_STATE_RNDV_RECV_END][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rndv_recv_ack_lc;
-
-	// RMA read/write stuff
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_BEGIN]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RMA_START] =
-			fi_ibv_rdm_rma_init_request;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RMA_INJECT]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_RMA_START] =
-			fi_ibv_rdm_rma_inject_request;	
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RMA_INITIALIZED]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_POST_READY] =
-			fi_ibv_rdm_rma_post_ready;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RMA_POSTPONED]
-		[FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC][FI_IBV_EVENT_POST_READY] =
-			fi_ibv_rdm_rma_post_ready;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RMA_WAIT4LC]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rma_buffered_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RMA_INJECT_WAIT4LC]
-		[FI_IBV_STATE_RNDV_NOT_USED][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rma_inject_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RMA_INITIALIZED]
-		[FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rma_zerocopy_lc;
-	fi_ibv_rdm_req_hndl_arr[FI_IBV_STATE_EAGER_RMA_POSTPONED]
-		[FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC][FI_IBV_EVENT_POST_LC] =
-			fi_ibv_rdm_rma_zerocopy_lc;
-
-	return FI_SUCCESS;
-}
-
-ssize_t fi_ibv_rdm_req_hndls_clean(void)
-{
-	size_t i, j, k;
-	for (i = 0; i < FI_IBV_STATE_EAGER_COUNT; ++i) {
-		for (j = 0; j < FI_IBV_STATE_RNDV_COUNT; ++j) {
-			for (k = 0; k < FI_IBV_EVENT_COUNT; ++k) {
-				fi_ibv_rdm_req_hndl_arr[i][j][k] = NULL;
-			}
-		}
-	}
-	return FI_SUCCESS;
-}
-
-ssize_t
-fi_ibv_rdm_req_hndl(struct fi_ibv_rdm_request * request,
-		    enum fi_ibv_rdm_request_event event, void *data)
-{
-	VERBS_DBG(FI_LOG_EP_DATA, "\t%p, eager_state = %s, rndv_state = %s, event = %s\n",
-		  request,
-		  fi_ibv_rdm_req_eager_state_to_str(request->state.eager),
-		  fi_ibv_rdm_req_rndv_state_to_str(request->state.rndv),
-		  fi_ibv_rdm_event_to_str(event));
-	assert(fi_ibv_rdm_req_hndl_arr[request->state.eager]
-				      [request->state.rndv][event]);
-
-	return fi_ibv_rdm_req_hndl_arr[request->state.eager]
-				      [request->state.rndv]
-				      [event] (request, data);
-}
-
-char *
-fi_ibv_rdm_req_eager_state_to_str(enum fi_ibv_rdm_request_eager_state state)
-{
-	switch (state) {
-	case FI_IBV_STATE_EAGER_BEGIN:
-		return "STATE_EAGER_BEGIN";
-
-	case FI_IBV_STATE_EAGER_SEND_POSTPONED:
-		return "STATE_EAGER_SEND_POSTPONED";
-	case FI_IBV_STATE_EAGER_SEND_WAIT4LC:
-		return "STATE_EAGER_SEND_WAIT4LC";
-	case FI_IBV_STATE_EAGER_SEND_END:
-		return "STATE_EAGER_SEND_END";
-
-	case FI_IBV_STATE_EAGER_RECV_BEGIN:
-		return "STATE_EAGER_RECV_BEGIN";
-	case FI_IBV_STATE_EAGER_RECV_WAIT4PKT:
-		return "STATE_EAGER_RECV_WAIT4PKT";
-	case FI_IBV_STATE_EAGER_RECV_WAIT4RECV:
-		return "STATE_EAGER_RECV_WAIT4RECV";
-	case FI_IBV_STATE_EAGER_RECV_CLAIMED:
-		return "FI_IBV_STATE_EAGER_RECV_CLAIMED";
-	case FI_IBV_STATE_EAGER_RECV_END:
-		return "STATE_EAGER_RECV_END";
-
-	case FI_IBV_STATE_EAGER_RMA_INJECT:
-		return "FI_IBV_STATE_EAGER_RMA_INJECT";
-	case FI_IBV_STATE_EAGER_RMA_INITIALIZED:
-		return "FI_IBV_STATE_EAGER_RMA_INITIALIZED";
-	case FI_IBV_STATE_EAGER_RMA_POSTPONED:
-		return "FI_IBV_STATE_EAGER_RMA_POSTPONED";
-	case FI_IBV_STATE_EAGER_RMA_WAIT4LC:
-		return "FI_IBV_STATE_EAGER_RMA_WAIT4LC";
-	case FI_IBV_STATE_EAGER_RMA_INJECT_WAIT4LC:
-		return "FI_IBV_STATE_EAGER_RMA_INJECT_WAIT4LC";
-	case FI_IBV_STATE_EAGER_RMA_END:
-		return "FI_IBV_STATE_EAGER_RMA_END";
-
-	case FI_IBV_STATE_EAGER_READY_TO_FREE:
-		return "STATE_EAGER_READY_TO_FREE";
-
-	case FI_IBV_STATE_EAGER_COUNT:
-		return "STATE_EAGER_COUNT";
-	default:
-		return "STATE_EAGER_UNKNOWN!!!";
-	}
-}
-
-char *fi_ibv_rdm_req_rndv_state_to_str(enum fi_ibv_rdm_request_rndv_state state)
-{
-	switch (state) {
-	case FI_IBV_STATE_RNDV_NOT_USED:
-		return "STATE_RNDV_NOT_USED";
-	case FI_IBV_STATE_RNDV_SEND_BEGIN:
-		return "STATE_RNDV_SEND_BEGIN";
-	case FI_IBV_STATE_RNDV_SEND_WAIT4SEND:
-		return "STATE_RNDV_SEND_WAIT4SEND";
-	case FI_IBV_STATE_RNDV_SEND_WAIT4ACK:
-		return "STATE_RNDV_SEND_WAIT4ACK";
-	case FI_IBV_STATE_RNDV_SEND_END:
-		return "STATE_RNDV_SEND_END";
-
-	case FI_IBV_STATE_RNDV_RECV_BEGIN:
-		return "STATE_RNDV_RECV_BEGIN";
-	case FI_IBV_STATE_RNDV_RECV_WAIT4RES:
-		return "STATE_RNDV_RECV_WAIT4RES";
-	case FI_IBV_STATE_RNDV_RECV_WAIT4RECV:
-		return "STATE_RNDV_RECV_WAIT4RECV";
-	case FI_IBV_STATE_RNDV_RECV_WAIT4LC:
-		return "STATE_RNDV_RECV_WAIT4LC";
-	case FI_IBV_STATE_RNDV_RECV_END:
-		return "STATE_RNDV_RECV_END";
-
-	case FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC:
-		return "FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC";
-	case FI_IBV_STATE_ZEROCOPY_RMA_END:
-		return "FI_IBV_STATE_ZEROCOPY_RMA_END";
-
-	case FI_IBV_STATE_RNDV_COUNT:
-		return "STATE_RNDV_COUNT";
-	default:
-		return "STATE_RNDV_UNKNOWN!!!";
-	}
-}
-
-char *fi_ibv_rdm_event_to_str(enum fi_ibv_rdm_request_event event)
-{
-	switch (event) {
-	case FI_IBV_EVENT_SEND_START:
-		return "EVENT_SEND_START";
-	case FI_IBV_EVENT_POST_READY:
-		return "FI_IBV_EVENT_POST_READY";
-	case FI_IBV_EVENT_POST_LC:
-		return "FI_IBV_EVENT_POST_LC";
-
-	case FI_IBV_EVENT_RECV_START:
-		return "EVENT_RECV_START";
-	case FI_IBV_EVENT_RECV_GOT_PKT_PREPROCESS:
-		return "EVENT_RECV_GOT_PKT_PREPROCESS";
-	case FI_IBV_EVENT_RECV_GOT_PKT_PROCESS:
-		return "EVENT_RECV_GOT_PKT_PROCESS";
-	case FI_IBV_EVENT_RECV_GOT_ACK:
-		return "EVENT_RECV_GOT_ACK";
-	case FI_IBV_EVENT_RECV_PEEK:
-		return "FI_IBV_EVENT_RECV_PEEK";
-	case FI_IBV_EVENT_RECV_CLAIM:
-		return "FI_IBV_EVENT_RECV_CLAIM";
-	case FI_IBV_EVENT_RECV_DISCARD:
-		return "FI_IBV_EVENT_RECV_DISCARD";
-
-	case FI_IBV_EVENT_RMA_START:
-		return "FI_IBV_EVENT_RMA_START";
-
-	case FI_IBV_EVENT_COUNT:
-		return "EVENT_COUNT";
-	default:
-		return "EVENT_UNKNOWN!!!";
-	}
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm_states.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm_states.h
deleted file mode 100644
index a4c84a405..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_tagged_ep_rdm_states.h
+++ /dev/null
@@ -1,199 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#ifndef _VERBS_TAGGED_EP_RDM_STATES_H
-#define _VERBS_TAGGED_EP_RDM_STATES_H
-
-#include <stddef.h>
-#include <stdint.h>
-
-struct fi_ibv_rdm_request;
-struct fi_verbs_rdm_request_minfo;
-
-enum fi_ibv_rdm_request_eager_state {
-	FI_IBV_STATE_EAGER_BEGIN = 0,      // must be 0
-
-	FI_IBV_STATE_EAGER_SEND_POSTPONED,
-	FI_IBV_STATE_EAGER_SEND_WAIT4LC,   // wait for local completion
-	FI_IBV_STATE_EAGER_SEND_END,
-
-	FI_IBV_STATE_EAGER_RECV_BEGIN,
-	FI_IBV_STATE_EAGER_RECV_WAIT4PKT,
-	FI_IBV_STATE_EAGER_RECV_WAIT4RECV,
-	FI_IBV_STATE_EAGER_RECV_CLAIMED,
-	FI_IBV_STATE_EAGER_RECV_END,
-
-	FI_IBV_STATE_EAGER_RMA_INJECT,
-	FI_IBV_STATE_EAGER_RMA_INITIALIZED,
-	FI_IBV_STATE_EAGER_RMA_POSTPONED,
-	FI_IBV_STATE_EAGER_RMA_WAIT4LC,
-	FI_IBV_STATE_EAGER_RMA_INJECT_WAIT4LC,
-	FI_IBV_STATE_EAGER_RMA_END,
-
-	FI_IBV_STATE_EAGER_READY_TO_FREE,
-
-	FI_IBV_STATE_EAGER_COUNT           // must be last
-};
-
-char *
-fi_ibv_rdm_req_eager_state_to_str(enum fi_ibv_rdm_request_eager_state state);
-
-enum fi_ibv_rdm_request_rndv_state {
-	FI_IBV_STATE_RNDV_NOT_USED = 0,    // must be 0
-	FI_IBV_STATE_RNDV_SEND_BEGIN,
-	//    FI_IBV_STATE_RNDV_SEND_WAIT4CTS, // not implemented yet
-	FI_IBV_STATE_RNDV_SEND_WAIT4SEND,
-	FI_IBV_STATE_RNDV_SEND_WAIT4ACK,
-	FI_IBV_STATE_RNDV_SEND_END,
-
-	FI_IBV_STATE_RNDV_RECV_BEGIN,
-	FI_IBV_STATE_RNDV_RECV_WAIT4RES,
-	FI_IBV_STATE_RNDV_RECV_WAIT4RECV,
-	FI_IBV_STATE_RNDV_RECV_WAIT4LC,
-	FI_IBV_STATE_RNDV_RECV_END,
-
-	FI_IBV_STATE_ZEROCOPY_RMA_WAIT4LC,
-	FI_IBV_STATE_ZEROCOPY_RMA_END,
-
-	FI_IBV_STATE_RNDV_COUNT            // must be last
-};
-
-char *
-fi_ibv_rdm_req_rndv_state_to_str(enum fi_ibv_rdm_request_rndv_state state);
-
-enum fi_ibv_rdm_request_event {
-	FI_IBV_EVENT_SEND_START = 0,
-	FI_IBV_EVENT_POST_READY,
-	FI_IBV_EVENT_POST_LC,
-
-	FI_IBV_EVENT_RECV_START,
-	FI_IBV_EVENT_RECV_GOT_PKT_PREPROCESS,
-	FI_IBV_EVENT_RECV_GOT_PKT_PROCESS,
-	FI_IBV_EVENT_RECV_GOT_ACK,
-	FI_IBV_EVENT_RECV_PEEK,
-	FI_IBV_EVENT_RECV_CLAIM,
-	FI_IBV_EVENT_RECV_DISCARD,
-
-	FI_IBV_EVENT_RMA_START,
-
-	FI_IBV_EVENT_COUNT                 // must be last
-};
-
-char *fi_ibv_rdm_event_to_str(enum fi_ibv_rdm_request_event event);
-
-// Send service data types
-
-enum ibv_rdm_send_type
-{
-	IBV_RDM_SEND_TYPE_UND = 0,
-	IBV_RDM_SEND_TYPE_GEN,
-	IBV_RDM_SEND_TYPE_INJ,
-	IBV_RDM_SEND_TYPE_VEC
-};
-
-struct fi_ibv_rdm_send_start_data {
-	struct fi_ibv_rdm_ep *ep_rdm;
-	struct fi_ibv_rdm_conn *conn;
-	void *context;
-	uint64_t flags;
-	size_t tag;
-	size_t data_len;
-	union {
-		void *src_addr;
-		struct iovec* iovec_arr;
-	} buf;
-	int iov_count;
-	int is_tagged;
-	unsigned int imm;
-	enum ibv_rdm_send_type stype;
-};
-
-struct fi_ibv_rdm_tagged_send_ready_data {
-	struct fi_ibv_rdm_ep *ep;
-};
-
-struct fi_ibv_rdm_tagged_send_completed_data {
-	struct fi_ibv_rdm_ep *ep;
-};
-
-// Recv service data types
-
-struct fi_ibv_rdm_tagged_recv_start_data {
-	struct fi_ibv_rdm_tagged_peek_data peek_data;
-	struct fi_context *context;
-	struct fi_ibv_rdm_ep *ep;
-	void *dest_addr;
-	size_t data_len;
-};
-
-struct fi_ibv_recv_got_pkt_preprocess_data {
-	struct fi_ibv_rdm_conn *conn;
-	struct fi_ibv_rdm_ep *ep;
-	struct fi_ibv_rdm_buf *rbuf;
-	size_t arrived_len;
-	uint64_t pkt_type;
-	int imm_data;
-};
-
-struct fi_ibv_recv_got_pkt_process_data {
-	struct fi_ibv_rdm_ep *ep;
-} ;
-
-// rma service data types
-
-
-struct fi_ibv_rdm_rma_start_data {
-	struct fi_ibv_rdm_ep *ep_rdm;
-	struct fi_ibv_rdm_conn *conn;
-	void *context;
-	uint64_t flags;
-	uint64_t data_len;
-	uintptr_t rbuf;
-	uintptr_t lbuf;
-	uint64_t mr_rkey;
-	uint64_t mr_lkey;
-	enum ibv_wr_opcode op_code;
-};
-
-struct fi_ibv_rma_post_ready_data {
-	struct fi_ibv_rdm_ep *ep_rdm;
-};
-
-// Interfaces
-
-ssize_t fi_ibv_rdm_req_hndls_init(void);
-ssize_t fi_ibv_rdm_req_hndls_clean(void);
-ssize_t fi_ibv_rdm_req_hndl(struct fi_ibv_rdm_request *request,
-			    enum fi_ibv_rdm_request_event event,
-			    void *data);
-
-#endif /* _VERBS_TAGGED_EP_RDM_STATES_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_utils.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_utils.c
deleted file mode 100644
index f5e7ff24f..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_utils.c
+++ /dev/null
@@ -1,309 +0,0 @@
-/*
- * Copyright (c) 2016, Cisco Systems, Inc. All rights reserved.
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <ifaddrs.h>
-#include <net/if.h>
-
-#include <rdma/fi_errno.h>
-#include "../fi_verbs.h"
-#include "verbs_utils.h"
-#include "verbs_rdm.h"
-#include "verbs_queuing.h"
-
-size_t rdm_buffer_size(size_t buf_send_size)
-{
-	size_t size = buf_send_size + FI_IBV_RDM_BUFF_SERVICE_DATA_SIZE +
-		sizeof(struct fi_ibv_rdm_header) + FI_IBV_BUF_ALIGNMENT;
-	size -= (size % FI_IBV_BUF_ALIGNMENT);
-	return size;
-}
-
-int fi_ibv_rdm_req_match(struct dlist_entry *item, const void *other)
-{
-	const struct fi_ibv_rdm_request *req = other;
-	return (item == &req->queue_entry);
-}
-
-int fi_ibv_rdm_req_match_by_info(struct dlist_entry *item, const void *info)
-{
-	struct fi_ibv_rdm_request *request =
-		container_of(item, struct fi_ibv_rdm_request, queue_entry);
-
-	const struct fi_ibv_rdm_minfo *minfo = info;
-
-	return	(
-			((request->minfo.conn == NULL) ||
-			(request->minfo.conn == minfo->conn))
-			&&
-			(request->minfo.is_tagged ?
-			((request->minfo.tag & request->minfo.tagmask) ==
-			(minfo->tag          & request->minfo.tagmask)) :
-			(request->minfo.is_tagged == minfo->is_tagged))
-		);
-}
-
-/*
- * The same as fi_ibv_rdm_req_match_by_info but conn and tagmask fields
- * are used for matching instead of request's ones
- */
-int fi_ibv_rdm_req_match_by_info2(struct dlist_entry *item, const void *info)
-{
-	struct fi_ibv_rdm_request *request =
-		container_of(item, struct fi_ibv_rdm_request, queue_entry);
-
-	const struct fi_ibv_rdm_minfo *minfo = info;
-
-	return	(
-			((minfo->conn == NULL) ||
-			(request->minfo.conn == minfo->conn))
-			&&
-			(minfo->is_tagged ?
-			((request->minfo.tag & minfo->tagmask) ==
-			(minfo->tag          & minfo->tagmask)) :
-			(request->minfo.is_tagged == minfo->is_tagged))
-		);
-}
-
-/*
- * The same as fi_ibv_rdm_tagged_req_match_by_info2 but context field is added  
- * to compare
- */
-int fi_ibv_rdm_req_match_by_info3(struct dlist_entry *item, const void *info)
-{
-	struct fi_ibv_rdm_request *request =
-		container_of(item, struct fi_ibv_rdm_request, queue_entry);
-
-	const struct fi_ibv_rdm_tagged_peek_data *peek_data = info;
-	const void *context = (peek_data->flags & FI_CLAIM) ?
-		peek_data->context : NULL;
-
-	return ((request->context == context) && 
-		fi_ibv_rdm_req_match_by_info2(item, &peek_data->minfo));
-}
-
-int fi_ibv_rdm_postponed_process(struct dlist_entry *postponed_item,
-				 const void *arg)
-{
-	const struct fi_ibv_rdm_tagged_send_ready_data *send_data = arg;
-
-	struct fi_ibv_rdm_postponed_entry *postponed_entry =
-	    container_of(postponed_item,
-			 struct fi_ibv_rdm_postponed_entry, queue_entry);
-	int ret = 0;
-	if (!dlist_empty(&postponed_entry->conn->postponed_requests_head)) {
-		struct dlist_entry *req_entry = 
-			postponed_entry->conn->postponed_requests_head.next;
-
-		struct fi_ibv_rdm_request *request =
-			container_of(req_entry, struct fi_ibv_rdm_request,
-				     queue_entry);
-
-		int res = 0;
-		if ((request->state.eager < FI_IBV_STATE_EAGER_RMA_INJECT) &&
-		    (request->sbuf == NULL)) {
-			res = fi_ibv_rdm_tagged_prepare_send_request(request,
-								 send_data->ep);
-		} else  {
-			/*
-			 * This case is possible only for segmented RNDV msg or 
-			 * RMA operation (> 1GB), connection must be already 
-			 * established
-			 */
-			assert(request->state.rndv != FI_IBV_STATE_RNDV_NOT_USED);
-			assert(fi_ibv_rdm_check_connection(request->minfo.conn));
-			if (request->state.eager <= FI_IBV_STATE_EAGER_RECV_END) {
-				res = !TSEND_RESOURCES_IS_BUSY(request->minfo.conn,
-							      send_data->ep);
-			} else {
-				res = !RMA_RESOURCES_IS_BUSY(request->minfo.conn,
-							      send_data->ep);
-			}
-		}
-
-		if (res) {
-			fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_POST_READY,
-					    (void *) send_data);
-			ret++;
-		}
-	}
-	return ret;
-}
-
-void fi_ibv_rdm_conn_init_cm_role(struct fi_ibv_rdm_conn *conn,
-				  struct fi_ibv_rdm_ep *ep)
-{
-	const int addr_cmp = memcmp(&conn->addr, &ep->my_addr,
-				    FI_IBV_RDM_DFLT_ADDRLEN);
-
-	if (addr_cmp < 0) {
-		conn->cm_role = FI_VERBS_CM_ACTIVE;
-	} else if (addr_cmp > 0) {
-		conn->cm_role = FI_VERBS_CM_PASSIVE;
-	} else {
-		conn->cm_role = FI_VERBS_CM_SELF;
-	}
-}
-
-void fi_ibv_rdm_clean_queues(struct fi_ibv_rdm_ep *ep)
-{
-	struct fi_ibv_rdm_request *request;
-	struct fi_ibv_rdm_multi_request *multi_request;
-
-	while ((request = fi_ibv_rdm_take_first_from_unexp_queue(ep))) {
-		if (request->unexp_rbuf) {
-			util_buf_release(ep->fi_ibv_rdm_extra_buffers_pool,
-					 request->unexp_rbuf);
-		}
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(ep->fi_ibv_rdm_request_pool, request);
-	}
-
-	while ((multi_request = fi_ibv_rdm_take_first_from_multi_recv_list(ep)))
-		util_buf_release(ep->fi_ibv_rdm_multi_request_pool, multi_request);
-
-	while ((request = fi_ibv_rdm_take_first_from_posted_queue(ep))) {
- 		/* Check `request->context->internal[0] == NULL` in fi_cancel
-		 * will handle the case that request was already canceled
-		 * internally by provider */
-		request->context->internal[0] = NULL;
-		if (request->iov_count > 0) {
-			util_buf_release(ep->fi_ibv_rdm_extra_buffers_pool,
-					 request->unexp_rbuf);
-		}
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(ep->fi_ibv_rdm_request_pool, request);
-	}
-
-	while ((request = fi_ibv_rdm_take_first_from_postponed_queue(ep))) {
-		if (request->iov_count > 0) {
-			util_buf_release(ep->fi_ibv_rdm_extra_buffers_pool,
-					 request->unexp_rbuf);
-		}
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(ep->fi_ibv_rdm_request_pool, request);
-	}
-
-	while ((request = fi_ibv_rdm_take_first_from_cq(ep->fi_scq))) {
-		if (request->iov_count > 0) {
-			util_buf_release(ep->fi_ibv_rdm_extra_buffers_pool,
-					 request->unexp_rbuf);
-		}
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(ep->fi_ibv_rdm_request_pool, request);
-	}
-
-	while ((request = fi_ibv_rdm_take_first_from_cq(ep->fi_rcq))) {
-		if (request->iov_count > 0) {
-			util_buf_release(ep->fi_ibv_rdm_extra_buffers_pool,
-					 request->unexp_rbuf);
-		}
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(ep->fi_ibv_rdm_request_pool, request);
-	}
-
-	while ((request = fi_ibv_rdm_take_first_from_errcq(ep->fi_scq))) {
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(ep->fi_ibv_rdm_request_pool, request);
-	}
-
-	while ((request = fi_ibv_rdm_take_first_from_errcq(ep->fi_rcq))) {
-		FI_IBV_RDM_DBG_REQUEST("to_pool: ", request, FI_LOG_DEBUG);
-		util_buf_release(ep->fi_ibv_rdm_request_pool, request);
-	}
-}
-
-ssize_t
-fi_ibv_rdm_send_common(struct fi_ibv_rdm_send_start_data* sdata)
-{
-	struct fi_ibv_rdm_request *request =
-		util_buf_alloc(sdata->ep_rdm->fi_ibv_rdm_request_pool);
-	if (OFI_UNLIKELY(!request))
-		return -FI_EAGAIN;
-	request->ep = sdata->ep_rdm;
-	FI_IBV_RDM_DBG_REQUEST("get_from_pool: ", request, FI_LOG_DEBUG);
-
-	/* Initial state */
-	request->state.eager = FI_IBV_STATE_EAGER_BEGIN;
-	request->state.rndv  = FI_IBV_STATE_RNDV_NOT_USED;
-	request->state.err   = FI_SUCCESS;
-
-	/* postponed_entry means that there are elements postponed to
-	 * send & current request must be queued */
-	const int in_order = (sdata->conn->postponed_entry) ? 0 : 1;
-	int ret = fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_SEND_START, sdata);
-
-	if (!ret && in_order &&
-	    fi_ibv_rdm_tagged_prepare_send_request(request, sdata->ep_rdm)) {
-		struct fi_ibv_rdm_tagged_send_ready_data req_data = 
-			{ .ep = sdata->ep_rdm };
-		ret = fi_ibv_rdm_req_hndl(request, FI_IBV_EVENT_POST_READY,
-					  &req_data);
-	}
-
-	return ret;
-}
-
-ssize_t
-rdm_trecv_second_event(struct fi_ibv_rdm_request *request, 
-			struct fi_ibv_rdm_ep *ep)
-{
-	ssize_t ret = FI_SUCCESS;
-
-	switch (request->state.rndv)
-	{
-	case FI_IBV_STATE_RNDV_NOT_USED:
-		if (request->state.eager != FI_IBV_STATE_EAGER_RECV_WAIT4PKT) {
-			struct fi_ibv_recv_got_pkt_process_data data = {
-				.ep = ep
-			};
-			ret = fi_ibv_rdm_req_hndl(request,
-						  FI_IBV_EVENT_RECV_START,
-						  &data);
-		}
-		break;
-	case FI_IBV_STATE_RNDV_RECV_WAIT4RES:
-		if (fi_ibv_rdm_tagged_prepare_send_request(request, ep)) {
-			struct fi_ibv_rdm_tagged_send_ready_data data = {
-				.ep = ep
-			};
-			ret = fi_ibv_rdm_req_hndl(request,
-						  FI_IBV_EVENT_POST_READY,
-						  &data);
-		}
-		break;
-	default:
-		break;
-	}
-
-	return ret;
-}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_utils.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_utils.h
deleted file mode 100644
index 7a3aeeb34..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ep_rdm/verbs_utils.h
+++ /dev/null
@@ -1,192 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- * Copyright (c) 2016 Cisco Systems, Inc. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#ifndef _VERBS_UTILS_H
-#define _VERBS_UTILS_H
-
-#include <alloca.h>
-#include <malloc.h>
-#include <stddef.h>
-#include <inttypes.h>
-#include <string.h>
-#include <sys/types.h>
-
-#include <infiniband/verbs.h>
-
-#include "../fi_verbs.h"
-
-#if (defined(__ICC) || defined(__INTEL_COMPILER) ||	\
- defined(__GNUC__) || defined(__GNUG__)) &&		\
- defined(__x86_64__)
-#include "xmmintrin.h"
-#define FI_IBV_PREFETCH_ADDR(_addr) {                    \
-        _mm_prefetch((const char *)(_addr), _MM_HINT_T0);\
-}
-#else /* ICC || GCC && x86_64 */
-#define FI_IBV_PREFETCH_ADDR(_addr)
-#endif /* ICC || GCC && x86_64 */
-
-/* TODO: Merge anything useful into verbs_rdm.h */
-
-struct fi_ibv_msg_ep;
-
-#define FI_IBV_RDM_DFLT_ADDRLEN	(sizeof (struct sockaddr_in))
-
-#define FI_IBV_RDM_CM_THREAD_TIMEOUT (100)
-
-#define FI_IBV_RDM_TAGGED_DFLT_BUFFER_NUM (8)
-#define FI_IBV_RDM_DFLT_CQREAD_BUNCH_SIZE (FI_IBV_RDM_TAGGED_DFLT_BUFFER_NUM)
-
-#define FI_IBV_RDM_DFLT_BUFFER_SIZE					\
-	(3 * FI_IBV_BUF_ALIGNMENT)
-
-#define FI_IBV_RDM_DFLT_BUFFERED_SIZE					\
-	(FI_IBV_RDM_DFLT_BUFFER_SIZE -					\
-	 FI_IBV_RDM_BUFF_SERVICE_DATA_SIZE -				\
-	 sizeof(struct fi_ibv_rdm_header))
-
-/*
- * calculates internal buffer size from user defined buffered send size in
- * consideration of wired protocols, alignment, etc
- */
-size_t rdm_buffer_size(size_t buf_send_size);
-
-#ifdef HAVE_VERBS_EXP_H
-/* 128MB is ODP MR limitation */
-#define FI_IBV_RDM_SEG_MAXSIZE (128*1024*1024)
-#else /* HAVE_VERBS_EXP_H */
-/* 1GB is RC_QP limitation */
-#define FI_IBV_RDM_SEG_MAXSIZE (1024*1024*1024)
-#endif /* HAVE_VERBS_EXP_H */
-
-/* TODO: CQs depths increased from 100 to 1000 to prevent
- *      "Work Request Flushed Error" in stress tests like alltoall.
- */
-#define FI_IBV_RDM_TAGGED_DFLT_SCQ_SIZE (1000)
-#define FI_IBV_RDM_TAGGED_DFLT_RCQ_SIZE (1000)
-
-#define FI_IBV_RDM_CM_RESOLVEADDR_TIMEOUT (30000)
-
-#if ENABLE_DEBUG
-#define FI_IBV_RDM_CHECK_RECV_WC(wc)						\
-	((wc->status == IBV_WC_SUCCESS) &&					\
-	(wc->opcode == IBV_WC_RECV_RDMA_WITH_IMM || wc->opcode == IBV_WC_RECV))
-#else
-#define FI_IBV_RDM_CHECK_RECV_WC(wc) (wc->status == IBV_WC_SUCCESS)
-#endif /* ENABLE_DEBUG */
-
-/* TODO: Holy macro batman, use verbs calls */
-#define FI_IBV_DBG_OPCODE(wc_opcode, str)                                      \
-        VERBS_DBG(FI_LOG_CQ, "CQ COMPL: "str" -> %s\n",                        \
-        wc_opcode == IBV_WC_SEND       ? "IBV_WC_SEND"       :                 \
-        wc_opcode == IBV_WC_RDMA_WRITE ? "IBV_WC_RDMA_WRITE" :                 \
-        wc_opcode == IBV_WC_RDMA_READ  ? "IBV_WC_RDMA_READ"  :                 \
-        wc_opcode == IBV_WC_COMP_SWAP  ? "IBV_WC_COMP_SWAP"  :                 \
-        wc_opcode == IBV_WC_FETCH_ADD  ? "IBV_WC_FETCH_ADD"  :                 \
-        wc_opcode == IBV_WC_BIND_MW    ? "IBV_WC_BIND_MW"    :                 \
-        wc_opcode == IBV_WC_RECV       ? "IBV_WC_RECV"       :                 \
-        wc_opcode == IBV_WC_RECV_RDMA_WITH_IMM ? "IBV_WC_RECV_RDMA_WITH_IMM" : \
-        "IBV_WC_UNKNOWN!!!");
-
-#if ENABLE_DEBUG
-
-#define FI_IBV_RDM_DBG_REQUEST(prefix, request, level)				\
-do {										\
-	const size_t max_str_len = 1024;					\
-	char str[max_str_len];							\
-	snprintf(str, max_str_len,						\
-		 "%s request: %p, eager_state: %s, rndv_state: %s,"		\
-		 " err_state: %ld, tag: 0x%lx, len: %lu, rest: %lu,"		\
-		 "context: %p, connection: %p ep: %p\n",			\
-		 prefix,							\
-		 request,							\
-		 fi_ibv_rdm_req_eager_state_to_str(request->state.eager),	\
-		 fi_ibv_rdm_req_rndv_state_to_str(request->state.rndv),		\
-		 request->state.err,						\
-		 request->minfo.tag,						\
-		 request->len,							\
-		 request->rest_len,						\
-		 request->context,						\
-		 request->minfo.conn,						\
-		 request->ep);							\
-										\
-	switch (level)								\
-	{									\
-	case FI_LOG_WARN:							\
-	case FI_LOG_TRACE:							\
-	case FI_LOG_INFO:							\
-		VERBS_INFO(FI_LOG_EP_DATA, "%s", str);				\
-		break;								\
-	case FI_LOG_DEBUG:							\
-	default:								\
-		VERBS_DBG(FI_LOG_EP_DATA, "%s", str);				\
-		break;								\
-	}									\
-} while (0);
-
-#else                           // ENABLE_DEBUG
-
-#define FI_IBV_RDM_DBG_REQUEST(prefix, request, level)
-
-#endif                          // ENABLE_DEBUG
-
-struct fi_ibv_rdm_minfo {
-	struct fi_ibv_rdm_conn	*conn;
-	uint64_t		is_tagged; /* TODO: unexpected RTS for MSG */
-	uint64_t		tag;
-	uint64_t		tagmask;
-};
-
-struct fi_ibv_rdm_tagged_peek_data {
-	struct fi_ibv_rdm_minfo minfo;
-	void *context;
-	uint64_t flags;
-};
-
-struct fi_ibv_rdm_cm;
-struct fi_ibv_rdm_request;
-struct fi_ibv_rdm_send_start_data;
-
-int fi_ibv_rdm_req_match(struct dlist_entry *item, const void *other);
-int fi_ibv_rdm_req_match_by_info(struct dlist_entry *item, const void *info);
-int fi_ibv_rdm_req_match_by_info2(struct dlist_entry *item, const void *info);
-int fi_ibv_rdm_req_match_by_info3(struct dlist_entry *item, const void *info);
-int fi_ibv_rdm_postponed_process(struct dlist_entry *item, const void *arg);
-void fi_ibv_rdm_conn_init_cm_role(struct fi_ibv_rdm_conn *conn,
-				  struct fi_ibv_rdm_ep *ep);
-
-ssize_t fi_ibv_rdm_send_common(struct fi_ibv_rdm_send_start_data* sdata);
-ssize_t rdm_trecv_second_event(struct fi_ibv_rdm_request *request,
-			       struct fi_ibv_rdm_ep *ep);
-
-#endif /* _VERBS_UTILS_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/fi_verbs.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/fi_verbs.c
index cd8b85945..39182bcf2 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/fi_verbs.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/fi_verbs.c
@@ -35,7 +35,6 @@
 #include <ofi_mem.h>
 
 #include "fi_verbs.h"
-#include "ep_rdm/verbs_rdm.h"
 
 static void fi_ibv_fini(void);
 
@@ -61,26 +60,33 @@ struct fi_ibv_gl_data fi_ibv_gl_data = {
 	.mr_max_cached_cnt	= 4096,
 	.mr_max_cached_size	= ULONG_MAX,
 	.mr_cache_merge_regions	= 0,
-
-	.rdm			= {
-		.buffer_num		= FI_IBV_RDM_TAGGED_DFLT_BUFFER_NUM,
-		.buffer_size		= FI_IBV_RDM_DFLT_BUFFERED_SIZE,
-		.rndv_seg_size		= FI_IBV_RDM_SEG_MAXSIZE,
-		.thread_timeout		= FI_IBV_RDM_CM_THREAD_TIMEOUT,
-		.eager_send_opcode	= "IBV_WR_SEND",
-		.cm_thread_affinity	= NULL,
-	},
-
 	.dgram			= {
 		.use_name_server	= 1,
 		.name_server_port	= 5678,
 	},
+
+	.msg			= {
+		/* Disabled by default. Use XRC transport for message
+		 * endpoint only if it is explicitly requested */
+		.prefer_xrc		= 0,
+		.xrcd_filename		= "/tmp/verbs_xrcd",
+	},
+};
+
+struct fi_ibv_dev_preset {
+	int		max_inline_data;
+	const char	*dev_name_prefix;
+} verbs_dev_presets[] = {
+	{
+		.max_inline_data = 48,
+		.dev_name_prefix = "i40iw",
+	},
 };
 
 struct fi_provider fi_ibv_prov = {
 	.name = VERBS_PROV_NAME,
 	.version = VERBS_PROV_VERS,
-	.fi_version = FI_VERSION(1, 6),
+	.fi_version = FI_VERSION(1, 7),
 	.getinfo = fi_ibv_getinfo,
 	.fabric = fi_ibv_fabric,
 	.cleanup = fi_ibv_fini
@@ -102,50 +108,6 @@ int fi_ibv_sockaddr_len(struct sockaddr *addr)
 		return ofi_sizeofaddr(addr);
 }
 
-int fi_ibv_rdm_cm_bind_ep(struct fi_ibv_rdm_cm *cm, struct fi_ibv_rdm_ep *ep)
-{
-	char my_ipoib_addr_str[INET6_ADDRSTRLEN];
-
-	assert(cm->ec && cm->listener);
-
-	if (ep->info->src_addr) {
-		memcpy(&ep->my_addr, ep->info->src_addr, sizeof(ep->my_addr));
-
-		inet_ntop(ep->my_addr.sin_family,
-			  &ep->my_addr.sin_addr.s_addr,
-			  my_ipoib_addr_str, INET_ADDRSTRLEN);
-	} else {
-		strcpy(my_ipoib_addr_str, "undefined");
-	}
-
-	VERBS_INFO(FI_LOG_EP_CTRL, "My IPoIB: %s\n", my_ipoib_addr_str);
-
-	if (!cm->is_bound) {
-		if (rdma_bind_addr(cm->listener, (struct sockaddr *)&ep->my_addr)) {
-			VERBS_INFO(FI_LOG_EP_CTRL,
-				"Failed to bind cm listener to my IPoIB addr %s: %s\n",
-				my_ipoib_addr_str, strerror(errno));
-			return -FI_EOTHER;
-		}
-		if (rdma_listen(cm->listener, 1024)) {
-			VERBS_INFO(FI_LOG_EP_CTRL, "rdma_listen failed: %s\n",
-				strerror(errno));
-			return -FI_EOTHER;
-		}
-		cm->is_bound = 1;
-	}
-
-	if (!ep->my_addr.sin_port) {
-		ep->my_addr.sin_port = rdma_get_src_port(cm->listener);
-	}
-	assert(ep->my_addr.sin_family == AF_INET);
-
-	VERBS_INFO(FI_LOG_EP_CTRL, "My ep_addr: %s:%u\n",
-		inet_ntoa(ep->my_addr.sin_addr), ntohs(ep->my_addr.sin_port));
-
-	return FI_SUCCESS;
-}
-
 int fi_ibv_get_rdma_rai(const char *node, const char *service, uint64_t flags,
 		   const struct fi_info *hints, struct rdma_addrinfo **rai)
 {
@@ -157,11 +119,8 @@ int fi_ibv_get_rdma_rai(const char *node, const char *service, uint64_t flags,
 		goto out;
 
 	if (!node && !rai_hints.ai_dst_addr) {
-		if ((!rai_hints.ai_src_addr && !service) ||
-		    (!rai_hints.ai_src_addr && FI_IBV_EP_TYPE_IS_RDM(hints)))
-		{
+		if (!rai_hints.ai_src_addr && !service)
 			node = local_node;
-		}
 		rai_hints.ai_flags |= RAI_PASSIVE;
 	}
 
@@ -204,6 +163,50 @@ out:
 	return ret;
 }
 
+int fi_ibv_get_rai_id(const char *node, const char *service, uint64_t flags,
+		      const struct fi_info *hints, struct rdma_addrinfo **rai,
+		      struct rdma_cm_id **id)
+{
+	int ret;
+
+	// TODO create a similar function that won't require pruning ib_rai
+	ret = fi_ibv_get_rdma_rai(node, service, flags, hints, rai);
+	if (ret)
+		return ret;
+
+	ret = rdma_create_id(NULL, id, NULL, RDMA_PS_TCP);
+	if (ret) {
+		VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_create_id", errno);
+		ret = -errno;
+		goto err1;
+	}
+
+	if ((*rai)->ai_flags & RAI_PASSIVE) {
+		ret = rdma_bind_addr(*id, (*rai)->ai_src_addr);
+		if (ret) {
+			VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_bind_addr", errno);
+			ret = -errno;
+			goto err2;
+		}
+		return 0;
+	}
+
+	ret = rdma_resolve_addr(*id, (*rai)->ai_src_addr,
+				(*rai)->ai_dst_addr, 2000);
+	if (ret) {
+		VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_resolve_addr", errno);
+		ret = -errno;
+		goto err2;
+	}
+	return 0;
+err2:
+	if (rdma_destroy_id(*id))
+		VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_destroy_id", errno);
+err1:
+	rdma_freeaddrinfo(*rai);
+	return ret;
+}
+
 int fi_ibv_create_ep(const char *node, const char *service,
 		     uint64_t flags, const struct fi_info *hints,
 		     struct rdma_addrinfo **rai, struct rdma_cm_id **id)
@@ -359,23 +362,35 @@ int fi_ibv_set_rnr_timer(struct ibv_qp *qp)
 }
 
 int fi_ibv_find_max_inline(struct ibv_pd *pd, struct ibv_context *context,
-                           enum ibv_qp_type qp_type)
+			   enum ibv_qp_type qp_type)
 {
 	struct ibv_qp_init_attr qp_attr;
 	struct ibv_qp *qp = NULL;
-	struct ibv_cq *cq = ibv_create_cq(context, 1, NULL, NULL, 0);
-	assert(cq);
+	struct ibv_cq *cq;
 	int max_inline = 2;
 	int rst = 0;
+	const char *dev_name = ibv_get_device_name(context->device);
+	uint8_t i;
+
+	for (i = 0; i < count_of(verbs_dev_presets); i++) {
+		if (!strncmp(dev_name, verbs_dev_presets[i].dev_name_prefix,
+			     strlen(verbs_dev_presets[i].dev_name_prefix)))
+			return verbs_dev_presets[i].max_inline_data;
+	}
+
+	cq = ibv_create_cq(context, 1, NULL, NULL, 0);
+	assert(cq);
 
 	memset(&qp_attr, 0, sizeof(qp_attr));
 	qp_attr.send_cq = cq;
-	qp_attr.recv_cq = cq;
 	qp_attr.qp_type = qp_type;
 	qp_attr.cap.max_send_wr = 1;
-	qp_attr.cap.max_recv_wr = 1;
 	qp_attr.cap.max_send_sge = 1;
-	qp_attr.cap.max_recv_sge = 1;
+	if (!fi_ibv_is_xrc_send_qp(qp_type)) {
+		qp_attr.recv_cq = cq;
+		qp_attr.cap.max_recv_wr = 1;
+		qp_attr.cap.max_recv_sge = 1;
+	}
 	qp_attr.sq_sig_all = 1;
 
 	do {
@@ -575,6 +590,22 @@ static int fi_ibv_read_params(void)
 			   "Invalid value of use_odp\n");
 		return -FI_EINVAL;
 	}
+
+	if (fi_ibv_get_param_bool("prefer_xrc", "Order XRC transport fi_infos"
+				  "ahead of RC. Default orders RC first.",
+				  &fi_ibv_gl_data.msg.prefer_xrc)) {
+		VERBS_WARN(FI_LOG_CORE,
+			   "Invalid value of prefer_xrc\n");
+		return -FI_EINVAL;
+	}
+
+	if (fi_ibv_get_param_str("xrcd_filename", "A file to "
+				 "associate with the XRC domain.",
+				 &fi_ibv_gl_data.msg.xrcd_filename)) {
+		VERBS_WARN(FI_LOG_CORE,
+			   "Invalid value of xrcd_filename\n");
+		return -FI_EINVAL;
+	}
 	if (fi_ibv_get_param_int("cqread_bunch_size", "The number of entries to "
 				 "be read from the verbs completion queue at a time",
 				 &fi_ibv_gl_data.cqread_bunch_size) ||
@@ -621,61 +652,6 @@ static int fi_ibv_read_params(void)
 		return -FI_EINVAL;
 	}
 
-	/* RDM-specific parameters */
-	if (fi_ibv_get_param_int("rdm_buffer_num", "The number of pre-registered "
-				 "buffers for buffered operations between "
-				 "the endpoints, must be a power of 2",
-				 &fi_ibv_gl_data.rdm.buffer_num) ||
-	    (fi_ibv_gl_data.rdm.buffer_num & (fi_ibv_gl_data.rdm.buffer_num - 1))) {
-		VERBS_WARN(FI_LOG_CORE,
-			   "Invalid value of rdm_buffer_num\n");
-		return -FI_EINVAL;
-	}
-	if (fi_ibv_get_param_int("rdm_buffer_size", "The maximum size of a "
-				 "buffered operation (bytes)",
-				 &fi_ibv_gl_data.rdm.buffer_size) ||
-	    (fi_ibv_gl_data.rdm.buffer_size < sizeof(struct fi_ibv_rdm_rndv_header))) {
-		VERBS_WARN(FI_LOG_CORE,
-			   "rdm_buffer_size should be greater than %"PRIu64"\n",
-			   sizeof(struct fi_ibv_rdm_rndv_header));
-		return -FI_EINVAL;
-	}
-	if (fi_ibv_get_param_int("rdm_rndv_seg_size", "The segment size for "
-				 "zero copy protocols (bytes)",
-				 &fi_ibv_gl_data.rdm.rndv_seg_size) ||
-	    (fi_ibv_gl_data.rdm.rndv_seg_size <= 0)) {
-		VERBS_WARN(FI_LOG_CORE,
-			   "Invalid value of rdm_rndv_seg_size\n");
-		return -FI_EINVAL;
-	}
-	if (fi_ibv_get_param_int("rdm_thread_timeout", "The wake up timeout of "
-				 "the helper thread (usec)",
-				 &fi_ibv_gl_data.rdm.thread_timeout) ||
-	    (fi_ibv_gl_data.rdm.thread_timeout < 0)) {
-		VERBS_WARN(FI_LOG_CORE,
-			   "Invalid value of rdm_thread_timeout\n");
-		return -FI_EINVAL;
-	}
-	if (fi_ibv_get_param_str("rdm_eager_send_opcode", "The operation code that "
-				 "will be used for eager messaging. Only IBV_WR_SEND "
-				 "and IBV_WR_RDMA_WRITE_WITH_IMM are supported. "
-				 "The last one is not applicable for iWarp.",
-				 &fi_ibv_gl_data.rdm.eager_send_opcode)) {
-		VERBS_WARN(FI_LOG_CORE,
-			   "Invalid value of rdm_eager_send_opcode\n");
-		return -FI_EINVAL;
-	}
-	if (fi_ibv_get_param_str("rdm_cm_thread_affinity",
-				 "If specified, bind the CM thread to the indicated "
-				 "range(s) of Linux virtual processor ID(s). "
-				 "This option is currently not supported on OS X. "
-				 "Usage: id_start[-id_end[:stride]][,]",
-				 &fi_ibv_gl_data.rdm.cm_thread_affinity)) {
-		VERBS_WARN(FI_LOG_CORE,
-			   "Invalid thread affinity range provided in the rdm_cm_thread_affinity\n");
-		return -FI_EINVAL;
-	}
-
 	/* DGRAM-specific parameters */
 	if (getenv("OMPI_COMM_WORLD_RANK") || getenv("PMI_RANK"))
 		fi_ibv_gl_data.dgram.use_name_server = 0;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/fi_verbs.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/fi_verbs.h
index 9f5aac571..90d1f495f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/fi_verbs.h
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/fi_verbs.h
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
+ * Copyright (c) 2013-2018 Intel Corporation, Inc.  All rights reserved.
  * Copyright (c) 2016 Cisco Systems, Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
@@ -49,7 +49,6 @@
 #include <assert.h>
 #include <pthread.h>
 #include <sys/epoll.h>
-#include <malloc.h>
 
 #include <infiniband/ib.h>
 #include <infiniband/verbs.h>
@@ -70,11 +69,15 @@
 #include "ofi_list.h"
 #include "ofi_signal.h"
 #include "ofi_util.h"
+#include "ofi_tree.h"
+#include "ofi_indexer.h"
 
 #ifdef HAVE_VERBS_EXP_H
 #include <infiniband/verbs_exp.h>
 #endif /* HAVE_VERBS_EXP_H */
 
+#include "ofi_verbs_priv.h"
+
 #ifndef AF_IB
 #define AF_IB 27
 #endif
@@ -93,24 +96,37 @@
 #define VERBS_WARN(subsys, ...) FI_WARN(&fi_ibv_prov, subsys, __VA_ARGS__)
 
 
-#define VERBS_INJECT_FLAGS(ep, len, flags) (((flags & FI_INJECT) || \
-		len <= ep->info->tx_attr->inject_size) ? IBV_SEND_INLINE : 0)
-#define VERBS_INJECT(ep, len) VERBS_INJECT_FLAGS(ep, len, ep->info->tx_attr->op_flags)
+#define VERBS_INJECT_FLAGS(ep, len, flags) ((((flags) & FI_INJECT) || \
+		len <= (ep)->inject_limit) ? IBV_SEND_INLINE : 0)
+#define VERBS_INJECT(ep, len) VERBS_INJECT_FLAGS(ep, len, (ep)->info->tx_attr->op_flags)
 
-#define VERBS_SELECTIVE_COMP(ep) (ep->ep_flags & FI_SELECTIVE_COMPLETION)
-#define VERBS_COMP_FLAGS(ep, flags) (ofi_need_completion(ep->ep_flags, flags) ?	\
-				     IBV_SEND_SIGNALED : 0)
-#define VERBS_COMP(ep) VERBS_COMP_FLAGS(ep, ep->info->tx_attr->op_flags)
+#define VERBS_COMP_FLAGS(ep, flags, context)		\
+	(((ep)->util_ep.tx_op_flags | (flags)) &		\
+	 FI_COMPLETION ? context : VERBS_NO_COMP_FLAG)
+#define VERBS_COMP(ep, context)						\
+	VERBS_COMP_FLAGS((ep), (ep)->info->tx_attr->op_flags, context)
 
 #define VERBS_WCE_CNT 1024
 #define VERBS_WRE_CNT 1024
-#define VERBS_EPE_CNT 1024
 
 #define VERBS_DEF_CQ_SIZE 1024
 #define VERBS_MR_IOV_LIMIT 1
 
+#define VERBS_NO_COMP_FLAG	((uint64_t)-1)
+
+#define FI_IBV_CM_DATA_SIZE	(56)
+#define VERBS_CM_DATA_SIZE	(FI_IBV_CM_DATA_SIZE -		\
+				 sizeof(struct fi_ibv_cm_data_hdr))
+
+#define FI_IBV_CM_REJ_CONSUMER_DEFINED	28
+
+#define VERBS_DGRAM_MSG_PREFIX_SIZE	(40)
+
 #define FI_IBV_EP_TYPE(info)						\
 	((info && info->ep_attr) ? info->ep_attr->type : FI_EP_MSG)
+#define FI_IBV_EP_PROTO(info)						\
+	(((info) && (info)->ep_attr) ? (info)->ep_attr->protocol :	\
+					FI_PROTO_UNSPEC)
 
 #define FI_IBV_MEM_ALIGNMENT (64)
 #define FI_IBV_BUF_ALIGNMENT (4096) /* TODO: Page or MTU size */
@@ -119,54 +135,16 @@
 #define VERBS_ANY_DOMAIN "verbs_any_domain"
 #define VERBS_ANY_FABRIC "verbs_any_fabric"
 
-/* NOTE:
- * When ibv_post_send/recv returns '-1' it means the following:
- * Deal with non-compliant libibverbs drivers which set errno
- * instead of directly returning the error value
- */
-#define FI_IBV_INVOKE_POST(type, wr_type, obj, wr, fail_action)		\
-({									\
-	ssize_t ret;							\
-	struct ibv_ ## wr_type ## _wr *bad_wr;				\
-	ret = ibv_post_ ## type(obj, wr, &bad_wr);			\
-	if (OFI_UNLIKELY(ret)) {					\
-		switch (ret) {						\
-			case ENOMEM:					\
-				ret = -FI_EAGAIN;			\
-				break;					\
-			case -1:					\
-				ret = (errno == ENOMEM) ? -FI_EAGAIN :	\
-							  -errno;	\
-				break;					\
-			default:					\
-				ret = -ret;				\
-				break;					\
-		}							\
-		(void) fail_action;					\
-	}								\
-	ret;								\
-})
+#define FI_IBV_MEMORY_HOOK_BEGIN(notifier)			\
+{								\
+	pthread_mutex_lock(&notifier->lock);			\
+	ofi_set_mem_free_hook(notifier->prev_free_hook);	\
+	ofi_set_mem_realloc_hook(notifier->prev_realloc_hook);	\
 
-#define FI_IBV_RELEASE_WRE(ep, wre)			\
-({							\
-	if (wre) {					\
-		fastlock_acquire(&ep->wre_lock);	\
-		dlist_remove(&wre->entry);		\
-		util_buf_release(ep->wre_pool, wre);	\
-		fastlock_release(&ep->wre_lock);	\
-	}						\
-})
-
-#define FI_IBV_MEMORY_HOOK_BEGIN(notifier)					\
-{										\
-	pthread_mutex_lock(&notifier->lock);					\
-	fi_ibv_mem_notifier_set_free_hook(notifier->prev_free_hook);		\
-	fi_ibv_mem_notifier_set_realloc_hook(notifier->prev_realloc_hook);	\
-
-#define FI_IBV_MEMORY_HOOK_END(notifier)					\
-	fi_ibv_mem_notifier_set_realloc_hook(fi_ibv_mem_notifier_realloc_hook);	\
-	fi_ibv_mem_notifier_set_free_hook(fi_ibv_mem_notifier_free_hook);	\
-	pthread_mutex_unlock(&notifier->lock);					\
+#define FI_IBV_MEMORY_HOOK_END(notifier)				\
+	ofi_set_mem_realloc_hook(fi_ibv_mem_notifier_realloc_hook);	\
+	ofi_set_mem_free_hook(fi_ibv_mem_notifier_free_hook);		\
+	pthread_mutex_unlock(&notifier->lock);				\
 }
 
 extern struct fi_provider fi_ibv_prov;
@@ -201,6 +179,11 @@ extern struct fi_ibv_gl_data {
 		int	use_name_server;
 		int	name_server_port;
 	} dgram;
+
+	struct {
+		int	prefer_xrc;
+		char	*xrcd_filename;
+	} msg;
 } fi_ibv_gl_data;
 
 struct verbs_addr {
@@ -217,7 +200,7 @@ struct verbs_addr {
  * - GRH (Global Route Header) - Network Layer:
  *   - GID - destination Global Identifier
  * - BTH (Base Transport Header) - Transport Layer:
- *   - QPN - destination Queue Oair number
+ *   - QPN - destination Queue Pair number
  *   - P_key - Partition Key
  *
  * Note: DON'T change the placement of the fields in the structure.
@@ -261,6 +244,7 @@ struct verbs_dev_info {
 	struct dlist_entry addrs;
 };
 
+
 struct fi_ibv_fabric {
 	struct util_fabric	util_fabric;
 	const struct fi_info	*info;
@@ -280,6 +264,11 @@ struct fi_ibv_eq_entry {
 
 typedef int (*fi_ibv_trywait_func)(struct fid *fid);
 
+/* The number of valid OFI indexer bits in the connection key used during
+ * XRC connection establishment. Note that only the lower 32-bits of the
+ * key are exchanged, so this value must be kept below 32-bits. */
+#define VERBS_TAG_INDEX_BITS	18
+
 struct fi_ibv_eq {
 	struct fid_eq		eq_fid;
 	struct fi_ibv_fabric	*fab;
@@ -289,47 +278,28 @@ struct fi_ibv_eq {
 	uint64_t		flags;
 	struct fi_eq_err_entry	err;
 	int			epfd;
+
+	struct {
+		/* The connection key map is used during the XRC connection
+		 * process to map an XRC reciprocal connection request back
+		 * to the active endpoint that initiated the original
+		 * connection request. It is protected with the eq::lock */
+		struct ofi_key_idx	conn_key_idx;
+		struct indexer		*conn_key_map;
+
+		/* TODO: This is limiting and restricts applications to using
+		 * a single listener per EQ. While sufficient for RXM we should
+		 * consider using an internal PEP listener for handling the
+		 * internally processed reciprocal connections. */
+		uint16_t		pep_port;
+	} xrc;
 };
 
 int fi_ibv_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
 		   struct fid_eq **eq, void *context);
 
-struct fi_ibv_rdm_ep;
-
-typedef struct fi_ibv_rdm_conn *
-	(*fi_ibv_rdm_addr_to_conn_func)
-	(struct fi_ibv_rdm_ep *ep, fi_addr_t addr);
-
-typedef fi_addr_t
-	(*fi_ibv_rdm_conn_to_addr_func)
-	(struct fi_ibv_rdm_ep *ep, struct fi_ibv_rdm_conn *conn);
-
-typedef struct fi_ibv_rdm_av_entry *
-	(*fi_ibv_rdm_addr_to_av_entry_func)
-	(struct fi_ibv_rdm_ep *ep, fi_addr_t addr);
-
-typedef fi_addr_t
-	(*fi_ibv_rdm_av_entry_to_addr_func)
-	(struct fi_ibv_rdm_ep *ep, struct fi_ibv_rdm_av_entry *av_entry);
-
-struct fi_ibv_av {
-	struct fid_av		av_fid;
-	struct fi_ibv_domain	*domain;
-	struct fi_ibv_rdm_ep	*ep;
-	struct fi_ibv_eq	*eq;
-	size_t			count;
-	size_t			used;
-	uint64_t		flags;
-	enum fi_av_type		type;
-	fi_ibv_rdm_addr_to_conn_func addr_to_conn;
-	fi_ibv_rdm_conn_to_addr_func conn_to_addr;
-	fi_ibv_rdm_addr_to_av_entry_func addr_to_av_entry;
-	fi_ibv_rdm_av_entry_to_addr_func av_entry_to_addr;
-};
-
 int fi_ibv_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 		   struct fid_av **av, void *context);
-struct fi_ops_av *fi_ibv_rdm_set_av_ops(void);
 
 struct fi_ibv_pep {
 	struct fid_pep		pep_fid;
@@ -342,36 +312,41 @@ struct fi_ibv_pep {
 };
 
 struct fi_ops_cm *fi_ibv_pep_ops_cm(struct fi_ibv_pep *pep);
-struct fi_ibv_rdm_cm;
 
 struct fi_ibv_mem_desc;
+struct fi_ibv_domain;
 typedef int(*fi_ibv_mr_reg_cb)(struct fi_ibv_domain *domain, void *buf,
 			       size_t len, uint64_t access,
 			       struct fi_ibv_mem_desc *md);
 typedef int(*fi_ibv_mr_dereg_cb)(struct fi_ibv_mem_desc *md);
 
-void fi_ibv_mem_notifier_free_hook(void *ptr, const void *caller);
-void *fi_ibv_mem_notifier_realloc_hook(void *ptr, size_t size, const void *caller);
-
 struct fi_ibv_mem_notifier;
 
 struct fi_ibv_domain {
 	struct util_domain		util_domain;
 	struct ibv_context		*verbs;
 	struct ibv_pd			*pd;
-	/*
-	 * TODO: Currently, only 1 rdm EP can be created per rdm domain!
-	 *	 CM logic should be separated from EP,
-	 *	 excluding naming/addressing
-	 */
+
 	enum fi_ep_type			ep_type;
-	struct fi_ibv_rdm_cm		*rdm_cm;
-	struct slist			ep_list;
 	struct fi_info			*info;
-	/* This EQ is utilized by verbs/RDM and verbs/DGRAM */
+	/* The EQ is utilized by verbs/MSG */
 	struct fi_ibv_eq		*eq;
 	uint64_t			eq_flags;
 
+	/* Indicates that MSG endpoints should use the XRC transport.
+	 * TODO: Move selection of XRC/RC to endpoint info from domain */
+	int				use_xrc;
+	struct {
+		int			xrcd_fd;
+		struct ibv_xrcd		*xrcd;
+
+		/* The domain maintains a RBTree for mapping an endpoint
+		 * destination addresses to physical XRC INI QP connected
+		 * to that host. */
+		fastlock_t		ini_mgmt_lock;
+		struct ofi_rbmap	*ini_conn_rbmap;
+	} xrc ;
+
 	/* MR stuff */
 	int				use_odp;
 	struct ofi_mr_cache		cache;
@@ -382,29 +357,16 @@ struct fi_ibv_domain {
 };
 
 struct fi_ibv_cq;
-typedef void (*fi_ibv_cq_read_entry)(struct ibv_wc *wc, int index, void *buf);
+typedef void (*fi_ibv_cq_read_entry)(struct ibv_wc *wc, void *buf);
 
 struct fi_ibv_wce {
 	struct slist_entry	entry;
 	struct ibv_wc		wc;
 };
 
-enum fi_ibv_wre_type {
-	IBV_SEND_WR,
-	IBV_RECV_WR,
-};
-
-struct fi_ibv_wre {
-	struct dlist_entry      entry;
-	void			*context;
-	struct fi_ibv_msg_ep	*ep;
-	struct fi_ibv_srq_ep	*srq;
-	enum fi_ibv_wre_type	wr_type;
-};
-
+struct fi_ibv_srq_ep;
 struct fi_ibv_cq {
-	struct fid_cq		cq_fid;
-	struct fi_ibv_domain	*domain;
+	struct util_cq		util_cq;
 	struct ibv_comp_channel	*channel;
 	struct ibv_cq		*cq;
 	size_t			entry_size;
@@ -414,32 +376,15 @@ struct fi_ibv_cq {
 	int			signal_fd[2];
 	fi_ibv_cq_read_entry	read_entry;
 	struct slist		wcq;
-	fastlock_t		lock;
-	struct slist		ep_list;
-	uint64_t		ep_cnt;
-	uint64_t		send_signal_wr_id;
-	uint64_t		wr_id_mask;
 	fi_ibv_trywait_func	trywait;
 	ofi_atomic32_t		nevents;
-	struct util_buf_pool	*epe_pool;
 	struct util_buf_pool	*wce_pool;
-};
 
-struct fi_ibv_rdm_request;
-typedef void (*fi_ibv_rdm_cq_read_entry)(struct fi_ibv_rdm_request *cq_entry,
-					 int index, void *buf);
-
-struct fi_ibv_rdm_cq {
-	struct fid_cq			cq_fid;
-	struct fi_ibv_domain		*domain;
-	struct fi_ibv_rdm_ep		*ep;
-	struct dlist_entry		request_cq;
-	struct dlist_entry		request_errcq;
-	uint64_t			flags;
-	size_t				entry_size;
-	fi_ibv_rdm_cq_read_entry	read_entry;
-	int				read_bunch_size;
-	enum fi_cq_wait_cond		wait_cond;
+	struct {
+		/* The list of XRC SRQ contexts associated with this CQ */
+		fastlock_t		srq_list_lock;
+		struct dlist_entry	srq_list;
+	} xrc;
 };
 
 int fi_ibv_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
@@ -454,12 +399,6 @@ struct fi_ibv_mem_desc {
 	struct ofi_mr_entry	*entry;
 };
 
-int fi_ibv_rdm_alloc_and_reg(struct fi_ibv_rdm_ep *ep,
-			     void **buf, size_t size,
-			     struct fi_ibv_mem_desc *md);
-ssize_t fi_ibv_rdm_dereg_and_free(struct fi_ibv_mem_desc *md,
-				  char **buff);
-
 static inline uint64_t
 fi_ibv_mr_internal_rkey(struct fi_ibv_mem_desc *md)
 {
@@ -472,32 +411,33 @@ fi_ibv_mr_internal_lkey(struct fi_ibv_mem_desc *md)
 	return md->mr->lkey;
 }
 
-typedef void (*fi_ibv_mem_free_hook)(void *, const void *);
-typedef void *(*fi_ibv_mem_realloc_hook)(void *, size_t, const void *);
-
 struct fi_ibv_mr_internal_ops {
 	struct fi_ops_mr	*fi_ops;
 	fi_ibv_mr_reg_cb	internal_mr_reg;
 	fi_ibv_mr_dereg_cb	internal_mr_dereg;
 };
 
-struct fi_ibv_mem_ptr_entry {
-	struct dlist_entry	entry;
-	void			*addr;
-	struct ofi_subscription *subscription;
-	UT_hash_handle		hh;
-};
-
 struct fi_ibv_mem_notifier {
-	struct fi_ibv_mem_ptr_entry	*mem_ptrs_hash;
-	struct util_buf_pool		*mem_ptrs_ent_pool;
-	struct dlist_entry		event_list;
-	fi_ibv_mem_free_hook		prev_free_hook;
-	fi_ibv_mem_realloc_hook		prev_realloc_hook;
+	RbtHandle			subscr_storage;
+	ofi_mem_free_hook		prev_free_hook;
+	ofi_mem_realloc_hook		prev_realloc_hook;
 	int				ref_cnt;
 	pthread_mutex_t			lock;
 };
 
+struct fi_ibv_subscr_entry {
+	struct dlist_entry	entry;
+	struct ofi_subscription	*subscription;
+};
+
+struct fi_ibv_monitor_entry {
+	struct dlist_entry	subscription_list;
+	struct iovec		iov;
+};
+
+void fi_ibv_mem_notifier_free_hook(void *ptr, const void *caller);
+void *fi_ibv_mem_notifier_realloc_hook(void *ptr, size_t size, const void *caller);
+
 extern struct fi_ibv_mr_internal_ops fi_ibv_mr_internal_ops;
 extern struct fi_ibv_mr_internal_ops fi_ibv_mr_internal_cache_ops;
 extern struct fi_ibv_mr_internal_ops fi_ibv_mr_internal_ex_ops;
@@ -506,191 +446,290 @@ int fi_ibv_mr_cache_entry_reg(struct ofi_mr_cache *cache,
 			      struct ofi_mr_entry *entry);
 void fi_ibv_mr_cache_entry_dereg(struct ofi_mr_cache *cache,
 				 struct ofi_mr_entry *entry);
-int fi_ibv_monitor_subscribe(struct ofi_mem_monitor *notifier, void *addr,
-			     size_t len, struct ofi_subscription *subscription);
-void fi_ibv_monitor_unsubscribe(struct ofi_mem_monitor *notifier, void *addr,
-				size_t len, struct ofi_subscription *subscription);
+int fi_ibv_monitor_subscribe(struct ofi_mem_monitor *notifier,
+			     struct ofi_subscription *subscription);
+void fi_ibv_monitor_unsubscribe(struct ofi_mem_monitor *notifier,
+				struct ofi_subscription *subscription);
 struct ofi_subscription *fi_ibv_monitor_get_event(struct ofi_mem_monitor *notifier);
 
-static inline void
-fi_ibv_mem_notifier_set_free_hook(fi_ibv_mem_free_hook free_hook)
-{
-#ifdef HAVE_GLIBC_MALLOC_HOOKS
-# ifdef __INTEL_COMPILER /* ICC */
-#  pragma warning push
-#  pragma warning disable 1478
-	__free_hook = free_hook;
-#  pragma warning pop
-# elif defined __clang__ /* Clang */
-#  pragma clang diagnostic push
-#  pragma clang diagnostic ignored "-Wdeprecated-declarations"
-	__free_hook = free_hook;
-#  pragma clang diagnostic pop
-# elif __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6) /* GCC >= 4.6 */
-#  pragma GCC diagnostic push
-#  pragma GCC diagnostic ignored "-Wdeprecated-declarations"
-	__free_hook = free_hook;
-#  pragma GCC diagnostic pop
-# else /* others */
-	__free_hook = free_hook;
-# endif
-#else /* !HAVE_GLIBC_MALLOC_HOOKS */
-	OFI_UNUSED(free_hook);
-#endif /* HAVE_GLIBC_MALLOC_HOOKS */
-}
+/*
+ * An XRC SRQ cannot be created until the associated RX CQ is known,
+ * maintain a list of validated pre-posted receives to post once
+ * the SRQ is created.
+ */
+struct fi_ibv_xrc_srx_prepost {
+	struct slist_entry	prepost_entry;
+	void			*buf;
+	void			*desc;
+	void			*context;
+	size_t			len;
+	fi_addr_t		src_addr;
+};
 
-static inline void
-fi_ibv_mem_notifier_set_realloc_hook(fi_ibv_mem_realloc_hook realloc_hook)
-{
-#ifdef HAVE_GLIBC_MALLOC_HOOKS
-# ifdef __INTEL_COMPILER /* ICC */
-#  pragma warning push
-#  pragma warning disable 1478
-	__realloc_hook = realloc_hook;
-#  pragma warning pop
-# elif defined __clang__ /* Clang */
-#  pragma clang diagnostic push
-#  pragma clang diagnostic ignored "-Wdeprecated-declarations"
-	__realloc_hook = realloc_hook;
-#  pragma clang diagnostic pop
-# elif __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6) /* GCC >= 4.6 */
-#  pragma GCC diagnostic push
-#  pragma GCC diagnostic ignored "-Wdeprecated-declarations"
-	__realloc_hook = realloc_hook;
-#  pragma GCC diagnostic pop
-# else /* others */
-	__realloc_hook = realloc_hook;
-# endif
-#else /* !HAVE_GLIBC_MALLOC_HOOKS */
-	OFI_UNUSED(realloc_hook);
-#endif /* HAVE_GLIBC_MALLOC_HOOKS */
-}
+struct fi_ibv_srq_ep {
+	struct fid_ep		ep_fid;
+	struct ibv_srq		*srq;
+	struct fi_ibv_domain	*domain;
+
+	/* For XRC SRQ only */
+	struct {
+		/* XRC SRQ is not created until endpoint enable */
+		fastlock_t		prepost_lock;
+		struct slist		prepost_list;
+		uint32_t		max_recv_wr;
+		uint32_t		max_sge;
+		uint32_t		prepost_count;
+
+		/* The RX CQ associated with this XRC SRQ. This field
+		 * and the srq_entry should only be modified while holding
+		 * the associted cq::xrc.srq_list_lock. */
+		struct fi_ibv_cq	*cq;
+
+		/* The CQ maintains a list of XRC SRQ associated with it */
+		struct dlist_entry	srq_entry;
+	} xrc;
+};
 
-static inline fi_ibv_mem_free_hook
-fi_ibv_mem_notifier_get_free_hook(void)
+int fi_ibv_srq_context(struct fid_domain *domain, struct fi_rx_attr *attr,
+		       struct fid_ep **rx_ep, void *context);
+
+static inline int fi_ibv_is_xrc(struct fi_info *info)
 {
-#ifdef HAVE_GLIBC_MALLOC_HOOKS
-# ifdef __INTEL_COMPILER /* ICC */
-#  pragma warning push
-#  pragma warning disable 1478
-	return __free_hook;
-#  pragma warning pop
-# elif defined __clang__ /* Clang */
-#  pragma clang diagnostic push
-#  pragma clang diagnostic ignored "-Wdeprecated-declarations"
-	return __free_hook;
-#  pragma clang diagnostic pop
-# elif __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6) /* GCC >= 4.6 */
-#  pragma GCC diagnostic push
-#  pragma GCC diagnostic ignored "-Wdeprecated-declarations"
-	return __free_hook;
-#  pragma GCC diagnostic pop
-# else /* others */
-	return __free_hook;
-# endif
-#else /* !HAVE_GLIBC_MALLOC_HOOKS */
-	return NULL;
-#endif /* HAVE_GLIBC_MALLOC_HOOKS */
+	return  (FI_IBV_EP_TYPE(info) == FI_EP_MSG) &&
+		(FI_IBV_EP_PROTO(info) == FI_PROTO_RDMA_CM_IB_XRC);
 }
 
-static inline fi_ibv_mem_realloc_hook
-fi_ibv_mem_notifier_get_realloc_hook(void)
+static inline int fi_ibv_is_xrc_send_qp(enum ibv_qp_type qp_type)
 {
-#ifdef HAVE_GLIBC_MALLOC_HOOKS
-# ifdef __INTEL_COMPILER /* ICC */
-#  pragma warning push
-#  pragma warning disable 1478
-	return __realloc_hook;
-#  pragma warning pop
-# elif defined __clang__ /* Clang */
-#  pragma clang diagnostic push
-#  pragma clang diagnostic ignored "-Wdeprecated-declarations"
-	return __realloc_hook;
-#  pragma clang diagnostic pop
-# elif __GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6) /* GCC >= 4.6 */
-#  pragma GCC diagnostic push
-#  pragma GCC diagnostic ignored "-Wdeprecated-declarations"
-	return __realloc_hook;
-#  pragma GCC diagnostic pop
-# else /* others */
-	return __realloc_hook;
-# endif
-#else /* !HAVE_GLIBC_MALLOC_HOOKS */
-	return NULL;
-#endif /* HAVE_GLIBC_MALLOC_HOOKS */
+	return qp_type == IBV_QPT_XRC_SEND;
 }
 
-struct fi_ibv_srq_ep {
-	struct fid_ep		ep_fid;
-	struct ibv_srq		*srq;
-	fastlock_t		wre_lock;
-	struct util_buf_pool	*wre_pool;
-	struct dlist_entry	wre_list;
+int fi_ibv_domain_xrc_init(struct fi_ibv_domain *domain);
+int fi_ibv_domain_xrc_cleanup(struct fi_ibv_domain *domain);
+
+enum fi_ibv_ini_qp_state {
+	FI_IBV_INI_QP_UNCONNECTED,
+	FI_IBV_INI_QP_CONNECTING,
+	FI_IBV_INI_QP_CONNECTED
 };
 
-int fi_ibv_srq_context(struct fid_domain *domain, struct fi_rx_attr *attr,
-		       struct fid_ep **rx_ep, void *context);
+#define FI_IBV_NO_INI_TGT_QPNUM 0
+#define FI_IBV_RECIP_CONN	1
 
-struct fi_ibv_msg_ep {
-	struct fid_ep		ep_fid;
-	struct rdma_cm_id	*id;
-	struct fi_ibv_eq	*eq;
-	struct fi_ibv_cq	*rcq;
-	struct fi_ibv_cq	*scq;
-	struct fi_ibv_srq_ep	*srq_ep;
-	uint64_t		ep_flags;
-	struct fi_info		*info;
-	ofi_atomic32_t		unsignaled_send_cnt;
-	int32_t			send_signal_thr;
-	int32_t			send_comp_thr;
-	ofi_atomic32_t		comp_pending;
-	fastlock_t		wre_lock;
-	struct util_buf_pool	*wre_pool;
-	struct dlist_entry	wre_list;
-	uint64_t		ep_id;
-	struct fi_ibv_domain	*domain;
+/*
+ * An XRC transport INI QP connection can be shared within a process to
+ * communicate with all the ranks on the same remote node. This structure is
+ * only accessed during connection setup and tear down and should be
+ * done while holding the domain:xrc:ini_mgmt_lock.
+ */
+struct fi_ibv_ini_shared_conn {
+	/* To share, EP must have same remote peer host addr and TX CQ */
+	struct sockaddr			*peer_addr;
+	struct fi_ibv_cq		*tx_cq;
+
+	/* The physical INI/TGT QPN connection. Virtual connections to the
+	 * same remote peer and TGT QPN will share this connection, with
+	 * the remote end opening the specified XRC TGT QPN for sharing. */
+	enum fi_ibv_ini_qp_state	state;
+	struct ibv_qp			*ini_qp;
+	uint32_t			tgt_qpn;
+
+	/* EP waiting on or using this INI/TGT physical connection will be in
+	 * one of these list and hold a reference to the shared connection. */
+	struct dlist_entry		pending_list;
+	struct dlist_entry		active_list;
+	ofi_atomic32_t			ref_cnt;
 };
 
-struct fi_ibv_msg_epe {
-	struct slist_entry	entry;
-	struct fi_ibv_msg_ep 	*ep;
+enum fi_ibv_xrc_ep_conn_state {
+	FI_IBV_XRC_UNCONNECTED,
+	FI_IBV_XRC_ORIG_CONNECTING,
+	FI_IBV_XRC_ORIG_CONNECTED,
+	FI_IBV_XRC_RECIP_CONNECTING,
+	FI_IBV_XRC_CONNECTED
+};
+
+/*
+ * The following XRC state is only required during XRC connection
+ * establishment and can be freed once bidirectional connectivity
+ * is established.
+ */
+struct fi_ibv_xrc_ep_conn_setup {
+	uint32_t			conn_tag;
+
+	/* IB CM message stale/duplicate detection processing requires
+	 * that shared INI/TGT connections use unique QP numbers during
+	 * RDMA CM connection setup. To avoid conflicts with actual HCA
+	 * QP number space, we allocate minimal QP that are left in the
+	 * reset state and closed once the setup process completes. */
+	struct ibv_qp			*rsvd_ini_qpn;
+	struct ibv_qp			*rsvd_tgt_qpn;
+
+
+	/* Delivery of the FI_CONNECTED event is delayed until
+	 * bidirectional connectivity is established. */
+	size_t				event_len;
+	uint8_t				event_data[FI_IBV_CM_DATA_SIZE];
+
+	/* Connection request may have to queue waiting for the
+	 * physical XRC INI/TGT QP connection to complete. */
+	int				pending_recip;
+	size_t				pending_paramlen;
+	uint8_t				pending_param[FI_IBV_CM_DATA_SIZE];
+};
+
+struct fi_ibv_ep {
+	struct util_ep			util_ep;
+	struct ibv_qp			*ibv_qp;
+	union {
+		struct rdma_cm_id		*id;
+		struct {
+			struct ofi_ib_ud_ep_name	ep_name;
+			int				service;
+		};
+	};
+
+	size_t				inject_limit;
+
+	struct fi_ibv_eq		*eq;
+	struct fi_ibv_srq_ep		*srq_ep;
+	struct fi_info			*info;
+
+	struct {
+		struct ibv_send_wr	rma_wr;
+		struct ibv_send_wr	msg_wr;
+		struct ibv_sge		sge;
+	} *wrs;
+};
+
+struct fi_ibv_xrc_ep {
+	/* Must be first */
+	struct fi_ibv_ep		base_ep;
+
+	/* XRC only fields */
+	struct rdma_cm_id		*tgt_id;
+	struct ibv_qp			*tgt_ibv_qp;
+	enum fi_ibv_xrc_ep_conn_state	conn_state;
+	uint32_t			srqn;
+	uint32_t			peer_srqn;
+
+	/* A reference is held to a shared physical XRC INI/TGT QP connecting
+	 * to the destination node. */
+	struct fi_ibv_ini_shared_conn	*ini_conn;
+	struct dlist_entry		ini_conn_entry;
+
+	/* The following state is allocated during XRC bidirectional setup and
+	 * freed once the connection is established. */
+	struct fi_ibv_xrc_ep_conn_setup	*conn_setup;
 };
 
 int fi_ibv_open_ep(struct fid_domain *domain, struct fi_info *info,
 		   struct fid_ep **ep, void *context);
 int fi_ibv_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
 		      struct fid_pep **pep, void *context);
-int fi_ibv_rdm_open_ep(struct fid_domain *domain, struct fi_info *info,
-			struct fid_ep **ep, void *context);
 int fi_ibv_create_ep(const char *node, const char *service,
 		     uint64_t flags, const struct fi_info *hints,
 		     struct rdma_addrinfo **rai, struct rdma_cm_id **id);
 void fi_ibv_destroy_ep(struct rdma_addrinfo *rai, struct rdma_cm_id **id);
-int fi_rbv_rdm_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
-			struct fid_cntr **cntr, void *context);
-int fi_ibv_rdm_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
-			struct fid_av **av_fid, void *context);
-int fi_ibv_dgram_endpoint_open(struct fid_domain *domain_fid,
-			       struct fi_info *info, struct fid_ep **ep_fid,
-			       void *context);
-int fi_ibv_dgram_cq_open(struct fid_domain *domain_fid, struct fi_cq_attr *attr,
-			 struct fid_cq **cq_fid, void *context);
-int fi_ibv_dgram_cntr_open(struct fid_domain *domain, struct fi_cntr_attr *attr,
-			   struct fid_cntr **cntr_fid, void *context);
 int fi_ibv_dgram_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 			 struct fid_av **av_fid, void *context);
+static inline
+struct fi_ibv_domain *fi_ibv_ep_to_domain(struct fi_ibv_ep *ep)
+{
+	return container_of(ep->util_ep.domain, struct fi_ibv_domain,
+			    util_domain);
+}
 
 struct fi_ops_atomic fi_ibv_msg_ep_atomic_ops;
+struct fi_ops_atomic fi_ibv_msg_xrc_ep_atomic_ops;
 struct fi_ops_cm fi_ibv_msg_ep_cm_ops;
-struct fi_ops_msg fi_ibv_msg_ep_msg_ops;
+struct fi_ops_cm fi_ibv_msg_xrc_ep_cm_ops;
+const struct fi_ops_msg fi_ibv_msg_ep_msg_ops_ts;
+const struct fi_ops_msg fi_ibv_msg_ep_msg_ops;
+const struct fi_ops_msg fi_ibv_dgram_msg_ops_ts;
+const struct fi_ops_msg fi_ibv_dgram_msg_ops;
+const struct fi_ops_msg fi_ibv_msg_xrc_ep_msg_ops;
+const struct fi_ops_msg fi_ibv_msg_xrc_ep_msg_ops_ts;
+const struct fi_ops_msg fi_ibv_msg_srq_xrc_ep_msg_ops;
+struct fi_ops_rma fi_ibv_msg_ep_rma_ops_ts;
 struct fi_ops_rma fi_ibv_msg_ep_rma_ops;
-struct fi_ops_msg fi_ibv_msg_srq_ep_msg_ops;
+struct fi_ops_rma fi_ibv_msg_xrc_ep_rma_ops_ts;
+struct fi_ops_rma fi_ibv_msg_xrc_ep_rma_ops;
+
+#define FI_IBV_XRC_VERSION	1
+
+struct fi_ibv_xrc_cm_data {
+	uint8_t		version;
+	uint8_t		reciprocal;
+	uint16_t	port;
+	uint32_t	param;
+	uint32_t	conn_tag;
+};
+
+struct fi_ibv_xrc_conn_info {
+	uint32_t		conn_tag;
+	uint32_t		is_reciprocal;
+	uint32_t		ini_qpn;
+	uint32_t		conn_data;
+	uint16_t		port;
+	struct rdma_conn_param	conn_param;
+};
 
 struct fi_ibv_connreq {
-	struct fid		handle;
-	struct rdma_cm_id	*id;
+	struct fid			handle;
+	struct rdma_cm_id		*id;
+
+	/* Support for XRC bidirectional connections, and
+	 * non-RDMA CM managed QP. */
+	int				is_xrc;
+	struct fi_ibv_xrc_conn_info	xrc;
+};
+
+struct fi_ibv_cm_data_hdr {
+	uint8_t	size;
+	char	data[];
 };
 
+void fi_ibv_msg_ep_get_qp_attr(struct fi_ibv_ep *ep,
+			       struct ibv_qp_init_attr *attr);
+int fi_ibv_process_xrc_connreq(struct fi_ibv_ep *ep,
+			       struct fi_ibv_connreq *connreq);
+
+void fi_ibv_next_xrc_conn_state(struct fi_ibv_xrc_ep *ep);
+void fi_ibv_prev_xrc_conn_state(struct fi_ibv_xrc_ep *ep);
+void fi_ibv_eq_set_xrc_conn_tag(struct fi_ibv_xrc_ep *ep);
+void fi_ibv_eq_clear_xrc_conn_tag(struct fi_ibv_xrc_ep *ep);
+struct fi_ibv_xrc_ep *fi_ibv_eq_xrc_conn_tag2ep(struct fi_ibv_eq *eq,
+						uint32_t conn_tag);
+void fi_ibv_set_xrc_cm_data(struct fi_ibv_xrc_cm_data *local, int reciprocal,
+			    uint32_t conn_tag, uint16_t port, uint32_t param);
+int fi_ibv_verify_xrc_cm_data(struct fi_ibv_xrc_cm_data *remote,
+			      int private_data_len);
+int fi_ibv_connect_xrc(struct fi_ibv_xrc_ep *ep, struct sockaddr *addr,
+		       int reciprocal, void *param, size_t paramlen);
+int fi_ibv_accept_xrc(struct fi_ibv_xrc_ep *ep, int reciprocal,
+		      void *param, size_t paramlen);
+void fi_ibv_free_xrc_conn_setup(struct fi_ibv_xrc_ep *ep);
+void fi_ibv_add_pending_ini_conn(struct fi_ibv_xrc_ep *ep, int reciprocal,
+				 void *conn_param, size_t conn_paramlen);
+void fi_ibv_sched_ini_conn(struct fi_ibv_ini_shared_conn *ini_conn);
+int fi_ibv_get_shared_ini_conn(struct fi_ibv_xrc_ep *ep,
+			       struct fi_ibv_ini_shared_conn **ini_conn);
+void fi_ibv_put_shared_ini_conn(struct fi_ibv_xrc_ep *ep);
+int fi_ibv_reserve_qpn(struct fi_ibv_xrc_ep *ep, struct ibv_qp **qp);
+
+void fi_ibv_save_priv_data(struct fi_ibv_xrc_ep *ep, const void *data,
+			   size_t len);
+int fi_ibv_ep_create_ini_qp(struct fi_ibv_xrc_ep *ep, void *dst_addr,
+			    uint32_t *peer_tgt_qpn);
+void fi_ibv_ep_ini_conn_done(struct fi_ibv_xrc_ep *ep, uint32_t peer_srqn,
+			    uint32_t peer_tgt_qpn);
+void fi_ibv_ep_ini_conn_rejected(struct fi_ibv_xrc_ep *ep);
+int fi_ibv_ep_create_tgt_qp(struct fi_ibv_xrc_ep *ep, uint32_t tgt_qpn);
+void fi_ibv_ep_tgt_conn_done(struct fi_ibv_xrc_ep *qp);
+int fi_ibv_ep_destroy_xrc_qp(struct fi_ibv_xrc_ep *ep);
+
+int fi_ibv_xrc_close_srq(struct fi_ibv_srq_ep *srq_ep);
 int fi_ibv_sockaddr_len(struct sockaddr *addr);
 
 
@@ -704,16 +743,15 @@ int fi_ibv_fi_to_rai(const struct fi_info *fi, uint64_t flags,
 		     struct rdma_addrinfo *rai);
 int fi_ibv_get_rdma_rai(const char *node, const char *service, uint64_t flags,
 			const struct fi_info *hints, struct rdma_addrinfo **rai);
-int fi_ibv_rdm_cm_bind_ep(struct fi_ibv_rdm_cm *cm, struct fi_ibv_rdm_ep *ep);
-
 struct verbs_ep_domain {
 	char			*suffix;
 	enum fi_ep_type		type;
+	uint32_t		protocol;
 	uint64_t		caps;
 };
 
-extern const struct verbs_ep_domain verbs_rdm_domain;
 extern const struct verbs_ep_domain verbs_dgram_domain;
+extern const struct verbs_ep_domain verbs_msg_xrc_domain;
 
 int fi_ibv_check_ep_attr(const struct fi_info *hints,
 			 const struct fi_info *info);
@@ -721,7 +759,16 @@ int fi_ibv_check_rx_attr(const struct fi_rx_attr *attr,
 			 const struct fi_info *hints,
 			 const struct fi_info *info);
 
-ssize_t fi_ibv_poll_cq(struct fi_ibv_cq *cq, struct ibv_wc *wc);
+static inline int fi_ibv_cmp_xrc_domain_name(const char *domain_name,
+					     const char *rdma_name)
+{
+	size_t domain_len = strlen(domain_name);
+	size_t suffix_len = strlen(verbs_msg_xrc_domain.suffix);
+
+	return domain_len > suffix_len ? strncmp(domain_name, rdma_name,
+						 domain_len - suffix_len) : -1;
+}
+
 int fi_ibv_cq_signal(struct fid_cq *cq);
 
 ssize_t fi_ibv_eq_write_event(struct fi_ibv_eq *eq, uint32_t event,
@@ -731,29 +778,117 @@ int fi_ibv_query_atomic(struct fid_domain *domain_fid, enum fi_datatype datatype
 			enum fi_op op, struct fi_atomic_attr *attr,
 			uint64_t flags);
 int fi_ibv_set_rnr_timer(struct ibv_qp *qp);
-void fi_ibv_empty_wre_list(struct util_buf_pool *wre_pool,
-			   struct dlist_entry *wre_list,
-			   enum fi_ibv_wre_type wre_type);
-void fi_ibv_cleanup_cq(struct fi_ibv_msg_ep *cur_ep);
+void fi_ibv_cleanup_cq(struct fi_ibv_ep *cur_ep);
 int fi_ibv_find_max_inline(struct ibv_pd *pd, struct ibv_context *context,
-                           enum ibv_qp_type qp_type);
+			   enum ibv_qp_type qp_type);
+
+struct fi_ibv_dgram_av {
+	struct util_av util_av;
+	struct dlist_entry av_entry_list;
+};
+
+struct fi_ibv_dgram_av_entry {
+	struct dlist_entry list_entry;
+	struct ofi_ib_ud_ep_name addr;
+	struct ibv_ah *ah;
+};
+
+static inline struct fi_ibv_dgram_av_entry*
+fi_ibv_dgram_av_lookup_av_entry(fi_addr_t fi_addr)
+{
+	return (struct fi_ibv_dgram_av_entry *)fi_addr;
+}
+
+/* NOTE:
+ * When ibv_post_send/recv returns '-1' it means the following:
+ * Deal with non-compliant libibverbs drivers which set errno
+ * instead of directly returning the error value
+ */
+static inline ssize_t fi_ibv_handle_post(int ret)
+{
+	switch (ret) {
+		case -ENOMEM:
+		case ENOMEM:
+			ret = -FI_EAGAIN;
+			break;
+		case -1:
+			ret = (errno == ENOMEM) ? -FI_EAGAIN :
+						  -errno;
+			break;
+		default:
+			ret = -abs(ret);
+			break;
+	}
+	return ret;
+}
+
+/* Returns 0 if it processes WR entry for which user
+ * doesn't request the completion */
+static inline int
+fi_ibv_process_wc(struct fi_ibv_cq *cq, struct ibv_wc *wc)
+{
+	return (wc->wr_id == VERBS_NO_COMP_FLAG) ? 0 : 1;
+}
+
+/* Returns 0 and tries read new completions if it processes
+ * WR entry for which user doesn't request the completion */
+static inline int
+fi_ibv_process_wc_poll_new(struct fi_ibv_cq *cq, struct ibv_wc *wc)
+{
+	if (wc->wr_id == VERBS_NO_COMP_FLAG) {
+		int ret;
+
+		while ((ret = ibv_poll_cq(cq->cq, 1, wc)) > 0) {
+			if (wc->wr_id != VERBS_NO_COMP_FLAG)
+				return 1;
+		}
+		return ret;
+	}
+	return 1;
+}
+
+static inline int fi_ibv_wc_2_wce(struct fi_ibv_cq *cq,
+				  struct ibv_wc *wc,
+				  struct fi_ibv_wce **wce)
+
+{
+	*wce = util_buf_alloc(cq->wce_pool);
+	if (OFI_UNLIKELY(!*wce))
+		return -FI_ENOMEM;
+	memset(*wce, 0, sizeof(**wce));
+	(*wce)->wc = *wc;
+
+	return FI_SUCCESS;
+}
 
 #define fi_ibv_init_sge(buf, len, desc) (struct ibv_sge)		\
 	{ .addr = (uintptr_t)buf,					\
 	  .length = (uint32_t)len,					\
 	  .lkey = (uint32_t)(uintptr_t)desc }
 
-#define fi_ibv_set_sge_iov(sg_list, iov, count, desc, len)	\
-({								\
-	size_t i;						\
-	sg_list = alloca(sizeof(*sg_list) * count);		\
-	for (i = 0; i < count; i++) {				\
-		sg_list[i] = fi_ibv_init_sge(			\
-				iov[i].iov_base,		\
-				iov[i].iov_len,			\
-				desc[i]);			\
-		len += iov[i].iov_len;				\
-	}							\
+#define fi_ibv_set_sge_iov(sg_list, iov, count, desc)	\
+({							\
+	size_t i;					\
+	sg_list = alloca(sizeof(*sg_list) * count);	\
+	for (i = 0; i < count; i++) {			\
+		sg_list[i] = fi_ibv_init_sge(		\
+				iov[i].iov_base,	\
+				iov[i].iov_len,		\
+				desc[i]);		\
+	}						\
+})
+
+#define fi_ibv_set_sge_iov_count_len(sg_list, iov, count, desc, len)	\
+({									\
+	size_t i;							\
+	sg_list = alloca(sizeof(*sg_list) * count);			\
+	for (i = 0; i < count; i++) {					\
+		sg_list[i] = fi_ibv_init_sge(				\
+				iov[i].iov_base,			\
+				iov[i].iov_len,				\
+				desc[i]);				\
+		len += iov[i].iov_len;					\
+	}								\
 })
 
 #define fi_ibv_init_sge_inline(buf, len) fi_ibv_init_sge(buf, len, NULL)
@@ -766,16 +901,124 @@ int fi_ibv_find_max_inline(struct ibv_pd *pd, struct ibv_context *context,
 		sg_list[i] = fi_ibv_init_sge_inline(		\
 					iov[i].iov_base,	\
 					iov[i].iov_len);	\
-			len += iov[i].iov_len;			\
+		len += iov[i].iov_len;				\
 	}							\
 })
 
-#define fi_ibv_send_iov(ep, wr, iov, desc, count, context)		\
-	fi_ibv_send_iov_flags(ep, wr, iov, desc, count, context,	\
-			ep->info->tx_attr->op_flags)
+#define fi_ibv_send_iov(ep, wr, iov, desc, count)		\
+	fi_ibv_send_iov_flags(ep, wr, iov, desc, count,		\
+			      (ep)->info->tx_attr->op_flags)
 
 #define fi_ibv_send_msg(ep, wr, msg, flags)				\
-	fi_ibv_send_iov_flags(ep, wr, msg->msg_iov, msg->desc,		\
-			msg->iov_count,	msg->context, flags)
+	fi_ibv_send_iov_flags(ep, wr, (msg)->msg_iov, (msg)->desc,	\
+			      (msg)->iov_count, flags)
+
+
+static inline int fi_ibv_poll_reap_unsig_cq(struct fi_ibv_ep *ep)
+{
+	struct fi_ibv_wce *wce;
+	struct ibv_wc wc[10];
+	int ret, i;
+	struct fi_ibv_cq *cq =
+		container_of(ep->util_ep.tx_cq, struct fi_ibv_cq, util_cq);
+
+	cq->util_cq.cq_fastlock_acquire(&cq->util_cq.cq_lock);
+	/* TODO: retrieve WCs as much as possible in a single
+	 * ibv_poll_cq call */
+	while (1) {
+		ret = ibv_poll_cq(cq->cq, 10, wc);
+		if (ret <= 0) {
+			cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
+			return ret;
+		}
+
+		for (i = 0; i < ret; i++) {
+			if (!fi_ibv_process_wc(cq, &wc[i]) ||
+			    OFI_UNLIKELY(wc[i].status == IBV_WC_WR_FLUSH_ERR))
+				continue;
+			if (OFI_LIKELY(!fi_ibv_wc_2_wce(cq, &wc[i], &wce)))
+				slist_insert_tail(&wce->entry, &cq->wcq);
+		}
+	}
+
+	cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
+	return FI_SUCCESS;
+}
+
+/* WR must be filled out by now except for context */
+static inline ssize_t
+fi_ibv_send_poll_cq_if_needed(struct fi_ibv_ep *ep, struct ibv_send_wr *wr)
+{
+	int ret;
+	struct ibv_send_wr *bad_wr;
+
+	ret = ibv_post_send(ep->ibv_qp, wr, &bad_wr);
+	if (OFI_UNLIKELY(ret)) {
+		ret = fi_ibv_handle_post(ret);
+		if (OFI_LIKELY(ret == -FI_EAGAIN)) {
+			ret = fi_ibv_poll_reap_unsig_cq(ep);
+			if (OFI_UNLIKELY(ret))
+				return -FI_EAGAIN;
+			/* Try again and return control to a caller */
+			ret = fi_ibv_handle_post(ibv_post_send(ep->ibv_qp, wr,
+							       &bad_wr));
+		}
+	}
+	return ret;
+}
+
+static inline ssize_t
+fi_ibv_send_buf(struct fi_ibv_ep *ep, struct ibv_send_wr *wr,
+		const void *buf, size_t len, void *desc)
+{
+	struct ibv_sge sge = fi_ibv_init_sge(buf, len, desc);
+
+	assert(wr->wr_id != VERBS_NO_COMP_FLAG);
+
+	wr->sg_list = &sge;
+	wr->num_sge = 1;
+
+	return fi_ibv_send_poll_cq_if_needed(ep, wr);
+}
+
+static inline ssize_t
+fi_ibv_send_buf_inline(struct fi_ibv_ep *ep, struct ibv_send_wr *wr,
+		       const void *buf, size_t len)
+{
+	struct ibv_sge sge = fi_ibv_init_sge_inline(buf, len);
+
+	assert(wr->wr_id == VERBS_NO_COMP_FLAG);
+
+	wr->sg_list = &sge;
+	wr->num_sge = 1;
+
+	return fi_ibv_send_poll_cq_if_needed(ep, wr);
+}
+
+static inline ssize_t
+fi_ibv_send_iov_flags(struct fi_ibv_ep *ep, struct ibv_send_wr *wr,
+		      const struct iovec *iov, void **desc, int count,
+		      uint64_t flags)
+{
+	size_t len = 0;
+
+	if (!desc)
+		fi_ibv_set_sge_iov_inline(wr->sg_list, iov, count, len);
+	else
+		fi_ibv_set_sge_iov_count_len(wr->sg_list, iov, count, desc, len);
+
+	wr->num_sge = count;
+	wr->send_flags = VERBS_INJECT_FLAGS(ep, len, flags);
+	wr->wr_id = VERBS_COMP_FLAGS(ep, flags, wr->wr_id);
+
+	if (flags & FI_FENCE)
+		wr->send_flags |= IBV_SEND_FENCE;
+
+	return fi_ibv_send_poll_cq_if_needed(ep, wr);
+}
+
+int fi_ibv_get_rai_id(const char *node, const char *service, uint64_t flags,
+		      const struct fi_info *hints, struct rdma_addrinfo **rai,
+		      struct rdma_cm_id **id);
 
 #endif /* FI_VERBS_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ofi_verbs_priv.h b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ofi_verbs_priv.h
new file mode 100644
index 000000000..c19a1f16e
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/ofi_verbs_priv.h
@@ -0,0 +1,63 @@
+/*
+ * Copyright (c) 2018 Cray Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef OFI_VERBS_PRIV_H
+#define OFI_VERBS_PRIV_H
+
+#if !VERBS_HAVE_XRC
+#define IBV_QPT_XRC_SEND 9ull
+#define IBV_QPT_XRC_RECV 10ull
+
+#define IBV_DEVICE_XRC (1 << 20)
+
+#define IBV_SRQ_INIT_ATTR_TYPE 0ull
+#define IBV_SRQ_INIT_ATTR_PD 1ull
+#define IBV_SRQ_INIT_ATTR_XRCD 2ull
+#define IBV_SRQ_INIT_ATTR_CQ 3ull
+
+#define IBV_SRQT_XRC 1ull
+#define FI_IBV_SET_REMOTE_SRQN(var, val) do { } while (0)
+#define FI_VERBS_XRC_ONLY __attribute__((unused))
+
+#define ibv_get_srq_num(srq, srqn) do { } while (0)
+#define ibv_create_srq_ex(context, attr) (NULL)
+#else /* !VERBS_HAVE_XRC */
+
+#define FI_IBV_SET_REMOTE_SRQN(var, val) \
+	do { \
+		(var).qp_type.xrc.remote_srqn = (val); \
+	} while (0)
+
+#define FI_VERBS_XRC_ONLY
+#endif /* VERBS_HAVE_XRC */
+
+#endif /* OFI_VERBS_PRIV_H */
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cm.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cm.c
index 23f702efd..92deef585 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cm.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cm.c
@@ -55,12 +55,11 @@ static int fi_ibv_copy_addr(void *dst_addr, size_t *dst_addrlen, void *src_addr)
 
 static int fi_ibv_msg_ep_setname(fid_t ep_fid, void *addr, size_t addrlen)
 {
-	struct fi_ibv_msg_ep *ep;
 	void *save_addr;
 	struct rdma_cm_id *id;
 	int ret;
-
-	ep = container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
 
 	if (addrlen != ep->info->src_addrlen) {
 		VERBS_INFO(FI_LOG_EP_CTRL,"addrlen expected: %zu, got: %zu.\n",
@@ -86,6 +85,7 @@ static int fi_ibv_msg_ep_setname(fid_t ep_fid, void *addr, size_t addrlen)
 		rdma_destroy_ep(ep->id);
 
 	ep->id = id;
+	ep->ibv_qp = ep->id->qp;
 	free(save_addr);
 
 	return 0;
@@ -98,48 +98,68 @@ err1:
 
 static int fi_ibv_msg_ep_getname(fid_t ep, void *addr, size_t *addrlen)
 {
-	struct fi_ibv_msg_ep *_ep;
 	struct sockaddr *sa;
-
-	_ep = container_of(ep, struct fi_ibv_msg_ep, ep_fid);
+	struct fi_ibv_ep *_ep =
+		container_of(ep, struct fi_ibv_ep, util_ep.ep_fid);
 	sa = rdma_get_local_addr(_ep->id);
 	return fi_ibv_copy_addr(addr, addrlen, sa);
 }
 
 static int fi_ibv_msg_ep_getpeer(struct fid_ep *ep, void *addr, size_t *addrlen)
 {
-	struct fi_ibv_msg_ep *_ep;
 	struct sockaddr *sa;
-
-	_ep = container_of(ep, struct fi_ibv_msg_ep, ep_fid);
+	struct fi_ibv_ep *_ep =
+		container_of(ep, struct fi_ibv_ep, util_ep.ep_fid);
 	sa = rdma_get_peer_addr(_ep->id);
 	return fi_ibv_copy_addr(addr, addrlen, sa);
 }
 
+static inline void
+fi_ibv_msg_ep_prepare_cm_data(const void *param, size_t param_size,
+			      struct fi_ibv_cm_data_hdr *cm_hdr)
+{
+	cm_hdr->size = (uint8_t)param_size;
+	memcpy(cm_hdr->data, param, cm_hdr->size);
+}
+
+static inline void
+fi_ibv_ep_prepare_rdma_cm_param(struct rdma_conn_param *conn_param,
+				struct fi_ibv_cm_data_hdr *cm_hdr,
+				size_t cm_hdr_data_size)
+{
+	conn_param->private_data = cm_hdr;
+	conn_param->private_data_len = (uint8_t)cm_hdr_data_size;
+	conn_param->responder_resources = RDMA_MAX_RESP_RES;
+	conn_param->initiator_depth = RDMA_MAX_INIT_DEPTH;
+	conn_param->flow_control = 1;
+	conn_param->rnr_retry_count = 7;
+}
+
 static int
 fi_ibv_msg_ep_connect(struct fid_ep *ep, const void *addr,
-		   const void *param, size_t paramlen)
+		      const void *param, size_t paramlen)
 {
-	struct fi_ibv_msg_ep *_ep;
-	struct rdma_conn_param conn_param;
+	struct rdma_conn_param conn_param = { 0 };
 	struct sockaddr *src_addr, *dst_addr;
 	int ret;
+	struct fi_ibv_cm_data_hdr *cm_hdr;
+	struct fi_ibv_ep *_ep =
+		container_of(ep, struct fi_ibv_ep, util_ep.ep_fid);
+
+	if (OFI_UNLIKELY(paramlen > VERBS_CM_DATA_SIZE))
+		return -FI_EINVAL;
 
-	_ep = container_of(ep, struct fi_ibv_msg_ep, ep_fid);
 	if (!_ep->id->qp) {
-		ret = ep->fid.ops->control(&ep->fid, FI_ENABLE, NULL);
+		ret = fi_control(&ep->fid, FI_ENABLE, NULL);
 		if (ret)
 			return ret;
 	}
 
-	memset(&conn_param, 0, sizeof conn_param);
-	conn_param.private_data = param;
-	conn_param.private_data_len = paramlen;
-	conn_param.responder_resources = RDMA_MAX_RESP_RES;
-	conn_param.initiator_depth = RDMA_MAX_INIT_DEPTH;
-	conn_param.flow_control = 1;
+	cm_hdr = alloca(sizeof(*cm_hdr) + paramlen);
+	fi_ibv_msg_ep_prepare_cm_data(param, paramlen, cm_hdr);
+	fi_ibv_ep_prepare_rdma_cm_param(&conn_param, cm_hdr,
+					sizeof(*cm_hdr) + paramlen);
 	conn_param.retry_count = 15;
-	conn_param.rnr_retry_count = 7;
 
 	if (_ep->srq_ep)
 		conn_param.srq = 1;
@@ -164,25 +184,26 @@ fi_ibv_msg_ep_connect(struct fid_ep *ep, const void *addr,
 static int
 fi_ibv_msg_ep_accept(struct fid_ep *ep, const void *param, size_t paramlen)
 {
-	struct fi_ibv_msg_ep *_ep;
 	struct rdma_conn_param conn_param;
 	struct fi_ibv_connreq *connreq;
 	int ret;
+	struct fi_ibv_cm_data_hdr *cm_hdr;
+	struct fi_ibv_ep *_ep =
+		container_of(ep, struct fi_ibv_ep, util_ep.ep_fid);
+
+	if (OFI_UNLIKELY(paramlen > VERBS_CM_DATA_SIZE))
+		return -FI_EINVAL;
 
-	_ep = container_of(ep, struct fi_ibv_msg_ep, ep_fid);
 	if (!_ep->id->qp) {
-		ret = ep->fid.ops->control(&ep->fid, FI_ENABLE, NULL);
+		ret = fi_control(&ep->fid, FI_ENABLE, NULL);
 		if (ret)
 			return ret;
 	}
 
-	memset(&conn_param, 0, sizeof conn_param);
-	conn_param.private_data = param;
-	conn_param.private_data_len = paramlen;
-	conn_param.responder_resources = RDMA_MAX_RESP_RES;
-	conn_param.initiator_depth = RDMA_MAX_INIT_DEPTH;
-	conn_param.flow_control = 1;
-	conn_param.rnr_retry_count = 7;
+	cm_hdr = alloca(sizeof(*cm_hdr) + paramlen);
+	fi_ibv_msg_ep_prepare_cm_data(param, paramlen, cm_hdr);
+	fi_ibv_ep_prepare_rdma_cm_param(&conn_param, cm_hdr,
+					sizeof(*cm_hdr) + paramlen);
 
 	if (_ep->srq_ep)
 		conn_param.srq = 1;
@@ -197,24 +218,86 @@ fi_ibv_msg_ep_accept(struct fid_ep *ep, const void *param, size_t paramlen)
 	return 0;
 }
 
+static int fi_ibv_msg_alloc_xrc_params(void **adjusted_param,
+				       const void *param, size_t *paramlen)
+{
+	struct fi_ibv_xrc_cm_data *cm_data;
+	size_t cm_datalen = sizeof(*cm_data) + *paramlen;
+
+	*adjusted_param = NULL;
+
+	if (cm_datalen > FI_IBV_CM_DATA_SIZE) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "XRC CM data overflow %"PRIu64"\n",
+			   cm_datalen);
+		return -FI_EINVAL;
+	}
+
+	cm_data = malloc(cm_datalen);
+	if (!cm_data) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to allocate XRC CM data\n");
+		return -FI_ENOMEM;
+	}
+
+	if (*paramlen)
+		memcpy((cm_data + 1), param, *paramlen);
+
+	*paramlen = cm_datalen;
+	*adjusted_param = cm_data;
+	return FI_SUCCESS;
+}
+
+static int
+fi_ibv_msg_xrc_ep_reject(struct fi_ibv_connreq *connreq,
+			 const void *param, size_t paramlen)
+{
+	struct fi_ibv_xrc_cm_data *cm_data;
+	int ret;
+
+	ret = fi_ibv_msg_alloc_xrc_params((void **)&cm_data, param, &paramlen);
+	if (ret)
+		return ret;
+
+	fi_ibv_set_xrc_cm_data(cm_data, connreq->xrc.is_reciprocal,
+			       connreq->xrc.conn_tag, connreq->xrc.port, 0);
+	ret = rdma_reject(connreq->id, cm_data,
+			  (uint8_t) paramlen) ? -errno : 0;
+	free(cm_data);
+	return ret;
+}
+
 static int
 fi_ibv_msg_ep_reject(struct fid_pep *pep, fid_t handle,
-		  const void *param, size_t paramlen)
+		     const void *param, size_t paramlen)
 {
-	struct fi_ibv_connreq *connreq;
+	struct fi_ibv_connreq *connreq =
+		container_of(handle, struct fi_ibv_connreq, handle);
+	struct fi_ibv_cm_data_hdr *cm_hdr;
 	int ret;
 
-	connreq = container_of(handle, struct fi_ibv_connreq, handle);
-	ret = rdma_reject(connreq->id, param, (uint8_t) paramlen) ? -errno : 0;
+	if (OFI_UNLIKELY(paramlen > VERBS_CM_DATA_SIZE))
+		return -FI_EINVAL;
+
+	cm_hdr = alloca(sizeof(*cm_hdr) + paramlen);
+	fi_ibv_msg_ep_prepare_cm_data(param, paramlen, cm_hdr);
+
+	if (connreq->is_xrc)
+		ret = fi_ibv_msg_xrc_ep_reject(connreq, cm_hdr,
+				(uint8_t)(sizeof(*cm_hdr) + paramlen));
+
+	else
+		ret = rdma_reject(connreq->id, cm_hdr,
+			(uint8_t)(sizeof(*cm_hdr) + paramlen)) ? -errno : 0;
 	free(connreq);
 	return ret;
 }
 
 static int fi_ibv_msg_ep_shutdown(struct fid_ep *ep, uint64_t flags)
 {
-	struct fi_ibv_msg_ep *_ep;
-	_ep = container_of(ep, struct fi_ibv_msg_ep, ep_fid);
-	return rdma_disconnect(_ep->id) ? -errno : 0;
+	struct fi_ibv_ep *_ep =
+		container_of(ep, struct fi_ibv_ep, util_ep.ep_fid);
+	if (_ep->id)
+		return rdma_disconnect(_ep->id) ? -errno : 0;
+	return 0;
 }
 
 struct fi_ops_cm fi_ibv_msg_ep_cm_ops = {
@@ -230,6 +313,102 @@ struct fi_ops_cm fi_ibv_msg_ep_cm_ops = {
 	.join = fi_no_join,
 };
 
+static int
+fi_ibv_msg_xrc_cm_common_verify(struct fi_ibv_xrc_ep *ep, size_t paramlen)
+{
+	int ret;
+
+	if (!fi_ibv_is_xrc(ep->base_ep.info)) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "EP is not using XRC\n");
+		return -FI_EINVAL;
+	}
+
+	if (!ep->srqn) {
+		ret = fi_control(&ep->base_ep.util_ep.ep_fid.fid,
+				 FI_ENABLE, NULL);
+		if (ret)
+			return ret;
+	}
+
+	if (OFI_UNLIKELY(paramlen > VERBS_CM_DATA_SIZE -
+			 sizeof(struct fi_ibv_xrc_cm_data)))
+		return -FI_EINVAL;
+
+	return FI_SUCCESS;
+}
+
+static int
+fi_ibv_msg_xrc_ep_connect(struct fid_ep *ep, const void *addr,
+		   const void *param, size_t paramlen)
+{
+	struct sockaddr *dst_addr;
+	void *adjusted_param;
+	struct fi_ibv_ep *_ep = container_of(ep, struct fi_ibv_ep,
+					     util_ep.ep_fid);
+	struct fi_ibv_xrc_ep *xrc_ep = container_of(_ep, struct fi_ibv_xrc_ep,
+						    base_ep);
+	int ret;
+	struct fi_ibv_cm_data_hdr *cm_hdr;
+
+	ret = fi_ibv_msg_xrc_cm_common_verify(xrc_ep, paramlen);
+	if (ret)
+		return ret;
+
+	cm_hdr = alloca(sizeof(*cm_hdr) + paramlen);
+	fi_ibv_msg_ep_prepare_cm_data(param, paramlen, cm_hdr);
+	paramlen += sizeof(*cm_hdr);
+
+	ret = fi_ibv_msg_alloc_xrc_params(&adjusted_param, cm_hdr, &paramlen);
+	if (ret)
+		return ret;
+
+	dst_addr = rdma_get_peer_addr(_ep->id);
+	ret = fi_ibv_connect_xrc(xrc_ep, dst_addr, 0, adjusted_param, paramlen);
+	free(adjusted_param);
+	return ret;
+}
+
+static int
+fi_ibv_msg_xrc_ep_accept(struct fid_ep *ep, const void *param, size_t paramlen)
+{
+	void *adjusted_param;
+	struct fi_ibv_ep *_ep =
+		container_of(ep, struct fi_ibv_ep, util_ep.ep_fid);
+	struct fi_ibv_xrc_ep *xrc_ep = container_of(_ep, struct fi_ibv_xrc_ep,
+						    base_ep);
+	int ret;
+	struct fi_ibv_cm_data_hdr *cm_hdr;
+
+	ret = fi_ibv_msg_xrc_cm_common_verify(xrc_ep, paramlen);
+	if (ret)
+		return ret;
+
+	cm_hdr = alloca(sizeof(*cm_hdr) + paramlen);
+	fi_ibv_msg_ep_prepare_cm_data(param, paramlen, cm_hdr);
+	paramlen += sizeof(*cm_hdr);
+
+	ret = fi_ibv_msg_alloc_xrc_params(&adjusted_param, cm_hdr, &paramlen);
+	if (ret)
+		return ret;
+
+	ret = fi_ibv_accept_xrc(xrc_ep, 0, adjusted_param, paramlen);
+	free(adjusted_param);
+	return ret;
+}
+
+struct fi_ops_cm fi_ibv_msg_xrc_ep_cm_ops = {
+	.size = sizeof(struct fi_ops_cm),
+	.setname = fi_ibv_msg_ep_setname,
+	.getname = fi_ibv_msg_ep_getname,
+	.getpeer = fi_ibv_msg_ep_getpeer,
+	.connect = fi_ibv_msg_xrc_ep_connect,
+	.listen = fi_no_listen,
+	.accept = fi_ibv_msg_xrc_ep_accept,
+	.reject = fi_no_reject,
+	.shutdown = fi_ibv_msg_ep_shutdown,
+	.join = fi_no_join,
+};
+
 static int fi_ibv_pep_setname(fid_t pep_fid, void *addr, size_t addrlen)
 {
 	struct fi_ibv_pep *pep;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cm_xrc.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cm_xrc.c
new file mode 100644
index 000000000..481c8506f
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cm_xrc.c
@@ -0,0 +1,381 @@
+/*
+ * Copyright (c) 2018 Cray Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "config.h"
+#include "fi_verbs.h"
+
+void fi_ibv_next_xrc_conn_state(struct fi_ibv_xrc_ep *ep)
+{
+	switch (ep->conn_state) {
+	case FI_IBV_XRC_UNCONNECTED:
+		ep->conn_state = FI_IBV_XRC_ORIG_CONNECTING;
+		break;
+	case FI_IBV_XRC_ORIG_CONNECTING:
+		ep->conn_state = FI_IBV_XRC_ORIG_CONNECTED;
+		break;
+	case FI_IBV_XRC_ORIG_CONNECTED:
+		ep->conn_state = FI_IBV_XRC_RECIP_CONNECTING;
+		break;
+	case FI_IBV_XRC_RECIP_CONNECTING:
+		ep->conn_state = FI_IBV_XRC_CONNECTED;
+		break;
+	case FI_IBV_XRC_CONNECTED:
+		break;
+	default:
+		assert(0);
+		VERBS_WARN(FI_LOG_FABRIC, "Unkown XRC connection state %d\n",
+			   ep->conn_state);
+	}
+}
+
+void fi_ibv_prev_xrc_conn_state(struct fi_ibv_xrc_ep *ep)
+{
+	switch (ep->conn_state) {
+	case FI_IBV_XRC_UNCONNECTED:
+		break;
+	case FI_IBV_XRC_ORIG_CONNECTING:
+		ep->conn_state = FI_IBV_XRC_UNCONNECTED;
+		break;
+	case FI_IBV_XRC_ORIG_CONNECTED:
+		ep->conn_state = FI_IBV_XRC_ORIG_CONNECTING;
+		break;
+	case FI_IBV_XRC_RECIP_CONNECTING:
+		ep->conn_state = FI_IBV_XRC_ORIG_CONNECTED;
+		break;
+	case FI_IBV_XRC_CONNECTED:
+		ep->conn_state = FI_IBV_XRC_RECIP_CONNECTING;
+		break;
+	default:
+		assert(0);
+		VERBS_WARN(FI_LOG_FABRIC, "Unkown XRC connection state %d\n",
+			   ep->conn_state);
+	}
+}
+
+void fi_ibv_save_priv_data(struct fi_ibv_xrc_ep *ep, const void *data,
+			   size_t len)
+{
+	ep->conn_setup->event_len = MIN(sizeof(ep->conn_setup->event_data),
+					len);
+	memcpy(ep->conn_setup->event_data, data, ep->conn_setup->event_len);
+}
+
+void fi_ibv_set_xrc_cm_data(struct fi_ibv_xrc_cm_data *local, int reciprocal,
+			    uint32_t conn_tag, uint16_t port, uint32_t param)
+{
+	local->version = FI_IBV_XRC_VERSION;
+	local->reciprocal = reciprocal ? 1 : 0;
+	local->port = htons(port);
+	local->conn_tag = htonl(conn_tag);
+	local->param = htonl(param);
+}
+
+int fi_ibv_verify_xrc_cm_data(struct fi_ibv_xrc_cm_data *remote,
+			      int private_data_len)
+{
+	if (sizeof(*remote) > private_data_len) {
+		VERBS_WARN(FI_LOG_EP_CTRL,
+			   "XRC MSG EP CM data length mismatch\n");
+		return -FI_EINVAL;
+	}
+
+	if (remote->version != FI_IBV_XRC_VERSION) {
+		VERBS_WARN(FI_LOG_EP_CTRL,
+			   "XRC MSG EP connection protocol mismatch "
+			   "(local %"PRIu8", remote %"PRIu8")\n",
+			   FI_IBV_XRC_VERSION, remote->version);
+		return -FI_EINVAL;
+	}
+	return FI_SUCCESS;
+}
+
+void fi_ibv_log_ep_conn(struct fi_ibv_xrc_ep *ep, char *desc)
+{
+	struct sockaddr *addr;
+	char buf[OFI_ADDRSTRLEN];
+	size_t len = sizeof(buf);
+
+	if (!fi_log_enabled(&fi_ibv_prov, FI_LOG_INFO, FI_LOG_FABRIC))
+		return;
+
+	VERBS_INFO(FI_LOG_FABRIC, "EP %p, %s\n", ep, desc);
+	VERBS_INFO(FI_LOG_FABRIC,
+		  "EP %p, CM ID %p, TGT CM ID %p, SRQN %d Peer SRQN %d\n",
+		  ep, ep->base_ep.id, ep->tgt_id, ep->srqn, ep->peer_srqn);
+
+	assert(ep->base_ep.id);
+
+	addr = rdma_get_local_addr(ep->base_ep.id);
+	if (addr) {
+		ofi_straddr(buf, &len, ep->base_ep.info->addr_format, addr);
+		VERBS_INFO(FI_LOG_FABRIC, "EP %p src_addr: %s\n", ep, buf);
+	}
+	addr = rdma_get_peer_addr(ep->base_ep.id);
+	if (addr) {
+		len = sizeof(buf);
+		ofi_straddr(buf, &len, ep->base_ep.info->addr_format, addr);
+		VERBS_INFO(FI_LOG_FABRIC, "EP %p dst_addr: %s\n", ep, buf);
+	}
+
+	if (ep->base_ep.ibv_qp) {
+		VERBS_INFO(FI_LOG_FABRIC, "EP %p, INI QP Num %d\n",
+			  ep, ep->base_ep.ibv_qp->qp_num);
+		VERBS_INFO(FI_LOG_FABRIC, "EP %p, Remote TGT QP Num %d\n", ep,
+			  ep->ini_conn->tgt_qpn);
+	}
+	if (ep->tgt_ibv_qp)
+		VERBS_INFO(FI_LOG_FABRIC, "EP %p, TGT QP Num %d\n",
+			  ep, ep->tgt_ibv_qp->qp_num);
+	if (ep->conn_setup && ep->conn_setup->rsvd_ini_qpn)
+		VERBS_INFO(FI_LOG_FABRIC, "EP %p, Reserved INI QPN %d\n",
+			  ep, ep->conn_setup->rsvd_ini_qpn->qp_num);
+	if (ep->conn_setup && ep->conn_setup->rsvd_tgt_qpn)
+		VERBS_INFO(FI_LOG_FABRIC, "EP %p, Reserved TGT QPN %d\n",
+			  ep, ep->conn_setup->rsvd_tgt_qpn->qp_num);
+}
+
+void fi_ibv_free_xrc_conn_setup(struct fi_ibv_xrc_ep *ep)
+{
+	assert(ep->conn_setup);
+
+	if (ep->conn_setup->rsvd_ini_qpn)
+		ibv_destroy_qp(ep->conn_setup->rsvd_ini_qpn);
+	if (ep->conn_setup->rsvd_tgt_qpn)
+		ibv_destroy_qp(ep->conn_setup->rsvd_tgt_qpn);
+
+	free(ep->conn_setup);
+	ep->conn_setup = NULL;
+
+	/*Free RDMA CM IDs releasing their associated resources, RDMA CM
+	 * is used for connection setup only with XRC */
+	if (ep->base_ep.id) {
+		rdma_destroy_id(ep->base_ep.id);
+		ep->base_ep.id = NULL;
+	}
+	if (ep->tgt_id) {
+		rdma_destroy_id(ep->tgt_id);
+		ep->tgt_id = NULL;
+	}
+}
+
+int fi_ibv_connect_xrc(struct fi_ibv_xrc_ep *ep, struct sockaddr *addr,
+		       int reciprocal, void *param, size_t paramlen)
+{
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+	struct sockaddr *peer_addr;
+	int ret;
+
+	assert(ep->base_ep.id && !ep->base_ep.ibv_qp && !ep->ini_conn);
+
+	peer_addr = rdma_get_local_addr(ep->base_ep.id);
+	if (peer_addr)
+		ofi_straddr_dbg(&fi_ibv_prov, FI_LOG_FABRIC,
+				"XRC connect src_addr", peer_addr);
+
+	peer_addr = rdma_get_peer_addr(ep->base_ep.id);
+	if (peer_addr)
+		ofi_straddr_dbg(&fi_ibv_prov, FI_LOG_FABRIC,
+				"XRC connect dest_addr", peer_addr);
+
+	if (!reciprocal) {
+		ep->conn_setup = calloc(1, sizeof(*ep->conn_setup));
+		if (!ep->conn_setup)
+			return -FI_ENOMEM;
+	}
+
+	fastlock_acquire(&domain->xrc.ini_mgmt_lock);
+	ret = fi_ibv_get_shared_ini_conn(ep, &ep->ini_conn);
+	if (ret) {
+		VERBS_WARN(FI_LOG_FABRIC,
+			   "Get of shared XRC INI connection failed %d\n", ret);
+		fastlock_release(&domain->xrc.ini_mgmt_lock);
+		if (!reciprocal) {
+			free(ep->conn_setup);
+			ep->conn_setup = NULL;
+		}
+		return ret;
+	}
+	fi_ibv_add_pending_ini_conn(ep, reciprocal, param, paramlen);
+	fi_ibv_sched_ini_conn(ep->ini_conn);
+	fastlock_release(&domain->xrc.ini_mgmt_lock);
+
+	return FI_SUCCESS;
+}
+
+void fi_ibv_ep_ini_conn_done(struct fi_ibv_xrc_ep *ep, uint32_t peer_srqn,
+			     uint32_t tgt_qpn)
+{
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+
+	assert(ep->base_ep.id && ep->ini_conn);
+
+	fastlock_acquire(&domain->xrc.ini_mgmt_lock);
+
+	assert(ep->ini_conn->state == FI_IBV_INI_QP_CONNECTING ||
+	       ep->ini_conn->state == FI_IBV_INI_QP_CONNECTED);
+
+	/* If this was a physical INI/TGT QP connection, remove the QP
+	 * from control of the RDMA CM. We don't want the shared INI QP
+	 * to be destroyed if this endpoint closes. */
+	if (ep->base_ep.id->qp) {
+		ep->ini_conn->state = FI_IBV_INI_QP_CONNECTED;
+		ep->ini_conn->tgt_qpn = tgt_qpn;
+		ep->base_ep.id->qp = NULL;
+		VERBS_DBG(FI_LOG_EP_CTRL,
+			  "Set INI Conn QP %d remote TGT QP %d\n",
+			  ep->ini_conn->ini_qp->qp_num,
+			  ep->ini_conn->tgt_qpn);
+	}
+
+	fi_ibv_log_ep_conn(ep, "INI Connection Done");
+	fi_ibv_sched_ini_conn(ep->ini_conn);
+	fastlock_release(&domain->xrc.ini_mgmt_lock);
+}
+
+void fi_ibv_ep_ini_conn_rejected(struct fi_ibv_xrc_ep *ep)
+{
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+
+	assert(ep->base_ep.id && ep->ini_conn);
+
+	fastlock_acquire(&domain->xrc.ini_mgmt_lock);
+	fi_ibv_log_ep_conn(ep, "INI Connection Rejected");
+
+	fi_ibv_put_shared_ini_conn(ep);
+	fastlock_release(&domain->xrc.ini_mgmt_lock);
+}
+
+void fi_ibv_ep_tgt_conn_done(struct fi_ibv_xrc_ep *ep)
+{
+	fi_ibv_log_ep_conn(ep, "TGT Connection Done\n");
+
+	if (ep->tgt_id->qp) {
+		assert(ep->tgt_ibv_qp == ep->tgt_id->qp);
+		ep->tgt_id->qp = NULL;
+	}
+}
+
+int fi_ibv_accept_xrc(struct fi_ibv_xrc_ep *ep, int reciprocal,
+		      void *param, size_t paramlen)
+{
+	struct sockaddr *addr;
+	struct fi_ibv_connreq *connreq;
+	struct rdma_conn_param conn_param = { 0 };
+	struct fi_ibv_xrc_cm_data *cm_data = param;
+	int ret;
+
+	addr = rdma_get_local_addr(ep->tgt_id);
+	if (addr)
+		ofi_straddr_dbg(&fi_ibv_prov, FI_LOG_CORE, "src_addr", addr);
+
+	addr = rdma_get_peer_addr(ep->tgt_id);
+	if (addr)
+		ofi_straddr_dbg(&fi_ibv_prov, FI_LOG_CORE, "dest_addr", addr);
+
+	connreq = container_of(ep->base_ep.info->handle,
+			       struct fi_ibv_connreq, handle);
+	ret = fi_ibv_ep_create_tgt_qp(ep, connreq->xrc.conn_data);
+	if (ret)
+		return ret;
+
+	fi_ibv_set_xrc_cm_data(cm_data, connreq->xrc.is_reciprocal,
+			       connreq->xrc.conn_tag, connreq->xrc.port,
+			       ep->srqn);
+	conn_param.private_data = cm_data;
+	conn_param.private_data_len = paramlen;
+	conn_param.responder_resources = RDMA_MAX_RESP_RES;
+	conn_param.initiator_depth = RDMA_MAX_INIT_DEPTH;
+	conn_param.flow_control = 1;
+	conn_param.rnr_retry_count = 7;
+	if (ep->base_ep.srq_ep)
+		conn_param.srq = 1;
+
+	/* Shared INI/TGT QP connection use a temporarily reserved QP number
+	 * avoid the appearance of being a stale/duplicate IB CM message */
+	if (!ep->tgt_id->qp)
+		conn_param.qp_num = ep->conn_setup->rsvd_tgt_qpn->qp_num;
+
+	if (connreq->xrc.is_reciprocal)
+		fi_ibv_eq_clear_xrc_conn_tag(ep);
+	else
+		ep->conn_setup->conn_tag = connreq->xrc.conn_tag;
+
+	assert(ep->conn_state == FI_IBV_XRC_UNCONNECTED ||
+	       ep->conn_state == FI_IBV_XRC_ORIG_CONNECTED);
+	fi_ibv_next_xrc_conn_state(ep);
+
+	ret = rdma_accept(ep->tgt_id, &conn_param);
+	if (ret) {
+		ret = -errno;
+		VERBS_INFO_ERRNO(FI_LOG_EP_CTRL,
+				 "XRC TGT, ibv_open_qp", errno);
+		fi_ibv_prev_xrc_conn_state(ep);
+	}
+	free(connreq);
+	return ret;
+}
+
+int fi_ibv_process_xrc_connreq(struct fi_ibv_ep *ep,
+			       struct fi_ibv_connreq *connreq)
+{
+	struct fi_ibv_xrc_ep *xrc_ep = container_of(ep, struct fi_ibv_xrc_ep,
+						    base_ep);
+	int ret;
+
+	assert(ep->info->src_addr);
+	assert(ep->info->dest_addr);
+
+	xrc_ep->conn_setup = calloc(1, sizeof(*xrc_ep->conn_setup));
+	if (!xrc_ep->conn_setup)
+		return -FI_ENOMEM;
+
+	/* This endpoint was created on the passive side of a connection
+	 * request. The reciprocal connection request will go back to the
+	 * passive port indicated by the active side */
+	ofi_addr_set_port(ep->info->src_addr, 0);
+	ofi_addr_set_port(ep->info->dest_addr, connreq->xrc.port);
+
+	ret = fi_ibv_create_ep(NULL, NULL, 0, ep->info, NULL, &ep->id);
+	if (ret) {
+		VERBS_WARN(FI_LOG_EP_CTRL,
+			   "Creation of INI cm_id failed %d\n", ret);
+		goto create_err;
+	}
+	xrc_ep->tgt_id = connreq->id;
+	xrc_ep->tgt_id->context = &ep->util_ep.ep_fid.fid;
+
+	return FI_SUCCESS;
+
+create_err:
+	free(xrc_ep->conn_setup);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cq.c
index 2343da682..7522b4266 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_cq.c
@@ -87,9 +87,9 @@ fi_ibv_cq_readerr(struct fid_cq *cq_fid, struct fi_cq_err_entry *entry,
 	struct slist_entry *slist_entry;
 	uint32_t api_version;
 
-	cq = container_of(cq_fid, struct fi_ibv_cq, cq_fid);
+	cq = container_of(cq_fid, struct fi_ibv_cq, util_cq.cq_fid);
 
-	fastlock_acquire(&cq->lock);
+	cq->util_cq.cq_fastlock_acquire(&cq->util_cq.cq_lock);
 	if (slist_empty(&cq->wcq))
 		goto err;
 
@@ -97,10 +97,10 @@ fi_ibv_cq_readerr(struct fid_cq *cq_fid, struct fi_cq_err_entry *entry,
 	if (!wce->wc.status)
 		goto err;
 
-	api_version = cq->domain->util_domain.fabric->fabric_fid.api_version;
+	api_version = cq->util_cq.domain->fabric->fabric_fid.api_version;
 
 	slist_entry = slist_remove_head(&cq->wcq);
-	fastlock_release(&cq->lock);
+	cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
 
 	wce = container_of(slist_entry, struct fi_ibv_wce, entry);
 
@@ -120,9 +120,9 @@ fi_ibv_cq_readerr(struct fid_cq *cq_fid, struct fi_cq_err_entry *entry,
 	}
 
 	util_buf_release(cq->wce_pool, wce);
-	return sizeof(*entry);
+	return 1;
 err:
-	fastlock_release(&cq->lock);
+	cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
 	return -FI_EAGAIN;
 }
 
@@ -178,7 +178,7 @@ fi_ibv_cq_sread(struct fid_cq *cq, void *buf, size_t count, const void *cond,
 	uint8_t *p;
 
 	p = buf;
-	_cq = container_of(cq, struct fi_ibv_cq, cq_fid);
+	_cq = container_of(cq, struct fi_ibv_cq, util_cq.cq_fid);
 
 	if (!_cq->channel)
 		return -FI_ENOSYS;
@@ -193,7 +193,7 @@ fi_ibv_cq_sread(struct fid_cq *cq, void *buf, size_t count, const void *cond,
 				break;
 		}
 
-		ret = _cq->cq_fid.ops->read(&_cq->cq_fid, p, count - cur);
+		ret = _cq->util_cq.cq_fid.ops->read(&_cq->util_cq.cq_fid, p, count - cur);
 		if (ret > 0) {
 			p += ret * _cq->entry_size;
 			cur += ret;
@@ -207,86 +207,34 @@ fi_ibv_cq_sread(struct fid_cq *cq, void *buf, size_t count, const void *cond,
 	return cur ? cur : ret;
 }
 
-static void fi_ibv_cq_read_context_entry(struct ibv_wc *wc, int i, void *buf)
+static void fi_ibv_cq_read_context_entry(struct ibv_wc *wc, void *buf)
 {
 	struct fi_cq_entry *entry = buf;
 
-	entry[i].op_context = (void *)(uintptr_t)wc->wr_id;
+	entry->op_context = (void *)(uintptr_t)wc->wr_id;
 }
 
-static void fi_ibv_cq_read_msg_entry(struct ibv_wc *wc, int i, void *buf)
+static void fi_ibv_cq_read_msg_entry(struct ibv_wc *wc, void *buf)
 {
 	struct fi_cq_msg_entry *entry = buf;
 
-	entry[i].op_context = (void *)(uintptr_t)wc->wr_id;
-	fi_ibv_handle_wc(wc, &entry[i].flags, &entry[i].len, NULL);
+	entry->op_context = (void *)(uintptr_t)wc->wr_id;
+	fi_ibv_handle_wc(wc, &entry->flags, &entry->len, NULL);
 }
 
-static void fi_ibv_cq_read_data_entry(struct ibv_wc *wc, int i, void *buf)
+static void fi_ibv_cq_read_data_entry(struct ibv_wc *wc, void *buf)
 {
 	struct fi_cq_data_entry *entry = buf;
 
-	entry[i].op_context = (void *)(uintptr_t)wc->wr_id;
-	fi_ibv_handle_wc(wc, &entry[i].flags, &entry[i].len, &entry[i].data);
-}
-
-static int fi_ibv_match_ep_id(struct slist_entry *entry,
-			      const void *ep_id)
-{
-	struct fi_ibv_msg_epe *epe =
-		container_of(entry, struct fi_ibv_msg_epe, entry);
-
-	return (epe->ep->ep_id == (uint64_t)ep_id);
-}
-
-static inline int fi_ibv_handle_internal_signal_wc(struct fi_ibv_cq *cq,
-						   struct ibv_wc *wc)
-{
-	struct fi_ibv_msg_epe *epe;
-	struct slist_entry *entry;
-
-	entry = slist_remove_first_match(&cq->ep_list,
-					 fi_ibv_match_ep_id,
-					 (void *)wc->wr_id);
-	if (!entry) {
-		VERBS_WARN(FI_LOG_CQ, "No matching EP for :"
-			   "given signaled send completion\n");
-		return -FI_EOTHER;
-	}
-	epe = container_of(entry, struct fi_ibv_msg_epe, entry);
-	ofi_atomic_sub32(&epe->ep->unsignaled_send_cnt,
-			 epe->ep->send_signal_thr);
-	ofi_atomic_dec32(&epe->ep->comp_pending);
-	util_buf_release(cq->epe_pool, epe);
-
-	return FI_SUCCESS;
-}
-
-static inline int fi_ibv_wc_2_wce(struct fi_ibv_cq *cq,
-				  struct ibv_wc *wc,
-				  struct fi_ibv_wce **wce)
-
-{
-	struct fi_ibv_wre *wre =
-		(struct fi_ibv_wre *)(uintptr_t)wc->wr_id;
-
-	*wce = util_buf_alloc(cq->wce_pool);
-	if (!*wce)
-		return -FI_ENOMEM;
-	memset(*wce, 0, sizeof(**wce));
-	wc->wr_id = (uintptr_t)wre->context;
-	(*wce)->wc = *wc;
-
-	return FI_SUCCESS;
+	entry->op_context = (void *)(uintptr_t)wc->wr_id;
+	fi_ibv_handle_wc(wc, &entry->flags, &entry->len, &entry->data);
 }
 
 /* Must call with cq->lock held */
-static inline int fi_ibv_poll_outstanding_cq(struct fi_ibv_msg_ep *ep,
+static inline int fi_ibv_poll_outstanding_cq(struct fi_ibv_ep *ep,
 					     struct fi_ibv_cq *cq)
 {
-	struct fi_ibv_wre *wre;
 	struct fi_ibv_wce *wce;
-	struct util_buf_pool *wre_pool;
 	struct ibv_wc wc;
 	ssize_t ret;
 
@@ -294,145 +242,56 @@ static inline int fi_ibv_poll_outstanding_cq(struct fi_ibv_msg_ep *ep,
 	if (ret <= 0)
 		return ret;
 
-	if ((wc.opcode == IBV_WC_RECV) ||
-	    (wc.opcode == IBV_WC_RECV_RDMA_WITH_IMM) ||
-	    ((wc.wr_id & cq->wr_id_mask) != cq->send_signal_wr_id)) {
-		wre = (struct fi_ibv_wre *)(uintptr_t)wc.wr_id;
-		if (wre->ep) {
-			wre_pool = wre->ep->wre_pool;
-			if ((wre->ep != ep) &&
-			    (wc.status != IBV_WC_WR_FLUSH_ERR)) {
-				ret = fi_ibv_wc_2_wce(cq, &wc, &wce);
-				if (ret) {
-					wre->ep = NULL;
-					ret = -FI_EAGAIN;
-					goto fn;
-				}
-				slist_insert_tail(&wce->entry, &cq->wcq);
-			}
-			wre->ep = NULL;
-		} else {
-			/* WRE belongs to SRQ's wre pool and should be
-			 * handled or rejected if status == `IBV_WC_WR_FLUSH_ERR` */
-			assert(wre->srq);
-			wre_pool = wre->srq->wre_pool;
-			wre->srq = NULL;
-			if (wc.status != IBV_WC_WR_FLUSH_ERR) {
-				ret = fi_ibv_wc_2_wce(cq, &wc, &wce);
-				if (ret) {
-					ret = -FI_EAGAIN;
-					goto fn;
-				}
-				slist_insert_tail(&wce->entry, &cq->wcq);
-			}
-		}
-fn:
-		dlist_remove(&wre->entry);
-		util_buf_release(wre_pool, wre);
-		return ret;
-	} else {
-		ret = fi_ibv_handle_internal_signal_wc(cq, &wc);
-		return ret ? ret : 1;
+	/* Handle WR entry when user doesn't request the completion */
+	if (wc.wr_id == VERBS_NO_COMP_FLAG) {
+		/* To ensure the new iteration */
+		return 1;
 	}
-}
 
-/* Must call with `ep|srq::wre_lock` held */
-void fi_ibv_empty_wre_list(struct util_buf_pool *wre_pool,
-			   struct dlist_entry *wre_list,
-			   enum fi_ibv_wre_type wre_type)
-{
-	struct fi_ibv_wre *wre;
-	struct dlist_entry *tmp;
-
-	dlist_foreach_container_safe(wre_list, struct fi_ibv_wre,
-				     wre, entry, tmp) {
-		if (wre->wr_type == wre_type) {
-			dlist_remove(&wre->entry);
-			wre->ep = NULL;
-			wre->srq = NULL;
-			util_buf_release(wre_pool, wre);
+	if (OFI_LIKELY(wc.status != IBV_WC_WR_FLUSH_ERR)) {
+		ret = fi_ibv_wc_2_wce(cq, &wc, &wce);
+		if (OFI_UNLIKELY(ret)) {
+			ret = -FI_EAGAIN;
+			goto fn;
 		}
+		slist_insert_tail(&wce->entry, &cq->wcq);
 	}
+	ret = 1;
+fn:
+
+	return ret;
 }
 
-void fi_ibv_cleanup_cq(struct fi_ibv_msg_ep *ep)
+void fi_ibv_cleanup_cq(struct fi_ibv_ep *ep)
 {
 	int ret;
 
-	fastlock_acquire(&ep->rcq->lock);
+	ep->util_ep.rx_cq->cq_fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
 	do {
-		ret = fi_ibv_poll_outstanding_cq(ep, ep->rcq);
+		ret = fi_ibv_poll_outstanding_cq(ep, container_of(ep->util_ep.rx_cq,
+								  struct fi_ibv_cq, util_cq));
 	} while (ret > 0);
+	ep->util_ep.rx_cq->cq_fastlock_release(&ep->util_ep.rx_cq->cq_lock);
 
-	/* Handle WRs for which there were no appropriate WCs */
-	fastlock_acquire(&ep->wre_lock);
-	fi_ibv_empty_wre_list(ep->wre_pool, &ep->wre_list, IBV_RECV_WR);
-	fastlock_release(&ep->wre_lock);
-	fastlock_release(&ep->rcq->lock);
-
-	fastlock_acquire(&ep->scq->lock);
+	ep->util_ep.tx_cq->cq_fastlock_acquire(&ep->util_ep.tx_cq->cq_lock);
 	do {
-		ret = fi_ibv_poll_outstanding_cq(ep, ep->scq);
+		ret = fi_ibv_poll_outstanding_cq(ep, container_of(ep->util_ep.tx_cq,
+								  struct fi_ibv_cq, util_cq));
 	} while (ret > 0);
-	/* Handle WRs for which there were no appropriate WCs */
-	fastlock_acquire(&ep->wre_lock);
-	fi_ibv_empty_wre_list(ep->wre_pool, &ep->wre_list, IBV_SEND_WR);
-	fastlock_release(&ep->wre_lock);
-	fastlock_release(&ep->scq->lock);
-
-	fastlock_destroy(&ep->wre_lock);
-	util_buf_pool_destroy(ep->wre_pool);
+	ep->util_ep.tx_cq->cq_fastlock_release(&ep->util_ep.tx_cq->cq_lock);
 }
 
 /* Must call with cq->lock held */
+static inline
 ssize_t fi_ibv_poll_cq(struct fi_ibv_cq *cq, struct ibv_wc *wc)
 {
-	struct fi_ibv_wre *wre;
-	struct util_buf_pool *wre_pool;
-	fastlock_t *wre_lock;
 	ssize_t ret;
 
 	ret = ibv_poll_cq(cq->cq, 1, wc);
 	if (ret <= 0)
 		return ret;
 
-	/* TODO Handle the case when app posts a send with same wr_id */
-	if ((wc->opcode == IBV_WC_RECV) ||
-	    (wc->opcode == IBV_WC_RECV_RDMA_WITH_IMM) ||
-	    ((wc->wr_id & cq->wr_id_mask) != cq->send_signal_wr_id)) {
-		wre = (struct fi_ibv_wre *)(uintptr_t)wc->wr_id;
-		assert(wre && (wre->ep || wre->srq));
-		wc->wr_id = (uintptr_t)wre->context;
-
-		if (wc->status == IBV_WC_WR_FLUSH_ERR) {
-			/* Handles case where remote side destroys
-			 * the connection, but local side isn't aware
-			 * about that yet */
-			ret = 0;
-		}
-
-		if (wre->ep) {
-			wre_pool = wre->ep->wre_pool;
-			wre_lock = &wre->ep->wre_lock;
-			wre->ep = NULL;
-		} else if (wre->srq) {
-			wre_pool = wre->srq->wre_pool;
-			wre_lock = &wre->srq->wre_lock;
-			wre->srq = NULL;
-		} else {
-			assert(0);
-			return -FI_EAVAIL;
-		}
-
-		fastlock_acquire(wre_lock);
-		dlist_remove(&wre->entry);
- 		util_buf_release(wre_pool, wre);
-		fastlock_release(wre_lock);
-	} else {
-		return fi_ibv_handle_internal_signal_wc(cq, wc);
-	}
-
-	return ret;
+	return fi_ibv_process_wc_poll_new(cq, wc);
 }
 
 static ssize_t fi_ibv_cq_read(struct fid_cq *cq_fid, void *buf, size_t count)
@@ -443,9 +302,9 @@ static ssize_t fi_ibv_cq_read(struct fid_cq *cq_fid, void *buf, size_t count)
 	struct ibv_wc wc;
 	ssize_t ret = 0, i;
 
-	cq = container_of(cq_fid, struct fi_ibv_cq, cq_fid);
+	cq = container_of(cq_fid, struct fi_ibv_cq, util_cq.cq_fid);
 
-	fastlock_acquire(&cq->lock);
+	cq->util_cq.cq_fastlock_acquire(&cq->util_cq.cq_lock);
 
 	for (i = 0; i < count; i++) {
 		if (!slist_empty(&cq->wcq)) {
@@ -456,7 +315,7 @@ static ssize_t fi_ibv_cq_read(struct fid_cq *cq_fid, void *buf, size_t count)
 			}
 			entry = slist_remove_head(&cq->wcq);
 			wce = container_of(entry, struct fi_ibv_wce, entry);
-			cq->read_entry(&wce->wc, i, buf);
+			cq->read_entry(&wce->wc, (char *)buf + i * cq->entry_size);
 			util_buf_release(cq->wce_pool, wce);
 			continue;
 		}
@@ -466,10 +325,21 @@ static ssize_t fi_ibv_cq_read(struct fid_cq *cq_fid, void *buf, size_t count)
 			break;
 
 		/* Insert error entry into wcq */
-		if (wc.status) {
+		if (OFI_UNLIKELY(wc.status)) {
+			if (wc.status == IBV_WC_WR_FLUSH_ERR) {
+				/* Handle case when remote side destroys
+				 * the connection, but local side isn't aware
+				 * about that yet */
+				VERBS_DBG(FI_LOG_CQ,
+					  "Ignoring WC with status "
+					  "IBV_WC_WR_FLUSH_ERR(%d)\n",
+					  wc.status);
+				i--;
+				continue;
+			}
 			wce = util_buf_alloc(cq->wce_pool);
 			if (!wce) {
-				fastlock_release(&cq->lock);
+				cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
 				return -FI_ENOMEM;
 			}
 			memset(wce, 0, sizeof(*wce));
@@ -479,10 +349,10 @@ static ssize_t fi_ibv_cq_read(struct fid_cq *cq_fid, void *buf, size_t count)
 			break;
 		}
 
-		cq->read_entry(&wc, i, buf);
+		cq->read_entry(&wc, (char *)buf + i * cq->entry_size);
 	}
 
-	fastlock_release(&cq->lock);
+	cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
 	return i ? i : (ret ? ret : -FI_EAGAIN);
 }
 
@@ -500,7 +370,7 @@ int fi_ibv_cq_signal(struct fid_cq *cq)
 	struct fi_ibv_cq *_cq;
 	char data = '0';
 
-	_cq = container_of(cq, struct fi_ibv_cq, cq_fid);
+	_cq = container_of(cq, struct fi_ibv_cq, util_cq.cq_fid);
 
 	if (write(_cq->signal_fd[1], &data, 1) != 1) {
 		VERBS_WARN(FI_LOG_CQ, "Error signalling CQ\n");
@@ -517,14 +387,14 @@ static int fi_ibv_cq_trywait(struct fid *fid)
 	void *context;
 	int ret = -FI_EAGAIN, rc;
 
-	cq = container_of(fid, struct fi_ibv_cq, cq_fid.fid);
+	cq = container_of(fid, struct fi_ibv_cq, util_cq.cq_fid);
 
 	if (!cq->channel) {
 		VERBS_WARN(FI_LOG_CQ, "No wait object object associated with CQ\n");
 		return -FI_EINVAL;
 	}
 
-	fastlock_acquire(&cq->lock);
+	cq->util_cq.cq_fastlock_acquire(&cq->util_cq.cq_lock);
 	if (!slist_empty(&cq->wcq))
 		goto out;
 
@@ -567,7 +437,7 @@ static int fi_ibv_cq_trywait(struct fid *fid)
 err:
 	util_buf_release(cq->wce_pool, wce);
 out:
-	fastlock_release(&cq->lock);
+	cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
 	return ret;
 }
 
@@ -587,7 +457,7 @@ static int fi_ibv_cq_control(fid_t fid, int command, void *arg)
 	struct fi_ibv_cq *cq;
 	int ret = 0;
 
-	cq = container_of(fid, struct fi_ibv_cq, cq_fid.fid);
+	cq = container_of(fid, struct fi_ibv_cq, util_cq.cq_fid);
 	switch(command) {
 	case FI_GETWAIT:
 		if (!cq->channel) {
@@ -606,36 +476,41 @@ static int fi_ibv_cq_control(fid_t fid, int command, void *arg)
 
 static int fi_ibv_cq_close(fid_t fid)
 {
-	struct fi_ibv_cq *cq;
-	struct fi_ibv_msg_epe *epe;
 	struct fi_ibv_wce *wce;
 	struct slist_entry *entry;
 	int ret;
-
-	cq = container_of(fid, struct fi_ibv_cq, cq_fid.fid);
+	struct fi_ibv_cq *cq =
+		container_of(fid, struct fi_ibv_cq, util_cq.cq_fid);
+	struct fi_ibv_srq_ep *srq_ep;
+	struct dlist_entry *srq_ep_temp;
 
 	if (ofi_atomic_get32(&cq->nevents))
 		ibv_ack_cq_events(cq->cq, ofi_atomic_get32(&cq->nevents));
 
-	fastlock_acquire(&cq->lock);
+	/* Since an RX CQ and SRX context can be destroyed in any order,
+	 * and the XRC SRQ references the RX CQ, we must destroy any
+	 * XRC SRQ using this CQ before destroying the CQ. */
+	fastlock_acquire(&cq->xrc.srq_list_lock);
+	dlist_foreach_container_safe(&cq->xrc.srq_list, struct fi_ibv_srq_ep,
+				     srq_ep, xrc.srq_entry, srq_ep_temp) {
+		ret = fi_ibv_xrc_close_srq(srq_ep);
+		if (ret) {
+			fastlock_release(&cq->xrc.srq_list_lock);
+			return -ret;
+		}
+	}
+	fastlock_release(&cq->xrc.srq_list_lock);
+
+	cq->util_cq.cq_fastlock_acquire(&cq->util_cq.cq_lock);
 	while (!slist_empty(&cq->wcq)) {
 		entry = slist_remove_head(&cq->wcq);
 		wce = container_of(entry, struct fi_ibv_wce, entry);
 		util_buf_release(cq->wce_pool, wce);
 	}
+	cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
 
-	while (!slist_empty(&cq->ep_list)) {
-		entry = slist_remove_head(&cq->ep_list);
-		epe = container_of(entry, struct fi_ibv_msg_epe, entry);
-		util_buf_release(cq->epe_pool, epe);
-	}
-	fastlock_release(&cq->lock);
-
-	util_buf_pool_destroy(cq->epe_pool);
 	util_buf_pool_destroy(cq->wce_pool);
 
-	fastlock_destroy(&cq->lock);
-
 	if (cq->cq) {
 		ret = ibv_destroy_cq(cq->cq);
 		if (ret)
@@ -649,9 +524,12 @@ static int fi_ibv_cq_close(fid_t fid)
 		ofi_close_socket(cq->signal_fd[1]);
 	}
 
+	ofi_cq_cleanup(&cq->util_cq);
+
 	if (cq->channel)
 		ibv_destroy_comp_channel(cq->channel);
 
+	fastlock_destroy(&cq->xrc.srq_list_lock);
 	free(cq);
 	return 0;
 }
@@ -664,112 +542,111 @@ static struct fi_ops fi_ibv_cq_fi_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
-int fi_ibv_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
-		   struct fid_cq **cq, void *context)
+static void fi_ibv_util_cq_progress_noop(struct util_cq *cq)
 {
-	struct fi_ibv_cq *_cq;
-	int ep_cnt_bits = 0;
+	/* This routine shouldn't be called */
+	assert(0);
+}
+
+int fi_ibv_cq_open(struct fid_domain *domain_fid, struct fi_cq_attr *attr,
+		   struct fid_cq **cq_fid, void *context)
+{
+	struct fi_ibv_cq *cq;
+	struct fi_ibv_domain *domain =
+		container_of(domain_fid, struct fi_ibv_domain,
+			     util_domain.domain_fid);
 	size_t size;
 	int ret;
+	struct fi_cq_attr tmp_attr = *attr;
 
-	_cq = calloc(1, sizeof *_cq);
-	if (!_cq)
+	cq = calloc(1, sizeof(*cq));
+	if (!cq)
 		return -FI_ENOMEM;
 
-	_cq->domain = container_of(domain, struct fi_ibv_domain,
-				   util_domain.domain_fid);
-	/*
-	 * RDM and DGRAM CQ functionalities are moved to correspond
-	 * separated functions
-	 */
-	assert(_cq->domain->ep_type == FI_EP_MSG);
+	/* verbs uses its own implementation of wait objects for CQ */
+	tmp_attr.wait_obj = FI_WAIT_NONE;
+	ret = ofi_cq_init(&fi_ibv_prov, domain_fid, &tmp_attr, &cq->util_cq,
+			  fi_ibv_util_cq_progress_noop, context);
+	if (ret)
+		goto err1;
 
 	switch (attr->wait_obj) {
 	case FI_WAIT_UNSPEC:
 	case FI_WAIT_FD:
-		_cq->channel = ibv_create_comp_channel(_cq->domain->verbs);
-		if (!_cq->channel) {
+		cq->channel = ibv_create_comp_channel(domain->verbs);
+		if (!cq->channel) {
 			ret = -errno;
 			VERBS_WARN(FI_LOG_CQ,
 				   "Unable to create completion channel\n");
-			goto err1;
+			goto err2;
 		}
 
-		ret = fi_fd_nonblock(_cq->channel->fd);
+		ret = fi_fd_nonblock(cq->channel->fd);
 		if (ret)
-			goto err2;
+			goto err3;
 
-		if (socketpair(AF_UNIX, SOCK_STREAM, 0, _cq->signal_fd)) {
+		if (socketpair(AF_UNIX, SOCK_STREAM, 0, cq->signal_fd)) {
 			ret = -errno;
-			goto err2;
+			goto err3;
 		}
 
-		ret = fi_fd_nonblock(_cq->signal_fd[0]);
+		ret = fi_fd_nonblock(cq->signal_fd[0]);
 		if (ret)
-			goto err3;
+			goto err4;
 
 		break;
 	case FI_WAIT_NONE:
 		break;
 	default:
 		ret = -FI_ENOSYS;
-		goto err3;
+		goto err4;
 	}
 
 	size = attr->size ? attr->size : VERBS_DEF_CQ_SIZE;
 
-	_cq->cq = ibv_create_cq(_cq->domain->verbs, size, _cq, _cq->channel,
-			attr->signaling_vector);
-
-	if (!_cq->cq) {
+	cq->cq = ibv_create_cq(domain->verbs, size, cq, cq->channel,
+			       attr->signaling_vector);
+	if (!cq->cq) {
 		ret = -errno;
 		VERBS_WARN(FI_LOG_CQ, "Unable to create verbs CQ\n");
-		goto err3;
+		goto err4;
 	}
 
-	if (_cq->channel) {
-		ret = ibv_req_notify_cq(_cq->cq, 0);
+	if (cq->channel) {
+		ret = ibv_req_notify_cq(cq->cq, 0);
 		if (ret) {
 			VERBS_WARN(FI_LOG_CQ,
 				   "ibv_req_notify_cq failed\n");
-			goto err4;
+			goto err5;
 		}
 	}
 
-	ret = util_buf_pool_create(&_cq->wce_pool, sizeof(struct fi_ibv_wce),
+	ret = util_buf_pool_create(&cq->wce_pool, sizeof(struct fi_ibv_wce),
 				   16, 0, VERBS_WCE_CNT);
 	if (ret) {
 		VERBS_WARN(FI_LOG_CQ, "Failed to create wce_pool\n");
-		goto err4;
-	}
-
-	ret = util_buf_pool_create(&_cq->epe_pool, sizeof(struct fi_ibv_msg_epe),
-				   16, 0, VERBS_EPE_CNT);
-	if (ret) {
-		VERBS_WARN(FI_LOG_CQ, "Failed to create epe_pool\n");
 		goto err5;
 	}
 
-	_cq->flags |= attr->flags;
-	_cq->wait_cond = attr->wait_cond;
-	_cq->cq_fid.fid.fclass = FI_CLASS_CQ;
-	_cq->cq_fid.fid.context = context;
-	_cq->cq_fid.fid.ops = &fi_ibv_cq_fi_ops;
-	_cq->cq_fid.ops = &fi_ibv_cq_ops;
+	cq->flags |= attr->flags;
+	cq->wait_cond = attr->wait_cond;
+	/* verbs uses its own ops for CQ */
+	cq->util_cq.cq_fid.fid.ops = &fi_ibv_cq_fi_ops;
+	cq->util_cq.cq_fid.ops = &fi_ibv_cq_ops;
 
 	switch (attr->format) {
 	case FI_CQ_FORMAT_UNSPEC:
 	case FI_CQ_FORMAT_CONTEXT:
-		_cq->read_entry = fi_ibv_cq_read_context_entry;
-		_cq->entry_size = sizeof(struct fi_cq_entry);
+		cq->read_entry = fi_ibv_cq_read_context_entry;
+		cq->entry_size = sizeof(struct fi_cq_entry);
 		break;
 	case FI_CQ_FORMAT_MSG:
-		_cq->read_entry = fi_ibv_cq_read_msg_entry;
-		_cq->entry_size = sizeof(struct fi_cq_msg_entry);
+		cq->read_entry = fi_ibv_cq_read_msg_entry;
+		cq->entry_size = sizeof(struct fi_cq_msg_entry);
 		break;
 	case FI_CQ_FORMAT_DATA:
-		_cq->read_entry = fi_ibv_cq_read_data_entry;
-		_cq->entry_size = sizeof(struct fi_cq_data_entry);
+		cq->read_entry = fi_ibv_cq_read_data_entry;
+		cq->entry_size = sizeof(struct fi_cq_data_entry);
 		break;
 	case FI_CQ_FORMAT_TAGGED:
 	default:
@@ -777,34 +654,28 @@ int fi_ibv_cq_open(struct fid_domain *domain, struct fi_cq_attr *attr,
 		goto err6;
 	}
 
-	fastlock_init(&_cq->lock);
-
-	slist_init(&_cq->wcq);
-	slist_init(&_cq->ep_list);
-
-	while (_cq->domain->info->domain_attr->ep_cnt >> ++ep_cnt_bits);
+	slist_init(&cq->wcq);
+	dlist_init(&cq->xrc.srq_list);
+	fastlock_init(&cq->xrc.srq_list_lock);
 
-	_cq->send_signal_wr_id = 0xffffffffffffc0de << ep_cnt_bits;
-	_cq->wr_id_mask = (~_cq->wr_id_mask) << ep_cnt_bits;
+	cq->trywait = fi_ibv_cq_trywait;
+	ofi_atomic_initialize32(&cq->nevents, 0);
 
-	_cq->trywait = fi_ibv_cq_trywait;
-	ofi_atomic_initialize32(&_cq->nevents, 0);
-
-	*cq = &_cq->cq_fid;
+	*cq_fid = &cq->util_cq.cq_fid;
 	return 0;
 err6:
-	util_buf_pool_destroy(_cq->epe_pool);
+	util_buf_pool_destroy(cq->wce_pool);
 err5:
-	util_buf_pool_destroy(_cq->wce_pool);
+	ibv_destroy_cq(cq->cq);
 err4:
-	ibv_destroy_cq(_cq->cq);
+	ofi_close_socket(cq->signal_fd[0]);
+	ofi_close_socket(cq->signal_fd[1]);
 err3:
-	ofi_close_socket(_cq->signal_fd[0]);
-	ofi_close_socket(_cq->signal_fd[1]);
+	if (cq->channel)
+		ibv_destroy_comp_channel(cq->channel);
 err2:
-	if (_cq->channel)
-		ibv_destroy_comp_channel(_cq->channel);
+	ofi_cq_cleanup(&cq->util_cq);
 err1:
-	free(_cq);
+	free(cq);
 	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_dgram_av.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_dgram_av.c
new file mode 100644
index 000000000..71b1d5aab
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_dgram_av.c
@@ -0,0 +1,263 @@
+/*
+ * Copyright (c) 2017 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "fi_verbs.h"
+
+static inline int fi_ibv_dgram_av_is_addr_valid(struct fi_ibv_dgram_av *av,
+						const void *addr)
+{
+	const struct ofi_ib_ud_ep_name *check_name = addr;
+	return (check_name->lid > 0);
+}
+
+static inline int
+fi_ibv_dgram_verify_av_flags(struct util_av *av, uint64_t flags)
+{
+	if ((av->flags & FI_EVENT) && !av->eq) {
+		VERBS_WARN(FI_LOG_AV, "No EQ bound to AV\n");
+		return -FI_ENOEQ;
+	}
+
+	if (flags & ~(FI_MORE)) {
+		VERBS_WARN(FI_LOG_AV, "Unsupported flags\n");
+		return -FI_ENOEQ;
+	}
+
+	return FI_SUCCESS;
+}
+
+static int
+fi_ibv_dgram_av_insert_addr(struct fi_ibv_dgram_av *av, const void *addr,
+			    fi_addr_t *fi_addr, void *context)
+{
+	int ret;
+	struct fi_ibv_dgram_av_entry *av_entry;
+	struct fi_ibv_domain *domain =
+		container_of(av->util_av.domain, struct fi_ibv_domain, util_domain);
+
+	if (OFI_UNLIKELY(!fi_ibv_dgram_av_is_addr_valid(av, addr))) {
+		ret = -FI_EADDRNOTAVAIL;
+		VERBS_WARN(FI_LOG_AV, "Invalid address\n");
+		goto fn1;
+	}
+
+	struct ibv_ah_attr ah_attr = {
+		.is_global = 0,
+		.dlid = ((struct ofi_ib_ud_ep_name *)addr)->lid,
+		.sl = ((struct ofi_ib_ud_ep_name *)addr)->sl,
+		.src_path_bits = 0,
+		.port_num = 1,
+	};
+
+	if (((struct ofi_ib_ud_ep_name *)addr)->gid.global.interface_id) {
+		ah_attr.is_global = 1;
+		ah_attr.grh.hop_limit = 64;
+		ah_attr.grh.dgid = ((struct ofi_ib_ud_ep_name *)addr)->gid;
+		ah_attr.grh.sgid_index = 0;
+	}
+
+	av_entry = calloc(1, sizeof(*av_entry));
+	if (OFI_UNLIKELY(!av_entry)) {
+		ret = -FI_ENOMEM;
+		VERBS_WARN(FI_LOG_AV, "Unable to allocate memory for AV entry\n");
+		goto fn1;
+	}
+
+	av_entry->ah = ibv_create_ah(domain->pd, &ah_attr);
+	if (OFI_UNLIKELY(!av_entry->ah)) {
+		ret = -errno;
+		VERBS_WARN(FI_LOG_AV,
+			   "Unable to create Address Handle, errno - %d\n", errno);
+		goto fn2;
+	}
+	av_entry->addr = *(struct ofi_ib_ud_ep_name *)addr;
+	dlist_insert_tail(&av_entry->list_entry, &av->av_entry_list);
+
+	if (fi_addr)
+		*fi_addr = (fi_addr_t)(uintptr_t)av_entry;
+	return 0;
+fn2:
+	free(av_entry);
+fn1:
+	if (fi_addr)
+		*fi_addr = FI_ADDR_NOTAVAIL;
+	return ret;
+}
+
+static int fi_ibv_dgram_av_insert(struct fid_av *av_fid, const void *addr,
+				  size_t count, fi_addr_t *fi_addr,
+				  uint64_t flags, void *context)
+{
+	int ret, success_cnt = 0;
+	size_t i;
+	struct fi_ibv_dgram_av *av =
+		 container_of(av_fid, struct fi_ibv_dgram_av, util_av.av_fid);
+
+	ret = fi_ibv_dgram_verify_av_flags(&av->util_av, flags);
+	if (ret)
+		return ret;
+
+	VERBS_DBG(FI_LOG_AV, "Inserting %"PRIu64" addresses\n", count);
+	for (i = 0; i < count; i++) {
+		ret = fi_ibv_dgram_av_insert_addr(
+				av, (struct ofi_ib_ud_ep_name *)addr + i,
+				fi_addr ? &fi_addr[i] : NULL, context);
+		if (!ret)
+			success_cnt++;
+	}
+
+	VERBS_DBG(FI_LOG_AV,
+		  "%"PRIu64" addresses were inserted successfully\n", count);
+	return success_cnt;
+}
+
+static inline void
+fi_ibv_dgram_av_remove_addr(struct fi_ibv_dgram_av_entry *av_entry)
+{
+	int ret = ibv_destroy_ah(av_entry->ah);
+	if (ret)
+		VERBS_WARN(FI_LOG_AV,
+			   "AH Destroying failed with status - %d\n",
+			   ret);
+	dlist_remove(&av_entry->list_entry);
+	free(av_entry);
+}
+
+static int fi_ibv_dgram_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr,
+				  size_t count, uint64_t flags)
+{
+	int i, ret;
+	struct fi_ibv_dgram_av *av =
+		container_of(av_fid, struct fi_ibv_dgram_av, util_av.av_fid);
+
+	ret = fi_ibv_dgram_verify_av_flags(&av->util_av, flags);
+	if (ret)
+		return ret;
+
+	for (i = count - 1; i >= 0; i--) {
+		struct fi_ibv_dgram_av_entry *av_entry =
+			(struct fi_ibv_dgram_av_entry *)fi_addr[i];
+		fi_ibv_dgram_av_remove_addr(av_entry);
+	}
+	return FI_SUCCESS;
+}
+
+static inline
+int fi_ibv_dgram_av_lookup(struct fid_av *av_fid, fi_addr_t fi_addr,
+			   void *addr, size_t *addrlen)
+{
+	struct fi_ibv_dgram_av_entry *av_entry;
+
+	av_entry = fi_ibv_dgram_av_lookup_av_entry(fi_addr);
+	if (!av_entry)
+		return -FI_ENOENT;
+
+	memcpy(addr, &av_entry->addr, MIN(*addrlen, sizeof(av_entry->addr)));
+	*addrlen = sizeof(av_entry->addr);
+	return FI_SUCCESS;
+}
+
+static inline const char *
+fi_ibv_dgram_av_straddr(struct fid_av *av, const void *addr, char *buf, size_t *len)
+{
+	return ofi_straddr(buf, len, FI_ADDR_IB_UD, addr);
+}
+
+static int fi_ibv_dgram_av_close(struct fid *av_fid)
+{
+	struct fi_ibv_dgram_av_entry *av_entry;
+	struct fi_ibv_dgram_av *av =
+		container_of(av_fid, struct fi_ibv_dgram_av, util_av.av_fid.fid);
+	int ret = ofi_av_close_lightweight(&av->util_av);
+	if (ret)
+		return ret;
+
+	while (!dlist_empty(&av->av_entry_list)) {
+		av_entry = container_of(av->av_entry_list.next,
+					struct fi_ibv_dgram_av_entry,
+					list_entry);
+		fi_ibv_dgram_av_remove_addr(av_entry);
+	}
+
+	free(av);
+	return FI_SUCCESS;
+}
+
+static struct fi_ops fi_ibv_dgram_fi_ops = {
+	.size		= sizeof(fi_ibv_dgram_fi_ops),
+	.close		= fi_ibv_dgram_av_close,
+	.bind		= ofi_av_bind,
+	.control	= fi_no_control,
+	.ops_open	= fi_no_ops_open,
+};
+
+static struct fi_ops_av fi_ibv_dgram_av_ops = {
+	.size		= sizeof(fi_ibv_dgram_av_ops),
+	.insert		= fi_ibv_dgram_av_insert,
+	.insertsvc	= fi_no_av_insertsvc,
+	.insertsym	= fi_no_av_insertsym,
+	.remove		= fi_ibv_dgram_av_remove,
+	.lookup		= fi_ibv_dgram_av_lookup,
+	.straddr	= fi_ibv_dgram_av_straddr,
+};
+
+int fi_ibv_dgram_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
+			 struct fid_av **av_fid, void *context)
+{
+	struct fi_ibv_domain *domain =
+		container_of(domain_fid, struct fi_ibv_domain,
+			     util_domain.domain_fid);
+	struct fi_ibv_dgram_av *av;
+	int ret;
+
+	av = calloc(1, sizeof(*av));
+	if (!av)
+		return -FI_ENOMEM;
+
+	if (attr->type == FI_AV_UNSPEC)
+		attr->type = FI_AV_MAP;
+
+	ret = ofi_av_init_lightweight(&domain->util_domain, attr,
+				      &av->util_av, context);
+	if (ret)
+		goto err_av_init;
+	dlist_init(&av->av_entry_list);
+
+	av->util_av.av_fid.fid.ops = &fi_ibv_dgram_fi_ops;
+	av->util_av.av_fid.ops = &fi_ibv_dgram_av_ops;
+	*av_fid = &av->util_av.av_fid;
+
+	return FI_SUCCESS;
+err_av_init:
+	free(av);
+	return ret;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_dgram_ep_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_dgram_ep_msg.c
new file mode 100644
index 000000000..36ad816e5
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_dgram_ep_msg.c
@@ -0,0 +1,276 @@
+/*
+ * Copyright (c) 2017 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "fi_verbs.h"
+
+static inline int
+fi_ibv_dgram_ep_set_addr(struct fi_ibv_ep *ep, fi_addr_t addr,
+			 struct ibv_send_wr *wr)
+{
+	struct fi_ibv_dgram_av_entry *av_entry =
+			fi_ibv_dgram_av_lookup_av_entry(addr);
+	if (OFI_UNLIKELY(!av_entry))
+		return -FI_ENOENT;
+	wr->wr.ud.ah = av_entry->ah;
+	wr->wr.ud.remote_qpn = av_entry->addr.qpn;
+	wr->wr.ud.remote_qkey = 0x11111111;
+
+	return 0;
+}
+
+static inline ssize_t
+fi_ibv_dgram_ep_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+			uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_recv_wr wr = {
+		.wr_id = (uintptr_t)msg->context,
+		.num_sge = msg->iov_count,
+		.next = NULL,
+	};
+	struct ibv_recv_wr *bad_wr;
+
+	assert(ep->util_ep.rx_cq);
+
+	fi_ibv_set_sge_iov(wr.sg_list, msg->msg_iov, msg->iov_count, msg->desc);
+
+	return fi_ibv_handle_post(ibv_post_recv(ep->ibv_qp, &wr, &bad_wr));
+}
+
+static inline ssize_t
+fi_ibv_dgram_ep_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		      size_t count, fi_addr_t src_addr, void *context)
+{
+	struct fi_msg msg = {
+		.msg_iov	= iov,
+		.desc		= desc,
+		.iov_count	= count,
+		.addr		= src_addr,
+		.context	= context,
+	};
+
+	return fi_ibv_dgram_ep_recvmsg(ep_fid, &msg, 0);
+}
+
+static inline ssize_t
+fi_ibv_dgram_ep_recv(struct fid_ep *ep_fid, void *buf, size_t len,
+		     void *desc, fi_addr_t src_addr, void *context)
+{
+	struct iovec iov = {
+		.iov_base	= buf,
+		.iov_len	= len,
+	};
+
+	return fi_ibv_dgram_ep_recvv(ep_fid, &iov, &desc,
+				     1, src_addr, context);
+}
+
+static ssize_t
+fi_ibv_dgram_ep_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
+			uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)msg->context,
+	};
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		wr.opcode = IBV_WR_SEND_WITH_IMM;
+		wr.imm_data = htonl((uint32_t)msg->data);
+	} else {
+		wr.opcode = IBV_WR_SEND;
+	}
+
+	if (fi_ibv_dgram_ep_set_addr(ep, msg->addr, &wr))
+		return -FI_ENOENT;
+
+	return fi_ibv_send_msg(ep, &wr, msg, flags);
+}
+
+static inline ssize_t
+fi_ibv_dgram_ep_sendv(struct fid_ep *ep_fid, const struct iovec *iov,
+		      void **desc, size_t count, fi_addr_t dest_addr,
+		      void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)context,
+		.opcode = IBV_WR_SEND,
+	};
+
+	if (fi_ibv_dgram_ep_set_addr(ep, dest_addr, &wr))
+		return -FI_ENOENT;
+
+	return fi_ibv_send_iov(ep, &wr, iov, desc, count);
+}
+
+static ssize_t
+fi_ibv_dgram_ep_send(struct fid_ep *ep_fid, const void *buf, size_t len,
+		     void *desc, fi_addr_t dest_addr, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.opcode = IBV_WR_SEND,
+		.send_flags = VERBS_INJECT(ep, len),
+	};
+
+	if (fi_ibv_dgram_ep_set_addr(ep, dest_addr, &wr))
+		return -FI_ENOENT;
+
+	return fi_ibv_send_buf(ep, &wr, buf, len, desc);
+}
+
+static inline ssize_t
+fi_ibv_dgram_ep_senddata(struct fid_ep *ep_fid, const void *buf,
+			 size_t len, void *desc, uint64_t data,
+			 fi_addr_t dest_addr, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.opcode = IBV_WR_SEND_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.send_flags = VERBS_INJECT(ep, len),
+	};
+
+	if (fi_ibv_dgram_ep_set_addr(ep, dest_addr, &wr))
+		return -FI_ENOENT;
+
+	return fi_ibv_send_buf(ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_dgram_ep_injectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
+			   uint64_t data, fi_addr_t dest_addr)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_SEND_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	if (fi_ibv_dgram_ep_set_addr(ep, dest_addr, &wr))
+		return -FI_ENOENT;
+
+	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
+}
+
+static ssize_t
+fi_ibv_dgram_ep_injectdata_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+				uint64_t data, fi_addr_t dest_addr)
+{
+	ssize_t ret;
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+
+	ep->wrs->msg_wr.imm_data = htonl((uint32_t)data);
+	ep->wrs->msg_wr.opcode = IBV_WR_SEND_WITH_IMM;
+
+	ep->wrs->sge.addr = (uintptr_t) buf;
+	ep->wrs->sge.length = (uint32_t) len;
+
+	if (fi_ibv_dgram_ep_set_addr(ep, dest_addr, &ep->wrs->msg_wr))
+		return -FI_ENOENT;
+
+	ret = fi_ibv_send_poll_cq_if_needed(ep, &ep->wrs->msg_wr);
+	ep->wrs->msg_wr.opcode = IBV_WR_SEND;
+	return ret;
+}
+
+static ssize_t
+fi_ibv_dgram_ep_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
+		       fi_addr_t dest_addr)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_SEND,
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	if (fi_ibv_dgram_ep_set_addr(ep, dest_addr, &wr))
+		return -FI_ENOENT;
+
+	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
+}
+
+static ssize_t
+fi_ibv_dgram_ep_inject_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+			    fi_addr_t dest_addr)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+
+	ep->wrs->sge.addr = (uintptr_t) buf;
+	ep->wrs->sge.length = (uint32_t) len;
+
+	if (fi_ibv_dgram_ep_set_addr(ep, dest_addr, &ep->wrs->msg_wr))
+		return -FI_ENOENT;
+
+	return fi_ibv_send_poll_cq_if_needed(ep, &ep->wrs->msg_wr);
+}
+
+const struct fi_ops_msg fi_ibv_dgram_msg_ops = {
+	.size		= sizeof(fi_ibv_dgram_msg_ops),
+	.recv		= fi_ibv_dgram_ep_recv,
+	.recvv		= fi_ibv_dgram_ep_recvv,
+	.recvmsg	= fi_ibv_dgram_ep_recvmsg,
+	.send		= fi_ibv_dgram_ep_send,
+	.sendv		= fi_ibv_dgram_ep_sendv,
+	.sendmsg	= fi_ibv_dgram_ep_sendmsg,
+	.inject		= fi_ibv_dgram_ep_inject_fast,
+	.senddata	= fi_ibv_dgram_ep_senddata,
+	.injectdata	= fi_ibv_dgram_ep_injectdata_fast,
+};
+
+const struct fi_ops_msg fi_ibv_dgram_msg_ops_ts = {
+	.size		= sizeof(fi_ibv_dgram_msg_ops),
+	.recv		= fi_ibv_dgram_ep_recv,
+	.recvv		= fi_ibv_dgram_ep_recvv,
+	.recvmsg	= fi_ibv_dgram_ep_recvmsg,
+	.send		= fi_ibv_dgram_ep_send,
+	.sendv		= fi_ibv_dgram_ep_sendv,
+	.sendmsg	= fi_ibv_dgram_ep_sendmsg,
+	.inject		= fi_ibv_dgram_ep_inject,
+	.senddata	= fi_ibv_dgram_ep_senddata,
+	.injectdata	= fi_ibv_dgram_ep_injectdata,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_domain.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_domain.c
index 2b64379d3..6083935e9 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_domain.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_domain.c
@@ -32,8 +32,7 @@
 
 #include "config.h"
 
-#include "ep_rdm/verbs_rdm.h"
-#include "ep_dgram/verbs_dgram.h"
+#include "ofi_iov.h"
 
 #include "fi_verbs.h"
 #include <malloc.h>
@@ -45,7 +44,6 @@ static int fi_ibv_domain_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 {
 	struct fi_ibv_domain *domain;
 	struct fi_ibv_eq *eq;
-	struct fi_ibv_dgram_eq *dgram_eq;
 
 	domain = container_of(fid, struct fi_ibv_domain,
 			      util_domain.domain_fid.fid);
@@ -54,23 +52,19 @@ static int fi_ibv_domain_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 	case FI_CLASS_EQ:
 		switch (domain->ep_type) {
 		case FI_EP_MSG:
-		case FI_EP_RDM:
 			eq = container_of(bfid, struct fi_ibv_eq, eq_fid);
 			domain->eq = eq;
 			domain->eq_flags = flags;
 			break;
 		case FI_EP_DGRAM:
-			dgram_eq = container_of(bfid, struct fi_ibv_dgram_eq,
-						util_eq.eq_fid);
-			if (!dgram_eq)
-				return -FI_EINVAL;
-			return ofi_domain_bind_eq(&domain->util_domain,
-						  &dgram_eq->util_eq);
+			return -FI_EINVAL;
 		default:
 			/* Shouldn't go here */
 			assert(0);
 			return -FI_EINVAL;
 		}
+		break;
+
 	default:
 		return -EINVAL;
 	}
@@ -78,44 +72,43 @@ static int fi_ibv_domain_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 	return 0;
 }
 
-static void fi_ibv_rdm_cm_set_thread_affinity(void)
+void fi_ibv_mem_notifier_handle_hook(void *arg, RbtIterator iter)
 {
-	if (fi_ibv_gl_data.rdm.cm_thread_affinity == NULL)
-		return;
+	struct iovec *key;
+	struct fi_ibv_subscr_entry *subscr_entry;
+	struct fi_ibv_monitor_entry *entry;
+
+	rbtKeyValue(fi_ibv_mem_notifier->subscr_storage, iter,
+		    (void *)&key, (void *)&entry);
+	dlist_foreach_container(&entry->subscription_list, struct fi_ibv_subscr_entry,
+				subscr_entry, entry) {
+		ofi_monitor_add_event_to_nq(subscr_entry->subscription);
+	}
 
-	if (ofi_set_thread_affinity(fi_ibv_gl_data.rdm.cm_thread_affinity) == -FI_ENOSYS)
-		VERBS_WARN(FI_LOG_DOMAIN,
-			   "FI_VERBS_RDM_CM_THREAD_AFFINITY is not supported on OS X\n");
+	VERBS_DBG(FI_LOG_MR, "Write event for region %p:%lu\n",
+		  key->iov_base, key->iov_len);
 }
 
-static void *fi_ibv_rdm_cm_progress_thread(void *dom)
+static inline void
+fi_ibv_mem_notifier_search_iov(struct fi_ibv_mem_notifier *notifier,
+			       struct iovec *iov)
 {
-	struct fi_ibv_domain *domain =
-		(struct fi_ibv_domain *)dom;
-	struct slist_entry *item, *prev;
-
-	fi_ibv_rdm_cm_set_thread_affinity();
-
-	while (domain->rdm_cm->fi_ibv_rdm_tagged_cm_progress_running) {
-		struct fi_ibv_rdm_ep *ep = NULL;
-		slist_foreach(&domain->ep_list, item, prev) {
-			(void) prev;
-			ep = container_of(item, struct fi_ibv_rdm_ep,
-					  list_entry);
-			if (fi_ibv_rdm_cm_progress(ep)) {
-				VERBS_INFO(FI_LOG_EP_DATA,
-					   "fi_ibv_rdm_cm_progress error\n");
-				abort();
-			}
-		}
-		usleep(domain->rdm_cm->cm_progress_timeout);
+	RbtIterator iter;
+	iter = rbtFind(notifier->subscr_storage, (void *)iov);
+	if (iter) {
+		VERBS_DBG(FI_LOG_MR, "Catch hook for memory %p:%lu\n",
+			  iov->iov_base, iov->iov_len);
+		rbtTraversal(fi_ibv_mem_notifier->subscr_storage, iter, NULL,
+			     fi_ibv_mem_notifier_handle_hook);
 	}
-	return NULL;
 }
 
 void fi_ibv_mem_notifier_free_hook(void *ptr, const void *caller)
 {
-	struct fi_ibv_mem_ptr_entry *entry;
+	struct iovec iov = {
+		.iov_base = ptr,
+		.iov_len = malloc_usable_size(ptr),
+	};
 	OFI_UNUSED(caller);
 
 	FI_IBV_MEMORY_HOOK_BEGIN(fi_ibv_mem_notifier)
@@ -124,23 +117,17 @@ void fi_ibv_mem_notifier_free_hook(void *ptr, const void *caller)
 
 	if (!ptr)
 		goto out;
-
-	HASH_FIND(hh, fi_ibv_mem_notifier->mem_ptrs_hash, &ptr, sizeof(void *), entry);
-	if (!entry)
-		goto out;
-	VERBS_DBG(FI_LOG_MR, "Catch free hook for %p, entry - %p\n", ptr, entry);
-
-	if (!dlist_empty(&entry->entry))
-		dlist_remove_init(&entry->entry);
-	dlist_insert_tail(&entry->entry,
-			  &fi_ibv_mem_notifier->event_list);
+	fi_ibv_mem_notifier_search_iov(fi_ibv_mem_notifier, &iov);
 out:
 	FI_IBV_MEMORY_HOOK_END(fi_ibv_mem_notifier)
 }
 
 void *fi_ibv_mem_notifier_realloc_hook(void *ptr, size_t size, const void *caller)
 {
-	struct fi_ibv_mem_ptr_entry *entry;
+	struct iovec iov = {
+		.iov_base = ptr,
+		.iov_len = malloc_usable_size(ptr),
+	};
 	void *ret_ptr;
 	OFI_UNUSED(caller);
 
@@ -150,16 +137,7 @@ void *fi_ibv_mem_notifier_realloc_hook(void *ptr, size_t size, const void *calle
 
 	if (!ptr)
 		goto out;
-
-	HASH_FIND(hh, fi_ibv_mem_notifier->mem_ptrs_hash, &ptr, sizeof(void *), entry);
-	if (!entry)
-		goto out;
-	VERBS_DBG(FI_LOG_MR, "Catch realloc hook for %p, entry - %p\n", ptr, entry);
-
-	if (!dlist_empty(&entry->entry))
-		dlist_remove_init(&entry->entry);
-	dlist_insert_tail(&entry->entry,
-			  &fi_ibv_mem_notifier->event_list);
+	fi_ibv_mem_notifier_search_iov(fi_ibv_mem_notifier, &iov);
 out:
 	FI_IBV_MEMORY_HOOK_END(fi_ibv_mem_notifier)
 	return ret_ptr;
@@ -172,9 +150,9 @@ static void fi_ibv_mem_notifier_finalize(struct fi_ibv_mem_notifier *notifier)
 	assert(fi_ibv_mem_notifier && (notifier == fi_ibv_mem_notifier));
 	pthread_mutex_lock(&fi_ibv_mem_notifier->lock);
 	if (--fi_ibv_mem_notifier->ref_cnt == 0) {
-		fi_ibv_mem_notifier_set_free_hook(fi_ibv_mem_notifier->prev_free_hook);
-		fi_ibv_mem_notifier_set_realloc_hook(fi_ibv_mem_notifier->prev_realloc_hook);
-		util_buf_pool_destroy(fi_ibv_mem_notifier->mem_ptrs_ent_pool);
+		ofi_set_mem_free_hook(fi_ibv_mem_notifier->prev_free_hook);
+		ofi_set_mem_realloc_hook(fi_ibv_mem_notifier->prev_realloc_hook);
+		rbtDelete(fi_ibv_mem_notifier->subscr_storage);
 		fi_ibv_mem_notifier->prev_free_hook = NULL;
 		fi_ibv_mem_notifier->prev_realloc_hook = NULL;
 		pthread_mutex_unlock(&fi_ibv_mem_notifier->lock);
@@ -187,10 +165,35 @@ static void fi_ibv_mem_notifier_finalize(struct fi_ibv_mem_notifier *notifier)
 #endif
 }
 
+#ifdef HAVE_GLIBC_MALLOC_HOOKS
+static int fi_ibv_mem_notifier_find_within(void *a, void *b)
+{
+	struct iovec *iov1 = a, *iov2 = b;
+
+	if (ofi_iov_shifted_left(iov1, iov2))
+		return -1;
+	else if (ofi_iov_shifted_right(iov1, iov2))
+		return 1;
+	else
+		return 0;
+}
+
+static int fi_ibv_mem_notifier_find_overlap(void *a, void *b)
+{
+	struct iovec *iov1 = a, *iov2 = b;
+
+	if (ofi_iov_left(iov1, iov2))
+		return -1;
+	else if (ofi_iov_right(iov1, iov2))
+		return 1;
+	else
+		return 0;
+}
+#endif
+
 static struct fi_ibv_mem_notifier *fi_ibv_mem_notifier_init(void)
 {
 #ifdef HAVE_GLIBC_MALLOC_HOOKS
-	int ret;
 	pthread_mutexattr_t mutex_attr;
 	if (fi_ibv_mem_notifier) {
 		/* already initialized */
@@ -201,11 +204,11 @@ static struct fi_ibv_mem_notifier *fi_ibv_mem_notifier_init(void)
 	if (!fi_ibv_mem_notifier)
 		goto fn;
 
-	ret = util_buf_pool_create(&fi_ibv_mem_notifier->mem_ptrs_ent_pool,
-				   sizeof(struct fi_ibv_mem_ptr_entry),
-				   FI_IBV_MEM_ALIGNMENT, 0,
-				   fi_ibv_gl_data.mr_max_cached_cnt);
-	if (ret)
+	fi_ibv_mem_notifier->subscr_storage =
+		rbtNew(fi_ibv_gl_data.mr_cache_merge_regions ?
+		       fi_ibv_mem_notifier_find_overlap :
+		       fi_ibv_mem_notifier_find_within);
+	if (!fi_ibv_mem_notifier->subscr_storage)
 		goto err1;
 
 	pthread_mutexattr_init(&mutex_attr);
@@ -214,20 +217,18 @@ static struct fi_ibv_mem_notifier *fi_ibv_mem_notifier_init(void)
 		goto err2;
 	pthread_mutexattr_destroy(&mutex_attr);
 
-	dlist_init(&fi_ibv_mem_notifier->event_list);
-
 	pthread_mutex_lock(&fi_ibv_mem_notifier->lock);
-	fi_ibv_mem_notifier->prev_free_hook = fi_ibv_mem_notifier_get_free_hook();
-	fi_ibv_mem_notifier->prev_realloc_hook = fi_ibv_mem_notifier_get_realloc_hook();
-	fi_ibv_mem_notifier_set_free_hook(fi_ibv_mem_notifier_free_hook);
-	fi_ibv_mem_notifier_set_realloc_hook(fi_ibv_mem_notifier_realloc_hook);
+	fi_ibv_mem_notifier->prev_free_hook = ofi_get_mem_free_hook();
+	fi_ibv_mem_notifier->prev_realloc_hook = ofi_get_mem_realloc_hook();
+	ofi_set_mem_free_hook(fi_ibv_mem_notifier_free_hook);
+	ofi_set_mem_realloc_hook(fi_ibv_mem_notifier_realloc_hook);
 	fi_ibv_mem_notifier->ref_cnt++;
 	pthread_mutex_unlock(&fi_ibv_mem_notifier->lock);
 fn:
 	return fi_ibv_mem_notifier;
 
 err2:
-	util_buf_pool_destroy(fi_ibv_mem_notifier->mem_ptrs_ent_pool);
+	rbtDelete(fi_ibv_mem_notifier->subscr_storage);
 err1:
 	free(fi_ibv_mem_notifier);
 	fi_ibv_mem_notifier = NULL;
@@ -239,36 +240,13 @@ err1:
 
 static int fi_ibv_domain_close(fid_t fid)
 {
-	struct fi_ibv_domain *domain;
-	struct fi_ibv_fabric *fab;
-	struct fi_ibv_rdm_av_entry *av_entry = NULL;
-	struct slist_entry *item;
-	void *status = NULL;
 	int ret;
-
-	domain = container_of(fid, struct fi_ibv_domain,
-			      util_domain.domain_fid.fid);
+	struct fi_ibv_fabric *fab;
+	struct fi_ibv_domain *domain =
+		container_of(fid, struct fi_ibv_domain,
+			     util_domain.domain_fid.fid);
 
 	switch (domain->ep_type) {
-	case FI_EP_RDM:
-		domain->rdm_cm->fi_ibv_rdm_tagged_cm_progress_running = 0;
-		pthread_join(domain->rdm_cm->cm_progress_thread, &status);
-		pthread_mutex_destroy(&domain->rdm_cm->cm_lock);
-
-		for (item = slist_remove_head(
-				&domain->rdm_cm->av_removed_entry_head);
-	     	     item;
-	     	     item = slist_remove_head(
-				&domain->rdm_cm->av_removed_entry_head)) {
-			av_entry = container_of(item,
-						struct fi_ibv_rdm_av_entry,
-						removed_next);
-			fi_ibv_rdm_overall_conn_cleanup(av_entry);
-			ofi_freealign(av_entry);
-		}
-		rdma_destroy_ep(domain->rdm_cm->listener);
-		free(domain->rdm_cm);
-		break;
 	case FI_EP_DGRAM:
 		fab = container_of(&domain->util_domain.fabric->fabric_fid,
 				   struct fi_ibv_fabric,
@@ -280,6 +258,11 @@ static int fi_ibv_domain_close(fid_t fid)
 			ofi_ns_stop_server(&fab->name_server);
 		break;
 	case FI_EP_MSG:
+		if (domain->use_xrc) {
+			ret = fi_ibv_domain_xrc_cleanup(domain);
+			if (ret)
+				return ret;
+		}
 		break;
 	default:
 		/* Never should go here */
@@ -325,11 +308,9 @@ static int fi_ibv_open_device_by_name(struct fi_ibv_domain *domain, const char *
 		const char *rdma_name = ibv_get_device_name(dev_list[i]->device);
 		switch (domain->ep_type) {
 		case FI_EP_MSG:
-			ret = strcmp(name, rdma_name);
-			break;
-		case FI_EP_RDM:
-			ret = strncmp(name, rdma_name,
-				      strlen(name) - strlen(verbs_rdm_domain.suffix));
+			ret = domain->use_xrc ?
+				fi_ibv_cmp_xrc_domain_name(name, rdma_name) :
+				strcmp(name, rdma_name);
 			break;
 		case FI_EP_DGRAM:
 			ret = strncmp(name, rdma_name,
@@ -372,26 +353,12 @@ static struct fi_ops_domain fi_ibv_msg_domain_ops = {
 	.query_atomic = fi_ibv_query_atomic,
 };
 
-static struct fi_ops_domain fi_ibv_rdm_domain_ops = {
-	.size = sizeof(struct fi_ops_domain),
-	.av_open = fi_ibv_rdm_av_open,
-	.cq_open = fi_ibv_rdm_cq_open,
-	.endpoint = fi_ibv_rdm_open_ep,
-	.scalable_ep = fi_no_scalable_ep,
-	.cntr_open = fi_rbv_rdm_cntr_open,
-	.poll_open = fi_no_poll_open,
-	.stx_ctx = fi_no_stx_context,
-	.srx_ctx = fi_no_srx_context,
-	.query_atomic = fi_ibv_query_atomic,
-};
-
 static struct fi_ops_domain fi_ibv_dgram_domain_ops = {
 	.size = sizeof(struct fi_ops_domain),
 	.av_open = fi_ibv_dgram_av_open,
-	.cq_open = fi_ibv_dgram_cq_open,
-	.endpoint = fi_ibv_dgram_endpoint_open,
+	.cq_open = fi_ibv_cq_open,
+	.endpoint = fi_ibv_open_ep,
 	.scalable_ep = fi_no_scalable_ep,
-	.cntr_open = fi_ibv_dgram_cntr_open,
 	.poll_open = fi_no_poll_open,
 	.stx_ctx = fi_no_stx_context,
 	.srx_ctx = fi_no_srx_context,
@@ -423,17 +390,12 @@ fi_ibv_domain(struct fid_fabric *fabric, struct fi_info *info,
 	      struct fid_domain **domain, void *context)
 {
 	struct fi_ibv_domain *_domain;
-	struct fi_ibv_fabric *fab;
-	const struct fi_info *fi;
-	void *status = NULL;
-	pthread_mutexattr_t mutex_attr;
 	int ret;
-
-	fab = container_of(fabric, struct fi_ibv_fabric,
-			   util_fabric.fabric_fid);
-
-	fi = fi_ibv_get_verbs_info(fi_ibv_util_prov.info,
-				   info->domain_attr->name);
+	struct fi_ibv_fabric *fab =
+		 container_of(fabric, struct fi_ibv_fabric,
+			      util_fabric.fabric_fid);
+	const struct fi_info *fi = fi_ibv_get_verbs_info(fi_ibv_util_prov.info,
+							 info->domain_attr->name);
 	if (!fi)
 		return -FI_EINVAL;
 
@@ -455,9 +417,12 @@ fi_ibv_domain(struct fid_fabric *fabric, struct fi_info *info,
 		goto err2;
 
 	_domain->ep_type = FI_IBV_EP_TYPE(info);
+	_domain->use_xrc = fi_ibv_is_xrc(info);
+
 	ret = fi_ibv_open_device_by_name(_domain, info->domain_attr->name);
 	if (ret)
 		goto err3;
+
 	_domain->pd = ibv_alloc_pd(_domain->verbs);
 	if (!_domain->pd) {
 		ret = -errno;
@@ -474,7 +439,6 @@ fi_ibv_domain(struct fid_fabric *fabric, struct fi_info *info,
 		_domain->notifier = fi_ibv_mem_notifier_init();
 		_domain->monitor.subscribe = fi_ibv_monitor_subscribe;
 		_domain->monitor.unsubscribe = fi_ibv_monitor_unsubscribe;
-		_domain->monitor.get_event = fi_ibv_monitor_get_event;
 		ofi_monitor_init(&_domain->monitor);
 
 		_domain->cache.max_cached_cnt = fi_ibv_gl_data.mr_max_cached_cnt;
@@ -497,57 +461,6 @@ fi_ibv_domain(struct fid_fabric *fabric, struct fi_info *info,
 	}
 
 	switch (_domain->ep_type) {
-	case FI_EP_RDM:
-		_domain->rdm_cm = calloc(1, sizeof(*_domain->rdm_cm));
-		if (!_domain->rdm_cm) {
-			ret = -FI_ENOMEM;
-			goto err5;
-		}
-		_domain->rdm_cm->cm_progress_timeout =
-			fi_ibv_gl_data.rdm.thread_timeout;
-		slist_init(&_domain->rdm_cm->av_removed_entry_head);
-
-		pthread_mutexattr_init(&mutex_attr);
-		pthread_mutexattr_settype(&mutex_attr, PTHREAD_MUTEX_RECURSIVE);
-		pthread_mutex_init(&_domain->rdm_cm->cm_lock, &mutex_attr);
-		pthread_mutexattr_destroy(&mutex_attr);
-		_domain->rdm_cm->fi_ibv_rdm_tagged_cm_progress_running = 1;
-		ret = pthread_create(&_domain->rdm_cm->cm_progress_thread,
-				     NULL, &fi_ibv_rdm_cm_progress_thread,
-				     (void *)_domain);
-		if (ret) {
-			VERBS_INFO(FI_LOG_DOMAIN,
-				   "Failed to launch CM progress thread, "
-				   "err :%d\n", ret);
-			ret = -FI_EOTHER;
-			goto err6;
-		}
-		_domain->util_domain.domain_fid.ops = &fi_ibv_rdm_domain_ops;
-
-		_domain->rdm_cm->ec = rdma_create_event_channel();
-		if (!_domain->rdm_cm->ec) {
-			VERBS_INFO(FI_LOG_DOMAIN,
-				   "Failed to create listener event channel: %s\n",
-				   strerror(errno));
-			ret = -FI_EOTHER;
-			goto err7;
-		}
-
-		if (fi_fd_nonblock(_domain->rdm_cm->ec->fd) != 0) {
-			VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "fcntl", errno);
-			ret = -FI_EOTHER;
-			goto err8;
-		}
-
-		if (rdma_create_id(_domain->rdm_cm->ec,
-				   &_domain->rdm_cm->listener, NULL, RDMA_PS_TCP)) {
-			VERBS_INFO(FI_LOG_DOMAIN, "Failed to create cm listener: %s\n",
-				   strerror(errno));
-			ret = -FI_EOTHER;
-			goto err8;
-		}
-		_domain->rdm_cm->is_bound = 0;
-		break;
 	case FI_EP_DGRAM:
 		if (fi_ibv_gl_data.dgram.use_name_server) {
 			/* Even if it's invoked not for the first time
@@ -567,26 +480,22 @@ fi_ibv_domain(struct fid_fabric *fabric, struct fi_info *info,
 		_domain->util_domain.domain_fid.ops = &fi_ibv_dgram_domain_ops;
 		break;
 	case FI_EP_MSG:
+		if (_domain->use_xrc) {
+			ret = fi_ibv_domain_xrc_init(_domain);
+			if (ret)
+				goto err5;
+		}
 		_domain->util_domain.domain_fid.ops = &fi_ibv_msg_domain_ops;
 		break;
 	default:
 		VERBS_INFO(FI_LOG_DOMAIN, "Ivalid EP type is provided, "
 			   "EP type :%d\n", _domain->ep_type);
 		ret = -FI_EINVAL;
-		goto err5;
+		goto err3;
 	}
 
 	*domain = &_domain->util_domain.domain_fid;
 	return FI_SUCCESS;
-/* Only verbs/RDM should be able to go through err[5-7] */
-err8:
-	rdma_destroy_event_channel(_domain->rdm_cm->ec);
-err7:
-	_domain->rdm_cm->fi_ibv_rdm_tagged_cm_progress_running = 0;
-	pthread_join(_domain->rdm_cm->cm_progress_thread, &status);
-err6:
-	pthread_mutex_destroy(&_domain->rdm_cm->cm_lock);
-	free(_domain->rdm_cm);
 err5:
 	if (fi_ibv_gl_data.mr_cache_enable)
 		ofi_mr_cache_cleanup(&_domain->cache);
@@ -615,7 +524,7 @@ static int fi_ibv_trywait(struct fid_fabric *fabric, struct fid **fids, int coun
 	for (i = 0; i < count; i++) {
 		switch (fids[i]->fclass) {
 		case FI_CLASS_CQ:
-			cq = container_of(fids[i], struct fi_ibv_cq, cq_fid.fid);
+			cq = container_of(fids[i], struct fi_ibv_cq, util_cq.cq_fid.fid);
 			ret = cq->trywait(fids[i]);
 			if (ret)
 				return ret;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_domain_xrc.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_domain_xrc.c
new file mode 100644
index 000000000..3d7de4b1d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_domain_xrc.c
@@ -0,0 +1,564 @@
+/*
+ * Copyright (c) 2018 Cray Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+#include "config.h"
+#include "fi_verbs.h"
+
+/* Domain XRC INI QP RBTree key */
+struct fi_ibv_ini_conn_key {
+	struct sockaddr		*addr;
+	struct fi_ibv_cq	*tx_cq;
+};
+
+static int fi_ibv_process_ini_conn(struct fi_ibv_xrc_ep *ep,int reciprocal,
+				   void *param, size_t paramlen);
+
+/*
+ * This routine is a work around that creates a QP for the only purpose of
+ * reserving the QP number. The QP is not transitioned out of the RESET state.
+ */
+int fi_ibv_reserve_qpn(struct fi_ibv_xrc_ep *ep, struct ibv_qp **qp)
+{
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+	struct fi_ibv_cq *cq = container_of(ep->base_ep.util_ep.tx_cq,
+					    struct fi_ibv_cq, util_cq);
+	struct ibv_qp_init_attr attr = { 0 };
+	int ret;
+
+	/* Limit library allocated resources and do not INIT QP */
+	attr.cap.max_send_wr = 1;
+	attr.cap.max_send_sge = 1;
+	attr.cap.max_recv_wr = 0;
+	attr.cap.max_recv_sge = 0;
+	attr.cap.max_inline_data = 0;
+	attr.send_cq = cq->cq;
+	attr.recv_cq = cq->cq;
+	attr.qp_type = IBV_QPT_RC;
+
+	*qp = ibv_create_qp(domain->pd, &attr);
+	if (!*qp) {
+		ret = -errno;
+		VERBS_INFO_ERRNO(FI_LOG_EP_CTRL,
+				 "Reservation QP create failed", ret);
+	}
+	return FI_SUCCESS;
+}
+
+static int fi_ibv_create_ini_qp(struct fi_ibv_xrc_ep *ep)
+{
+#if VERBS_HAVE_XRC
+	struct ibv_qp_init_attr_ex attr_ex;
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+	int ret;
+
+	fi_ibv_msg_ep_get_qp_attr(&ep->base_ep,
+			(struct ibv_qp_init_attr *)&attr_ex);
+	attr_ex.qp_type = IBV_QPT_XRC_SEND;
+	attr_ex.comp_mask = IBV_QP_INIT_ATTR_PD;
+	attr_ex.pd = domain->pd;
+	attr_ex.qp_context = domain;
+
+	ret = rdma_create_qp_ex(ep->base_ep.id, &attr_ex);
+	if (ret) {
+		ret = -errno;
+		VERBS_INFO_ERRNO(FI_LOG_EP_CTRL,
+				 "XRC INI QP, rdma_create_qp_ex()", -ret);
+		return ret;
+	}
+	return FI_SUCCESS;
+#else /* VERBS_HAVE_XRC */
+	return -FI_ENOSYS;
+#endif /* !VERBS_HAVE_XRC */
+}
+
+static inline void fi_ibv_set_ini_conn_key(struct fi_ibv_xrc_ep *ep,
+					   struct fi_ibv_ini_conn_key *key)
+{
+	key->addr = ep->base_ep.info->dest_addr;
+	key->tx_cq = container_of(ep->base_ep.util_ep.tx_cq,
+				  struct fi_ibv_cq, util_cq);
+}
+
+/* Caller must hold domain:xrc:ini_mgmt_lock */
+int fi_ibv_get_shared_ini_conn(struct fi_ibv_xrc_ep *ep,
+			       struct fi_ibv_ini_shared_conn **ini_conn) {
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+	struct fi_ibv_ini_conn_key key;
+	struct fi_ibv_ini_shared_conn *conn;
+	struct ofi_rbnode *node;
+	int ret;
+	assert(ep->base_ep.id);
+
+	fi_ibv_set_ini_conn_key(ep, &key);
+	node = ofi_rbmap_find(domain->xrc.ini_conn_rbmap, &key);
+	if (node) {
+		*ini_conn = node->data;
+		ofi_atomic_inc32(&(*ini_conn)->ref_cnt);
+		return FI_SUCCESS;
+	}
+
+	*ini_conn = NULL;
+	conn = calloc(1, sizeof(*conn));
+	if (!conn)
+		return -FI_ENOMEM;
+
+	conn->tgt_qpn = FI_IBV_NO_INI_TGT_QPNUM;
+	conn->peer_addr = mem_dup(key.addr, ofi_sizeofaddr(key.addr));
+	if (!conn->peer_addr) {
+		free(conn);
+		return -FI_ENOMEM;
+	}
+	conn->tx_cq = container_of(ep->base_ep.util_ep.tx_cq,
+				   struct fi_ibv_cq, util_cq);
+	dlist_init(&conn->pending_list);
+	dlist_init(&conn->active_list);
+	ofi_atomic_initialize32(&conn->ref_cnt, 1);
+
+	ret = ofi_rbmap_insert(domain->xrc.ini_conn_rbmap,
+			       (void *) &key, (void *) conn);
+	assert(ret != -FI_EALREADY);
+	if (ret) {
+		VERBS_WARN(FI_LOG_FABRIC, "INI QP RBTree insert failed %d\n",
+			   ret);
+		goto insert_err;
+	}
+	*ini_conn = conn;
+	return FI_SUCCESS;
+
+insert_err:
+	free(conn->peer_addr);
+	free(conn);
+	return ret;
+}
+
+/* Caller must hold domain:xrc:ini_mgmt_lock */
+void fi_ibv_put_shared_ini_conn(struct fi_ibv_xrc_ep *ep)
+{
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+	struct fi_ibv_ini_shared_conn *ini_conn;
+	struct fi_ibv_ini_conn_key key;
+	struct ofi_rbnode *node;
+
+	if (!ep->ini_conn)
+		return;
+
+	/* remove from pending or active connection list */
+	dlist_remove(&ep->ini_conn_entry);
+	ep->conn_state = FI_IBV_XRC_UNCONNECTED;
+	ini_conn = ep->ini_conn;
+	ep->ini_conn = NULL;
+	ep->base_ep.ibv_qp = NULL;
+
+	/* Tear down physical INI/TGT when no longer being used */
+	if (!ofi_atomic_dec32(&ini_conn->ref_cnt)) {
+		if (ini_conn->ini_qp && ibv_destroy_qp(ini_conn->ini_qp))
+			VERBS_WARN(FI_LOG_FABRIC, "destroy of QP error %d\n",
+				   errno);
+
+		fi_ibv_set_ini_conn_key(ep, &key);
+		node = ofi_rbmap_find(domain->xrc.ini_conn_rbmap, &key);
+		assert(node);
+		ofi_rbmap_delete(domain->xrc.ini_conn_rbmap, node);
+		free(ini_conn->peer_addr);
+		free(ini_conn);
+	} else {
+		fi_ibv_sched_ini_conn(ini_conn);
+	}
+}
+
+/* Caller must hold domain:xrc:ini_mgmt_lock */
+void fi_ibv_add_pending_ini_conn(struct fi_ibv_xrc_ep *ep, int reciprocal,
+				 void *conn_param, size_t conn_paramlen)
+{
+	ep->conn_setup->pending_recip = reciprocal;
+	ep->conn_setup->pending_paramlen = MIN(conn_paramlen,
+				sizeof(ep->conn_setup->pending_param));
+	memcpy(ep->conn_setup->pending_param, conn_param,
+	       ep->conn_setup->pending_paramlen);
+	dlist_insert_tail(&ep->ini_conn_entry, &ep->ini_conn->pending_list);
+}
+
+static void fi_ibv_create_shutdown_event(struct fi_ibv_xrc_ep *ep)
+{
+	struct fi_eq_cm_entry entry = {
+		.fid = &ep->base_ep.util_ep.ep_fid.fid,
+	};
+
+	fi_ibv_eq_write_event(ep->base_ep.eq, FI_SHUTDOWN,
+			      &entry, sizeof(entry));
+}
+
+/* Caller must hold domain:xrc:ini_mgmt_lock */
+void fi_ibv_sched_ini_conn(struct fi_ibv_ini_shared_conn *ini_conn)
+{
+	struct fi_ibv_xrc_ep *ep;
+	enum fi_ibv_ini_qp_state last_state;
+	int ret;
+
+	/* Continue to schedule shared connections if the physical connection
+	 * has completed and there are connection requests pending. We could
+	 * implement a throttle here if it is determined that it is better to
+	 * limit the number of outstanding connections. */
+	while (1) {
+		if (dlist_empty(&ini_conn->pending_list) ||
+				ini_conn->state == FI_IBV_INI_QP_CONNECTING)
+			return;
+
+		dlist_pop_front(&ini_conn->pending_list,
+				struct fi_ibv_xrc_ep, ep, ini_conn_entry);
+
+		dlist_insert_tail(&ep->ini_conn_entry,
+				  &ep->ini_conn->active_list);
+		last_state = ep->ini_conn->state;
+		if (last_state == FI_IBV_INI_QP_UNCONNECTED) {
+			ret = fi_ibv_create_ini_qp(ep);
+			if (ret) {
+				VERBS_WARN(FI_LOG_FABRIC, "Failed to create "
+					   "physical INI QP %d\n", ret);
+				goto err;
+			}
+			ep->ini_conn->ini_qp = ep->base_ep.id->qp;
+			ep->ini_conn->state = FI_IBV_INI_QP_CONNECTING;
+		} else {
+			if (!ep->base_ep.id->qp) {
+				ret = fi_ibv_reserve_qpn(ep,
+						 &ep->conn_setup->rsvd_ini_qpn);
+				if (ret) {
+					VERBS_WARN(FI_LOG_FABRIC, "rsvd_ini_qpn"
+						  " create err %d\n", ret);
+					goto err;
+				}
+			}
+		}
+
+		assert(ep->ini_conn->ini_qp);
+
+		ep->base_ep.ibv_qp = ep->ini_conn->ini_qp;
+		ret = fi_ibv_process_ini_conn(ep, ep->conn_setup->pending_recip,
+					      ep->conn_setup->pending_param,
+					      ep->conn_setup->pending_paramlen);
+err:
+		if (ret) {
+			ep->ini_conn->state = last_state;
+			fi_ibv_put_shared_ini_conn(ep);
+
+			/* We need to let the application know that the
+			 * connect request has failed. */
+			fi_ibv_create_shutdown_event(ep);
+		}
+	}
+}
+
+/* Caller must hold domain:xrc:ini_mgmt_lock */
+int fi_ibv_process_ini_conn(struct fi_ibv_xrc_ep *ep,int reciprocal,
+			    void *param, size_t paramlen)
+{
+	struct fi_ibv_xrc_cm_data *cm_data = param;
+	struct rdma_conn_param conn_param = { 0 };
+	int ret;
+
+	assert(ep->base_ep.ibv_qp);
+
+	if (!reciprocal)
+		fi_ibv_eq_set_xrc_conn_tag(ep);
+
+	fi_ibv_set_xrc_cm_data(cm_data, reciprocal, ep->conn_setup->conn_tag,
+			       ep->base_ep.eq->xrc.pep_port,
+			       ep->ini_conn->tgt_qpn);
+	conn_param.private_data = cm_data;
+	conn_param.private_data_len = paramlen;
+	conn_param.responder_resources = RDMA_MAX_RESP_RES;
+	conn_param.initiator_depth = RDMA_MAX_INIT_DEPTH;
+	conn_param.flow_control = 1;
+	conn_param.retry_count = 15;
+	conn_param.rnr_retry_count = 7;
+	conn_param.srq = 1;
+
+	/* Shared connections use reserved temporary QP numbers to
+	 * avoid the appearance of stale/duplicate CM messages */
+	if (!ep->base_ep.id->qp)
+		conn_param.qp_num = ep->conn_setup->rsvd_ini_qpn->qp_num;
+
+	assert(ep->conn_state == FI_IBV_XRC_UNCONNECTED ||
+	       ep->conn_state == FI_IBV_XRC_ORIG_CONNECTED);
+	fi_ibv_next_xrc_conn_state(ep);
+
+	ret = rdma_connect(ep->base_ep.id, &conn_param) ? -errno : 0;
+	if (ret) {
+		ret = -errno;
+		VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_connect", errno);
+		fi_ibv_prev_xrc_conn_state(ep);
+	}
+	return ret;
+}
+
+int fi_ibv_ep_create_tgt_qp(struct fi_ibv_xrc_ep *ep, uint32_t tgt_qpn)
+{
+#if VERBS_HAVE_XRC
+	struct ibv_qp_open_attr open_attr;
+	struct ibv_qp_init_attr_ex attr_ex;
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+	struct ibv_qp *rsvd_qpn;
+	int ret;
+
+	assert(ep->tgt_id && !ep->tgt_id->qp);
+
+	/* If a target QP number was specified then open that existing
+	 * QP for sharing. */
+	if (tgt_qpn) {
+		ret = fi_ibv_reserve_qpn(ep, &rsvd_qpn);
+		if (!rsvd_qpn) {
+			VERBS_WARN(FI_LOG_FABRIC,
+				   "Create of XRC reserved QPN failed %d\n",
+				   ret);
+			return ret;
+		}
+
+		memset(&open_attr, 0, sizeof(open_attr));
+		open_attr.qp_num = tgt_qpn;
+		open_attr.comp_mask = IBV_QP_OPEN_ATTR_NUM |
+			IBV_QP_OPEN_ATTR_XRCD | IBV_QP_OPEN_ATTR_TYPE |
+			IBV_QP_OPEN_ATTR_CONTEXT;
+		open_attr.xrcd = domain->xrc.xrcd;
+		open_attr.qp_type = IBV_QPT_XRC_RECV;
+		open_attr.qp_context = ep;
+
+		ep->tgt_ibv_qp = ibv_open_qp(domain->verbs, &open_attr);
+		if (!ep->tgt_ibv_qp) {
+			VERBS_INFO_ERRNO(FI_LOG_EP_CTRL,
+				   "XRC TGT QP, ibv_open_qp()", errno);
+			ibv_destroy_qp(rsvd_qpn);
+			return -errno;
+		}
+		ep->conn_setup->rsvd_tgt_qpn = rsvd_qpn;
+		return FI_SUCCESS;
+	}
+
+	/* An existing XRC target was not specified, create XRC TGT
+	 * side of new physical connection. */
+	fi_ibv_msg_ep_get_qp_attr(&ep->base_ep,
+			(struct ibv_qp_init_attr *)&attr_ex);
+	attr_ex.qp_type = IBV_QPT_XRC_RECV;
+	attr_ex.qp_context = ep;
+	attr_ex.comp_mask = IBV_QP_INIT_ATTR_PD | IBV_QP_INIT_ATTR_XRCD;
+	attr_ex.pd = domain->pd;
+	attr_ex.xrcd = domain->xrc.xrcd;
+	if (rdma_create_qp_ex(ep->tgt_id, &attr_ex)) {
+		VERBS_INFO_ERRNO(FI_LOG_EP_CTRL,
+				 "Physical XRC TGT QP, rdma_create_ep_ex()",
+				 errno);
+		return -errno;
+	}
+	ep->tgt_ibv_qp = ep->tgt_id->qp;
+
+	return FI_SUCCESS;
+#else /* VERBS_HAVE_XRC */
+	return -FI_ENOSYS;
+#endif /* !VERBS_HAVE_XRC */
+}
+
+static int fi_ibv_put_tgt_qp(struct fi_ibv_xrc_ep *ep)
+{
+	int ret;
+
+	if (!ep->tgt_ibv_qp)
+		return FI_SUCCESS;
+
+	/* The kernel will not destroy the detached TGT QP until all
+	 * shared opens have called ibv_destroy_qp. */
+	ret = ibv_destroy_qp(ep->tgt_ibv_qp);
+	if (ret) {
+		VERBS_INFO_ERRNO(FI_LOG_EP_CTRL,
+				 "Close XRC TGT QP, ibv_destroy_qp()", errno);
+		return -errno;
+	}
+	ep->tgt_ibv_qp = NULL;
+
+	return FI_SUCCESS;
+}
+
+int fi_ibv_ep_destroy_xrc_qp(struct fi_ibv_xrc_ep *ep)
+{
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
+
+	if (ep->base_ep.ibv_qp) {
+		fastlock_acquire(&domain->xrc.ini_mgmt_lock);
+		fi_ibv_put_shared_ini_conn(ep);
+		fastlock_release(&domain->xrc.ini_mgmt_lock);
+	}
+	if (ep->base_ep.id) {
+		rdma_destroy_id(ep->base_ep.id);
+		ep->base_ep.id = NULL;
+	}
+	if (ep->tgt_ibv_qp)
+		fi_ibv_put_tgt_qp(ep);
+
+	if (ep->tgt_id) {
+		rdma_destroy_id(ep->tgt_id);
+		ep->tgt_id = NULL;
+	}
+	return 0;
+}
+
+FI_VERBS_XRC_ONLY
+static int fi_ibv_ini_conn_compare(struct ofi_rbmap *map, void *key, void *data)
+{
+	struct fi_ibv_ini_shared_conn *ini_conn = data;
+	struct fi_ibv_ini_conn_key *_key = key;
+	int ret;
+
+	assert(_key->addr->sa_family == ini_conn->peer_addr->sa_family);
+
+	/* Only interested in the interface address and TX CQ */
+	switch (_key->addr->sa_family) {
+	case AF_INET:
+		ret = memcmp(&ofi_sin_addr(_key->addr),
+			     &ofi_sin_addr(ini_conn->peer_addr),
+			     sizeof(ofi_sin_addr(_key->addr)));
+		break;
+	case AF_INET6:
+		ret = memcmp(&ofi_sin6_addr(_key->addr),
+			     &ofi_sin6_addr(ini_conn->peer_addr),
+			     sizeof(ofi_sin6_addr(_key->addr)));
+		break;
+	default:
+		VERBS_WARN(FI_LOG_FABRIC, "Unsupported address format\n");
+		assert(0);
+		return -FI_EINVAL;
+	}
+	if (ret)
+		return ret;
+
+	return _key->tx_cq < ini_conn->tx_cq ?
+			-1 : _key->tx_cq > ini_conn->tx_cq;
+}
+
+FI_VERBS_XRC_ONLY
+static int fi_ibv_domain_xrc_validate_hw(struct fi_ibv_domain *domain)
+{
+	struct ibv_device_attr attr;
+	int ret;
+
+	ret = ibv_query_device(domain->verbs, &attr);
+	if (ret || !(attr.device_cap_flags & IBV_DEVICE_XRC)) {
+		VERBS_INFO(FI_LOG_DOMAIN, "XRC is not supported");
+		return -FI_EINVAL;
+	}
+	return FI_SUCCESS;
+}
+
+int fi_ibv_domain_xrc_init(struct fi_ibv_domain *domain)
+{
+#if VERBS_HAVE_XRC
+	struct ibv_xrcd_init_attr attr;
+	int ret;
+
+	ret = fi_ibv_domain_xrc_validate_hw(domain);
+	if (ret)
+		return ret;
+
+	domain->xrc.xrcd_fd = -1;
+	if (fi_ibv_gl_data.msg.xrcd_filename) {
+		domain->xrc.xrcd_fd = open(fi_ibv_gl_data.msg.xrcd_filename,
+				       O_CREAT, S_IWUSR | S_IRUSR);
+		if (domain->xrc.xrcd_fd < 0) {
+			VERBS_INFO_ERRNO(FI_LOG_DOMAIN,
+					 "XRCD file open", errno);
+			return -errno;
+		}
+	}
+
+	attr.comp_mask = IBV_XRCD_INIT_ATTR_FD | IBV_XRCD_INIT_ATTR_OFLAGS;
+	attr.fd = domain->xrc.xrcd_fd;
+	attr.oflags = O_CREAT;
+	domain->xrc.xrcd = ibv_open_xrcd(domain->verbs, &attr);
+	if (!domain->xrc.xrcd) {
+		ret = -errno;
+		VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "ibv_open_xrcd", errno);
+		goto xrcd_err;
+	}
+
+	fastlock_init(&domain->xrc.ini_mgmt_lock);
+	domain->xrc.ini_conn_rbmap = calloc(1,
+			sizeof(*domain->xrc.ini_conn_rbmap));
+
+	if (!domain->xrc.ini_conn_rbmap) {
+		ret = -ENOMEM;
+		VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "XRC INI QP RB Tree", -ret);
+		goto rbmap_err;
+	}
+	domain->xrc.ini_conn_rbmap->compare = &fi_ibv_ini_conn_compare;
+	ofi_rbmap_init(domain->xrc.ini_conn_rbmap);
+
+	domain->use_xrc = 1;
+	return FI_SUCCESS;
+
+rbmap_err:
+	(void)ibv_close_xrcd(domain->xrc.xrcd);
+xrcd_err:
+	if (domain->xrc.xrcd_fd >= 0) {
+		close(domain->xrc.xrcd_fd);
+		domain->xrc.xrcd_fd = -1;
+	}
+	return ret;
+#else /* VERBS_HAVE_XRC */
+	return -FI_ENOSYS;
+#endif /* !VERBS_HAVE_XRC */
+}
+
+int fi_ibv_domain_xrc_cleanup(struct fi_ibv_domain *domain)
+{
+#if VERBS_HAVE_XRC
+	int ret;
+
+	assert(domain->xrc.xrcd);
+
+	/* All endpoint and hence XRC INI QP should be closed */
+	if (!ofi_rbmap_empty(domain->xrc.ini_conn_rbmap)) {
+		VERBS_WARN(FI_LOG_DOMAIN, "XRC domain busy\n");
+		return -FI_EBUSY;
+	}
+
+	ret = ibv_close_xrcd(domain->xrc.xrcd);
+	if (ret) {
+		VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "ibv_close_xrcd", ret);
+		return -ret;
+	}
+	if (domain->xrc.xrcd_fd >= 0) {
+		close(domain->xrc.xrcd_fd);
+		domain->xrc.xrcd_fd = -1;
+	}
+
+	ofi_rbmap_cleanup(domain->xrc.ini_conn_rbmap);
+	fastlock_destroy(&domain->xrc.ini_mgmt_lock);
+#endif /* VERBS_HAVE_XRC */
+	return 0;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_ep.c
new file mode 100644
index 000000000..2f0f08e10
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_ep.c
@@ -0,0 +1,2072 @@
+/*
+ * Copyright (c) 2013-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "config.h"
+
+#include "fi_verbs.h"
+
+#define VERBS_RESOLVE_TIMEOUT 2000	// ms
+
+static struct fi_ops_msg fi_ibv_srq_msg_ops;
+
+static inline int fi_ibv_msg_ep_cmdata_size(fid_t fid)
+{
+	struct fi_ibv_pep *pep;
+	struct fi_ibv_ep *ep;
+	struct fi_info *info;
+
+	switch (fid->fclass) {
+	case FI_CLASS_PEP:
+		pep = container_of(fid, struct fi_ibv_pep, pep_fid.fid);
+		info = pep->info;
+		break;
+	case FI_CLASS_EP:
+		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid.fid);
+		info = ep->info;
+		break;
+	default:
+		info = NULL;
+	};
+	if (fi_ibv_is_xrc(info))
+		return VERBS_CM_DATA_SIZE - sizeof(struct fi_ibv_xrc_cm_data);
+	else
+		return VERBS_CM_DATA_SIZE;
+}
+
+static int fi_ibv_ep_getopt(fid_t fid, int level, int optname,
+			    void *optval, size_t *optlen)
+{
+	switch (level) {
+	case FI_OPT_ENDPOINT:
+		switch (optname) {
+		case FI_OPT_CM_DATA_SIZE:
+			if (*optlen < sizeof(size_t))
+				return -FI_ETOOSMALL;
+			*((size_t *) optval) = fi_ibv_msg_ep_cmdata_size(fid);
+			*optlen = sizeof(size_t);
+			return 0;
+		default:
+			return -FI_ENOPROTOOPT;
+		}
+	default:
+		return -FI_ENOPROTOOPT;
+	}
+	return 0;
+}
+
+static int fi_ibv_ep_setopt(fid_t fid, int level, int optname,
+			    const void *optval, size_t optlen)
+{
+	switch (level) {
+	case FI_OPT_ENDPOINT:
+		return -FI_ENOPROTOOPT;
+	default:
+		return -FI_ENOPROTOOPT;
+	}
+	return 0;
+}
+
+static struct fi_ops_ep fi_ibv_ep_base_ops = {
+	.size = sizeof(struct fi_ops_ep),
+	.cancel = fi_no_cancel,
+	.getopt = fi_ibv_ep_getopt,
+	.setopt = fi_ibv_ep_setopt,
+	.tx_ctx = fi_no_tx_ctx,
+	.rx_ctx = fi_no_rx_ctx,
+	.rx_size_left = fi_no_rx_size_left,
+	.tx_size_left = fi_no_tx_size_left,
+};
+
+static struct fi_ops_rma fi_ibv_dgram_rma_ops = {
+	.size = sizeof(struct fi_ops_rma),
+	.read = fi_no_rma_read,
+	.readv = fi_no_rma_readv,
+	.readmsg = fi_no_rma_readmsg,
+	.write = fi_no_rma_write,
+	.writev = fi_no_rma_writev,
+	.writemsg = fi_no_rma_writemsg,
+	.inject = fi_no_rma_inject,
+	.writedata = fi_no_rma_writedata,
+	.injectdata = fi_no_rma_injectdata,
+};
+
+static int fi_ibv_alloc_wrs(struct fi_ibv_ep *ep)
+{
+	ep->wrs = calloc(1, sizeof(*ep->wrs));
+	if (!ep->wrs)
+		return -FI_ENOMEM;
+
+	ep->wrs->msg_wr.wr_id = VERBS_NO_COMP_FLAG;
+	ep->wrs->msg_wr.opcode = IBV_WR_SEND;
+	ep->wrs->msg_wr.send_flags = IBV_SEND_INLINE;
+	ep->wrs->msg_wr.sg_list = &ep->wrs->sge;
+	ep->wrs->msg_wr.num_sge = 1;
+
+	ep->wrs->rma_wr.wr_id = VERBS_NO_COMP_FLAG;
+	ep->wrs->rma_wr.opcode = IBV_WR_RDMA_WRITE;
+	ep->wrs->rma_wr.send_flags = IBV_SEND_INLINE;
+	ep->wrs->rma_wr.sg_list = &ep->wrs->sge;
+	ep->wrs->rma_wr.num_sge = 1;
+
+	return FI_SUCCESS;
+}
+
+static void fi_ibv_free_wrs(struct fi_ibv_ep *ep)
+{
+	free(ep->wrs);
+}
+
+static void fi_ibv_util_ep_progress_noop(struct util_ep *util_ep)
+{
+	/* This routine shouldn't be called */
+	assert(0);
+}
+
+static struct fi_ibv_ep *
+fi_ibv_alloc_init_ep(struct fi_info *info, struct fi_ibv_domain *domain,
+		     void *context)
+{
+	struct fi_ibv_ep *ep;
+	struct fi_ibv_xrc_ep *xrc_ep;
+	int ret;
+
+	if (fi_ibv_is_xrc(info)) {
+		xrc_ep = calloc(1, sizeof(*xrc_ep));
+		if (!xrc_ep)
+			return NULL;
+		ep = &xrc_ep->base_ep;
+	} else {
+		ep = calloc(1, sizeof(*ep));
+		if (!ep)
+			return NULL;
+	}
+
+	ep->info = fi_dupinfo(info);
+	if (!ep->info)
+		goto err1;
+
+	if (domain->util_domain.threading != FI_THREAD_SAFE) {
+		if (fi_ibv_alloc_wrs(ep))
+			goto err2;
+	}
+
+	ret = ofi_endpoint_init(&domain->util_domain.domain_fid, &fi_ibv_util_prov, info,
+				&ep->util_ep, context, fi_ibv_util_ep_progress_noop);
+	if (ret) {
+		VERBS_WARN(FI_LOG_EP_CTRL,
+			   "Unable to initialize EP, error - %d\n", ret);
+		goto err3;
+	}
+
+	ep->util_ep.ep_fid.msg = calloc(1, sizeof(*ep->util_ep.ep_fid.msg));
+	if (!ep->util_ep.ep_fid.msg)
+		goto err4;
+
+	return ep;
+err4:
+	(void) ofi_endpoint_close(&ep->util_ep);
+err3:
+	fi_ibv_free_wrs(ep);
+err2:
+	fi_freeinfo(ep->info);
+err1:
+	free(ep);
+	return NULL;
+}
+
+static int fi_ibv_close_free_ep(struct fi_ibv_ep *ep)
+{
+	int ret;
+
+	free(ep->util_ep.ep_fid.msg);
+	ep->util_ep.ep_fid.msg = NULL;
+
+	ret = ofi_endpoint_close(&ep->util_ep);
+	if (ret)
+		return ret;
+
+	fi_ibv_free_wrs(ep);
+	fi_freeinfo(ep->info);
+	free(ep);
+
+	return 0;
+}
+
+static inline void fi_ibv_ep_xrc_close(struct fi_ibv_ep *ep)
+{
+	struct fi_ibv_xrc_ep *xrc_ep = container_of(ep, struct fi_ibv_xrc_ep,
+						    base_ep);
+
+	fi_ibv_ep_destroy_xrc_qp(xrc_ep);
+	if (xrc_ep->conn_setup)
+		fi_ibv_free_xrc_conn_setup(xrc_ep);
+}
+
+static int fi_ibv_ep_close(fid_t fid)
+{
+	int ret;
+	struct fi_ibv_fabric *fab;
+	struct fi_ibv_ep *ep =
+		container_of(fid, struct fi_ibv_ep, util_ep.ep_fid.fid);
+
+	switch (ep->util_ep.type) {
+	case FI_EP_MSG:
+		if (fi_ibv_is_xrc(ep->info))
+			fi_ibv_ep_xrc_close(ep);
+		else
+			rdma_destroy_ep(ep->id);
+		fi_ibv_cleanup_cq(ep);
+		break;
+	case FI_EP_DGRAM:
+		fab = container_of(&ep->util_ep.domain->fabric->fabric_fid,
+				   struct fi_ibv_fabric, util_fabric.fabric_fid.fid);
+		ofi_ns_del_local_name(&fab->name_server,
+				      &ep->service, &ep->ep_name);
+		ret = ibv_destroy_qp(ep->ibv_qp);
+		if (ret) {
+			VERBS_WARN(FI_LOG_EP_CTRL,
+				   "Unable to destroy QP (errno = %d)\n", errno);
+			return -errno;
+		}
+		fi_ibv_cleanup_cq(ep);
+		break;
+	default:
+		VERBS_INFO(FI_LOG_DOMAIN, "Unknown EP type\n");
+		assert(0);
+		return -FI_EINVAL;
+	}
+
+	VERBS_INFO(FI_LOG_DOMAIN, "EP %p is being closed\n", ep);
+
+	ret = fi_ibv_close_free_ep(ep);
+	if (ret) {
+		VERBS_WARN(FI_LOG_DOMAIN,
+			   "Unable to close EP (%p), error - %d\n", ep, ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static inline int fi_ibv_ep_xrc_set_tgt_chan(struct fi_ibv_ep *ep)
+{
+	struct fi_ibv_xrc_ep *xrc_ep = container_of(ep, struct fi_ibv_xrc_ep,
+						    base_ep);
+	if (xrc_ep->tgt_id)
+		return rdma_migrate_id(xrc_ep->tgt_id, ep->eq->channel);
+
+	return FI_SUCCESS;
+}
+
+static int fi_ibv_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
+{
+	struct fi_ibv_ep *ep;
+	struct util_cq *cq;
+	struct fi_ibv_dgram_av *av;
+	int ret;
+
+	ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid.fid);
+	ret = ofi_ep_bind_valid(&fi_ibv_prov, bfid, flags);
+	if (ret)
+		return ret;
+
+	switch (ep->util_ep.type) {
+	case FI_EP_MSG:
+		switch (bfid->fclass) {
+		case FI_CLASS_CQ:
+			cq = container_of(bfid, struct util_cq, cq_fid.fid);
+			ret = ofi_ep_bind_cq(&ep->util_ep, cq, flags);
+			if (ret)
+				return ret;
+			break;
+		case FI_CLASS_EQ:
+			ep->eq = container_of(bfid, struct fi_ibv_eq, eq_fid.fid);
+			ret = rdma_migrate_id(ep->id, ep->eq->channel);
+			if (ret)
+				return -errno;
+			if (fi_ibv_is_xrc(ep->info)) {
+				ret = fi_ibv_ep_xrc_set_tgt_chan(ep);
+				if (ret)
+					return -errno;
+			}
+			break;
+		case FI_CLASS_SRX_CTX:
+			ep->srq_ep = container_of(bfid, struct fi_ibv_srq_ep, ep_fid.fid);
+			break;
+		default:
+			return -FI_EINVAL;
+		}
+		break;
+	case FI_EP_DGRAM:
+		switch (bfid->fclass) {
+		case FI_CLASS_CQ:
+			cq = container_of(bfid, struct util_cq, cq_fid.fid);
+			ret = ofi_ep_bind_cq(&ep->util_ep, cq, flags);
+			if (ret)
+				return ret;
+			break;
+		case FI_CLASS_AV:
+			av = container_of(bfid, struct fi_ibv_dgram_av,
+					  util_av.av_fid.fid);
+			return ofi_ep_bind_av(&ep->util_ep, &av->util_av);
+		default:
+			return -FI_EINVAL;
+		}
+		break;
+	default:
+		VERBS_INFO(FI_LOG_DOMAIN, "Unknown EP type\n");
+		assert(0);
+		return -FI_EINVAL;
+	}
+
+	return 0;
+}
+
+static int fi_ibv_create_dgram_ep(struct fi_ibv_domain *domain, struct fi_ibv_ep *ep,
+				  struct ibv_qp_init_attr *init_attr)
+{
+	struct fi_ibv_fabric *fab;
+	struct ibv_qp_attr attr = {
+		.qp_state = IBV_QPS_INIT,
+		.pkey_index = 0,
+		.port_num = 1,
+		.qkey = 0x11111111,
+	};
+	int ret = 0;
+	union ibv_gid gid;
+	uint16_t p_key;
+	struct ibv_port_attr port_attr;
+
+	init_attr->qp_type = IBV_QPT_UD;
+
+	ep->ibv_qp = ibv_create_qp(domain->pd, init_attr);
+	if (!ep->ibv_qp) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to create IBV "
+			   "Queue Pair\n");
+		return -errno;
+	}
+
+	ret = ibv_modify_qp(ep->ibv_qp, &attr,
+			    IBV_QP_STATE |
+			    IBV_QP_PKEY_INDEX |
+			    IBV_QP_PORT |
+			    IBV_QP_QKEY);
+	if (ret) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to modify QP state "
+			   "to INIT\n");
+		return -errno;
+	}
+
+	memset(&attr, 0, sizeof(attr));
+	attr.qp_state = IBV_QPS_RTR;
+	ret = ibv_modify_qp(ep->ibv_qp, &attr,
+			    IBV_QP_STATE);
+	if (ret) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to modify QP state "
+			   "to RTR\n");
+		return -errno;
+	}
+
+	if (ep->util_ep.tx_cq) {
+		memset(&attr, 0, sizeof(attr));
+		attr.qp_state = IBV_QPS_RTS;
+		attr.sq_psn = 0xffffff;
+		ret = ibv_modify_qp(ep->ibv_qp, &attr,
+				    IBV_QP_STATE |
+				    IBV_QP_SQ_PSN);
+		if (ret) {
+			VERBS_WARN(FI_LOG_EP_CTRL, "Unable to modify QP state "
+				   "to RTS\n");
+			return -errno;
+		}
+	}
+
+	if (ibv_query_gid(domain->verbs, 1, 0, &gid)) {
+		VERBS_WARN(FI_LOG_EP_CTRL,
+			   "Unable to query GID, errno = %d",
+			   errno);
+		return -errno;
+	}
+
+	if (ibv_query_pkey(domain->verbs, 1, 0, &p_key)) {
+		VERBS_WARN(FI_LOG_EP_CTRL,
+			   "Unable to query P_Key, errno = %d",
+			   errno);
+		return -errno;
+	}
+
+	if (ibv_query_port(domain->verbs, 1, &port_attr)) {
+		VERBS_WARN(FI_LOG_EP_CTRL,
+			   "Unable to query port attributes, errno = %d",
+			   errno);
+		return -errno;
+	}
+
+	ep->ep_name.lid = port_attr.lid;
+	ep->ep_name.sl = port_attr.sm_sl;
+	ep->ep_name.gid = gid;
+	ep->ep_name.qpn = ep->ibv_qp->qp_num;
+	ep->ep_name.pkey = p_key;
+
+	fab = container_of(ep->util_ep.domain->fabric,
+			   struct fi_ibv_fabric, util_fabric);
+
+	ofi_ns_add_local_name(&fab->name_server,
+			      &ep->service, &ep->ep_name);
+
+	return 0;
+}
+
+/* fi_ibv_srq_ep::xrc.prepost_lock must be held */
+FI_VERBS_XRC_ONLY
+static int fi_ibv_process_xrc_preposted(struct fi_ibv_srq_ep *srq_ep)
+{
+	struct fi_ibv_xrc_srx_prepost *recv;
+	struct slist_entry *entry;
+	int ret;
+
+	/* The pre-post SRQ function ops have been replaced so the
+	 * posting here results in adding the RX entries to the SRQ */
+	while (!slist_empty(&srq_ep->xrc.prepost_list)) {
+		entry = slist_remove_head(&srq_ep->xrc.prepost_list);
+		recv = container_of(entry, struct fi_ibv_xrc_srx_prepost,
+				    prepost_entry);
+		ret = fi_recv(&srq_ep->ep_fid, recv->buf, recv->len,
+			      recv->desc, recv->src_addr, recv->context);
+		free(recv);
+		if (ret) {
+			VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "fi_recv", errno);
+			return -errno;
+		}
+	}
+	return FI_SUCCESS;
+}
+
+static int fi_ibv_ep_enable_xrc(struct fi_ibv_ep *ep)
+{
+#if VERBS_HAVE_XRC
+	struct fi_ibv_xrc_ep *xrc_ep = container_of(ep, struct fi_ibv_xrc_ep,
+						    base_ep);
+	struct fi_ibv_srq_ep *srq_ep = ep->srq_ep;
+	struct fi_ibv_domain *domain = container_of(ep->util_ep.rx_cq->domain,
+					    struct fi_ibv_domain, util_domain);
+	struct fi_ibv_cq *cq = container_of(ep->util_ep.rx_cq,
+					    struct fi_ibv_cq, util_cq);
+	struct ibv_srq_init_attr_ex attr;
+	ssize_t ret;
+
+	/* XRC EP additional initialization */
+	dlist_init(&xrc_ep->ini_conn_entry);
+	xrc_ep->conn_state = FI_IBV_XRC_UNCONNECTED;
+
+	fastlock_acquire(&srq_ep->xrc.prepost_lock);
+	if (srq_ep->srq) {
+		/*
+		 * Multiple endpoints bound to the same XRC SRX context have
+		 * the restriction that they must be bound to the same RX CQ
+		 */
+		if (!srq_ep->xrc.cq || srq_ep->xrc.cq != cq) {
+			fastlock_release(&srq_ep->xrc.prepost_lock);
+			VERBS_WARN(FI_LOG_EP_CTRL, "SRX_CTX/CQ mismatch\n");
+			return -FI_EINVAL;
+		}
+		ibv_get_srq_num(srq_ep->srq, &xrc_ep->srqn);
+		ret = FI_SUCCESS;
+		goto done;
+	}
+
+	memset(&attr, 0, sizeof(attr));
+	attr.attr.max_wr = srq_ep->xrc.max_recv_wr;
+	attr.attr.max_sge = srq_ep->xrc.max_sge;
+	attr.comp_mask = IBV_SRQ_INIT_ATTR_TYPE | IBV_SRQ_INIT_ATTR_XRCD |
+			 IBV_SRQ_INIT_ATTR_CQ | IBV_SRQ_INIT_ATTR_PD;
+	attr.srq_type = IBV_SRQT_XRC;
+	attr.xrcd = domain->xrc.xrcd;
+	attr.cq = cq->cq;
+	attr.pd = domain->pd;
+
+	srq_ep->srq = ibv_create_srq_ex(domain->verbs, &attr);
+	if (!srq_ep->srq) {
+		VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "ibv_create_srq_ex", errno);
+		ret = -errno;
+		goto done;
+	}
+	/* The RX CQ maintains a list of all the XRC SRQs that were created
+	 * using it as the CQ */
+	cq->util_cq.cq_fastlock_acquire(&cq->xrc.srq_list_lock);
+	dlist_insert_tail(&srq_ep->xrc.srq_entry, &cq->xrc.srq_list);
+	srq_ep->xrc.cq = cq;
+	cq->util_cq.cq_fastlock_release(&cq->xrc.srq_list_lock);
+
+	ibv_get_srq_num(srq_ep->srq, &xrc_ep->srqn);
+
+	/* Swap functions since locking is no longer required */
+	srq_ep->ep_fid.msg = &fi_ibv_srq_msg_ops;
+	ret = fi_ibv_process_xrc_preposted(srq_ep);
+done:
+	fastlock_release(&srq_ep->xrc.prepost_lock);
+
+	return ret;
+#else /* VERBS_HAVE_XRC */
+	return -FI_ENOSYS;
+#endif /* !VERBS_HAVE_XRC */
+}
+
+void fi_ibv_msg_ep_get_qp_attr(struct fi_ibv_ep *ep,
+			       struct ibv_qp_init_attr *attr)
+{
+	if (ep->util_ep.tx_cq) {
+		struct fi_ibv_cq *cq = container_of(ep->util_ep.tx_cq,
+						    struct fi_ibv_cq, util_cq);
+
+		attr->cap.max_send_wr = ep->info->tx_attr->size;
+		attr->cap.max_send_sge = ep->info->tx_attr->iov_limit;
+		attr->send_cq = cq->cq;
+	} else {
+		struct fi_ibv_cq *cq =
+			container_of(ep->util_ep.rx_cq, struct fi_ibv_cq, util_cq);
+
+		attr->send_cq = cq->cq;
+	}
+
+	if (ep->util_ep.rx_cq) {
+		struct fi_ibv_cq *cq =
+			container_of(ep->util_ep.rx_cq, struct fi_ibv_cq, util_cq);
+
+		attr->cap.max_recv_wr = ep->info->rx_attr->size;
+		attr->cap.max_recv_sge = ep->info->rx_attr->iov_limit;
+		attr->recv_cq = cq->cq;
+	} else {
+		struct fi_ibv_cq *cq =
+			container_of(ep->util_ep.tx_cq, struct fi_ibv_cq, util_cq);
+
+		attr->recv_cq = cq->cq;
+	}
+	attr->cap.max_inline_data = ep->info->tx_attr->inject_size;
+	attr->qp_type = IBV_QPT_RC;
+	attr->sq_sig_all = 1;
+
+	if (ep->srq_ep) {
+		attr->srq = ep->srq_ep->srq;
+		/* Recieve posts are done to SRQ not QP RQ */
+		attr->cap.max_recv_wr = 0;
+	}
+}
+
+
+static int fi_ibv_ep_enable(struct fid_ep *ep_fid)
+{
+	struct ibv_qp_init_attr attr = { 0 };
+	struct fi_ibv_ep *ep = container_of(ep_fid, struct fi_ibv_ep,
+					    util_ep.ep_fid);
+	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(ep);
+	int ret;
+
+	if (!ep->eq && (ep->util_ep.type == FI_EP_MSG)) {
+		VERBS_WARN(FI_LOG_EP_CTRL,
+			   "Endpoint is not bound to an event queue\n");
+		return -FI_ENOEQ;
+	}
+
+	if (!ep->util_ep.tx_cq && !ep->util_ep.rx_cq) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
+			   "a send or receive completion queue\n");
+		return -FI_ENOCQ;
+	}
+
+	if (!ep->util_ep.tx_cq && (ofi_send_allowed(ep->util_ep.caps) ||
+				ofi_rma_initiate_allowed(ep->util_ep.caps))) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
+			   "a send completion queue when it has transmit "
+			   "capabilities enabled (FI_SEND | FI_RMA).\n");
+		return -FI_ENOCQ;
+	}
+
+	if (!ep->util_ep.rx_cq && ofi_recv_allowed(ep->util_ep.caps)) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
+			   "a receive completion queue when it has receive "
+			   "capabilities enabled. (FI_RECV)\n");
+		return -FI_ENOCQ;
+	}
+	fi_ibv_msg_ep_get_qp_attr(ep, &attr);
+
+	switch (ep->util_ep.type) {
+	case FI_EP_MSG:
+		if (ep->srq_ep) {
+			/* Override receive function pointers to prevent the user from
+			 * posting Receive WRs to a QP where a SRQ is attached to it */
+			if (domain->use_xrc) {
+				*ep->util_ep.ep_fid.msg = fi_ibv_msg_srq_xrc_ep_msg_ops;
+				return fi_ibv_ep_enable_xrc(ep);
+			} else {
+				ep->util_ep.ep_fid.msg->recv = fi_no_msg_recv;
+				ep->util_ep.ep_fid.msg->recvv = fi_no_msg_recvv;
+				ep->util_ep.ep_fid.msg->recvmsg = fi_no_msg_recvmsg;
+			}
+		} else if (domain->use_xrc) {
+			VERBS_WARN(FI_LOG_EP_CTRL, "XRC EP_MSG not bound "
+				   "to srx_context\n");
+			return -FI_EINVAL;
+		}
+
+		attr.qp_context = ep;
+		ret = rdma_create_qp(ep->id, domain->pd, &attr);
+		if (ret) {
+			ret = -errno;
+			VERBS_WARN(FI_LOG_EP_CTRL,
+				   "Unable to create rdma qp: %s (%d)\n",
+				   fi_strerror(-ret), -ret);
+			return ret;
+		}
+
+		/* Allow shared XRC INI QP not controlled by RDMA CM
+		 * to share same post functions as RC QP. */
+		ep->ibv_qp = ep->id->qp;
+		break;
+	case FI_EP_DGRAM:
+		assert(domain);
+		attr.sq_sig_all = 1;
+		ret = fi_ibv_create_dgram_ep(domain, ep, &attr);
+		if (ret) {
+			VERBS_WARN(FI_LOG_EP_CTRL, "Unable to create dgram EP: %s (%d)\n",
+				   fi_strerror(-ret), -ret);
+			return ret;
+		}
+		break;
+	default:
+		VERBS_INFO(FI_LOG_DOMAIN, "Unknown EP type\n");
+		assert(0);
+		return -FI_EINVAL;
+	}
+	return 0;
+}
+
+static int fi_ibv_ep_control(struct fid *fid, int command, void *arg)
+{
+	struct fid_ep *ep;
+
+	switch (fid->fclass) {
+	case FI_CLASS_EP:
+		ep = container_of(fid, struct fid_ep, fid);
+		switch (command) {
+		case FI_ENABLE:
+			return fi_ibv_ep_enable(ep);
+			break;
+		default:
+			return -FI_ENOSYS;
+		}
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+}
+
+static int fi_ibv_dgram_ep_setname(fid_t ep_fid, void *addr, size_t addrlen)
+{
+	struct fi_ibv_ep *ep;
+	void *save_addr;
+	int ret = FI_SUCCESS;
+
+	if (ep_fid->fclass != FI_CLASS_EP)
+		return -FI_EINVAL;
+
+	ep = container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid.fid);
+	if (!ep)
+		return -FI_EINVAL;
+
+	if (addrlen < ep->info->src_addrlen) {
+		VERBS_INFO(FI_LOG_EP_CTRL,
+			   "addrlen expected: %"PRIu64", got: %"PRIu64"\n",
+			   ep->info->src_addrlen, addrlen);
+		return -FI_ETOOSMALL;
+	}
+	/*
+	 * save previous address to be able make
+	 * a roll back on the previous one
+	 */
+	save_addr = ep->info->src_addr;
+
+	ep->info->src_addr = calloc(1, ep->info->src_addrlen);
+	if (!ep->info->src_addr) {
+		ep->info->src_addr = save_addr;
+		ret = -FI_ENOMEM;
+		goto err;
+	}
+
+	memcpy(ep->info->src_addr, addr, ep->info->src_addrlen);
+	memcpy(&ep->ep_name, addr, ep->info->src_addrlen);
+
+err:
+	ep->info->src_addr = save_addr;
+	return ret;
+}
+
+static int fi_ibv_dgram_ep_getname(fid_t ep_fid, void *addr, size_t *addrlen)
+{
+	struct fi_ibv_ep *ep;
+
+	if (ep_fid->fclass != FI_CLASS_EP)
+		return -FI_EINVAL;
+
+	ep = container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid.fid);
+	if (!ep)
+		return -FI_EINVAL;
+
+	if (*addrlen < sizeof(ep->ep_name)) {
+		*addrlen = sizeof(ep->ep_name);
+		VERBS_INFO(FI_LOG_EP_CTRL,
+			   "addrlen expected: %"PRIu64", got: %"PRIu64"\n",
+			   sizeof(ep->ep_name), *addrlen);
+		return -FI_ETOOSMALL;
+	}
+
+	memset(addr, 0, *addrlen);
+	memcpy(addr, &ep->ep_name, sizeof(ep->ep_name));
+	*addrlen = sizeof(ep->ep_name);
+
+	return FI_SUCCESS;
+}
+
+static struct fi_ops fi_ibv_ep_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = fi_ibv_ep_close,
+	.bind = fi_ibv_ep_bind,
+	.control = fi_ibv_ep_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static struct fi_ops_cm fi_ibv_dgram_cm_ops = {
+	.size = sizeof(fi_ibv_dgram_cm_ops),
+	.setname = fi_ibv_dgram_ep_setname,
+	.getname = fi_ibv_dgram_ep_getname,
+	.getpeer = fi_no_getpeer,
+	.connect = fi_no_connect,
+	.listen = fi_no_listen,
+	.accept = fi_no_accept,
+	.reject = fi_no_reject,
+	.shutdown = fi_no_shutdown,
+	.join = fi_no_join,
+};
+
+int fi_ibv_open_ep(struct fid_domain *domain, struct fi_info *info,
+		   struct fid_ep **ep_fid, void *context)
+{
+	struct fi_ibv_domain *dom;
+	struct fi_ibv_ep *ep;
+	struct fi_ibv_connreq *connreq;
+	struct fi_ibv_pep *pep;
+	struct fi_info *fi;
+	int ret;
+
+	if (info->src_addr)
+		ofi_straddr_dbg(&fi_ibv_prov, FI_LOG_FABRIC,
+				"open_ep src addr", info->src_addr);
+	if (info->dest_addr)
+		ofi_straddr_dbg(&fi_ibv_prov, FI_LOG_FABRIC,
+				"open_ep dest addr", info->dest_addr);
+
+	dom = container_of(domain, struct fi_ibv_domain,
+			   util_domain.domain_fid);
+	/* strncmp is used here, because the function is used
+	 * to allocate DGRAM (has prefix <dev_name>-dgram) and MSG EPs */
+	if (strncmp(dom->verbs->device->name, info->domain_attr->name,
+		    strlen(dom->verbs->device->name))) {
+		VERBS_INFO(FI_LOG_DOMAIN,
+			   "Invalid info->domain_attr->name: %s and %s\n",
+			   dom->verbs->device->name, info->domain_attr->name);
+		return -FI_EINVAL;
+	}
+
+	fi = dom->info;
+
+	if (info->ep_attr) {
+		ret = fi_ibv_check_ep_attr(info, fi);
+		if (ret)
+			return ret;
+	}
+
+	if (info->tx_attr) {
+		ret = ofi_check_tx_attr(&fi_ibv_prov, fi->tx_attr,
+					info->tx_attr, info->mode);
+		if (ret)
+			return ret;
+	}
+
+	if (info->rx_attr) {
+		ret = fi_ibv_check_rx_attr(info->rx_attr, info, fi);
+		if (ret)
+			return ret;
+	}
+
+	ep = fi_ibv_alloc_init_ep(info, dom, context);
+	if (!ep)
+		return -FI_ENOMEM;
+
+	ep->inject_limit = ep->info->tx_attr->inject_size;
+
+	switch (info->ep_attr->type) {
+	case FI_EP_MSG:
+		if (dom->use_xrc) {
+			if (dom->util_domain.threading == FI_THREAD_SAFE) {
+				*ep->util_ep.ep_fid.msg = fi_ibv_msg_xrc_ep_msg_ops_ts;
+				ep->util_ep.ep_fid.rma = &fi_ibv_msg_xrc_ep_rma_ops_ts;
+			} else {
+				*ep->util_ep.ep_fid.msg = fi_ibv_msg_xrc_ep_msg_ops;
+				ep->util_ep.ep_fid.rma = &fi_ibv_msg_xrc_ep_rma_ops;
+			}
+			ep->util_ep.ep_fid.cm = &fi_ibv_msg_xrc_ep_cm_ops;
+			ep->util_ep.ep_fid.atomic = &fi_ibv_msg_xrc_ep_atomic_ops;
+		} else {
+			if (dom->util_domain.threading == FI_THREAD_SAFE) {
+				*ep->util_ep.ep_fid.msg = fi_ibv_msg_ep_msg_ops_ts;
+				ep->util_ep.ep_fid.rma = &fi_ibv_msg_ep_rma_ops_ts;
+			} else {
+				*ep->util_ep.ep_fid.msg = fi_ibv_msg_ep_msg_ops;
+				ep->util_ep.ep_fid.rma = &fi_ibv_msg_ep_rma_ops;
+			}
+			ep->util_ep.ep_fid.cm = &fi_ibv_msg_ep_cm_ops;
+			ep->util_ep.ep_fid.atomic = &fi_ibv_msg_ep_atomic_ops;
+		}
+
+		if (!info->handle) {
+			ret = fi_ibv_create_ep(NULL, NULL, 0, info, NULL, &ep->id);
+			if (ret)
+				goto err1;
+		} else if (info->handle->fclass == FI_CLASS_CONNREQ) {
+			connreq = container_of(info->handle,
+					       struct fi_ibv_connreq, handle);
+			if (dom->use_xrc) {
+				assert(connreq->is_xrc);
+
+				if (!connreq->xrc.is_reciprocal) {
+					ret = fi_ibv_process_xrc_connreq(ep,
+								connreq);
+					if (ret)
+						goto err1;
+				}
+			} else {
+				ep->id = connreq->id;
+				ep->ibv_qp = ep->id->qp;
+			}
+		} else if (info->handle->fclass == FI_CLASS_PEP) {
+			pep = container_of(info->handle, struct fi_ibv_pep, pep_fid.fid);
+			ep->id = pep->id;
+			ep->ibv_qp = ep->id->qp;
+			pep->id = NULL;
+
+			if (rdma_resolve_addr(ep->id, info->src_addr, info->dest_addr,
+					      VERBS_RESOLVE_TIMEOUT)) {
+				ret = -errno;
+				VERBS_INFO(FI_LOG_DOMAIN, "Unable to rdma_resolve_addr\n");
+				goto err2;
+			}
+
+			if (rdma_resolve_route(ep->id, VERBS_RESOLVE_TIMEOUT)) {
+				ret = -errno;
+				VERBS_INFO(FI_LOG_DOMAIN, "Unable to rdma_resolve_route\n");
+				goto err2;
+			}
+		} else {
+			ret = -FI_ENOSYS;
+			goto err1;
+		}
+		ep->id->context = &ep->util_ep.ep_fid.fid;
+		break;
+	case FI_EP_DGRAM:
+		ep->service = (info->src_addr) ?
+			(((struct ofi_ib_ud_ep_name *)info->src_addr)->service) :
+			(((getpid() & 0x7FFF) << 16) + ((uintptr_t)ep & 0xFFFF));
+
+		if (dom->util_domain.threading == FI_THREAD_SAFE) {
+			*ep->util_ep.ep_fid.msg = fi_ibv_dgram_msg_ops_ts;
+		} else {
+			*ep->util_ep.ep_fid.msg = fi_ibv_dgram_msg_ops;
+		}
+		ep->util_ep.ep_fid.rma = &fi_ibv_dgram_rma_ops;
+		ep->util_ep.ep_fid.cm = &fi_ibv_dgram_cm_ops;
+		break;
+	default:
+		VERBS_INFO(FI_LOG_DOMAIN, "Unknown EP type\n");
+		ret = -FI_EINVAL;
+		assert(0);
+		goto err1;
+	}
+
+	*ep_fid = &ep->util_ep.ep_fid;
+	ep->util_ep.ep_fid.fid.ops = &fi_ibv_ep_ops;
+	ep->util_ep.ep_fid.ops = &fi_ibv_ep_base_ops;
+
+	return FI_SUCCESS;
+err2:
+	ep->ibv_qp = NULL;
+	rdma_destroy_ep(ep->id);
+err1:
+	fi_ibv_close_free_ep(ep);
+	return ret;
+}
+
+static int fi_ibv_pep_bind(fid_t fid, struct fid *bfid, uint64_t flags)
+{
+	struct fi_ibv_pep *pep;
+	int ret;
+
+	pep = container_of(fid, struct fi_ibv_pep, pep_fid.fid);
+	if (bfid->fclass != FI_CLASS_EQ)
+		return -FI_EINVAL;
+
+	pep->eq = container_of(bfid, struct fi_ibv_eq, eq_fid.fid);
+	/*
+	 * This is a restrictive solution that enables an XRC EP to
+	 * inform it's peer the port that should be used in making the
+	 * reciprocal connection request. While it meets RXM requirements
+	 * it limits an EQ to a single passive endpoint. TODO: implement
+	 * a more general solution.
+	 */
+	if (fi_ibv_is_xrc(pep->info)) {
+	       if (pep->eq->xrc.pep_port) {
+			VERBS_WARN(FI_LOG_EP_CTRL,
+				   "XRC limits EQ binding to a single PEP\n");
+			return -FI_EINVAL;
+	       }
+	       pep->eq->xrc.pep_port = ntohs(rdma_get_src_port(pep->id));
+	}
+
+	ret = rdma_migrate_id(pep->id, pep->eq->channel);
+	if (ret)
+		return -errno;
+
+	return 0;
+}
+
+static int fi_ibv_pep_control(struct fid *fid, int command, void *arg)
+{
+	struct fi_ibv_pep *pep;
+	int ret = 0;
+
+	switch (fid->fclass) {
+	case FI_CLASS_PEP:
+		pep = container_of(fid, struct fi_ibv_pep, pep_fid.fid);
+		switch (command) {
+		case FI_BACKLOG:
+			if (!arg)
+				return -FI_EINVAL;
+			pep->backlog = *(int *) arg;
+			break;
+		default:
+			ret = -FI_ENOSYS;
+			break;
+		}
+		break;
+	default:
+		ret = -FI_ENOSYS;
+		break;
+	}
+
+	return ret;
+}
+
+static int fi_ibv_pep_close(fid_t fid)
+{
+	struct fi_ibv_pep *pep;
+
+	pep = container_of(fid, struct fi_ibv_pep, pep_fid.fid);
+	if (pep->id)
+		rdma_destroy_ep(pep->id);
+
+	fi_freeinfo(pep->info);
+	free(pep);
+	return 0;
+}
+
+static struct fi_ops fi_ibv_pep_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = fi_ibv_pep_close,
+	.bind = fi_ibv_pep_bind,
+	.control = fi_ibv_pep_control,
+	.ops_open = fi_no_ops_open,
+};
+
+static struct fi_ops_ep fi_ibv_pep_ops = {
+	.size = sizeof(struct fi_ops_ep),
+	.getopt = fi_ibv_ep_getopt,
+	.setopt = fi_no_setopt,
+	.tx_ctx = fi_no_tx_ctx,
+	.rx_ctx = fi_no_rx_ctx,
+	.rx_size_left = fi_no_rx_size_left,
+	.tx_size_left = fi_no_tx_size_left,
+};
+
+int fi_ibv_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
+		      struct fid_pep **pep, void *context)
+{
+	struct fi_ibv_pep *_pep;
+	int ret;
+
+	_pep = calloc(1, sizeof *_pep);
+	if (!_pep)
+		return -FI_ENOMEM;
+
+	if (!(_pep->info = fi_dupinfo(info))) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+
+	if (_pep->info->dest_addr || _pep->info->dest_addrlen) {
+		free(_pep->info->dest_addr);
+		_pep->info->dest_addr = NULL;
+		_pep->info->dest_addrlen = 0;
+	}
+
+	ret = rdma_create_id(NULL, &_pep->id, &_pep->pep_fid.fid, RDMA_PS_TCP);
+	if (ret) {
+		VERBS_INFO(FI_LOG_DOMAIN, "Unable to create rdma_cm_id\n");
+		goto err2;
+	}
+
+	if (info->src_addr) {
+		ret = rdma_bind_addr(_pep->id, (struct sockaddr *)info->src_addr);
+		if (ret) {
+			VERBS_INFO(FI_LOG_DOMAIN, "Unable to bind address to rdma_cm_id\n");
+			goto err3;
+		}
+		_pep->bound = 1;
+	}
+
+	_pep->pep_fid.fid.fclass = FI_CLASS_PEP;
+	_pep->pep_fid.fid.context = context;
+	_pep->pep_fid.fid.ops = &fi_ibv_pep_fi_ops;
+	_pep->pep_fid.ops = &fi_ibv_pep_ops;
+	_pep->pep_fid.cm = fi_ibv_pep_ops_cm(_pep);
+
+	_pep->src_addrlen = info->src_addrlen;
+
+	*pep = &_pep->pep_fid;
+	return 0;
+
+err3:
+	rdma_destroy_id(_pep->id);
+err2:
+	fi_freeinfo(_pep->info);
+err1:
+	free(_pep);
+	return ret;
+}
+
+static struct fi_ops_ep fi_ibv_srq_ep_base_ops = {
+	.size = sizeof(struct fi_ops_ep),
+	.cancel = fi_no_cancel,
+	.getopt = fi_no_getopt,
+	.setopt = fi_no_setopt,
+	.tx_ctx = fi_no_tx_ctx,
+	.rx_ctx = fi_no_rx_ctx,
+	.rx_size_left = fi_no_rx_size_left,
+	.tx_size_left = fi_no_tx_size_left,
+};
+
+static struct fi_ops_cm fi_ibv_srq_cm_ops = {
+	.size = sizeof(struct fi_ops_cm),
+	.setname = fi_no_setname,
+	.getname = fi_no_getname,
+	.getpeer = fi_no_getpeer,
+	.connect = fi_no_connect,
+	.listen = fi_no_listen,
+	.accept = fi_no_accept,
+	.reject = fi_no_reject,
+	.shutdown = fi_no_shutdown,
+	.join = fi_no_join,
+};
+
+static struct fi_ops_rma fi_ibv_srq_rma_ops = {
+	.size = sizeof(struct fi_ops_rma),
+	.read = fi_no_rma_read,
+	.readv = fi_no_rma_readv,
+	.readmsg = fi_no_rma_readmsg,
+	.write = fi_no_rma_write,
+	.writev = fi_no_rma_writev,
+	.writemsg = fi_no_rma_writemsg,
+	.inject = fi_no_rma_inject,
+	.writedata = fi_no_rma_writedata,
+	.injectdata = fi_no_rma_injectdata,
+};
+
+static struct fi_ops_atomic fi_ibv_srq_atomic_ops = {
+	.size = sizeof(struct fi_ops_atomic),
+	.write = fi_no_atomic_write,
+	.writev = fi_no_atomic_writev,
+	.writemsg = fi_no_atomic_writemsg,
+	.inject = fi_no_atomic_inject,
+	.readwrite = fi_no_atomic_readwrite,
+	.readwritev = fi_no_atomic_readwritev,
+	.readwritemsg = fi_no_atomic_readwritemsg,
+	.compwrite = fi_no_atomic_compwrite,
+	.compwritev = fi_no_atomic_compwritev,
+	.compwritemsg = fi_no_atomic_compwritemsg,
+	.writevalid = fi_no_atomic_writevalid,
+	.readwritevalid = fi_no_atomic_readwritevalid,
+	.compwritevalid = fi_no_atomic_compwritevalid,
+};
+
+static inline ssize_t
+fi_ibv_srq_ep_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg, uint64_t flags)
+{
+	struct fi_ibv_srq_ep *ep =
+		container_of(ep_fid, struct fi_ibv_srq_ep, ep_fid);
+	struct ibv_recv_wr wr = {
+		.wr_id = (uintptr_t)msg->context,
+		.num_sge = msg->iov_count,
+		.next = NULL,
+	};
+	struct ibv_recv_wr *bad_wr;
+
+	assert(ep->srq);
+
+	fi_ibv_set_sge_iov(wr.sg_list, msg->msg_iov, msg->iov_count, msg->desc);
+
+	return fi_ibv_handle_post(ibv_post_srq_recv(ep->srq, &wr, &bad_wr));
+}
+
+static ssize_t
+fi_ibv_srq_ep_recv(struct fid_ep *ep_fid, void *buf, size_t len,
+		void *desc, fi_addr_t src_addr, void *context)
+{
+	struct fi_ibv_srq_ep *ep =
+		container_of(ep_fid, struct fi_ibv_srq_ep, ep_fid);
+	struct ibv_sge sge = fi_ibv_init_sge(buf, len, desc);
+	struct ibv_recv_wr wr = {
+		.wr_id = (uintptr_t)context,
+		.num_sge = 1,
+		.sg_list = &sge,
+		.next = NULL,
+	};
+	struct ibv_recv_wr *bad_wr;
+
+	return fi_ibv_handle_post(ibv_post_srq_recv(ep->srq, &wr, &bad_wr));
+}
+
+static ssize_t
+fi_ibv_srq_ep_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		    size_t count, fi_addr_t src_addr, void *context)
+{
+	struct fi_msg msg = {
+		.msg_iov = iov,
+		.desc = desc,
+		.iov_count = count,
+		.addr = src_addr,
+		.context = context,
+	};
+
+	return fi_ibv_srq_ep_recvmsg(ep_fid, &msg, 0);
+}
+
+static struct fi_ops_msg fi_ibv_srq_msg_ops = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = fi_ibv_srq_ep_recv,
+	.recvv = fi_ibv_srq_ep_recvv,
+	.recvmsg = fi_ibv_srq_ep_recvmsg,
+	.send = fi_no_msg_send,
+	.sendv = fi_no_msg_sendv,
+	.sendmsg = fi_no_msg_sendmsg,
+	.inject = fi_no_msg_inject,
+	.senddata = fi_no_msg_senddata,
+	.injectdata = fi_no_msg_injectdata,
+};
+
+/*
+ * XRC SRQ semantics differ from basic SRQ semantics in that the SRQ not the
+ * QP selects which CQ will be used for receive completions. An artifact of
+ * this is that the XRC SRQ can not be created until a CQ is bound to the
+ * endpoint. This routine will be swapped out when the first endpoint bound
+ * to the shared receive context is enabled.
+ */
+static ssize_t
+fi_ibv_xrc_srq_ep_prepost_recv(struct fid_ep *ep_fid, void *buf, size_t len,
+			void *desc, fi_addr_t src_addr, void *context)
+{
+	struct fi_ibv_srq_ep *ep =
+		container_of(ep_fid, struct fi_ibv_srq_ep, ep_fid);
+	struct fi_ibv_xrc_srx_prepost *recv;
+	ssize_t ret;
+
+	fastlock_acquire(&ep->xrc.prepost_lock);
+
+	/* Handle race that can occur when SRQ is created and pre-post
+	 * receive message function is swapped out. */
+	if (ep->srq) {
+		fastlock_release(&ep->xrc.prepost_lock);
+		return fi_ibv_handle_post(fi_recv(ep_fid, buf, len, desc,
+						 src_addr, context));
+	}
+
+	/* The only software error that can occur is overflow */
+	if (OFI_UNLIKELY(ep->xrc.prepost_count >= ep->xrc.max_recv_wr)) {
+		ret = -FI_EAVAIL;
+		goto done;
+	}
+
+	recv = calloc(1, sizeof(*recv));
+	if (OFI_UNLIKELY(!recv)) {
+		ret = -FI_EAGAIN;
+		goto done;
+	}
+
+	recv->buf = buf;
+	recv->desc = desc;
+	recv->src_addr = src_addr;
+	recv->len = len;
+	recv->context = context;
+	ep->xrc.prepost_count++;
+	slist_insert_tail(&recv->prepost_entry, &ep->xrc.prepost_list);
+	ret = FI_SUCCESS;
+done:
+	fastlock_release(&ep->xrc.prepost_lock);
+	return ret;
+}
+
+static struct fi_ops_msg fi_ibv_xrc_srq_msg_ops = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = fi_ibv_xrc_srq_ep_prepost_recv,
+	.recvv = fi_no_msg_recvv,		/* Not used by RXM */
+	.recvmsg = fi_no_msg_recvmsg,		/* Not used by RXM */
+	.send = fi_no_msg_send,
+	.sendv = fi_no_msg_sendv,
+	.sendmsg = fi_no_msg_sendmsg,
+	.inject = fi_no_msg_inject,
+	.senddata = fi_no_msg_senddata,
+	.injectdata = fi_no_msg_injectdata,
+};
+
+static void fi_ibv_cleanup_prepost_bufs(struct fi_ibv_srq_ep *srq_ep)
+{
+	struct fi_ibv_xrc_srx_prepost *recv;
+	struct slist_entry *entry;
+
+	while (!slist_empty(&srq_ep->xrc.prepost_list)) {
+		entry = slist_remove_head(&srq_ep->xrc.prepost_list);
+		recv = container_of(entry, struct fi_ibv_xrc_srx_prepost,
+				    prepost_entry);
+		free(recv);
+	}
+}
+
+/* Must hold the associated CQ lock cq::xrc.srq_list_lock */
+int fi_ibv_xrc_close_srq(struct fi_ibv_srq_ep *srq_ep)
+{
+	int ret;
+
+	assert(srq_ep->domain->use_xrc);
+	if (!srq_ep->xrc.cq || !srq_ep->srq)
+		return FI_SUCCESS;
+
+	ret = ibv_destroy_srq(srq_ep->srq);
+	if (ret) {
+		VERBS_WARN(FI_LOG_EP_CTRL, "Cannot destroy SRQ rc=%d\n", ret);
+		return -ret;
+	}
+	srq_ep->srq = NULL;
+	srq_ep->xrc.cq = NULL;
+	dlist_remove(&srq_ep->xrc.srq_entry);
+	fi_ibv_cleanup_prepost_bufs(srq_ep);
+
+	return FI_SUCCESS;
+}
+
+static int fi_ibv_srq_close(fid_t fid)
+{
+	struct fi_ibv_srq_ep *srq_ep = container_of(fid, struct fi_ibv_srq_ep,
+						    ep_fid.fid);
+	int ret;
+
+	if (srq_ep->domain->use_xrc) {
+		if (srq_ep->xrc.cq) {
+			fastlock_acquire(&srq_ep->xrc.cq->xrc.srq_list_lock);
+			ret = fi_ibv_xrc_close_srq(srq_ep);
+			fastlock_release(&srq_ep->xrc.cq->xrc.srq_list_lock);
+			if (ret)
+				goto err;
+		}
+		fastlock_destroy(&srq_ep->xrc.prepost_lock);
+	} else {
+		ret = ibv_destroy_srq(srq_ep->srq);
+		if (ret)
+			goto err;
+	}
+	free(srq_ep);
+	return FI_SUCCESS;
+
+err:
+	VERBS_WARN(FI_LOG_EP_CTRL, "Cannot destroy SRQ rc=%d\n", ret);
+	return ret;
+}
+
+static struct fi_ops fi_ibv_srq_ep_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = fi_ibv_srq_close,
+	.bind = fi_no_bind,
+	.control = fi_no_control,
+	.ops_open = fi_no_ops_open,
+};
+
+int fi_ibv_srq_context(struct fid_domain *domain, struct fi_rx_attr *attr,
+		       struct fid_ep **srq_ep_fid, void *context)
+{
+	struct ibv_srq_init_attr srq_init_attr = { 0 };
+	struct fi_ibv_domain *dom;
+	struct fi_ibv_srq_ep *srq_ep;
+	int ret;
+
+	if (!domain)
+		return -FI_EINVAL;
+
+	srq_ep = calloc(1, sizeof(*srq_ep));
+	if (!srq_ep) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+
+	dom = container_of(domain, struct fi_ibv_domain,
+			   util_domain.domain_fid);
+
+	srq_ep->ep_fid.fid.fclass = FI_CLASS_SRX_CTX;
+	srq_ep->ep_fid.fid.context = context;
+	srq_ep->ep_fid.fid.ops = &fi_ibv_srq_ep_ops;
+	srq_ep->ep_fid.ops = &fi_ibv_srq_ep_base_ops;
+	srq_ep->ep_fid.cm = &fi_ibv_srq_cm_ops;
+	srq_ep->ep_fid.rma = &fi_ibv_srq_rma_ops;
+	srq_ep->ep_fid.atomic = &fi_ibv_srq_atomic_ops;
+	srq_ep->domain = dom;
+
+	/* XRC SRQ creation is delayed until the first endpoint it is bound
+	 * to is enabled.*/
+	if (dom->use_xrc) {
+		fastlock_init(&srq_ep->xrc.prepost_lock);
+		slist_init(&srq_ep->xrc.prepost_list);
+		dlist_init(&srq_ep->xrc.srq_entry);
+		srq_ep->xrc.max_recv_wr = attr->size;
+		srq_ep->xrc.max_sge = attr->iov_limit;
+		srq_ep->ep_fid.msg = &fi_ibv_xrc_srq_msg_ops;
+		goto done;
+	}
+
+	srq_ep->ep_fid.msg = &fi_ibv_srq_msg_ops;
+	srq_init_attr.attr.max_wr = attr->size;
+	srq_init_attr.attr.max_sge = attr->iov_limit;
+
+	srq_ep->srq = ibv_create_srq(dom->pd, &srq_init_attr);
+	if (!srq_ep->srq) {
+		VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "ibv_create_srq", errno);
+		ret = -errno;
+		goto err2;
+	}
+
+done:
+	*srq_ep_fid = &srq_ep->ep_fid;
+
+	return FI_SUCCESS;
+
+err2:
+	/* Only basic SRQ can take this path */
+	free(srq_ep);
+err1:
+	return ret;
+}
+
+
+#define fi_ibv_atomicvalid(name, flags)					\
+static int fi_ibv_msg_ep_atomic_ ## name(struct fid_ep *ep_fid,		\
+					 enum fi_datatype datatype,	\
+					 enum fi_op op, size_t *count)	\
+{									\
+	struct fi_ibv_ep *ep = container_of(ep_fid, struct fi_ibv_ep,	\
+					    util_ep.ep_fid);		\
+	struct fi_atomic_attr attr;					\
+	int ret;							\
+									\
+	ret = fi_ibv_query_atomic(&ep->util_ep.domain->domain_fid,	\
+				  datatype, op, &attr, flags);		\
+	if (!ret)							\
+		*count = attr.count;					\
+	return ret;							\
+}
+
+fi_ibv_atomicvalid(writevalid, 0);
+fi_ibv_atomicvalid(readwritevalid, FI_FETCH_ATOMIC);
+fi_ibv_atomicvalid(compwritevalid, FI_COMPARE_ATOMIC);
+
+int fi_ibv_query_atomic(struct fid_domain *domain_fid, enum fi_datatype datatype,
+			enum fi_op op, struct fi_atomic_attr *attr,
+			uint64_t flags)
+{
+	struct fi_ibv_domain *domain = container_of(domain_fid,
+						    struct fi_ibv_domain,
+						    util_domain.domain_fid);
+	char *log_str_fetch = "fi_fetch_atomic with FI_SUM op";
+	char *log_str_comp = "fi_compare_atomic";
+	char *log_str;
+
+	if (flags & FI_TAGGED)
+		return -FI_ENOSYS;
+
+	if ((flags & FI_FETCH_ATOMIC) && (flags & FI_COMPARE_ATOMIC))
+		return -FI_EBADFLAGS;
+
+	if (!flags) {
+		switch (op) {
+		case FI_ATOMIC_WRITE:
+			break;
+		default:
+			return -FI_ENOSYS;
+		}
+	} else {
+		if (flags & FI_FETCH_ATOMIC) {
+			switch (op) {
+			case FI_ATOMIC_READ:
+				goto check_datatype;
+			case FI_SUM:
+				log_str = log_str_fetch;
+				break;
+			default:
+				return -FI_ENOSYS;
+			}
+		} else if (flags & FI_COMPARE_ATOMIC) {
+			if (op != FI_CSWAP)
+				return -FI_ENOSYS;
+			log_str = log_str_comp;
+		} else {
+			return  -FI_EBADFLAGS;
+		}
+		if (domain->info->tx_attr->op_flags & FI_INJECT) {
+			VERBS_INFO(FI_LOG_EP_DATA,
+				   "FI_INJECT not supported for %s\n", log_str);
+			return -FI_EINVAL;
+		}
+	}
+check_datatype:
+	switch (datatype) {
+	case FI_INT64:
+	case FI_UINT64:
+#if __BITS_PER_LONG == 64
+	case FI_DOUBLE:
+	case FI_FLOAT:
+#endif
+		break;
+	default:
+		return -FI_EINVAL;
+	}
+
+	attr->size = ofi_datatype_size(datatype);
+	if (attr->size == 0)
+		return -FI_EINVAL;
+
+	attr->count = 1;
+	return 0;
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_write(struct fid_ep *ep_fid, const void *buf, size_t count,
+			void *desc, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_WRITE,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)(uintptr_t)key,
+		.send_flags = VERBS_INJECT(ep, sizeof(uint64_t)) |
+			      IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(count != 1))
+		return -FI_E2BIG;
+
+	if (OFI_UNLIKELY(op != FI_ATOMIC_WRITE))
+		return -FI_ENOSYS;
+
+	count_copy = count;
+
+	ret = fi_ibv_msg_ep_atomic_writevalid(ep_fid, datatype, op, &count_copy);
+	if (ret)
+		return ret;
+
+	return fi_ibv_send_buf(ep, &wr, buf, sizeof(uint64_t), desc);
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_writev(struct fid_ep *ep,
+			const struct fi_ioc *iov, void **desc, size_t count,
+			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	if (OFI_UNLIKELY(iov->count != 1))
+		return -FI_E2BIG;
+
+	return fi_ibv_msg_ep_atomic_write(ep, iov->addr, count, desc[0],
+			dest_addr, addr, key, datatype, op, context);
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_writemsg(struct fid_ep *ep_fid,
+			const struct fi_msg_atomic *msg, uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_FLAGS(ep, flags, (uintptr_t)msg->context),
+		.wr.rdma.remote_addr = msg->rma_iov->addr,
+		.wr.rdma.rkey = (uint32_t)(uintptr_t)msg->rma_iov->key,
+		.send_flags = VERBS_INJECT_FLAGS(ep, sizeof(uint64_t), flags) |
+			      IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
+		return -FI_E2BIG;
+
+	if (OFI_UNLIKELY(msg->op != FI_ATOMIC_WRITE))
+		return -FI_ENOSYS;
+
+	count_copy = msg->iov_count;
+
+	ret = fi_ibv_msg_ep_atomic_writevalid(ep_fid, msg->datatype, msg->op,
+			&count_copy);
+	if (ret)
+		return ret;
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;
+		wr.imm_data = htonl((uint32_t)msg->data);
+	} else {
+		wr.opcode = IBV_WR_RDMA_WRITE;
+	}
+
+	return fi_ibv_send_buf(ep, &wr, msg->msg_iov->addr, sizeof(uint64_t),
+			       msg->desc[0]);
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_readwrite(struct fid_ep *ep_fid, const void *buf, size_t count,
+			void *desc, void *result, void *result_desc,
+			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype,
+			enum fi_op op, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.send_flags = IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(count != 1))
+		return -FI_E2BIG;
+
+	count_copy = count;
+
+	ret = fi_ibv_msg_ep_atomic_readwritevalid(ep_fid, datatype, op,
+			&count_copy);
+	if (ret)
+		return ret;
+
+	switch (op) {
+	case FI_ATOMIC_READ:
+		wr.opcode = IBV_WR_RDMA_READ;
+		wr.wr.rdma.remote_addr = addr;
+		wr.wr.rdma.rkey = (uint32_t)(uintptr_t)key;
+		break;
+	case FI_SUM:
+		wr.opcode = IBV_WR_ATOMIC_FETCH_AND_ADD;
+		wr.wr.atomic.remote_addr = addr;
+		wr.wr.atomic.compare_add = (uintptr_t)buf;
+		wr.wr.atomic.swap = 0;
+		wr.wr.atomic.rkey = (uint32_t)(uintptr_t)key;
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+
+	return fi_ibv_send_buf(ep, &wr, result, sizeof(uint64_t), result_desc);
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_readwritev(struct fid_ep *ep, const struct fi_ioc *iov,
+			void **desc, size_t count,
+			struct fi_ioc *resultv, void **result_desc,
+			size_t result_count, fi_addr_t dest_addr, uint64_t addr,
+			uint64_t key, enum fi_datatype datatype,
+			enum fi_op op, void *context)
+{
+	if (OFI_UNLIKELY(iov->count != 1))
+		return -FI_E2BIG;
+
+	return fi_ibv_msg_ep_atomic_readwrite(ep, iov->addr, count,
+			desc[0], resultv->addr, result_desc[0],
+			dest_addr, addr, key, datatype, op, context);
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_readwritemsg(struct fid_ep *ep_fid,
+				const struct fi_msg_atomic *msg,
+				struct fi_ioc *resultv, void **result_desc,
+				size_t result_count, uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_FLAGS(ep, flags, (uintptr_t)msg->context),
+		.send_flags = IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
+		return -FI_E2BIG;
+
+	count_copy = msg->iov_count;
+
+	ret = fi_ibv_msg_ep_atomic_readwritevalid(ep_fid, msg->datatype, msg->op,
+		       &count_copy);
+	if (ret)
+		return ret;
+
+	switch (msg->op) {
+	case FI_ATOMIC_READ:
+		wr.opcode = IBV_WR_RDMA_READ;
+		wr.wr.rdma.remote_addr = msg->rma_iov->addr;
+		wr.wr.rdma.rkey = (uint32_t) (uintptr_t) msg->rma_iov->key;
+		break;
+	case FI_SUM:
+		wr.opcode = IBV_WR_ATOMIC_FETCH_AND_ADD;
+		wr.wr.atomic.remote_addr = msg->rma_iov->addr;
+		wr.wr.atomic.compare_add = (uintptr_t) msg->addr;
+		wr.wr.atomic.swap = 0;
+		wr.wr.atomic.rkey = (uint32_t) (uintptr_t) msg->rma_iov->key;
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+
+	if (flags & FI_REMOTE_CQ_DATA)
+		wr.imm_data = htonl((uint32_t) msg->data);
+
+	return fi_ibv_send_buf(ep, &wr, resultv->addr,
+			       sizeof(uint64_t), result_desc[0]);
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_compwrite(struct fid_ep *ep_fid, const void *buf, size_t count,
+			void *desc, const void *compare,
+			void *compare_desc, void *result,
+			void *result_desc,
+			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype,
+			enum fi_op op, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.opcode = IBV_WR_ATOMIC_CMP_AND_SWP,
+		.wr.atomic.remote_addr = addr,
+		.wr.atomic.compare_add = (uintptr_t)compare,
+		.wr.atomic.swap = (uintptr_t)buf,
+		.wr.atomic.rkey = (uint32_t)(uintptr_t)key,
+		.send_flags = IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(count != 1))
+		return -FI_E2BIG;
+
+	count_copy = count;
+
+	ret = fi_ibv_msg_ep_atomic_compwritevalid(ep_fid, datatype, op, &count_copy);
+	if (ret)
+		return ret;
+
+	return fi_ibv_send_buf(ep, &wr, result, sizeof(uint64_t), result_desc);
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_compwritev(struct fid_ep *ep, const struct fi_ioc *iov,
+				void **desc, size_t count,
+				const struct fi_ioc *comparev,
+				void **compare_desc, size_t compare_count,
+				struct fi_ioc *resultv, void **result_desc,
+				size_t result_count,
+				fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+				enum fi_datatype datatype,
+				enum fi_op op, void *context)
+{
+	if (OFI_UNLIKELY(iov->count != 1))
+		return -FI_E2BIG;
+
+	return fi_ibv_msg_ep_atomic_compwrite(ep, iov->addr, count, desc[0],
+				comparev->addr, compare_desc[0], resultv->addr,
+				result_desc[0], dest_addr, addr, key,
+				datatype, op, context);
+}
+
+static ssize_t
+fi_ibv_msg_ep_atomic_compwritemsg(struct fid_ep *ep_fid,
+				const struct fi_msg_atomic *msg,
+				const struct fi_ioc *comparev,
+				void **compare_desc, size_t compare_count,
+				struct fi_ioc *resultv,
+				void **result_desc, size_t result_count,
+				uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_FLAGS(ep, flags, (uintptr_t)msg->context),
+		.opcode = IBV_WR_ATOMIC_CMP_AND_SWP,
+		.wr.atomic.remote_addr = msg->rma_iov->addr,
+		.wr.atomic.compare_add = (uintptr_t)comparev->addr,
+		.wr.atomic.swap = (uintptr_t)msg->addr,
+		.wr.atomic.rkey = (uint32_t)(uintptr_t)msg->rma_iov->key,
+		.send_flags = IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
+		return -FI_E2BIG;
+
+	count_copy = msg->iov_count;
+
+	ret = fi_ibv_msg_ep_atomic_compwritevalid(ep_fid, msg->datatype, msg->op,
+		       &count_copy);
+	if (ret)
+		return ret;
+
+	if (flags & FI_REMOTE_CQ_DATA)
+		wr.imm_data = htonl((uint32_t) msg->data);
+
+	return fi_ibv_send_buf(ep, &wr, resultv->addr, sizeof(uint64_t),
+			result_desc[0]);
+}
+
+struct fi_ops_atomic fi_ibv_msg_ep_atomic_ops = {
+	.size		= sizeof(struct fi_ops_atomic),
+	.write		= fi_ibv_msg_ep_atomic_write,
+	.writev		= fi_ibv_msg_ep_atomic_writev,
+	.writemsg	= fi_ibv_msg_ep_atomic_writemsg,
+	.inject		= fi_no_atomic_inject,
+	.readwrite	= fi_ibv_msg_ep_atomic_readwrite,
+	.readwritev	= fi_ibv_msg_ep_atomic_readwritev,
+	.readwritemsg	= fi_ibv_msg_ep_atomic_readwritemsg,
+	.compwrite	= fi_ibv_msg_ep_atomic_compwrite,
+	.compwritev	= fi_ibv_msg_ep_atomic_compwritev,
+	.compwritemsg	= fi_ibv_msg_ep_atomic_compwritemsg,
+	.writevalid	= fi_ibv_msg_ep_atomic_writevalid,
+	.readwritevalid	= fi_ibv_msg_ep_atomic_readwritevalid,
+	.compwritevalid = fi_ibv_msg_ep_atomic_compwritevalid
+};
+
+static ssize_t
+fi_ibv_msg_xrc_ep_atomic_write(struct fid_ep *ep_fid, const void *buf,
+		size_t count, void *desc, fi_addr_t dest_addr, uint64_t addr,
+		uint64_t key, enum fi_datatype datatype, enum fi_op op,
+		void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(&ep->base_ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_WRITE,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)(uintptr_t)key,
+		.send_flags = VERBS_INJECT(&ep->base_ep, sizeof(uint64_t)) |
+			      IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(count != 1))
+		return -FI_E2BIG;
+
+	if (OFI_UNLIKELY(op != FI_ATOMIC_WRITE))
+		return -FI_ENOSYS;
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	count_copy = count;
+
+	ret = fi_ibv_msg_ep_atomic_writevalid(ep_fid, datatype, op, &count_copy);
+	if (ret)
+		return ret;
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, buf, sizeof(uint64_t), desc);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_atomic_writemsg(struct fid_ep *ep_fid,
+			const struct fi_msg_atomic *msg, uint64_t flags)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_FLAGS(&ep->base_ep, flags,
+					  (uintptr_t)msg->context),
+		.wr.rdma.remote_addr = msg->rma_iov->addr,
+		.wr.rdma.rkey = (uint32_t)(uintptr_t)msg->rma_iov->key,
+		.send_flags = VERBS_INJECT_FLAGS(&ep->base_ep,
+				sizeof(uint64_t), flags) | IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
+		return -FI_E2BIG;
+
+	if (OFI_UNLIKELY(msg->op != FI_ATOMIC_WRITE))
+		return -FI_ENOSYS;
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+	count_copy = msg->iov_count;
+
+	ret = fi_ibv_msg_ep_atomic_writevalid(ep_fid, msg->datatype, msg->op,
+			&count_copy);
+	if (ret)
+		return ret;
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;
+		wr.imm_data = htonl((uint32_t)msg->data);
+	} else {
+		wr.opcode = IBV_WR_RDMA_WRITE;
+	}
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, msg->msg_iov->addr,
+			       sizeof(uint64_t), msg->desc[0]);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_atomic_readwrite(struct fid_ep *ep_fid, const void *buf,
+		size_t count, void *desc, void *result, void *result_desc,
+		fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		enum fi_datatype datatype, enum fi_op op, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(&ep->base_ep, (uintptr_t)context),
+		.send_flags = IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(count != 1))
+		return -FI_E2BIG;
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+	count_copy = count;
+
+	ret = fi_ibv_msg_ep_atomic_readwritevalid(ep_fid, datatype, op,
+			&count_copy);
+	if (ret)
+		return ret;
+
+	switch (op) {
+	case FI_ATOMIC_READ:
+		wr.opcode = IBV_WR_RDMA_READ;
+		wr.wr.rdma.remote_addr = addr;
+		wr.wr.rdma.rkey = (uint32_t)(uintptr_t)key;
+		break;
+	case FI_SUM:
+		wr.opcode = IBV_WR_ATOMIC_FETCH_AND_ADD;
+		wr.wr.atomic.remote_addr = addr;
+		wr.wr.atomic.compare_add = (uintptr_t)buf;
+		wr.wr.atomic.swap = 0;
+		wr.wr.atomic.rkey = (uint32_t)(uintptr_t)key;
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, result,
+			       sizeof(uint64_t), result_desc);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_atomic_readwritemsg(struct fid_ep *ep_fid,
+			const struct fi_msg_atomic *msg,
+			struct fi_ioc *resultv, void **result_desc,
+			size_t result_count, uint64_t flags)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_FLAGS(&ep->base_ep, flags,
+					  (uintptr_t)msg->context),
+		.send_flags = IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
+		return -FI_E2BIG;
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+	count_copy = msg->iov_count;
+
+	ret = fi_ibv_msg_ep_atomic_readwritevalid(ep_fid, msg->datatype, msg->op,
+		       &count_copy);
+	if (ret)
+		return ret;
+
+	switch (msg->op) {
+	case FI_ATOMIC_READ:
+		wr.opcode = IBV_WR_RDMA_READ;
+		wr.wr.rdma.remote_addr = msg->rma_iov->addr;
+		wr.wr.rdma.rkey = (uint32_t) (uintptr_t) msg->rma_iov->key;
+		break;
+	case FI_SUM:
+		wr.opcode = IBV_WR_ATOMIC_FETCH_AND_ADD;
+		wr.wr.atomic.remote_addr = msg->rma_iov->addr;
+		wr.wr.atomic.compare_add = (uintptr_t) msg->addr;
+		wr.wr.atomic.swap = 0;
+		wr.wr.atomic.rkey = (uint32_t) (uintptr_t) msg->rma_iov->key;
+		break;
+	default:
+		return -FI_ENOSYS;
+	}
+
+	if (flags & FI_REMOTE_CQ_DATA)
+		wr.imm_data = htonl((uint32_t) msg->data);
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, resultv->addr,
+			       sizeof(uint64_t), result_desc[0]);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_atomic_compwrite(struct fid_ep *ep_fid, const void *buf, size_t count,
+			void *desc, const void *compare,
+			void *compare_desc, void *result,
+			void *result_desc,
+			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+			enum fi_datatype datatype,
+			enum fi_op op, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(&ep->base_ep, (uintptr_t)context),
+		.opcode = IBV_WR_ATOMIC_CMP_AND_SWP,
+		.wr.atomic.remote_addr = addr,
+		.wr.atomic.compare_add = (uintptr_t)compare,
+		.wr.atomic.swap = (uintptr_t)buf,
+		.wr.atomic.rkey = (uint32_t)(uintptr_t)key,
+		.send_flags = IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(count != 1))
+		return -FI_E2BIG;
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+	count_copy = count;
+
+	ret = fi_ibv_msg_ep_atomic_compwritevalid(ep_fid, datatype, op, &count_copy);
+	if (ret)
+		return ret;
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, result,
+			       sizeof(uint64_t), result_desc);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_atomic_compwritemsg(struct fid_ep *ep_fid,
+				const struct fi_msg_atomic *msg,
+				const struct fi_ioc *comparev,
+				void **compare_desc, size_t compare_count,
+				struct fi_ioc *resultv,
+				void **result_desc, size_t result_count,
+				uint64_t flags)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_FLAGS(&ep->base_ep, flags,
+					  (uintptr_t)msg->context),
+		.opcode = IBV_WR_ATOMIC_CMP_AND_SWP,
+		.wr.atomic.remote_addr = msg->rma_iov->addr,
+		.wr.atomic.compare_add = (uintptr_t)comparev->addr,
+		.wr.atomic.swap = (uintptr_t)msg->addr,
+		.wr.atomic.rkey = (uint32_t)(uintptr_t)msg->rma_iov->key,
+		.send_flags = IBV_SEND_FENCE,
+	};
+	size_t count_copy;
+	int ret;
+
+	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
+		return -FI_E2BIG;
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+	count_copy = msg->iov_count;
+
+	ret = fi_ibv_msg_ep_atomic_compwritevalid(ep_fid, msg->datatype, msg->op,
+		       &count_copy);
+	if (ret)
+		return ret;
+
+	if (flags & FI_REMOTE_CQ_DATA)
+		wr.imm_data = htonl((uint32_t) msg->data);
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, resultv->addr,
+			       sizeof(uint64_t), result_desc[0]);
+}
+
+struct fi_ops_atomic fi_ibv_msg_xrc_ep_atomic_ops = {
+	.size		= sizeof(struct fi_ops_atomic),
+	.write		= fi_ibv_msg_xrc_ep_atomic_write,
+	.writev		= fi_ibv_msg_ep_atomic_writev,
+	.writemsg	= fi_ibv_msg_xrc_ep_atomic_writemsg,
+	.inject		= fi_no_atomic_inject,
+	.readwrite	= fi_ibv_msg_xrc_ep_atomic_readwrite,
+	.readwritev	= fi_ibv_msg_ep_atomic_readwritev,
+	.readwritemsg	= fi_ibv_msg_xrc_ep_atomic_readwritemsg,
+	.compwrite	= fi_ibv_msg_xrc_ep_atomic_compwrite,
+	.compwritev	= fi_ibv_msg_ep_atomic_compwritev,
+	.compwritemsg	= fi_ibv_msg_xrc_ep_atomic_compwritemsg,
+	.writevalid	= fi_ibv_msg_ep_atomic_writevalid,
+	.readwritevalid	= fi_ibv_msg_ep_atomic_readwritevalid,
+	.compwritevalid = fi_ibv_msg_ep_atomic_compwritevalid
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_eq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_eq.c
index 911dc955f..157ccc333 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_eq.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_eq.c
@@ -1,5 +1,6 @@
 /*
  * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
+ * Copyright (c) 2018 Cray Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -52,32 +53,92 @@ static ssize_t
 fi_ibv_eq_readerr(struct fid_eq *eq, struct fi_eq_err_entry *entry,
 		  uint64_t flags)
 {
-	struct fi_ibv_eq *_eq;
-	uint32_t api_version;
-	void *err_data = NULL;
-	size_t err_data_size = 0;
+	struct fi_ibv_eq *_eq =
+		container_of(eq, struct fi_ibv_eq, eq_fid.fid);
+	ofi_eq_handle_err_entry(_eq->fab->util_fabric.fabric_fid.api_version,
+				flags, &_eq->err, entry);
+	return sizeof(*entry);
+}
 
-	_eq = container_of(eq, struct fi_ibv_eq, eq_fid.fid);
-	if (!_eq->err.err)
-		return 0;
+void fi_ibv_eq_set_xrc_conn_tag(struct fi_ibv_xrc_ep *ep)
+{
+	struct fi_ibv_eq *eq = ep->base_ep.eq;
 
-	api_version = _eq->fab->util_fabric.fabric_fid.api_version;
+	fastlock_acquire(&eq->lock);
+	ep->conn_setup->conn_tag =
+		(uint32_t)ofi_idx2key(&eq->xrc.conn_key_idx,
+				ofi_idx_insert(eq->xrc.conn_key_map, ep));
+	fastlock_release(&eq->lock);
+}
 
-	if ((FI_VERSION_GE(api_version, FI_VERSION(1, 5)))
-		&& entry->err_data && entry->err_data_size) {
-		err_data_size = MIN(entry->err_data_size, _eq->err.err_data_size);
-		err_data = _eq->err.err_data;
-	}
+void fi_ibv_eq_clear_xrc_conn_tag(struct fi_ibv_xrc_ep *ep)
+{
+	struct fi_ibv_eq *eq = ep->base_ep.eq;
+	int index;
 
-	*entry = _eq->err;
-	if (err_data) {
-		memcpy(entry->err_data, err_data, err_data_size);
-		entry->err_data_size = err_data_size;
-	}
+	fastlock_acquire(&eq->lock);
+	index = ofi_key2idx(&eq->xrc.conn_key_idx,
+			    (uint64_t)ep->conn_setup->conn_tag);
+	if (!ofi_idx_is_valid(eq->xrc.conn_key_map, index))
+	    VERBS_WARN(FI_LOG_EQ, "Invalid XRC connection connection tag\n");
+	else
+		ofi_idx_remove(eq->xrc.conn_key_map, index);
+	ep->conn_setup->conn_tag = 0;
+	fastlock_release(&eq->lock);
+}
 
-	_eq->err.err = 0;
-	_eq->err.prov_errno = 0;
-	return sizeof(*entry);
+struct fi_ibv_xrc_ep *fi_ibv_eq_xrc_conn_tag2ep(struct fi_ibv_eq *eq,
+						uint32_t conn_tag)
+{
+	struct fi_ibv_xrc_ep *ep;
+	int index;
+
+	fastlock_acquire(&eq->lock);
+	index = ofi_key2idx(&eq->xrc.conn_key_idx, (uint64_t)conn_tag);
+	ep = ofi_idx_lookup(eq->xrc.conn_key_map, index);
+	if (!ep)
+		VERBS_WARN(FI_LOG_FABRIC,
+			   "Invalid XRC connection tag\n");
+	fastlock_release(&eq->lock);
+
+	return ep;
+}
+
+static int fi_ibv_eq_set_xrc_info(struct rdma_cm_event *event,
+				  struct fi_ibv_xrc_conn_info *info)
+{
+	struct fi_ibv_xrc_cm_data *remote = (struct fi_ibv_xrc_cm_data *)
+						event->param.conn.private_data;
+	int ret;
+
+	ret = fi_ibv_verify_xrc_cm_data(remote,
+					event->param.conn.private_data_len);
+	if (ret)
+		return ret;
+
+	info->is_reciprocal = remote->reciprocal;
+	info->conn_tag = ntohl(remote->conn_tag);
+	info->port = ntohs(remote->port);
+	info->conn_data = ntohl(remote->param);
+	info->conn_param = event->param.conn;
+	info->conn_param.private_data = NULL;
+	info->conn_param.private_data_len = 0;
+
+	return FI_SUCCESS;
+}
+
+static int
+fi_ibv_pep_dev_domain_match(struct fi_info *hints, const char *devname)
+{
+	int ret;
+
+	if ((FI_IBV_EP_PROTO(hints)) == FI_PROTO_RDMA_CM_IB_XRC)
+		ret = fi_ibv_cmp_xrc_domain_name(hints->domain_attr->name,
+						 devname);
+	else
+		ret = strcmp(hints->domain_attr->name, devname);
+
+	return ret;
 }
 
 static int
@@ -102,7 +163,7 @@ fi_ibv_eq_cm_getinfo(struct fi_ibv_fabric *fab, struct rdma_cm_event *event,
 		if (!(hints->domain_attr->name = strdup(devname)))
 			goto err1;
 	} else {
-		if (strcmp(hints->domain_attr->name, devname)) {
+		if (fi_ibv_pep_dev_domain_match(hints, devname)) {
 			VERBS_WARN(FI_LOG_EQ, "Passive endpoint domain: %s does"
 				   " not match device: %s where we got a "
 				   "connection request\n",
@@ -144,9 +205,20 @@ fi_ibv_eq_cm_getinfo(struct fi_ibv_fabric *fab, struct rdma_cm_event *event,
 
 	connreq->handle.fclass = FI_CLASS_CONNREQ;
 	connreq->id = event->id;
+
+	if (fi_ibv_is_xrc(*info)) {
+		connreq->is_xrc = 1;
+		ret = fi_ibv_eq_set_xrc_info(event, &connreq->xrc);
+		if (ret)
+			goto err3;
+	}
+
 	(*info)->handle = &connreq->handle;
 	fi_freeinfo(hints);
 	return 0;
+
+err3:
+	free(connreq);
 err2:
 	fi_freeinfo(*info);
 err1:
@@ -154,20 +226,268 @@ err1:
 	return ret;
 }
 
+static inline int fi_ibv_eq_copy_event_data(struct fi_eq_cm_entry *entry,
+				size_t max_dest_len, const void *priv_data,
+				size_t priv_datalen)
+{
+	const struct fi_ibv_cm_data_hdr *cm_hdr = priv_data;
+
+	size_t datalen = MIN(max_dest_len - sizeof(*entry), cm_hdr->size);
+	if (datalen)
+		memcpy(entry->data, cm_hdr->data, datalen);
+
+	return datalen;
+}
+
+static void fi_ibv_eq_skip_xrc_cm_data(const void **priv_data,
+				       size_t *priv_data_len)
+{
+	const struct fi_ibv_xrc_cm_data *cm_data = *priv_data;
+
+	if (*priv_data_len > sizeof(*cm_data)) {
+		*priv_data = (cm_data + 1);
+		*priv_data_len -= sizeof(*cm_data);
+	}
+}
+
+static int
+fi_ibv_eq_xrc_connreq_event(struct fi_ibv_eq *eq, struct fi_eq_cm_entry *entry,
+			    const void **priv_data, size_t *priv_datalen)
+{
+	struct fi_ibv_connreq *connreq = container_of(entry->info->handle,
+						struct fi_ibv_connreq, handle);
+	struct fi_ibv_xrc_ep *ep;
+	struct fi_ibv_xrc_cm_data cm_data;
+	int ret;
+
+	if (!connreq->xrc.is_reciprocal) {
+		fi_ibv_eq_skip_xrc_cm_data(priv_data, priv_datalen);
+		return FI_SUCCESS;
+	}
+
+	/*
+	 * Reciprocal connections are initiated and handled internally by
+	 * the provider, get the endpoint that issued the original connection
+	 * request.
+	 */
+	ep = fi_ibv_eq_xrc_conn_tag2ep(eq, connreq->xrc.conn_tag);
+	if (!ep) {
+		VERBS_WARN(FI_LOG_FABRIC,
+			   "Reciprocal XRC connection tag not found\n");
+		goto send_reject;
+	}
+	ep->tgt_id = connreq->id;
+	ep->tgt_id->context = &ep->base_ep.util_ep.ep_fid.fid;
+	ep->base_ep.info->handle = entry->info->handle;
+
+	ret = rdma_migrate_id(ep->tgt_id, ep->base_ep.eq->channel);
+	if (ret) {
+		VERBS_WARN(FI_LOG_FABRIC, "Could not migrate CM ID\n");
+		goto send_reject;
+	}
+
+	ret = fi_ibv_accept_xrc(ep, FI_IBV_RECIP_CONN, &cm_data,
+				sizeof(cm_data));
+	if (ret) {
+		VERBS_WARN(FI_LOG_FABRIC,
+			   "Reciprocal XRC Accept failed %d\n", ret);
+		goto send_reject;
+	}
+	/* Event is handled internally and not passed to the application */
+	return -FI_EAGAIN;
+
+send_reject:
+	if (rdma_reject(connreq->id, *priv_data, *priv_datalen))
+		VERBS_WARN(FI_LOG_FABRIC, "rdma_reject %d\n", -errno);
+	return -FI_EAGAIN;
+}
+
+static int
+fi_ibv_eq_xrc_conn_event(struct fi_ibv_xrc_ep *ep,
+			 struct rdma_cm_event *cma_event,
+			 struct fi_eq_cm_entry *entry)
+{
+	struct fi_ibv_xrc_conn_info xrc_info;
+	struct fi_ibv_xrc_cm_data cm_data;
+	const void *priv_data = cma_event->param.conn.private_data;
+	size_t priv_datalen = cma_event->param.conn.private_data_len;
+	int ret;
+
+	VERBS_DBG(FI_LOG_FABRIC, "EP %p INITIAL CONNECTION DONE state %d\n",
+		  ep, ep->conn_state);
+	fi_ibv_next_xrc_conn_state(ep);
+
+	/*
+	 * Original application initiated connect is done, if the passive
+	 * side of that connection initiate the reciprocal connection request
+	 * to create bidirectional connectivity.
+	 */
+	if (priv_data) {
+		ret = fi_ibv_eq_set_xrc_info(cma_event, &xrc_info);
+		if (ret) {
+			fi_ibv_prev_xrc_conn_state(ep);
+			rdma_disconnect(ep->base_ep.id);
+			goto err;
+		}
+		ep->peer_srqn = xrc_info.conn_data;
+		fi_ibv_ep_ini_conn_done(ep, xrc_info.conn_data,
+					xrc_info.conn_param.qp_num);
+		fi_ibv_eq_skip_xrc_cm_data(&priv_data, &priv_datalen);
+		fi_ibv_save_priv_data(ep, priv_data, priv_datalen);
+	} else {
+		fi_ibv_ep_tgt_conn_done(ep);
+		ret = fi_ibv_connect_xrc(ep, NULL, FI_IBV_RECIP_CONN, &cm_data,
+					 sizeof(cm_data));
+		if (ret) {
+			fi_ibv_prev_xrc_conn_state(ep);
+			rdma_disconnect(ep->tgt_id);
+			goto err;
+		}
+	}
+err:
+	entry->info = NULL;
+	/* Event is handled internally and not passed to the application */
+	return -FI_EAGAIN;
+}
+
+static size_t
+fi_ibv_eq_xrc_recip_conn_event(struct fi_ibv_eq *eq,
+			       struct fi_ibv_xrc_ep *ep,
+			       struct rdma_cm_event *cma_event,
+			       struct fi_eq_cm_entry *entry, size_t len)
+{
+	fid_t fid = cma_event->id->context;
+	struct fi_ibv_xrc_conn_info xrc_info;
+	int ret;
+
+	fi_ibv_next_xrc_conn_state(ep);
+	VERBS_DBG(FI_LOG_FABRIC, "EP %p RECIPROCAL CONNECTION DONE state %d\n",
+		  ep, ep->conn_state);
+
+	/* If this is the reciprocal active side notification */
+	if (cma_event->param.conn.private_data) {
+		ret = fi_ibv_eq_set_xrc_info(cma_event, &xrc_info);
+		if (ret) {
+			VERBS_WARN(FI_LOG_FABRIC,
+				   "Reciprocal connection protocol mismatch\n");
+			eq->err.err = -ret;
+			eq->err.prov_errno = ret;
+			eq->err.fid = fid;
+			return -FI_EAVAIL;
+		}
+
+		ep->peer_srqn = xrc_info.conn_data;
+		fi_ibv_ep_ini_conn_done(ep, xrc_info.conn_data,
+					xrc_info.conn_param.qp_num);
+	} else {
+			fi_ibv_ep_tgt_conn_done(ep);
+	}
+
+	/* The internal reciprocal XRC connection has completed. Return the
+	 * CONNECTED event application data associated with the original
+	 * connection. */
+	entry->fid = fid;
+	len = fi_ibv_eq_copy_event_data(entry, len,
+					ep->conn_setup->event_data,
+					ep->conn_setup->event_len);
+	entry->info = NULL;
+	return sizeof(*entry) + len;
+}
+
+static int
+fi_ibv_eq_xrc_rej_event(struct fi_ibv_eq *eq, struct rdma_cm_event *cma_event)
+{
+	struct fi_ibv_xrc_ep *ep;
+	fid_t fid = cma_event->id->context;
+	struct fi_ibv_xrc_conn_info xrc_info;
+	enum fi_ibv_xrc_ep_conn_state state;
+
+	ep = container_of(fid, struct fi_ibv_xrc_ep, base_ep.util_ep.ep_fid);
+	state = ep->conn_state;
+
+	if (ep->base_ep.id != cma_event->id || state == FI_IBV_XRC_CONNECTED) {
+		VERBS_WARN(FI_LOG_FABRIC,
+			   "Stale CM Reject %d received\n", cma_event->status);
+		return -FI_EAGAIN;
+	}
+
+	/* If reject comes from remote provider peer */
+	if (cma_event->status == FI_IBV_CM_REJ_CONSUMER_DEFINED) {
+		if (cma_event->param.conn.private_data_len &&
+		    fi_ibv_eq_set_xrc_info(cma_event, &xrc_info)) {
+			VERBS_WARN(FI_LOG_FABRIC,
+				   "CM REJ private data not valid\n");
+			return -FI_EAGAIN;
+		}
+
+		fi_ibv_ep_ini_conn_rejected(ep);
+		return FI_SUCCESS;
+	}
+
+	VERBS_WARN(FI_LOG_FABRIC, "Non-application generated CM Reject %d\n",
+		   cma_event->status);
+	if (cma_event->param.conn.private_data_len)
+		VERBS_WARN(FI_LOG_FABRIC, "Unexpected CM Reject priv_data\n");
+
+	fi_ibv_ep_ini_conn_rejected(ep);
+
+	return state == FI_IBV_XRC_ORIG_CONNECTING ? FI_SUCCESS : -FI_EAGAIN;
+}
+
+static inline int
+fi_ibv_eq_xrc_connected_event(struct fi_ibv_eq *eq,
+			      struct rdma_cm_event *cma_event,
+			      struct fi_eq_cm_entry *entry, size_t len,
+			      int *acked)
+{
+	struct fi_ibv_xrc_ep *ep;
+	fid_t fid = cma_event->id->context;
+	int ret;
+
+	ep = container_of(fid, struct fi_ibv_xrc_ep, base_ep.util_ep.ep_fid);
+
+	assert(ep->conn_state == FI_IBV_XRC_ORIG_CONNECTING ||
+	       ep->conn_state == FI_IBV_XRC_RECIP_CONNECTING);
+
+	if (ep->conn_state == FI_IBV_XRC_ORIG_CONNECTING)
+		return fi_ibv_eq_xrc_conn_event(ep, cma_event, entry);
+
+	ret = fi_ibv_eq_xrc_recip_conn_event(eq, ep, cma_event, entry, len);
+
+	/* Bidirectional connection setup is complete, destroy RDMA CM
+	 * ID(s) since  RDMA CM is used for connection setup only */
+	*acked = 1;
+	rdma_ack_cm_event(cma_event);
+
+	/* TODO: Ultimately we will want to initiate freeing of the connection
+	 * resources here with fi_ibv_free_xrc_conn_setup(ep); however, timewait
+	 * issues in larger fabrics need to be resolved first. The resources
+	 * will be freed at EP close if not freed here */
+
+	return ret;
+}
+
 static ssize_t
-fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq, struct rdma_cm_event *cma_event,
-	uint32_t *event, struct fi_eq_cm_entry *entry, size_t len)
+fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
+	struct rdma_cm_event *cma_event, uint32_t *event,
+	struct fi_eq_cm_entry *entry, size_t len, int *acked)
 {
-	struct fi_ibv_pep *pep;
-	fid_t fid;
-	size_t datalen;
+	const struct fi_ibv_cm_data_hdr *cm_hdr;
+	size_t datalen = 0;
+	size_t priv_datalen = cma_event->param.conn.private_data_len;
+	const void *priv_data = cma_event->param.conn.private_data;
 	int ret;
+	fid_t fid = cma_event->id->context;
+	struct fi_ibv_pep *pep =
+		container_of(fid, struct fi_ibv_pep, pep_fid);
+	struct fi_ibv_ep *ep;
+
+	*acked = 0;
 
-	fid = cma_event->id->context;
-	pep = container_of(fid, struct fi_ibv_pep, pep_fid);
 	switch (cma_event->event) {
 	case RDMA_CM_EVENT_CONNECT_REQUEST:
 		*event = FI_CONNREQ;
+
 		ret = fi_ibv_eq_cm_getinfo(eq->fab, cma_event, pep->info, &entry->info);
 		if (ret) {
 			rdma_destroy_id(cma_event->id);
@@ -177,18 +497,34 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq, struct rdma_cm_event *cma_event
 			eq->err.prov_errno = ret;
 			goto err;
 		}
+
+		if (fi_ibv_is_xrc(entry->info)) {
+			ret = fi_ibv_eq_xrc_connreq_event(eq, entry, &priv_data,
+							  &priv_datalen);
+			if (ret == -FI_EAGAIN)
+				return ret;
+		}
 		break;
 	case RDMA_CM_EVENT_ESTABLISHED:
 		*event = FI_CONNECTED;
-		entry->info = NULL;
-		if (cma_event->id->qp->context->device->transport_type !=
+
+		if (cma_event->id->qp &&
+		    cma_event->id->qp->context->device->transport_type !=
 		    IBV_TRANSPORT_IWARP) {
 			ret = fi_ibv_set_rnr_timer(cma_event->id->qp);
 			if (ret)
 				return ret;
 		}
+		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid);
+		if (fi_ibv_is_xrc(ep->info))
+			return fi_ibv_eq_xrc_connected_event(eq, cma_event,
+							     entry, len, acked);
+		entry->info = NULL;
 		break;
 	case RDMA_CM_EVENT_DISCONNECTED:
+		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid);
+		if (fi_ibv_is_xrc(ep->info))
+			return -FI_EAGAIN;
 		*event = FI_SHUTDOWN;
 		entry->info = NULL;
 		break;
@@ -199,8 +535,29 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq, struct rdma_cm_event *cma_event
 		eq->err.err = -cma_event->status;
 		goto err;
 	case RDMA_CM_EVENT_REJECTED:
+		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid);
+		if (fi_ibv_is_xrc(ep->info)) {
+			ret = fi_ibv_eq_xrc_rej_event(eq, cma_event);
+			if (ret == -FI_EAGAIN)
+				return ret;
+			fi_ibv_eq_skip_xrc_cm_data(&priv_data, &priv_datalen);
+		}
 		eq->err.err = ECONNREFUSED;
 		eq->err.prov_errno = -cma_event->status;
+		if (eq->err.err_data) {
+			free(eq->err.err_data);
+			eq->err.err_data = NULL;
+			eq->err.err_data_size = 0;
+		}
+		if (priv_datalen) {
+			cm_hdr = priv_data;
+			eq->err.err_data = calloc(1, cm_hdr->size);
+			if (OFI_LIKELY(eq->err.err_data != NULL)) {
+				memcpy(eq->err.err_data, cm_hdr->data,
+				       cm_hdr->size);
+				eq->err.err_data_size = cm_hdr->size;
+			}
+		}
 		goto err;
 	case RDMA_CM_EVENT_DEVICE_REMOVAL:
 		eq->err.err = ENODEV;
@@ -213,9 +570,11 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq, struct rdma_cm_event *cma_event
 	}
 
 	entry->fid = fid;
-	datalen = MIN(len - sizeof(*entry), cma_event->param.conn.private_data_len);
-	if (datalen)
-		memcpy(entry->data, cma_event->param.conn.private_data, datalen);
+
+	/* rdmacm has no way to track how much data is sent by peer */
+	if (priv_datalen)
+		datalen = fi_ibv_eq_copy_event_data(entry, len, priv_data,
+						    priv_datalen);
 	return sizeof(*entry) + datalen;
 err:
 	eq->err.fid = fid;
@@ -223,7 +582,7 @@ err:
 }
 
 ssize_t fi_ibv_eq_write_event(struct fi_ibv_eq *eq, uint32_t event,
-		const void *buf, size_t len)
+			      const void *buf, size_t len)
 {
 	struct fi_ibv_eq_entry *entry;
 
@@ -292,6 +651,7 @@ fi_ibv_eq_read(struct fid_eq *eq_fid, uint32_t *event,
 	struct fi_ibv_eq *eq;
 	struct rdma_cm_event *cma_event;
 	ssize_t ret = 0;
+	int acked;
 
 	eq = container_of(eq_fid, struct fi_ibv_eq, eq_fid.fid);
 
@@ -306,20 +666,23 @@ fi_ibv_eq_read(struct fid_eq *eq_fid, uint32_t *event,
 		if (ret)
 			return -errno;
 
+		acked = 0;
 		if (len < sizeof(struct fi_eq_cm_entry)) {
 			ret = -FI_ETOOSMALL;
 			goto ack;
 		}
 
 		ret = fi_ibv_eq_cm_process_event(eq, cma_event, event,
-				(struct fi_eq_cm_entry *)buf, len);
+				(struct fi_eq_cm_entry *)buf, len, &acked);
 		if (ret < 0)
 			goto ack;
 
 		if (flags & FI_PEEK)
 			ret = fi_ibv_eq_write_event(eq, *event, buf, len);
 ack:
-		rdma_ack_cm_event(cma_event);
+		if (!acked)
+			rdma_ack_cm_event(cma_event);
+
 		return ret;
 	}
 
@@ -410,6 +773,9 @@ static int fi_ibv_eq_close(fid_t fid)
 	}
 
 	dlistfd_head_free(&eq->list_head);
+
+	ofi_idx_reset(eq->xrc.conn_key_map);
+	free(eq->xrc.conn_key_map);
 	fastlock_destroy(&eq->lock);
 	free(eq);
 
@@ -438,6 +804,12 @@ int fi_ibv_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
 	_eq->fab = container_of(fabric, struct fi_ibv_fabric,
 				util_fabric.fabric_fid);
 
+	ofi_key_idx_init(&_eq->xrc.conn_key_idx, VERBS_TAG_INDEX_BITS);
+	_eq->xrc.conn_key_map = calloc(1, sizeof(*_eq->xrc.conn_key_map));
+	if (!_eq->xrc.conn_key_map) {
+		ret = -ENOMEM;
+		goto err0;
+	}
 	fastlock_init(&_eq->lock);
 	ret = dlistfd_head_init(&_eq->list_head);
 	if (ret) {
@@ -502,6 +874,8 @@ err2:
 	dlistfd_head_free(&_eq->list_head);
 err1:
 	fastlock_destroy(&_eq->lock);
+	free(_eq->xrc.conn_key_map);
+err0:
 	free(_eq);
 	return ret;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_info.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_info.c
index 65ebdc0e9..0aaae6494 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_info.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_info.c
@@ -34,9 +34,9 @@
 
 #include <ifaddrs.h>
 #include <net/if.h>
+#include <stdint.h>
 
 #include "fi_verbs.h"
-#include "ep_rdm/verbs_rdm.h"
 
 
 #define VERBS_IB_PREFIX "IB-0x"
@@ -47,23 +47,15 @@
 #define VERBS_MSG_CAPS (FI_MSG | FI_RMA | FI_ATOMICS | FI_READ | FI_WRITE |	\
 			FI_SEND | FI_RECV | FI_REMOTE_READ | FI_REMOTE_WRITE |	\
 			VERBS_DOMAIN_CAPS)
-#define VERBS_RDM_CAPS (FI_MSG | FI_RMA | FI_TAGGED | FI_READ | FI_WRITE |	\
-			FI_RECV | FI_MULTI_RECV | FI_SEND | FI_REMOTE_READ |	\
-			FI_REMOTE_WRITE | VERBS_DOMAIN_CAPS)
 #define VERBS_DGRAM_CAPS (FI_MSG | FI_RECV | FI_SEND | VERBS_DOMAIN_CAPS)
 
-#define VERBS_RDM_MODE (FI_CONTEXT)
+#define VERBS_DGRAM_RX_MODE (FI_MSG_PREFIX)
 
 #define VERBS_TX_OP_FLAGS (FI_INJECT | FI_COMPLETION | FI_TRANSMIT_COMPLETE)
 #define VERBS_TX_OP_FLAGS_IWARP (FI_INJECT | FI_COMPLETION)
-#define VERBS_TX_OP_FLAGS_IWARP_RDM (VERBS_TX_OP_FLAGS)
-
-#define VERBS_TX_RDM_MODE VERBS_RDM_MODE
 
 #define VERBS_RX_MODE (FI_RX_CQ_DATA)
 
-#define VERBS_RX_RDM_OP_FLAGS (FI_COMPLETION)
-
 #define VERBS_MSG_ORDER (FI_ORDER_RAR | FI_ORDER_RAW | FI_ORDER_RAS | \
 		FI_ORDER_WAW | FI_ORDER_WAS | FI_ORDER_SAW | FI_ORDER_SAS )
 
@@ -92,8 +84,9 @@ const struct fi_domain_attr verbs_domain_attr = {
 	.max_ep_tx_ctx		= 1,
 	.max_ep_rx_ctx		= 1,
 	.mr_iov_limit		= VERBS_MR_IOV_LIMIT,
-	/* max_err_data is size of ibv_wc::vendor_err for CQ, 0 - for EQ */
-	.max_err_data		= sizeof_field(struct ibv_wc, vendor_err),
+	/* max_err_data is size of ibv_wc::vendor_err for CQ, UINT8_MAX - for EQ */
+	.max_err_data		= MAX(sizeof_field(struct ibv_wc, vendor_err),
+				      UINT8_MAX),
 };
 
 const struct fi_ep_attr verbs_ep_attr = {
@@ -112,12 +105,11 @@ const struct fi_rx_attr verbs_rx_attr = {
 	.total_buffered_recv	= 0,
 };
 
-const struct fi_rx_attr verbs_rdm_rx_attr = {
-	.mode			= VERBS_RDM_MODE | VERBS_RX_MODE,
-	.op_flags		= VERBS_RX_RDM_OP_FLAGS,
+const struct fi_rx_attr verbs_dgram_rx_attr = {
+	.mode			= VERBS_DGRAM_RX_MODE | VERBS_RX_MODE,
 	.msg_order		= VERBS_MSG_ORDER,
+	.comp_order		= FI_ORDER_STRICT | FI_ORDER_DATA,
 	.total_buffered_recv	= 0,
-	.iov_limit		= 1
 };
 
 const struct fi_tx_attr verbs_tx_attr = {
@@ -129,38 +121,36 @@ const struct fi_tx_attr verbs_tx_attr = {
 	.rma_iov_limit		= 1,
 };
 
-const struct fi_tx_attr verbs_rdm_tx_attr = {
-	.mode			= VERBS_TX_RDM_MODE,
+const struct fi_tx_attr verbs_dgram_tx_attr = {
+	.mode			= 0,
 	.op_flags		= VERBS_TX_OP_FLAGS,
 	.msg_order		= VERBS_MSG_ORDER,
-	.inject_size		= FI_IBV_RDM_DFLT_BUFFERED_SIZE,
+	.comp_order		= FI_ORDER_STRICT,
+	.inject_size		= 0,
 	.rma_iov_limit		= 1,
 };
 
 const struct verbs_ep_domain verbs_msg_domain = {
 	.suffix			= "",
 	.type			= FI_EP_MSG,
+	.protocol		= FI_PROTO_UNSPEC,
 	.caps			= VERBS_MSG_CAPS,
 };
 
-const struct verbs_ep_domain verbs_rdm_domain = {
-	.suffix			= "-rdm",
-	.type			= FI_EP_RDM,
-	.caps			= VERBS_RDM_CAPS,
+const struct verbs_ep_domain verbs_msg_xrc_domain = {
+	.suffix			= "-xrc",
+	.type			= FI_EP_MSG,
+	.protocol		= FI_PROTO_RDMA_CM_IB_XRC,
+	.caps			= VERBS_MSG_CAPS,
 };
 
 const struct verbs_ep_domain verbs_dgram_domain = {
 	.suffix			= "-dgram",
 	.type			= FI_EP_DGRAM,
+	.protocol		= FI_PROTO_UNSPEC,
 	.caps			= VERBS_DGRAM_CAPS,
 };
 
-struct fi_ibv_rdm_sysaddr
-{
-	struct sockaddr_in addr;
-	int is_found;
-};
-
 int fi_ibv_check_ep_attr(const struct fi_info *hints,
 			 const struct fi_info *info)
 {
@@ -177,10 +167,9 @@ int fi_ibv_check_ep_attr(const struct fi_info *hints,
 	switch (hints->ep_attr->protocol) {
 	case FI_PROTO_UNSPEC:
 	case FI_PROTO_RDMA_CM_IB_RC:
+	case FI_PROTO_RDMA_CM_IB_XRC:
 	case FI_PROTO_IWARP:
 	case FI_PROTO_IB_UD:
-	case FI_PROTO_IB_RDM:
-	case FI_PROTO_IWARP_RDM:
 		break;
 	default:
 		VERBS_INFO(FI_LOG_CORE,
@@ -411,7 +400,7 @@ static int fi_ibv_rai_to_fi(struct rdma_addrinfo *rai, struct fi_info *fi)
 }
 
 static inline int fi_ibv_get_qp_cap(struct ibv_context *ctx,
-				    struct fi_info *info)
+				    struct fi_info *info, uint32_t protocol)
 {
 	struct ibv_pd *pd;
 	struct ibv_cq *cq;
@@ -433,16 +422,21 @@ static inline int fi_ibv_get_qp_cap(struct ibv_context *ctx,
 		goto err1;
 	}
 
-	qp_type = (info->ep_attr->type != FI_EP_DGRAM) ?
-			    IBV_QPT_RC : IBV_QPT_UD;
+	if (protocol == FI_PROTO_RDMA_CM_IB_XRC)
+		qp_type = IBV_QPT_XRC_SEND;
+	else
+		qp_type = (info->ep_attr->type != FI_EP_DGRAM) ?
+				    IBV_QPT_RC : IBV_QPT_UD;
 
 	memset(&init_attr, 0, sizeof init_attr);
 	init_attr.send_cq = cq;
-	init_attr.recv_cq = cq;
 	init_attr.cap.max_send_wr = fi_ibv_gl_data.def_tx_size;
-	init_attr.cap.max_recv_wr = fi_ibv_gl_data.def_rx_size;
 	init_attr.cap.max_send_sge = fi_ibv_gl_data.def_tx_iov_limit;
-	init_attr.cap.max_recv_sge = fi_ibv_gl_data.def_rx_iov_limit;
+	if (!fi_ibv_is_xrc_send_qp(qp_type)) {
+		init_attr.recv_cq = cq;
+		init_attr.cap.max_recv_wr = fi_ibv_gl_data.def_rx_size;
+		init_attr.cap.max_recv_sge = fi_ibv_gl_data.def_rx_iov_limit;
+	}
 	init_attr.cap.max_inline_data = fi_ibv_find_max_inline(pd, ctx, qp_type);
 	init_attr.qp_type = qp_type;
 
@@ -483,7 +477,7 @@ static int fi_ibv_mtu_type_to_len(enum ibv_mtu mtu_type)
 }
 
 static int fi_ibv_get_device_attrs(struct ibv_context *ctx,
-				   struct fi_info *info)
+				   struct fi_info *info, uint32_t protocol)
 {
 	struct ibv_device_attr device_attr;
 	struct ibv_port_attr port_attr;
@@ -498,6 +492,13 @@ static int fi_ibv_get_device_attrs(struct ibv_context *ctx,
 		return -errno;
 	}
 
+	if (protocol == FI_PROTO_RDMA_CM_IB_XRC) {
+		if (!(device_attr.device_cap_flags & IBV_DEVICE_XRC)) {
+			VERBS_WARN(FI_LOG_FABRIC, "XRC not supported\n");
+			return -FI_EINVAL;
+		}
+	}
+
 	info->domain_attr->cq_cnt 		= device_attr.max_cq;
 	info->domain_attr->ep_cnt 		= device_attr.max_qp;
 	info->domain_attr->tx_ctx_cnt 		= MIN(info->domain_attr->tx_ctx_cnt,
@@ -510,9 +511,6 @@ static int fi_ibv_get_device_attrs(struct ibv_context *ctx,
 						      device_attr.max_qp);
 	info->domain_attr->max_ep_srx_ctx	= device_attr.max_srq;
 	info->domain_attr->mr_cnt		= device_attr.max_mr;
-	if (info->ep_attr->type == FI_EP_RDM)
-		info->domain_attr->cntr_cnt	= device_attr.max_qp * 4;
-
 	info->tx_attr->size 			= device_attr.max_qp_wr;
 	info->tx_attr->iov_limit 		= device_attr.max_sge;
 
@@ -524,8 +522,12 @@ static int fi_ibv_get_device_attrs(struct ibv_context *ctx,
 						  MIN(device_attr.max_sge,
 						      device_attr.max_srq_sge) :
 						  device_attr.max_sge;
+	if (protocol == FI_PROTO_RDMA_CM_IB_XRC) {
+		info->rx_attr->iov_limit = MIN(info->rx_attr->iov_limit, 1);
+		info->ep_attr->rx_ctx_cnt = FI_SHARED_CONTEXT;
+	}
 
-	ret = fi_ibv_get_qp_cap(ctx, info);
+	ret = fi_ibv_get_qp_cap(ctx, info, protocol);
 	if (ret)
 		return ret;
 
@@ -608,47 +610,45 @@ static int fi_ibv_alloc_info(struct ibv_context *ctx, struct fi_info **info,
 	int ret;
 
 	if ((ctx->device->transport_type != IBV_TRANSPORT_IB) &&
-	    (ep_dom->type == FI_EP_DGRAM))
+	    ((ep_dom->type == FI_EP_DGRAM) ||
+	    (ep_dom->protocol == FI_PROTO_RDMA_CM_IB_XRC)))
 		return -FI_EINVAL;
 
 	if (!(fi = fi_allocinfo()))
 		return -FI_ENOMEM;
 
-	fi->caps		= ep_dom->caps;
-	fi->handle		= NULL;
-	if (ep_dom->type == FI_EP_RDM) {
-		fi->mode	= VERBS_RDM_MODE;
-		*(fi->tx_attr)	= verbs_rdm_tx_attr;
-		*(fi->rx_attr)	= verbs_rdm_rx_attr;
-	} else {
-		*(fi->tx_attr)	= verbs_tx_attr;
-		*(fi->rx_attr)	= verbs_rx_attr;
-	}
-
-	*(fi->ep_attr)		= verbs_ep_attr;
-	*(fi->domain_attr)	= verbs_domain_attr;
+	fi->caps = ep_dom->caps;
+	fi->handle = NULL;
+	*(fi->ep_attr) = verbs_ep_attr;
+	*(fi->domain_attr) = verbs_domain_attr;
 
-	if (ep_dom->type == FI_EP_RDM)
-		fi->domain_attr->mr_mode &= ~FI_MR_LOCAL;
+	switch (ep_dom->type) {
+	case FI_EP_MSG:
+		*(fi->tx_attr) = verbs_tx_attr;
+		*(fi->rx_attr) = verbs_rx_attr;
+		break;
+	case FI_EP_DGRAM:
+		fi->mode = VERBS_DGRAM_RX_MODE;
+		*(fi->tx_attr) = verbs_dgram_tx_attr;
+		*(fi->rx_attr) = verbs_dgram_rx_attr;
+		fi->ep_attr->msg_prefix_size = VERBS_DGRAM_MSG_PREFIX_SIZE;
+		break;
+	default:
+		assert(0);
+		return -FI_EINVAL;
+	}
+		
 
-	*(fi->fabric_attr)	= verbs_fabric_attr;
+	*(fi->fabric_attr) = verbs_fabric_attr;
 
-	fi->ep_attr->type	= ep_dom->type;
-	fi->tx_attr->caps	= ep_dom->caps;
-	fi->rx_attr->caps	= ep_dom->caps;
+	fi->ep_attr->type = ep_dom->type;
+	fi->tx_attr->caps = ep_dom->caps;
+	fi->rx_attr->caps = ep_dom->caps;
 
-	ret = fi_ibv_get_device_attrs(ctx, fi);
+	ret = fi_ibv_get_device_attrs(ctx, fi, ep_dom->protocol);
 	if (ret)
 		goto err;
 
-	if (ep_dom->type == FI_EP_RDM) {
-		fi->tx_attr->iov_limit = 1;
-		fi->tx_attr->rma_iov_limit = 1;
-		fi->tx_attr->inject_size = fi_ibv_gl_data.rdm.buffer_size;
-
-		fi->rx_attr->iov_limit = 1;
-	}
-
 	switch (ctx->device->transport_type) {
 	case IBV_TRANSPORT_IB:
 		if(ibv_query_gid(ctx, 1, 0, &gid)) {
@@ -664,15 +664,14 @@ static int fi_ibv_alloc_info(struct ibv_context *ctx, struct fi_info **info,
 			goto err;
 		}
 
-		snprintf(fi->fabric_attr->name, name_len, VERBS_IB_PREFIX "%" PRIu64,
+		snprintf(fi->fabric_attr->name, name_len, VERBS_IB_PREFIX "%" PRIx64,
 			 be64toh(gid.global.subnet_prefix));
 
 		switch (ep_dom->type) {
 		case FI_EP_MSG:
-			fi->ep_attr->protocol = FI_PROTO_RDMA_CM_IB_RC;
-			break;
-		case FI_EP_RDM:
-			fi->ep_attr->protocol = FI_PROTO_IB_RDM;
+			fi->ep_attr->protocol =
+				ep_dom->protocol == FI_PROTO_UNSPEC ?
+				FI_PROTO_RDMA_CM_IB_RC : ep_dom->protocol;
 			break;
 		case FI_EP_DGRAM:
 			fi->ep_attr->protocol = FI_PROTO_IB_UD;
@@ -689,14 +688,8 @@ static int fi_ibv_alloc_info(struct ibv_context *ctx, struct fi_info **info,
 			ret = -FI_ENOMEM;
 			goto err;
 		}
-
-		if (ep_dom->type == FI_EP_MSG) {
-			fi->ep_attr->protocol = FI_PROTO_IWARP;
-			fi->tx_attr->op_flags = VERBS_TX_OP_FLAGS_IWARP;
-		} else {
-			fi->ep_attr->protocol = FI_PROTO_IWARP_RDM;
-			fi->tx_attr->op_flags = VERBS_TX_OP_FLAGS_IWARP_RDM;
-		}
+		fi->ep_attr->protocol = FI_PROTO_IWARP;
+		fi->tx_attr->op_flags = VERBS_TX_OP_FLAGS_IWARP;
 
 		/* TODO Some iWarp HW may support immediate data as per RFC 7306
 		 * (RDMA Protocol Extensions). Update this to figure out if the
@@ -710,7 +703,7 @@ static int fi_ibv_alloc_info(struct ibv_context *ctx, struct fi_info **info,
 	}
 
 	name_len = strlen(ctx->device->name) + strlen(ep_dom->suffix);
-	fi->domain_attr->name = malloc(name_len + 1);
+	fi->domain_attr->name = calloc(1, name_len + 2);
 	if (!fi->domain_attr->name) {
 		ret = -FI_ENOMEM;
 		goto err;
@@ -718,7 +711,6 @@ static int fi_ibv_alloc_info(struct ibv_context *ctx, struct fi_info **info,
 
 	snprintf(fi->domain_attr->name, name_len + 1, "%s%s",
 		 ctx->device->name, ep_dom->suffix);
-	fi->domain_attr->name[name_len] = '\0';
 
 	*info = fi;
 	return 0;
@@ -847,27 +839,25 @@ static int fi_ibv_getifaddrs(struct dlist_entry *verbs_devs)
 			goto err1;
 		}
 
-		ret = fi_ibv_create_ep(name, NULL, FI_NUMERICHOST | FI_SOURCE,
-				NULL, &rai, &id);
+		ret = fi_ibv_get_rai_id(name, NULL, FI_NUMERICHOST | FI_SOURCE,
+					NULL, &rai, &id);
 		if (ret)
 			continue;
 
 		ret = fi_ibv_add_rai(verbs_devs, id, rai);
-		if (ret)
-			goto err2;
-
+		if (ret) {
+			rdma_freeaddrinfo(rai);
+			rdma_destroy_id(id);
+			goto err1;
+		}
 		VERBS_DBG(FI_LOG_FABRIC, "Found active interface for verbs device: "
 			  "%s with address: %s\n",
 			  ibv_get_device_name(id->verbs->device), name);
-
-		rdma_destroy_ep(id);
-
+		rdma_destroy_id(id);
 		num_verbs_ifs++;
 	}
 	freeifaddrs(ifaddr);
 	return num_verbs_ifs ? 0 : -FI_ENODATA;
-err2:
-	rdma_destroy_ep(id);
 err1:
 	fi_ibv_verbs_devs_free(verbs_devs);
 	freeifaddrs(ifaddr);
@@ -973,7 +963,7 @@ static void fi_ibv_sockaddr_set_port(struct sockaddr *sa, uint16_t port)
 	}
 }
 
-/* the `rai` parameter is used for the MSG/RDM EP types */
+/* the `rai` parameter is used for the MSG EP type */
 /* the `fmt`, `[src | dest]_addr` parameters are used for the DGRAM EP type */
 /* if the `fmt` parameter isn't used, pass FI_FORMAT_UNSPEC */
 static int fi_ibv_set_info_addrs(struct fi_info *info,
@@ -1053,14 +1043,27 @@ rai_to_fi:
 				     NULL, NULL);
 }
 
+#define VERBS_NUM_DOMAIN_TYPES		3
+
 int fi_ibv_init_info(const struct fi_info **all_infos)
 {
 	struct ibv_context **ctx_list;
 	struct fi_info *fi = NULL, *tail = NULL;
-	int ret = 0, i, num_devices;
+	const struct verbs_ep_domain *ep_type[VERBS_NUM_DOMAIN_TYPES];
+	int ret = 0, i, j, num_devices;
 
 	*all_infos = NULL;
 
+	/* List XRC MSG_EP domain before default RC MSG_EP if requested */
+	if (fi_ibv_gl_data.msg.prefer_xrc) {
+		ep_type[0] = &verbs_msg_xrc_domain;
+		ep_type[1] = &verbs_msg_domain;
+	} else {
+		ep_type[0] = &verbs_msg_domain;
+		ep_type[1] = &verbs_msg_xrc_domain;
+	}
+	ep_type[2] = &verbs_dgram_domain;
+
 	if (!fi_ibv_gl_data.fork_unsafe) {
 		VERBS_INFO(FI_LOG_CORE, "Enabling IB fork support\n");
 		ret = ibv_fork_init();
@@ -1088,25 +1091,13 @@ int fi_ibv_init_info(const struct fi_info **all_infos)
 	}
 
 	for (i = 0; i < num_devices; i++) {
-		ret = fi_ibv_alloc_info(ctx_list[i], &fi, &verbs_msg_domain);
-		if (!ret) {
-			if (!*all_infos)
-				*all_infos = fi;
-			else
-				tail->next = fi;
-			tail = fi;
-
-			ret = fi_ibv_alloc_info(ctx_list[i], &fi,
-						&verbs_rdm_domain);
+		for (j = 0; j < VERBS_NUM_DOMAIN_TYPES; j++) {
+			ret = fi_ibv_alloc_info(ctx_list[i], &fi, ep_type[j]);
 			if (!ret) {
-				tail->next = fi;
-				tail = fi;
-			}
-
-			ret = fi_ibv_alloc_info(ctx_list[i], &fi,
-						&verbs_dgram_domain);
-			if (!ret) {
-				tail->next = fi;
+				if (!*all_infos)
+					*all_infos = fi;
+				else
+					tail->next = fi;
 				tail = fi;
 			}
 		}
@@ -1124,7 +1115,7 @@ static int fi_ibv_set_default_attr(struct fi_info *info, size_t *attr,
 				   size_t default_attr, char *attr_str)
 {
 	if (default_attr > *attr) {
-		VERBS_WARN(FI_LOG_FABRIC, "Ignoring provider default value "
+		VERBS_INFO(FI_LOG_FABRIC, "Ignoring provider default value "
 			   "for %s as it is greater than the value supported "
 			   "by domain: %s\n", attr_str, info->domain_attr->name);
 	} else {
@@ -1150,34 +1141,26 @@ static int fi_ibv_set_default_info(struct fi_info *info)
 				      "rx context size");
 	if (ret)
 		return ret;
+	ret = fi_ibv_set_default_attr(info, &info->tx_attr->iov_limit,
+				      fi_ibv_gl_data.def_tx_iov_limit,
+				      "tx iov_limit");
+	if (ret)
+		return ret;
 
-	/* Don't set defaults for verb/RDM as
-	 * it supports an iov limit of just 1 */
-	if (info->ep_attr->type != FI_EP_RDM) {
-		ret = fi_ibv_set_default_attr(
-			info, &info->tx_attr->iov_limit,
-			fi_ibv_gl_data.def_tx_iov_limit,
-			"tx iov_limit");
-		if (ret)
-			return ret;
+	ret = fi_ibv_set_default_attr(info, &info->rx_attr->iov_limit,
+				      fi_ibv_gl_data.def_rx_iov_limit,
+				      "rx iov_limit");
+	if (ret)
+		return ret;
 
-		ret = fi_ibv_set_default_attr(
-			info, &info->rx_attr->iov_limit,
-			fi_ibv_gl_data.def_rx_iov_limit,
-			"rx iov_limit");
+	if (info->ep_attr->type == FI_EP_MSG) {
+		/* For verbs iov limit is same for
+		 * both regular messages and RMA */
+		ret = fi_ibv_set_default_attr(info, &info->tx_attr->rma_iov_limit,
+					      fi_ibv_gl_data.def_tx_iov_limit,
+				"tx rma_iov_limit");
 		if (ret)
 			return ret;
-
-		if (info->ep_attr->type != FI_EP_DGRAM) {
-			/* For verbs iov limit is same for
-			 * both regular messages and RMA */
-			ret = fi_ibv_set_default_attr(
-				info, &info->tx_attr->rma_iov_limit,
-				fi_ibv_gl_data.def_tx_iov_limit,
-				"tx rma_iov_limit");
-			if (ret)
-				return ret;
-		}
 	}
 	return 0;
 }
@@ -1225,9 +1208,29 @@ static int fi_ibv_get_matching_info(uint32_t version,
 	*info = tail = NULL;
 
 	for ( ; check_info; check_info = check_info->next) {
+		VERBS_DBG(FI_LOG_FABRIC, "Checking domain: %s\n",
+			  check_info->domain_attr->name);
+
 		if (hints) {
-			VERBS_DBG(FI_LOG_FABRIC, "Checking domain: %s\n",
-				  check_info->domain_attr->name);
+			if ((check_info->ep_attr->protocol ==
+			     FI_PROTO_RDMA_CM_IB_XRC) &&
+			    (!hints->ep_attr ||
+			     (hints->ep_attr->rx_ctx_cnt != FI_SHARED_CONTEXT))) {
+				VERBS_INFO(FI_LOG_FABRIC,
+					   "hints->ep_attr->rx_ctx_cnt != "
+					   "FI_SHARED_CONTEXT. Skipping "
+					   "XRC FI_EP_MSG endpoints\n");
+				continue;
+			}
+			if ((check_info->ep_attr->protocol ==
+			    FI_PROTO_RDMA_CM_IB_XRC) && !VERBS_HAVE_XRC) {
+				VERBS_INFO(FI_LOG_FABRIC,
+					   "XRC not built into provider, "
+					   "skipping XRC FI_EP_MSG "
+					   "endpoints\n");
+				continue;
+			}
+
 			ret = fi_ibv_check_hints(version, hints,
 						 check_info);
 			if (ret)
@@ -1255,6 +1258,8 @@ static int fi_ibv_get_matching_info(uint32_t version,
 			}
 		}
 
+		VERBS_DBG(FI_LOG_FABRIC, "Adding fi_info for domain: %s\n",
+			  fi->domain_attr->name);
 		if (!*info)
 			*info = fi;
 		else
@@ -1279,8 +1284,7 @@ static int fi_ibv_del_info_not_belong_to_dev(const char *dev_name, struct fi_inf
 	*info = NULL;
 
 	while (check_info) {
-		/* Use strncmp since verbs RDM domain name
-		 * would have "-rdm" suffix */
+		/* Use strncmp since verbs domain names would have "-<ep_type>" suffix */
 		if (dev_name && strncmp(dev_name, check_info->domain_attr->name,
 					strlen(dev_name))) {
 			/* This branch removing `check_info` entry from the list */
@@ -1369,8 +1373,15 @@ static int fi_ibv_handle_ib_ud_addr(const char *node, const char *service,
 		}
 
 		if (flags & FI_SOURCE) {
-			if (service)
-				sscanf(service, "%" SCNu16, &src_addr->service);
+			if (service) {
+				ret = sscanf(service, "%" SCNu16,
+					     &src_addr->service);
+				if (ret != 1) {
+					ret = -errno;
+					goto fn2;
+				}
+			}
+
 			VERBS_INFO(FI_LOG_CORE, "node '%s' service '%s' "
 				                "converted to <service=%d>\n",
 				   node, service, src_addr->service);
@@ -1425,23 +1436,41 @@ static int fi_ibv_handle_sock_addr(const char *node, const char *service,
 	const char *dev_name = NULL;
 	int ret;
 
-	ret = fi_ibv_create_ep(node, service, flags, hints, &rai, &id);
+	ret = fi_ibv_get_rai_id(node, service, flags, hints, &rai, &id);
 	if (ret)
 		return ret;
 	if (id->verbs) {
 		dev_name = ibv_get_device_name(id->verbs->device);
 		ret = fi_ibv_del_info_not_belong_to_dev(dev_name, info);
 		if (ret)
-			goto fn;
+			goto out;
 	}
 
 	ret = fi_ibv_fill_addr(rai, info, id);
 	fi_ibv_remove_nosrc_info(info);
-fn:
-	fi_ibv_destroy_ep(rai, &id);
+out:
+	rdma_freeaddrinfo(rai);
+	if (rdma_destroy_id(id))
+		VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_destroy_id", errno);
 	return ret;
 }
 
+static inline int
+fi_ibv_hints_match_dgram_ep(const struct fi_info *hints)
+{
+	return (hints && ((hints->addr_format == FI_ADDR_IB_UD) ||
+			  (hints->ep_attr && (hints->ep_attr->type == FI_EP_DGRAM))));
+}
+
+static inline int
+fi_ibv_hints_match_msg_ep(const struct fi_info *hints)
+{
+	return (hints && ((hints->addr_format == FI_SOCKADDR) ||
+			  (hints->addr_format == FI_SOCKADDR_IN) ||
+			  (hints->addr_format == FI_SOCKADDR_IN6) ||
+			  (hints->addr_format == FI_SOCKADDR_IB) ||
+			  (hints->ep_attr && (hints->ep_attr->type == FI_EP_MSG))));
+}
 
 static int fi_ibv_get_match_infos(uint32_t version, const char *node,
 				  const char *service, uint64_t flags,
@@ -1458,21 +1487,45 @@ static int fi_ibv_get_match_infos(uint32_t version, const char *node,
 	if (ret)
 		return ret;
 
-	if (hints && (hints->addr_format == FI_ADDR_IB_UD)) {
+	/* Check if the user requested to support DGRAM EP type only */
+	if (fi_ibv_hints_match_dgram_ep(hints)) {
 		/* This is case when only IB UD addresses are passed */
 		ret = fi_ibv_handle_ib_ud_addr(node, service, flags, info);
-		if (ret)
+		if (ret) {
+			VERBS_INFO(FI_LOG_CORE,
+				   "Handling of the IB UD address fails - %d, "
+				   "support of this was requested thru the passed hints\n",
+				   ret);
 			fi_freeinfo(*info);
+		}
+		return ret;
+	}
+
+	/* Check if the user requested to support MSG EP type only */
+	if (fi_ibv_hints_match_msg_ep(hints)) {
+		ret = fi_ibv_handle_sock_addr(node, service, flags, hints, info);
+		if (ret) {
+			VERBS_INFO(FI_LOG_CORE,
+				   "Handling of the socket address fails - %d, but the "
+				   "support of this was requested thru the passed hints\n",
+				   ret);
+			if (*info)
+				fi_freeinfo(*info);
+		} else {
+			if (!*info)
+				return -FI_ENODATA;
+		}
 		return ret;
 	}
 
 	ret_sock_addr = fi_ibv_handle_sock_addr(node, service, flags, hints, info);
-	if (ret_sock_addr)
+	if (ret_sock_addr) {
 		VERBS_INFO(FI_LOG_CORE, "Handling of the socket address fails - %d\n",
 			   ret_sock_addr);
-
-	if (!*info)
-		return -FI_ENODATA;
+	} else {
+		if (!*info)
+			return -FI_ENODATA;
+	}
 
 	ret_ib_ud_addr = fi_ibv_handle_ib_ud_addr(node, service, flags, info);
 	if (ret_ib_ud_addr)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_mr.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_mr.c
index 05f8514cb..2267287d8 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_mr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_mr.c
@@ -32,7 +32,6 @@
 
 #include <ofi_util.h>
 #include "fi_verbs.h"
-#include "verbs_rdm.h"
 
 #define FI_IBV_DEFINE_MR_REG_OPS(type)							\
 											\
@@ -180,13 +179,6 @@ fi_ibv_mr_ofi2ibv_access(uint64_t ofi_access, struct fi_ibv_domain *domain)
 {
 	int ibv_access = 0;
 
-	/* Enable local write access by default for FI_EP_RDM which hides local
-	 * registration requirements. This allows to avoid buffering or double
-	 * registration */
-	if (!(domain->info->caps & FI_LOCAL_MR) &&
-	    !(domain->info->domain_attr->mr_mode & FI_MR_LOCAL))
-		ibv_access |= IBV_ACCESS_LOCAL_WRITE;
-
 	/* Local read access to an MR is enabled by default in verbs */
 	if (ofi_access & FI_RECV)
 		ibv_access |= IBV_ACCESS_LOCAL_WRITE;
@@ -261,38 +253,6 @@ int fi_ibv_mr_internal_dereg(struct fi_ibv_mem_desc *md)
 	return ret;
 }
 
-int fi_ibv_rdm_alloc_and_reg(struct fi_ibv_rdm_ep *ep,
-			     void **buf, size_t size,
-			     struct fi_ibv_mem_desc *md)
-{
-	if (!*buf) {
-		if (ofi_memalign((void **)buf,
-				 FI_IBV_BUF_ALIGNMENT, size))
-			return -FI_ENOMEM;
-	}
-
-	memset(*buf, 0, size);
-	return fi_ibv_mr_internal_reg(ep->domain, *buf, size,
-				      FI_WRITE | FI_REMOTE_WRITE, md);
-}
-
-ssize_t fi_ibv_rdm_dereg_and_free(struct fi_ibv_mem_desc *md,
-				  char **buff)
-{
-	ssize_t ret = FI_SUCCESS;
-	ret = fi_ibv_mr_internal_dereg(md);
-	if (ret)
-		VERBS_WARN(FI_LOG_AV,
-			   "Unable to deregister MR, ret = %"PRId64"\n", ret);
-
-	if (buff && *buff) {
-		ofi_freealign(*buff);
-		*buff = NULL;
-	}
-
-	return ret;
-}
-
 static inline
 int fi_ibv_mr_internal_cache_reg(struct fi_ibv_domain *domain, void *buf,
 				 size_t len, uint64_t access,
@@ -376,88 +336,104 @@ static struct fi_ops fi_ibv_mr_cache_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
-int fi_ibv_monitor_subscribe(struct ofi_mem_monitor *notifier, void *addr,
-			     size_t len, struct ofi_subscription *subscription)
+int fi_ibv_monitor_subscribe(struct ofi_mem_monitor *notifier,
+			     struct ofi_subscription *subscription)
 {
 	struct fi_ibv_domain *domain =
 		container_of(notifier, struct fi_ibv_domain, monitor);
-	struct fi_ibv_mem_ptr_entry *entry;
 	int ret = FI_SUCCESS;
+	RbtStatus rbt_ret;
+	RbtIterator iter;
+	struct iovec *key;
+	struct fi_ibv_subscr_entry *subscr_entry;
+	struct fi_ibv_monitor_entry *entry =
+		calloc(1, sizeof(*entry));
+	if (OFI_UNLIKELY(!entry))
+		return -FI_ENOMEM;
 
 	pthread_mutex_lock(&domain->notifier->lock);
-	fi_ibv_mem_notifier_set_free_hook(domain->notifier->prev_free_hook);
-	fi_ibv_mem_notifier_set_realloc_hook(domain->notifier->prev_realloc_hook);
-
-	entry = util_buf_alloc(domain->notifier->mem_ptrs_ent_pool);
-	if (OFI_UNLIKELY(!entry)) {
-		ret = -FI_ENOMEM;
-		goto fn;
+	ofi_set_mem_free_hook(domain->notifier->prev_free_hook);
+	ofi_set_mem_realloc_hook(domain->notifier->prev_realloc_hook);
+
+	entry->iov = subscription->iov;
+	dlist_init(&entry->subscription_list);
+
+	rbt_ret = rbtInsert(domain->notifier->subscr_storage,
+			    (void *)&entry->iov, (void *)entry);
+	switch (rbt_ret) {
+	case RBT_STATUS_DUPLICATE_KEY:
+		free(entry);
+		iter = rbtFind(domain->notifier->subscr_storage,
+			       (void *)&subscription->iov);
+		assert(iter);
+		rbtKeyValue(domain->notifier->subscr_storage, iter,
+			    (void *)&key, (void *)&entry);
+		/* fall through */
+	case RBT_STATUS_OK:
+		subscr_entry = calloc(1, sizeof(*subscr_entry));
+		if (OFI_LIKELY(subscr_entry != NULL)) {
+			subscr_entry->subscription = subscription;
+			dlist_insert_tail(&subscr_entry->entry, &entry->subscription_list);
+			break;
+		}
+		/* Do not free monitor entry in case of diplicate key */
+		if (rbt_ret == RBT_STATUS_OK) {
+			iter = rbtFind(domain->notifier->subscr_storage,
+				       (void *)&subscription->iov);
+			assert(iter);
+			rbtErase(domain->notifier->subscr_storage, iter);
+			free(entry);
+		}
+		/* fall through */
+	default:
+		ret = -FI_EAVAIL;
+		break;
 	}
 
-	entry->addr = addr;
-	entry->subscription = subscription;
-	dlist_init(&entry->entry);
-	HASH_ADD(hh, domain->notifier->mem_ptrs_hash, addr, sizeof(void *), entry);
-
-fn:
-	fi_ibv_mem_notifier_set_free_hook(fi_ibv_mem_notifier_free_hook);
-	fi_ibv_mem_notifier_set_realloc_hook(fi_ibv_mem_notifier_realloc_hook);
+	ofi_set_mem_free_hook(fi_ibv_mem_notifier_free_hook);
+	ofi_set_mem_realloc_hook(fi_ibv_mem_notifier_realloc_hook);
 	pthread_mutex_unlock(&domain->notifier->lock);
 	return ret;
 }
 
-void fi_ibv_monitor_unsubscribe(struct ofi_mem_monitor *notifier, void *addr,
-				size_t len, struct ofi_subscription *subscription)
+void fi_ibv_monitor_unsubscribe(struct ofi_mem_monitor *notifier,
+				struct ofi_subscription *subscription)
 {
 	struct fi_ibv_domain *domain =
 		container_of(notifier, struct fi_ibv_domain, monitor);
-	struct fi_ibv_mem_ptr_entry *entry;
+	RbtIterator iter;
+	struct fi_ibv_subscr_entry *subscr_entry;
+	struct fi_ibv_monitor_entry *entry;
+	struct iovec *key;
 
 	pthread_mutex_lock(&domain->notifier->lock);
-	fi_ibv_mem_notifier_set_free_hook(domain->notifier->prev_free_hook);
-	fi_ibv_mem_notifier_set_realloc_hook(domain->notifier->prev_realloc_hook);
-
-	HASH_FIND(hh, domain->notifier->mem_ptrs_hash, &addr, sizeof(void *), entry);
-	assert(entry);
-
-	HASH_DEL(domain->notifier->mem_ptrs_hash, entry);
-
-	if (!dlist_empty(&entry->entry))
-		dlist_remove_init(&entry->entry);
+	ofi_set_mem_free_hook(domain->notifier->prev_free_hook);
+	ofi_set_mem_realloc_hook(domain->notifier->prev_realloc_hook);
+
+	iter = rbtFind(domain->notifier->subscr_storage,
+		       (void *)&subscription->iov);
+	assert(iter);
+	rbtKeyValue(domain->notifier->subscr_storage, iter,
+		    (void *)&key, (void *)&entry);
+	dlist_foreach_container(&entry->subscription_list, struct fi_ibv_subscr_entry,
+				subscr_entry, entry) {
+		if (subscr_entry->subscription == subscription) {
+			dlist_remove(&subscr_entry->entry);
+			free(subscr_entry);
+			break;
+		}
+	}
 
-	util_buf_release(domain->notifier->mem_ptrs_ent_pool, entry);
+	if (dlist_empty(&entry->subscription_list)) {
+		rbtErase(domain->notifier->subscr_storage, iter);
+		free(entry);
+	}
 
-	fi_ibv_mem_notifier_set_realloc_hook(fi_ibv_mem_notifier_realloc_hook);
-	fi_ibv_mem_notifier_set_free_hook(fi_ibv_mem_notifier_free_hook);
+	ofi_set_mem_realloc_hook(fi_ibv_mem_notifier_realloc_hook);
+	ofi_set_mem_free_hook(fi_ibv_mem_notifier_free_hook);
 	pthread_mutex_unlock(&domain->notifier->lock);
 }
 
-struct ofi_subscription *
-fi_ibv_monitor_get_event(struct ofi_mem_monitor *notifier)
-{
-	struct fi_ibv_domain *domain =
-		container_of(notifier, struct fi_ibv_domain, monitor);
-	struct fi_ibv_mem_ptr_entry *entry;
-
-	pthread_mutex_lock(&domain->notifier->lock);
-	if (!dlist_empty(&domain->notifier->event_list)) {
-		dlist_pop_front(&domain->notifier->event_list,
-				struct fi_ibv_mem_ptr_entry,
-				entry, entry);
-		VERBS_DBG(FI_LOG_MR,
-			  "Retrieve %p (entry %p) from event list\n",
-			  entry->addr, entry);
-		/* needed to protect against double insertions */
-		dlist_init(&entry->entry);
-
-		pthread_mutex_unlock(&domain->notifier->lock);
-		return entry->subscription;
-	} else {
-		pthread_mutex_unlock(&domain->notifier->lock);
-		return NULL;
-	}
-}
-
 int fi_ibv_mr_cache_entry_reg(struct ofi_mr_cache *cache,
 			      struct ofi_mr_entry *entry)
 {
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_msg.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_msg.c
new file mode 100644
index 000000000..e8b79b50a
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_msg.c
@@ -0,0 +1,385 @@
+/*
+ * Copyright (c) 2013-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "config.h"
+
+#include "fi_verbs.h"
+
+
+static inline ssize_t
+fi_ibv_msg_ep_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg, uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_recv_wr wr = {
+		.wr_id = (uintptr_t)msg->context,
+		.num_sge = msg->iov_count,
+		.next = NULL,
+	};
+	struct ibv_recv_wr *bad_wr;
+
+	assert(ep->util_ep.rx_cq);
+
+	fi_ibv_set_sge_iov(wr.sg_list, msg->msg_iov, msg->iov_count, msg->desc);
+
+	return fi_ibv_handle_post(ibv_post_recv(ep->ibv_qp, &wr, &bad_wr));
+}
+
+static ssize_t
+fi_ibv_msg_ep_recv(struct fid_ep *ep_fid, void *buf, size_t len,
+		void *desc, fi_addr_t src_addr, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_sge sge = fi_ibv_init_sge(buf, len, desc);
+	struct ibv_recv_wr wr = {
+		.wr_id = (uintptr_t)context,
+		.num_sge = 1,
+		.sg_list = &sge,
+		.next = NULL,
+	};
+	struct ibv_recv_wr *bad_wr;
+
+	assert(ep->util_ep.rx_cq);
+
+	return fi_ibv_handle_post(ibv_post_recv(ep->ibv_qp, &wr, &bad_wr));
+}
+
+static ssize_t
+fi_ibv_msg_ep_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+                 size_t count, fi_addr_t src_addr, void *context)
+{
+	struct fi_msg msg = {
+		.msg_iov = iov,
+		.desc = desc,
+		.iov_count = count,
+		.addr = src_addr,
+		.context = context,
+	};
+
+	return fi_ibv_msg_ep_recvmsg(ep_fid, &msg, 0);
+}
+
+static ssize_t
+fi_ibv_msg_ep_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg, uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)msg->context,
+	};
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		wr.opcode = IBV_WR_SEND_WITH_IMM;
+		wr.imm_data = htonl((uint32_t)msg->data);
+	} else {
+		wr.opcode = IBV_WR_SEND;
+	}
+
+	return fi_ibv_send_msg(ep, &wr, msg, flags);
+}
+
+static ssize_t
+fi_ibv_msg_ep_send(struct fid_ep *ep_fid, const void *buf, size_t len,
+		void *desc, fi_addr_t dest_addr, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.opcode = IBV_WR_SEND,
+		.send_flags = VERBS_INJECT(ep, len),
+	};
+
+	return fi_ibv_send_buf(ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_ep_senddata(struct fid_ep *ep_fid, const void *buf, size_t len,
+		       void *desc, uint64_t data, fi_addr_t dest_addr, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.opcode = IBV_WR_SEND_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.send_flags = VERBS_INJECT(ep, len),
+	};
+
+	return fi_ibv_send_buf(ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_ep_sendv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		    size_t count, fi_addr_t dest_addr, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)context,
+		.opcode = IBV_WR_SEND,
+	};
+
+	return fi_ibv_send_iov(ep, &wr, iov, desc, count);
+}
+
+static ssize_t fi_ibv_msg_ep_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
+		fi_addr_t dest_addr)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_SEND,
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
+}
+
+static ssize_t fi_ibv_msg_ep_injectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
+		    uint64_t data, fi_addr_t dest_addr)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_SEND_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
+}
+
+static ssize_t
+fi_ibv_msg_inject_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+		       fi_addr_t dest_addr)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+
+	ep->wrs->sge.addr = (uintptr_t) buf;
+	ep->wrs->sge.length = (uint32_t) len;
+
+	return fi_ibv_send_poll_cq_if_needed(ep, &ep->wrs->msg_wr);
+}
+
+static ssize_t fi_ibv_msg_ep_injectdata_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+					     uint64_t data, fi_addr_t dest_addr)
+{
+	ssize_t ret;
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+
+	ep->wrs->msg_wr.imm_data = htonl((uint32_t)data);
+	ep->wrs->msg_wr.opcode = IBV_WR_SEND_WITH_IMM;
+
+	ep->wrs->sge.addr = (uintptr_t) buf;
+	ep->wrs->sge.length = (uint32_t) len;
+
+	ret = fi_ibv_send_poll_cq_if_needed(ep, &ep->wrs->msg_wr);
+	ep->wrs->msg_wr.opcode = IBV_WR_SEND;
+	return ret;
+}
+
+const struct fi_ops_msg fi_ibv_msg_ep_msg_ops_ts = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = fi_ibv_msg_ep_recv,
+	.recvv = fi_ibv_msg_ep_recvv,
+	.recvmsg = fi_ibv_msg_ep_recvmsg,
+	.send = fi_ibv_msg_ep_send,
+	.sendv = fi_ibv_msg_ep_sendv,
+	.sendmsg = fi_ibv_msg_ep_sendmsg,
+	.inject = fi_ibv_msg_ep_inject,
+	.senddata = fi_ibv_msg_ep_senddata,
+	.injectdata = fi_ibv_msg_ep_injectdata,
+};
+
+const struct fi_ops_msg fi_ibv_msg_ep_msg_ops = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = fi_ibv_msg_ep_recv,
+	.recvv = fi_ibv_msg_ep_recvv,
+	.recvmsg = fi_ibv_msg_ep_recvmsg,
+	.send = fi_ibv_msg_ep_send,
+	.sendv = fi_ibv_msg_ep_sendv,
+	.sendmsg = fi_ibv_msg_ep_sendmsg,
+	.inject = fi_ibv_msg_inject_fast,
+	.senddata = fi_ibv_msg_ep_senddata,
+	.injectdata = fi_ibv_msg_ep_injectdata_fast,
+};
+
+static ssize_t
+fi_ibv_msg_xrc_ep_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg, uint64_t flags)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)msg->context,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		wr.opcode = IBV_WR_SEND_WITH_IMM;
+		wr.imm_data = htonl((uint32_t)msg->data);
+	} else {
+		wr.opcode = IBV_WR_SEND;
+	}
+
+	return fi_ibv_send_msg(&ep->base_ep, &wr, msg, flags);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_send(struct fid_ep *ep_fid, const void *buf, size_t len,
+		void *desc, fi_addr_t dest_addr, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(&ep->base_ep, (uintptr_t)context),
+		.opcode = IBV_WR_SEND,
+		.send_flags = VERBS_INJECT(&ep->base_ep, len),
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_senddata(struct fid_ep *ep_fid, const void *buf, size_t len,
+		       void *desc, uint64_t data, fi_addr_t dest_addr, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(&ep->base_ep, (uintptr_t)context),
+		.opcode = IBV_WR_SEND_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.send_flags = VERBS_INJECT(&ep->base_ep, len),
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_sendv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		    size_t count, fi_addr_t dest_addr, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)context,
+		.opcode = IBV_WR_SEND,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_iov(&ep->base_ep, &wr, iov, desc, count);
+}
+
+static ssize_t fi_ibv_msg_xrc_ep_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
+		fi_addr_t dest_addr)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_SEND,
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf_inline(&ep->base_ep, &wr, buf, len);
+}
+
+static ssize_t fi_ibv_msg_xrc_ep_injectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
+		    uint64_t data, fi_addr_t dest_addr)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_SEND_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf_inline(&ep->base_ep, &wr, buf, len);
+}
+
+/* NOTE: Initially the XRC endpoint must be used with a SRQ. */
+const struct fi_ops_msg fi_ibv_msg_xrc_ep_msg_ops_ts = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = fi_no_msg_recv,
+	.recvv = fi_no_msg_recvv,
+	.recvmsg = fi_no_msg_recvmsg,
+	.send = fi_no_msg_send,
+	.sendv = fi_no_msg_sendv,
+	.sendmsg = fi_no_msg_sendmsg,
+	.inject = fi_no_msg_inject,
+	.senddata = fi_no_msg_senddata,
+	.injectdata = fi_no_msg_injectdata,
+};
+
+const struct fi_ops_msg fi_ibv_msg_xrc_ep_msg_ops = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = fi_no_msg_recv,
+	.recvv = fi_no_msg_recvv,
+	.recvmsg = fi_no_msg_recvmsg,
+	.send = fi_no_msg_send,
+	.sendv = fi_no_msg_sendv,
+	.sendmsg = fi_no_msg_sendmsg,
+	.inject = fi_no_msg_inject,
+	.senddata = fi_no_msg_senddata,
+	.injectdata = fi_no_msg_injectdata,
+};
+
+const struct fi_ops_msg fi_ibv_msg_srq_xrc_ep_msg_ops = {
+	.size = sizeof(struct fi_ops_msg),
+	.recv = fi_no_msg_recv,
+	.recvv = fi_no_msg_recvv,
+	.recvmsg = fi_no_msg_recvmsg,
+	.send = fi_ibv_msg_xrc_ep_send,
+	.sendv = fi_ibv_msg_xrc_ep_sendv,
+	.sendmsg = fi_ibv_msg_xrc_ep_sendmsg,
+	.inject = fi_ibv_msg_xrc_ep_inject,
+	.senddata = fi_ibv_msg_xrc_ep_senddata,
+	.injectdata = fi_ibv_msg_xrc_ep_injectdata,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_msg_ep.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_msg_ep.c
deleted file mode 100644
index 385acbd53..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_msg_ep.c
+++ /dev/null
@@ -1,1457 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "config.h"
-
-#include "fi_verbs.h"
-
-
-#define VERBS_CM_DATA_SIZE 56
-#define VERBS_RESOLVE_TIMEOUT 2000	// ms
-
-
-static int
-fi_ibv_msg_ep_getopt(fid_t fid, int level, int optname,
-		  void *optval, size_t *optlen)
-{
-	switch (level) {
-	case FI_OPT_ENDPOINT:
-		switch (optname) {
-		case FI_OPT_CM_DATA_SIZE:
-			if (*optlen < sizeof(size_t))
-				return -FI_ETOOSMALL;
-			*((size_t *) optval) = VERBS_CM_DATA_SIZE;
-			*optlen = sizeof(size_t);
-			return 0;
-		default:
-			return -FI_ENOPROTOOPT;
-		}
-	default:
-		return -FI_ENOPROTOOPT;
-	}
-	return 0;
-}
-
-static int
-fi_ibv_msg_ep_setopt(fid_t fid, int level, int optname,
-		  const void *optval, size_t optlen)
-{
-	switch (level) {
-	case FI_OPT_ENDPOINT:
-		return -FI_ENOPROTOOPT;
-	default:
-		return -FI_ENOPROTOOPT;
-	}
-	return 0;
-}
-
-static struct fi_ops_ep fi_ibv_msg_ep_base_ops = {
-	.size = sizeof(struct fi_ops_ep),
-	.cancel = fi_no_cancel,
-	.getopt = fi_ibv_msg_ep_getopt,
-	.setopt = fi_ibv_msg_ep_setopt,
-	.tx_ctx = fi_no_tx_ctx,
-	.rx_ctx = fi_no_rx_ctx,
-	.rx_size_left = fi_no_rx_size_left,
-	.tx_size_left = fi_no_tx_size_left,
-};
-
-static struct fi_ibv_msg_ep *fi_ibv_alloc_msg_ep(struct fi_info *info)
-{
-	struct fi_ibv_msg_ep *ep;
-
-	ep = calloc(1, sizeof *ep);
-	if (!ep)
-		return NULL;
-
-	ep->info = fi_dupinfo(info);
-	if (!ep->info)
-		goto err;
-
-	return ep;
-err:
-	free(ep);
-	return NULL;
-}
-
-static void fi_ibv_free_msg_ep(struct fi_ibv_msg_ep *ep)
-{
-	fi_freeinfo(ep->info);
-	free(ep);
-}
-
-static int fi_ibv_msg_ep_close(fid_t fid)
-{
-	struct fi_ibv_msg_ep *ep;
-
-	ep = container_of(fid, struct fi_ibv_msg_ep, ep_fid.fid);
-	rdma_destroy_ep(ep->id);
-
-	fi_ibv_cleanup_cq(ep);
-
-	VERBS_INFO(FI_LOG_DOMAIN, "EP %p was closed \n", ep);
-
-	fi_ibv_free_msg_ep(ep);
-
-	return 0;
-}
-
-static int fi_ibv_msg_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
-{
-	struct fi_ibv_msg_ep *ep;
-	int ret;
-
-	ep = container_of(fid, struct fi_ibv_msg_ep, ep_fid.fid);
-	ret = ofi_ep_bind_valid(&fi_ibv_prov, bfid, flags);
-	if (ret)
-		return ret;
-
-	switch (bfid->fclass) {
-	case FI_CLASS_CQ:
-		/* Must bind a CQ to either RECV or SEND completions, and
-		 * the FI_SELECTIVE_COMPLETION flag is only valid when binding the
-		 * FI_SEND CQ. */
-		if (!(flags & (FI_RECV|FI_SEND))
-				|| (flags & (FI_SEND|FI_SELECTIVE_COMPLETION))
-							== FI_SELECTIVE_COMPLETION) {
-			return -EINVAL;
-		}
-		if (flags & FI_RECV) {
-			if (ep->rcq)
-				return -EINVAL;
-			ep->rcq = container_of(bfid, struct fi_ibv_cq, cq_fid.fid);
-		}
-		if (flags & FI_SEND) {
-			if (ep->scq)
-				return -EINVAL;
-			ep->scq = container_of(bfid, struct fi_ibv_cq, cq_fid.fid);
-			if (flags & FI_SELECTIVE_COMPLETION)
-				ep->ep_flags |= FI_SELECTIVE_COMPLETION;
-			else
-				ep->info->tx_attr->op_flags |= FI_COMPLETION;
-			ep->ep_id = ep->scq->send_signal_wr_id | ep->scq->ep_cnt++;
-		}
-		break;
-	case FI_CLASS_EQ:
-		ep->eq = container_of(bfid, struct fi_ibv_eq, eq_fid.fid);
-		ret = rdma_migrate_id(ep->id, ep->eq->channel);
-		if (ret)
-			return -errno;
-		break;
-	case FI_CLASS_SRX_CTX:
-		ep->srq_ep = container_of(bfid, struct fi_ibv_srq_ep, ep_fid.fid);
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	return 0;
-}
-
-static int fi_ibv_msg_ep_enable(struct fid_ep *ep_fid)
-{
-	struct ibv_qp_init_attr attr = { 0 };
-	struct fi_ibv_msg_ep *ep;
-	struct ibv_pd *pd;
-	int ret;
-
-	ep = container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	if (!ep->eq) {
-		VERBS_WARN(FI_LOG_EP_CTRL,
-			   "Endpoint is not bound to an event queue\n");
-		return -FI_ENOEQ;
-	}
-
-	if (!ep->scq && !ep->rcq) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
-			   "a send or receive completion queue\n");
-		return -FI_ENOCQ;
-	}
-
-	if (!ep->scq && (ofi_send_allowed(ep->info->caps) ||
-				ofi_rma_initiate_allowed(ep->info->caps))) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
-			   "a send completion queue when it has transmit "
-			   "capabilities enabled (FI_SEND | FI_RMA).\n");
-		return -FI_ENOCQ;
-	}
-
-	if (!ep->rcq && ofi_recv_allowed(ep->info->caps)) {
-		VERBS_WARN(FI_LOG_EP_CTRL, "Endpoint is not bound to "
-			   "a receive completion queue when it has receive "
-			   "capabilities enabled. (FI_RECV)\n");
-		return -FI_ENOCQ;
-	}
-
-	if (ep->scq) {
-		attr.cap.max_send_wr = ep->info->tx_attr->size;
-		attr.cap.max_send_sge = ep->info->tx_attr->iov_limit;
-		attr.send_cq = ep->scq->cq;
-		pd = ep->scq->domain->pd;
-	} else {
-		attr.send_cq = ep->rcq->cq;
-		pd = ep->rcq->domain->pd;
-	}
-
-	if (ep->rcq) {
-		attr.cap.max_recv_wr = ep->info->rx_attr->size;
-		attr.cap.max_recv_sge = ep->info->rx_attr->iov_limit;
-		attr.recv_cq = ep->rcq->cq;
-	} else {
-		attr.recv_cq = ep->scq->cq;
-	}
-
-	attr.cap.max_inline_data = ep->info->tx_attr->inject_size;
-
-	if (ep->srq_ep) {
-		attr.srq = ep->srq_ep->srq;
-		/* Use of SRQ, no need to allocate recv_wr entries in the QP */
-		attr.cap.max_recv_wr = 0;
-
-		/* Override the default ops to prevent the user from posting WRs to a
-		 * QP where a SRQ is attached to */
-		ep->ep_fid.msg = &fi_ibv_msg_srq_ep_msg_ops;
-	}
-
-	attr.qp_type = IBV_QPT_RC;
-	attr.sq_sig_all = 0;
-	attr.qp_context = ep;
-
-	ret = rdma_create_qp(ep->id, pd, &attr);
-	if (ret) {
-		ret = -errno;
-		VERBS_WARN(FI_LOG_EP_CTRL, "Unable to create rdma qp: %s (%d)\n",
-			   fi_strerror(-ret), -ret);
-		return ret;
-	}
-	return 0;
-}
-
-static int fi_ibv_msg_ep_control(struct fid *fid, int command, void *arg)
-{
-	struct fid_ep *ep;
-
-	switch (fid->fclass) {
-	case FI_CLASS_EP:
-		ep = container_of(fid, struct fid_ep, fid);
-		switch (command) {
-		case FI_ENABLE:
-			return fi_ibv_msg_ep_enable(ep);
-			break;
-		default:
-			return -FI_ENOSYS;
-		}
-		break;
-	default:
-		return -FI_ENOSYS;
-	}
-}
-
-static struct fi_ops fi_ibv_msg_ep_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = fi_ibv_msg_ep_close,
-	.bind = fi_ibv_msg_ep_bind,
-	.control = fi_ibv_msg_ep_control,
-	.ops_open = fi_no_ops_open,
-};
-
-int fi_ibv_open_ep(struct fid_domain *domain, struct fi_info *info,
-		   struct fid_ep **ep_fid, void *context)
-{
-	struct fi_ibv_domain *dom;
-	struct fi_ibv_msg_ep *ep;
-	struct fi_ibv_connreq *connreq;
-	struct fi_ibv_pep *pep;
-	struct fi_info *fi;
-	int ret;
-
-	dom = container_of(domain, struct fi_ibv_domain,
-			   util_domain.domain_fid);
-	if (strcmp(dom->verbs->device->name, info->domain_attr->name)) {
-		VERBS_INFO(FI_LOG_DOMAIN, "Invalid info->domain_attr->name\n");
-		return -FI_EINVAL;
-	}
-
-	fi = dom->info;
-
-	if (info->ep_attr) {
-		ret = fi_ibv_check_ep_attr(info, fi);
-		if (ret)
-			return ret;
-	}
-
-	if (info->tx_attr) {
-		ret = ofi_check_tx_attr(&fi_ibv_prov, fi->tx_attr,
-					info->tx_attr, info->mode);
-		if (ret)
-			return ret;
-	}
-
-	if (info->rx_attr) {
-		ret = fi_ibv_check_rx_attr(info->rx_attr, info, fi);
-		if (ret)
-			return ret;
-	}
-
-	ep = fi_ibv_alloc_msg_ep(info);
-	if (!ep)
-		return -FI_ENOMEM;
-
-	if (!info->handle) {
-		ret = fi_ibv_create_ep(NULL, NULL, 0, info, NULL, &ep->id);
-		if (ret)
-			goto err1;
-	} else if (info->handle->fclass == FI_CLASS_CONNREQ) {
-		connreq = container_of(info->handle, struct fi_ibv_connreq, handle);
-		ep->id = connreq->id;
-        } else if (info->handle->fclass == FI_CLASS_PEP) {
-		pep = container_of(info->handle, struct fi_ibv_pep, pep_fid.fid);
-		ep->id = pep->id;
-		pep->id = NULL;
-
-		if (rdma_resolve_addr(ep->id, info->src_addr, info->dest_addr,
-				      VERBS_RESOLVE_TIMEOUT)) {
-			ret = -errno;
-			VERBS_INFO(FI_LOG_DOMAIN, "Unable to rdma_resolve_addr\n");
-			goto err2;
-		}
-
-		if (rdma_resolve_route(ep->id, VERBS_RESOLVE_TIMEOUT)) {
-			ret = -errno;
-			VERBS_INFO(FI_LOG_DOMAIN, "Unable to rdma_resolve_route\n");
-			goto err2;
-		}
-	} else {
-		ret = -FI_ENOSYS;
-		goto err1;
-	}
-
-	fastlock_init(&ep->wre_lock);
-	ret = util_buf_pool_create(&ep->wre_pool, sizeof(struct fi_ibv_wre),
-				   16, 0, VERBS_WRE_CNT);
-	if (ret) {
-		VERBS_WARN(FI_LOG_CQ, "Failed to create wre_pool\n");
-		goto err3;
-	}
-	dlist_init(&ep->wre_list);
-
-	ep->id->context = &ep->ep_fid.fid;
-	ep->ep_fid.fid.fclass = FI_CLASS_EP;
-	ep->ep_fid.fid.context = context;
-	ep->ep_fid.fid.ops = &fi_ibv_msg_ep_ops;
-	ep->ep_fid.ops = &fi_ibv_msg_ep_base_ops;
-	ep->ep_fid.msg = &fi_ibv_msg_ep_msg_ops;
-	ep->ep_fid.cm = &fi_ibv_msg_ep_cm_ops;
-	ep->ep_fid.rma = &fi_ibv_msg_ep_rma_ops;
-	ep->ep_fid.atomic = &fi_ibv_msg_ep_atomic_ops;
-
-	ofi_atomic_initialize32(&ep->unsignaled_send_cnt, 0);
-	ofi_atomic_initialize32(&ep->comp_pending, 0);
-	/* The `send_signal_thr` and `send_comp_thr` values are necessary to avoid
-	 * overrun the send queue size */
-	/* A signaled Send Request must be posted when the `send_signal_thr`
-	 * value is reached */
-	ep->send_signal_thr = (ep->info->tx_attr->size * 4) / 5;
-	/* Polling of CQ for internal signaled Send Requests must be initiated upon
-	 * reaching the `send_comp_thr` value */
-	ep->send_comp_thr = (ep->info->tx_attr->size * 9) / 10;
-
-	ep->domain = dom;
-	*ep_fid = &ep->ep_fid;
-
-	return FI_SUCCESS;
-err3:
-	fastlock_destroy(&ep->wre_lock);
-err2:
-	rdma_destroy_ep(ep->id);
-err1:
-	fi_ibv_free_msg_ep(ep);
-	return ret;
-}
-
-static int fi_ibv_pep_bind(fid_t fid, struct fid *bfid, uint64_t flags)
-{
-	struct fi_ibv_pep *pep;
-	int ret;
-
-	pep = container_of(fid, struct fi_ibv_pep, pep_fid.fid);
-	if (bfid->fclass != FI_CLASS_EQ)
-		return -FI_EINVAL;
-
-	pep->eq = container_of(bfid, struct fi_ibv_eq, eq_fid.fid);
-	ret = rdma_migrate_id(pep->id, pep->eq->channel);
-	if (ret)
-		return -errno;
-
-	return 0;
-}
-
-static int fi_ibv_pep_control(struct fid *fid, int command, void *arg)
-{
-	struct fi_ibv_pep *pep;
-	int ret = 0;
-
-	switch (fid->fclass) {
-	case FI_CLASS_PEP:
-		pep = container_of(fid, struct fi_ibv_pep, pep_fid.fid);
-		switch (command) {
-		case FI_BACKLOG:
-			if (!arg)
-				return -FI_EINVAL;
-			pep->backlog = *(int *) arg;
-			break;
-		default:
-			ret = -FI_ENOSYS;
-			break;
-		}
-		break;
-	default:
-		ret = -FI_ENOSYS;
-		break;
-	}
-
-	return ret;
-}
-
-static int fi_ibv_pep_close(fid_t fid)
-{
-	struct fi_ibv_pep *pep;
-
-	pep = container_of(fid, struct fi_ibv_pep, pep_fid.fid);
-	if (pep->id)
-		rdma_destroy_ep(pep->id);
-
-	fi_freeinfo(pep->info);
-	free(pep);
-	return 0;
-}
-
-static struct fi_ops fi_ibv_pep_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = fi_ibv_pep_close,
-	.bind = fi_ibv_pep_bind,
-	.control = fi_ibv_pep_control,
-	.ops_open = fi_no_ops_open,
-};
-
-static struct fi_ops_ep fi_ibv_pep_ops = {
-	.size = sizeof(struct fi_ops_ep),
-	.getopt = fi_ibv_msg_ep_getopt,
-	.setopt = fi_no_setopt,
-	.tx_ctx = fi_no_tx_ctx,
-	.rx_ctx = fi_no_rx_ctx,
-	.rx_size_left = fi_no_rx_size_left,
-	.tx_size_left = fi_no_tx_size_left,
-};
-
-int fi_ibv_passive_ep(struct fid_fabric *fabric, struct fi_info *info,
-		      struct fid_pep **pep, void *context)
-{
-	struct fi_ibv_pep *_pep;
-	int ret;
-
-	_pep = calloc(1, sizeof *_pep);
-	if (!_pep)
-		return -FI_ENOMEM;
-
-	if (!(_pep->info = fi_dupinfo(info))) {
-		ret = -FI_ENOMEM;
-		goto err1;
-	}
-
-	ret = rdma_create_id(NULL, &_pep->id, &_pep->pep_fid.fid, RDMA_PS_TCP);
-	if (ret) {
-		VERBS_INFO(FI_LOG_DOMAIN, "Unable to create rdma_cm_id\n");
-		goto err2;
-	}
-
-	if (info->src_addr) {
-		ret = rdma_bind_addr(_pep->id, (struct sockaddr *)info->src_addr);
-		if (ret) {
-			VERBS_INFO(FI_LOG_DOMAIN, "Unable to bind address to rdma_cm_id\n");
-			goto err3;
-		}
-		_pep->bound = 1;
-	}
-
-	_pep->pep_fid.fid.fclass = FI_CLASS_PEP;
-	_pep->pep_fid.fid.context = context;
-	_pep->pep_fid.fid.ops = &fi_ibv_pep_fi_ops;
-	_pep->pep_fid.ops = &fi_ibv_pep_ops;
-	_pep->pep_fid.cm = fi_ibv_pep_ops_cm(_pep);
-
-	_pep->src_addrlen = info->src_addrlen;
-
-	*pep = &_pep->pep_fid;
-	return 0;
-
-err3:
-	rdma_destroy_id(_pep->id);
-err2:
-	fi_freeinfo(_pep->info);
-err1:
-	free(_pep);
-	return ret;
-}
-
-#define VERBS_SIGNAL_SEND(ep) \
-	(ofi_atomic_get32(&ep->unsignaled_send_cnt) >= (ep)->send_signal_thr && \
-	 !ofi_atomic_get32(&ep->comp_pending))
-
-static inline int
-fi_ibv_signal_send(struct fi_ibv_msg_ep *ep, struct ibv_send_wr *wr)
-{
-	struct fi_ibv_msg_epe *epe;
-
-	fastlock_acquire(&ep->scq->lock);
-	if (VERBS_SIGNAL_SEND(ep)) {
-		epe = util_buf_alloc(ep->scq->epe_pool);
-		if (!epe) {
-			fastlock_release(&ep->scq->lock);
-			return -FI_ENOMEM;
-		}
-		memset(epe, 0, sizeof(*epe));
-		wr->send_flags |= IBV_SEND_SIGNALED;
-		wr->wr_id = ep->ep_id;
-		epe->ep = ep;
-		slist_insert_tail(&epe->entry, &ep->scq->ep_list);
-		ofi_atomic_inc32(&ep->comp_pending);
-	}
-	fastlock_release(&ep->scq->lock);
-	return 0;
-}
-
-static inline int
-fi_ibv_prepare_signal_send(struct fi_ibv_msg_ep *ep, struct ibv_send_wr *wr,
-			   struct fi_ibv_wre **wre, void *context)
-{
-	fastlock_acquire(&ep->wre_lock);
-	*wre = util_buf_alloc(ep->wre_pool);
-	if (OFI_UNLIKELY(!*wre)) {
-		fastlock_release(&ep->wre_lock);
-		return -FI_EAGAIN;
-	}
-	dlist_insert_tail(&(*wre)->entry, &ep->wre_list);
-	fastlock_release(&ep->wre_lock);
-
-	(*wre)->context = context;
-	(*wre)->ep = ep;
-	(*wre)->wr_type = IBV_SEND_WR;
-	wr->wr_id = (uintptr_t)*wre;
-
-	assert((wr->wr_id & ep->scq->wr_id_mask) != ep->scq->send_signal_wr_id);
-	ofi_atomic_set32(&ep->unsignaled_send_cnt, 0);
-
-	return FI_SUCCESS;
-}
-
-static int fi_ibv_reap_comp(struct fi_ibv_msg_ep *ep)
-{
-	struct fi_ibv_wce *wce = NULL;
-	int got_wc = 0;
-	int ret = 0;
-
-	fastlock_acquire(&ep->scq->lock);
-	while (ofi_atomic_get32(&ep->comp_pending) > 0) {
-		if (!wce) {
-			wce = util_buf_alloc(ep->scq->wce_pool);
-			if (!wce) {
-				fastlock_release(&ep->scq->lock);
-				return -FI_ENOMEM;
-			}
-			memset(wce, 0, sizeof(*wce));
-		}
-		ret = fi_ibv_poll_cq(ep->scq, &wce->wc);
-		if (ret < 0) {
-			VERBS_WARN(FI_LOG_EP_DATA,
-				   "Failed to read completion for signaled send\n");
-			util_buf_release(ep->scq->wce_pool, wce);
-			fastlock_release(&ep->scq->lock);
-			return ret;
-		} else if (ret > 0) {
-			slist_insert_tail(&wce->entry, &ep->scq->wcq);
-			got_wc = 1;
-			wce = NULL;
-		}
-	}
-	if (wce)
-		util_buf_release(ep->scq->wce_pool, wce);
-
-	if (got_wc && ep->scq->channel)
-		ret = fi_ibv_cq_signal(&ep->scq->cq_fid);
-
-	fastlock_release(&ep->scq->lock);
-	return ret;
-}
-
-/* WR must be filled out by now except for context */
-static inline ssize_t
-fi_ibv_send(struct fi_ibv_msg_ep *ep, struct ibv_send_wr *wr, void *context)
-{
-	struct fi_ibv_wre *wre = NULL;
-	int ret;
-
-	if (wr->send_flags & IBV_SEND_SIGNALED) {
-		ret = fi_ibv_prepare_signal_send(ep, wr, &wre, context);
-		if (OFI_UNLIKELY(ret))
-			return ret;
-	} else {
-		if (VERBS_SIGNAL_SEND(ep)) {
-			ret = fi_ibv_signal_send(ep, wr);
-			if (ret)
-				return ret;
-		} else {
-			wr->wr_id = 0ULL;
-			if (ofi_atomic_inc32(&ep->unsignaled_send_cnt) >=
-							ep->send_comp_thr) {
-				ret = fi_ibv_reap_comp(ep);
-				if (ret)
-					return ret;
-			}
-		}
-	}
-
-	return FI_IBV_INVOKE_POST(send, send, ep->id->qp, wr,
-				  FI_IBV_RELEASE_WRE(ep, wre));
-}
-
-static inline ssize_t
-fi_ibv_send_buf(struct fi_ibv_msg_ep *ep, struct ibv_send_wr *wr,
-		const void *buf, size_t len, void *desc, void *context)
-{
-	struct ibv_sge sge = fi_ibv_init_sge(buf, len, desc);
-
-	wr->sg_list = &sge;
-	wr->num_sge = 1;
-
-	return fi_ibv_send(ep, wr, context);
-}
-
-static inline ssize_t
-fi_ibv_send_buf_inline(struct fi_ibv_msg_ep *ep, struct ibv_send_wr *wr,
-		       const void *buf, size_t len)
-{
-	struct ibv_sge sge = fi_ibv_init_sge_inline(buf, len);
-
-	wr->sg_list = &sge;
-	wr->num_sge = 1;
-
-	return fi_ibv_send(ep, wr, NULL);
-}
-
-static inline ssize_t
-fi_ibv_send_iov_flags(struct fi_ibv_msg_ep *ep, struct ibv_send_wr *wr,
-		      const struct iovec *iov, void **desc, int count,
-		      void *context, uint64_t flags)
-{
-	size_t len = 0;
-
-	if (!desc)
-		fi_ibv_set_sge_iov_inline(wr->sg_list, iov, count, len);
-	else
-		fi_ibv_set_sge_iov(wr->sg_list, iov, count, desc, len);
-
-	wr->num_sge = count;
-	wr->send_flags = VERBS_INJECT_FLAGS(ep, len, flags) | VERBS_COMP_FLAGS(ep, flags);
-
-	if (flags & FI_FENCE)
-		wr->send_flags |= IBV_SEND_FENCE;
-
-	return fi_ibv_send(ep, wr, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg, uint64_t flags)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct fi_ibv_wre *wre;
-	struct ibv_sge *sge = NULL;
-	struct ibv_recv_wr wr = {
-		.num_sge = msg->iov_count,
-		.next = NULL,
-	};
-	size_t i;
-
-	assert(ep->rcq);
-
-	fastlock_acquire(&ep->wre_lock);
-	wre = util_buf_alloc(ep->wre_pool);
-	if (OFI_UNLIKELY(!wre)) {
-		fastlock_release(&ep->wre_lock);
-		return -FI_EAGAIN;
-	}
-	dlist_insert_tail(&wre->entry, &ep->wre_list);
-	fastlock_release(&ep->wre_lock);
-
-	wre->ep = ep;
-	wre->srq = NULL;
-	wre->context = msg->context;
-	wre->wr_type = IBV_RECV_WR;
-
-	wr.wr_id = (uintptr_t)wre;
-	sge = alloca(sizeof(*sge) * msg->iov_count);
-	for (i = 0; i < msg->iov_count; i++) {
-		sge[i].addr = (uintptr_t)msg->msg_iov[i].iov_base;
-		sge[i].length = (uint32_t)msg->msg_iov[i].iov_len;
-		sge[i].lkey = (uint32_t)(uintptr_t)(msg->desc[i]);
-	}
-	wr.sg_list = sge;
-
-	return FI_IBV_INVOKE_POST(recv, recv, ep->id->qp, &wr,
-				  FI_IBV_RELEASE_WRE(ep, wre));
-}
-
-static ssize_t
-fi_ibv_msg_ep_recv(struct fid_ep *ep, void *buf, size_t len,
-		void *desc, fi_addr_t src_addr, void *context)
-{
-	struct iovec iov = {
-		.iov_base = buf,
-		.iov_len = len,
-	};
-	struct fi_msg msg = {
-		.msg_iov = &iov,
-		.desc = &desc,
-		.iov_count = 1,
-		.addr = src_addr,
-		.context = context,
-	};
-
-	return fi_ibv_msg_ep_recvmsg(ep, &msg, 0);
-}
-
-static ssize_t
-fi_ibv_msg_ep_recvv(struct fid_ep *ep, const struct iovec *iov, void **desc,
-                 size_t count, fi_addr_t src_addr, void *context)
-{
-	struct fi_msg msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = src_addr,
-		.context = context,
-	};
-
-	return fi_ibv_msg_ep_recvmsg(ep, &msg, 0);
-}
-
-static ssize_t
-fi_ibv_msg_ep_sendmsg(struct fid_ep *ep_fid, const struct fi_msg *msg, uint64_t flags)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = { 0 };
-
-	if (flags & FI_REMOTE_CQ_DATA) {
-		wr.opcode = IBV_WR_SEND_WITH_IMM;
-		wr.imm_data = htonl((uint32_t)msg->data);
-	} else {
-		wr.opcode = IBV_WR_SEND;
-	}
-
-	return fi_ibv_send_msg(ep, &wr, msg, flags);
-}
-
-static ssize_t
-fi_ibv_msg_ep_send(struct fid_ep *ep_fid, const void *buf, size_t len,
-		void *desc, fi_addr_t dest_addr, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_SEND,
-		.send_flags = VERBS_INJECT(ep, len) | VERBS_COMP(ep),
-	};
-
-	return fi_ibv_send_buf(ep, &wr, buf, len, desc, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_senddata(struct fid_ep *ep_fid, const void *buf, size_t len,
-		    void *desc, uint64_t data, fi_addr_t dest_addr, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_SEND_WITH_IMM,
-		.imm_data = htonl((uint32_t)data),
-		.send_flags = VERBS_INJECT(ep, len) | VERBS_COMP(ep),
-	};
-
-	return fi_ibv_send_buf(ep, &wr, buf, len, desc, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_sendv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
-                 size_t count, fi_addr_t dest_addr, void *context)
-{
-	struct fi_ibv_msg_ep *ep;
-	struct ibv_send_wr wr = { 0 };
-
-	wr.opcode = IBV_WR_SEND;
-
-	ep = container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	return fi_ibv_send_iov(ep, &wr, iov, desc, count, context);
-}
-
-static ssize_t fi_ibv_msg_ep_inject(struct fid_ep *ep_fid, const void *buf, size_t len,
-		fi_addr_t dest_addr)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_SEND,
-		.send_flags = IBV_SEND_INLINE,
-	};
-
-	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
-}
-
-static ssize_t fi_ibv_msg_ep_injectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
-		    uint64_t data, fi_addr_t dest_addr)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_SEND_WITH_IMM,
-		.imm_data = htonl((uint32_t)data),
-		.send_flags = IBV_SEND_INLINE,
-	};
-
-	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
-}
-
-struct fi_ops_msg fi_ibv_msg_ep_msg_ops = {
-	.size = sizeof(struct fi_ops_msg),
-	.recv = fi_ibv_msg_ep_recv,
-	.recvv = fi_ibv_msg_ep_recvv,
-	.recvmsg = fi_ibv_msg_ep_recvmsg,
-	.send = fi_ibv_msg_ep_send,
-	.sendv = fi_ibv_msg_ep_sendv,
-	.sendmsg = fi_ibv_msg_ep_sendmsg,
-	.inject = fi_ibv_msg_ep_inject,
-	.senddata = fi_ibv_msg_ep_senddata,
-	.injectdata = fi_ibv_msg_ep_injectdata,
-};
-
-struct fi_ops_msg fi_ibv_msg_srq_ep_msg_ops = {
-	.size = sizeof(struct fi_ops_msg),
-	.recv = fi_no_msg_recv,
-	.recvv = fi_no_msg_recvv,
-	.recvmsg = fi_no_msg_recvmsg,
-	.send = fi_ibv_msg_ep_send,
-	.sendv = fi_ibv_msg_ep_sendv,
-	.sendmsg = fi_ibv_msg_ep_sendmsg,
-	.inject = fi_ibv_msg_ep_inject,
-	.senddata = fi_ibv_msg_ep_senddata,
-	.injectdata = fi_ibv_msg_ep_injectdata,
-};
-
-#define VERBS_COMP_READ_FLAGS(ep, flags) \
-	((!VERBS_SELECTIVE_COMP(ep) || (flags & \
-	  (FI_COMPLETION | FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE))) ? \
-	   IBV_SEND_SIGNALED : 0)
-#define VERBS_COMP_READ(ep) \
-	VERBS_COMP_READ_FLAGS(ep, ep->info->tx_attr->op_flags)
-
-static ssize_t
-fi_ibv_msg_ep_rma_write(struct fid_ep *ep_fid, const void *buf, size_t len,
-		     void *desc, fi_addr_t dest_addr,
-		     uint64_t addr, uint64_t key, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_WRITE,
-		.wr.rdma.remote_addr = addr,
-		.wr.rdma.rkey = (uint32_t)key,
-		.send_flags = VERBS_INJECT(ep, len) | VERBS_COMP(ep),
-	};
-
-	return fi_ibv_send_buf(ep, &wr, buf, len, desc, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_rma_writev(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
-		      size_t count, fi_addr_t dest_addr,
-		      uint64_t addr, uint64_t key, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_WRITE,
-		.wr.rdma.remote_addr = addr,
-		.wr.rdma.rkey = (uint32_t)key
-	};
-
-	return fi_ibv_send_iov(ep, &wr, iov, desc, count, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_rma_writemsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
-			uint64_t flags)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.wr.rdma.remote_addr = msg->rma_iov->addr,
-		.wr.rdma.rkey = (uint32_t)msg->rma_iov->key,
-	};
-
-	if (flags & FI_REMOTE_CQ_DATA) {
-		wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;
-		wr.imm_data = htonl((uint32_t)msg->data);
-	} else {
-		wr.opcode = IBV_WR_RDMA_WRITE;
-	}
-
-	return fi_ibv_send_msg(ep, &wr, msg, flags);
-}
-
-static ssize_t
-fi_ibv_msg_ep_rma_read(struct fid_ep *ep_fid, void *buf, size_t len,
-		    void *desc, fi_addr_t src_addr,
-		    uint64_t addr, uint64_t key, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_READ,
-		.wr.rdma.remote_addr = addr,
-		.wr.rdma.rkey = (uint32_t)key,
-		.send_flags = VERBS_COMP_READ(ep),
-	};
-
-	return fi_ibv_send_buf(ep, &wr, buf, len, desc, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_rma_readv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
-		     size_t count, fi_addr_t src_addr,
-		     uint64_t addr, uint64_t key, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_READ,
-		.wr.rdma.remote_addr = addr,
-		.wr.rdma.rkey = (uint32_t)key,
-		.send_flags = VERBS_COMP_READ(ep),
-		.num_sge = count,
-	};
-	size_t len = 0;
-
-	fi_ibv_set_sge_iov(wr.sg_list, iov, count, desc, len);
-
-	return fi_ibv_send(ep, &wr, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_rma_readmsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
-			uint64_t flags)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_READ,
-		.wr.rdma.remote_addr = msg->rma_iov->addr,
-		.wr.rdma.rkey = (uint32_t)msg->rma_iov->key,
-		.send_flags = VERBS_COMP_READ_FLAGS(ep, flags),
-		.num_sge = msg->iov_count,
-	};
-	size_t len = 0;
-
-	fi_ibv_set_sge_iov(wr.sg_list, msg->msg_iov, msg->iov_count, msg->desc, len);
-
-	return fi_ibv_send(ep, &wr, msg->context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_rma_writedata(struct fid_ep *ep_fid, const void *buf, size_t len,
-			void *desc, uint64_t data, fi_addr_t dest_addr,
-			uint64_t addr, uint64_t key, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_WRITE_WITH_IMM,
-		.imm_data = htonl((uint32_t)data),
-		.wr.rdma.remote_addr = addr,
-		.wr.rdma.rkey = (uint32_t)key,
-		.send_flags = VERBS_INJECT(ep, len) | VERBS_COMP(ep),
-	};
-
-	return fi_ibv_send_buf(ep, &wr, buf, len, desc, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_rma_inject_write(struct fid_ep *ep_fid, const void *buf, size_t len,
-		     fi_addr_t dest_addr, uint64_t addr, uint64_t key)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_WRITE,
-		.wr.rdma.remote_addr = addr,
-		.wr.rdma.rkey = (uint32_t)key,
-		.send_flags = IBV_SEND_INLINE,
-	};
-
-	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
-}
-
-static ssize_t
-fi_ibv_msg_ep_rma_inject_writedata(struct fid_ep *ep_fid, const void *buf, size_t len,
-			uint64_t data, fi_addr_t dest_addr, uint64_t addr,
-			uint64_t key)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_WRITE_WITH_IMM,
-		.imm_data = htonl((uint32_t)data),
-		.wr.rdma.remote_addr = addr,
-		.wr.rdma.rkey = (uint32_t)key,
-		.send_flags = IBV_SEND_INLINE,
-	};
-
-	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
-}
-
-struct fi_ops_rma fi_ibv_msg_ep_rma_ops = {
-	.size = sizeof(struct fi_ops_rma),
-	.read = fi_ibv_msg_ep_rma_read,
-	.readv = fi_ibv_msg_ep_rma_readv,
-	.readmsg = fi_ibv_msg_ep_rma_readmsg,
-	.write = fi_ibv_msg_ep_rma_write,
-	.writev = fi_ibv_msg_ep_rma_writev,
-	.writemsg = fi_ibv_msg_ep_rma_writemsg,
-	.inject = fi_ibv_msg_ep_rma_inject_write,
-	.writedata = fi_ibv_msg_ep_rma_writedata,
-	.injectdata = fi_ibv_msg_ep_rma_inject_writedata,
-};
-
-#define fi_ibv_atomicvalid(name, flags)					\
-static int fi_ibv_msg_ep_atomic_ ## name(struct fid_ep *ep_fid,		\
-			      enum fi_datatype datatype,  		\
-			      enum fi_op op, size_t *count)             \
-{                                                                       \
-	struct fi_ibv_msg_ep *ep = container_of(ep_fid,			\
-						struct fi_ibv_msg_ep,   \
-						ep_fid);                \
-	struct fi_atomic_attr attr;                                     \
-	int ret;                                                        \
-                                                                        \
-	ret = fi_ibv_query_atomic(&ep->domain->util_domain.domain_fid,	\
-				  datatype, op, &attr, flags);		\
-	if (!ret)                                                       \
-		*count = attr.count;                                    \
-	return ret;                                                     \
-}                                                                       \
-
-fi_ibv_atomicvalid(writevalid, 0);
-fi_ibv_atomicvalid(readwritevalid, FI_FETCH_ATOMIC);
-fi_ibv_atomicvalid(compwritevalid, FI_COMPARE_ATOMIC);
-
-int fi_ibv_query_atomic(struct fid_domain *domain_fid, enum fi_datatype datatype,
-			enum fi_op op, struct fi_atomic_attr *attr,
-			uint64_t flags)
-{
-	struct fi_ibv_domain *domain = container_of(domain_fid,
-						    struct fi_ibv_domain,
-						    util_domain.domain_fid);
-	char *log_str_fetch = "fi_fetch_atomic with FI_SUM op";
-	char *log_str_comp = "fi_compare_atomic";
-	char *log_str;
-
-	if (flags & FI_TAGGED)
-		return -FI_ENOSYS;
-
-	if ((flags & FI_FETCH_ATOMIC) && (flags & FI_COMPARE_ATOMIC))
-		return -FI_EBADFLAGS;
-
-	if (!flags) {
-		switch (op) {
-		case FI_ATOMIC_WRITE:
-			break;
-		default:
-			return -FI_ENOSYS;
-		}
-	} else {
-		if (flags & FI_FETCH_ATOMIC) {
-			switch (op) {
-			case FI_ATOMIC_READ:
-				goto check_datatype;
-			case FI_SUM:
-				log_str = log_str_fetch;
-				break;
-			default:
-				return -FI_ENOSYS;
-			}
-		} else if (flags & FI_COMPARE_ATOMIC) {
-			if (op != FI_CSWAP)
-				return -FI_ENOSYS;
-			log_str = log_str_comp;
-		} else {
-			return  -FI_EBADFLAGS;
-		}
-		if (domain->info->tx_attr->op_flags & FI_INJECT) {
-			VERBS_INFO(FI_LOG_EP_DATA,
-				   "FI_INJECT not supported for %s\n", log_str);
-			return -FI_EINVAL;
-		}
-	}
-check_datatype:
-	switch (datatype) {
-	case FI_INT64:
-	case FI_UINT64:
-#if __BITS_PER_LONG == 64
-	case FI_DOUBLE:
-	case FI_FLOAT:
-#endif
-		break;
-	default:
-		return -FI_EINVAL;
-	}
-
-	attr->size = ofi_datatype_size(datatype);
-	if (attr->size == 0)
-		return -FI_EINVAL;
-
-	attr->count = 1;
-	return 0;
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_write(struct fid_ep *ep_fid, const void *buf, size_t count,
-			void *desc, fi_addr_t dest_addr, uint64_t addr, uint64_t key,
-			enum fi_datatype datatype, enum fi_op op, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_RDMA_WRITE,
-		.wr.rdma.remote_addr = addr,
-		.wr.rdma.rkey = (uint32_t)(uintptr_t)key,
-		.send_flags = VERBS_INJECT(ep, sizeof(uint64_t)) |
-			      VERBS_COMP(ep) | IBV_SEND_FENCE,
-	};
-	size_t count_copy;
-	int ret;
-
-	if (OFI_UNLIKELY(count != 1))
-		return -FI_E2BIG;
-
-	if (OFI_UNLIKELY(op != FI_ATOMIC_WRITE))
-		return -FI_ENOSYS;
-
-	count_copy = count;
-
-	ret = fi_ibv_msg_ep_atomic_writevalid(ep_fid, datatype, op, &count_copy);
-	if (ret)
-		return ret;
-
-	return fi_ibv_send_buf(ep, &wr, buf, sizeof(uint64_t), desc, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_writev(struct fid_ep *ep,
-                        const struct fi_ioc *iov, void **desc, size_t count,
-                        fi_addr_t dest_addr, uint64_t addr, uint64_t key,
-                        enum fi_datatype datatype, enum fi_op op, void *context)
-{
-	if (OFI_UNLIKELY(iov->count != 1))
-		return -FI_E2BIG;
-
-	return fi_ibv_msg_ep_atomic_write(ep, iov->addr, count, desc[0],
-			dest_addr, addr, key, datatype, op, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_writemsg(struct fid_ep *ep_fid,
-                        const struct fi_msg_atomic *msg, uint64_t flags)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.wr.rdma.remote_addr = msg->rma_iov->addr,
-		.wr.rdma.rkey = (uint32_t)(uintptr_t)msg->rma_iov->key,
-		.send_flags = VERBS_INJECT_FLAGS(ep, sizeof(uint64_t), flags) |
-			      VERBS_COMP_FLAGS(ep, flags) | IBV_SEND_FENCE,
-	};
-	size_t count_copy;
-	int ret;
-
-	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
-		return -FI_E2BIG;
-
-	if (OFI_UNLIKELY(msg->op != FI_ATOMIC_WRITE))
-		return -FI_ENOSYS;
-
-	count_copy = msg->iov_count;
-
-	ret = fi_ibv_msg_ep_atomic_writevalid(ep_fid, msg->datatype, msg->op,
-			&count_copy);
-	if (ret)
-		return ret;
-
-	if (flags & FI_REMOTE_CQ_DATA) {
-		wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;
-		wr.imm_data = htonl((uint32_t)msg->data);
-	} else {
-		wr.opcode = IBV_WR_RDMA_WRITE;
-	}
-
-	return fi_ibv_send_buf(ep, &wr, msg->msg_iov->addr, sizeof(uint64_t),
-			msg->desc[0], msg->context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_readwrite(struct fid_ep *ep_fid, const void *buf, size_t count,
-			void *desc, void *result, void *result_desc,
-			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
-			enum fi_datatype datatype,
-			enum fi_op op, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.send_flags = VERBS_COMP(ep) | IBV_SEND_FENCE,
-	};
-	size_t count_copy;
-	int ret;
-
-	if (OFI_UNLIKELY(count != 1))
-		return -FI_E2BIG;
-
-	count_copy = count;
-
-	ret = fi_ibv_msg_ep_atomic_readwritevalid(ep_fid, datatype, op,
-			&count_copy);
-	if (ret)
-		return ret;
-
-	switch (op) {
-	case FI_ATOMIC_READ:
-		wr.opcode = IBV_WR_RDMA_READ;
-		wr.wr.rdma.remote_addr = addr;
-		wr.wr.rdma.rkey = (uint32_t)(uintptr_t)key;
-		break;
-	case FI_SUM:
-		wr.opcode = IBV_WR_ATOMIC_FETCH_AND_ADD;
-		wr.wr.atomic.remote_addr = addr;
-		wr.wr.atomic.compare_add = (uintptr_t)buf;
-		wr.wr.atomic.swap = 0;
-		wr.wr.atomic.rkey = (uint32_t)(uintptr_t)key;
-		break;
-	default:
-		return -FI_ENOSYS;
-	}
-
-	return fi_ibv_send_buf(ep, &wr, result, sizeof(uint64_t), result_desc,
-		context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_readwritev(struct fid_ep *ep, const struct fi_ioc *iov,
-			void **desc, size_t count,
-			struct fi_ioc *resultv, void **result_desc,
-			size_t result_count, fi_addr_t dest_addr, uint64_t addr,
-			uint64_t key, enum fi_datatype datatype,
-			enum fi_op op, void *context)
-{
-	if (OFI_UNLIKELY(iov->count != 1))
-		return -FI_E2BIG;
-
-        return fi_ibv_msg_ep_atomic_readwrite(ep, iov->addr, count,
-			desc[0], resultv->addr, result_desc[0],
-			dest_addr, addr, key, datatype, op, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_readwritemsg(struct fid_ep *ep_fid,
-				const struct fi_msg_atomic *msg,
-				struct fi_ioc *resultv, void **result_desc,
-				size_t result_count, uint64_t flags)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.send_flags = VERBS_COMP_FLAGS(ep, flags) | IBV_SEND_FENCE,
-	};
-	size_t count_copy;
-	int ret;
-
-	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
-		return -FI_E2BIG;
-
-	count_copy = msg->iov_count;
-
-	ret = fi_ibv_msg_ep_atomic_readwritevalid(ep_fid, msg->datatype, msg->op,
-		       &count_copy);
-	if (ret)
-		return ret;
-
-	switch (msg->op) {
-	case FI_ATOMIC_READ:
-		wr.opcode = IBV_WR_RDMA_READ;
-		wr.wr.rdma.remote_addr = msg->rma_iov->addr;
-		wr.wr.rdma.rkey = (uint32_t) (uintptr_t) msg->rma_iov->key;
-		break;
-	case FI_SUM:
-		wr.opcode = IBV_WR_ATOMIC_FETCH_AND_ADD;
-		wr.wr.atomic.remote_addr = msg->rma_iov->addr;
-		wr.wr.atomic.compare_add = (uintptr_t) msg->addr;
-		wr.wr.atomic.swap = 0;
-		wr.wr.atomic.rkey = (uint32_t) (uintptr_t) msg->rma_iov->key;
-		break;
-	default:
-		return -FI_ENOSYS;
-	}
-
-	if (flags & FI_REMOTE_CQ_DATA)
-		wr.imm_data = htonl((uint32_t) msg->data);
-
-	return fi_ibv_send_buf(ep, &wr, resultv->addr, sizeof(uint64_t),
-			result_desc[0], msg->context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_compwrite(struct fid_ep *ep_fid, const void *buf, size_t count,
-			void *desc, const void *compare,
-			void *compare_desc, void *result,
-			void *result_desc,
-			fi_addr_t dest_addr, uint64_t addr, uint64_t key,
-			enum fi_datatype datatype,
-			enum fi_op op, void *context)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_ATOMIC_CMP_AND_SWP,
-		.wr.atomic.remote_addr = addr,
-		.wr.atomic.compare_add = (uintptr_t)compare,
-		.wr.atomic.swap = (uintptr_t)buf,
-		.wr.atomic.rkey = (uint32_t)(uintptr_t)key,
-		.send_flags = VERBS_COMP(ep) | IBV_SEND_FENCE,
-	};
-	size_t count_copy;
-	int ret;
-
-	if (OFI_UNLIKELY(count != 1))
-		return -FI_E2BIG;
-
-	count_copy = count;
-
-	ret = fi_ibv_msg_ep_atomic_compwritevalid(ep_fid, datatype, op, &count_copy);
-	if (ret)
-		return ret;
-
-	return fi_ibv_send_buf(ep, &wr, result, sizeof(uint64_t), result_desc, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_compwritev(struct fid_ep *ep, const struct fi_ioc *iov,
-				void **desc, size_t count,
-				const struct fi_ioc *comparev,
-				void **compare_desc, size_t compare_count,
-				struct fi_ioc *resultv, void **result_desc,
-				size_t result_count,
-				fi_addr_t dest_addr, uint64_t addr, uint64_t key,
-				enum fi_datatype datatype,
-				enum fi_op op, void *context)
-{
-	if (OFI_UNLIKELY(iov->count != 1))
-		return -FI_E2BIG;
-
-	return fi_ibv_msg_ep_atomic_compwrite(ep, iov->addr, count, desc[0],
-				comparev->addr, compare_desc[0], resultv->addr,
-				result_desc[0], dest_addr, addr, key,
-                        	datatype, op, context);
-}
-
-static ssize_t
-fi_ibv_msg_ep_atomic_compwritemsg(struct fid_ep *ep_fid,
-				const struct fi_msg_atomic *msg,
-				const struct fi_ioc *comparev,
-				void **compare_desc, size_t compare_count,
-				struct fi_ioc *resultv,
-				void **result_desc, size_t result_count,
-				uint64_t flags)
-{
-	struct fi_ibv_msg_ep *ep =
-		container_of(ep_fid, struct fi_ibv_msg_ep, ep_fid);
-	struct ibv_send_wr wr = {
-		.opcode = IBV_WR_ATOMIC_CMP_AND_SWP,
-		.wr.atomic.remote_addr = msg->rma_iov->addr,
-		.wr.atomic.compare_add = (uintptr_t)comparev->addr,
-		.wr.atomic.swap = (uintptr_t)msg->addr,
-		.wr.atomic.rkey = (uint32_t)(uintptr_t)msg->rma_iov->key,
-		.send_flags = VERBS_COMP_FLAGS(ep, flags) | IBV_SEND_FENCE,
-	};
-	size_t count_copy;
-	int ret;
-
-	if (OFI_UNLIKELY(msg->iov_count != 1 || msg->msg_iov->count != 1))
-		return -FI_E2BIG;
-
-	count_copy = msg->iov_count;
-
-	ret = fi_ibv_msg_ep_atomic_compwritevalid(ep_fid, msg->datatype, msg->op,
-		       &count_copy);
-	if (ret)
-		return ret;
-
-	if (flags & FI_REMOTE_CQ_DATA)
-		wr.imm_data = htonl((uint32_t) msg->data);
-
-	return fi_ibv_send_buf(ep, &wr, resultv->addr, sizeof(uint64_t),
-			result_desc[0], msg->context);
-}
-
-struct fi_ops_atomic fi_ibv_msg_ep_atomic_ops = {
-	.size		= sizeof(struct fi_ops_atomic),
-	.write		= fi_ibv_msg_ep_atomic_write,
-	.writev		= fi_ibv_msg_ep_atomic_writev,
-	.writemsg	= fi_ibv_msg_ep_atomic_writemsg,
-	.inject		= fi_no_atomic_inject,
-	.readwrite	= fi_ibv_msg_ep_atomic_readwrite,
-	.readwritev	= fi_ibv_msg_ep_atomic_readwritev,
-	.readwritemsg	= fi_ibv_msg_ep_atomic_readwritemsg,
-	.compwrite	= fi_ibv_msg_ep_atomic_compwrite,
-	.compwritev	= fi_ibv_msg_ep_atomic_compwritev,
-	.compwritemsg	= fi_ibv_msg_ep_atomic_compwritemsg,
-	.writevalid	= fi_ibv_msg_ep_atomic_writevalid,
-	.readwritevalid	= fi_ibv_msg_ep_atomic_readwritevalid,
-	.compwritevalid = fi_ibv_msg_ep_atomic_compwritevalid
-};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_rma.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_rma.c
new file mode 100644
index 000000000..702c8959d
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_rma.c
@@ -0,0 +1,533 @@
+/*
+ * Copyright (c) 2013-2018 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "config.h"
+
+#include "fi_verbs.h"
+
+
+#define VERBS_COMP_READ_FLAGS(ep, flags, context)		\
+	(((ep)->util_ep.tx_op_flags | (flags)) &			\
+	 (FI_COMPLETION | FI_TRANSMIT_COMPLETE |		\
+	  FI_DELIVERY_COMPLETE) ? context : VERBS_NO_COMP_FLAG)
+
+#define VERBS_COMP_READ(ep, context)		\
+	VERBS_COMP_READ_FLAGS(ep, 0, context)
+
+static ssize_t
+fi_ibv_msg_ep_rma_write(struct fid_ep *ep_fid, const void *buf, size_t len,
+		     void *desc, fi_addr_t dest_addr,
+		     uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_WRITE,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.send_flags = VERBS_INJECT(ep, len),
+	};
+
+	return fi_ibv_send_buf(ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_writev(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		      size_t count, fi_addr_t dest_addr,
+		      uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)context,
+		.opcode = IBV_WR_RDMA_WRITE,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+	};
+
+	return fi_ibv_send_iov(ep, &wr, iov, desc, count);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_writemsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
+			uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)msg->context,
+		.wr.rdma.remote_addr = msg->rma_iov->addr,
+		.wr.rdma.rkey = (uint32_t)msg->rma_iov->key,
+	};
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;
+		wr.imm_data = htonl((uint32_t)msg->data);
+	} else {
+		wr.opcode = IBV_WR_RDMA_WRITE;
+	}
+
+	return fi_ibv_send_msg(ep, &wr, msg, flags);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_read(struct fid_ep *ep_fid, void *buf, size_t len,
+		    void *desc, fi_addr_t src_addr,
+		    uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_READ(ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_READ,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+	};
+
+	return fi_ibv_send_buf(ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_readv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
+		     size_t count, fi_addr_t src_addr,
+		     uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_READ(ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_READ,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.num_sge = count,
+	};
+
+	fi_ibv_set_sge_iov(wr.sg_list, iov, count, desc);
+
+	return fi_ibv_send_poll_cq_if_needed(ep, &wr);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_readmsg(struct fid_ep *ep_fid, const struct fi_msg_rma *msg,
+			uint64_t flags)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_READ_FLAGS(ep, flags, (uintptr_t)msg->context),
+		.opcode = IBV_WR_RDMA_READ,
+		.wr.rdma.remote_addr = msg->rma_iov->addr,
+		.wr.rdma.rkey = (uint32_t)msg->rma_iov->key,
+		.num_sge = msg->iov_count,
+	};
+
+	fi_ibv_set_sge_iov(wr.sg_list, msg->msg_iov, msg->iov_count, msg->desc);
+
+	return fi_ibv_send_poll_cq_if_needed(ep, &wr);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_writedata(struct fid_ep *ep_fid, const void *buf, size_t len,
+			void *desc, uint64_t data, fi_addr_t dest_addr,
+			uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_WRITE_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.send_flags = VERBS_INJECT(ep, len),
+	};
+
+	return fi_ibv_send_buf(ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_inject_write(struct fid_ep *ep_fid, const void *buf, size_t len,
+		     fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_RDMA_WRITE,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
+}
+
+static ssize_t
+fi_ibv_rma_write_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+		      fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	struct fi_ibv_ep *ep;
+
+	ep = container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+
+	ep->wrs->rma_wr.wr.rdma.remote_addr = addr;
+	ep->wrs->rma_wr.wr.rdma.rkey = (uint32_t) key;
+
+	ep->wrs->sge.addr = (uintptr_t) buf;
+	ep->wrs->sge.length = (uint32_t) len;
+
+	return fi_ibv_send_poll_cq_if_needed(ep, &ep->wrs->rma_wr);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_inject_writedata(struct fid_ep *ep_fid, const void *buf, size_t len,
+			uint64_t data, fi_addr_t dest_addr, uint64_t addr,
+			uint64_t key)
+{
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_RDMA_WRITE_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	return fi_ibv_send_buf_inline(ep, &wr, buf, len);
+}
+
+static ssize_t
+fi_ibv_msg_ep_rma_inject_writedata_fast(struct fid_ep *ep_fid, const void *buf, size_t len,
+					uint64_t data, fi_addr_t dest_addr, uint64_t addr,
+					uint64_t key)
+{
+	ssize_t ret;
+	struct fi_ibv_ep *ep =
+		container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid);
+	ep->wrs->rma_wr.wr.rdma.remote_addr = addr;
+	ep->wrs->rma_wr.wr.rdma.rkey = (uint32_t) key;
+
+	ep->wrs->rma_wr.imm_data = htonl((uint32_t) data);
+	ep->wrs->rma_wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;
+
+	ep->wrs->sge.addr = (uintptr_t) buf;
+	ep->wrs->sge.length = (uint32_t) len;
+
+	ret = fi_ibv_send_poll_cq_if_needed(ep, &ep->wrs->rma_wr);
+	ep->wrs->rma_wr.opcode = IBV_WR_RDMA_WRITE;
+	return ret;
+}
+
+struct fi_ops_rma fi_ibv_msg_ep_rma_ops_ts = {
+	.size = sizeof(struct fi_ops_rma),
+	.read = fi_ibv_msg_ep_rma_read,
+	.readv = fi_ibv_msg_ep_rma_readv,
+	.readmsg = fi_ibv_msg_ep_rma_readmsg,
+	.write = fi_ibv_msg_ep_rma_write,
+	.writev = fi_ibv_msg_ep_rma_writev,
+	.writemsg = fi_ibv_msg_ep_rma_writemsg,
+	.inject = fi_ibv_msg_ep_rma_inject_write,
+	.writedata = fi_ibv_msg_ep_rma_writedata,
+	.injectdata = fi_ibv_msg_ep_rma_inject_writedata,
+};
+
+struct fi_ops_rma fi_ibv_msg_ep_rma_ops = {
+	.size = sizeof(struct fi_ops_rma),
+	.read = fi_ibv_msg_ep_rma_read,
+	.readv = fi_ibv_msg_ep_rma_readv,
+	.readmsg = fi_ibv_msg_ep_rma_readmsg,
+	.write = fi_ibv_msg_ep_rma_write,
+	.writev = fi_ibv_msg_ep_rma_writev,
+	.writemsg = fi_ibv_msg_ep_rma_writemsg,
+	.inject = fi_ibv_rma_write_fast,
+	.writedata = fi_ibv_msg_ep_rma_writedata,
+	.injectdata = fi_ibv_msg_ep_rma_inject_writedata_fast,
+};
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_write(struct fid_ep *ep_fid, const void *buf,
+		size_t len, void *desc, fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(&ep->base_ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_WRITE,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.send_flags = VERBS_INJECT(&ep->base_ep, len),
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_writev(struct fid_ep *ep_fid, const struct iovec *iov,
+		void **desc, size_t count, fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)context,
+		.opcode = IBV_WR_RDMA_WRITE,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_iov(&ep->base_ep, &wr, iov, desc, count);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_writemsg(struct fid_ep *ep_fid,
+			const struct fi_msg_rma *msg, uint64_t flags)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = (uintptr_t)msg->context,
+		.wr.rdma.remote_addr = msg->rma_iov->addr,
+		.wr.rdma.rkey = (uint32_t)msg->rma_iov->key,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	if (flags & FI_REMOTE_CQ_DATA) {
+		wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;
+		wr.imm_data = htonl((uint32_t)msg->data);
+	} else {
+		wr.opcode = IBV_WR_RDMA_WRITE;
+	}
+
+	return fi_ibv_send_msg(&ep->base_ep, &wr, msg, flags);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_read(struct fid_ep *ep_fid, void *buf, size_t len,
+		void *desc, fi_addr_t src_addr, uint64_t addr,
+		uint64_t key, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_READ(&ep->base_ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_READ,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_readv(struct fid_ep *ep_fid, const struct iovec *iov,
+		void **desc, size_t count, fi_addr_t src_addr,
+		uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_READ(&ep->base_ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_READ,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.num_sge = count,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	fi_ibv_set_sge_iov(wr.sg_list, iov, count, desc);
+
+	return fi_ibv_send_poll_cq_if_needed(&ep->base_ep, &wr);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_readmsg(struct fid_ep *ep_fid,
+		const struct fi_msg_rma *msg, uint64_t flags)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP_READ_FLAGS(&ep->base_ep, flags,
+					       (uintptr_t)msg->context),
+		.opcode = IBV_WR_RDMA_READ,
+		.wr.rdma.remote_addr = msg->rma_iov->addr,
+		.wr.rdma.rkey = (uint32_t)msg->rma_iov->key,
+		.num_sge = msg->iov_count,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	fi_ibv_set_sge_iov(wr.sg_list, msg->msg_iov, msg->iov_count, msg->desc);
+
+	return fi_ibv_send_poll_cq_if_needed(&ep->base_ep, &wr);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_writedata(struct fid_ep *ep_fid, const void *buf,
+		size_t len, void *desc, uint64_t data, fi_addr_t dest_addr,
+		uint64_t addr, uint64_t key, void *context)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_COMP(&ep->base_ep, (uintptr_t)context),
+		.opcode = IBV_WR_RDMA_WRITE_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.send_flags = VERBS_INJECT(&ep->base_ep, len),
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf(&ep->base_ep, &wr, buf, len, desc);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_inject_write(struct fid_ep *ep_fid, const void *buf,
+		size_t len, fi_addr_t dest_addr, uint64_t addr,
+		uint64_t key)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_RDMA_WRITE,
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf_inline(&ep->base_ep, &wr, buf, len);
+}
+
+static ssize_t
+fi_ibv_xrc_rma_write_fast(struct fid_ep *ep_fid, const void *buf,
+	  size_t len, fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+
+	ep->base_ep.wrs->rma_wr.wr.rdma.remote_addr = addr;
+	ep->base_ep.wrs->rma_wr.wr.rdma.rkey = (uint32_t) key;
+	FI_IBV_SET_REMOTE_SRQN(ep->base_ep.wrs->rma_wr, ep->peer_srqn);
+	ep->base_ep.wrs->sge.addr = (uintptr_t) buf;
+	ep->base_ep.wrs->sge.length = (uint32_t) len;
+
+	return fi_ibv_send_poll_cq_if_needed(&ep->base_ep,
+					     &ep->base_ep.wrs->rma_wr);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_inject_writedata(struct fid_ep *ep_fid,
+		const void *buf, size_t len, uint64_t data,
+		fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+
+	struct ibv_send_wr wr = {
+		.wr_id = VERBS_NO_COMP_FLAG,
+		.opcode = IBV_WR_RDMA_WRITE_WITH_IMM,
+		.imm_data = htonl((uint32_t)data),
+		.wr.rdma.remote_addr = addr,
+		.wr.rdma.rkey = (uint32_t)key,
+		.send_flags = IBV_SEND_INLINE,
+	};
+
+	FI_IBV_SET_REMOTE_SRQN(wr, ep->peer_srqn);
+
+	return fi_ibv_send_buf_inline(&ep->base_ep, &wr, buf, len);
+}
+
+static ssize_t
+fi_ibv_msg_xrc_ep_rma_inject_writedata_fast(struct fid_ep *ep_fid,
+		const void *buf, size_t len, uint64_t data,
+		fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+{
+	ssize_t ret;
+	struct fi_ibv_xrc_ep *ep = container_of(ep_fid, struct fi_ibv_xrc_ep,
+						base_ep.util_ep.ep_fid);
+	ep->base_ep.wrs->rma_wr.wr.rdma.remote_addr = addr;
+	ep->base_ep.wrs->rma_wr.wr.rdma.rkey = (uint32_t) key;
+	FI_IBV_SET_REMOTE_SRQN(ep->base_ep.wrs->rma_wr, ep->peer_srqn);
+
+	ep->base_ep.wrs->rma_wr.imm_data = htonl((uint32_t) data);
+	ep->base_ep.wrs->rma_wr.opcode = IBV_WR_RDMA_WRITE_WITH_IMM;
+
+	ep->base_ep.wrs->sge.addr = (uintptr_t) buf;
+	ep->base_ep.wrs->sge.length = (uint32_t) len;
+
+	ret = fi_ibv_send_poll_cq_if_needed(&ep->base_ep,
+					    &ep->base_ep.wrs->rma_wr);
+	ep->base_ep.wrs->rma_wr.opcode = IBV_WR_RDMA_WRITE;
+	return ret;
+}
+
+struct fi_ops_rma fi_ibv_msg_xrc_ep_rma_ops_ts = {
+	.size = sizeof(struct fi_ops_rma),
+	.read = fi_ibv_msg_xrc_ep_rma_read,
+	.readv = fi_ibv_msg_xrc_ep_rma_readv,
+	.readmsg = fi_ibv_msg_xrc_ep_rma_readmsg,
+	.write = fi_ibv_msg_xrc_ep_rma_write,
+	.writev = fi_ibv_msg_xrc_ep_rma_writev,
+	.writemsg = fi_ibv_msg_xrc_ep_rma_writemsg,
+	.inject = fi_ibv_msg_xrc_ep_rma_inject_write,
+	.writedata = fi_ibv_msg_xrc_ep_rma_writedata,
+	.injectdata = fi_ibv_msg_xrc_ep_rma_inject_writedata,
+};
+
+struct fi_ops_rma fi_ibv_msg_xrc_ep_rma_ops = {
+	.size = sizeof(struct fi_ops_rma),
+	.read = fi_ibv_msg_xrc_ep_rma_read,
+	.readv = fi_ibv_msg_xrc_ep_rma_readv,
+	.readmsg = fi_ibv_msg_xrc_ep_rma_readmsg,
+	.write = fi_ibv_msg_xrc_ep_rma_write,
+	.writev = fi_ibv_msg_xrc_ep_rma_writev,
+	.writemsg = fi_ibv_msg_xrc_ep_rma_writemsg,
+	.inject = fi_ibv_xrc_rma_write_fast,
+	.writedata = fi_ibv_msg_xrc_ep_rma_writedata,
+	.injectdata = fi_ibv_msg_xrc_ep_rma_inject_writedata_fast,
+};
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_srq.c b/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_srq.c
deleted file mode 100644
index 23712dabf..000000000
--- a/src/mpid/ch4/netmod/ofi/libfabric/prov/verbs/src/verbs_srq.c
+++ /dev/null
@@ -1,275 +0,0 @@
-/*
- * Copyright (c) 2013-2015 Intel Corporation, Inc.  All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "config.h"
-
-#include "fi_verbs.h"
-
-static struct fi_ops_ep fi_ibv_srq_ep_base_ops = {
-	.size = sizeof(struct fi_ops_ep),
-	.cancel = fi_no_cancel,
-	.getopt = fi_no_getopt,
-	.setopt = fi_no_setopt,
-	.tx_ctx = fi_no_tx_ctx,
-	.rx_ctx = fi_no_rx_ctx,
-	.rx_size_left = fi_no_rx_size_left,
-	.tx_size_left = fi_no_tx_size_left,
-};
-
-static struct fi_ops_cm fi_ibv_srq_cm_ops = {
-	.size = sizeof(struct fi_ops_cm),
-	.setname = fi_no_setname,
-	.getname = fi_no_getname,
-	.getpeer = fi_no_getpeer,
-	.connect = fi_no_connect,
-	.listen = fi_no_listen,
-	.accept = fi_no_accept,
-	.reject = fi_no_reject,
-	.shutdown = fi_no_shutdown,
-	.join = fi_no_join,
-};
-
-static struct fi_ops_rma fi_ibv_srq_rma_ops = {
-	.size = sizeof(struct fi_ops_rma),
-	.read = fi_no_rma_read,
-	.readv = fi_no_rma_readv,
-	.readmsg = fi_no_rma_readmsg,
-	.write = fi_no_rma_write,
-	.writev = fi_no_rma_writev,
-	.writemsg = fi_no_rma_writemsg,
-	.inject = fi_no_rma_inject,
-	.writedata = fi_no_rma_writedata,
-	.injectdata = fi_no_rma_injectdata,
-};
-
-static struct fi_ops_atomic fi_ibv_srq_atomic_ops = {
-	.size = sizeof(struct fi_ops_atomic),
-	.write = fi_no_atomic_write,
-	.writev = fi_no_atomic_writev,
-	.writemsg = fi_no_atomic_writemsg,
-	.inject = fi_no_atomic_inject,
-	.readwrite = fi_no_atomic_readwrite,
-	.readwritev = fi_no_atomic_readwritev,
-	.readwritemsg = fi_no_atomic_readwritemsg,
-	.compwrite = fi_no_atomic_compwrite,
-	.compwritev = fi_no_atomic_compwritev,
-	.compwritemsg = fi_no_atomic_compwritemsg,
-	.writevalid = fi_no_atomic_writevalid,
-	.readwritevalid = fi_no_atomic_readwritevalid,
-	.compwritevalid = fi_no_atomic_compwritevalid,
-};
-
-static ssize_t
-fi_ibv_srq_ep_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg, uint64_t flags)
-{
-	struct fi_ibv_srq_ep *ep =
-		container_of(ep_fid, struct fi_ibv_srq_ep, ep_fid);
-	struct fi_ibv_wre *wre;
-	struct ibv_sge *sge = NULL;
-	struct ibv_recv_wr wr = {
-		.num_sge = msg->iov_count,
-		.next = NULL,
-	};
-	size_t i;
-
-	assert(ep->srq);
-
-	fastlock_acquire(&ep->wre_lock);
-	wre = util_buf_alloc(ep->wre_pool);
-	if (!wre) {
-		fastlock_release(&ep->wre_lock);
-		return -FI_EAGAIN;
-	}
-	dlist_insert_tail(&wre->entry, &ep->wre_list);
-	fastlock_release(&ep->wre_lock);
-
-	wre->srq = ep;
-	wre->ep = NULL;
-	wre->context = msg->context;
-	wre->wr_type = IBV_RECV_WR;
-
-	wr.wr_id = (uintptr_t)wre;
-	sge = alloca(sizeof(*sge) * msg->iov_count);
-	for (i = 0; i < msg->iov_count; i++) {
-		sge[i].addr = (uintptr_t)msg->msg_iov[i].iov_base;
-		sge[i].length = (uint32_t)msg->msg_iov[i].iov_len;
-		sge[i].lkey = (uint32_t)(uintptr_t)(msg->desc[i]);
-	}
-	wr.sg_list = sge;
-
-	return FI_IBV_INVOKE_POST(srq_recv, recv, ep->srq, &wr,
-				  FI_IBV_RELEASE_WRE(ep, wre));
-}
-
-static ssize_t
-fi_ibv_srq_ep_recv(struct fid_ep *ep, void *buf, size_t len,
-		void *desc, fi_addr_t src_addr, void *context)
-{
-	struct iovec iov = {
-		.iov_base = buf,
-		.iov_len = len,
-	};
-	struct fi_msg msg = {
-		.msg_iov = &iov,
-		.desc = &desc,
-		.iov_count = 1,
-		.addr = src_addr,
-		.context = context,
-	};
-
-	return fi_ibv_srq_ep_recvmsg(ep, &msg, 0);
-}
-
-static ssize_t
-fi_ibv_srq_ep_recvv(struct fid_ep *ep, const struct iovec *iov, void **desc,
-                 size_t count, fi_addr_t src_addr, void *context)
-{
-	struct fi_msg msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = src_addr,
-		.context = context,
-	};
-
-	return fi_ibv_srq_ep_recvmsg(ep, &msg, 0);
-}
-
-static struct fi_ops_msg fi_ibv_srq_msg_ops = {
-	.size = sizeof(struct fi_ops_msg),
-	.recv = fi_ibv_srq_ep_recv,
-	.recvv = fi_ibv_srq_ep_recvv,
-	.recvmsg = fi_ibv_srq_ep_recvmsg,
-	.send = fi_no_msg_send,
-	.sendv = fi_no_msg_sendv,
-	.sendmsg = fi_no_msg_sendmsg,
-	.inject = fi_no_msg_inject,
-	.senddata = fi_no_msg_senddata,
-	.injectdata = fi_no_msg_injectdata,
-};
-
-static int fi_ibv_srq_close(fid_t fid)
-{
-	struct fi_ibv_srq_ep *srq_ep;
-	int ret;
-
-	srq_ep = container_of(fid, struct fi_ibv_srq_ep, ep_fid.fid);
-	ret = ibv_destroy_srq(srq_ep->srq);
-	if (ret)
-		VERBS_WARN(FI_LOG_EP_CTRL,
-			   "Cannot destroy SRQ rc=%d\n", ret);
-
-	/* All WCs from Receive CQ belongs to SRQ, no need to check EP. */
-	/* Assumes that all EP that associated with the SRQ have
-	 * already been closed (therefore, no more completions would
-	 * arrive in CQ for the recv posted to SRQ) */
-	/* Just to be clear, passes `IBV_RECV_WR`, because SRQ's WREs
-	 * have `IBV_RECV_WR` type only */
-	fi_ibv_empty_wre_list(srq_ep->wre_pool, &srq_ep->wre_list, IBV_RECV_WR);
-	util_buf_pool_destroy(srq_ep->wre_pool);
-	fastlock_destroy(&srq_ep->wre_lock);
-
-	free(srq_ep);
-
-	return FI_SUCCESS;
-}
-
-static struct fi_ops fi_ibv_srq_ep_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = fi_ibv_srq_close,
-	.bind = fi_no_bind,
-	.control = fi_no_control,
-	.ops_open = fi_no_ops_open,
-};
-
-
-int fi_ibv_srq_context(struct fid_domain *domain, struct fi_rx_attr *attr,
-		       struct fid_ep **srq_ep_fid, void *context)
-{
-	struct ibv_srq_init_attr srq_init_attr = { 0 };
-	struct fi_ibv_domain *dom;
-	struct fi_ibv_srq_ep *srq_ep;
-	int ret;
-
-	if (!domain)
-		return -FI_EINVAL;
-
-	srq_ep = calloc(1, sizeof(*srq_ep));
-	if (!srq_ep) {
-		ret = -FI_ENOMEM;
-		goto err1;
-	}
-
-	dom = container_of(domain, struct fi_ibv_domain,
-			   util_domain.domain_fid);
-
-	srq_ep->ep_fid.fid.fclass = FI_CLASS_SRX_CTX;
-	srq_ep->ep_fid.fid.context = context;
-	srq_ep->ep_fid.fid.ops = &fi_ibv_srq_ep_ops;
-	srq_ep->ep_fid.ops = &fi_ibv_srq_ep_base_ops;
-	srq_ep->ep_fid.msg = &fi_ibv_srq_msg_ops;
-	srq_ep->ep_fid.cm = &fi_ibv_srq_cm_ops;
-	srq_ep->ep_fid.rma = &fi_ibv_srq_rma_ops;
-	srq_ep->ep_fid.atomic = &fi_ibv_srq_atomic_ops;
-
-	srq_init_attr.attr.max_wr = attr->size;
-	srq_init_attr.attr.max_sge = attr->iov_limit;
-
-	srq_ep->srq = ibv_create_srq(dom->pd, &srq_init_attr);
-	if (!srq_ep->srq) {
-		VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "ibv_create_srq", errno);
-		ret = -errno;
-		goto err2;
-	}
-
-	fastlock_init(&srq_ep->wre_lock);
-	ret = util_buf_pool_create(&srq_ep->wre_pool, sizeof(struct fi_ibv_wre),
-				   16, 0, VERBS_WRE_CNT);
-	if (ret) {
-		VERBS_WARN(FI_LOG_DOMAIN, "Failed to create wre_pool\n");
-		goto err3;
-	}
-	dlist_init(&srq_ep->wre_list);
-
-	*srq_ep_fid = &srq_ep->ep_fid;
-
-	return FI_SUCCESS;
-err3:
-	fastlock_destroy(&srq_ep->wre_lock);
-	if (ibv_destroy_srq(srq_ep->srq))
-		VERBS_INFO_ERRNO(FI_LOG_DOMAIN, "ibv_destroy_srq", errno);
-err2:
-	free(srq_ep);
-err1:
-	return ret;
-}
-
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/abi_1_0.c b/src/mpid/ch4/netmod/ofi/libfabric/src/abi_1_0.c
index fb73b4890..c0fdd832f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/src/abi_1_0.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/abi_1_0.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
+ * Copyright (c) 2016-2018 Intel Corporation. All rights reserved.
  * Copyright (c) 2017, Cisco Systems, Inc. All rights reserved.
  *
  * This software is available to you under a choice of one of two
@@ -105,6 +105,23 @@ struct fi_info_1_0 {
 	struct fi_fabric_attr_1_0	*fabric_attr;
 };
 
+struct fi_info_1_1 {
+	struct fi_info			*next;
+	uint64_t			caps;
+	uint64_t			mode;
+	uint32_t			addr_format;
+	size_t				src_addrlen;
+	size_t				dest_addrlen;
+	void				*src_addr;
+	void				*dest_addr;
+	fid_t				handle;
+	struct fi_tx_attr		*tx_attr;
+	struct fi_rx_attr		*rx_attr;
+	struct fi_ep_attr_1_0		*ep_attr;
+	struct fi_domain_attr_1_0	*domain_attr;
+	struct fi_fabric_attr_1_0	*fabric_attr;
+};
+
 #define ofi_dup_attr(dst, src)				\
 	do {						\
 		dst = calloc(1, sizeof(*dst));		\
@@ -113,6 +130,9 @@ struct fi_info_1_0 {
 	} while (0);
 
 
+/*
+ * ABI 1.0
+ */
 __attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
 void fi_freeinfo_1_0(struct fi_info_1_0 *info)
 {
@@ -120,7 +140,6 @@ void fi_freeinfo_1_0(struct fi_info_1_0 *info)
 }
 COMPAT_SYMVER(fi_freeinfo_1_0, fi_freeinfo, FABRIC_1.0);
 
-
 __attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
 struct fi_info_1_0 *fi_dupinfo_1_0(const struct fi_info_1_0 *info)
 {
@@ -244,3 +263,56 @@ int fi_fabric_1_0(struct fi_fabric_attr_1_0 *attr_1_0,
 	return fi_fabric(&attr, fabric, context);
 }
 COMPAT_SYMVER(fi_fabric_1_0, fi_fabric, FABRIC_1.0);
+
+
+/*
+ * ABI 1.1
+ */
+__attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
+void fi_freeinfo_1_1(struct fi_info_1_1 *info)
+{
+	fi_freeinfo((struct fi_info *) info);
+}
+COMPAT_SYMVER(fi_freeinfo_1_1, fi_freeinfo, FABRIC_1.1);
+
+__attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
+struct fi_info_1_1 *fi_dupinfo_1_1(const struct fi_info_1_1 *info)
+{
+	struct fi_info *dup, *base;
+
+	if (!info)
+		return (struct fi_info_1_1 *) ofi_allocinfo_internal();
+
+	ofi_dup_attr(base, info);
+	if (base == NULL)
+		return NULL;
+
+	dup = fi_dupinfo(base);
+
+	free(base);
+	return (struct fi_info_1_1 *) dup;
+}
+COMPAT_SYMVER(fi_dupinfo_1_1, fi_dupinfo, FABRIC_1.1);
+
+__attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
+int fi_getinfo_1_1(uint32_t version, const char *node, const char *service,
+		   uint64_t flags, const struct fi_info_1_1 *hints_1_1,
+		   struct fi_info_1_1 **info)
+{
+	struct fi_info *hints;
+	int ret;
+
+	if (hints_1_1) {
+		hints = (struct fi_info *) fi_dupinfo_1_1(hints_1_1);
+		if (!hints)
+			return -FI_ENOMEM;
+	} else {
+		hints = NULL;
+	}
+	ret = fi_getinfo(version, node, service, flags, hints,
+			 (struct fi_info **) info);
+	fi_freeinfo(hints);
+
+	return ret;
+}
+COMPAT_SYMVER(fi_getinfo_1_1, fi_getinfo, FABRIC_1.1);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/common.c b/src/mpid/ch4/netmod/ofi/libfabric/src/common.c
index 0a85fcb46..a3b74773f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/src/common.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/common.c
@@ -1,7 +1,7 @@
 /*
  * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.
  * Copyright (c) 2006-2017 Cisco Systems, Inc.  All rights reserved.
- * Copyright (c) 2013 Intel Corp., Inc.  All rights reserved.
+ * Copyright (c) 2013-2018 Intel Corp., Inc.  All rights reserved.
  * Copyright (c) 2015 Los Alamos Nat. Security, LLC. All rights reserved.
  *
  * This software is available to you under a choice of one of two
@@ -58,6 +58,8 @@
 #include <rdma/fi_errno.h>
 #include <ofi.h>
 #include <ofi_util.h>
+#include <ofi_epoll.h>
+#include <shared/ofi_str.h>
 
 struct fi_provider core_prov = {
 	.name = "core",
@@ -102,6 +104,11 @@ uint8_t ofi_msb(uint64_t num)
 	return msb;
 }
 
+uint8_t ofi_lsb(uint64_t num)
+{
+	return ofi_msb(num & (~(num - 1)));
+}
+
 int ofi_send_allowed(uint64_t caps)
 {
 	if (caps & FI_MSG ||
@@ -220,6 +227,31 @@ uint64_t fi_gettime_us(void)
 	return now.tv_sec * 1000000 + now.tv_usec;
 }
 
+uint16_t ofi_get_sa_family(const struct fi_info *info)
+{
+	if (!info)
+		return 0;
+
+	switch (info->addr_format) {
+	case FI_SOCKADDR_IN:
+		return AF_INET;
+	case FI_SOCKADDR_IN6:
+		return AF_INET6;
+	case FI_SOCKADDR_IB:
+		return AF_IB;
+	case FI_SOCKADDR:
+	case FI_FORMAT_UNSPEC:
+		if (info->src_addr)
+			return ((struct sockaddr *) info->src_addr)->sa_family;
+
+		if (info->dest_addr)
+			return ((struct sockaddr *) info->dest_addr)->sa_family;
+		/* fall through */
+	default:
+		return 0;
+	}
+}
+
 const char *ofi_straddr(char *buf, size_t *len,
 			uint32_t addr_format, const void *addr)
 {
@@ -433,6 +465,8 @@ static int ofi_str_to_sin(const char *str, void **addr, size_t *len)
 	if (ret == 1)
 		goto match_ip;
 
+	FI_WARN(&core_prov, FI_LOG_CORE,
+		"Malformed FI_ADDR_STR: %s\n", str);
 err:
 	free(sin);
 	return -FI_EINVAL;
@@ -440,8 +474,11 @@ err:
 match_ip:
 	ip[sizeof(ip) - 1] = '\0';
 	ret = inet_pton(AF_INET, ip, &sin->sin_addr);
-	if (ret != 1)
+	if (ret != 1) {
+		FI_WARN(&core_prov, FI_LOG_CORE,
+			"Unable to convert IPv4 address: %s\n", ip);
 		goto err;
+	}
 
 match_port:
 	sin->sin_port = htons(sin->sin_port);
@@ -473,6 +510,8 @@ static int ofi_str_to_sin6(const char *str, void **addr, size_t *len)
 	if (ret == 1)
 		goto match_ip;
 
+	FI_WARN(&core_prov, FI_LOG_CORE,
+		"Malformed FI_ADDR_STR: %s\n", str);
 err:
 	free(sin6);
 	return -FI_EINVAL;
@@ -480,8 +519,11 @@ err:
 match_ip:
 	ip[sizeof(ip) - 1] = '\0';
 	ret = inet_pton(AF_INET6, ip, &sin6->sin6_addr);
-	if (ret != 1)
+	if (ret != 1) {
+		FI_WARN(&core_prov, FI_LOG_CORE,
+			"Unable to convert IPv6 address: %s\n", ip);
 		goto err;
+	}
 
 match_port:
 	sin6->sin6_port = htons(sin6->sin6_port);
@@ -584,6 +626,14 @@ int ofi_is_wildcard_listen_addr(const char *node, const char *service,
 	struct addrinfo *res = NULL;
 	int ret;
 
+	if (hints && hints->addr_format != FI_FORMAT_UNSPEC &&
+	    hints->addr_format != FI_SOCKADDR &&
+	    hints->addr_format != FI_SOCKADDR_IN &&
+	    hints->addr_format != FI_SOCKADDR_IN6)
+		return 0;
+
+	/* else it's okay to call getaddrinfo, proceed with processing */
+
 	if (node) {
 		ret = getaddrinfo(node, service, NULL, &res);
 		if (ret) {
@@ -612,6 +662,35 @@ out:
 	return ((flags & FI_SOURCE) && service) ? 1 : 0;
 }
 
+size_t ofi_mask_addr(struct sockaddr *maskaddr, const struct sockaddr *srcaddr,
+		     const struct sockaddr *netmask)
+{
+	size_t i, size, len = 0;
+	uint8_t *ip, *mask, bits;
+
+	memcpy(maskaddr, srcaddr, ofi_sizeofaddr(srcaddr));
+	size = ofi_sizeofip(srcaddr);
+	ip = ofi_get_ipaddr(maskaddr);
+	mask = ofi_get_ipaddr(netmask);
+
+	if (!size || !ip || !mask)
+		return 0;
+
+	for (i = 0; i < size; i++) {
+		ip[i] &= mask[i];
+
+		if (mask[i] == 0xff) {
+			len += 8;
+		} else {
+			for (bits = mask[i]; bits; bits >>= 1) {
+				if (bits & 0x1)
+					len++;
+			}
+		}
+	}
+	return len;
+}
+
 void ofi_straddr_log_internal(const char *func, int line,
 			      const struct fi_provider *prov,
 			      enum fi_log_level level,
@@ -629,53 +708,175 @@ void ofi_straddr_log_internal(const char *func, int line,
 	}
 }
 
+int ofi_discard_socket(SOCKET sock, size_t len)
+{
+	char buf;
+	ssize_t ret = 0;
+
+	for (; len && !ret; len--)
+		ret = ofi_recvall_socket(sock, &buf, 1);
+	return ret;
+}
+
+
 #ifndef HAVE_EPOLL
 
 int fi_epoll_create(struct fi_epoll **ep)
 {
+	int ret;
+
 	*ep = calloc(1, sizeof(struct fi_epoll));
-	return *ep ? 0 : -FI_ENOMEM;
+	if (!*ep)
+		return -FI_ENOMEM;
+
+	(*ep)->size = 64;
+	(*ep)->fds = calloc((*ep)->size, sizeof(*(*ep)->fds) +
+			    sizeof(*(*ep)->context));
+	if (!(*ep)->fds) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+	(*ep)->context = (void *)((*ep)->fds + (*ep)->size);
+
+	ret = fd_signal_init(&(*ep)->signal);
+	if (ret)
+		goto err2;
+
+	(*ep)->fds[(*ep)->nfds].fd = (*ep)->signal.fd[FI_READ_FD];
+	(*ep)->fds[(*ep)->nfds].events = FI_EPOLL_IN;
+	(*ep)->context[(*ep)->nfds++] = NULL;
+	slist_init(&(*ep)->work_item_list);
+	fastlock_init(&(*ep)->lock);
+	return FI_SUCCESS;
+err2:
+	free((*ep)->fds);
+err1:
+	free(*ep);
+	return ret;
 }
 
-int fi_epoll_add(struct fi_epoll *ep, int fd, void *context)
+
+static int fi_epoll_ctl(struct fi_epoll *ep, enum fi_epoll_ctl op,
+			int fd, uint32_t events, void *context)
 {
-	struct pollfd *fds;
-	void *contexts;
+	struct fi_epoll_work_item *item;
 
-	if (ep->nfds == ep->size) {
-		fds = calloc(ep->size + 64,
-			     sizeof(*ep->fds) + sizeof(*ep->context));
-		if (!fds)
-			return -FI_ENOMEM;
+	item = calloc(1,sizeof(*item));
+	if (!item)
+		return -FI_ENOMEM;
 
-		ep->size += 64;
-		contexts = fds + ep->size;
+	item->fd = fd;
+	item->events = events;
+	item->context = context;
+	item->type = op;
+	fastlock_acquire(&ep->lock);
+	slist_insert_tail(&item->entry, &ep->work_item_list);
+	fd_signal_set(&ep->signal);
+	fastlock_release(&ep->lock);
+	return 0;
+}
 
-		memcpy(fds, ep->fds, ep->nfds * sizeof(*ep->fds));
-		memcpy(contexts, ep->context, ep->nfds * sizeof(*ep->context));
-		free(ep->fds);
-		ep->fds = fds;
-		ep->context = contexts;
-	}
+int fi_epoll_add(struct fi_epoll *ep, int fd, uint32_t events, void *context)
+{
+	return fi_epoll_ctl(ep, EPOLL_CTL_ADD, fd, events, context);
+}
 
-	ep->fds[ep->nfds].fd = fd;
-	ep->fds[ep->nfds].events = POLLIN;
-	ep->context[ep->nfds++] = context;
-	return 0;
+int fi_epoll_mod(struct fi_epoll *ep, int fd, uint32_t events, void *context)
+{
+	return fi_epoll_ctl(ep, EPOLL_CTL_MOD, fd, events, context);
 }
 
 int fi_epoll_del(struct fi_epoll *ep, int fd)
+{
+	return fi_epoll_ctl(ep, EPOLL_CTL_DEL, fd, 0, NULL);
+}
+
+static int fi_epoll_fd_array_grow(struct fi_epoll *ep)
+{
+	struct pollfd *fds;
+	void *contexts;
+
+	fds = calloc(ep->size + 64,
+		     sizeof(*ep->fds) + sizeof(*ep->context));
+	if (!fds)
+		return -FI_ENOMEM;
+
+	ep->size += 64;
+	contexts = fds + ep->size;
+
+	memcpy(fds, ep->fds, ep->nfds * sizeof(*ep->fds));
+	memcpy(contexts, ep->context, ep->nfds * sizeof(*ep->context));
+	free(ep->fds);
+	ep->fds = fds;
+	ep->context = contexts;
+	return FI_SUCCESS;
+}
+
+static void fi_epoll_cleanup_array(struct fi_epoll *ep)
 {
 	int i;
 
 	for (i = 0; i < ep->nfds; i++) {
-		if (ep->fds[i].fd == fd) {
-			ep->fds[i].fd = ep->fds[ep->nfds - 1].fd;
-			ep->context[i] = ep->context[--ep->nfds];
-      			return 0;
+		while (ep->fds[i].fd == INVALID_SOCKET) {
+			ep->fds[i].fd = ep->fds[ep->nfds-1].fd;
+			ep->fds[i].events = ep->fds[ep->nfds-1].events;
+			ep->fds[i].revents = ep->fds[ep->nfds-1].revents;
+			ep->context[i] = ep->context[ep->nfds-1];
+			ep->nfds--;
+			if (i == ep->nfds)
+				break;
 		}
-  	}
-	return -FI_EINVAL;
+	}
+}
+
+static void fi_epoll_process_work_item_list(struct fi_epoll *ep)
+{
+	struct slist_entry *entry;
+	struct fi_epoll_work_item *item;
+	int i;
+
+	while (!slist_empty(&ep->work_item_list)) {
+		if ((ep->nfds == ep->size) &&
+		    fi_epoll_fd_array_grow(ep))
+			continue;
+
+		entry = slist_remove_head(&ep->work_item_list);
+		item = container_of(entry, struct fi_epoll_work_item, entry);
+
+		switch (item->type) {
+		case EPOLL_CTL_ADD:
+			ep->fds[ep->nfds].fd = item->fd;
+			ep->fds[ep->nfds].events = item->events;
+			ep->context[ep->nfds] = item->context;
+			ep->nfds++;
+			break;
+		case EPOLL_CTL_DEL:
+			for (i = 0; i < ep->nfds; i++) {
+				if (ep->fds[i].fd == item->fd) {
+					ep->fds[i].fd = INVALID_SOCKET;
+					break;
+				}
+			}
+			break;
+		case EPOLL_CTL_MOD:
+			for (i = 0; i < ep->nfds; i++) {
+				if (ep->fds[i].fd == item->fd) {
+
+					ep->fds[i].events = item->events;
+					ep->fds[i].revents &= item->events;
+					ep->context = item->context;
+					break;
+				}
+			}
+			break;
+		default:
+			assert(0);
+			goto out;
+		}
+		free(item);
+	}
+out:
+	fi_epoll_cleanup_array(ep);
 }
 
 int fi_epoll_wait(struct fi_epoll *ep, void **contexts, int max_contexts,
@@ -683,31 +884,59 @@ int fi_epoll_wait(struct fi_epoll *ep, void **contexts, int max_contexts,
 {
 	int i, ret;
 	int found = 0;
+	uint64_t start = (timeout >= 0) ? fi_gettime_ms() : 0;
 
-	ret = poll(ep->fds, ep->nfds, timeout);
-	if (ret == SOCKET_ERROR)
-		return -ofi_sockerr();
-	else if (ret == 0)
-		return 0;
+	do {
+		ret = poll(ep->fds, ep->nfds, timeout);
+		if (ret == SOCKET_ERROR)
+			return -ofi_sockerr();
+		else if (ret == 0)
+			return 0;
+
+		if (ep->fds[0].revents)
+			fd_signal_reset(&ep->signal);
+
+		fastlock_acquire(&ep->lock);
+		if (!slist_empty(&ep->work_item_list))
+			fi_epoll_process_work_item_list(ep);
+
+		fastlock_release(&ep->lock);
 
-	for (i = ep->index; i < ep->nfds && found < max_contexts; i++) {
-		if (ep->fds[i].revents) {
-			contexts[found++] = ep->context[i];
-			ep->index = i;
+		for (i = ep->index; i < ep->nfds && found < max_contexts; i++) {
+			if (ep->fds[i].revents && i) {
+				contexts[found++] = ep->context[i];
+				ep->index = i;
+			}
 		}
-	}
-	for (i = 0; i < ep->index && found < max_contexts; i++) {
-		if (ep->fds[i].revents) {
-			contexts[found++] = ep->context[i];
-			ep->index = i;
+		for (i = 0; i < ep->index && found < max_contexts; i++) {
+			if (ep->fds[i].revents && i) {
+				contexts[found++] = ep->context[i];
+				ep->index = i;
+			}
 		}
-	}
+
+		if (timeout > 0)
+			timeout -= (int) (fi_gettime_ms() - start);
+
+	} while (timeout > 0 && !found);
+
 	return found;
 }
 
 void fi_epoll_close(struct fi_epoll *ep)
 {
+	struct fi_epoll_work_item *item;
+	struct slist_entry *entry;
 	if (ep) {
+		while (!slist_empty(&ep->work_item_list)) {
+			entry = slist_remove_head(&ep->work_item_list);
+			item = container_of(entry,
+					    struct fi_epoll_work_item,
+					    entry);
+			free(item);
+		}
+		fastlock_destroy(&ep->lock);
+		fd_signal_free(&ep->signal);
 		free(ep->fds);
 		free(ep);
 	}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/fabric.c b/src/mpid/ch4/netmod/ofi/libfabric/src/fabric.c
index b23571587..1136b440f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/src/fabric.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/fabric.c
@@ -43,7 +43,9 @@
 #include <rdma/fi_errno.h>
 #include "ofi_util.h"
 #include "ofi.h"
+#include "shared/ofi_str.h"
 #include "ofi_prov.h"
+#include "ofi_perf.h"
 
 #ifdef HAVE_LIBDL
 #include <dlfcn.h>
@@ -73,11 +75,26 @@ static int ofi_find_name(char **names, const char *name)
 	return -1;
 }
 
-static int ofi_is_util_prov(const struct fi_provider *provider)
+static enum ofi_prov_type ofi_prov_type(const struct fi_provider *provider)
 {
 	const struct fi_prov_context *ctx;
 	ctx = (const struct fi_prov_context *) &provider->context;
-	return ctx->is_util_prov;
+	return ctx->type;
+}
+
+static int ofi_is_util_prov(const struct fi_provider *provider)
+{
+	return ofi_prov_type(provider) == OFI_PROV_UTIL;
+}
+
+static int ofi_is_core_prov(const struct fi_provider *provider)
+{
+	return ofi_prov_type(provider) == OFI_PROV_CORE;
+}
+
+static int ofi_is_hook_prov(const struct fi_provider *provider)
+{
+	return ofi_prov_type(provider) == OFI_PROV_HOOK;
 }
 
 int ofi_apply_filter(struct fi_filter *filter, const char *name)
@@ -91,14 +108,15 @@ int ofi_apply_filter(struct fi_filter *filter, const char *name)
 	return 0;
 }
 
-/*
- * Utility providers may be disabled, but do not need to be explicitly
- * enabled.  This allows them to always be available when only a core
- * provider is enabled.
- */
 static int ofi_getinfo_filter(const struct fi_provider *provider)
 {
-	if (!prov_filter.negated && ofi_is_util_prov(provider))
+	/* Positive filters only apply to core providers.  They must be
+	 * explicitly enabled by the filter.  Other providers (i.e. utility)
+	 * are automatically enabled in this case, so that they can work
+	 * over any enabled core filter.  Negative filters may be used
+	 * to disable any provider.
+	 */
+	if (!prov_filter.negated && !ofi_is_core_prov(provider))
 		return 0;
 
 	return ofi_apply_filter(&prov_filter, provider->name);
@@ -117,6 +135,38 @@ static struct ofi_prov *ofi_getprov(const char *prov_name, size_t len)
 	return NULL;
 }
 
+struct fi_provider *ofi_get_hook(const char *name)
+{
+	struct ofi_prov *prov;
+	struct fi_provider *provider = NULL;
+	char *try_name = NULL;
+	int ret;
+
+	prov = ofi_getprov(name, strlen(name));
+	if (!prov) {
+		ret = asprintf(&try_name, "ofi_%s_hook", name);
+		if (ret > 0)
+			prov = ofi_getprov(try_name, ret);
+		else
+			try_name = NULL;
+	}
+
+	if (prov) {
+		if (prov->provider && ofi_is_hook_prov(prov->provider)) {
+			provider = prov->provider;
+		} else {
+			FI_WARN(&core_prov, FI_LOG_CORE,
+				"Specified provider is not a hook: %s\n", name);
+		}
+	} else {
+		FI_WARN(&core_prov, FI_LOG_CORE,
+			"No hook found for: %s\n", name);
+	}
+
+	free(try_name);
+	return provider;
+}
+
 static void cleanup_provider(struct fi_provider *provider, void *dlhandle)
 {
 	OFI_UNUSED(dlhandle);
@@ -166,26 +216,44 @@ static struct ofi_prov *ofi_create_prov_entry(const char *prov_name)
  */
 static void ofi_ordered_provs_init(void)
 {
-	char *ordered_prov_names[] =
-			{"psm2", "psm", "usnic", "mlx", "gni",
-			 "bgq", "netdir", "ofi_rxm", "ofi_rxd", "verbs",
-			/* Initialize the socket(s) provider last.  This will result in
-			 * it being the least preferred provider. */
+	char *ordered_prov_names[] = {
+		"psm2", "psm", "usnic", "mlx", "gni",
+		"bgq", "netdir", "ofi_rxm", "ofi_rxd", "verbs",
+		/* Initialize the socket based providers last of the
+		 * standard providers.  This will result in them being
+		 * the least preferred providers.
+		 */
+
+		/* Before you add ANYTHING here, read the comment above!!! */
+		"UDP", "sockets", "tcp", /* NOTHING GOES HERE! */
+		/* Seriously, read it! */
 
-			/* Before you add ANYTHING here, read the comment above!!! */
-			"UDP", "sockets", "tcp" /* NOTHING GOES HERE! */};
-			/* Seriously, read it! */
+		/* These are hooking providers only.  Their order
+		 * doesn't matter
+		 */
+		"ofi_perf_hook", "ofi_noop_hook",
+	};
 	int num_provs = sizeof(ordered_prov_names)/sizeof(ordered_prov_names[0]), i;
 
 	for (i = 0; i < num_provs; i++)
 		ofi_create_prov_entry(ordered_prov_names[i]);
 }
 
+static void ofi_set_prov_type(struct fi_prov_context *ctx,
+			      struct fi_provider *provider)
+{
+	if (!provider->getinfo)
+		ctx->type = OFI_PROV_HOOK;
+	else if (ofi_has_util_prefix(provider->name))
+		ctx->type = OFI_PROV_UTIL;
+	else
+		ctx->type = OFI_PROV_CORE;
+}
+
 static int ofi_register_provider(struct fi_provider *provider, void *dlhandle)
 {
 	struct fi_prov_context *ctx;
 	struct ofi_prov *prov = NULL;
-	size_t len;
 	int ret;
 
 	if (!provider || !provider->name) {
@@ -199,7 +267,7 @@ static int ofi_register_provider(struct fi_provider *provider, void *dlhandle)
 	       "registering provider: %s (%d.%d)\n", provider->name,
 	       FI_MAJOR(provider->version), FI_MINOR(provider->version));
 
-	if (!provider->getinfo || !provider->fabric) {
+	if (!provider->fabric) {
 		FI_WARN(&core_prov, FI_LOG_CORE,
 			"provider missing mandatory entry points\n");
 		ret = -FI_EINVAL;
@@ -223,7 +291,7 @@ static int ofi_register_provider(struct fi_provider *provider, void *dlhandle)
 	}
 
 	ctx = (struct fi_prov_context *) &provider->context;
-	ctx->is_util_prov = (ofi_util_name(provider->name, &len) != NULL);
+	ofi_set_prov_type(ctx, provider);
 
 	if (ofi_getinfo_filter(provider)) {
 		FI_INFO(&core_prov, FI_LOG_CORE,
@@ -295,75 +363,9 @@ static int lib_filter(const struct dirent *entry)
 }
 #endif
 
-/* split the given string "s" using the specified delimiter(s) in the string
- * "delim" and return an array of strings.  The array is terminated with a NULL
- * pointer.  You can clean this array up with a call to free_string_array().
- *
- * Returns NULL on failure.
- */
-static char **split_and_alloc(const char *s, const char *delim)
-{
-	int i, n;
-	char *tmp;
-	char *dup = NULL;
-	char **arr = NULL;
-
-	if (!s || !delim)
-		return NULL;
-
-	dup = strdup(s);
-	if (!dup) {
-		FI_WARN(&core_prov, FI_LOG_CORE, "failed to allocate memory\n");
-		return NULL;
-	}
-
-	/* compute the array size */
-	n = 1;
-	for (tmp = dup; *tmp != '\0'; ++tmp) {
-		for (i = 0; delim[i] != '\0'; ++i) {
-			if (*tmp == delim[i]) {
-				++n;
-				break;
-			}
-		}
-	}
-
-	/* +1 to leave space for NULL terminating pointer */
-	arr = calloc(n + 1, sizeof(*arr));
-	if (!arr) {
-		FI_WARN(&core_prov, FI_LOG_CORE, "failed to allocate memory\n");
-		goto cleanup;
-	}
-
-	/* set array elts to point inside the dup'ed string */
-	for (tmp = dup, i = 0; tmp != NULL; ++i) {
-		arr[i] = strsep(&tmp, delim);
-	}
-	assert(i == n);
-
-	return arr;
-
-cleanup:
-	free(dup);
-	free(arr);
-	return NULL;
-}
-
-/* see split_and_alloc() */
-static void free_string_array(char **s)
-{
-	/* all strings are allocated from the same strdup'ed slab, so just free
-	 * the first element */
-	if (s != NULL)
-		free(s[0]);
-
-	/* and then the actual array of pointers */
-	free(s);
-}
-
 void ofi_free_filter(struct fi_filter *filter)
 {
-	free_string_array(filter->names);
+	ofi_free_string_array(filter->names);
 }
 
 void ofi_create_filter(struct fi_filter *filter, const char *raw_filter)
@@ -377,7 +379,7 @@ void ofi_create_filter(struct fi_filter *filter, const char *raw_filter)
 		++raw_filter;
 	}
 
-	filter->names = split_and_alloc(raw_filter, ",");
+	filter->names= ofi_split_and_alloc(raw_filter, ",", NULL);
 	if (!filter->names)
 		FI_WARN(&core_prov, FI_LOG_CORE,
 			"unable to parse filter from: %s\n", raw_filter);
@@ -444,6 +446,8 @@ void fi_ini(void)
 	fi_log_init();
 	ofi_osd_init();
 	ofi_pmem_init();
+	ofi_perf_init();
+	ofi_hook_init();
 
 	fi_param_define(NULL, "provider", FI_PARAM_STRING,
 			"Only use specified provider (default: all available)");
@@ -481,12 +485,12 @@ void fi_ini(void)
 	if (!provdir)
 		provdir = PROVDLDIR;
 
-	dirs = split_and_alloc(provdir, ":");
+	dirs = ofi_split_and_alloc(provdir, ":", NULL);
 	if (dirs) {
 		for (n = 0; dirs[n]; ++n) {
 			ofi_ini_dir(dirs[n]);
 		}
-		free_string_array(dirs);
+		ofi_free_string_array(dirs);
 	}
 libdl_done:
 #endif
@@ -501,19 +505,16 @@ libdl_done:
 	ofi_register_provider(SHM_INIT, NULL);
 	ofi_register_provider(RXM_INIT, NULL);
 	ofi_register_provider(VERBS_INIT, NULL);
-
-	{
-		/* TODO: RXD is not stable for now. Disable it by default */
-		int enable_rxd = 0;
-		fi_param_define(NULL, "rxd_enable", FI_PARAM_BOOL,
-				"Enable RXD provider (default: no)");
-		fi_param_get_bool(NULL, "rxd_enable", &enable_rxd);
-		if (enable_rxd)
-			ofi_register_provider(RXD_INIT, NULL);
-	}
+	/* ofi_register_provider(RSTREAM_INIT, NULL); - no support */
+	ofi_register_provider(MRAIL_INIT, NULL);
+	ofi_register_provider(RXD_INIT, NULL);
 
 	ofi_register_provider(UDP_INIT, NULL);
 	ofi_register_provider(SOCKETS_INIT, NULL);
+	ofi_register_provider(TCP_INIT, NULL);
+
+	ofi_register_provider(PERF_HOOK_INIT, NULL);
+	ofi_register_provider(NOOP_HOOK_INIT, NULL);
 
 	ofi_init = 1;
 
@@ -542,6 +543,155 @@ FI_DESTRUCTOR(fi_fini(void))
 	ofi_osd_fini();
 }
 
+/* The provider must free any prov_attr data prior to calling this
+ * routine.
+ */
+int ofi_nic_close(struct fid *fid)
+{
+	struct fid_nic *nic = (struct fid_nic *) fid;
+
+	assert(fid && fid->fclass == FI_CLASS_NIC);
+
+	if (nic->device_attr) {
+		free(nic->device_attr->name);
+		free(nic->device_attr->device_id);
+		free(nic->device_attr->device_version);
+		free(nic->device_attr->vendor_id);
+		free(nic->device_attr->driver);
+		free(nic->device_attr->firmware);
+		free(nic->device_attr);
+	}
+
+	free(nic->bus_attr);
+
+	if (nic->link_attr) {
+		free(nic->link_attr->address);
+		free(nic->link_attr->network_type);
+		free(nic->link_attr);
+	}
+
+	free(nic);
+	return 0;
+}
+
+int ofi_nic_control(struct fid *fid, int command, void *arg)
+{
+	struct fid_nic *nic = container_of(fid, struct fid_nic, fid);
+	struct fid_nic **dup = (struct fid_nic **) arg;
+
+	switch(command) {
+	case FI_DUP:
+		*dup = ofi_nic_dup(nic);
+		return *dup ? FI_SUCCESS : -FI_ENOMEM;
+	default:
+		return -FI_ENOSYS;
+	}
+}
+
+struct fi_ops default_nic_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = ofi_nic_close,
+	.control = ofi_nic_control,
+	.tostr = ofi_nic_tostr,
+};
+
+static int ofi_dup_dev_attr(const struct fi_device_attr *attr,
+			    struct fi_device_attr **dup_attr)
+{
+	*dup_attr = calloc(1, sizeof(**dup_attr));
+	if (!*dup_attr)
+		return -FI_ENOMEM;
+
+	if (ofi_str_dup(attr->name, &(*dup_attr)->name) ||
+	    ofi_str_dup(attr->device_id, &(*dup_attr)->device_id) ||
+	    ofi_str_dup(attr->device_version, &(*dup_attr)->device_version) ||
+	    ofi_str_dup(attr->vendor_id, &(*dup_attr)->vendor_id) ||
+	    ofi_str_dup(attr->driver, &(*dup_attr)->driver) ||
+	    ofi_str_dup(attr->firmware, &(*dup_attr)->firmware))
+		return -FI_ENOMEM;
+
+	return 0;
+}
+
+static int ofi_dup_bus_attr(const struct fi_bus_attr *attr,
+			    struct fi_bus_attr **dup_attr)
+{
+	*dup_attr = calloc(1, sizeof(**dup_attr));
+	if (!*dup_attr)
+		return -FI_ENOMEM;
+
+	**dup_attr = *attr;
+	return 0;
+}
+
+static int ofi_dup_link_attr(const struct fi_link_attr *attr,
+			     struct fi_link_attr **dup_attr)
+{
+	*dup_attr = calloc(1, sizeof(**dup_attr));
+	if (!*dup_attr)
+		return -FI_ENOMEM;
+
+	if (ofi_str_dup(attr->address, &(*dup_attr)->address) ||
+	    ofi_str_dup(attr->network_type, &(*dup_attr)->network_type))
+		return -FI_ENOMEM;
+
+	(*dup_attr)->mtu = attr->mtu;
+	(*dup_attr)->speed = attr->speed;
+	(*dup_attr)->state = attr->state;
+	return 0;
+}
+
+struct fid_nic *ofi_nic_dup(const struct fid_nic *nic)
+{
+	struct fid_nic *dup_nic;
+	int ret;
+
+	dup_nic = calloc(1, sizeof(*dup_nic));
+	if (!dup_nic)
+		return NULL;
+
+	if (!nic) {
+		dup_nic->fid.fclass = FI_CLASS_NIC;
+		dup_nic->device_attr = calloc(1, sizeof(*dup_nic->device_attr));
+		dup_nic->bus_attr = calloc(1, sizeof(*dup_nic->bus_attr));
+		dup_nic->link_attr = calloc(1, sizeof(*dup_nic->link_attr));
+
+		if (!dup_nic->device_attr || !dup_nic->bus_attr ||
+		    !dup_nic->link_attr)
+			goto fail;
+
+		dup_nic->fid.ops = &default_nic_ops;
+		return dup_nic;
+	}
+
+	assert(nic->fid.fclass == FI_CLASS_NIC);
+	dup_nic->fid = nic->fid;
+
+	if (nic->device_attr) {
+		ret = ofi_dup_dev_attr(nic->device_attr, &dup_nic->device_attr);
+		if (ret)
+			goto fail;
+	}
+
+	if (nic->bus_attr) {
+		ret = ofi_dup_bus_attr(nic->bus_attr, &dup_nic->bus_attr);
+		if (ret)
+			goto fail;
+	}
+
+	if (nic->link_attr) {
+		ret = ofi_dup_link_attr(nic->link_attr, &dup_nic->link_attr);
+		if (ret)
+			goto fail;
+	}
+
+	return dup_nic;
+
+fail:
+	ofi_nic_close(&dup_nic->fid);
+	return NULL;
+}
+
 __attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
 void DEFAULT_SYMVER_PRE(fi_freeinfo)(struct fi_info *info)
 {
@@ -568,6 +718,10 @@ void DEFAULT_SYMVER_PRE(fi_freeinfo)(struct fi_info *info)
 			free(info->fabric_attr->prov_name);
 			free(info->fabric_attr);
 		}
+		if (info->nic &&
+		    FI_CHECK_OP(info->nic->fid.ops, struct fi_ops, close)) {
+			fi_close(&info->nic->fid);
+		}
 		free(info);
 	}
 }
@@ -630,7 +784,7 @@ static void ofi_set_prov_attr(struct fi_fabric_attr *attr,
 		attr->prov_name = ofi_strdup_append(core_name, prov->name);
 		free(core_name);
 	} else {
-		assert(!ofi_is_util_prov(prov));
+		assert(ofi_is_core_prov(prov));
 		attr->prov_name = strdup(prov->name);
 	}
 	attr->prov_version = prov->version;
@@ -638,59 +792,81 @@ static void ofi_set_prov_attr(struct fi_fabric_attr *attr,
 
 /*
  * The layering of utility providers over core providers follows these rules.
- * 1. If both are specified, then only return that layering
- * 2. If a utility provider is specified, return it over any* core provider.
- * 3. If a core provider is specified, return any utility provider that can
- *    layer over it, plus the core provider itself, if possible.
- * 4* A utility provider will not layer over the sockets provider unless the
- *    user explicitly requests that combination.
- *
- * Utility providers use an internal flag, OFI_CORE_PROV_ONLY, to indicate
- * that only core providers should respond to an fi_getinfo query.  This
- * prevents utility providers from layering over other utility providers.
+ * 0. Provider names are delimited by ";"
+ * 1. Rules when # of providers <= 2:
+ *    1a. If both are specified, then only return that layering
+ *    1b. If a utility provider is specified, return it over any* core provider.
+ *    1c. If a core provider is specified, return any utility provider that can
+ *        layer over it, plus the core provider itself, if possible.
+ *    1d. A utility provider will not layer over the sockets provider unless the
+ *        user explicitly requests that combination.
+ *    1e. OFI_CORE_PROV_ONLY flag prevents utility providers layering over other
+ *        utility providers.
+ * 2. If both the providers are utility providers or if more than two providers
+ *    are specified, the rightmost provider would be compared.
+ * 3. If any provider has a caret symbol "^" is prefixed before any provider
+ *    name it would be excluded (internal use only). These excluded providers
+ *    should be listed only at the end.
  */
 static int ofi_layering_ok(const struct fi_provider *provider,
-			   const char *util_name, size_t util_len,
-			   const char *core_name, size_t core_len,
+			   char **prov_vec, size_t count,
 			   uint64_t flags)
 {
+	char *prov_name;
+	int i;
+
+	/* Excluded providers must be at the end */
+	for (i = count - 1; i >= 0; i--) {
+		if (prov_vec[i][0] != '^')
+		    break;
+
+		if (!strcasecmp(&prov_vec[i][1], provider->name))
+			return 0;
+	}
+	count = i + 1;
+
 	if (flags & OFI_CORE_PROV_ONLY) {
-		if (ofi_is_util_prov(provider)) {
+		assert((count == 1) || (count == 0));
+		if (!ofi_is_core_prov(provider)) {
 			FI_INFO(&core_prov, FI_LOG_CORE,
-				"Need core provider, skipping util %s\n",
+				"Need core provider, skipping %s\n",
 				provider->name);
 			return 0;
 		}
 
-		if ((!core_len || !core_name) &&
-		    !strcasecmp(provider->name, "sockets")) {
+		if ((count == 0) && !strcasecmp(provider->name, "sockets")) {
 			FI_INFO(&core_prov, FI_LOG_CORE,
 				"Skipping util;sockets layering\n");
 			return 0;
 		}
 	}
 
-	if (util_len && util_name) {
-		assert(!(flags & OFI_CORE_PROV_ONLY));
-		if ((strlen(provider->name) != util_len) ||
-		    strncasecmp(util_name, provider->name, util_len))
-			return 0;
+	if (!count)
+		return 1;
+
+	/* To maintain backward compatibility with the previous behavior of
+	 * ofi_layering_ok we need to check if the # of providers is two or
+	 * fewer. In such a case, we have to be agnostic to the ordering of
+	 * core and utility providers */
 
-	} else if (core_len && core_name) {
-		if (!strncasecmp(core_name, "sockets", core_len) &&
-		    ofi_is_util_prov(provider)) {
+	if ((count == 1) && ofi_is_util_prov(provider) &&
+	    !ofi_has_util_prefix(prov_vec[0])) {
+		if (!strcasecmp(prov_vec[0], "sockets")) {
 			FI_INFO(&core_prov, FI_LOG_CORE,
 				"Sockets requested, skipping util layering\n");
 			return 0;
+		} else {
+			return 1;
 		}
-
-		if (!ofi_is_util_prov(provider) &&
-		    ((strlen(provider->name) != core_len) ||
-		     strncasecmp(core_name, provider->name, core_len)))
-			return 0;
 	}
 
-	return 1;
+	if ((count == 2) && ofi_has_util_prefix(prov_vec[0]) &&
+	    !ofi_has_util_prefix(prov_vec[1]))
+		prov_name = prov_vec[0];
+	else
+		prov_name = prov_vec[count - 1];
+
+	return !strcasecmp(provider->name, prov_name);
 }
 
 __attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
@@ -700,8 +876,8 @@ int DEFAULT_SYMVER_PRE(fi_getinfo)(uint32_t version, const char *node,
 {
 	struct ofi_prov *prov;
 	struct fi_info *tail, *cur;
-	const char *util_name = NULL, *core_name = NULL;
-	size_t util_len = 0, core_len = 0;
+	char **prov_vec = NULL;
+	size_t count = 0;
 	int ret;
 
 	if (!ofi_init)
@@ -718,19 +894,20 @@ int DEFAULT_SYMVER_PRE(fi_getinfo)(uint32_t version, const char *node,
 	}
 
 	if (hints && hints->fabric_attr && hints->fabric_attr->prov_name) {
-		util_name = ofi_util_name(hints->fabric_attr->prov_name,
-					  &util_len);
-		core_name = ofi_core_name(hints->fabric_attr->prov_name,
-					  &core_len);
+		prov_vec = ofi_split_and_alloc(hints->fabric_attr->prov_name,
+					       ";", &count);
+		if (!prov_vec)
+			return -FI_ENOMEM;
+		FI_DBG(&core_prov, FI_LOG_CORE, "hints prov_name: %s\n",
+		       hints->fabric_attr->prov_name);
 	}
 
 	*info = tail = NULL;
 	for (prov = prov_head; prov; prov = prov->next) {
-		if (!prov->provider)
+		if (!prov->provider || !prov->provider->getinfo)
 			continue;
 
-		if (!ofi_layering_ok(prov->provider, util_name, util_len,
-				     core_name, core_len, flags))
+		if (!ofi_layering_ok(prov->provider, prov_vec, count, flags))
 			continue;
 
 		if (FI_VERSION_LT(prov->provider->fi_version, version)) {
@@ -771,6 +948,7 @@ int DEFAULT_SYMVER_PRE(fi_getinfo)(uint32_t version, const char *node,
 		ofi_set_prov_attr(tail->fabric_attr, prov->provider);
 		tail->fabric_attr->api_version = version;
 	}
+	ofi_free_string_array(prov_vec);
 
 	return *info ? 0 : -FI_ENODATA;
 }
@@ -804,6 +982,7 @@ __attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
 struct fi_info *DEFAULT_SYMVER_PRE(fi_dupinfo)(const struct fi_info *info)
 {
 	struct fi_info *dup;
+	int ret;
 
 	if (!info)
 		return ofi_allocinfo_internal();
@@ -891,6 +1070,13 @@ struct fi_info *DEFAULT_SYMVER_PRE(fi_dupinfo)(const struct fi_info *info)
 				goto fail;
 		}
 	}
+
+	if (info->nic) {
+		ret = fi_control(&info->nic->fid, FI_DUP, &dup->nic);
+		if (ret && ret != -FI_ENOSYS)
+			goto fail;
+	}
+
 	return dup;
 
 fail:
@@ -905,7 +1091,6 @@ int DEFAULT_SYMVER_PRE(fi_fabric)(struct fi_fabric_attr *attr,
 {
 	struct ofi_prov *prov;
 	const char *top_name;
-	size_t len;
 	int ret;
 
 	if (!attr || !attr->prov_name || !attr->name)
@@ -914,23 +1099,32 @@ int DEFAULT_SYMVER_PRE(fi_fabric)(struct fi_fabric_attr *attr,
 	if (!ofi_init)
 		fi_ini();
 
-	top_name = ofi_util_name(attr->prov_name, &len);
-	if (!top_name)
-		top_name = ofi_core_name(attr->prov_name, &len);
+	top_name = strrchr(attr->prov_name, OFI_NAME_DELIM);
+	if (top_name)
+		top_name++;
+	else
+		top_name = attr->prov_name;
 
 	if (!top_name)
 		return -FI_EINVAL;
 
-	prov = ofi_getprov(top_name, len);
+	prov = ofi_getprov(top_name, strlen(top_name));
 	if (!prov || !prov->provider || !prov->provider->fabric)
 		return -FI_ENODEV;
 
 	ret = prov->provider->fabric(attr, fabric, context);
-	if (!ret && FI_VERSION_GE(prov->provider->fi_version, FI_VERSION(1, 5)))
-		(*fabric)->api_version = attr->api_version;
+	if (!ret) {
+		if (FI_VERSION_GE(prov->provider->fi_version, FI_VERSION(1, 5)))
+			(*fabric)->api_version = attr->api_version;
+		FI_INFO(&core_prov, FI_LOG_CORE, "Opened fabric: %s\n",
+			attr->name);
+
+		ofi_hook_install(*fabric, fabric, prov->provider);
+	}
+
 	return ret;
 }
-CURRENT_SYMVER(fi_fabric_, fi_fabric);
+DEFAULT_SYMVER(fi_fabric_, fi_fabric, FABRIC_1.1);
 
 __attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
 uint32_t DEFAULT_SYMVER_PRE(fi_version)(void)
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/fi_tostr.c b/src/mpid/ch4/netmod/ofi/libfabric/src/fi_tostr.c
index b43ed7214..db5035c71 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/src/fi_tostr.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/fi_tostr.c
@@ -64,20 +64,24 @@
  *
  * Printing functions are generally named after this pattern:
  *
- * struct fi_info : fi_tostr_info(..., struct fi_info, ...)
- * fi_info->caps  : fi_tostr_caps(..., typeof(caps), ...)
+ * struct fi_info : ofi_tostr_info(..., struct fi_info, ...)
+ * fi_info->caps  : ofi_tostr_caps(..., typeof(caps), ...)
  */
 
-#define FI_BUFSIZ 8192
+#define OFI_BUFSIZ 8192
 
 #define TAB "    "
 
 #define CASEENUMSTR(SYM) \
-	case SYM: { strcatf(buf, #SYM); break; }
+	case SYM: { ofi_strcatf(buf, #SYM); break; }
 #define IFFLAGSTR(flags, SYM) \
-	do { if (flags & SYM) strcatf(buf, #SYM ", "); } while(0)
+	do { if (flags & SYM) ofi_strcatf(buf, #SYM ", "); } while(0)
+#define CASEENUMSTRN(SYM, N) \
+	case SYM: { ofi_strncatf(buf, N, #SYM); break; }
+#define IFFLAGSTRN(flags, SYM, N) \
+	do { if (flags & SYM) ofi_strncatf(buf, N, #SYM ", "); } while(0)
 
-static void fi_remove_comma(char *buffer)
+static void ofi_remove_comma(char *buffer)
 {
 	size_t sz = strlen(buffer);
 	if (sz < 2)
@@ -86,30 +90,30 @@ static void fi_remove_comma(char *buffer)
 		buffer[sz-2] = '\0';
 }
 
-static void strcatf(char *dest, const char *fmt, ...)
+static void ofi_strncatf(char *dest, size_t n, const char *fmt, ...)
 {
-	size_t len = strnlen(dest,FI_BUFSIZ);
+	size_t len = strnlen(dest, n);
 	va_list arglist;
 
-	va_start (arglist, fmt);
-	vsnprintf(&dest[len], FI_BUFSIZ - 1 - len, fmt, arglist);
-	va_end (arglist);
+	va_start(arglist, fmt);
+	vsnprintf(&dest[len], n - 1 - len, fmt, arglist);
+	va_end(arglist);
 }
 
-static void fi_tostr_flags(char *buf, uint64_t flags)
+#define ofi_strcatf(dest, ...) \
+	ofi_strncatf(dest, OFI_BUFSIZ, __VA_ARGS__)
+
+static void ofi_tostr_fid(const char *label, char *buf, const struct fid *fid)
 {
-	IFFLAGSTR(flags, FI_MSG);
-	IFFLAGSTR(flags, FI_RMA);
-	IFFLAGSTR(flags, FI_TAGGED);
-	IFFLAGSTR(flags, FI_ATOMIC);
-	IFFLAGSTR(flags, FI_MULTICAST);
+	if (!fid || !FI_CHECK_OP(fid->ops, struct fi_ops, tostr))
+		ofi_strcatf(buf, "%s%p\n", label, fid);
+	else
+		fid->ops->tostr(fid, buf, OFI_BUFSIZ - strnlen(buf, OFI_BUFSIZ));
+}
 
-	IFFLAGSTR(flags, FI_READ);
-	IFFLAGSTR(flags, FI_WRITE);
-	IFFLAGSTR(flags, FI_RECV);
-	IFFLAGSTR(flags, FI_SEND);
-	IFFLAGSTR(flags, FI_REMOTE_READ);
-	IFFLAGSTR(flags, FI_REMOTE_WRITE);
+static void ofi_tostr_opflags(char *buf, uint64_t flags)
+{
+	IFFLAGSTR(flags, FI_MULTICAST);
 
 	IFFLAGSTR(flags, FI_MULTI_RECV);
 	IFFLAGSTR(flags, FI_REMOTE_CQ_DATA);
@@ -125,12 +129,13 @@ static void fi_tostr_flags(char *buf, uint64_t flags)
 	IFFLAGSTR(flags, FI_DELIVERY_COMPLETE);
 	IFFLAGSTR(flags, FI_AFFINITY);
 
-	IFFLAGSTR(flags, FI_RMA_PMEM);
+	IFFLAGSTR(flags, FI_CLAIM);
+	IFFLAGSTR(flags, FI_DISCARD);
 
-	fi_remove_comma(buf);
+	ofi_remove_comma(buf);
 }
 
-static void fi_tostr_addr_format(char *buf, uint32_t addr_format)
+static void oofi_tostr_addr_format(char *buf, uint32_t addr_format)
 {
 	switch (addr_format) {
 	CASEENUMSTR(FI_FORMAT_UNSPEC);
@@ -146,26 +151,26 @@ static void fi_tostr_addr_format(char *buf, uint32_t addr_format)
 	CASEENUMSTR(FI_ADDR_STR);
 	default:
 		if (addr_format & FI_PROV_SPECIFIC)
-			strcatf(buf, "Provider specific");
+			ofi_strcatf(buf, "Provider specific");
 		else
-			strcatf(buf, "Unknown");
+			ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_progress(char *buf, enum fi_progress progress)
+static void ofi_tostr_progress(char *buf, enum fi_progress progress)
 {
 	switch (progress) {
 	CASEENUMSTR(FI_PROGRESS_UNSPEC);
 	CASEENUMSTR(FI_PROGRESS_AUTO);
 	CASEENUMSTR(FI_PROGRESS_MANUAL);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_threading(char *buf, enum fi_threading threading)
+static void ofi_tostr_threading(char *buf, enum fi_threading threading)
 {
 	switch (threading) {
 	CASEENUMSTR(FI_THREAD_UNSPEC);
@@ -175,14 +180,13 @@ static void fi_tostr_threading(char *buf, enum fi_threading threading)
 	CASEENUMSTR(FI_THREAD_COMPLETION);
 	CASEENUMSTR(FI_THREAD_ENDPOINT);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_order(char *buf, uint64_t flags)
+static void ofi_tostr_msgorder(char *buf, uint64_t flags)
 {
-	IFFLAGSTR(flags, FI_ORDER_NONE);
 	IFFLAGSTR(flags, FI_ORDER_RAR);
 	IFFLAGSTR(flags, FI_ORDER_RAW);
 	IFFLAGSTR(flags, FI_ORDER_RAS);
@@ -192,30 +196,59 @@ static void fi_tostr_order(char *buf, uint64_t flags)
 	IFFLAGSTR(flags, FI_ORDER_SAR);
 	IFFLAGSTR(flags, FI_ORDER_SAW);
 	IFFLAGSTR(flags, FI_ORDER_SAS);
-	IFFLAGSTR(flags, FI_ORDER_STRICT);
+
+
+	ofi_remove_comma(buf);
+}
+
+static void ofi_tostr_comporder(char *buf, uint64_t flags)
+{
+	if ((flags & FI_ORDER_STRICT) == FI_ORDER_NONE) {
+		ofi_strcatf(buf, "FI_ORDER_NONE, ");
+	} else if ((flags & FI_ORDER_STRICT) == FI_ORDER_STRICT) {
+		ofi_strcatf(buf, "FI_ORDER_STRICT, ");
+	}
+
 	IFFLAGSTR(flags, FI_ORDER_DATA);
 
-	fi_remove_comma(buf);
+	ofi_remove_comma(buf);
 }
 
-static void fi_tostr_caps(char *buf, uint64_t caps)
+static void ofi_tostr_caps(char *buf, uint64_t caps)
 {
+	IFFLAGSTR(caps, FI_MSG);
+	IFFLAGSTR(caps, FI_RMA);
+	IFFLAGSTR(caps, FI_TAGGED);
+	IFFLAGSTR(caps, FI_ATOMIC);
+	IFFLAGSTR(caps, FI_MULTICAST);
+
+	IFFLAGSTR(caps, FI_READ);
+	IFFLAGSTR(caps, FI_WRITE);
+	IFFLAGSTR(caps, FI_RECV);
+	IFFLAGSTR(caps, FI_SEND);
+	IFFLAGSTR(caps, FI_REMOTE_READ);
+	IFFLAGSTR(caps, FI_REMOTE_WRITE);
+
+	IFFLAGSTR(caps, FI_MULTI_RECV);
+	IFFLAGSTR(caps, FI_REMOTE_CQ_DATA);
+	IFFLAGSTR(caps, FI_TRIGGER);
+	IFFLAGSTR(caps, FI_FENCE);
+
+	IFFLAGSTR(caps, FI_VARIABLE_MSG);
 	IFFLAGSTR(caps, FI_RMA_PMEM);
 	IFFLAGSTR(caps, FI_SOURCE_ERR);
 	IFFLAGSTR(caps, FI_LOCAL_COMM);
 	IFFLAGSTR(caps, FI_REMOTE_COMM);
 	IFFLAGSTR(caps, FI_SHARED_AV);
-	IFFLAGSTR(caps, FI_NUMERICHOST);
 	IFFLAGSTR(caps, FI_RMA_EVENT);
 	IFFLAGSTR(caps, FI_SOURCE);
 	IFFLAGSTR(caps, FI_NAMED_RX_CTX);
 	IFFLAGSTR(caps, FI_DIRECTED_RECV);
-	fi_tostr_flags(buf, caps);
 
-	fi_remove_comma(buf);
+	ofi_remove_comma(buf);
 }
 
-static void fi_tostr_ep_type(char *buf, enum fi_ep_type ep_type)
+static void ofi_tostr_ep_type(char *buf, enum fi_ep_type ep_type)
 {
 	switch (ep_type) {
 	CASEENUMSTR(FI_EP_UNSPEC);
@@ -225,12 +258,12 @@ static void fi_tostr_ep_type(char *buf, enum fi_ep_type ep_type)
 	CASEENUMSTR(FI_EP_SOCK_STREAM);
 	CASEENUMSTR(FI_EP_SOCK_DGRAM);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_protocol(char *buf, uint32_t protocol)
+static void ofi_tostr_protocol(char *buf, uint32_t protocol)
 {
 	switch (protocol) {
 	CASEENUMSTR(FI_PROTO_UNSPEC);
@@ -249,16 +282,18 @@ static void fi_tostr_protocol(char *buf, uint32_t protocol)
 	CASEENUMSTR(FI_PROTO_MLX);
 	CASEENUMSTR(FI_PROTO_NETWORKDIRECT);
 	CASEENUMSTR(FI_PROTO_SHM);
+	CASEENUMSTR(FI_PROTO_RSTREAM);
+	CASEENUMSTR(FI_PROTO_RDMA_CM_IB_XRC);
 	default:
 		if (protocol & FI_PROV_SPECIFIC)
-			strcatf(buf, "Provider specific");
+			ofi_strcatf(buf, "Provider specific");
 		else
-			strcatf(buf, "Unknown");
+			ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_mode(char *buf, uint64_t mode)
+static void ofi_tostr_mode(char *buf, uint64_t mode)
 {
 	IFFLAGSTR(mode, FI_CONTEXT);
 	IFFLAGSTR(mode, FI_MSG_PREFIX);
@@ -268,11 +303,12 @@ static void fi_tostr_mode(char *buf, uint64_t mode)
 	IFFLAGSTR(mode, FI_NOTIFY_FLAGS_ONLY);
 	IFFLAGSTR(mode, FI_RESTRICTED_COMP);
 	IFFLAGSTR(mode, FI_CONTEXT2);
+	IFFLAGSTR(mode, FI_BUFFERED_RECV);
 
-	fi_remove_comma(buf);
+	ofi_remove_comma(buf);
 }
 
-static void fi_tostr_addr(char *buf, uint32_t addr_format, void *addr)
+static void ofi_tostr_addr(char *buf, uint32_t addr_format, void *addr)
 {
 	char *p;
 	size_t len;
@@ -280,7 +316,7 @@ static void fi_tostr_addr(char *buf, uint32_t addr_format, void *addr)
 	p = buf + strlen(buf);
 
 	if (addr == NULL) {
-		strcatf(p, "(null)");
+		ofi_strcatf(p, "(null)");
 		return;
 	}
 
@@ -288,128 +324,128 @@ static void fi_tostr_addr(char *buf, uint32_t addr_format, void *addr)
 	ofi_straddr(p, &len, addr_format, addr);
 }
 
-static void fi_tostr_tx_attr(char *buf, const struct fi_tx_attr *attr,
+static void ofi_tostr_tx_attr(char *buf, const struct fi_tx_attr *attr,
 			     const char *prefix)
 {
 	if (!attr) {
-		strcatf(buf, "%sfi_tx_attr: (null)\n", prefix);
+		ofi_strcatf(buf, "%sfi_tx_attr: (null)\n", prefix);
 		return;
 	}
 
-	strcatf(buf, "%sfi_tx_attr:\n", prefix);
-	strcatf(buf, "%s%scaps: [ ", prefix, TAB);
-	fi_tostr_caps(buf, attr->caps);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%sfi_tx_attr:\n", prefix);
+	ofi_strcatf(buf, "%s%scaps: [ ", prefix, TAB);
+	ofi_tostr_caps(buf, attr->caps);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%smode: [ ", prefix, TAB);
-	fi_tostr_mode(buf, attr->mode);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%s%smode: [ ", prefix, TAB);
+	ofi_tostr_mode(buf, attr->mode);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%sop_flags: [ ", prefix, TAB);
-	fi_tostr_flags(buf, attr->op_flags);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%s%sop_flags: [ ", prefix, TAB);
+	ofi_tostr_opflags(buf, attr->op_flags);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%smsg_order: [ ", prefix, TAB);
-	fi_tostr_order(buf, attr->msg_order);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%s%smsg_order: [ ", prefix, TAB);
+	ofi_tostr_msgorder(buf, attr->msg_order);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%scomp_order: [ ", prefix, TAB);
-	fi_tostr_order(buf, attr->comp_order);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%s%scomp_order: [ ", prefix, TAB);
+	ofi_tostr_comporder(buf, attr->comp_order);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%sinject_size: %zd\n", prefix, TAB, attr->inject_size);
-	strcatf(buf, "%s%ssize: %zd\n", prefix, TAB, attr->size);
-	strcatf(buf, "%s%siov_limit: %zd\n", prefix, TAB, attr->iov_limit);
-	strcatf(buf, "%s%srma_iov_limit: %zd\n", prefix, TAB, attr->rma_iov_limit);
+	ofi_strcatf(buf, "%s%sinject_size: %zu\n", prefix, TAB, attr->inject_size);
+	ofi_strcatf(buf, "%s%ssize: %zu\n", prefix, TAB, attr->size);
+	ofi_strcatf(buf, "%s%siov_limit: %zu\n", prefix, TAB, attr->iov_limit);
+	ofi_strcatf(buf, "%s%srma_iov_limit: %zu\n", prefix, TAB, attr->rma_iov_limit);
 }
 
-static void fi_tostr_rx_attr(char *buf, const struct fi_rx_attr *attr,
+static void ofi_tostr_rx_attr(char *buf, const struct fi_rx_attr *attr,
 			     const char *prefix)
 {
 	if (!attr) {
-		strcatf(buf, "%sfi_rx_attr: (null)\n", prefix);
+		ofi_strcatf(buf, "%sfi_rx_attr: (null)\n", prefix);
 		return;
 	}
 
-	strcatf(buf, "%sfi_rx_attr:\n", prefix);
-	strcatf(buf, "%s%scaps: [ ", prefix, TAB);
-	fi_tostr_caps(buf, attr->caps);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%sfi_rx_attr:\n", prefix);
+	ofi_strcatf(buf, "%s%scaps: [ ", prefix, TAB);
+	ofi_tostr_caps(buf, attr->caps);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%smode: [ ", prefix, TAB);
-	fi_tostr_mode(buf, attr->mode);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%s%smode: [ ", prefix, TAB);
+	ofi_tostr_mode(buf, attr->mode);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%sop_flags: [ ", prefix, TAB);
-	fi_tostr_flags(buf, attr->op_flags);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%s%sop_flags: [ ", prefix, TAB);
+	ofi_tostr_opflags(buf, attr->op_flags);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%smsg_order: [ ", prefix, TAB);
-	fi_tostr_order(buf, attr->msg_order);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%s%smsg_order: [ ", prefix, TAB);
+	ofi_tostr_msgorder(buf, attr->msg_order);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%scomp_order: [ ", prefix, TAB);
-	fi_tostr_order(buf, attr->comp_order);
-	strcatf(buf, " ]\n");
+	ofi_strcatf(buf, "%s%scomp_order: [ ", prefix, TAB);
+	ofi_tostr_comporder(buf, attr->comp_order);
+	ofi_strcatf(buf, " ]\n");
 
-	strcatf(buf, "%s%stotal_buffered_recv: %zd\n", prefix, TAB, attr->total_buffered_recv);
-	strcatf(buf, "%s%ssize: %zd\n", prefix, TAB, attr->size);
-	strcatf(buf, "%s%siov_limit: %zd\n", prefix, TAB, attr->iov_limit);
+	ofi_strcatf(buf, "%s%stotal_buffered_recv: %zu\n", prefix, TAB, attr->total_buffered_recv);
+	ofi_strcatf(buf, "%s%ssize: %zu\n", prefix, TAB, attr->size);
+	ofi_strcatf(buf, "%s%siov_limit: %zu\n", prefix, TAB, attr->iov_limit);
 }
 
-static void fi_tostr_ep_attr(char *buf, const struct fi_ep_attr *attr, const char *prefix)
+static void ofi_tostr_ep_attr(char *buf, const struct fi_ep_attr *attr, const char *prefix)
 {
 	if (!attr) {
-		strcatf(buf, "%sfi_ep_attr: (null)\n", prefix);
+		ofi_strcatf(buf, "%sfi_ep_attr: (null)\n", prefix);
 		return;
 	}
 
-	strcatf(buf, "%sfi_ep_attr:\n", prefix);
-	strcatf(buf, "%s%stype: ", prefix, TAB);
-	fi_tostr_ep_type(buf, attr->type);
-	strcatf(buf, "\n");
-	strcatf(buf, "%s%sprotocol: ", prefix, TAB);
-	fi_tostr_protocol(buf, attr->protocol);
-	strcatf(buf, "\n");
-	strcatf(buf, "%s%sprotocol_version: %d\n", prefix, TAB, attr->protocol_version);
-	strcatf(buf, "%s%smax_msg_size: %zd\n", prefix, TAB, attr->max_msg_size);
-	strcatf(buf, "%s%smsg_prefix_size: %zd\n", prefix, TAB, attr->msg_prefix_size);
-	strcatf(buf, "%s%smax_order_raw_size: %zd\n", prefix, TAB, attr->max_order_raw_size);
-	strcatf(buf, "%s%smax_order_war_size: %zd\n", prefix, TAB, attr->max_order_war_size);
-	strcatf(buf, "%s%smax_order_waw_size: %zd\n", prefix, TAB, attr->max_order_waw_size);
-	strcatf(buf, "%s%smem_tag_format: 0x%016llx\n", prefix, TAB, attr->mem_tag_format);
-
-	strcatf(buf, "%s%stx_ctx_cnt: %zd\n", prefix, TAB, attr->tx_ctx_cnt);
-	strcatf(buf, "%s%srx_ctx_cnt: %zd\n", prefix, TAB, attr->rx_ctx_cnt);
-
-	strcatf(buf, "%s%sauth_key_size: %zd\n", prefix, TAB, attr->auth_key_size);
+	ofi_strcatf(buf, "%sfi_ep_attr:\n", prefix);
+	ofi_strcatf(buf, "%s%stype: ", prefix, TAB);
+	ofi_tostr_ep_type(buf, attr->type);
+	ofi_strcatf(buf, "\n");
+	ofi_strcatf(buf, "%s%sprotocol: ", prefix, TAB);
+	ofi_tostr_protocol(buf, attr->protocol);
+	ofi_strcatf(buf, "\n");
+	ofi_strcatf(buf, "%s%sprotocol_version: %d\n", prefix, TAB, attr->protocol_version);
+	ofi_strcatf(buf, "%s%smax_msg_size: %zu\n", prefix, TAB, attr->max_msg_size);
+	ofi_strcatf(buf, "%s%smsg_prefix_size: %zu\n", prefix, TAB, attr->msg_prefix_size);
+	ofi_strcatf(buf, "%s%smax_order_raw_size: %zu\n", prefix, TAB, attr->max_order_raw_size);
+	ofi_strcatf(buf, "%s%smax_order_war_size: %zu\n", prefix, TAB, attr->max_order_war_size);
+	ofi_strcatf(buf, "%s%smax_order_waw_size: %zu\n", prefix, TAB, attr->max_order_waw_size);
+	ofi_strcatf(buf, "%s%smem_tag_format: 0x%016llx\n", prefix, TAB, attr->mem_tag_format);
+
+	ofi_strcatf(buf, "%s%stx_ctx_cnt: %zu\n", prefix, TAB, attr->tx_ctx_cnt);
+	ofi_strcatf(buf, "%s%srx_ctx_cnt: %zu\n", prefix, TAB, attr->rx_ctx_cnt);
+
+	ofi_strcatf(buf, "%s%sauth_key_size: %zu\n", prefix, TAB, attr->auth_key_size);
 }
 
-static void fi_tostr_resource_mgmt(char *buf, enum fi_resource_mgmt rm)
+static void ofi_tostr_resource_mgmt(char *buf, enum fi_resource_mgmt rm)
 {
 	switch (rm) {
 	CASEENUMSTR(FI_RM_UNSPEC);
 	CASEENUMSTR(FI_RM_DISABLED);
 	CASEENUMSTR(FI_RM_ENABLED);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_av_type(char *buf, enum fi_av_type type)
+static void ofi_tostr_av_type(char *buf, enum fi_av_type type)
 {
 	switch (type) {
 	CASEENUMSTR(FI_AV_UNSPEC);
 	CASEENUMSTR(FI_AV_MAP);
 	CASEENUMSTR(FI_AV_TABLE);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_mr_mode(char *buf, int mr_mode)
+static void ofi_tostr_mr_mode(char *buf, int mr_mode)
 {
 	IFFLAGSTR(mr_mode, FI_MR_BASIC);
 	IFFLAGSTR(mr_mode, FI_MR_SCALABLE);
@@ -421,10 +457,10 @@ static void fi_tostr_mr_mode(char *buf, int mr_mode)
 	IFFLAGSTR(mr_mode, FI_MR_MMU_NOTIFY);
 	IFFLAGSTR(mr_mode, FI_MR_RMA_EVENT);
 
-	fi_remove_comma(buf);
+	ofi_remove_comma(buf);
 }
 
-static void fi_tostr_op_type(char *buf, int op_type)
+static void ofi_tostr_op_type(char *buf, int op_type)
 {
 	switch (op_type) {
 	CASEENUMSTR(FI_OP_RECV);
@@ -439,120 +475,225 @@ static void fi_tostr_op_type(char *buf, int op_type)
 	CASEENUMSTR(FI_OP_CNTR_SET);
 	CASEENUMSTR(FI_OP_CNTR_ADD);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_domain_attr(char *buf, const struct fi_domain_attr *attr,
+static void ofi_tostr_domain_attr(char *buf, const struct fi_domain_attr *attr,
 				 const char *prefix)
 {
 	if (!attr) {
-		strcatf(buf, "%sfi_domain_attr: (null)\n", prefix);
+		ofi_strcatf(buf, "%sfi_domain_attr: (null)\n", prefix);
 		return;
 	}
 
-	strcatf(buf, "%sfi_domain_attr:\n", prefix);
-
-	strcatf(buf, "%s%sdomain: 0x%x\n", prefix, TAB, attr->domain);
-
-	strcatf(buf, "%s%sname: %s\n", prefix, TAB, attr->name);
-	strcatf(buf, "%s%sthreading: ", prefix, TAB);
-	fi_tostr_threading(buf, attr->threading);
-	strcatf(buf, "\n");
-
-	strcatf(buf, "%s%scontrol_progress: ", prefix,TAB);
-	fi_tostr_progress(buf, attr->control_progress);
-	strcatf(buf, "\n");
-	strcatf(buf, "%s%sdata_progress: ", prefix, TAB);
-	fi_tostr_progress(buf, attr->data_progress);
-	strcatf(buf, "\n");
-	strcatf(buf, "%s%sresource_mgmt: ", prefix, TAB);
-	fi_tostr_resource_mgmt(buf, attr->resource_mgmt);
-	strcatf(buf, "\n");
-	strcatf(buf, "%s%sav_type: ", prefix, TAB);
-	fi_tostr_av_type(buf, attr->av_type);
-	strcatf(buf, "\n");
-	strcatf(buf, "%s%smr_mode: [ ", prefix, TAB);
-	fi_tostr_mr_mode(buf, attr->mr_mode);
-	strcatf(buf, " ]\n");
-
-	strcatf(buf, "%s%smr_key_size: %zd\n", prefix, TAB, attr->mr_key_size);
-	strcatf(buf, "%s%scq_data_size: %zd\n", prefix, TAB, attr->cq_data_size);
-	strcatf(buf, "%s%scq_cnt: %zd\n", prefix, TAB, attr->cq_cnt);
-	strcatf(buf, "%s%sep_cnt: %zd\n", prefix, TAB, attr->ep_cnt);
-	strcatf(buf, "%s%stx_ctx_cnt: %zd\n", prefix, TAB, attr->tx_ctx_cnt);
-	strcatf(buf, "%s%srx_ctx_cnt: %zd\n", prefix, TAB, attr->rx_ctx_cnt);
-	strcatf(buf, "%s%smax_ep_tx_ctx: %zd\n", prefix, TAB, attr->max_ep_tx_ctx);
-	strcatf(buf, "%s%smax_ep_rx_ctx: %zd\n", prefix, TAB, attr->max_ep_rx_ctx);
-	strcatf(buf, "%s%smax_ep_stx_ctx: %zd\n", prefix, TAB, attr->max_ep_stx_ctx);
-	strcatf(buf, "%s%smax_ep_srx_ctx: %zd\n", prefix, TAB, attr->max_ep_srx_ctx);
-	strcatf(buf, "%s%scntr_cnt: %zd\n", prefix, TAB, attr->cntr_cnt);
-	strcatf(buf, "%s%smr_iov_limit: %zd\n", prefix, TAB, attr->mr_iov_limit);
-
-	strcatf(buf, "%scaps: [ ", TAB);
-	fi_tostr_caps(buf, attr->caps);
-	strcatf(buf, " ]\n");
-
-	strcatf(buf, "%smode: [ ", TAB);
-	fi_tostr_mode(buf, attr->mode);
-	strcatf(buf, " ]\n");
-
-	strcatf(buf, "%s%sauth_key_size: %zd\n", prefix, TAB, attr->auth_key_size);
-	strcatf(buf, "%s%smax_err_data: %zd\n", prefix, TAB, attr->max_err_data);
-	strcatf(buf, "%s%smr_cnt: %zd\n", prefix, TAB, attr->mr_cnt);
-}
-
-static void fi_tostr_fabric_attr(char *buf, const struct fi_fabric_attr *attr,
+	ofi_strcatf(buf, "%sfi_domain_attr:\n", prefix);
+
+	ofi_strcatf(buf, "%s%sdomain: 0x%x\n", prefix, TAB, attr->domain);
+
+	ofi_strcatf(buf, "%s%sname: %s\n", prefix, TAB, attr->name);
+	ofi_strcatf(buf, "%s%sthreading: ", prefix, TAB);
+	ofi_tostr_threading(buf, attr->threading);
+	ofi_strcatf(buf, "\n");
+
+	ofi_strcatf(buf, "%s%scontrol_progress: ", prefix,TAB);
+	ofi_tostr_progress(buf, attr->control_progress);
+	ofi_strcatf(buf, "\n");
+	ofi_strcatf(buf, "%s%sdata_progress: ", prefix, TAB);
+	ofi_tostr_progress(buf, attr->data_progress);
+	ofi_strcatf(buf, "\n");
+	ofi_strcatf(buf, "%s%sresource_mgmt: ", prefix, TAB);
+	ofi_tostr_resource_mgmt(buf, attr->resource_mgmt);
+	ofi_strcatf(buf, "\n");
+	ofi_strcatf(buf, "%s%sav_type: ", prefix, TAB);
+	ofi_tostr_av_type(buf, attr->av_type);
+	ofi_strcatf(buf, "\n");
+	ofi_strcatf(buf, "%s%smr_mode: [ ", prefix, TAB);
+	ofi_tostr_mr_mode(buf, attr->mr_mode);
+	ofi_strcatf(buf, " ]\n");
+
+	ofi_strcatf(buf, "%s%smr_key_size: %zu\n", prefix, TAB, attr->mr_key_size);
+	ofi_strcatf(buf, "%s%scq_data_size: %zu\n", prefix, TAB, attr->cq_data_size);
+	ofi_strcatf(buf, "%s%scq_cnt: %zu\n", prefix, TAB, attr->cq_cnt);
+	ofi_strcatf(buf, "%s%sep_cnt: %zu\n", prefix, TAB, attr->ep_cnt);
+	ofi_strcatf(buf, "%s%stx_ctx_cnt: %zu\n", prefix, TAB, attr->tx_ctx_cnt);
+	ofi_strcatf(buf, "%s%srx_ctx_cnt: %zu\n", prefix, TAB, attr->rx_ctx_cnt);
+	ofi_strcatf(buf, "%s%smax_ep_tx_ctx: %zu\n", prefix, TAB, attr->max_ep_tx_ctx);
+	ofi_strcatf(buf, "%s%smax_ep_rx_ctx: %zu\n", prefix, TAB, attr->max_ep_rx_ctx);
+	ofi_strcatf(buf, "%s%smax_ep_stx_ctx: %zu\n", prefix, TAB, attr->max_ep_stx_ctx);
+	ofi_strcatf(buf, "%s%smax_ep_srx_ctx: %zu\n", prefix, TAB, attr->max_ep_srx_ctx);
+	ofi_strcatf(buf, "%s%scntr_cnt: %zu\n", prefix, TAB, attr->cntr_cnt);
+	ofi_strcatf(buf, "%s%smr_iov_limit: %zu\n", prefix, TAB, attr->mr_iov_limit);
+
+	ofi_strcatf(buf, "%scaps: [ ", TAB);
+	ofi_tostr_caps(buf, attr->caps);
+	ofi_strcatf(buf, " ]\n");
+
+	ofi_strcatf(buf, "%smode: [ ", TAB);
+	ofi_tostr_mode(buf, attr->mode);
+	ofi_strcatf(buf, " ]\n");
+
+	ofi_strcatf(buf, "%s%sauth_key_size: %zu\n", prefix, TAB, attr->auth_key_size);
+	ofi_strcatf(buf, "%s%smax_err_data: %zu\n", prefix, TAB, attr->max_err_data);
+	ofi_strcatf(buf, "%s%smr_cnt: %zu\n", prefix, TAB, attr->mr_cnt);
+}
+
+static void ofi_tostr_fabric_attr(char *buf, const struct fi_fabric_attr *attr,
 				 const char *prefix)
 {
 	if (!attr) {
-		strcatf(buf, "%sfi_fabric_attr: (null)\n", prefix);
+		ofi_strcatf(buf, "%sfi_fabric_attr: (null)\n", prefix);
 		return;
 	}
 
-	strcatf(buf, "%sfi_fabric_attr:\n", prefix);
-	strcatf(buf, "%s%sname: %s\n", prefix, TAB, attr->name);
-	strcatf(buf, "%s%sprov_name: %s\n", prefix, TAB, attr->prov_name);
-	strcatf(buf, "%s%sprov_version: %d.%d\n", prefix, TAB,
+	ofi_strcatf(buf, "%sfi_fabric_attr:\n", prefix);
+	ofi_strcatf(buf, "%s%sname: %s\n", prefix, TAB, attr->name);
+	ofi_strcatf(buf, "%s%sprov_name: %s\n", prefix, TAB, attr->prov_name);
+	ofi_strcatf(buf, "%s%sprov_version: %d.%d\n", prefix, TAB,
 		FI_MAJOR(attr->prov_version), FI_MINOR(attr->prov_version));
-	strcatf(buf, "%s%sapi_version: %d.%d\n", prefix, TAB,
+	ofi_strcatf(buf, "%s%sapi_version: %d.%d\n", prefix, TAB,
 		FI_MAJOR(attr->api_version), FI_MINOR(attr->api_version));
 }
 
-static void fi_tostr_info(char *buf, const struct fi_info *info)
+static void ofi_tostr_device_attr(char *buf, size_t len,
+				  const struct fi_device_attr *attr)
 {
-	strcatf(buf, "fi_info:\n");
-	strcatf(buf, "%scaps: [ ", TAB);
-	fi_tostr_caps(buf, info->caps);
-	strcatf(buf, " ]\n");
+	const char *prefix = TAB TAB;
+
+	ofi_strncatf(buf, len, "%sfi_device_attr:\n", prefix);
+
+	prefix = TAB TAB TAB;
+	ofi_strncatf(buf, len, "%sname: %s\n", prefix, attr->name);
+	ofi_strncatf(buf, len, "%sdevice_id: %s\n", prefix, attr->device_id);
+	ofi_strncatf(buf, len, "%sdevice_version: %s\n", prefix,
+		     attr->device_version);
+	ofi_strncatf(buf, len, "%svendor_id: %s\n", prefix, attr->vendor_id);
+	ofi_strncatf(buf, len, "%sdriver: %s\n", prefix, attr->driver);
+	ofi_strncatf(buf, len, "%sfirmware: %s\n", prefix, attr->firmware);
+}
 
-	strcatf(buf, "%smode: [ ", TAB);
-	fi_tostr_mode(buf, info->mode);
-	strcatf(buf, " ]\n");
+static void ofi_tostr_pci_attr(char *buf, size_t len,
+			       const struct fi_pci_attr *attr)
+{
+	const char *prefix = TAB TAB TAB;
 
-	strcatf(buf, "%saddr_format: ", TAB);
-	fi_tostr_addr_format(buf, info->addr_format);
-	strcatf(buf, "\n");
+	ofi_strncatf(buf, len, "%sfi_pci_attr:\n", prefix);
 
-	strcatf(buf, "%ssrc_addrlen: %zd\n", TAB, info->src_addrlen);
-	strcatf(buf, "%sdest_addrlen: %zd\n", TAB, info->dest_addrlen);
-	strcatf(buf, "%ssrc_addr: ", TAB);
-	fi_tostr_addr(buf, info->addr_format, info->src_addr);
-	strcatf(buf, "\n");
-	strcatf(buf, "%sdest_addr: ", TAB);
-	fi_tostr_addr(buf, info->addr_format, info->dest_addr);
-	strcatf(buf, "\n");
-	strcatf(buf, "%shandle: %s\n", TAB, info->handle);
+	prefix = TAB TAB TAB TAB;
+	ofi_strncatf(buf, len, "%sdomain_id: %u\n", prefix, attr->domain_id);
+	ofi_strncatf(buf, len, "%sbus_id: %u\n", prefix, attr->bus_id);
+	ofi_strncatf(buf, len, "%sdevice_id: %u\n", prefix, attr->device_id);
+	ofi_strncatf(buf, len, "%sfunction_id: %u\n", prefix, attr->function_id);
+}
 
-	fi_tostr_tx_attr(buf, info->tx_attr, TAB);
-	fi_tostr_rx_attr(buf, info->rx_attr, TAB);
-	fi_tostr_ep_attr(buf, info->ep_attr, TAB);
-	fi_tostr_domain_attr(buf, info->domain_attr, TAB);
-	fi_tostr_fabric_attr(buf, info->fabric_attr, TAB);
+static void ofi_tostr_bus_type(char *buf, size_t len, int type)
+{
+	switch (type) {
+	CASEENUMSTRN(FI_BUS_UNKNOWN, len);
+	CASEENUMSTRN(FI_BUS_PCI, len);
+	default:
+		ofi_strncatf(buf, len, "Unknown");
+		break;
+	}
+}
+
+static void ofi_tostr_bus_attr(char *buf, size_t len,
+			       const struct fi_bus_attr *attr)
+{
+	const char *prefix = TAB TAB;
+
+	ofi_strncatf(buf, len, "%sfi_bus_attr:\n", prefix);
+
+	prefix = TAB TAB TAB;
+	ofi_strncatf(buf, len, "%sfi_bus_type: ", prefix);
+	ofi_tostr_bus_type(buf, len, attr->bus_type);
+	ofi_strncatf(buf, len, "\n");
+
+	switch (attr->bus_type) {
+	case FI_BUS_PCI:
+		ofi_tostr_pci_attr(buf, len, &attr->attr.pci);
+		break;
+	default:
+		break;
+	}
 }
 
-static void fi_tostr_atomic_type(char *buf, enum fi_datatype type)
+static void ofi_tostr_link_state(char *buf, size_t len, int state)
+{
+	switch (state) {
+	CASEENUMSTRN(FI_LINK_UNKNOWN, len);
+	CASEENUMSTRN(FI_LINK_DOWN, len);
+	CASEENUMSTRN(FI_LINK_UP, len);
+	default:
+		ofi_strncatf(buf, len, "Unknown");
+		break;
+	}
+}
+
+static void ofi_tostr_link_attr(char *buf, size_t len,
+				const struct fi_link_attr *attr)
+{
+	const char *prefix = TAB TAB;
+	ofi_strncatf(buf, len, "%sfi_link_attr:\n", prefix);
+
+	prefix = TAB TAB TAB;
+	ofi_strncatf(buf, len, "%saddress: %s\n", prefix, attr->address);
+	ofi_strncatf(buf, len, "%smtu: %zu\n", prefix, attr->mtu);
+	ofi_strncatf(buf, len, "%sspeed: %zu\n", prefix, attr->speed);
+	ofi_strncatf(buf, len, "%sstate: ", prefix);
+	ofi_tostr_link_state(buf, len, attr->state);
+	ofi_strncatf(buf, len, "\n%snetwork_type: %s\n", prefix,
+		     attr->network_type);
+}
+
+int ofi_nic_tostr(const struct fid *fid_nic, char *buf, size_t len)
+{
+	const struct fid_nic *nic = (const struct fid_nic*) fid_nic;
+
+	assert(fid_nic->fclass == FI_CLASS_NIC);
+	ofi_strncatf(buf, len, "%sfid_nic:\n", TAB);
+
+	ofi_tostr_device_attr(buf, len, nic->device_attr);
+	ofi_tostr_bus_attr(buf, len, nic->bus_attr);
+	ofi_tostr_link_attr(buf, len, nic->link_attr);
+	return 0;
+}
+
+static void ofi_tostr_info(char *buf, const struct fi_info *info)
+{
+	ofi_strcatf(buf, "fi_info:\n");
+	ofi_strcatf(buf, "%scaps: [ ", TAB);
+	ofi_tostr_caps(buf, info->caps);
+	ofi_strcatf(buf, " ]\n");
+
+	ofi_strcatf(buf, "%smode: [ ", TAB);
+	ofi_tostr_mode(buf, info->mode);
+	ofi_strcatf(buf, " ]\n");
+
+	ofi_strcatf(buf, "%saddr_format: ", TAB);
+	oofi_tostr_addr_format(buf, info->addr_format);
+	ofi_strcatf(buf, "\n");
+
+	ofi_strcatf(buf, "%ssrc_addrlen: %zu\n", TAB, info->src_addrlen);
+	ofi_strcatf(buf, "%sdest_addrlen: %zu\n", TAB, info->dest_addrlen);
+	ofi_strcatf(buf, "%ssrc_addr: ", TAB);
+	ofi_tostr_addr(buf, info->addr_format, info->src_addr);
+	ofi_strcatf(buf, "\n");
+	ofi_strcatf(buf, "%sdest_addr: ", TAB);
+	ofi_tostr_addr(buf, info->addr_format, info->dest_addr);
+	ofi_strcatf(buf, "\n");
+	ofi_tostr_fid(TAB "handle: ", buf, info->handle);
+
+	ofi_tostr_tx_attr(buf, info->tx_attr, TAB);
+	ofi_tostr_rx_attr(buf, info->rx_attr, TAB);
+	ofi_tostr_ep_attr(buf, info->ep_attr, TAB);
+	ofi_tostr_domain_attr(buf, info->domain_attr, TAB);
+	ofi_tostr_fabric_attr(buf, info->fabric_attr, TAB);
+	ofi_tostr_fid(TAB "nic_fid: ", buf, &info->nic->fid);
+}
+
+static void ofi_tostr_atomic_type(char *buf, enum fi_datatype type)
 {
 	switch (type) {
 	CASEENUMSTR(FI_INT8);
@@ -570,12 +711,12 @@ static void fi_tostr_atomic_type(char *buf, enum fi_datatype type)
 	CASEENUMSTR(FI_LONG_DOUBLE);
 	CASEENUMSTR(FI_LONG_DOUBLE_COMPLEX);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_atomic_op(char *buf, enum fi_op op)
+static void ofi_tostr_atomic_op(char *buf, enum fi_op op)
 {
 	switch (op) {
 	CASEENUMSTR(FI_MIN);
@@ -598,18 +739,18 @@ static void fi_tostr_atomic_op(char *buf, enum fi_op op)
 	CASEENUMSTR(FI_CSWAP_GT);
 	CASEENUMSTR(FI_MSWAP);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_version(char *buf)
+static void ofi_tostr_version(char *buf)
 {
-	strcatf(buf, VERSION);
-	strcatf(buf, BUILD_ID);
+	ofi_strcatf(buf, VERSION);
+	ofi_strcatf(buf, BUILD_ID);
 }
 
-static void fi_tostr_eq_event(char *buf, int type)
+static void ofi_tostr_eq_event(char *buf, int type)
 {
 	switch (type) {
 	CASEENUMSTR(FI_NOTIFY);
@@ -619,12 +760,12 @@ static void fi_tostr_eq_event(char *buf, int type)
 	CASEENUMSTR(FI_MR_COMPLETE);
 	CASEENUMSTR(FI_AV_COMPLETE);
 	default:
-		strcatf(buf, "Unknown");
+		ofi_strcatf(buf, "Unknown");
 		break;
 	}
 }
 
-static void fi_tostr_cq_event_flags(char *buf, uint64_t flags)
+static void ofi_tostr_cq_event_flags(char *buf, uint64_t flags)
 {
 	IFFLAGSTR(flags, FI_SEND);
 	IFFLAGSTR(flags, FI_RECV);
@@ -638,7 +779,9 @@ static void fi_tostr_cq_event_flags(char *buf, uint64_t flags)
 	IFFLAGSTR(flags, FI_REMOTE_WRITE);
 	IFFLAGSTR(flags, FI_REMOTE_CQ_DATA);
 	IFFLAGSTR(flags, FI_MULTI_RECV);
-	fi_remove_comma(buf);
+	IFFLAGSTR(flags, FI_MORE);
+	IFFLAGSTR(flags, FI_CLAIM);
+	ofi_remove_comma(buf);
 }
 
 __attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
@@ -657,7 +800,7 @@ char *DEFAULT_SYMVER_PRE(fi_tostr)(const void *data, enum fi_type datatype)
 	enumval = (const int *) data;
 
 	if (!buf) {
-		buf = calloc(FI_BUFSIZ, 1);
+		buf = calloc(OFI_BUFSIZ, 1);
 		if (!buf)
 			return NULL;
 	}
@@ -665,77 +808,80 @@ char *DEFAULT_SYMVER_PRE(fi_tostr)(const void *data, enum fi_type datatype)
 
 	switch (datatype) {
 	case FI_TYPE_INFO:
-		fi_tostr_info(buf, data);
+		ofi_tostr_info(buf, data);
 		break;
 	case FI_TYPE_EP_TYPE:
-		fi_tostr_ep_type(buf, *enumval);
+		ofi_tostr_ep_type(buf, *enumval);
 		break;
 	case FI_TYPE_CAPS:
-		fi_tostr_caps(buf, *val64);
+		ofi_tostr_caps(buf, *val64);
 		break;
 	case FI_TYPE_OP_FLAGS:
-		fi_tostr_flags(buf, *val64);
+		ofi_tostr_opflags(buf, *val64);
 		break;
 	case FI_TYPE_ADDR_FORMAT:
-		fi_tostr_addr_format(buf, *val32);
+		oofi_tostr_addr_format(buf, *val32);
 		break;
 	case FI_TYPE_TX_ATTR:
-		fi_tostr_tx_attr(buf, data, "");
+		ofi_tostr_tx_attr(buf, data, "");
 		break;
 	case FI_TYPE_RX_ATTR:
-		fi_tostr_rx_attr(buf, data, "");
+		ofi_tostr_rx_attr(buf, data, "");
 		break;
 	case FI_TYPE_EP_ATTR:
-		fi_tostr_ep_attr(buf, data, "");
+		ofi_tostr_ep_attr(buf, data, "");
 		break;
 	case FI_TYPE_DOMAIN_ATTR:
-		fi_tostr_domain_attr(buf, data, "");
+		ofi_tostr_domain_attr(buf, data, "");
 		break;
 	case FI_TYPE_FABRIC_ATTR:
-		fi_tostr_fabric_attr(buf, data, "");
+		ofi_tostr_fabric_attr(buf, data, "");
 		break;
 	case FI_TYPE_THREADING:
-		fi_tostr_threading(buf, *enumval);
+		ofi_tostr_threading(buf, *enumval);
 		break;
 	case FI_TYPE_PROGRESS:
-		fi_tostr_progress(buf, *enumval);
+		ofi_tostr_progress(buf, *enumval);
 		break;
 	case FI_TYPE_PROTOCOL:
-		fi_tostr_protocol(buf, *val32);
+		ofi_tostr_protocol(buf, *val32);
 		break;
 	case FI_TYPE_MSG_ORDER:
-		fi_tostr_order(buf, *val64);
+		ofi_tostr_msgorder(buf, *val64);
 		break;
 	case FI_TYPE_MODE:
-		fi_tostr_mode(buf, *val64);
+		ofi_tostr_mode(buf, *val64);
 		break;
 	case FI_TYPE_AV_TYPE:
-		fi_tostr_av_type(buf, *enumval);
+		ofi_tostr_av_type(buf, *enumval);
 		break;
 	case FI_TYPE_ATOMIC_TYPE:
-		fi_tostr_atomic_type(buf, *enumval);
+		ofi_tostr_atomic_type(buf, *enumval);
 		break;
 	case FI_TYPE_ATOMIC_OP:
-		fi_tostr_atomic_op(buf, *enumval);
+		ofi_tostr_atomic_op(buf, *enumval);
 		break;
 	case FI_TYPE_VERSION:
-		fi_tostr_version(buf);
+		ofi_tostr_version(buf);
 		break;
 	case FI_TYPE_EQ_EVENT:
-		fi_tostr_eq_event(buf, *enumval);
+		ofi_tostr_eq_event(buf, *enumval);
 		break;
 	case FI_TYPE_CQ_EVENT_FLAGS:
-		fi_tostr_cq_event_flags(buf, *val64);
+		ofi_tostr_cq_event_flags(buf, *val64);
 		break;
 	case FI_TYPE_MR_MODE:
 		/* mr_mode was an enum converted to int flags */
-		fi_tostr_mr_mode(buf, *enumval);
+		ofi_tostr_mr_mode(buf, *enumval);
 		break;
 	case FI_TYPE_OP_TYPE:
-		fi_tostr_op_type(buf, *enumval);
+		ofi_tostr_op_type(buf, *enumval);
+		break;
+	case FI_TYPE_FID:
+		ofi_tostr_fid("fid: ", buf, data);
 		break;
 	default:
-		strcatf(buf, "Unknown type");
+		ofi_strcatf(buf, "Unknown type");
 		break;
 	}
 	return buf;
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/iov.c b/src/mpid/ch4/netmod/ofi/libfabric/src/iov.c
index c65c8853d..b40c2196e 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/src/iov.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/iov.c
@@ -101,3 +101,72 @@ int ofi_truncate_iov(struct iovec *iov, size_t *iov_count, size_t trim_size)
 	}
 	return -FI_ETRUNC;
 }
+
+/* Copy 'len' bytes worth of src iovec to dst */
+int ofi_copy_iov_desc(struct iovec *dst_iov, void **dst_desc, size_t *dst_count,
+		      struct iovec *src_iov, void **src_desc, size_t src_count,
+		      size_t *index, size_t *offset, size_t len)
+{
+	size_t i, j;
+
+	assert(*index < src_count);
+	assert(*offset <= src_iov[*index].iov_len);
+
+	for (i = 0, j = *index; j < src_count; i++, j++) {
+		dst_iov[i].iov_base = (uint8_t *)src_iov[j].iov_base + *offset;
+		if (src_desc)
+			dst_desc[i] = src_desc[j];
+
+		if (len <= src_iov[j].iov_len - *offset) {
+			dst_iov[i].iov_len = len;
+			*dst_count = i + 1;
+
+			if (len == src_iov[j].iov_len - *offset) {
+				*index = j + 1;
+				*offset = 0;
+			} else {
+				*index = j;
+				*offset += len;
+			}
+			return 0;
+		}
+		dst_iov[i].iov_len = src_iov[j].iov_len - *offset;
+		len -= dst_iov[i].iov_len;
+		*offset = 0;
+	}
+	return -FI_ETOOSMALL;
+}
+
+/* Copy 'len' bytes worth of src fi_rma_iov to dst */
+int ofi_copy_rma_iov(struct fi_rma_iov *dst_iov, size_t *dst_count,
+		struct fi_rma_iov *src_iov, size_t src_count,
+		size_t *index, size_t *offset, size_t len)
+{
+	size_t i, j;
+
+	assert(*index < src_count);
+	assert(*offset <= src_iov[*index].len);
+
+	for (i = 0, j = *index; j < src_count; i++, j++) {
+		dst_iov[i].addr	= src_iov[j].addr + *offset;
+		dst_iov[i].key	= src_iov[j].key;
+
+		if (len <= src_iov[j].len - *offset) {
+			dst_iov[i].len = len;
+			*dst_count = i + 1;
+
+			if (len == src_iov[j].len - *offset) {
+				*index = j + 1;
+				*offset = 0;
+			} else {
+				*index = j;
+				*offset += len;
+			}
+			return 0;
+		}
+		dst_iov[i].len = src_iov[j].len - *offset;
+		len -= dst_iov[i].len;
+		*offset = 0;
+	}
+	return -FI_ETOOSMALL;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/linux/osd.c b/src/mpid/ch4/netmod/ofi/libfabric/src/linux/osd.c
new file mode 100644
index 000000000..977193c95
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/linux/osd.c
@@ -0,0 +1,66 @@
+/*
+ * Copyright (c) 2018 Amazon.com, Inc. or its affiliates. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _GNU_SOURCE
+#define _GNU_SOURCE
+#endif /* _GNU_SOURCE */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <errno.h>
+
+#include "ofi.h"
+#include "ofi_osd.h"
+
+ssize_t ofi_get_hugepage_size(void)
+{
+	FILE *fd;
+	char *line = NULL;
+	size_t len = 0;
+	ssize_t val = -1;
+
+	fd = fopen("/proc/meminfo", "r");
+	if (!fd)
+		return -errno;
+
+	while (getline(&line, &len, fd) != -1)
+		if (sscanf(line, "Hugepagesize: %lu kB", &val) == 1)
+			break;
+
+	free(line);
+	fclose(fd);
+
+	if (val == -1)
+		return -FI_ENOENT;
+
+	return val * 1024;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/perf.c b/src/mpid/ch4/netmod/ofi/libfabric/src/perf.c
index 5416510bf..1cd2a6590 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/src/perf.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/perf.c
@@ -42,6 +42,28 @@
 #include <rdma/providers/fi_log.h>
 
 
+enum ofi_perf_domain	perf_domain = OFI_PMU_CPU;
+uint32_t		perf_cntr = OFI_PMC_CPU_INSTR;
+uint32_t		perf_flags;
+
+
+void ofi_perf_init(void)
+{
+	char *param_val = NULL;
+
+	fi_param_define(NULL, "perf_cntr", FI_PARAM_STRING,
+			"Performance counter to analyze (default: cpu_instr). "
+			"Options: cpu_instr, cpu_cycles.");
+	fi_param_get_str(NULL, "perf_cntr", &param_val);
+	if (!param_val)
+		return;
+
+	if (!strcasecmp(param_val, "cpu_cycles")) {
+		perf_domain = OFI_PMU_CPU;
+		perf_cntr = OFI_PMC_CPU_CYCLES;
+	}
+}
+
 int ofi_perfset_create(const struct fi_provider *prov,
 		       struct ofi_perfset *set, size_t size,
 		       enum ofi_perf_domain domain, uint32_t cntr_id,
@@ -56,7 +78,7 @@ int ofi_perfset_create(const struct fi_provider *prov,
 		return ret;
 	}
 
-	set->data = calloc(size, sizeof(*set->data) + sizeof(*set->names));
+	set->data = calloc(size, sizeof(*set->data));
 	if (!set->data) {
 		ofi_pmu_close(set->ctx);
 		return -FI_ENOMEM;
@@ -64,46 +86,65 @@ int ofi_perfset_create(const struct fi_provider *prov,
 
 	set->prov = prov;
 	set->size = size;
-	set->count = 0;
-	set->names = (char **)(set->data + size);
 	return 0;
 }
 
 void ofi_perfset_close(struct ofi_perfset *set)
 {
-	while (set->count--)
-		free(set->names[set->count]);
 	ofi_pmu_close(set->ctx);
 	free(set->data);
 }
 
-struct ofi_perf_data *ofi_perfset_data(struct ofi_perfset *set,
-				       const char *name)
+static const char *ofi_perf_name(void)
 {
-	if (set->count == set->size)
-		return NULL;
-
-	if (name) {
-		set->names[set->count] = strdup(name);
-		if (!set->names[set->count])
-			return NULL;
+	switch (perf_domain) {
+	case OFI_PMU_CPU:
+		switch (perf_cntr) {
+		case OFI_PMC_CPU_CYCLES:
+			return "CPU cycles";
+		case OFI_PMC_CPU_INSTR:
+			return "CPU instr";
+		}
+		break;
+	case OFI_PMU_CACHE:
+		switch (perf_cntr) {
+		case OFI_PMC_CACHE_L1_DATA:
+			return "L1 data cache";
+		case OFI_PMC_CACHE_L1_INSTR:
+			return "L1 instr cache";
+		case OFI_PMC_CACHE_TLB_DATA:
+			return "TLB data cache";
+		case OFI_PMC_CACHE_TLB_INSTR:
+			return "TLB instr cache";
+		}
+		break;
+	case OFI_PMU_OS:
+		switch (perf_cntr) {
+		case OFI_PMC_OS_PAGE_FAULT:
+			return "page faults";
+		}
+		break;
+	case OFI_PMU_NIC:
+		break;
 	}
-
-	return &set->data[set->count++];
+	return "unknown";
 }
 
-void ofi_perfset_log(struct ofi_perfset *set)
+void ofi_perfset_log(struct ofi_perfset *set, const char *names[])
 {
 	size_t i;
 
-	for (i = 0; i < set->count; i++) {
-		if (!set->data[i].sum)
+	FI_TRACE(set->prov, FI_LOG_CORE, "\n");
+	FI_TRACE(set->prov, FI_LOG_CORE, "\tPERF: %s\n", ofi_perf_name());
+	FI_TRACE(set->prov, FI_LOG_CORE, "\t%-20s%-10s%s\n", "Name", "Avg", "Events");
+
+	for (i = 0; i < set->size; i++) {
+		if (!set->data[i].events)
 			continue;
 
-		FI_INFO(set->prov, FI_LOG_CORE, "PERF (%s) "
-			"events=%" PRIu64 " avg=%g\n",
-			set->names[i] ? set->names[i] : "unknown",
-			set->data[i].events,
-			(double) set->data[i].sum / set->data[i].events);
+		FI_TRACE(set->prov, FI_LOG_CORE, "\t%-20s%-10g%" PRIu64 "\n",
+			names && names[i] ? names[i] : "unknown",
+			(double) set->data[i].sum / set->data[i].events,
+			set->data[i].events);
 	}
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/rbtree.c b/src/mpid/ch4/netmod/ofi/libfabric/src/rbtree.c
index 6b88fb879..c6377fa7c 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/src/rbtree.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/rbtree.c
@@ -434,3 +434,24 @@ void *rbtFind(RbtHandle h, void *key) {
     }
     return NULL;
 }
+
+void rbtTraversal(RbtHandle h, RbtIterator it, void *handler_arg,
+          void(*handler)(void *arg, RbtIterator it)) {
+    RbtType *rbt = h;
+    NodeType *root = it;
+
+    // apply handler for:
+    // -o the root of the tree/subtree
+    handler(handler_arg, it);
+    // - the left subtree
+    if (root->left != SENTINEL)
+        rbtTraversal(h, root->left, handler_arg, handler);
+    // - the right subtree
+    if (root->right != SENTINEL)
+        rbtTraversal(h, root->right, handler_arg, handler);
+}
+
+void *rbtRoot(RbtHandle h) {
+    RbtType *rbt = h;
+    return rbt->root;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/shared/ofi_str.c b/src/mpid/ch4/netmod/ofi/libfabric/src/shared/ofi_str.c
new file mode 100644
index 000000000..80218f9de
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/shared/ofi_str.c
@@ -0,0 +1,171 @@
+/*
+ * Copyright (c) 2018 Intel Corp., Inc.  All rights reserved.
+ * Copyright (c) 2018 Cisco Systems, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <assert.h>
+
+#include <rdma/fi_errno.h>
+
+/*
+ * TODO remove this and include ofi_osd.h which would require merging osd.h
+ * files in libfabric and fabtests
+ */
+#if defined _WIN32
+#define strdup _strdup
+
+static inline char* strsep(char **stringp, const char *delim)
+{
+	char* ptr = *stringp;
+	char* p;
+
+	p = ptr ? strpbrk(ptr, delim) : NULL;
+
+	if(!p)
+		*stringp = NULL;
+	else
+	{
+		*p = 0;
+		*stringp = p + 1;
+	}
+
+	return ptr;
+}
+#endif
+
+/* String utility functions */
+
+int ofi_rm_substr(char *str, const char *substr)
+{
+	char *dest, *src;
+
+	dest = strstr(str, substr);
+	if (!dest)
+		return -FI_EINVAL;
+
+	src = dest + strlen(substr);
+	memmove(dest, src, strlen(src) + 1);
+	return 0;
+}
+
+int ofi_rm_substr_delim(char *str, const char *substr, const char delim)
+{
+	char *pattern;
+	size_t len = strlen(substr) + 2; // account for delim and null char
+	int ret;
+
+	pattern = malloc(len);
+	if (!pattern)
+		return -FI_ENOMEM;
+
+	snprintf(pattern, len, "%c%s", delim, substr);
+	ret = ofi_rm_substr(str, pattern);
+	if (!ret)
+		goto out;
+
+	snprintf(pattern, len, "%s%c", substr, delim);
+	ret = ofi_rm_substr(str, pattern);
+	if (!ret)
+		goto out;
+
+	ret = ofi_rm_substr(str, substr);
+out:
+	free(pattern);
+	return ret;
+}
+
+/* Split the given string "s" using the specified delimiter(s) in the string
+ * "delim" and return an array of strings. The array is terminated with a NULL
+ * pointer. Returned array should be freed with ofi_free_string_array().
+ *
+ * Returns NULL on failure.
+ */
+
+char **ofi_split_and_alloc(const char *s, const char *delim, size_t *count)
+{
+	int i, n;
+	char *tmp;
+	char *dup = NULL;
+	char **arr = NULL;
+
+	if (!s || !delim)
+		return NULL;
+
+	dup = strdup(s);
+	if (!dup)
+		return NULL;
+
+	/* compute the array size */
+	n = 1;
+	for (tmp = dup; *tmp != '\0'; ++tmp) {
+		for (i = 0; delim[i] != '\0'; ++i) {
+			if (*tmp == delim[i]) {
+				++n;
+				break;
+			}
+		}
+	}
+
+	/* +1 to leave space for NULL terminating pointer */
+	arr = calloc(n + 1, sizeof(*arr));
+	if (!arr)
+		goto cleanup;
+
+	/* set array elts to point inside the dup'ed string */
+	for (tmp = dup, i = 0; tmp != NULL; ++i) {
+		arr[i] = strsep(&tmp, delim);
+	}
+	assert(i == n);
+
+	if (count)
+		*count = n;
+	return arr;
+
+cleanup:
+	free(dup);
+	free(arr);
+	return NULL;
+}
+
+/* see ofi_split_and_alloc() */
+void ofi_free_string_array(char **s)
+{
+	/* all strings are allocated from the same strdup'ed slab, so just free
+	 * the first element */
+	if (s != NULL)
+		free(s[0]);
+
+	/* and then the actual array of pointers */
+	free(s);
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/tree.c b/src/mpid/ch4/netmod/ofi/libfabric/src/tree.c
new file mode 100644
index 000000000..ce3109076
--- /dev/null
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/tree.c
@@ -0,0 +1,326 @@
+/*
+ * Copyright (c) 2015 Cray Inc. All rights reserved.
+ * Copyright (c) 2018 Intel Corp, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+/*
+ * Copied from http://oopweb.com/Algorithms/Documents/Sman/VolumeFrames.html?/Algorithms/Documents/Sman/Volume/RedBlackTrees_files/s_rbt.htm
+ *
+ * Disclosure from the author's main page:
+ * (http://oopweb.com/Algorithms/Documents/Sman/VolumeFrames.html?/Algorithms/Documents/Sman/Volume/RedBlackTrees_files/s_rbt.htm)
+ *
+ *     Source code when part of a software project may be used freely
+ *     without reference to the author.
+ *
+ */
+
+// reentrant red-black tree
+
+#include <assert.h>
+
+#include <ofi_tree.h>
+#include <rdma/fi_errno.h>
+
+
+void ofi_rbmap_init(struct ofi_rbmap *map)
+{
+	assert(map->compare);
+
+	map->root = &map->sentinel;
+	map->sentinel.left = &map->sentinel;
+	map->sentinel.right = &map->sentinel;
+	map->sentinel.parent = NULL;
+	map->sentinel.color = BLACK;
+	map->sentinel.data = NULL;
+}
+
+static void ofi_delete_tree(struct ofi_rbmap *map, struct ofi_rbnode *node)
+{
+	if (node == &map->sentinel)
+		return;
+
+	ofi_delete_tree(map, node->left);
+	ofi_delete_tree(map, node->right);
+	free(node);
+}
+
+void ofi_rbmap_cleanup(struct ofi_rbmap *map)
+{
+	ofi_delete_tree(map, map->root);
+	free(map);
+}
+
+int ofi_rbmap_empty(struct ofi_rbmap *map)
+{
+	return map->root == &map->sentinel;
+}
+
+static void ofi_rotate_left(struct ofi_rbmap *map, struct ofi_rbnode *node)
+{
+	struct ofi_rbnode *y = node->right;
+
+	node->right = y->left;
+	if (y->left != &map->sentinel)
+		y->left->parent = node;
+
+	if (y != &map->sentinel)
+		y->parent = node->parent;
+	if (node->parent) {
+		if (node== node->parent->left)
+			node->parent->left = y;
+		else
+			node->parent->right = y;
+	} else {
+		map->root = y;
+	}
+
+	y->left = node;
+	if (node != &map->sentinel)
+		node->parent = y;
+}
+
+static void ofi_rotate_right(struct ofi_rbmap *map, struct ofi_rbnode *node)
+{
+	struct ofi_rbnode *y = node->left;
+
+	node->left = y->right;
+	if (y->right != &map->sentinel)
+		y->right->parent = node;
+
+	if (y != &map->sentinel)
+		y->parent = node->parent;
+	if (node->parent) {
+		if (node == node->parent->right)
+			node->parent->right = y;
+		else
+			node->parent->left = y;
+	} else {
+		map->root = y;
+	}
+
+	y->right = node;
+	if (node != &map->sentinel)
+		node->parent = y;
+}
+
+static void
+ofi_insert_rebalance(struct ofi_rbmap *map, struct ofi_rbnode *x)
+{
+	struct ofi_rbnode *y;
+
+	while (x != map->root && x->parent->color == RED) {
+		if (x->parent == x->parent->parent->left) {
+			y = x->parent->parent->right;
+			if (y->color == RED) {
+				x->parent->color = BLACK;
+				y->color = BLACK;
+				x->parent->parent->color = RED;
+				x = x->parent->parent;
+			} else {
+				if (x == x->parent->right) {
+					x = x->parent;
+					ofi_rotate_left(map, x);
+				}
+
+				x->parent->color = BLACK;
+				x->parent->parent->color = RED;
+				ofi_rotate_right(map, x->parent->parent);
+			}
+		} else {
+			y = x->parent->parent->left;
+			if (y->color == RED) {
+				x->parent->color = BLACK;
+				y->color = BLACK;
+				x->parent->parent->color = RED;
+				x = x->parent->parent;
+			} else {
+				if (x == x->parent->left) {
+					x = x->parent;
+					ofi_rotate_right(map, x);
+				}
+				x->parent->color = BLACK;
+				x->parent->parent->color = RED;
+				ofi_rotate_left(map, x->parent->parent);
+			}
+		}
+	}
+	map->root->color = BLACK;
+}
+
+int ofi_rbmap_insert(struct ofi_rbmap *map, void *key, void *data)
+{
+	struct ofi_rbnode *current, *parent, *node;
+	int ret;
+
+	current = map->root;
+	parent = NULL;
+
+	while (current != &map->sentinel) {
+		ret = map->compare(map, key, current->data);
+		if (ret == 0)
+			return -FI_EALREADY;
+
+		parent = current;
+		current = (ret < 0) ? current->left : current->right;
+	}
+
+	node = malloc(sizeof(*node));
+	if (!node)
+		return -FI_ENOMEM;
+
+	node->parent = parent;
+	node->left = &map->sentinel;
+	node->right = &map->sentinel;
+	node->color = RED;
+	node->data = data;
+
+	if (parent) {
+		if (map->compare(map, key, parent->data) < 0)
+			parent->left = node;
+		else
+			parent->right = node;
+	} else {
+		map->root = node;
+	}
+
+	ofi_insert_rebalance(map, node);
+	return 0;
+}
+
+static void ofi_delete_rebalance(struct ofi_rbmap *map, struct ofi_rbnode *node)
+{
+	struct ofi_rbnode *w;
+
+	while (node != map->root && node->color == BLACK) {
+		if (node == node->parent->left) {
+			w = node->parent->right;
+			if (w->color == RED) {
+				w->color = BLACK;
+				node->parent->color = RED;
+				ofi_rotate_left(map, node->parent);
+				w = node->parent->right;
+			}
+			if (w->left->color == BLACK && w->right->color == BLACK) {
+				w->color = RED;
+				node = node->parent;
+			} else {
+				if (w->right->color == BLACK) {
+					w->left->color = BLACK;
+					w->color = RED;
+					ofi_rotate_right(map, w);
+					w = node->parent->right;
+				}
+				w->color = node->parent->color;
+				node->parent->color = BLACK;
+				w->right->color = BLACK;
+				ofi_rotate_left(map, node->parent);
+				node = map->root;
+			}
+		} else {
+			w = node->parent->left;
+			if (w->color == RED) {
+				w->color = BLACK;
+				node->parent->color = RED;
+				ofi_rotate_right(map, node->parent);
+				w = node->parent->left;
+			}
+			if (w->right->color == BLACK && w->left->color == BLACK) {
+				w->color = RED;
+				node = node->parent;
+			} else {
+				if (w->left->color == BLACK) {
+					w->right->color = BLACK;
+					w->color = RED;
+					ofi_rotate_left(map, w);
+					w = node->parent->left;
+				}
+				w->color = node->parent->color;
+				node->parent->color = BLACK;
+				w->left->color = BLACK;
+				ofi_rotate_right(map, node->parent);
+				node = map->root;
+			}
+		}
+	}
+	node->color = BLACK;
+}
+
+void ofi_rbmap_delete(struct ofi_rbmap *map, struct ofi_rbnode *node)
+{
+	struct ofi_rbnode *x, *y;
+
+	if (node->left == &map->sentinel || node->right == &map->sentinel) {
+		y = node;
+	} else {
+		y = node->right;
+		while (y->left != &map->sentinel)
+			y = y->left;
+	}
+
+	if (y->left != &map->sentinel)
+		x = y->left;
+	else
+		x = y->right;
+
+	x->parent = y->parent;
+	if (y->parent) {
+		if (y == y->parent->left)
+			y->parent->left = x;
+		else
+			y->parent->right = x;
+	} else {
+		map->root = x;
+	}
+
+	if (y != node)
+		node->data = y->data;
+
+	if (y->color == BLACK)
+		ofi_delete_rebalance(map, x);
+
+	free (y);
+}
+
+struct ofi_rbnode *ofi_rbmap_find(struct ofi_rbmap *map, void *key)
+{
+	struct ofi_rbnode *node;
+	int ret;
+
+	node = map->root;
+	while (node != &map->sentinel) {
+		ret = map->compare(map, key, node->data);
+		if (ret == 0)
+			return node;
+
+		node = (ret < 0) ? node->left : node->right;
+	}
+	return NULL;
+}
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/src/windows/osd.c b/src/mpid/ch4/netmod/ofi/libfabric/src/windows/osd.c
index 815a91612..f387a281d 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/src/windows/osd.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/src/windows/osd.c
@@ -42,8 +42,7 @@
 #include "ofi_osd.h"
 #include "ofi_file.h"
 #include "ofi_list.h"
-
-#include "prov/sockets/include/sock.h"
+#include "ofi_util.h"
 
 #include "rdma/providers/fi_log.h"
 
@@ -132,6 +131,23 @@ int ofi_getsockname(SOCKET fd, struct sockaddr *addr, socklen_t *len)
 	return FI_SUCCESS;
 }
 
+int ofi_getpeername(SOCKET fd, struct sockaddr *addr, socklen_t *len)
+{
+	struct sockaddr_storage sock_addr;
+	socklen_t sock_addr_len = sizeof(sock_addr);
+	int ret;
+
+	ret = getpeername(fd, (struct sockaddr *) &sock_addr, &sock_addr_len);
+	if (ret)
+		return ret;
+
+	if (addr)
+		memcpy(addr, &sock_addr, MIN(*len, sock_addr_len));
+	*len = sock_addr_len;
+
+	return FI_SUCCESS;
+}
+
 int fi_read_file(const char *dir, const char *file, char *buf, size_t size)
 {
 	char *path = 0;
@@ -386,48 +402,6 @@ fn_nomem:
 	goto fn_complete;
 }
 
-/* enumerate existing addresses */
-/* in case if GetIpAddrTable is not enough, try to use
-   GetAdaptersInfo or GetAdaptersAddresses */
-void sock_get_ip_addr_table(struct slist *addr_list)
-{
-	DWORD i;
-	MIB_IPADDRTABLE _iptbl;
-	MIB_IPADDRTABLE *iptbl = &_iptbl;
-	ULONG ips = 1;
-	ULONG res = GetIpAddrTable(iptbl, &ips, 0);
-	if (res == ERROR_INSUFFICIENT_BUFFER) {
-		iptbl = malloc(ips);
-		if (!iptbl)
-			goto failed_no_mem;
-		res = GetIpAddrTable(iptbl, &ips, 0);
-		if (res != NO_ERROR)
-			goto failed_get_addr;
-	}
-	else if (res != NO_ERROR) {
-		goto failed;
-	}
-
-	for (i = 0; i < iptbl->dwNumEntries; i++) {
-		if (iptbl->table[i].dwAddr && iptbl->table[i].dwAddr != ntohl(INADDR_LOOPBACK)) {
-			struct sock_host_list_entry *addr_entry;
-			addr_entry = calloc(1, sizeof(struct sock_host_list_entry));
-			inet_ntop(AF_INET, &iptbl->table[i].dwAddr, addr_entry->hostname, sizeof(addr_entry->hostname));
-			slist_insert_tail(&addr_entry->entry, addr_list);
-		}
-	}
-
-	if (iptbl != &_iptbl)
-		free(iptbl);
-	return;
-
-failed_get_addr:
-	free(iptbl);
-failed_no_mem:
-failed:
-	return;
-}
-
 int getifaddrs(struct ifaddrs **ifap)
 {
 	DWORD i;
@@ -500,44 +474,94 @@ void freeifaddrs(struct ifaddrs *ifa)
 	}
 }
 
-ssize_t ofi_writev_socket(SOCKET fd, const struct iovec *iovec, size_t iov_cnt)
+static ssize_t
+ofi_sendv_socket(SOCKET fd, const struct iovec *iovec, size_t iov_cnt, int flags)
 {
-	ssize_t size;
+	ssize_t size = 0;
 	int ret, i;
-	WSABUF *wsa_buf;
-	DWORD flags = 0;
 
-	wsa_buf = (WSABUF *)alloca(iov_cnt * sizeof(WSABUF));
+	if (iov_cnt == 1)
+		return send(fd, iovec[0].iov_base, iovec[0].iov_len, flags);
 
 	for (i = 0; i < iov_cnt; i++) {
-		wsa_buf[i].buf = (char *)iovec[i].iov_base;
-		wsa_buf[i].len = iovec[i].iov_len;
+		ret = send(fd, iovec[i].iov_base, iovec[i].iov_len, flags);
+		if (ret >= 0) {
+			size += ret;
+			if (ret != iovec[i].iov_len)
+				return size;
+		} else {
+			return size ? size : ret;
+		}
 	}
+	return size;
+}
 
-	ret = WSASend(fd, wsa_buf, iov_cnt, &size, &flags, NULL, NULL);
-	if (ret)
-		size = (ssize_t)ret;
+static ssize_t
+ofi_recvv_socket(SOCKET fd, const struct iovec *iovec, size_t iov_cnt, int flags)
+{
+	ssize_t size = 0;
+	int ret, i;
 
+	if (iov_cnt == 1)
+		return recv(fd, iovec[0].iov_base, iovec[0].iov_len, flags);
+
+	for (i = 0; i < iov_cnt; i++) {
+		ret = recv(fd, iovec[i].iov_base, iovec[i].iov_len, flags);
+		if (ret >= 0) {
+			size += ret;
+			if (ret != iovec[i].iov_len)
+				return size;
+		} else {
+			return size ? size : ret;
+		}
+	}
 	return size;
 }
 
+ssize_t ofi_writev_socket(SOCKET fd, const struct iovec *iovec, size_t iov_cnt)
+{
+	return ofi_sendv_socket(fd, iovec, iov_cnt, 0);
+}
+
 ssize_t ofi_readv_socket(SOCKET fd, const struct iovec *iovec, size_t iov_cnt)
 {
-	ssize_t size;
-	int ret,i;
-	WSABUF *wsa_buf;
-	DWORD flags = 0;
+	return ofi_recvv_socket(fd, iovec, iov_cnt, 0);
+}
 
-	wsa_buf = (WSABUF *)alloca(iov_cnt *sizeof(WSABUF));
+ssize_t ofi_sendmsg_tcp(SOCKET fd, const struct msghdr *msg, int flags)
+{
+	return ofi_sendv_socket(fd, msg->msg_iov, msg->msg_iovlen, flags);
+}
 
-	for (i = 0; i <iov_cnt; i++) {
-		wsa_buf[i].buf = (char *)iovec[i].iov_base;
-		wsa_buf[i].len = iovec[i].iov_len;
-	}
+ssize_t ofi_recvmsg_tcp(SOCKET fd, struct msghdr *msg, int flags)
+{
+	return ofi_recvv_socket(fd, msg->msg_iov, msg->msg_iovlen, flags);
+}
 
-	ret = WSARecv(fd, wsa_buf, iov_cnt, &size, &flags, NULL, NULL);
-	if (ret)
-		size = (ssize_t)ret;
+/*
+ * We assume that the same WSARecvMsg pointer will work for all UDP sockets.
+ */
+ssize_t ofi_recvmsg_udp(SOCKET fd, struct msghdr *msg, int flags)
+{
+	static LPFN_WSARECVMSG WSARecvMsg = NULL;
+	GUID guid = WSAID_WSARECVMSG;
+	DWORD bytes;
+	int ret;
 
-	return size;
+	if (!WSARecvMsg) {
+		pthread_mutex_lock(&common_locks.ini_lock);
+		if (!WSARecvMsg) {
+			ret = WSAIoctl(fd, SIO_GET_EXTENSION_FUNCTION_POINTER, &guid,
+					sizeof(guid), &WSARecvMsg, sizeof(WSARecvMsg),
+					&bytes, NULL, NULL);
+		} else {
+			ret = 0;
+		}
+		pthread_mutex_unlock(&common_locks.ini_lock);
+		if (ret)
+			return ret;
+	}
+
+	ret = WSARecvMsg(fd, msg, &bytes, NULL, NULL);
+	return ret ? ret : bytes;
 }
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/strerror.vcxproj b/src/mpid/ch4/netmod/ofi/libfabric/strerror.vcxproj
index 92d685dac..ed0f356ca 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/strerror.vcxproj
+++ b/src/mpid/ch4/netmod/ofi/libfabric/strerror.vcxproj
@@ -30,8 +30,8 @@
     <ProjectGuid>{C835FB00-8E80-4D4A-9791-4B7D6D37168A}</ProjectGuid>
     <Keyword>Win32Proj</Keyword>
     <RootNamespace>strerror</RootNamespace>
-    <WindowsTargetPlatformVersion>8.1</WindowsTargetPlatformVersion>
   </PropertyGroup>
+  <Import Project="$(SolutionDir)\Libfabric.Build.Default.props" />
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
   <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug-v140|x64'" Label="Configuration">
     <ConfigurationType>Application</ConfigurationType>
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/util/info.c b/src/mpid/ch4/netmod/ofi/libfabric/util/info.c
index ae66bfb7f..131591d3f 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/util/info.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/util/info.c
@@ -19,7 +19,7 @@
  *
  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AWV
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
@@ -219,6 +219,8 @@ static const char *param_type(enum fi_param_type type)
 		return "String";
 	case FI_PARAM_INT:
 		return "Integer";
+	case FI_PARAM_SIZE_T:
+		return "size_t";
 	case FI_PARAM_BOOL:
 		return "Boolean (0/1, on/off, true/false, yes/no)";
 	default:
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/util/pingpong.c b/src/mpid/ch4/netmod/ofi/libfabric/util/pingpong.c
index 9651e62ff..23f3adc77 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/util/pingpong.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/util/pingpong.c
@@ -21,7 +21,7 @@
  *
  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AWV
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
@@ -65,10 +65,6 @@
 #define OFI_MR_BASIC_MAP (FI_MR_ALLOCATED | FI_MR_PROV_KEY | FI_MR_VIRT_ADDR)
 #endif
 
-#ifndef PP_FIVERSION
-#define PP_FIVERSION FI_VERSION(1, 5)
-#endif
-
 static const uint64_t TAG = 1234;
 
 enum precision {
@@ -182,7 +178,8 @@ struct ct_pingpong {
 
 	fi_addr_t remote_fi_addr;
 	void *buf, *tx_buf, *rx_buf;
-	size_t buf_size, tx_size, rx_size, msg_prefix_size;
+	size_t buf_size, tx_size, rx_size;
+	size_t rx_prefix_size, tx_prefix_size;
 
 	int timeout_sec;
 	uint64_t start, end;
@@ -245,13 +242,8 @@ static long parse_ulong(char *str, long max)
 
 static void pp_banner_fabric_info(struct ct_pingpong *ct)
 {
-	PP_DEBUG(
-	    "Running pingpong test with the %s provider and %s endpoint type\n",
-	    ct->fi->fabric_attr->prov_name,
-	    fi_tostr(&ct->fi->ep_attr->type, FI_TYPE_EP_TYPE));
-	PP_DEBUG("%s", fi_tostr(ct->fi->fabric_attr, FI_TYPE_FABRIC_ATTR));
-	PP_DEBUG("%s", fi_tostr(ct->fi->domain_attr, FI_TYPE_DOMAIN_ATTR));
-	PP_DEBUG("%s", fi_tostr(ct->fi->ep_attr, FI_TYPE_EP_ATTR));
+	PP_DEBUG("Running pingpong test with fi_info:\n%s\n",
+		 fi_tostr(ct->fi, FI_TYPE_INFO));
 }
 
 static void pp_banner_options(struct ct_pingpong *ct)
@@ -565,6 +557,18 @@ static int pp_send_name(struct ct_pingpong *ct, struct fid *endpoint)
 	if (ret < 0)
 		goto fn;
 
+	PP_DEBUG("Sending address format\n");
+	if (ct->fi) {
+		ret = pp_ctrl_send(ct, (char *) &ct->fi->addr_format,
+				   sizeof(ct->fi->addr_format));
+	} else {
+		ret = pp_ctrl_send(ct, (char *) &ct->fi_pep->addr_format,
+				   sizeof(ct->fi_pep->addr_format));
+
+	}
+	if (ret < 0)
+		goto fn;
+
 	PP_DEBUG("Sending name\n");
 	ret = pp_ctrl_send(ct, local_name, addrlen);
 	PP_DEBUG("Sent name\n");
@@ -592,6 +596,12 @@ static int pp_recv_name(struct ct_pingpong *ct)
 		return -ENOMEM;
 	}
 
+	PP_DEBUG("Receiving address format\n");
+	ret = pp_ctrl_recv(ct, (char *) &ct->hints->addr_format,
+			   sizeof(ct->hints->addr_format));
+	if (ret < 0)
+		return ret;
+
 	PP_DEBUG("Receiving name\n");
 	ret = pp_ctrl_recv(ct, ct->rem_name, len);
 	if (ret < 0)
@@ -856,7 +866,7 @@ static int pp_check_buf(void *buf, int size)
 
 static void eq_readerr(struct fid_eq *eq)
 {
-	struct fi_eq_err_entry eq_err;
+	struct fi_eq_err_entry eq_err = { 0 };
 	int rd;
 
 	rd = fi_eq_readerr(eq, &eq_err, 0);
@@ -1042,7 +1052,7 @@ static void show_perf(char *name, int tsize, int sent, int acked,
 
 static int pp_cq_readerr(struct fid_cq *cq)
 {
-	struct fi_cq_err_entry cq_err;
+	struct fi_cq_err_entry cq_err = { 0 };
 	int ret;
 
 	ret = fi_cq_readerr(cq, &cq_err, 0);
@@ -1067,7 +1077,7 @@ static int pp_get_cq_comp(struct fid_cq *cq, uint64_t *cur, uint64_t total,
 	if (timeout_sec >= 0)
 		a = pp_gettime_us();
 
-	while (total - *cur > 0) {
+	do {
 		ret = fi_cq_read(cq, &comp, 1);
 		if (ret > 0) {
 			if (timeout_sec >= 0)
@@ -1091,7 +1101,7 @@ static int pp_get_cq_comp(struct fid_cq *cq, uint64_t *cur, uint64_t total,
 				return -FI_ENODATA;
 			}
 		}
-	}
+	} while (total - *cur > 0);
 
 	return 0;
 }
@@ -1171,9 +1181,9 @@ static ssize_t pp_tx(struct ct_pingpong *ct, struct fid_ep *ep, size_t size)
 	ssize_t ret;
 
 	if (pp_check_opts(ct, PP_OPT_VERIFY_DATA | PP_OPT_ACTIVE))
-		pp_fill_buf((char *)ct->tx_buf + ct->msg_prefix_size, size);
+		pp_fill_buf((char *)ct->tx_buf + ct->tx_prefix_size, size);
 
-	ret = pp_post_tx(ct, ep, size + ct->msg_prefix_size, ct->tx_ctx_ptr);
+	ret = pp_post_tx(ct, ep, size + ct->tx_prefix_size, ct->tx_ctx_ptr);
 	if (ret)
 		return ret;
 
@@ -1200,9 +1210,9 @@ static ssize_t pp_inject(struct ct_pingpong *ct, struct fid_ep *ep, size_t size)
 	ssize_t ret;
 
 	if (pp_check_opts(ct, PP_OPT_VERIFY_DATA | PP_OPT_ACTIVE))
-		pp_fill_buf((char *)ct->tx_buf + ct->msg_prefix_size, size);
+		pp_fill_buf((char *)ct->tx_buf + ct->tx_prefix_size, size);
 
-	ret = pp_post_inject(ct, ep, size + ct->msg_prefix_size);
+	ret = pp_post_inject(ct, ep, size + ct->tx_prefix_size);
 	if (ret)
 		return ret;
 
@@ -1214,12 +1224,10 @@ static ssize_t pp_post_rx(struct ct_pingpong *ct, struct fid_ep *ep,
 {
 	if (!(ct->fi->caps & FI_TAGGED))
 		PP_POST(fi_recv, pp_get_rx_comp, ct->rx_seq, "receive", ep,
-			ct->rx_buf, MAX(size, PP_MAX_CTRL_MSG + ct->msg_prefix_size),
-			fi_mr_desc(ct->mr), 0, ctx);
+			ct->rx_buf, size, fi_mr_desc(ct->mr), 0, ctx);
 	else
 		PP_POST(fi_trecv, pp_get_rx_comp, ct->rx_seq, "t-receive", ep,
-			ct->rx_buf, MAX(size, PP_MAX_CTRL_MSG + ct->msg_prefix_size),
-			fi_mr_desc(ct->mr), 0, TAG, 0, ctx);
+			ct->rx_buf, size, fi_mr_desc(ct->mr), 0, TAG, 0, ctx);
 	return 0;
 }
 
@@ -1232,7 +1240,7 @@ static ssize_t pp_rx(struct ct_pingpong *ct, struct fid_ep *ep, size_t size)
 		return ret;
 
 	if (pp_check_opts(ct, PP_OPT_VERIFY_DATA | PP_OPT_ACTIVE)) {
-		ret = pp_check_buf((char *)ct->rx_buf + ct->msg_prefix_size,
+		ret = pp_check_buf((char *)ct->rx_buf + ct->rx_prefix_size,
 				   size);
 		if (ret)
 			return ret;
@@ -1244,8 +1252,8 @@ static ssize_t pp_rx(struct ct_pingpong *ct, struct fid_ep *ep, size_t size)
 	 * before message size is updated. The recvs posted are always for the
 	 * next incoming message.
 	 */
-	ret = pp_post_rx(ct, ct->ep, ct->rx_size + ct->msg_prefix_size,
-			 ct->rx_ctx_ptr);
+	ret = pp_post_rx(ct, ct->ep, MAX(ct->rx_size , PP_MAX_CTRL_MSG) +
+			 ct->rx_prefix_size, ct->rx_ctx_ptr);
 	if (!ret)
 		ct->cnt_ack_msg++;
 
@@ -1287,7 +1295,7 @@ static int pp_alloc_msgs(struct ct_pingpong *ct)
 	ct->rx_size = ct->tx_size;
 	ct->buf_size = MAX(ct->tx_size, PP_MAX_CTRL_MSG) +
 		       MAX(ct->rx_size, PP_MAX_CTRL_MSG) +
-		       2 * ct->msg_prefix_size;
+		       ct->tx_prefix_size + ct->rx_prefix_size;
 
 	alignment = ofi_sysconf(_SC_PAGESIZE);
 	if (alignment < 0) {
@@ -1307,7 +1315,7 @@ static int pp_alloc_msgs(struct ct_pingpong *ct)
 	ct->rx_buf = ct->buf;
 	ct->tx_buf = (char *)ct->buf +
 			MAX(ct->rx_size, PP_MAX_CTRL_MSG) +
-			ct->msg_prefix_size;
+			ct->tx_prefix_size;
 	ct->tx_buf = (void *)(((uintptr_t)ct->tx_buf + alignment - 1) &
 			      ~(alignment - 1));
 
@@ -1395,7 +1403,11 @@ static int pp_alloc_active_res(struct ct_pingpong *ct, struct fi_info *fi)
 			return ret;
 		}
 	}
-	ct->msg_prefix_size = fi->ep_attr->msg_prefix_size;
+
+	if (fi->tx_attr->mode & FI_MSG_PREFIX)
+		ct->tx_prefix_size = fi->ep_attr->msg_prefix_size;
+	if (fi->rx_attr->mode & FI_MSG_PREFIX)
+		ct->rx_prefix_size = fi->ep_attr->msg_prefix_size;
 
 	ret = fi_endpoint(ct->domain, fi, &(ct->ep), NULL);
 	if (ret) {
@@ -1415,7 +1427,8 @@ static int pp_getinfo(struct ct_pingpong *ct, struct fi_info *hints,
 	if (!hints->ep_attr->type)
 		hints->ep_attr->type = FI_EP_DGRAM;
 
-	ret = fi_getinfo(PP_FIVERSION, NULL, NULL, flags, hints, info);
+	ret = fi_getinfo(FI_VERSION(FI_MAJOR_VERSION, FI_MINOR_VERSION),
+			 NULL, NULL, flags, hints, info);
 	if (ret) {
 		PP_PRINTERR("fi_getinfo", ret);
 		return ret;
@@ -1445,7 +1458,7 @@ static int pp_getinfo(struct ct_pingpong *ct, struct fi_info *hints,
 		ct->rx_ctx_ptr = NULL;
 	}
 
-	if (hints && ((hints->caps & FI_DIRECTED_RECV) == 0)) {
+	if ((hints->caps & FI_DIRECTED_RECV) == 0) {
 		(*info)->caps &= ~FI_DIRECTED_RECV;
 		(*info)->rx_attr->caps &= ~FI_DIRECTED_RECV;
 	}
@@ -1483,8 +1496,8 @@ static int pp_init_ep(struct ct_pingpong *ct)
 		return ret;
 	}
 
-	ret = pp_post_rx(ct, ct->ep, MAX(ct->rx_size, PP_MAX_CTRL_MSG),
-			 ct->rx_ctx_ptr);
+	ret = pp_post_rx(ct, ct->ep, MAX(ct->rx_size, PP_MAX_CTRL_MSG) +
+			 ct->rx_prefix_size, ct->rx_ctx_ptr);
 	if (ret)
 		return ret;
 
@@ -1522,10 +1535,6 @@ static int pp_exchange_names_connected(struct ct_pingpong *ct)
 
 	PP_DEBUG("Connection-based endpoint: setting up connection\n");
 
-	ret = pp_ctrl_sync(ct);
-	if (ret)
-		return ret;
-
 	if (ct->opts.dst_addr) {
 		ret = pp_recv_name(ct);
 		if (ret < 0)
@@ -1599,26 +1608,21 @@ static int pp_server_connect(struct ct_pingpong *ct)
 
 	ret = pp_exchange_names_connected(ct);
 	if (ret)
-		goto err;
-
-	ret = pp_ctrl_sync(ct);
-	if (ret)
-		goto err;
+		return ret;
 
 	/* Listen */
 	rd = fi_eq_sread(ct->eq, &event, &entry, sizeof(entry), -1, 0);
 	if (rd != sizeof(entry)) {
 		pp_process_eq_err(rd, ct->eq, "fi_eq_sread");
-		return (int)rd;
+		return (int) rd;
 	}
 
-	ct->fi = entry.info;
 	if (event != FI_CONNREQ) {
 		fprintf(stderr, "Unexpected CM event %d\n", event);
-		ret = -FI_EOTHER;
-		goto err;
+		return -FI_EOTHER;
 	}
 
+	ct->fi = entry.info;
 	ret = fi_domain(ct->fabric, ct->fi, &(ct->domain), NULL);
 	if (ret) {
 		PP_PRINTERR("fi_domain", ret);
@@ -1641,10 +1645,6 @@ static int pp_server_connect(struct ct_pingpong *ct)
 		goto err;
 	}
 
-	ret = pp_ctrl_sync(ct);
-	if (ret)
-		goto err;
-
 	/* Accept */
 	rd = fi_eq_sread(ct->eq, &event, &entry, sizeof(entry), -1, 0);
 	if (rd != sizeof(entry)) {
@@ -1679,11 +1679,6 @@ static int pp_client_connect(struct ct_pingpong *ct)
 	if (ret)
 		return ret;
 
-	/* Check that the remote is still up */
-	ret = pp_ctrl_sync(ct);
-	if (ret)
-		return ret;
-
 	ret = pp_open_fabric_res(ct);
 	if (ret)
 		return ret;
@@ -1702,10 +1697,6 @@ static int pp_client_connect(struct ct_pingpong *ct)
 		return ret;
 	}
 
-	ret = pp_ctrl_sync(ct);
-	if (ret)
-		return ret;
-
 	/* Connect */
 	rd = fi_eq_sread(ct->eq, &event, &entry, sizeof(entry), -1, 0);
 	if (rd != sizeof(entry)) {
@@ -1846,7 +1837,7 @@ static int pp_finalize(struct ct_pingpong *ct)
 {
 	struct iovec iov;
 	int ret;
-	struct fi_context ctx;
+	struct fi_context ctx[2];
 	struct fi_msg msg;
 	struct fi_msg_tagged tmsg;
 
@@ -1854,14 +1845,14 @@ static int pp_finalize(struct ct_pingpong *ct)
 
 	strcpy(ct->tx_buf, "fin");
 	iov.iov_base = ct->tx_buf;
-	iov.iov_len = 4 + ct->msg_prefix_size;
+	iov.iov_len = 4 + ct->tx_prefix_size;
 
 	if (!(ct->fi->caps & FI_TAGGED)) {
 		memset(&msg, 0, sizeof(msg));
 		msg.msg_iov = &iov;
 		msg.iov_count = 1;
 		msg.addr = ct->remote_fi_addr;
-		msg.context = &ctx;
+		msg.context = ctx;
 
 		ret = fi_sendmsg(ct->ep, &msg, FI_INJECT | FI_TRANSMIT_COMPLETE);
 		if (ret) {
@@ -1873,7 +1864,7 @@ static int pp_finalize(struct ct_pingpong *ct)
 		tmsg.msg_iov = &iov;
 		tmsg.iov_count = 1;
 		tmsg.addr = ct->remote_fi_addr;
-		tmsg.context = &ctx;
+		tmsg.context = ctx;
 		tmsg.tag = TAG;
 
 		ret = fi_tsendmsg(ct->ep, &tmsg, FI_INJECT | FI_TRANSMIT_COMPLETE);
diff --git a/src/mpid/ch4/netmod/ofi/libfabric/util/strerror.c b/src/mpid/ch4/netmod/ofi/libfabric/util/strerror.c
index ed8d338ce..a890968f7 100644
--- a/src/mpid/ch4/netmod/ofi/libfabric/util/strerror.c
+++ b/src/mpid/ch4/netmod/ofi/libfabric/util/strerror.c
@@ -19,7 +19,7 @@
  *
  * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
  * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AWV
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
  * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
  * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
  * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
